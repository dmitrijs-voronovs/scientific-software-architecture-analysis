quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability,"	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2019-10-01 02:53:03,81] [info] WorkflowManagerActor WorkflowActor-c55a06f3-abc1-4db1-8e0f-ea0303caab2c is in a terminal state: WorkflowFailedState; [2019-10-01 02:53:07,42] [info] Not triggering log of token queue status. Effective log interval = None; [2019-10-01 02:53:08,41] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2019-10-01 02:53:12,32] [info] Workflow polling stopped; [2019-10-01 02:53:12,33] [info] 0 workflows released by cromid-876ccf5; [2019-10-01 02:53:12,34] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2019-10-01 02:53:12,34] [info] Aborting all running workflows.; [2019-10-01 02:53:12,34] [info] JobExecutionTokenDispenser stopped; [2019-10-01 02:53:12,35] [info] WorkflowStoreActor stopped; [2019-10-01 02:53:12,35] [info] WorkflowLogCopyRouter stopped; [2019-10-01 02:53:12,35] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor All workflows finished; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor stopped; [2019-10-01 02:53:12,65] [info] Connection pools shut down; [2019-10-01 02:53:12,65] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2019-10",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:9433,down,down,9433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,3,['down'],['down']
Availability,"	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:353); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:46); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:134); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:40); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 18 more; 19/02/18 16:58:29 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 16:58:29.970 INFO PrintVariantsSpark - Shutting down engine; [February 18, 2019 4:58:29 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:8825,down,down,8825,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['down'],['down']
Availability, 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); Caused by: org.sqlite.SQLiteException: [SQLITE_IOERR_LOCK] I/O error in the advisory file locking logic (disk I/O error); 	at org.sqlite.core.DB.newSQLException(DB.java:909); 	at org.sqlite.core.DB.newSQLException(DB.java:921); 	at org.sqlite.core.DB.throwex(DB.java:886); 	at org.sqlite.core.NativeDB.prepare_utf8(Native Method); 	at org.sqlite.core.NativeDB.prepare(NativeDB.java:127); 	at org.sqlite.core.DB.prepare(DB.java:227); 	at org.sqlite.jdbc3.JDBC3Statement.executeQuery(JDBC3Statement.java:81); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.cosmic.CosmicFuncotationFactory.createFuncotations(CosmicFuncotationFactory.java:215); 	... 21 more. ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4413:2312,error,error,2312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413,2,['error'],['error']
Availability, 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:178); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: java.net.UnknownHostException: bioinfo: bioinfo: unknown error; 	at java.net.InetAddress.getLocalHost(InetAddress.java:1505); 	at org.apache.spark.util.Utils$.findLocalInetAddress(Utils.scala:891); 	at org.apache.spark.util.Utils$.org$apache$spark$util$Utils$$localIpAddress$lzycompute(Utils.scala:884); 	at org.apache.spark.util.Utils$.org$apache$spark$util$Utils$$localIpAddress(Utils.scala:884); 	at org.apache.spark.util.Utils$$anonfun$localHostName$1.apply(Utils.scala:941); 	at org.apache.spark.util.Utils$$anonfun$localHostName$1.apply(Utils.scala:941); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.util.Utils$.localHostName(Utils.scala:941); 	at org.apache.spark.internal.config.package$.<init>(package.scala:204); 	at org.apache.spark.internal.config.package$.<clinit>(package.scala); 	... 12 more; Caused by: java.net.UnknownHostException: bioinfo: unknown error; 	at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method); 	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928); 	at java.net.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5802:3887,error,error,3887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802,1,['error'],['error']
Availability," (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. After sourcing the tab-completion script, some tools shown cannot be run. Maybe they exist somewhere in an experimental dev version but are not bundled for public release?. ### Affected version(s); - [x ] Latest public release version [4.1.7.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. After trying to tab complete the DepthOfCoverage, I saw a few tools not listed in the documentation. I tried running them and sure enough, there were errors:. `A USER ERROR has occurred: '*' is not a valid command.`; (* is one of the tools listed below). #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. ```; cd gatk-4.1.7.0; source gatk-completion.sh; ./gatk Depth<tab>; #>DepthOfCoverage DepthPerAlleleBySample DepthPerSampleHC; ./gatk DepthPerSampleHC -h; ...; ***********************************************************************; A USER ERROR has occurred: 'DepthPerSampleHC' is not a valid command.; ***********************************************************************; ./gatk DepthPerAlleleBySample -h; ...; ***********************************************************************; A USER ERROR has occurred: 'DepthPerAlleleBySample' is not a valid command.; ***********************************************************************; ./gatk DepthOfCoverage -h; **BETA FEATURE - WORK IN PROGRESS**; USAGE: DepthOfCoverage [arguments]; Generate coverage summary information for reads data; Version:4.1.7.0; ....; ```. #### Expected behavior; _Tell us what should happen_. Only valid tools should be available for tab completion",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6615:2383,ERROR,ERROR,2383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6615,3,"['ERROR', 'avail']","['ERROR', 'available']"
Availability," - ------------------------------------------------------------ 01:13:16.077 INFO HaplotypeCaller - HTSJDK Version: 2.13.2 01:13:16.077 INFO HaplotypeCaller - Picard Version: 2.17.2 01:13:16.077 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false 01:13:16.078 INFO HaplotypeCaller - Deflater: IntelDeflater 01:13:16.078 INFO HaplotypeCaller - Inflater: IntelInflater 01:13:16.078 INFO HaplotypeCaller - GCS max retries/reopens: 20 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes 01:13:16.078 INFO HaplotypeCaller - Initializing engine 01:13:17.087 INFO HaplotypeCaller - Shutting down engine [January 18, 2020 1:13:17 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes. Runtime.totalMemory()=2216689664 java.lang.NullPointerException at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463) at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457) at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234) at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150) at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98) at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:621) at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:563) at org.broadinstitute.hellbe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-1605272955:2010,down,down,2010,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-1605272955,1,['down'],['down']
Availability," - Fix up FQ and race condition issues with volatile tasks work [VS-478] (#7888); - Use gvs-internal project in integration test (#7901); - Add cost observability BQ table [VS-441] (#7891); - Add preliminary labels to queries [VS-381] (#7902); - Workflow compute costs [VS-472] (#7905); - Fix bug and update images (#7912); - VS 483 Beta user wdl (#7894); - Core storage model cost [VS-473] (#7913); - Update Quickstart & Integration to use re-blocked v2 gVCFs [VS-491] (#7924); - KM GVS documentation (#7903); - Track BigQuery costs of GVS python VS-480 (#7915); - Read cost observability table [VS-475] (#7923); - Fix Race Condition, Add Support for Extract by Array of Sample Names (ie from a Sample Set) (#7917); - Rightsize import batches [VS-486] (#7925); - [AoU DRC] Support uppercase site_ids for reblocking (#7929); - Populate cost metadata for GATK tasks. (#7919); - remove accidentally added input (#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change bac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:26303,error,errors,26303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['error'],['errors']
Availability," - GCS max retries/reopens: 20; 10:19:39.338 INFO GenomicsDBImport - Requester pays: disabled; 10:19:39.338 INFO GenomicsDBImport - Initializing engine; 10:19:39.489 INFO IntervalArgumentCollection - Processing 100 bp from intervals; 10:19:39.490 INFO GenomicsDBImport - Done initializing engine; 10:19:39.948 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.4.4-ce4e1b9; 10:19:39.951 INFO GenomicsDBImport - Vid Map JSON file will be written to /home/test/Software/gatk-4.4.0.0/test/./02/vidmap.json; 10:19:39.951 INFO GenomicsDBImport - Callset Map JSON file will be written to /home/test/Software/gatk-4.4.0.0/test/./02/callset.json; 10:19:39.951 INFO GenomicsDBImport - Complete VCF Header will be written to /home/test/Software/gatk-4.4.0.0/test/./02/vcfheader.vcf; 10:19:39.951 INFO GenomicsDBImport - Importing to workspace - /home/test/Software/gatk-4.4.0.0/test/./02; 10:19:40.060 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 10:19:40.075 INFO GenomicsDBImport - Shutting down engine; org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=285212672; java.lang.NumberFormatException: For input string: ""G""; 	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67); 	at java.base/java.lang.Integer.parseInt(Integer.java:668); 	at java.base/java.lang.Integer.parseInt(Integer.java:786); 	at htsjdk.tribble.readers.TabixReader.getIntv(TabixReader.java:337); 	at htsjdk.tribble.readers.TabixReader.access$500(TabixReader.java:48); 	at htsjdk.tribble.readers.TabixReader$IteratorImpl.next(TabixReader.java:438); 	at htsjdk.tribble.readers.TabixIteratorLineReader.readLine(TabixIteratorLineReader.java:46); 	at htsjdk.tribble.TabixFeatureReader$FeatureIterator.readNextRecord(TabixFeatureReader.java:170); 	at htsjdk.tribble.TabixFeatureReader$FeatureIterator.<init>(TabixFeatureReader.java:159); 	at htsjdk.tribble.TabixFeatureReader.query(TabixFeatureReader.java:13",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8517:3029,down,down,3029,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8517,1,['down'],['down']
Availability," - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:48:13.680 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 00:48:13.680 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 00:48:13.680 INFO MarkDuplicatesSpark - Initializing engine; 00:48:13.680 INFO MarkDuplicatesSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4aa298b7] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@37574691].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 00:48:19.247 INFO MarkDuplicatesSpark - Shutting down engine; [June 7, 2017 12:48:19 AM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=1029701632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 0.0 failed 4 times, most recent failure: Lost task 15.3 in stage 0.0 (TID 59, 172.31.77.139, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2722); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1565); a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:4121,ERROR,ERROR,4121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['ERROR'],['ERROR']
Availability," - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:15:57.329 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:15:57.329 INFO FilterMutectCalls - Deflater: IntelDeflater; 11:15:57.329 INFO FilterMutectCalls - Inflater: IntelInflater; 11:15:57.329 INFO FilterMutectCalls - GCS max retries/reopens: 20; 11:15:57.329 INFO FilterMutectCalls - Requester pays: disabled; 11:15:57.329 INFO FilterMutectCalls - Initializing engine; 11:15:57.537 INFO FeatureManager - Using codec VCFCodec to read file file:///tmp/tmp.8lRGFREUhm/MT.vcf.gz; 11:15:57.553 INFO FilterMutectCalls - Done initializing engine; 11:15:57.599 INFO ProgressMeter - Starting traversal; 11:15:57.599 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 11:15:57.599 INFO FilterMutectCalls - Starting pass 0 through the variants; 11:15:57.637 INFO FilterMutectCalls - Finished pass 0 through the variants; 11:15:57.657 INFO FilterMutectCalls - Shutting down engine; [November 7, 2019 11:15:57 AM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2148007936; java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:122); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:3126,down,down,3126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['down'],['down']
Availability," - Importing batch 1 with 80 samples; 17:18:22.600 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:18:30.825 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:18:36.178 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:18:41.657 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:18:48.155 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:18:54.358 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:19:01.067 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:19:08.337 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:19:09.814 INFO ProgressMeter - chr1:227419 95.0 1 0.0; 17:19:09.814 INFO GenomicsDBImport - Done importing batch 1/1; 17:19:09.815 INFO ProgressMeter - chr1:227419 95.0 1 0.0; 17:19:09.815 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 95.0 minutes.; 17:19:09.815 INFO GenomicsDBImport - Import completed!; 17:19:09.816 INFO GenomicsDBImport - Shutting down engine; [January 16, 2021 5:19:09 PM IST] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 95.12 minutes.; Runtime.totalMemory()=13188464640. And when I tried to create panel of normal using `CreateSomaticPanelOfNormals` and I am getting an error that `It isn't a regular file`: Here is the stack trace:. 17:19:12.932 INFO CreateSomaticPanelOfNormals - ------------------------------------------------------------; 17:19:12.933 INFO CreateSomaticPanelOfNormals - The Genome Analysis Toolkit (GATK) v4.1.9.0; 17:19:12.933 INFO CreateSomaticPanelOfNormals - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:19:12.933 INFO CreateSomaticPanelOfNormals - Executing as akansha@sbilab on Linux v4.4.0-169-generic amd64; 17:19:12.933 INFO CreateSomaticPanelOfNormals - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~16.04-b01; 17:19:12.933 INFO CreateSomaticPanelOfNormals - Start Date/Time: January 16, 2021 5:19:12 PM ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-761558811:13139,down,down,13139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-761558811,1,['down'],['down']
Availability," - Inflater: IntelInflater; 08:33:37.135 INFO FilterAlignmentArtifacts - GCS max retries/reopens: 20; 08:33:37.135 INFO FilterAlignmentArtifacts - Requester pays: disabled; 08:33:37.136 WARN FilterAlignmentArtifacts -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 08:33:37.136 INFO FilterAlignmentArtifacts - Initializing engine; 08:33:37.531 INFO FeatureManager - Using codec VCFCodec to read file file:///data/filteredVCF/in2510-8.orientationFilter.vcf; 08:33:37.586 INFO FilterAlignmentArtifacts - Done initializing engine; 08:33:37.668 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 08:33:37.706 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 08:33:37.707 INFO IntelPairHmm - Available threads: 8; 08:33:37.707 INFO IntelPairHmm - Requested threads: 4; 08:33:37.707 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 08:33:37.708 INFO ProgressMeter - Starting traversal; 08:33:37.708 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007ff7b7dfe32d, pid=849, tid=0x00007ff82e11d700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_smithwaterman5951765478004985534.so+0x132d] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x1bd; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:5132,Avail,Available,5132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['Avail'],['Available']
Availability," - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-09 13:35:14 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-09 13:35:14 INFO Client:54 - Verifying our application",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9514,AVAIL,AVAILABLE,9514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability," - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8339,AVAIL,AVAILABLE,8339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability," - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.36",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45836,AVAIL,AVAILABLE,45836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability," ------------------------------------------------------------------------------------------. then I added a name like this:. --variant:VCF $NOW/w-91.raw.g.vcf \; --variant:VCF $NOW/w-92.raw.g.vcf \; --variant:VCF $NOW/w-93.raw.g.vcf \. also met a error like this:. ##### ERROR; ##### ERROR MESSAGE: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; ##### ERROR ------------------------------------------------------------------------------------------. and I change the name like this:. --variant:VCF3 $NOW/w-91.raw.g.vcf \; --variant:VCF3 $NOW/w-92.raw.g.vcf \; --variant:VCF3 $NOW/w-93.raw.g.vcf \. also error:. ##### ERROR MESSAGE: Unable to parse header with error: Your input file has a malformed header: This codec is strictly for VCFv3 and does not support VCFv4.1, for input source: /gss1/home/hjb20181119/panyongpeng/NN1138-2/RIL_genotype/mapping/w-1.raw.g.vcf; ##### ERROR ------------------------------------------------------------------------------------------. I checked my GVCF file and the header is :. ##fileformat=VCFv4.1; ##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FORMAT=<ID=AD,Number=.,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block"">; ##FORMAT=<ID=PGT,Number=1,Type=String,Description=""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7315:2135,ERROR,ERROR,2135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7315,1,['ERROR'],['ERROR']
Availability," --MINIMUM_BASE_QUALITY 20 --STOP_AFTER -1 --INCLUDE_BQ_HISTOGRAM false --COUNT_UNPAIRED false --SAMPLE_SIZE 10000 --ALLELE_FRACTION 0.001 --ALLELE_FRACTION 0.005 --ALLELE_FRACTION 0.01 --ALLELE_FRACTION 0.02 --ALLELE_FRACTION 0.05 --ALLELE_FRACTION 0.1 --ALLELE_FRACTION 0.2 --ALLELE_FRACTION 0.3 --ALLELE_FRACTION 0.5 --READ_LENGTH 150 --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 8 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Sep 16, 2019 2:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Mon Sep 16 02:33:15 UTC 2019] Executing as user@server on Linux 3.10.0-693.21.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_192-b01; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.3.0; [Mon Sep 16 02:33:22 UTC 2019] picard.analysis.CollectWgsMetrics done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=6996099072; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; java.lang.IllegalArgumentException: The requested position is not covered by this StartEdgingRecordAndOffset object.; at htsjdk.samtools.util.AbstractRecordAndOffset.validateOffset(AbstractRecordAndOffset.java:109); at htsjdk.samtools.util.EdgingRecordAndOffset$StartEdgingRecordAndOffset.getBaseQuality(EdgingRecordAndOffset.java:112); at picard.analysis.FastWgsMetricsCollector.excludeByQuality(FastWgsMetricsCollector.java:189); at picard.analysis.FastWgsMetricsCollector.processRecord(FastWgsMetricsCollector.java:144); at picard.analysis.FastWgsMetricsCollector.addInfo(FastWgsMetricsCollector.java:105); at picard.analysis.WgsMetricsProcessorImpl.processFile(WgsMetricsProcessorImpl.java:93); at picard.analysis.CollectWgsMe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6163:2078,avail,available,2078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6163,1,['avail'],['available']
Availability, /work/Analysis/wgs_chr19/callset.json; 15:00:38.849 INFO GenomicsDBImport - Complete VCF Header will be written to /work/Analysis/wgs_chr19/vcfheader.vcf; 15:00:38.850 INFO GenomicsDBImport - Importing to array - /work/Analysis/wgs_chr19/genomicsdb_array; 15:00:38.850 INFO ProgressMeter - Starting traversal; 15:00:38.850 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 15:00:39.771 INFO GenomicsDBImport - Importing batch 1 with 5 samples; Buffer resized from 28469bytes to 32688; Buffer resized from 28473bytes to 32630; Buffer resized from 28469bytes to 32745; Buffer resized from 28469bytes to 32717; Buffer resized from 28466bytes to 32648; Buffer resized from 32688bytes to 32758; Buffer resized from 32630bytes to 32726; Buffer resized from 32648bytes to 32703; Buffer resized from 32717bytes to 32751; Buffer resized from 32703bytes to 32765; Buffer resized from 32745bytes to 32768; Buffer resized from 32726bytes to 32763; Buffer resized from 32765bytes to 32767; Buffer resized from 32758bytes to 32765; Buffer resized from 32751bytes to 32762; Buffer resized from 32767bytes to 32769; Buffer resized from 32763bytes to 32768; Buffer resized from 32762bytes to 32768; Buffer resized from 32765bytes to 32767; Buffer resized from 32767bytes to 32769; Buffer resized from 32768bytes to 32769; Buffer resized from 32768bytes to 32769; Buffer resized from 32768bytes to 32769; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : Error while syncing array chr19$1$58617616 to disk; TileDB error message : [TileDB::utils] Error: Cannot sync file '/work/Analysis/wgs_chr19/chr19$1$58617616/.__a89fdd44-1241-43ba-9072-6fcf116fbc1d139627949156096_1538460040234'; File syncing error. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/13135/gatk-v4-0-8-1-genomicsdbimport-error-variantstoragemanagerexception-exception/p1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342:4336,Error,Error,4336,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342,5,"['Error', 'error']","['Error', 'error', 'error-variantstoragemanagerexception-exception']"
Availability," 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 18/04/24 14:34:27 INFO DAGScheduler: Job 0 failed: first at ReadsSparkSource.java:221, took 4.816635 s; ```; Our system is an HPC, where all the nodes share the same file system. I run my SPARK on only one node to test the software. I red elesewhere that this might be aproblem of missing jars, so I tried to inlcude these libraries in the SPARK jar folder and added the option:; `; --conf [--jars=""~/bin/spark-2.2.0-bin-hadoop2.7/jars/hbase-client-1.4.3.jar, ~/bin/spark-2.2.0-bin-hadoop2.7/jars/hbase-common-1.4.3.jar, ~/bin/spark-2.2.0-bin-hadoop2.7/jars/hbase-hadoop2-compat-1.4.3.jar, ~/bin/spark-2.2.0-bin-hadoop2.7/jars/hive-hbase-handler-1.2.1.spark2.jar"" ]`. But I still get the error. Is GATK using hbase? If yes shall some jars be included to a local SPARK system to enable it to run GATK tools? Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383916494:2812,error,error,2812,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383916494,1,['error'],['error']
Availability, 02:07:52.355 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 02:07:52.355 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 02:07:52.356 INFO IntelPairHmm - Available threads: 104; 02:07:52.356 INFO IntelPairHmm - Requested threads: 4; 02:07:52.356 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 02:07:52.408 INFO ProgressMeter - Starting traversal; 02:07:52.408 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 02:07:53.316 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes; 02:07:53.598 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.49244E-4; 02:07:53.598 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.007888748000000001; 02:07:53.598 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.00 sec; 02:07:53.598 INFO HaplotypeCaller - Shutting down engine; [28 November 2019 at 2:07:53 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=8220835840; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.read.AlignmentUtils.needsConsolidation(AlignmentUtils.java:758); at org.broadinstitute.hellbender.utils.read.AlignmentUtils.consolidateCigar(AlignmentUtils.java:719); at org.broadinstitute.hellbender.utils.read.AlignmentUtils.applyCigarToCigar(AlignmentUtils.java:1290); at org.broadinstitute.hellbender.utils.read.AlignmentUtils.createReadAlignedToRef(AlignmentUtils.java:100); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.realignReadsToTheirBestHaplotype(AssemblyBasedCallerUtils.java:85); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:606); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6292:4274,down,down,4274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6292,1,['down'],['down']
Availability," 02:53:12,34] [info] Aborting all running workflows.; [2019-10-01 02:53:12,34] [info] JobExecutionTokenDispenser stopped; [2019-10-01 02:53:12,35] [info] WorkflowStoreActor stopped; [2019-10-01 02:53:12,35] [info] WorkflowLogCopyRouter stopped; [2019-10-01 02:53:12,35] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor All workflows finished; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor stopped; [2019-10-01 02:53:12,65] [info] Connection pools shut down; [2019-10-01 02:53:12,65] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] SubWorkflowStoreActor stopped; [2019-10-01 02:53:12,65] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2019-10-01 02:53:12,66] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2019-10-01 02:53:12,66] [info] KvWriteActor Shutting down: 0 queued messages to process; [2019-10-01 02:53:12,66] [info] JobStoreActor stopped; [2019-10-01 02:53:12,66] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2019-10-01 02:53:12,66] [info] CallCacheWriteActor stopped; [2019-10-01 02:53:12,66] [info] IoProxy stopped; [2019-10-01 02:53:12,66] [info] ServiceRegistryActor stopped; [2019-10-01 02:53:12,67] [info] DockerHashActor stopped; [2019-10-01 02:53:12,69] [info] Database closed; [2019-10-01 02:53:12,69] [info] Stream materializer shut down; [2019-10-01 02:53:12,69] [info] WDL HTTP import resolver closed; Workflow c55a06f3-abc1-4db1-8e0f-ea0303caab2c transitioned to state Failed; ```. Any help will be much appreciated. Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:9964,down,down,9964,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,12,['down'],['down']
Availability," 10:58:19.798 INFO VariantAnnotator - Inflater: IntelInflater; 10:58:19.798 INFO VariantAnnotator - GCS max retries/reopens: 20; 10:58:19.798 INFO VariantAnnotator - Requester pays: disabled; 10:58:19.798 INFO VariantAnnotator - Initializing engine; 10:58:19.942 INFO FeatureManager - Using codec VCFCodec to read file file:///run/media/riadh/One%20Touch/Reference_data_b38/gnomad.genomes.v3.1.2.sites.chr3.vcf.bgz; 10:58:19.971 INFO FeatureManager - Using codec VCFCodec to read file file:///run/media/riadh/My%20Book_From%20Eiklid/Analysis/gatk-4.2.4.1/ensembl-vep/PE69_chr3.vcf; 10:58:20.063 INFO VariantAnnotator - Done initializing engine; 10:58:20.091 WARN VariantAnnotatorEngine - The requested expression attribute ""gnomad.ALT"" is missing from the header in its resource file gnomad; 10:58:20.140 INFO ProgressMeter - Starting traversal; 10:58:20.140 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 10:58:42.160 INFO VariantAnnotator - Shutting down engine; [March 17, 2022 at 10:58:42 AM CET] org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator done. Elapsed time: 0.37 minutes.; Runtime.totalMemory()=17158897664; java.lang.IllegalStateException: Allele in genotype C not in the variant context [C*, CT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.base/java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.var",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053:3631,down,down,3631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053,1,['down'],['down']
Availability," 14:25:55.526 INFO Mutect2 - ------------------------------------------------------------; 14:25:55.526 INFO Mutect2 - HTSJDK Version: 2.23.0; 14:25:55.526 INFO Mutect2 - Picard Version: 2.22.8; 14:25:55.526 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:25:55.526 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:25:55.527 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:25:55.527 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:25:55.527 INFO Mutect2 - Deflater: IntelDeflater; 14:25:55.527 INFO Mutect2 - Inflater: IntelInflater; 14:25:55.527 INFO Mutect2 - GCS max retries/reopens: 20; 14:25:55.527 INFO Mutect2 - Requester pays: disabled; 14:25:55.527 INFO Mutect2 - Initializing engine; 14:25:55.994 INFO FeatureManager - Using codec BEDCodec to read file file:///test.bed; 14:25:56.086 INFO IntervalArgumentCollection - Processing 3896357 bp from intervals; 14:25:56.115 INFO Mutect2 - Shutting down engine; [October 7, 2021 2:25:56 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2102919168; **java.lang.NullPointerException**; at java.util.ComparableTimSort.countRunAndMakeAscending(ComparableTimSort.java:325); at java.util.ComparableTimSort.sort(ComparableTimSort.java:202); at java.util.Arrays.sort(Arrays.java:1312); at java.util.Arrays.sort(Arrays.java:1506); at java.util.ArrayList.sort(ArrayList.java:1462); at java.util.Collections.sort(Collections.java:143); at org.broadinstitute.hellbender.utils.IntervalUtils.sortAndMergeIntervals(IntervalUtils.java:467); at org.broadinstitute.hellbender.utils.IntervalUtils.getIntervalsWithFlanks(IntervalUtils.java:965); at org.broadinstitute.hellbender.utils.IntervalUtils.getIntervalsWithFlanks(IntervalUtils.java:980); at org.broadinstitute.hellbender.engine.MultiIntervalLocalReadShard.(MultiIntervalLocalReadShard.java:59); at org.broadinstitute.hellbender.engine.AssemblyReg",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7496:3046,down,down,3046,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7496,1,['down'],['down']
Availability," 15:10:05.038 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -440.458 +/- 167.216, SNR: 9.0, T: 1.81: 93%|#########2| 927/1000 [00:01<00:00, 428.25it/s]; 15:10:05.149 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -431.479 +/- 164.680, SNR: 8.6, T: 1.81: 97%|#########7| 970/1000 [00:01<00:00, 416.04it/s]; 15:10:05.229 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -426.199 +/- 162.710, SNR: 8.3, T: 1.80: 100%|##########| 1000/1000 [00:01<00:00, 521.12it/s]; 15:10:05.229 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1): 0%| | 0/100 [00:00<?, ?it/s]; 15:10:05.502 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 1.0000 +/- 0.0000: 1%|1 | 1/100 [00:00<00:26, 3.68it/s]; 15:10:05.772 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0046 +/- 0.0049: 2%|2 | 2/100 [00:00<00:26, 3.69it/s]; 15:10:06.039 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0023 +/- 0.0037: 3%|3 | 3/100 [00:00<00:26, 3.71it/s]; 15:10:06.307 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0016 +/- 0.0036: 4%|4 | 4/100 [00:01<00:25, 3.72it/s]; 15:10:06.575 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0018 +/- 0.0019: 5%|5 | 5/100 [00:01<00:25, 3.72it/s]; 15:10:06.844 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0013 +/- 0.0014: 6%|6 | 6/100 [00:01<00:25, 3.72it/s]; 15:10:07.113 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0014 +/- 0.0019: 7%|7 | 7/100 [00:01<00:24, 3.72it/s]; 15:10:07.381 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0011 +/- 0.0011: 8%|8 | 8/100 [00:02<00:24, 3.72it/s]; 15:10:07.649 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnv",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:11260,error,error,11260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['error'],['error']
Availability," 16:25:50 INFO DAGScheduler:54 - Job 4 failed: collect at FindBreakpointEvidenceSpark.java:963, took 30.909355 s; 2019-02-17 16:25:50 INFO AbstractConnector:318 - Stopped Spark@7433ca19{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-02-17 16:25:50 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-02-17 16:25:50 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-02-17 16:25:50 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Added taskresult_980 in memory on scc-q04.scc.bu.edu:41981 (size: 4.9 MB, free: 42.5 GB); 2019-02-17 16:25:50 ERROR TransportRequestHandler:210 - Error while invoking RpcHandler#receive() for one-way message.; org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.; at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160); at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:140); at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:655); at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:208); at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:113); at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:42920,ERROR,ERROR,42920,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability," 18:11:34 INFO util.log: Logging initialized @3816ms; 17/10/13 18:11:34 INFO server.Server: jetty-9.3.z-SNAPSHOT; 17/10/13 18:11:34 INFO server.Server: Started @3902ms; 17/10/13 18:11:34 INFO server.AbstractConnector: Started ServerConnector@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:34 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@710ae6a7{/jobs,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7b211077{/jobs/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62b0bf85{/jobs/job,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f07d414{/jobs/job/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40faff12{/stages,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@223967ea{/stages/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5d7f1e59{/stages/stage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68e47e7{/stages/stage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16ac4d3d{/stages/pool,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@719c1faf{/stages/pool/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f172892{/storage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@45f9d394{/storage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:6272,AVAIL,AVAILABLE,6272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability," 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:54:54.732 INFO HaplotypeCaller - Deflater: IntelDeflater; 09:54:54.732 INFO HaplotypeCaller - Inflater: IntelInflater; 09:54:54.732 INFO HaplotypeCaller - GCS max retries/reopens: 20; 09:54:54.732 INFO HaplotypeCaller - Requester pays: disabled; 09:54:54.732 INFO HaplotypeCaller - Initializing engine; 09:55:05.747 INFO HaplotypeCaller - Shutting down engine; [September 11, 2020 9:55:05 AM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=5152178176; ***********************************************************************. A USER ERROR has occurred: Fasta dict file file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.dict for reference file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.fa.gz does not exist.; Please see http://gatkforums.broadinstitute.org/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference for help creating it. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Command 'java -Xmx100G -jar /opt/gatk/gatk-package-4.1.7.0-local.jar HaplotypeCaller -R Triticum_aestivum_Claire_EIv1.1.fa.gz --sequence-dictionary Triticum_aestivum_Claire_EIv1.1.fa.gz.dict -I ClaireTest_MD.bam -O ClaireTest_MD_NoInter; vals_Output.vcf --stand-call-conf 10 --native-pair-hmm-threads 30' failed with 512. ```. I'm using the local gatk of version 4.1.7.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6808:2662,ERROR,ERROR,2662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808,1,['ERROR'],['ERROR']
Availability, 2022-08-16T00:09:07.2841948Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2856913Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2860245Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2861934Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3012792Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3151812Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3156616Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3263061Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3605617Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3694118Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3740413Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:2734,error,error,2734,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability," 2022-08-16T00:09:07.4039323Z location: class CountingReadFilter; 2022-08-16T00:09:07.4039849Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T00:09:07.4040311Z @VisibleForTesting; 2022-08-16T00:09:07.4040921Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4041294Z location: class CountingVariantFilter; 2022-08-16T00:09:07.4054361Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4060164Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T00:09:07.4060614Z @VisibleForTesting; 2022-08-16T00:09:07.4061233Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4061591Z location: class ReadFilter; 2022-08-16T00:09:07.4083439Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4092135Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4107682Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4116317Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4117746Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4124264Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T00:09:07.4124816Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-08-16T00:09:07.4125855Z symbol: class BiMap; 2022-08-1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:12236,error,error,12236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability, 2022-08-16T22:45:53.6638787Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6653787Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6657039Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6658760Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6739776Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6889124Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6895571Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6965286Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6965863Z * Returns the STR period at a given position.??; 2022-08-16T22:45:53.6972650Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6973221Z * Returns the STR period at a given position.??; 2022-08-16T22:45:53.6981573Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7254348Z src/main/java/org/broadinstitute/he,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:4387,error,error,4387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability," 2022-08-16T22:45:53.8024320Z location: class CountingReadFilter; 2022-08-16T22:45:53.8024635Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T22:45:53.8024772Z @VisibleForTesting; 2022-08-16T22:45:53.8025036Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8025212Z location: class CountingVariantFilter; 2022-08-16T22:45:53.8032154Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8035089Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T22:45:53.8035234Z @VisibleForTesting; 2022-08-16T22:45:53.8035505Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8035658Z location: class ReadFilter; 2022-08-16T22:45:53.8087327Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8103864Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8113680Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8117654Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8118430Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8124030Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T22:45:53.8124383Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-08-16T22:45:53.8124657Z symbol: class BiMap; 2022-08-1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:14274,error,error,14274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability, 2022-08-16T22:45:53.8269986Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8270563Z [0K; 2022-08-16T22:45:53.8270698Z [0K; 2022-08-16T22:45:53.8270832Z [0K; 2022-08-16T22:45:53.8272441Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 31s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/transformers/DRAGENMappingQualityReadTransformer.java:3: error: package com.google.common.annotations does not exist[0K; 2022-08-16T22:45:53.8283859Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8284709Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8288203Z src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8294852Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8295684Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8296401Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8377958Z src/main/java/org/broadinstitute/hellbender/utils/runtime/ProcessControllerBase.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8390248Z src/main/j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:18852,error,error,18852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability," 20:05:41.342 INFO GenomicsDBImport - Importing to array - /tmp/tmp.ceRdvv/GDB/genomicsdb\_array ; ; 20:05:41.342 INFO ProgressMeter - Starting traversal ; ; 20:05:41.342 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute ; ; 20:05:41.890 INFO GenomicsDBImport - Starting batch input file preload ; ; 20:05:42.320 INFO GenomicsDBImport - Finished batch preload ; ; 20:05:42.320 INFO GenomicsDBImport - Importing batch 1 with 100 samples ; ; 20:06:03.127 INFO ProgressMeter - chr1:5149001 0.4 1 2.8. .... 03:37:31.740 INFO GenomicsDBImport - Importing batch 1502 with 19 samples ; ; 03:37:35.318 INFO GenomicsDBImport - Done importing batch 1502/1502 ; ; 03:37:35.318 INFO ProgressMeter - chr1:5149001 451.9 1502 3.3 ; ; 03:37:35.318 INFO ProgressMeter - Traversal complete. Processed 1502 total batches in 451.9 minutes. ; ; 03:37:35.318 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed! ; ; 03:37:35.318 INFO GenomicsDBImport - Shutting down engine ; ; \[July 28, 2020 3:37:35 AM GMT\] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 451.99 minutes. ; ; Runtime.totalMemory()=1351453507584. Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz ; ; 03:37:53.320 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6742:6618,down,down,6618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742,1,['down'],['down']
Availability, 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:4542,reliab,reliable,4542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability," 25, referenceIndex:37. Run the command as follows: ; ```; ./gatk HaplotypeCallerSpark --native-pair-hmm-threads 40 -ERC GVCF -R hg38/fa/GRCh38.fna -I NA12878.sort.dup.BQSR.bam -L random.bed -O NA12878.g.vcf.gz ; ```; The contents of random.bed:; ```; chr1_KI270706v1_random 45744 46286; chr1_KI270706v1_random 69250 69770; chr4_GL000008v2_random 7167 7691; chr4_GL000008v2_random 131611 132154; chr4_GL000008v2_random 155105 155625; chr4_GL000008v2_random 177247 177767; chr4_GL000008v2_random 191280 191800; ```; And the weird thing is that when I removed one of these chromosomes chr1_KI270706v1_random, it works. . ----. ## Bug Report; The following errors were found while running the HaplotypeCallerSpark on WES data; ```; 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 INFO NewHadoopRDD: Input split: file:/data/phoenix-output/LUSH_WES/sz01-huyue-LUSH_WES-2021041210463878ad3/NA12878/LUSH_BQSR/NA12878.sort.dup.BQSR.bam:67108864+29181309; 21/04/13 07:32:24 INFO FileOutputCommitter: Saved output of task 'attempt_20210413073224_0026_r_000001_0' to file:/dev/shm/chr4_GL000008v2_random.g.vcf.gz.parts; 21/04/13 07:32:24 INFO SparkHadoopMapRedUtil: attempt_20210413073224_0026_r_000001_0: Committed; 21/04/13 07:32:24 INFO Executor: Finished task 1.0 in stage 5.0 (TID 106). 762 bytes result sent to driver; 21/04/13 07:32:24 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 106) in 136 ms on localhost (executor driver) (1/3); 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:989,error,errors,989,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,3,"['error', 'failure']","['errors', 'failures']"
Availability," 26.0 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:44818 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:44818 (size: 2.1 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/13 18:11:44 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/13 18:11:44 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/13 18:11:44 INFO spark.SparkContext: Starting job: runJob at SparkHadoopMapReduceWriter.scala:88; 17/10/13 18:11:44 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Got job 0 (runJob at SparkHadoopMapReduceWriter.scala:88) with 1 output partitions; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:16210,failure,failures,16210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['failure'],['failures']
Availability," 26|2, 2], DP=94, ECNT=1, GERMQ=93, MBQ=[31, 20], MFRL=[288, 110], MMQ=[60, 60], MPOS=56, NALOD=1.37, NLOD=6.17, POPAF=4.6, ROQ=93, TLOD=10.97} GT=GT:AD:AF:DP:F1R2:F2R1:SB 0/1:46,4:0.07:50:14,3:10,0:28,18,2,2 0/0:23,0:0.041:23:8,0:5,0:15,8,0,0 filters=; 11:43:25.661 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000441716.2 for problem variant: chr6:167976552-167976594(ACAGTGGGGGTCATTCCCCCTGCAGTGTGTTGGGAGGAGGAGG* -> A); 11:44:04.904 INFO ProgressMeter - chr8:677091 4.5 3000 666.0; 11:45:35.226 INFO ProgressMeter - chr11:62279639 6.0 4000 665.6; 11:46:54.284 INFO ProgressMeter - chr15:19905537 7.3 5000 682.4; 11:48:12.767 WARN FuncotatorUtils - createAminoAcidSequence given a coding sequence of length not divisible by 3. Dropping bases from the end: 2 (size=293, ref allele: G); 11:48:16.949 ERROR GencodeFuncotationFactory - Problem creating a GencodeFuncotation on transcript ENST00000379751.5 for variant: chr20:3786474-3786537(TGGGGCCCATCCCGGCGCGCCCCCCGCCCCGGGGCCCGGCGCCGCCGCCGCCGCCCCGGGGCGG* -> T): Cannot yet handle indels starting outside an exon and ending within an exon.; 11:48:16.949 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000379751.5 for problem variant: chr20:3786474-3786537(TGGGGCCCATCCCGGCGCGCCCCCCGCCCCGGGGCCCGGCGCCGCCGCCGCCGCCCCGGGGCGG* -> T); 11:48:31.506 INFO ProgressMeter - chr21:18282114 8.9 6000 670.6; 11:49:08.210 INFO ProgressMeter - chr21:18282114 9.6 6888 720.6; 11:49:08.210 INFO ProgressMeter - Traversal complete. Processed 6888 total variants in 9.6 minutes.; 11:49:08.210 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/2; 11:49:08.211 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/4781; 11:49:08.230 INFO Funcotator - Shutting down engine; [July 7, 2021 11:49:08 AM GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 9.72 minutes.; Runtime.totalMemory()=4879548416; Tool returned:; true",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-887961422:2453,down,down,2453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-887961422,1,['down'],['down']
Availability," 3.4 5175000 1536641.9; 21:15:40.046 INFO SplitNCigarReads - Finished first pass through the reads; 21:15:40.613 INFO OverhangFixingManager - Overhang Fixing Manager saved 434 reads in the first pass; WARNING: BAM index file /gatk/my_data/subset_TINY_rehead.bam.bai is older than BAM /gatk/my_data/subset_TINY_rehead.bam; 21:15:40.627 INFO SplitNCigarReads - Starting second pass through the reads; 21:15:49.553 INFO ProgressMeter - 1:52446384 3.5 5365000 1514089.6; 21:16:00.221 INFO ProgressMeter - 1:151676272 3.7 5420000 1456525.9; 21:16:10.407 INFO ProgressMeter - 1:210675831 3.9 5438000 1397596.1; 21:16:20.508 INFO ProgressMeter - 10:126252122 4.1 5482000 1350473.6; 21:16:30.624 INFO ProgressMeter - 12:763575 4.2 5535000 1309155.4; 21:16:40.899 INFO ProgressMeter - 12:98644570 4.4 5601000 1273195.7; 21:16:50.938 INFO ProgressMeter - 14:70584526 4.6 5656000 1238589.9; 21:17:01.113 INFO ProgressMeter - 16:51645883 4.7 5764000 1217043.7; 21:17:05.994 INFO SplitNCigarReads - Shutting down engine; [March 2, 2023 9:17:05 PM UTC] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 4.86 minutes.; Runtime.totalMemory()=3214934016; htsjdk.samtools.util.RuntimeIOException: Attempt to add record to closed writer.; 	at htsjdk.samtools.util.AbstractAsyncWriter.write(AbstractAsyncWriter.java:57); 	at htsjdk.samtools.AsyncSAMFileWriter.addAlignment(AsyncSAMFileWriter.java:53); 	at org.broadinstitute.hellbender.utils.read.SAMFileGATKReadWriter.addRead(SAMFileGATKReadWriter.java:21); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.writeReads(OverhangFixingManager.java:358); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.flush(OverhangFixingManager.java:338); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.closeTool(SplitNCigarReads.java:196); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1052); 	at org.broadinstitute.hellbender.cmdline.Command",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452564826:5636,down,down,5636,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452564826,1,['down'],['down']
Availability," 4:61122642 10.0 19223000 1919197.3; 01:10:04.009 INFO ProgressMeter - 4:77404115 10.2 19546000 1919442.2; 01:10:14.027 INFO ProgressMeter - 4:90982301 10.4 19859000 1918719.2; 01:10:24.037 INFO ProgressMeter - 5:5319910 10.5 20215000 1922132.2; 01:10:34.043 INFO ProgressMeter - 5:13428416 10.7 20557000 1924140.1; 01:10:44.052 INFO ProgressMeter - 5:18554429 10.9 20887000 1924971.5; 01:10:54.053 INFO ProgressMeter - 5:23247594 11.0 21241000 1927979.5; 01:11:04.057 INFO ProgressMeter - 5:25901452 11.2 21588000 1930263.3; 01:11:14.089 INFO ProgressMeter - 5:32482380 11.4 21916000 1930729.5; 01:11:24.106 INFO ProgressMeter - 5:38674297 11.5 22249000 1931652.6; 01:11:34.133 INFO ProgressMeter - 5:49679881 11.7 22573000 1931754.3; 01:11:44.145 INFO ProgressMeter - 5:53234595 11.9 22925000 1934259.1; 04:10:15.659 INFO ProgressMeter - 6:1726401 190.4 23183000 121774.0; 04:10:25.671 INFO ProgressMeter - 6:10206926 190.5 23517000 123420.2; 04:10:31.341 INFO BaseRecalibrator - Shutting down engine; [February 22, 2021 at 4:10:31 AM PST] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 190.65 minutes.; Runtime.totalMemory()=1268776960; java.lang.IllegalStateException: cigar is completely soft-clipped; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:129); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:143); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.consolidateCigar(BaseRecalibrationEngine.java:293); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transfo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7092:8487,down,down,8487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7092,1,['down'],['down']
Availability," 5740000 672351.6; 13:53:40.253 INFO ProgressMeter - chr19:40111935 8.7 5871000 674471.0; 13:53:50.326 INFO ProgressMeter - chr20:33030731 8.9 5993000 675459.1; 13:54:00.362 INFO ProgressMeter - chr21:27087627 9.0 6111000 676013.0; 13:54:10.423 INFO ProgressMeter - chr22:41712333 9.2 6226000 676191.6; 13:54:20.447 INFO ProgressMeter - chrX:39799780 9.4 6342000 676514.9; 13:54:30.520 INFO ProgressMeter - chrX:91818371 9.5 6453000 676246.2; 13:54:40.591 INFO ProgressMeter - chrX:143619069 9.7 6568000 676399.8; 13:54:50.640 INFO ProgressMeter - chrUn_KI270743v1:125398 9.9 6674000 675662.2; 13:55:00.673 INFO ProgressMeter - chr20_KI270869v1_alt:62679 10.0 6792000 676161.8; 13:55:10.679 INFO ProgressMeter - chr19_GL949752v1_alt:485077 10.2 6910000 676673.7; 13:55:26.149 INFO ProgressMeter - HLA-DRB1*11:01:02:3272 10.5 6938356 662718.7; 13:55:26.149 INFO ProgressMeter - Traversal complete. Processed 6938356 total records in 10.5 minutes.; 13:55:26.149 INFO ComposeSTRTableFile - Shutting down engine; [April 4, 2021 1:55:26 PM EDT] org.broadinstitute.hellbender.tools.dragstr.ComposeSTRTableFile done. Elapsed time: 10.52 minutes.; Runtime.totalMemory()=1128792064; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar CalibrateDragstrModel -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --str-table-path gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.STR.table -O gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.Dragstr.model -I /restricted/projectnb/casa/wgs.hg38/adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; 13:55:30.890 INFO NativeLibraryLoader - Loading libgkl_c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:10993,down,down,10993,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['down'],['down']
Availability," 7, 2017 12:48:13 AM UTC] Executing as tianj@ip-xxx-xx-xx-xxx on Linux 4.4.41-36.55.amzn1.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.alpha.2-1100-g04dbeb2-SNAPSHOT; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 00:48:13.680 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:48:13.680 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 00:48:13.680 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 00:48:13.680 INFO MarkDuplicatesSpark - Initializing engine; 00:48:13.680 INFO MarkDuplicatesSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4aa298b7] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@37574691].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 00:48:19.247 INFO MarkDuplicatesSpark - Shutting down engine; [June 7, 2017 12:48:19 AM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=1029701632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 0.0 failed 4 times, most recent failure: Lost task 15.3 in stage 0.0 (TID 59, 172.31.77.139, ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:3920,ERROR,ERROR,3920,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['ERROR'],['ERROR']
Availability," : 8 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 271413 (TileDB column 271412) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 275583 (TileDB column 275582) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 275664 (TileDB column 275663) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 285109 (TileDB column 285108) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. 20:40:00.698 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.6447453060000009,Cpu time(s),0.6353685659999999; [January 14, 2022 8:40:00 PM MST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.40 minutes.; Runtime.totalMemory()=2523922432; java.lang.IllegalStateException: Genotype [1057-01 CTT*/* GQ 99 DP 67 AD 34,21,3,6,1,0,2,0 {SB=7,27,15,18}] does not contain likelihoods necessary to calculate posteriors.; ```. So in my case, it is also failing after a site where number of alt alleles (7) is exactly 1 more than --max-alternate-alleles (6), but not always on the first such variant with 7 alt alleles, depending on other command line options. If I revert GenotypeGVCFs to previous versions from 4.1.9.0 to 4.2.4.0 they all work (using the same GVCF database from GenomicsDBImport 4.2.4.1), so this apparent bug is new in GenotypeGVCFs 4.2.4.1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1015835315:4023,down,down,4023,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1015835315,1,['down'],['down']
Availability," : false; 16:46:49.700 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:46:49.700 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:46:49.700 INFO Mutect2 - Deflater: IntelDeflater; 16:46:49.700 INFO Mutect2 - Inflater: IntelInflater; 16:46:49.700 INFO Mutect2 - GCS max retries/reopens: 20; 16:46:49.700 INFO Mutect2 - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 16:46:49.700 INFO Mutect2 - Initializing engine; 16:46:49.995 INFO FeatureManager - Using codec VCFCodec to read file file:///home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz; 16:46:50.064 INFO Mutect2 - Shutting down engine; [November 6, 2019 4:46:50 PM CST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2394947584; org.broadinstitute.hellbender.exceptions.GATKException: Error initializing feature reader for path /home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:357); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:308); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:255); 	at org.broadinstitute.hellbender.engine.FeatureManager.addToFeatureSources(FeatureManager.java:202); 	at org.broadinstitute.hellbender.engine.FeatureManager.initializeFeatureSources(FeatureManager.java:182); 	at org.broadinstitute.hellbender.engine.FeatureManager.<init>(FeatureManager.java:153); 	at org.broadinstitute.hellbender.engine.GATKTool.initializeFeatures(GATKTool.java:415); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:636); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:160); 	at org.broadinstitute.hellbender.cmdline.Comm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6248:3073,Error,Error,3073,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6248,1,['Error'],['Error']
Availability, :arrow_down: |; | [...copynumber/utils/segmentation/KernelSegmenter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL3NlZ21lbnRhdGlvbi9LZXJuZWxTZWdtZW50ZXIuamF2YQ==) | `95.671% <> (-2.164%)` | `45 <0> (-3)` | |; | [...s/copynumber/models/AlleleFractionLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvbkxpa2VsaWhvb2RzLmphdmE=) | `97.826% <> ()` | `11 <0> ()` | :arrow_down: |; | [...ools/copynumber/models/AlleleFractionModeller.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvbk1vZGVsbGVyLmphdmE=) | `88.406% <> (-5.797%)` | `14 <0> (-4)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | ... and [1353 more](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5732#issuecomment-470293496:3800,down,downsampling,3800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5732#issuecomment-470293496,1,['down'],['downsampling']
Availability," ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 6.0 in stage 0.0 (TID 6), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 36.0 in stage 0.0 (TID 36), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 28.0 in stage 0.0 (TID 28), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 7.0 in stage 0.0 (TID 7), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 29.0 in stage 0.0 (TID 29), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 8.0 in stage 0.0 (TID 8), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Stage 0 was cancelled** ; **20/03/05 09:28:58 INFO DAGScheduler: ShuffleMapStage 0 (mapToPair at PSFilter.java:125) failed in 63.548 s due to Job aborted due to stage failure: Task 34 in stage 0.0 failed 1 times, most recent failure: Lost task 34.0 in stage 0.0 (TID 34, localhost, executor driver): com.esotericsoftware.kryo.KryoException: Buffer underflow.** ; **at com.esotericsoftware.kryo.io.Input.require(Input.java:199)** ; **at com.esotericsoftware.kryo.io.Input.readLong(Input.java:686)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet.<init>(LongHopscotchSet.java:83)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:527)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:519)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:712)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet.<init>(LargeLongHopscotchSet.java:55)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet$Serializer.read(LargeLongHopscotchSet.java:172)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:38092,failure,failure,38092,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['failure'],['failure']
Availability," = main_function(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 45, in main_function; from theano import config; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/__init__.py"", line 110, in <module>; from theano.compile import (; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/__init__.py"", line 12, in <module>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42. collect2: error: ld returned 1 exit status. ```. Then I have installed theano with python 3.6.6 which is compiled with gcc 5.4.0, and it was giving me no errors. ```sh. $ theano-nose . ----------------------------------------------------------------------; Ran 0 tests in 0.012s. OK; ```. The Theano toolchain issue might be caused by theano not being actively developed anymore. Probably they never tested it with newer toolchains.; See this message that is also on the T",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:2942,error,error,2942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['error'],['error']
Availability, > 894 expanding to 1790; > 21:14:17.874 DEBUG MathUtils$Log10Cache - cache miss 1791 > 1790 expanding to 3582; > 21:14:17.894 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:1->2; > 21:14:17.930 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:1->2; > 21:14:17.937 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:1->2; > 21:14:18.507 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:3->4; > 21:14:18.510 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:2->3; > 21:27:38.720 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:2->3; > 21:28:26.332 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:2->3; > 21:30:24.296 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:4->5; > 21:30:24.299 DEBUG GenotypeLikelihoodCalculators - Expanding capacity ploidy:2->2 allele:3->4; > . Here's standard error:. > WARNING: No valid combination operation found for INFO field DS - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field DS - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; > WARNING: No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4161:7136,error,error,7136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161,1,['error'],['error']
Availability," > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.config",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:2389,ERROR,ERROR,2389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability, ? 19589 ; ==========================================; Files ? 1973 ; Lines ? 147147 ; Branches ? 16215 ; ==========================================; Hits ? 64898 ; Misses ? 77129 ; Partials ? 5120; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5787?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...utils/activityprofile/ActivityProfileUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9hY3Rpdml0eXByb2ZpbGUvQWN0aXZpdHlQcm9maWxlVW5pdFRlc3QuamF2YQ==) | `0.442% <0%> ()` | `1 <0> (?)` | |; | [...ils/optimization/PersistenceOptimizerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplclVuaXRUZXN0LmphdmE=) | `2% <0%> ()` | `1 <0> (?)` | |; | [...utils/downsampling/DownsamplingMethodUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRG93bnNhbXBsaW5nTWV0aG9kVW5pdFRlc3QuamF2YQ==) | `3.448% <0%> ()` | `1 <0> (?)` | |; | [...yper/StandardCallerArgumentCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvblVuaXRUZXN0LmphdmE=) | `4.098% <0%> ()` | `2 <0> (?)` | |; | [...lbender/utils/mcmc/ParameterizedStateUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlcml6ZWRTdGF0ZVVuaXRUZXN0LmphdmE=) | `14.286% <0%> ()` | `2 <0> (?)` | |; | [...itute/hellbender/engine/ProgressMeterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750:1423,down,downsampling,1423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750,3,"['Down', 'down']","['DownsamplingMethodUnitTest', 'downsampling']"
Availability," @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in https://github.com/samtools/htsjdk/pull/759. I can expand this to all INFO field annotations. ---. @ldgauthier commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265221057). Expanding to all INFO annotations would be wonderful, but that can be a separate issue. ---. @ronlevine commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265223581). That's not the only one, @magicDGS requested validating the `AF` values (which can be a separate issue). . ---. @vdauwera commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265226356). I think this one requires some additional discussion, so let's hold off for now -- it's not essential for 3.7 and we can't wait any longer to release. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-287824654). @ldgauthier Would it be ok to kick this down the road to whenever ValidateVariants gets ported to GATK4?. ---. @ldgauthier commented on [Tue Mar 21 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-288223822). Yeah, this isn't critical for any production pipelines - pass that buck. On Mar 20, 2017 12:56 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> Would it be ok to kick this; > down the road to whenever ValidateVariants gets ported to GATK4?; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-287824654>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdLPwS6I5nu9TQiw4BFqRojmTiL0aks5rnq_OgaJpZM4FaLwX>; > .; >",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:7806,down,down,7806,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,2,['down'],['down']
Availability," Affected tool(s) or class(es); - Tool/class name(s), special parameters: GenomicsDBImport. ### Affected version(s); - Version: gatk4-4.4.0.0-0. ### Description ; Hello,. I have been having an issue come up when utilizing `GenomicsDBImport`. This issue has happened when using a range of samples and shard counts (8 - 1000 samples, shard count of up to 2000). My current example is an attempt to joint call 1000 samples together. I will submit the jobs and 1-2 of the shards (of the ~100 concurrently running) will throw a `malloc(): unaligned tcache chunk detected`. When I resubmit that shard, it will usually rerun without a problem. Or if I kill all jobs and resubmit, a different shard will throw the malloc error. . I have run approximately 20 tests and I seem to get this failure 2/3 times. However, it only arises on the initial submission and not when additional jobs are submitted as previous shards complete. Please note that the 1000 samples have successfully been imported into the GenomicsDB but this error seems to persist somewhat randomly across multiple machines. . Thank you for your assistance! . #### Steps to reproduce. - Command used (omitting paths to 1000 samples for brevity) for one of the failed shards. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8g -jar /gpfs/gpfs_de6000/home/dalegre/miniconda3/envs/GOASTv4.0/share/gatk4-4.4.0.0-0/gatk-package-4.4.0.0-local.jar GenomicsDBImport -V [samples 1-1002] --genomicsdb-workspace-path results/jointcalling/genomicsDB/temp_0882_of_2000_DB --merge-input-intervals false --bypass-feature-reader --tmp-dir temp --max-num-intervals-to-import-in-parallel 10 --batch-size 50 --intervals results/germline/interval/temp_0882_of_2000/scattered.interval_list --genomicsdb-shared-posixfs-optimizations true; ```. #### Expected behavior; All shards are imported into the GenomicsDB successfully. . #### Actual beha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8683:1039,error,error,1039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8683,1,['error'],['error']
Availability," CQ tag; ERROR: Record 26312, Read name UMI-CCT-TTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 70755, Read name UMI-CAG-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 145082, Read name UMI-AAC-ATG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 181500, Read name UMI-ACT-CTT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186837, Read name UMI-CAA-CTC-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186862, Read name UMI-CGC-GCC-0, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186904, Read name UMI-AGG-GTC-0, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186919, Read name UMI-CGC-TGC-0, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186947, Read name UMI-TAA-TAG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186970, Read name UMI-GAG-GCC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186972, Read name UMI-TAT-TTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186985, Read name UMI-ACG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186995, Read name UMI-CTT-GCA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187006, Read name UMI-CTA-GGG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187037, Read name UMI-AGT-CTG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187061, Read name UMI-CAT-GGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187074, Read name UMI-AAA-CGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187110, Read name UMI-ACG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187121, Read name UMI-CCG-GCC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187154, Read name UMI-CAA-CTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187181, Read name UMI-CGG-GAG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187209, Read name UMI-CAA-GTT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:3046,ERROR,ERROR,3046,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," Caller (when run through the Unified Genotyper the down-sampling works just fine).; I see in SAMDataSource line 668 that assumeDownstreamLIBSDownsampling is being set to true. But then it doesn't look like LIBS is actually down-sampling. Don't have time to debug more so passing on to David. ---. @droazen said (over multiple comments):. I am looking into this. LIBS is actually calling into the downsamplers correctly in the test case that Eric provided. You can see this by examining readStates.size() for each locus -- it never exceeds the -dcov target of 200. The problem must lie elsewhere -- I'll continue to step through this in the debugger. [...]. After some more debugging and consultation with Ryan, I've found that DP values exceeding dcov are to be expected given the way the ActiveRegion traversal currently works. Here's a summary of what's going on:. -dcov 200 does cause LIBS to cap the depth at each locus to 200, but due to code Mark added a while back LIBS will save all of the undownsampled reads in memory during active region traversals (which kind of defeats the purpose of downsampling in the first place!). -TraverseActiveRegions gets the undownsampled reads from LIBS, and adds them to the active regions that get passed to the walker. -The HaplotypeCaller does a post-hoc downsampling pass on the reads in the active region in finalizeActiveRegion() to a hardcoded (!!!) and completely arbitrary depth of 1000, ignoring dcov. -The HaplotypeCaller does realignment of reads to the haplotypes, potentially causes the depth of coverage to vary at the locus in question. -The GenotypingEngine then computes DP based on the reads that still overlap the locus post-realignment. The end result is that DP for the HaplotypeCaller represents the undownsampled depth of coverage at the locus in question, subject to the hardcoded cap of 1000 and realignment to the haplotypes. In this particular case, the actual depth at locus 1:14464 is 561 (with no downsampling), and the DP val",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:2796,down,downsampling,2796,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['down'],['downsampling']
Availability," ContextHandler - Stopped o.s.j.s.ServletContextHandler@7074da1d{/,null,STOPPED,@Spark}; 10:33:07.347 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45717,AVAIL,AVAILABLE,45717,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability, DEBUG Mutect2 - Processing assembly region at chrM:13321-13620 isActive: false numReads: 55070; 12:09:01.757 DEBUG Mutect2 - Processing assembly region at chrM:13621-13636 isActive: false numReads: 55240; 12:09:02.341 DEBUG Mutect2 - Processing assembly region at chrM:13637-13936 isActive: true numReads: 110273; 12:09:09.957 DEBUG ReadThreadingGraph - Recovered 24 of 26 dangling tails; 12:09:10.041 DEBUG ReadThreadingGraph - Recovered 6 of 14 dangling heads; 12:09:10.602 DEBUG Mutect2Engine - Active Region chrM:13637-13936; 12:09:10.608 DEBUG Mutect2Engine - Extended Act Region chrM:13537-14036; 12:09:10.613 DEBUG Mutect2Engine - Ref haplotype coords chrM:13537-14036; 12:09:10.617 DEBUG Mutect2Engine - Haplotype count 128; 12:09:10.621 DEBUG Mutect2Engine - Kmer sizes count 0; 12:09:10.625 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:51.290 DEBUG Mutect2 - Processing assembly region at chrM:13937-13944 isActive: true numReads: 54773; 12:13:53.989 DEBUG ReadThreadingGraph - Recovered 29 of 59 dangling tails; 12:13:54.004 DEBUG ReadThreadingGraph - Recovered 0 of 35 dangling heads; 12:13:54.432 DEBUG Mutect2Engine - Active Region chrM:13937-13944; 12:13:54.440 DEBUG Mutect2Engine - Extended Act Region chrM:13837-14044; 12:13:54.447 DEBUG Mutect2Engine - Ref haplotype coords chrM:13837-14044; 12:13:54.452 DEBUG Mutect2Engine - Haplotype count 128; 12:13:54.456 DEBUG Mutect2Engine - Kmer sizes count 0; 12:13:54.462 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:55.715 DEBUG Mutect2 - Processing assembly region at chrM:13945-14244 isActive: false numReads: 54745; 12:13:56.962 DEBUG Mutect2 - Processing assembly region at chrM:14245-14544 isActive: false numReads: 0; 12:13:56.973 DEBUG Mutect2 - Processing assembly region at chrM:14545-14844 isActive: false numReads: 0; 12:13:56.984 DEBUG Mutect2 - Processing assembly region at chrM:14845-15144 isActive: false numReads: 0; 12:13:56.995 DEBUG Mutect2 - Processing assembly region at chrM:15145-15444 isActive: false ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:20767,Recover,Recovered,20767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability, DEBUG ReadThreadingGraph - Recovered 2 of 24 dangling heads; 11:41:57.286 DEBUG IntToDoubleFunctionCache - cache miss 136737 > 53234 expanding to 136747; 11:41:57.301 DEBUG IntToDoubleFunctionCache - cache miss 136976 > 136747 expanding to 273496; 11:41:57.935 DEBUG Mutect2Engine - Active Region chrM:8830-9129; 11:41:57.937 DEBUG Mutect2Engine - Extended Act Region chrM:8730-9229; 11:41:57.939 DEBUG Mutect2Engine - Ref haplotype coords chrM:8730-9229; 11:41:57.940 DEBUG Mutect2Engine - Haplotype count 128; 11:41:57.941 DEBUG Mutect2Engine - Kmer sizes count 0; 11:41:57.942 DEBUG Mutect2Engine - Kmer sizes values []; 11:53:42.116 DEBUG Mutect2 - Processing assembly region at chrM:9130-9143 isActive: true numReads: 148251; 11:53:58.336 DEBUG ReadThreadingGraph - Recovered 4 of 9 dangling tails; 11:53:58.398 DEBUG ReadThreadingGraph - Recovered 0 of 20 dangling heads; 11:54:11.645 DEBUG ReadThreadingGraph - Recovered 20 of 23 dangling tails; 11:54:11.670 DEBUG ReadThreadingGraph - Recovered 0 of 60 dangling heads; 11:54:11.843 DEBUG Mutect2Engine - Active Region chrM:9130-9143; 11:54:11.852 DEBUG Mutect2Engine - Extended Act Region chrM:9030-9243; 11:54:11.861 DEBUG Mutect2Engine - Ref haplotype coords chrM:9030-9243; 11:54:11.870 DEBUG Mutect2Engine - Haplotype count 232; 11:54:11.879 DEBUG Mutect2Engine - Kmer sizes count 0; 11:54:11.889 DEBUG Mutect2Engine - Kmer sizes values []; 11:54:21.878 DEBUG IntToDoubleFunctionCache - cache miss 96632 > 95278 expanding to 190558; 11:54:22.252 DEBUG Mutect2 - Processing assembly region at chrM:9144-9301 isActive: false numReads: 273760; 11:54:28.421 DEBUG Mutect2 - Processing assembly region at chrM:9302-9584 isActive: true numReads: 250870; 11:55:47.246 DEBUG ReadThreadingGraph - Recovered 13 of 14 dangling tails; 11:55:47.346 DEBUG ReadThreadingGraph - Recovered 6 of 47 dangling heads; 11:55:47.787 DEBUG Mutect2Engine - Active Region chrM:9302-9584; 11:55:47.792 DEBUG Mutect2Engine - Extended Act Region chrM:9202-9684; 11:5,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:16494,Recover,Recovered,16494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability," Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 05:06:55.412 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:06:55.412 INFO SelectVariants - Deflater: IntelDeflater; 05:06:55.412 INFO SelectVariants - Inflater: IntelInflater; 05:06:55.412 INFO SelectVariants - GCS max retries/reopens: 20; 05:06:55.412 INFO SelectVariants - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:06:55.412 INFO SelectVariants - Initializing engine; 05:06:55.796 INFO FeatureManager - Using codec VCFCodec to read file file:///disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gz; 05:06:55.962 INFO SelectVariants - Done initializing engine; 05:06:56.099 INFO ProgressMeter - Starting traversal; 05:06:56.099 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 06:39:06.894 INFO SelectVariants - Shutting down engine; [November 6, 2019 6:39:06 AM EST] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 92.20 minutes.; Runtime.totalMemory()=29215424512; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; at java.util.Arrays.copyOf(Arrays.java:3181); at java.util.ArrayList.grow(ArrayList.java:265); at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:239); at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:231); at java.util.ArrayList.add(ArrayList.java:462); at htsjdk.variant.variantcontext.GenotypeLikelihoods.calculatePLIndexToAlleleIndices(GenotypeLikelihoods.java:392); at htsjdk.variant.variantcontext.GenotypeLikelihoods.calculatePLIndexToAlleleIndices(GenotypeLikelihoods.java:394); at htsjdk.variant.variantcontext.GenotypeLikelihoods.calculatePLIndexToAlleleIndices(GenotypeLikelihoods.java:394); at htsjdk.variant.variantcontext.GenotypeLikelihoods.calculatePLIndexToAlleleIndices(GenotypeLikelihoods.java:394); at ht",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6254:3562,down,down,3562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6254,1,['down'],['down']
Availability," ERROR: Record 966509, Read name UMI-AGT-GGT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966514, Read name UMI-ATC-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966699, Read name UMI-CCG-TGA-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966722, Read name UMI-AGG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966742, Read name UMI-CCG-TCA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966752, Read name UMI-GAA-GAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966784, Read name UMI-CCT-TAT-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966875, Read name UMI-AGG-GGG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966887, Read name UMI-AGG-CCG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966916, Read name UMI-GCT-TCG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966939, Read name UMI-CAA-TGT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Reco",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:9539,ERROR,ERROR,9539,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," ERROR: Record 966514, Read name UMI-ATC-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966699, Read name UMI-CCG-TGA-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966722, Read name UMI-AGG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966742, Read name UMI-CCG-TCA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966752, Read name UMI-GAA-GAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966784, Read name UMI-CCT-TAT-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966875, Read name UMI-AGG-GGG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966887, Read name UMI-AGG-CCG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966916, Read name UMI-GCT-TCG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966939, Read name UMI-CAA-TGT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966989, Read name UMI-GAA-TCA-7, Zero-length read without FZ, CS or CQ tag; ERROR: Reco",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:9629,ERROR,ERROR,9629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966699, Read name UMI-CCG-TGA-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966722, Read name UMI-AGG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966742, Read name UMI-CCG-TCA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966752, Read name UMI-GAA-GAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966784, Read name UMI-CCT-TAT-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966875, Read name UMI-AGG-GGG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966887, Read name UMI-AGG-CCG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966916, Read name UMI-GCT-TCG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966939, Read name UMI-CAA-TGT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966989, Read name UMI-GAA-TCA-7, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966991, Read name UMI-TAG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Reco",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:9719,ERROR,ERROR,9719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966699, Read name UMI-CCG-TGA-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966722, Read name UMI-AGG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966742, Read name UMI-CCG-TCA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966752, Read name UMI-GAA-GAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966784, Read name UMI-CCT-TAT-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966875, Read name UMI-AGG-GGG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966887, Read name UMI-AGG-CCG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966916, Read name UMI-GCT-TCG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966939, Read name UMI-CAA-TGT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966989, Read name UMI-GAA-TCA-7, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966991, Read name UMI-TAG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 967245, Read name UMI-AAG-ATT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Reco",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:9809,ERROR,ERROR,9809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability, FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:09:03.377 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:09:03.377 INFO FilterMutectCalls - Deflater: IntelDeflater; 22:09:03.377 INFO FilterMutectCalls - Inflater: IntelInflater; 22:09:03.377 INFO FilterMutectCalls - GCS max retries/reopens: 20; 22:09:03.377 INFO FilterMutectCalls - Requester pays: disabled; 22:09:03.378 INFO FilterMutectCalls - Initializing engine; 22:09:04.031 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/GenomicsDBImport/200924_A00679_0401_AHKGKKDSXY/Set13-3_L3_379X79.somatic.vcf.gz; 22:09:04.071 INFO FilterMutectCalls - Shutting down engine; [2021228 100904] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.52 minutes.; Runtime.totalMemory()=1552416768; org.broadinstitute.hellbender.exceptions.GATKException: Error initializing feature reader for path /data/nws/WES/GenomicsDBImport/200924_A00679_0401_AHKGKKDSXY/Set13-3_L3_379X79.somatic.vcf.gz; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:375); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:327); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:277); 	at org.broadinstitute.hellbender.engine.VariantWalker.initializeDrivingVariants(VariantWalker.java:58); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:706); 	at org.broadinstitute.hellbender.engine.VariantWalker.onStartup(VariantWalker.java:45); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7114:2963,Error,Error,2963,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7114,1,['Error'],['Error']
Availability," GATK 4.2.2.0. I have tried running GGVCFs with 500gb memory, 600gb memory, and 1.6tb memory. In each case the run stops without issuing a warning or exception at exactly the same spot. I can't run a stack trace as the java process terminates. My exact command is ; ; gatk --java-options ""-Xmx1600g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R /home/dan_vanderpool/Wolf_raw_reads/Wolf_genome/GCA_905319855.2_mCanLor1.2_genomic.fa \; -V gendb://Wolf_Genome_Variantsdb \; -O All_Wolf_Samples_Joint_Genotypes_Raw.vcf.gz \; -L /scratch/dan/Wolf_reads_raw/Wolf_GenCov300_Q20_Merged.interval_list \; -imr ALL \; --genomicsdb-max-alternate-alleles 10 \; --max-alternate-alleles 6 . This runs perfectly until it reaches the 2 millionth variant mark whereupon everything stops, and all processes are terminated. You will notice this isn't occurring at chr1= ~200k (as in previous reports), but instead on the variants processed = ~2million. It seems odd that previous posts had a similar error (reported alternately as chr position ~200k or 2m). ; ; If I try running ""SelectVariants"" on any interval in the database ; ; gatk SelectVariants \; -R /home/dan_vanderpool/Wolf_raw_reads/Wolf_genome/GCA_905319855.2_mCanLor1.2_genomic.fa \; -V gendb://Wolf_Genome_Variantsdb \; -select-type SNP \; -O test_error1m.vcf.gz; -L chr1:1000000-2000000. The process stalls (doesn't terminate) without reporting any variants with the progress meter as below. . 18:46:19.529 INFO SelectVariants - Done initializing engine; 18:46:19.574 INFO ProgressMeter - Starting traversal; 18:46:19.574 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute. The stack trace on the stalled ""SelectVariants"" command looks like:. ""G1 Refine#78"" os_prio=0 tid=0x00007ff536ea6000 nid=0x1af0e0 runnable . ""G1 Refine#79"" os_prio=0 tid=0x00007ff536ea8000 nid=0x1af0e1 runnable . ""G1 Refine#80"" os_prio=0 tid=0x00007ff536ea9800 nid=0x1af0e2 runnable . ""G1 Refine#81"" os_prio=0 tid=0x00007ff536eab80",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1049112454:1386,error,error,1386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1049112454,1,['error'],['error']
Availability," GT: `0/0` or `0/1` or `1/1`. We currently report depth based copy number and quality for these variants in custom format fields `RD_CN` and `RD_GQ` if they are available; we could possibly move those values to the standard `CN` and `CNQ`, but there is some complexity in how to handle events detected by paired end and split reads without good read depth support; ie those under 1kb or so depending on our depth binning size and the coverage. Our depth genotyping module makes estimates of copy number for these sites but sometimes these can be very inaccurate so at the moment we prefer not to report total copy number in those fields. Probably what we _should_ do is fill in CN with 0, 1, or 2 based on the genotype we emitted and set CNQ to the value we computed for GQ. For multiallelic CNVs (i.e. sites where our model is not sure that the variant is bi-allelic) we write:. - ALT: `<CNV>`; - SVTYPE: `CNV`; - GT and GQ: `.`; - CN and CNQ: estimate of total (diploid/unphased) copy number and quality of the depth evidence. I think there are some tradeoffs in completely characterizing the evidence for and quality of each call and enabling easy searching across the whole VCF without having to parse and understand the entire record. Older versions of our pipeline used to put the diploid copy number of the event into the GT field, I think similarly to what's being described above. This is incorrect VCF -- GT values should be indices into the allele list for the variant, and should be a list of length equal to the ploidy. . My view is that if you can confidently infer the alleles present at the site in the sample set you should use a GT value of the form `0/1`, and if you don't know or aren't interested in trying to infer them you should use CN for total copy number and CNQ for the quality. CNF is also available in the spec for fractional estimates of copy number; for example Genome STRiP uses it to report the raw depth signal, which is useful for QC and identifying mosaic events.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-622053171:1993,avail,available,1993,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-622053171,1,['avail'],['available']
Availability," Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest STANDARD_ERROR; 01:40:14.522 WARN NativeLibraryLoader - Unable to load libgkl_pairhmm_fpga.so from native/libgkl_pairhmm_fpga.so (/tmp/libgkl_pairhmm_fpga17703278887667828152.so: libgkl_pairhmm_shacc.so: cannot open shared object file: No such file or directory); #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fe1a5cd00f2, pid=6969, tid=6997; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P"" (or dumping to /home/travis/build/broadinstitute/gatk/core.6969); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid6969.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; Starting process 'Gradle Test Executor 2'. Working directory: /home/travis/build/broadinstitute/gatk Command: /usr/local/lib/jvm/openjdk11/bin/java -Dgatk.spark.debug -Dorg.gradle.native=false -Dsamjdk.compression_level=2 -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -javaagent:build/tmp/expandedArchives/org.jacoco.agent-0.8.4.jar_982888894296538c98d7324f3ca78d8f/jacocoagent.jar=destfile=build/jacoco/test.exec,append=true,inclnolocationclasses=false,dumponexit=true,output=file,jmx=false @/tmp/gradle-worker-classpath15215090933788021522txt -Xms500M -Xmx3500M -Dfile.encoding=UTF-8 -Duser.country=US -Duser.language=en -Duser.variant -ea worker.org.gradle.process.internal.worker.GradleWorkerMain 'Gradle Test Executor 2'; Successfully",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-607332088:1563,error,error,1563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-607332088,1,['error'],['error']
Availability," HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 05:39:39.307 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:39:39.307 INFO CNNScoreVariants - Deflater: IntelDeflater; 05:39:39.307 INFO CNNScoreVariants - Inflater: IntelInflater; 05:39:39.307 INFO CNNScoreVariants - GCS max retries/reopens: 20; 05:39:39.307 INFO CNNScoreVariants - Requester pays: disabled; 05:39:39.307 INFO CNNScoreVariants - Initializing engine; 05:39:39.905 INFO FeatureManager - Using codec VCFCodec to read file file:///home/fmbuga/gatk4_gcp_wgs/06_vcf_raw/SRR16299720_dedup_AORRG_recal_raw.vcf; 05:39:40.108 INFO CNNScoreVariants - Done initializing engine; 05:39:40.109 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/fmbuga/.conda/envs/gatk4/share/gatk4-4.2.6.1-1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 05:39:40.429 INFO CNNScoreVariants - Done scoring variants with CNN.; 05:39:40.429 INFO CNNScoreVariants - Shutting down engine; [October 9, 2022 5:39:40 AM PDT] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=1903165440; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.utils.runtime.ProcessControllerAckResult.hasMessage(ProcessControllerAckResult.java:49); 	at org.broadinstitute.hellbender.utils.runtime.ProcessControllerAckResult.getDisplayMessage(ProcessControllerAckResult.java:69); 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.waitForAck(StreamingProcessController.java:235); 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.waitForAck(StreamingPythonScriptExecutor.java:216); 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.sendSynchronousCommand(StreamingPythonScriptExecutor.java:183); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.onTraversalStart(CNNScoreVariants.java:313); 	at org.broadinstitute.hellbende",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1274925490:3467,down,down,3467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1274925490,1,['down'],['down']
Availability," HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:55:36.414 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:55:36.414 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:55:36.414 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:55:36.415 INFO HaplotypeCaller - Deflater: IntelDeflater; 12:55:36.415 INFO HaplotypeCaller - Inflater: IntelInflater; 12:55:36.415 INFO HaplotypeCaller - GCS max retries/reopens: 20; 12:55:36.415 INFO HaplotypeCaller - Requester pays: disabled; 12:55:36.415 INFO HaplotypeCaller - Initializing engine; 12:55:36.508 INFO IntervalArgumentCollection - Processing 1 bp from intervals; 12:55:36.511 INFO HaplotypeCaller - Done initializing engine; 12:55:36.515 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 12:55:36.523 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/linux/Downloads/SNP/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 12:55:36.524 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/linux/Downloads/SNP/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 12:55:36.552 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 12:55:36.553 INFO IntelPairHmm - Available threads: 12; 12:55:36.553 INFO IntelPairHmm - Requested threads: 4; 12:55:36.553 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 12:55:36.569 INFO ProgressMeter - Starting traversal; 12:55:36.569 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 12:55:36.587 INFO HaplotypeCaller - 0 read(s) filtered by: MappingQualityReadFilter ; 0 read(s) filtered by: MappingQualityAvailableReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7229:2162,Down,Downloads,2162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7229,1,['Down'],['Downloads']
Availability," I am running GATK via a docker container as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. ``` bash; ./gatk Mutect2 -I:tumor 1st.chr1.bam -I:normal 2nd.chr1.bam -O variants.vcf.gz --min-pruning 8 -R reference.chr1.fa; ```; I repeated this three times, the last time to make sure whether the .vcf.stats is being generated or not. This was a test run using the input filtered for chr1 using `samtools view -b`. I though this was the reason for getting the error message about Contig 2 not being present. ```bash; ...; 18:39:03.207 INFO ProgressMeter - 1:282722440 448.7 1529870 3409.8; 18:39:06.592 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 19.218222963000002; 18:39:06.592 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5376.604473962; 18:39:06.593 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 12201.77 sec; 18:39:06.594 INFO Mutect2 - Shutting down engine; [August 25, 2020 6:39:06 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 448.75 minutes.; Runtime.totalMemory()=12349079552; ***********************************************************************. A USER ERROR has occurred: Contig 2 not present in the sequence dictionary [1]. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Is there any way of getting around this and generating .vcf.stats without repeating a lengthy variant calling `Mutect2`? Is this a problem introduced by running the truncated input files?. Looking up online, it seems this seemed to be an issue in the previous versions of GATK:https://github.com/broadinstitute/gatk/issues/6102. Thanks!. #### Expected behavior; I would expect .vcf.stats to be automatically generated with the output. #### Actual behavior; N",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6768:1302,down,down,1302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768,1,['down'],['down']
Availability," I failed to find hg19 host reference in the GATK resource bundle, first I created a BWA image file and a Kmer file originated from hg19 reference fasta with the command below. But for microbe-related files, I used ones that were contained in the bundle. . **'''** ; ; **gatk --java-options ""-Xmx50G"" BwaMemIndexImageCreator -I ./ref.fasta** ; **gatk --java-options ""-Xmx50G"" PathSeqBuildKmers --reference ./ref.fasta -O ref.hss** ; ; **'''**. . And then I ran PathSeq with the following command. . **'''** ; ; **gatk --java-options ""-Xmx200G"" PathSeqPipelineSpark \** ; **--input sample.bam \** ; **--filter-bwa-image ref.fasta.img \** ; **--kmer-file ref.hss \** ; **--is-host-aligned true \** ; **--min-clipped-read-length 70 \** ; **--microbe-fasta pathseq\_microbe.fa \** ; **--microbe-bwa-image pathseq\_microbe.fa.img \** ; **--taxonomy-file pathseq\_taxonomy.db \** ; **--output sample.pathseq.bam \** ; **--scores-output sample.pathseq.txt** ; ; ; **'''**. . and unfortunately it was shut down by this error message. **09:27:43.974 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/mnt/clinix1/Analysis/mongol/phenomata/Tools/Anaconda3/envs/gatk4/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so** ; **Mar 05, 2020 9:27:44 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine** ; **INFO: Failed to detect whether we are running on Google Compute Engine.** ; **09:27:44.733 INFO PathSeqPipelineSpark - ------------------------------------------------------------** ; **09:27:44.733 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.1.4.1** ; **09:27:44.734 INFO PathSeqPipelineSpark - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/)** ; **09:27:44.734 INFO PathSeqPipelineSpark - Executing as phenomata@cm132 on Linux v2.6.32-573.18.1.el6.x86\_64 amd64** ; **09:27:44.734 INFO PathSeqPi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:1699,down,down,1699,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,2,"['down', 'error']","['down', 'error']"
Availability," I'll choose a different snippet. EDITEDIT: Now using gs://broad-gotc-test-storage/joint_genotyping/exome/scientific/truth/master/gather_vcfs_high_memory/small_callset_low_threshold.vcf.gz provided by @ldgauthier, which does have AS annotations.; ; We'll use expected outputs here as inputs to downstream steps, but rather than provide the expected outputs directly, we'll create copies of them and provide those as inputs. This will make the tests better encapsulated. However, it should be relatively easy to update the whole chain of test files, should one choose to do so. EDIT: Let's just provide the expected outputs directly. So it'll be even easier to update the whole chain---just set the flags for all three tools to overwrite the expected results.; ; We test the Cartesian product of the following options: 1) non-allele-specific vs. allele-specific, 2) SNP vs. indel vs. both, and 3) positive vs. positive-unlabeled. Downstream, we'll further subset to a subset of these options, since training/scoring functionality shouldn't really change across some of them.; ; I'm currently just using call outs to system commands to diff and h5diff the VCFs and HDF5s, respectively. I think the latter command should be available in the GATK Conda environment. This will be a bit awkward, in the sense that the tests for this tool will require the Conda environment, but the tool itself will not. But I think this is probably preferable to writing test code to compare HDF5s, minimal though that might be, since the schema might change in the future.; - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs. Could perhaps expand on the `resources` parameter once the required labels are settled.; - [x] Parameter validation.; - [x] Clean up docs for parent walker.; - [x] Decide on required labels. I think ""training"" and ""calibration"" (rather than the legacy ""training"" and ""truth"") might be good candidates. EDIT: Switched ""truth"" to ""calibration"" throughout the codebase.; - [x] Validate ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059:2377,Down,Downstream,2377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059,1,['Down'],['Downstream']
Availability," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3651:3435,ERROR,ERROR,3435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651,5,['ERROR'],['ERROR']
Availability," INFO AbstractConnector:318 - Stopped Spark@6be766d1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-06-03 23:00:09 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4040; 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-06-03 23:00:09 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-06-03 23:00:09 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-06-03 23:00:09 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-06-03 23:00:09 INFO MemoryStore:54 - MemoryStore cleared; 2019-06-03 23:00:09 INFO BlockManager:54 - BlockManager stopped; 2019-06-03 23:00:09 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-06-03 23:00:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-06-03 23:00:09 INFO SparkContext:54 - Successfully stopped SparkContext; 23:00:09.356 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 11:00:09 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 7.01 minutes.; Runtime.totalMemory()=4327997440; 2019-06-03 23:00:09 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-06-03 23:00:09 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-73067845-b641-4212-9c81-51e8d6aa9f31; 2019-06-03 23:00:09 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-b4b61d51-d75f-45e5-9e10-8171d3acea1d; ```. hadoop fs -ls /project/casa/gcad/adsp.cc/sv/*sam; -rw-r--r-- 3 farrell casa 389867305631 2019-06-03 23:00 /project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.sam",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:16093,down,down,16093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['down'],['down']
Availability," INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.xx:45142 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:42:02 INFO TaskSetManager: Lost task 0.3 in stage 2.0 (TID 8) on xx.xx.xx.xx, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 2]; 18/04/24 17:42:02 ERROR TaskSetManager: Task 0 in stage 2.0 failed 4 times; aborting job; 18/04/24 17:42:02 INFO TaskSchedulerImpl: Cancelling stage 2; 18/04/24 17:42:02 INFO TaskSchedulerImpl: Stage 2 was cancelled; 18/04/24 17:42:02 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at PSFilter.java:125) failed in 117.782 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 8, xx.xx.xx.xx, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:34103,Error,Error,34103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Error'],['Error']
Availability," INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5232,ERROR,ERROR,5232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['ERROR'],['ERROR']
Availability," INFO FilterMutectCalls - ------------------------------------------------------------; 09:44:29.502 INFO FilterMutectCalls - HTSJDK Version: 2.20.1; 09:44:29.502 INFO FilterMutectCalls - Picard Version: 2.20.5; 09:44:29.502 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:44:29.502 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:44:29.502 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:44:29.503 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:44:29.503 INFO FilterMutectCalls - Deflater: IntelDeflater; 09:44:29.503 INFO FilterMutectCalls - Inflater: IntelInflater; 09:44:29.503 INFO FilterMutectCalls - GCS max retries/reopens: 20; 09:44:29.503 INFO FilterMutectCalls - Requester pays: disabled; 09:44:29.503 INFO FilterMutectCalls - Initializing engine; 09:44:29.869 INFO FeatureManager - Using codec VCFCodec to read file file:///mnt/md0/DataProcess/Ranshi/Mutect2/Try.vcf.gz; 09:44:29.942 INFO FilterMutectCalls - Done initializing engine; 09:44:30.029 INFO FilterMutectCalls - Shutting down engine; [2019821 094430] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2097152000; ***********************************************************************. A USER ERROR has occurred: Mutect stats table Try.vcf.gz.stats not found. When Mutect2 outputs a file calls.vcf it also creates a calls.vcf.stats file. Perhaps this file was not moved along with the vcf, or perhaps it was not delocalized from a virtual machine while running in the cloud. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```. `Try.vcf.stat` was lost, I have to re-run `Mutect2` using latest release. It seems that this bug was fixed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-523262338:2908,down,down,2908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-523262338,2,"['ERROR', 'down']","['ERROR', 'down']"
Availability," INFO GenomicsDBImport - Initializing engine; 10:49:12.577 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 10:49:12.938 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; 10:49:13.163 INFO IntervalArgumentCollection - Processing 51304566 bp from intervals; 10:49:13.163 INFO GenomicsDBImport - Done initializing engine; 10:49:13.164 INFO GenomicsDBImport - Callset Map JSON file will be re-written to /mnt/mone/OMICS/Project/Joint_call/GATK_GenomicDB/test_database/test_overwrite_1/callset.json; 10:49:13.164 INFO GenomicsDBImport - Incrementally importing to workspace - /mnt/mone/OMICS/Project/Joint_call/GATK_GenomicDB/test_database/test_overwrite_1; 10:49:13.164 INFO ProgressMeter - Starting traversal; 10:49:13.164 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 10:49:13.231 INFO GenomicsDBImport - Shutting down engine; [June 18, 2021 10:49:13 AM KST] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2194669568; org.genomicsdb.exception.GenomicsDBException: Duplicate sample name found: 4762. Sample was originally in /mnt/mone/OMICS/Project/Asian_Genome/Korea/4762/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf; at org.genomicsdb.importer.extensions.CallSetMapExtensions.checkDuplicateCallsetsForIncrementalImport(CallSetMapExtensions.java:270); at org.genomicsdb.importer.extensions.CallSetMapExtensions.mergeCallsetsForIncrementalImport(CallSetMapExtensions.java:241); at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:252); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:745); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7324:4064,down,down,4064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7324,1,['down'],['down']
Availability," INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/713.mkdup.sort.rg.tsv (40 / 323); 06:49:07.999 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/252.mkdup.sort.rg.tsv (41 / 323); 06:49:10.433 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/547.mkdup.sort.rg.tsv (42 / 323); 06:49:13.341 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/154.mkdup.sort.rg.tsv (43 / 323); 06:49:15.782 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/651.mkdup.sort.rg.tsv (44 / 323); 06:49:18.251 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/94.mkdup.sort.rg.tsv (45 / 323); 06:49:20.605 INFO GermlineCNVCaller - Shutting down engine; [August 13, 2021 6:49:20 AM GMT] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 2.27 minutes.; Runtime.totalMemory()=2076049408; java.lang.IllegalArgumentException: Prefix string too short; at java.io.File.createTempFile(File.java:2001); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFileInDirectory(IOUtils.java:685); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFile(IOUtils.java:666); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.lambda$writeIntervalSubsetReadCountFiles$1(GermlineCNVCaller.java:434); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.Abs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7410:1424,down,down,1424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7410,1,['down'],['down']
Availability," INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:57:08.790 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 00:57:08.790 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:57:08.790 INFO IndexFeatureFile - Deflater: IntelDeflater; 00:57:08.790 INFO IndexFeatureFile - Inflater: IntelInflater; 00:57:08.790 INFO IndexFeatureFile - GCS max retries/reopens: 20; 00:57:08.790 INFO IndexFeatureFile - Requester pays: disabled; 00:57:08.790 INFO IndexFeatureFile - Initializing engine; 00:57:08.790 INFO IndexFeatureFile - Done initializing engine; 00:57:09.166 INFO FeatureManager - Using codec VCFCodec to read file file:///share/pool/CompGenomVert/phoxy_snp_calling/VC_HIFI/output/called/final/allsites.filtered.vcf; 00:57:09.250 INFO ProgressMeter - Starting traversal; 00:57:09.250 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 00:57:09.251 INFO IndexFeatureFile - Shutting down engine; [11. September 2023 00:57:09 MESZ] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.NumberFormatException: For input string: ""175,24""; at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043); at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); at java.lang.Double.parseDouble(Double.java:538); at htsjdk.variant.vcf.VCFUtils.parseVcfDouble(VCFUtils.java:262); at htsjdk.variant.vcf.AbstractVCFCodec.parseQual(AbstractVCFCodec.java:620); at htsjdk.variant.vcf.AbstractVCFCodec.parseVCFLine(AbstractVCFCodec.java:422); at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:384); at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:328); at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:48); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:70); at htsjdk.tribble.AsciiFeatureCodec.decode(Asc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8372#issuecomment-1733069316:2866,down,down,2866,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8372#issuecomment-1733069316,1,['down'],['down']
Availability," INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/alcalan/.conda/mutect2-cd161e2f51ff2240ce6390abc942bbdd/share/gatk4-4.1.5.0-1/gatk-package-4.1.5.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 10:34:26.264 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 10:34:26.267 INFO IntelPairHmm - Available threads: 8; 10:34:26.267 INFO IntelPairHmm - Requested threads: 4; 10:34:26.267 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 10:34:26.375 INFO ProgressMeter - Starting traversal; 10:34:26.375 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 10:34:26.950 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 10:34:26.950 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 10:34:26.950 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.03 sec; 10:34:26.951 INFO Mutect2 - Shutting down engine; [March 23, 2020 10:34:26 AM CET] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=1214251008; java.lang.StringIndexOutOfBoundsException: String index out of range: -1; 	at java.lang.String.substring(String.java:1927); 	at org.broadinstitute.hellbender.tools.walkers.annotator.TandemRepeat.getNumTandemRepeatUnits(TandemRepeat.java:54); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyRegionTrimmer.trim(AssemblyRegionTrimmer.java:175); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:229); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:299); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKToo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6516:4843,down,down,4843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6516,1,['down'],['down']
Availability," INFO TaskSetManager: Starting task 0.2 in stage 0.0 (TID 2, xx.xx.xx.xx, executor 0, partition 0, PROCESS_LOCAL, 4956 bytes); 18/04/23 20:42:02 INFO TaskSetManager: Lost task 0.2 in stage 0.0 (TID 2) on xx.xx.xx.xx, executor 0: java.lang.IllegalStateException (unread block data) [duplicate 2]; 18/04/23 20:42:02 INFO TaskSetManager: Starting task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0, partition 0, PROCESS_LOCAL, 4956 bytes); 18/04/23 20:42:02 INFO TaskSetManager: Lost task 0.3 in stage 0.0 (TID 3) on xx.xx.xx.xx, executor 0: java.lang.IllegalStateException (unread block data) [duplicate 3]; 18/04/23 20:42:02 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job; 18/04/23 20:42:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool; 18/04/23 20:42:02 INFO TaskSchedulerImpl: Cancelling stage 0; 18/04/23 20:42:02 INFO DAGScheduler: ResultStage 0 (first at ReadsSparkSource.java:221) failed in 11.519 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:15256,failure,failure,15256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['failure'],['failure']
Availability," INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.4.4-ce4e1b9; 12:01:33.262 INFO NativeGenomicsDB - pid=1923139 tid=1923140 No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; 12:01:33.262 INFO NativeGenomicsDB - pid=1923139 tid=1923140 No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; 12:01:33.262 INFO NativeGenomicsDB - pid=1923139 tid=1923140 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 12:01:33.288 INFO GenotypeGVCFs - Shutting down engine; [March 1, 2024 at 12:01:33 PM UTC] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.25 minutes.; Runtime.totalMemory()=1130364928; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. ; content of my callset.json file:. {""callsets"": [{""sample_name"": ""ERR318225"",""row_idx"": 223,""idx_in_file"": 0,""stream_name"": ""ERR318225_stream""},{""sample_name"": ""ERR318226"",""row_idx"": 224,""idx_in_file"": 0,""stream_name"": ""ERR318226_stream""},{""sample_name"": ""ERR4133262"",""row_idx"": 225,""idx_in_file"": 0,""stream_name"": ""ERR4133262_stream""},{""sample_name"": ""ERR4133361"",""row_idx"": 226,""idx_in_file"": 0,""stream_name"": ""ERR4133361_stream""},{""sample_name"": ""ERR4133400"",""row_idx"": 227,""idx_in_file"": 0,""stream_name"": ""ERR4133400_stream""},{""sample_name"": ""ERR4133407"",""row_idx"": 228,""idx_in_file"": 0,""stream_name"": ""ERR4133407_stream""},{""sample_name"": ""ERR4133418"",""row_idx"": 229,""idx_in_file"": 0,""stream_name"": ""ERR4133418_stream""},{""sample_name"": ""ERR41",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8709:5241,ERROR,ERROR,5241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8709,1,['ERROR'],['ERROR']
Availability," Importing to array - /home/WangBS/Analyses/vcf/test/chr02/genomicsdb_array; 23:42:44.276 INFO ProgressMeter - Starting traversal; 23:42:44.276 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 23:42:45.830 INFO GenomicsDBImport - Importing batch 1 with 63 samples; Buffer resized from 37294 bytes to 65464; Buffer resized from 37294 bytes to 65511; Buffer resized from 37293 bytes to 65539; Buffer resized from 37294 bytes to 65447; .....; .....; Buffer resized from 65538 bytes to 65539; Buffer resized from 65538 bytes to 65539; Buffer resized from 65538 bytes to 65539; 06:50:14.219 INFO ProgressMeter - Qrob_Chr02:1 427.5 1 0.0; 06:50:14.220 INFO GenomicsDBImport - Done importing batch 1/1; 06:50:14.221 INFO ProgressMeter - Qrob_Chr02:1 427.5 1 0.0; 06:50:14.229 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 427.5 minutes.; 06:50:14.236 INFO GenomicsDBImport - Import completed!; 06:50:14.236 INFO GenomicsDBImport - Shutting down engine; [January 27, 2019 6:50:14 AM CST] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 428.57 minutes.; Runtime.totalMemory()=8988393472; Tool returned:; true; Using GATK jar /home/WangBS/software/GATK/gatk/build/libs/gatk-package-4.0.11.0-56-g2c0e9b0-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx24g -jar /home/WangBS/software/GATK/gatk/build/libs/gatk-package-4.0.11.0-56-g2c0e9b0-SNAPSHOT-local.jar GenotypeGVCFs -R /home/WangBS/Reference/Qrobur/Qrob_PM1N.fa -V gendb:///home/WangBS/Analyses/vcf/test/chr02 -all-sites -O /home/WangBS/Analyses/vcf/test/chr02.vcf; 06:50:19.236 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/WangBS/software/GATK/gatk/build/libs/gatk-package-4.0.11.0-56-g2c0e9b0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; 06:51:21.116 INFO Genot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5865:4194,down,down,4194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865,1,['down'],['down']
Availability," IndexFeatureFile - GCS max retries/reopens: 20; 09:28:39.196 INFO IndexFeatureFile - Requester pays: disabled; 09:28:39.196 INFO IndexFeatureFile - Initializing engine; 09:28:39.196 INFO IndexFeatureFile - Done initializing engine; 09:28:39.696 INFO FeatureManager - Using codec VCFCodec to read file file:///storage/ppl/yifang/20190327_David_rampseq_Ehsan/data/samtools_sorted_out/SNPs_candidates.g.vcf; 09:28:39.708 INFO ProgressMeter - Starting traversal; 09:28:39.708 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; =========This is the indexed chromosome ===================; 09:28:41.968 INFO ProgressMeter - **chr7B_part2:295520629** 0.0 925631 24596040.7. 09:28:41.968 INFO ProgressMeter - Traversal complete. Processed 925631 total records in 0.0 minutes.; 09:28:42.006 INFO IndexFeatureFile - Successfully wrote index to /storage/ppl/yifang/20190327/data/samtools_sorted_out/SNPs_candidates.g.vcf.idx; 09:28:42.006 INFO IndexFeatureFile - Shutting down engine; [May 6, 2019 9:28:42 CST AM] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=2434269184). ```; This is my command line:; `java -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar ${gatk4_jar} IndexFeatureFile --feature-file ${gvcf} --output ${gvcf}.idx 2>${LOGDIR}/index_candidates.log`. I tried this exact command line with another genome, which worked just fine with output progress report as following for a comparison of the multiple chromosomes processed:; ```; 12:50:38.871 INFO ProgressMeter - Starting traversal; 12:50:38.873 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 12:50:48.876 INFO ProgressMeter - N1:21408210 0.2 5669000 34010598.9; 12:50:58.876 INFO ProgressMeter - N2:13383863 0.3 11960000 35874618.8. ...... 12:55:58.884 INFO ProgressMeter - N19:50063133 5.3 208660000 39122405.2; 12:56:02.409 INFO ProgressMeter - N19:55994806 5.4 210940859 39119265.4; 12:56:02.409 INFO Progr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5917:4395,down,down,4395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5917,1,['down'],['down']
Availability," Inflater: IntelInflater; 22:30:25.478 INFO BaseRecalibrator - GCS max retries/reopens: 20; 22:30:25.479 INFO BaseRecalibrator - Requester pays: disabled; 22:30:25.479 INFO BaseRecalibrator - Initializing engine; WARNING 2024-03-08 22:30:25 SamFiles The index file /mnt/storage/users/dockworker/mpedersen/work/RNAseq_variant_call/work/d6/362957b6215ad2e8193c27c895d42d/VR0024SA.withoutERCCs.withRG.markedDup.splitNcigar.bai was found by resolving the canonical path of a symlink: VR0024SA.withoutERCCs.withRG.markedDup.splitNcigar.bam -> /mnt/storage/users/dockworker/mpedersen/work/RNAseq_variant_call/work/d6/362957b6215ad2e8193c27c895d42d/VR0024SA.withoutERCCs.withRG.markedDup.splitNcigar.bam; 22:30:25.631 INFO FeatureManager - Using codec VCFCodec to read file file://1000G_phase1.snps.high_confidence.hg38.vcf.gz; 22:30:25.754 INFO FeatureManager - Using codec VCFCodec to read file file://Mills_and_1000G_gold_standard.indels.hg38.vcf.gz; 23:39:21.541 INFO BaseRecalibrator - Shutting down engine; [March 8, 2024 at 11:39:21 PM GMT] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 68.94 minutes.; Runtime.totalMemory()=214748364800; java.lang.OutOfMemoryError: Java heap space; at htsjdk.tribble.readers.TabixReader.readInt(TabixReader.java:189); at htsjdk.tribble.readers.TabixReader.readIndex(TabixReader.java:274); at htsjdk.tribble.readers.TabixReader.readIndex(TabixReader.java:287); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:165); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:433); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:377); at org.broadinstitute.hellbender.engine.FeatureDataS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8726:2110,down,down,2110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8726,1,['down'],['down']
Availability," Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5293,ERROR,ERROR,5293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['ERROR'],['ERROR']
Availability," IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/Users/daniel/workspaces/gatk4test/build/libs/shadowJar-0.0.1-SNAPSHOT-all.jar!/com/intel/gkl/native/libIntelGKL.dylib; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x0000000128c014d0, pid=31197, tid=5891; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libIntelGKL8818190486223479934.dylib+0xe4d0] _ZN7ContextIfEC2Ev+0x30; #; # Core dump written. Default location: /cores/core or core.31197; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/gatk4test/hs_err_pid31197.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6 (core dumped); ```. To fix it, I tried by excluding `com.intel.gkl` from GATK and add it as a dependency to my program, but it blows up anyway. In addition, I tried a sample program to load the PairHMM fastest implementation by `PairHMM.Implementation.FASTEST_AVAILABLE.makeNewHMM()`, and it also blows up. If I remove completely the dependency in my shadow jar, the command line blows up because the gkl `IntelDeflaterFactory` is not found. I guess that the error in the library is GKL-related, but in the case of the GATK framework I would like to have a way of using the library without assuming that the final user will have support for the native code or not. Could this be done? I prefer not to remove the faster code by intel because I know that some users will benefit from it. Just in case it is needed, my system is a Mac OS X (10.11.5) with Darwin Kernel Version 15.5.0 (root:xnu-3248.50.21~8/RELEASE_X86_64 x86_64). Thank you very much in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1985:1887,error,error,1887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1985,1,['error'],['error']
Availability," Linux 3.10.0-514.16.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b15; Version: 4.alpha.2-1125-g27b5190-SNAPSHOT; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a]",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4521,ERROR,ERROR,4521,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['ERROR'],['ERROR']
Availability," MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!** ; **20/03/05 09:28:58 INFO NewHadoopRDD: Input split: file:/clinix1/Analysis/mongol/phenomata/04.GC\_CC/01.Alignment/Aligned/17039\_N.bam:1342177280+33554432** ; **20/03/05 09:28:58 INFO MemoryStore: MemoryStore cleared** ; **20/03/05 09:28:58 INFO BlockManager: BlockManager stopped** ; **20/03/05 09:28:58 INFO BlockManagerMaster: BlockManagerMaster stopped** ; **20/03/05 09:28:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!** ; **20/03/05 09:28:58 INFO SparkContext: Successfully stopped SparkContext** ; **09:28:58.889 INFO PathSeqPipelineSpark - Shutting down engine** ; **[2020 3 5 ()  9 28 58] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.25 minutes.** ; **Runtime.totalMemory()=19560660992** ; **org.apache.spark.SparkException: Job aborted due to stage failure: Task 34 in stage 0.0 failed 1 times, most recent failure: Lost task 34.0 in stage 0.0 (TID 34, localhost, executor driver): com.esotericsoftware.kryo.KryoException: Buffer underflow.** ; **at com.esotericsoftware.kryo.io.Input.require(Input.java:199)** ; **at com.esotericsoftware.kryo.io.Input.readLong(Input.java:686)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet.<init>(LongHopscotchSet.java:83)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:527)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:519)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:712)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet.<init>(LargeLongHopscotchSet.java:55)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet$Serializer.read(LargeLongHopscotchSet.java:172)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:42519,failure,failure,42519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['failure'],['failure']
Availability," MarkDuplicatesSpark - ------------------------------------------------------------; 21:47:48.271 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 21:47:48.271 INFO MarkDuplicatesSpark - HTSJDK Version: 2.14.3; 21:47:48.271 INFO MarkDuplicatesSpark - Picard Version: 2.18.2; 21:47:48.271 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 21:47:48.271 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 21:47:48.272 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 21:47:48.272 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 21:47:48.272 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 21:47:48.272 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 21:47:48.272 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 21:47:48.272 INFO MarkDuplicatesSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 21:47:48.272 WARN MarkDuplicatesSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: MarkDuplicatesSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 21:47:48.273 INFO MarkDuplicatesSpark - Initializing engine; 21:47:48.273 INFO MarkDuplicatesSpark - Done initializing engine; 22:29:27.746 INFO ReadsSparkSink - Finished sorting the bam file and dumping read shards to disk, proceeding to merge the shards into a single file using the master thread; 22:43:29.758 INFO ReadsSparkSink - Finished merging shards into a single output bam; 22:43:36.475 INFO MarkDuplicatesSpark - Shutting down engine; [May 7, 2018 10:43:36 PM EDT] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 55.82 minutes.; Runtime.totalMemory()=12430868480; ```. Created after discussion with @lbergelson",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746:7985,down,down,7985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746,1,['down'],['down']
Availability," MarkDuplicatesSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:40:21.994 WARN MarkDuplicatesSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: MarkDuplicatesSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 14:40:21.994 INFO MarkDuplicatesSpark - Initializing engine; 14:40:21.994 INFO MarkDuplicatesSpark - Done initializing engine; 14:40:22.338 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 15:24:12.735 INFO ReadsSparkSink - Finished sorting the bam file and dumping read shards to disk, proceeding to merge the shards into a single file using the master thread; 15:41:27.766 INFO ReadsSparkSink - Finished merging shards into a single output bam; 15:41:34.351 INFO MarkDuplicatesSpark - Shutting down engine; [May 7, 2018 3:41:34 PM EDT] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 61.21 minutes.; Runtime.totalMemory()=13635682304; ```. With native libraries (note the lack of the usual warning):. ```; $ ${GATK_DIR}/gatk MarkDuplicatesSpark --java-options ""-Djava.library.path=${HADOOP_DIR}/hadoop-2.6.5-src/hadoop-common-project/hadoop-common/target/hadoop-common-2.6.5/lib/native"" -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.dupmarked_native.bam -- --spark-runner LOCAL --spark-master local[8]; Using GATK wrapper script ${GATK_DIR}/gatk/build/install/gatk/bin/gatk; Running:; ${GATK_DIR}/gatk/build/install/gatk/bin/gatk MarkDuplicatesSpark -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.dupmarked_native.bam --spark-master local[8]; 21:47:47.494 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLB",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746:4282,down,down,4282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746,1,['down'],['down']
Availability, Mutect2Engine - Active Region chrM:1154-1397; 11:35:45.413 DEBUG Mutect2Engine - Extended Act Region chrM:1054-1497; 11:35:45.413 DEBUG Mutect2Engine - Ref haplotype coords chrM:1054-1497; 11:35:45.413 DEBUG Mutect2Engine - Haplotype count 1; 11:35:45.413 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:45.414 DEBUG Mutect2Engine - Kmer sizes values []; 11:35:45.737 DEBUG Mutect2 - Processing assembly region at chrM:1398-1697 isActive: false numReads: 2722; 11:35:45.837 DEBUG Mutect2 - Processing assembly region at chrM:1698-1997 isActive: false numReads: 0; 11:35:45.999 DEBUG Mutect2 - Processing assembly region at chrM:1998-2297 isActive: false numReads: 0; 11:35:46.219 DEBUG Mutect2 - Processing assembly region at chrM:2298-2543 isActive: false numReads: 2555; 11:35:46.674 DEBUG Mutect2 - Processing assembly region at chrM:2544-2841 isActive: true numReads: 5108; 11:35:48.094 DEBUG ReadThreadingGraph - Recovered 17 of 20 dangling tails; 11:35:48.198 DEBUG ReadThreadingGraph - Recovered 16 of 50 dangling heads; 11:35:48.511 DEBUG IntToDoubleFunctionCache - cache miss 2389 > 10 expanding to 2399; 11:35:48.874 DEBUG Mutect2Engine - Active Region chrM:2544-2841; 11:35:48.874 DEBUG Mutect2Engine - Extended Act Region chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Ref haplotype coords chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Haplotype count 128; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:08.907 INFO ProgressMeter - chrM:2544 0.4 10 22.3; 11:36:08.954 DEBUG Mutect2 - Processing assembly region at chrM:2842-2920 isActive: false numReads: 4726; 11:36:09.094 DEBUG Mutect2 - Processing assembly region at chrM:2921-3202 isActive: true numReads: 4600; 11:36:09.663 DEBUG ReadThreadingGraph - Recovered 1 of 2 dangling tails; 11:36:09.671 DEBUG ReadThreadingGraph - Recovered 4 of 7 dangling heads; 11:36:09.750 DEBUG Mutect2Engine - Active Region chrM:2921-3202; 11:36:09.750 DEBUG Mutect2Engin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:9267,Recover,Recovered,9267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability," SparkContext; 22:45:35.933 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 10:45:35 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 5.79 minutes.; Runtime.totalMemory()=4147118080; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-423d02dc-cbc1-4c83-907d-ca315ca231bc; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-c035847e-6113-48f1-b5d1-66184925be7d; ```. $ hadoop fs -ls /project/casa/gcad/adsp.cc/sv/*. -rw-r--r-- 3 farrell casa 1684348 2019-06-03 22:34 /project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.bam.sbi; -rw-r--r-- 3 farrell casa 27494132363 2019-06-03 22:45 /project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.cram. Writing to a sam worked without triggering error.... ```; 2019-06-03 22:59:08 INFO TaskSetManager:54 - Finished task 183.0 in stage 0.0 (TID 181) in 106230 ms on scc-q04.scc.bu.edu (executor 23) (162/189); 2019-06-03 22:59:08 INFO TaskSetManager:54 - Finished task 154.0 in stage 0.0 (TID 153) in 138243 ms on scc-q01.scc.bu.edu (executor 18) (163/189); 2019-06-03 22:59:09 INFO TaskSetManager:54 - Finished task 142.0 in stage 0.0 (TID 147) in 144577 ms on scc-q09.scc.bu.edu (executor 29) (164/189); 2019-06-03 22:59:10 INFO TaskSetManager:54 - Finished task 136.0 in stage 0.0 (TID 138) in 195420 ms on scc-q09.scc.bu.edu (executor 16) (165/189); 2019-06-03 22:59:12 INFO TaskSetManager:54 - Finished task 146.0 in stage 0.0 (TID 152) in 142642 ms on scc-q06.scc.bu.edu (executor 28) (166/189); 2019-06-03 22:59:14 INFO TaskSetManager:54 - Finished task 162.0 in stage 0.0 (TID 156) in 138765 ms on scc-q06.scc.bu.edu (executor 28) (167/189); 2019-06-03 22:59:16 INFO TaskSetManager:54 - Finished task 151.0 in stage 0.0 ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:10266,error,error,10266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,2,['error'],['error']
Availability," Started o.s.j.s.ServletContextHandler@2262f0d8{/environment,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59e082f8{/environment/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d43cc9{/executors,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@656ec00d{/executors/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed25612{/executors/threadDump,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56e5c8fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9e33a6a{/static,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b3fc6d8{/,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed31735{/api,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@351e89fc{/jobs/job/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15586843{/stages/stage/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.131.101.159:4040; 17/10/13 18:11:34 INFO spark.SparkContext: Added JAR file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar at spark://10.131.101.159:45754/jars/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar with timestamp 1507889494965; 17/10/13 18:11:35 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 17/10/13 18:11:35 INFO gcs.GoogleHadoopFileSystemB",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:8523,AVAIL,AVAILABLE,8523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability," Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletCo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8469,AVAIL,AVAILABLE,8469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability," Started o.s.j.s.ServletContextHandler@45f9d394{/storage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a588b5f{/storage/rdd,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bdb5e0f{/storage/rdd/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2262f0d8{/environment,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59e082f8{/environment/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d43cc9{/executors,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@656ec00d{/executors/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed25612{/executors/threadDump,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56e5c8fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9e33a6a{/static,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b3fc6d8{/,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed31735{/api,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@351e89fc{/jobs/job/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15586843{/stages/stage/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.131.101.159:4040; 17/10/13 18:11:34 INFO spark.SparkContext: Added JAR file:/opt/Software/gatk/build/libs/gat",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:8134,AVAIL,AVAILABLE,8134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability," The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.FileAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.FileAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""file"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```. By backtracking, the problem goes away at commit d827adc81266c788482c9cb4f119f2e3c1e152b8. Since spark-submmit was broken after 8af8bcc920ee5f393562e3e632d9ccd4acd9a638, the bug could be anywhere between commit 8af8bcc920ee5f393562e3e632d9ccd4acd9a638 and d25894b3bc80e450210cf8a9124c4171e65f3717. The log4j.property file is below:; ```; # Set everything to be logged to the console; log4j.rootCategory=WARN,console; log4j.appender.console=org.apache.log4j.ConsoleAppender; log4j.appen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2734:1285,ERROR,ERROR,1285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2734,1,['ERROR'],['ERROR']
Availability," There are huge customers of Hadoop already work on hadoop.fs for years, if GAKT on spark could rely on org.apache.hadoop.fs.{FileSystem, Path} , I guess GAKT could acquire more existing customers of Hadoop on Cloud much faster . . Maybe we could consider migrating java.nio.file.FileSystem impl to org.apache.hadoop.fs.{FileSystem, Path} impl in [SparkContextFacto]r(https://github.com/broadinstitute/gatk/blob/73f2a62bee52518b57a985717770ed3a64d83243/src/main/java/org/broadinstitute/hellbender/engine/spark/SparkContextFactory.java), otherwise we could support both nio and hadoop thru env variable, Let me know your thought!. ```; scala> stringRdd.saveAsTextFile(""oss://eric-new/testwrite10""). scala> val stringRdd = sc.parallelize(Seq(""Test String"")); stringRdd: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[4] at parallelize at <console>:24. scala> stringRdd.saveAsTextFile(""oss://eric-new/testwrite11""); ```. ``` oss nio is missing; 18/01/03 17:13:13 INFO NewHadoopRDD: Input split: oss://eric-new/resources/NA12878.chr17_69k_70k.dictFix.bam:1632-3770875903; 18/01/03 17:13:13 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0); java.nio.file.ProviderNotFoundException: Provider ""oss"" not found; 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:341); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:143); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:226); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:180); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:179); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:134); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-354989381:2162,ERROR,ERROR,2162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-354989381,1,['ERROR'],['ERROR']
Availability," ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrowser.bed.bgz --known-sites snp151flagged_tablebrowser.bed.bgz`; ```; ERROR: return code 3; STDERR:; 15:46:35.795 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:46:42.808 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:42.810 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.0.0; 15:46:42.810 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:46:42.813 INFO BaseRecalibrator - Executing as mpmachado@lx-bioinfo02 on Linux v2.6.32-696.23.1.el6.x86_64 amd64; 15:46:42.814 INFO BaseRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; 15:46:42.814 INFO BaseRecalibrator - Start Date/Time: March 7, 2019 3:46:35 PM UTC; 15:46:42.815 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:42.815 INFO BaseRecalibrator - ------------------------------------------------------------; 15:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:2736,ERROR,ERROR,2736,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['ERROR'],['ERROR']
Availability," WrappedArray(null); 18/04/24 17:41:53 INFO TaskSetManager: Starting task 1.2 in stage 2.0 (TID 9, xx.xx.xx.25, executor 6, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:41:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.xx:45142 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:42:02 INFO TaskSetManager: Lost task 0.3 in stage 2.0 (TID 8) on xx.xx.xx.xx, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 2]; 18/04/24 17:42:02 ERROR TaskSetManager: Task 0 in stage 2.0 failed 4 times; aborting job; 18/04/24 17:42:02 INFO TaskSchedulerImpl: Cancelling stage 2; 18/04/24 17:42:02 INFO TaskSchedulerImpl: Stage 2 was cancelled; 18/04/24 17:42:02 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at PSFilter.java:125) failed in 117.782 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 8, xx.xx.xx.xx, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$an",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:33935,failure,failure,33935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['failure'],['failure']
Availability," [00:01<00:00, 428.25it/s]; 15:10:05.149 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -431.479 +/- 164.680, SNR: 8.6, T: 1.81: 97%|#########7| 970/1000 [00:01<00:00, 416.04it/s]; 15:10:05.229 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -426.199 +/- 162.710, SNR: 8.3, T: 1.80: 100%|##########| 1000/1000 [00:01<00:00, 521.12it/s]; 15:10:05.229 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1): 0%| | 0/100 [00:00<?, ?it/s]; 15:10:05.502 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 1.0000 +/- 0.0000: 1%|1 | 1/100 [00:00<00:26, 3.68it/s]; 15:10:05.772 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0046 +/- 0.0049: 2%|2 | 2/100 [00:00<00:26, 3.69it/s]; 15:10:06.039 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0023 +/- 0.0037: 3%|3 | 3/100 [00:00<00:26, 3.71it/s]; 15:10:06.307 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0016 +/- 0.0036: 4%|4 | 4/100 [00:01<00:25, 3.72it/s]; 15:10:06.575 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0018 +/- 0.0019: 5%|5 | 5/100 [00:01<00:25, 3.72it/s]; 15:10:06.844 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0013 +/- 0.0014: 6%|6 | 6/100 [00:01<00:25, 3.72it/s]; 15:10:07.113 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0014 +/- 0.0019: 7%|7 | 7/100 [00:01<00:24, 3.72it/s]; 15:10:07.381 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0011 +/- 0.0011: 8%|8 | 8/100 [00:02<00:24, 3.72it/s]; 15:10:07.649 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0008 +/- 0.0009: 10%|# | 10/100 [00:02<00:24, 3.72it/s]; 15:10:08.193 INFO gc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:11409,error,error,11409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['error'],['error']
Availability, [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:230); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:227); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLau,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:5702,ERROR,ERROR,5702,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability," [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] A problem occurred evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configurati",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:2194,ERROR,ERROR,2194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability," [VS-472] (#7905); - Fix bug and update images (#7912); - VS 483 Beta user wdl (#7894); - Core storage model cost [VS-473] (#7913); - Update Quickstart & Integration to use re-blocked v2 gVCFs [VS-491] (#7924); - KM GVS documentation (#7903); - Track BigQuery costs of GVS python VS-480 (#7915); - Read cost observability table [VS-475] (#7923); - Fix Race Condition, Add Support for Extract by Array of Sample Names (ie from a Sample Set) (#7917); - Rightsize import batches [VS-486] (#7925); - [AoU DRC] Support uppercase site_ids for reblocking (#7929); - Populate cost metadata for GATK tasks. (#7919); - remove accidentally added input (#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change backticks to single quotes in several error messages - causing shell to attempt to execute. (#7995); - VS-598 - Minor update to AoU Documentation. (#7994); - Allow for incremental addition of data to alt_allele [VS-52] (#7993); - Minor AoU Documentation Update (#7999); -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:26691,down,download,26691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['down'],['download']
Availability," [hs_err_pid100.log](https://github.com/broadinstitute/gatk/files/6203288/hs_err_pid100.log); [hs_err_pid164.log](https://github.com/broadinstitute/gatk/files/6203289/hs_err_pid164.log); [hs_err_pid274.log](https://github.com/broadinstitute/gatk/files/6203290/hs_err_pid274.log); [hs_err_pid400.log](https://github.com/broadinstitute/gatk/files/6203291/hs_err_pid400.log); [hs_err_pid482.log](https://github.com/broadinstitute/gatk/files/6203292/hs_err_pid482.log); [hs_err_pid711.log](https://github.com/broadinstitute/gatk/files/6203293/hs_err_pid711.log); [hs_err_pid735.log](https://github.com/broadinstitute/gatk/files/6203294/hs_err_pid735.log); [hs_err_pid801.log](https://github.com/broadinstitute/gatk/files/6203295/hs_err_pid801.log); [hs_err_pid825.log](https://github.com/broadinstitute/gatk/files/6203296/hs_err_pid825.log); [hs_err_pid849.log](https://github.com/broadinstitute/gatk/files/6203297/hs_err_pid849.log); [otherFiles.zip](https://github.com/broadinstitute/gatk/files/6203305/otherFiles.zip); [in2510-8.orientationFilter.vcf.txt](https://github.com/broadinstitute/gatk/files/6203356/in2510-8.orientationFilter.vcf.txt); *VCF extension appended with .txt to satisfy GitHub's upload requirements*. #### Expected behavior; Worked on 7 other files generated with the same pipeline. . #### Actual behavior; Unsure why this last one is causing a segfault. The VCF included is not the whole VCF submitted originally. I went cutting out lines from the original until I could isolate it down to a minimal set required to reproduce the crash (I included all of the crash logs generated in case it can help). I was expecting to find a single line or maybe two that were required to reproduce this issue, but that range appears to be needed. Eliminating either the first or last line from the range will make the program work again. Did not attempt to remove lines from the middle of the range yet to see if they're necessary to cause the fault, but it's 2am and I should probably sleep.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:7969,down,down,7969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,2,"['down', 'fault']","['down', 'fault']"
Availability," \; -L /home/nguyen/RB1/RB1.cohort.gc.filtered.interval_list \; --interval-merging-rule OVERLAPPING_ONLY \; -I ... (63 tsv files output from CollectReadCounts); ```. ### Affected version(s); - GATK 4.1.6.1; ### Description ; Full error log:; ```; Traceback (most recent call last):; File ""/tmp/cohort_determine_ploidy_and_depth.380621677219090732.py"", line 119, in <module>; ploidy_task.engage(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 339, in engage; converged_continuous = self._update_continuous_posteriors(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 395, in _update_continuous_posteriors; assert not np.isnan(loss), ""The optimization step for ELBO update returned a NaN""; AssertionError: The optimization step for ELBO update returned a NaN; 11:09:59.446 DEBUG ScriptExecutor - Result: 1; 11:09:59.447 INFO DetermineGermlineContigPloidy - Shutting down engine; [April 28, 2020 11:09:59 AM ICT] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=623902720; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/cohort_determine_ploidy_and_depth.380621677219090732.py --sample_coverage_metadata=/tmp/samples-by-coverage-per-contig8606344533091962323.tsv --output_calls_path=/home/nguyen/Exec/gatk-4.1.6.0/ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.000000e-02 --adamax_beta1=9.000000e-01 --adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.0000",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6573:1345,down,down,1345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6573,1,['down'],['down']
Availability," ```; 1	12919623	.	C	T	.	.	DP=741;ECNT=4;POP_AF=1.000e-03;P_GERMLINE=-2.169e-04;TLOD=743.86; 	GT:AD:AF:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:PGT:PID:SA_MAP_AF:SA_POST_PROB	0/1:520,210:0.291:0,0:520,210:36:153,132:57:47:0; |1:12919623_C_T:0.232,0.283,0.288:0.835,2.995e-04,0.165; ```; Also called in a different variant caller:; ```; 1	12919623	.	CC	TG	6989.54	.	AB=0.308968;ABP=423.639;AC=1;AF=0.5;AN=2;AO=410;CIGAR=2X;DP=1327;DPB=1327;DPRA=0;EPP=55.973;EPPR=139.678;GTI=0;LEN=2;MEANALT=8;MQM=50.4732;MQMR=56.3933;NS=1;NUMALT=1;ODDS=1609.4;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=13156;QR=30163;RO=900;RPL=282;RPP=128.617;RPPR=256.291;RPR=128;RUN=1;SAF=177;SAP=19.6194;SAR=233;SRF=377;SRP=54.4404;SRR=523;TYPE=mnp;technology.ILLUMINA=1	GT:DP:AD:RO:QR:AO:QA:GL	0/1:1327:900,410:900:30163:410:13156:-725.008,0,-2308.15; ```; Yes, M2 also calls the neighboring C>G substitution, these are just being represented differently between the two callers. You can see there is a discrepancy between the counts, 741 in the M2 call and almost double that (1327) in the other call. Looking directly at the aligned reads, I can see 1346 reads overlapping this location. Removing those with MAPQ<20, we are left with about 1302 reads. Again, there are no reads that are smaller than 30bp. Looking at the distribution of start site counts, there is a spike at the beginning of the region, as we would expect. The largest number of counts tied to a start site is 343 in this region. So, there should not be a downsampling effect since the ; `-maxReadsPerAlignmentStart` parameter has been set to 500. I don't think read position is an issue here, though I haven't fully quantified it. I can see this region in IGV and it looks clean. These examples are very easy to find in our data. The calls themselves seem really good, just trying to figure out how to deal with count estimation. Right now our solution is to use multiple variant callers. Thanks for looking at this, please let me know if I can provide anything else.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3808#issuecomment-344740595:2560,down,downsampling,2560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3808#issuecomment-344740595,1,['down'],['downsampling']
Availability," ```; private static JavaSparkContext createTestSparkContext(Map<String, String> overridingProperties) {; determineSparkMaster();; final SparkConf sparkConf = setupSparkConf(""TestContext"", DEFAULT_SPARK_MASTER, DEFAULT_TEST_PROPERTIES, overridingProperties);; return new JavaSparkContext(sparkConf);; }. /**; * Determine the number of cores Spark master should use. Only used in Spark Test; * Read the specification from the environmental variable GATK_TEST_SPARK_CORES; * If the value is a valid positive integer, use it; * If the value is bogus (strings, etc), or the env. var. is not set, use all available cores, as in ""local[*]""; */. private static void determineSparkMaster() {; int foo = 0;; try {; foo = Integer.parseInt( System.getenv(""GATK_TEST_SPARK_CORES"") );; } catch ( NumberFormatException e ) {}; String numSparkCores;; if ( foo > 0 ) {; numSparkCores = String.format(""[%d]"", foo);; } else {; numSparkCores = ""[*]"";; }; DEFAULT_SPARK_MASTER = ""local"" + numSparkCores;; }. ```. Error messages:. ```; java.lang.NullPointerException at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:77); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:74); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:65); at org.broadinstitute.hellbender.utils.test.testers.SamFileTester.runTest(SamFileTester.java:263); at org.broadinstitute.hellbender.utils.test.testers.AbstractMarkDuplicatesComman",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1768:1320,Error,Error,1320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1768,1,['Error'],['Error']
Availability," `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and link by `EVENT`; - [ ] we are making a choice that treats duplication expansion as insertion. If decide to treat `DUP` as a separate 1st class type, we need to ; - [ ] shift the left breakpoint to the right by 1 base compared to the current implementation, and ; - [ ] `downstreamBreakpointRefPos = complication.getDupSeqRepeatUnitRefSpan().getEnd();`. ----------; ## CPX variant re-interpretation. Send cpx variant for re-interpretation of simple basic types, and check for consistency (this might be the difficult part)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:3231,down,downstreamBreakpointRefPos,3231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021,2,['down'],['downstreamBreakpointRefPos']
Availability," a dangling head which often causes problem and in this case causes the variant to sometimes not be correctly assembled. This is where the dangling head gets separated from garbage in the 20 threshold graph: ![Screen Shot 2022-01-25 at 4 13 52 PM](https://user-images.githubusercontent.com/16102845/151060728-5a0d4d95-2eb4-4777-a0e9-34b07b2e6196.png). And here is that spot in the 60 threshold graph:; ![Screen Shot 2022-01-25 at 4 16 43 PM](https://user-images.githubusercontent.com/16102845/151061165-fb803312-59b8-48c4-b196-b0e97d2e00ea.png). And here it is in the 1 threshold ; <img width=""303"" alt=""Screen Shot 2022-01-25 at 4 22 17 PM"" src=""https://user-images.githubusercontent.com/16102845/151061909-25d41a3d-39c2-461e-8fd3-938e859ef3d7.png"">; graph:. This seems to have caused the two thresholds to assemble different haplotypes after dangling end recovery (since all of these are dangling ends because the assembly engine can't do anything else because there is not enough padding provided) and it just so happens this failed assembly misses the correct haplotype in that 20 threshold graph and we end up throwing away most of the reads as incongruent with assembly as a result which is why the depth drops out so low at that site. This is a pretty rare edge case and I happened to be able to recover the 20 mq threshold variant with reasonable correct coverage by playing with the `--min-pruning 4` argument. In general though this issue might or might not have existed if the bam snippet provided (and especially the calling interval you provided of chr7:145945238-145945238) were not centered on one single point since assembly works best and is most likely to succeed when it has a few hundred bases of padding around the variant in question (typically for a SNP we end up with at least 100 bases of active window plus another 300 bases of padding on either side for assembly) which cuts down on the risk of assembly failures like this one. I'm curious if you observed this behavior on ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7124#issuecomment-1021629139:1118,recover,recovery,1118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7124#issuecomment-1021629139,1,['recover'],['recovery']
Availability," already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCF. ### Affected version(s); 4.1.7; 4.1.8; 4.1.9. ### Description ; Starting with GATK4.1.7, the AF annotation in the changed from '0' to '.'. This change is cause downstream issues with our processing pipeline. #### Steps to reproduce; CMD using 4.1.6:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.6.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.6.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,0:68:12,15,0:21,18,0:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. CMD using 4.1.7:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.7.HC.vcf.gz. Looking at one of t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6938:1392,down,downstream,1392,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6938,1,['down'],['downstream']
Availability," also removes by debugging code and comments. I think it is ready for a review. To some other questions you had above:. 1) The HashMap<FeatureInput<VariantContext>, HashMap<String, Collection<VariantContext>>> can be wrapped in a class with just a couple of methods, so we don't have to manifest that long type all over the place. I realize that's non-optimal, but this isnt anything I introduced here. I would really like to keep this PR as limited as we can, and address some larger refactoring in a different PR, once we've migrated to MultiVariantWalkerGroupedOnStart. 2) I know this PR still in an interim state, but passing the VariantWalker in as an argument to the comp methods doesn't seem like a step forward to me. If we can't solve that problem completely in this PR (which is fine, I'm all for trying to contain this), are those changes necessary ? Perhaps that part should just wait for the next round. As noted above, I'd like to propose this as iterative, with a second PR coming soon. I did this b/c it moved us toward not needing to pass around the walker. It minimizes the code that has access to the walker (as opposed to setting it after creating the instance of the Evaluator, etc. Yes, it exposes it for two methods, but those classes no longer hang on to it. I would like to ultimately remove this entirely. 3) To re-iterate testEvalTrackWithoutGenotypesWithSampleFields: the input file, noGenotypes.vcf, has a header dictionary with the full set of contigs, and a single variant from chr 1. Prior to this PR, the test executed and supplied b37_reference_20_21 as the reference FASTA. The variant in that VCF is from chr 1, not 20/21. The old code should have failed. It didnt, probably since it was preferentially taking the sequence dictionary from the VCF header and basically ignoring the FASTA. It didnt make much practical difference, but I believe my change here is right. I added the test case testEvalTrackWithoutGenotypesWithSampleFieldsWrongRef to cover that error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747619130:2507,error,error,2507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747619130,1,['error'],['error']
Availability," and reading the right arrays. For example, if you wish to read (""chr2"", [ 50, 50M] ), then only the second array is queried.; - In the previous version of the tool, the array name was a constant - _genomicsdb_array_. The new version will be backward compatible with respect to reads. Hence, if a directory named _genomicsdb_array_ is found in the workspace directory, it's passed as the array for the _GenomicsDBFeatureReader_ otherwise the array names are generated from the directory entry names.; - Parallel import based on chromosome intervals. The number of threads to use can be specified as an integer argument to the [executeImport call](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBImport.java#L535). If no argument is specified, the number of threads is determined by Java's ForkJoinPool (typically equal to the \#cores in the system). ; - The max number of intervals to import in parallel can be controlled by the command line argument --max-num-intervals-to-import-in-parallel (default 1); - Note that increasing parallelism increases the number of FeatureReaders opened to feed data to the importer. So, if you are using _N_ threads and your batch size is _B_, you will have _N*B_ feature readers open.; - Protobuf based API for import and read; - [Import](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBImport.java#L522); - [Read](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/engine/FeatureDataSource.java#L405); - #3688 ; - Option to produce GT field; - [Option to produce GT for spanning deletion based on min PL value](https://github.com/Intel-HLS/GenomicsDB/issues/161); - https://github.com/broadinstitute/gatk/issues/2687; - Doesn't support #4541 or #3689 yet - next version; - Bug fixes; - #4716 ; - More error messages",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645:2650,error,error,2650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645,1,['error'],['error']
Availability, are irrelevant. If we further exclude:. * lines saying that a class was imported that follow a complaint about the class; * lines with only a timestamp and a `^` symbol. we obtain the following:. ```; 2022-08-16T00:09:07.2545204Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2547467Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:4: error: package com.google.common.base does not exist; 2022-08-16T00:09:07.2647018Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2671678Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2726493Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2743559Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2775681Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2833952Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2841948Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2856913Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2860245Z src/main/java/org/broadinstitute,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:1155,error,error,1155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability," as a prior on whether a site is homozygous, rather than hard filtering on these sites (and pulling down corresponding counts from the tumor---this strategy was held over from GetHetCoverage/AllelicCapSeg). The main reason is that the normal will typically be sequenced at lower coverage (~30x), so this strategy will cause us to miss obvious hets in the tumor (~80x). This is now relevant for two reasons: 1) it seems that we will want to run the filter with more stringent parameters, as higher base error rates are causing homs to leak past the filter, which in turn affects the fit of the allele-fraction model (which only attempts to model hets) by biasing normal segments towards unbalanced, and 2) we now want to run ModelSegments separately on the normal to allow for the filtering of germline events. So we want to be more stringent with low-coverage normals without affecting our high-coverage tumors. For example, here's some hg38 NovaSeq FFPE WGS data from a ~40x normal:. ![download](https://user-images.githubusercontent.com/11076296/43977946-9bd0a1bc-9cb3-11e8-9d7f-016a99c1c173.png). Compare to an hg19 TCGA WGS ~40x normal:. ![download 1](https://user-images.githubusercontent.com/11076296/43978051-f8820770-9cb3-11e8-8e16-13b51792614f.png). The hom-ref tail in the first plot is much fatter and clearly leaks into the het cloud. Also curious is that the het cloud is far less binomial (or even beta-binomial---note also the absence of the tail extending to the origin). I am still not sure why the incoming data looks different. There are several confounding factors: NovaSeq vs. HiSeq, hg38 vs. hg19, AF > 2% gnomAD sites vs. AF > 10% 1000G sites, FFPE vs. frozen, etc. I have not seen enough examples/combinations to be able to say which are the most important factors. Changing the genotyping/filtering strategy can get around this change in the data without a corresponding change in the allele-fraction model for now, but getting the data to look as good as possible upstream wo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3915#issuecomment-412189218:1122,down,download,1122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3915#issuecomment-412189218,2,['down'],['download']
Availability," at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:530); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [828b3d22-2109-4128-b4af-427a9d410db0] entered state [ERROR] while waiting for [DONE].; ```. Likely because of . ```; ""--conf"", ""spark.yarn.dist.files="" + script + ""/build/libIntelDeflater.so"",; ```. in gatk-launch. This likely needs special handling for dataproc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:9643,ERROR,ERROR,9643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,2,['ERROR'],['ERROR']
Availability," at the coverage mode (~ 100 fragments/bin), and a mode that bifurcates to lower values. **I conjecture that the bimodality results from heterogeneity of mappability scores at different positions in the same bin. The bins are 1k wide and it is feasible that some positions are highly mappable and other positions are not. This conjecture can be tested by collecting coverage on smaller bins and to check whether the bimodality weakens. If it does, I suggest filtering based on read position, similar to Genome STRiP, as opposed to filtering bins.**. Also, there is little sample-to-sample variation in coverage-mappability scatter plots (as opposed to, let's say, GC). **Therefore, there is no reason to consider mappability as a bias covariate**. The mappability coverage bias can be captured by a cohort-wide mean bias. Finally, let us study the NB overdispersion of different samples for different contigs:; ![image](https://user-images.githubusercontent.com/15305869/37785938-c47b4e38-2dd1-11e8-85f5-6e82764afbde.png). There's a clear structure here: some samples have higher overdispersion than the others. This could be due to degraded samples, less even GC curve, different chemistry, etc. In any event, we can regress the residual variance $psi_sj$ (for sample s, contig j) with a linear model:. psi_sj ~ N(a_s * psi_j + b_s, \beta). Here's how the regression looks like:; ![image](https://user-images.githubusercontent.com/15305869/37786020-fec1fccc-2dd1-11e8-9751-92e38979f120.png). Pretty much everything is explained by the linear model. This provides support for our choice of linear-NB model in gCNV. Finally, let us examine whether there is a correlation between $a_s$, $b_s$, and depth of coverage:. ![image](https://user-images.githubusercontent.com/15305869/37786095-26b08384-2dd2-11e8-9aed-8adff8995ac5.png); ![image](https://user-images.githubusercontent.com/15305869/37786101-2a6d4be2-2dd2-11e8-85c5-5c6754d42d52.png). There is absolutely no correlation, which is again expected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558:4033,degraded,degraded,4033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558,1,['degraded'],['degraded']
Availability," but I'm also attaching the full error output.; [pathseq_TCGA.slurm.1619078_1.err.txt](https://github.com/broadinstitute/gatk/files/1965063/pathseq_TCGA.slurm.1619078_1.err.txt). Thanks so much for any help you can provide!. `; 18/05/01 14:20:59 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.12.137.46, 39719, None),broadcast_1_piece0,StorageLevel(memory, 1 replicas),127561,0)); 18/05/01 14:21:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/05/01 14:23:29 INFO MemoryStore: MemoryStore cleared; 18/05/01 14:23:29 INFO BlockManager: BlockManager stopped; 18/05/01 14:23:29 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/05/01 14:24:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/05/01 14:25:36 INFO SparkContext: Successfully stopped SparkContext; 14:25:37.027 INFO PathSeqPipelineSpark - Shutting down engine; [May 1, 2018 2:25:37 PM EDT] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 37.98 minutes.; Runtime.totalMemory()=23999283200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: Lost task 20.0 in stage 1.0 (TID 891, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 131031 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(Array",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:1709,down,down,1709,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['down'],['down']
Availability," causing the bug in #3894.; This PR removes that problematic de-overlapping step (done first the 1-liner commit, i.e. the 2nd commit, which doesn't use the de-overlapped alignments, then once the generated variants are reviewed to be OK, I removed the de-overlapping step in the 3rd commit).; The in the 4th commit, I experimented with removing, again only in the experimental code path, the alignment filter based on its alignment length. I personally think that is a better treatment, but don't have a strong opinion on it. So for the experimental code path, if we accept the first 3 commits, no de-overlapping is done on the alignments, just like the stable code path. The stable and the experimental version would only differ on which contigs are sent for this analysis, i.e. they differ in the preprocessing step. To be more specific, ; * the stable version calls into `ChimericAlignment.parseOneContig()` for turning all assembly contigs, no matter how many alignments it has, gets a list of chimeric pairs, and sends them down for breakpoint inference; * in the experimental tool, `ChimericAlignment.extractSimpleChimera()` takes **only** contigs with exactly **two** good alignments and turn it into a **single** pair, then send the pair down for inference. Regarding `ChimericAlignment.parseOneContig()`, it is good for extracting novel adjacencies and outputting BND records for contigs with multiple (more than two) alignments, but it doesn't report the bigger picture (the new class `CpxVariantDetector` is trying to do that job, and it seems to be doing a good job based on manual review, I am not sure if there are tools available for evaluating such complex rearrangements).; So down the road, `ChimericAlignment.parseOneContig()` will probably be turned into other use; * turning the CPX variants we emit into BND's if so requested, and/or ; * dumpster diving on those contigs that we believe havn't assembled across the whole event&mdash;hence cannot tell the full story in a CPX var",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769:1626,down,down,1626,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769,1,['down'],['down']
Availability, chrM:14245-14544 isActive: false numReads: 0; 12:13:56.973 DEBUG Mutect2 - Processing assembly region at chrM:14545-14844 isActive: false numReads: 0; 12:13:56.984 DEBUG Mutect2 - Processing assembly region at chrM:14845-15144 isActive: false numReads: 0; 12:13:56.995 DEBUG Mutect2 - Processing assembly region at chrM:15145-15444 isActive: false numReads: 0; 12:13:57.009 DEBUG Mutect2 - Processing assembly region at chrM:15445-15744 isActive: false numReads: 0; 12:13:57.027 INFO ProgressMeter - chrM:15445 38.3 60 1.6; 12:13:57.035 DEBUG Mutect2 - Processing assembly region at chrM:15745-15960 isActive: false numReads: 14; 12:13:57.047 DEBUG Mutect2 - Processing assembly region at chrM:15961-16230 isActive: true numReads: 30; 12:13:57.055 DEBUG ReadThreadingGraph - Recovered 1 of 1 dangling tails; 12:13:57.063 DEBUG ReadThreadingGraph - Recovered 0 of 1 dangling heads; 12:13:57.096 DEBUG ReadThreadingGraph - Recovered 3 of 3 dangling tails; 12:13:57.106 DEBUG ReadThreadingGraph - Recovered 3 of 5 dangling heads; 12:13:57.464 DEBUG Mutect2Engine - Active Region chrM:15961-16230; 12:13:57.469 DEBUG Mutect2Engine - Extended Act Region chrM:15861-16299; 12:13:57.472 DEBUG Mutect2Engine - Ref haplotype coords chrM:15861-16299; 12:13:57.476 DEBUG Mutect2Engine - Haplotype count 111; 12:13:57.479 DEBUG Mutect2Engine - Kmer sizes count 0; 12:13:57.482 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:58.821 DEBUG Mutect2 - Processing assembly region at chrM:16231-16299 isActive: false numReads: 15; 12:13:58.938 INFO Mutect2 - 0 read(s) filtered by: MappingQualityReadFilter ; 0 read(s) filtered by: MappingQualityNotZeroReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter ; 0 read(s) filtered by: NonChimericOriginalAlignmentReadFilter ; 0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter ; 0 read(s) filtered by: GoodCigarReadFilter ; 0 read(s) filte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:22420,Recover,Recovered,22420,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability," class Range; 2022-08-16T00:09:07.3894678Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3897711Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3902203Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3902980Z symbol: class RangeMap; 2022-08-16T00:09:07.3903340Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3903864Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3904505Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3905250Z symbol: class Range; 2022-08-16T00:09:07.3905751Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3906273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T00:09:07.3906908Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T00:09:07.3907793Z symbol: class Range; 2022-08-16T00:09:07.3908125Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3910592Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3914013Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3921838Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3936070Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 20",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:6950,error,error,6950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability," class Range; 2022-08-16T22:45:53.7743866Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7747579Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7748444Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7776218Z symbol: class RangeMap; 2022-08-16T22:45:53.7776715Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7777389Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7778220Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7779110Z symbol: class Range; 2022-08-16T22:45:53.7779574Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7780209Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T22:45:53.7780965Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T22:45:53.7781896Z symbol: class Range; 2022-08-16T22:45:53.7782232Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7785096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7789228Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7798240Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7810436Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 20",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:8988,error,error,8988,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability," class(es); MarkDuplicatesSpark . ### Affected version(s); - Latest public release version [4.4.0.0]. ### Description . I am working on 40X human WGS data, running MarkDuplicatesSpark on the computation node of a cluster with 40 cores and 192GB RAM. MarkDuplicatesSpark usually hangs and never finish (even after few days) with log as below:. ```; 11:26:29.511 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.511 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:29.512 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.512 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, igno",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:1089,failure,failures,1089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['failure'],['failures']
Availability," confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 17:08:13.200 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 17:08:13.206 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 17:08:13.227 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 17:08:13.228 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 17:08:13.260 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 17:08:13.260 INFO IntelPairHmm - Available threads: 1; 17:08:13.260 INFO IntelPairHmm - Requested threads: 4; 17:08:13.261 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 17:08:13.261 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 17:08:13.346 INFO ProgressMeter - Starting traversal; 17:08:13.346 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 17:08:17.401 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes. 17:08:43.866 INFO ProgressMeter - chr1:1053465 0.5 3780 7431.7. ...Many lines in between and then... 19:11:09.189 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.190328316; 19:11:09.189 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 398.5135636; 19:11:09.190 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 258.73 sec; 19:11:09.190 INFO HaplotypeCaller - Shutting down engine; [August 27, 2020 7:1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783:3490,Avail,Available,3490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783,1,['Avail'],['Available']
Availability, depth metadata...; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chrM). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270706v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270707v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270708v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:1406,reliab,reliable,1406,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability, does not exist; 2022-08-16T22:45:53.6965286Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6965863Z * Returns the STR period at a given position.??; 2022-08-16T22:45:53.6972650Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6973221Z * Returns the STR period at a given position.??; 2022-08-16T22:45:53.6981573Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7254348Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7492903Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7498018Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7502319Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7512488Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7514136Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7515610Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7517156Z src/main/java/org/bro,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:5630,error,error,5630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability," dropbox link: https://www.dropbox.com/sh/xae79hanumpireu/AABKo1l4Y-z5G5YLBqSpylRva?dl=0. Then the following code will reproduce the issue:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0.zip; unzip gatk-4.1.2.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chr1\t97329945\t.\tT\tA\t.\t.\t.""; \; echo -e ""chr1\t97329967\t.\tC\tT\t.\t.\t."") | bgzip > input.vcf.gz && \; tabix -f input.vcf.gz. for score in 11 12; do; gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.$score.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz \; -L chr1:97329945-97329967 \; --min-base-quality-score $score && \; bcftools query \; -f ""[%CHROM\t%POS\t%REF\t%ALT\t%GT\t%AD\n]"" \; output.$score.vcf.gz \; -r chr1:97329945-97329967; done; ```. When the parameter `--min-base-quality-score 11` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	1/1	0,35; chr1	97329967	C	T	1/1	0,33; ```; When the parameter `--min-base-quality-score 12` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	0/1	9,10; chr1	97329967	C	T	0/1	6,11; ```; The first output is the output that makes sense. When `--min-base-quality-score 12` is used, it is as if HaplotypeCaller invents some reference allele reads and then uses them to genotype th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045:1131,echo,echo,1131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045,1,['echo'],['echo']
Availability," error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7517156Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7642312Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7643965Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7645667Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7690890Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7738985Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7739852Z symbol: class RangeMap; 2022-08-16T22:45:53.7740332Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7740892Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7741707Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7743523Z symbol: class Range; 2022-08-16T22:45:53.7743866Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7747579Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7748444Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7776218Z symbol: class RangeMap; 2022-08-16T22:45:53.7776715Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7777389Z src/main/java/org/broad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:7509,error,error,7509,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability, exist; 2022-08-16T00:09:07.2726493Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2743559Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2775681Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2833952Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2841948Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2856913Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2860245Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2861934Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3012792Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3151812Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3156616Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3263061Z src/main/java/org,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:2039,error,error,2039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability, exist; 2022-08-16T22:45:53.6571861Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6588890Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6621393Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6631099Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6638787Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6653787Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6657039Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6658760Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6739776Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6889124Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6895571Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6965286Z src/main/java/org,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:3692,error,error,3692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability," field DS - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field FS - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field QD - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field SOR - the field will NOT be part of INFO fields in the generated VCF records; 15:02:25.234 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.017439521000000003,Cpu time(s),0.016764516000000004; [February 3, 2020 3:02:25 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=700973056; java.lang.ArrayIndexOutOfBoundsException: 3; at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.generatePL(ReferenceConfidenceVariantContextMerger.java:652); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:543); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:310); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:136); at java.util.stream.ForEa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6357#issuecomment-581619640:7814,down,down,7814,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6357#issuecomment-581619640,2,['down'],['down']
Availability," file that reproduces the issue. First of all, you have to download the mini input.bam file from this dropbox link: https://www.dropbox.com/sh/xae79hanumpireu/AABKo1l4Y-z5G5YLBqSpylRva?dl=0. Then the following code will reproduce the issue:; ```; wget https://github.com/broadinstitute/picard/releases/download/2.19.0/picard.jar. wget https://github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0.zip; unzip gatk-4.1.2.0.zip. wget -O- ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chr1\t97329945\t.\tT\tA\t.\t.\t.""; \; echo -e ""chr1\t97329967\t.\tC\tT\t.\t.\t."") | bgzip > input.vcf.gz && \; tabix -f input.vcf.gz. for score in 11 12; do; gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.$score.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz \; -L chr1:97329945-97329967 \; --min-base-quality-score $score && \; bcftools query \; -f ""[%CHROM\t%POS\t%REF\t%ALT\t%GT\t%AD\n]"" \; output.$score.vcf.gz \; -r chr1:97329945-97329967; done; ```. When the parameter `--min-base-quality-score 11` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	1/1	0,35; chr1	97329967	C	T	1/1	0,33; ```; When the parameter `--min-base-quality-score 12` is used, the GT/AD output is this:; ```; chr1	97329945	T	A	0/1	9,10; chr1	97329967	C	T	0/1	6,11; ```; The first output is the output that makes sense. When `--min-base-quality-score 12` is us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045:977,echo,echo,977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045,3,['echo'],['echo']
Availability," following reasons:; - Gradle detected a problem with the following location: '/home/jeremie/GATK/build/classes/java/main'. Reason: Task ':gatkDoc' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/home/jeremie/GATK/build/resources/main'. Reason: Task ':gatkDoc' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/jeremie/GATK/build/tmp/gatkDoc/javadoc.options'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.gradle.org/7.3.2/userguide/command_line_interface.html#sec:command_line_warnings. Execution optimizations have been disabled for 1 invalid unit(s) of work during this build to ensure correctness.; Please consult deprecation warnings for more details. BUILD FAILED in 33s; 5 actionable tasks: 5 executed; ```; which doe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1202544500:1156,FAILURE,FAILURE,1156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1202544500,1,['FAILURE'],['FAILURE']
Availability, for this subset of the data. Error is; ```; Stdout: 22:01:54.365 INFO segment_gcnv_calls - Loading ploidy calls...; 22:01:54.366 INFO gcnvkernel.io.io_metadata - Loading germline contig ploidy and global read depth metadata...; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chrM). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270706v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270707v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270708v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:1197,reliab,reliable,1197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability," found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records ; ; 14:17:39.941 info NativeGenomicsDB - pid=12231 tid=12232 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records ; ; 14:17:41.513 INFO FeatureManager - Using codec IntervalListCodec to read file file:///shared/projects/gentaumix/Ressources/interval\_genomicsdbi/temp\_6/interval.interval\_list ; ; 14:17:41.628 INFO IntervalArgumentCollection - Processing 62000000 bp from intervals ; ; 14:17:41.743 INFO GenotypeGVCFs - Done initializing engine ; ; 14:17:41.897 INFO ProgressMeter - Starting traversal ; ; 14:17:41.898 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute ; ; 14:17:52.020 INFO ProgressMeter - chr2:60009645 0.2 9000 53349.1 ; ; 14:18:02.071 INFO ProgressMeter - chr2:60039632 0.3 37000 110048.1 ; ; 14:18:02.683 INFO GenotypeGVCFs - Shutting down engine ; ; GENOMICSDB\_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),5.257768857000008,Cpu time(s),5.221303873999989 ; ; \[10 septembre 2021 14:18:02 CEST\] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.46 minutes. ; ; Runtime.totalMemory()=7034372096 ; ; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 ; ; at java.util.ArrayList.rangeCheck(ArrayList.java:659) ; ; at java.util.ArrayList.get(ArrayList.java:435) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.combineAttributeMap(StrandBiasUtils.java:120) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS\_StrandBiasTest.combineRawData(AS\_StrandBiasTest.java:118) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:234) ; ; at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMer",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7465:6820,down,down,6820,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7465,1,['down'],['down']
Availability," from this workspace (https://app.terra.bio/#workspaces/help-gatk/Germline-CNVs-GATK4), and the workflow is keep failing at the ""CollectCounts"" step with the following error; in multiple shards. --------------------------------------------------------------------------------------------------------------------; A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; --------------------------------------------------------------------------------------------------------------------. This was weird since I set a correct index file as an input, but after some investigation, I realized that ; the error seemed to be occurring when the bucket path where BAM index was located was different from that of BAM file ; For example, if you look at this log below, . `Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam to /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!; 2021/09/29 15:46:14 Localizing input drs://dg.4DFC:ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1 -> /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Requester Pays project ID is Some(vanallen-firecloud-nih); Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai to /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487:1025,down,download,1025,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487,1,['down'],['download']
Availability," gs://mb-myoseq-germline-cnv/contig_annots.tsv --sexGenotypeTable gs://mb-myoseq-germline-cnv/test_sex_genotypes.tsv --copyNumberTransitionPriorTable /home/mehrtash/homo_sapiens_germline_HMM_priors.tsv --jobType LEARN_AND_CALL --targets /home/mehrtash/whole_exome_agilent_1.1_refseq_plus_3_boosters.Homo_sapiens_assembly19.targets.tsv --copyRatioUpdate true --gammaUpdate true --logLikelihoodTolThresholdCopyRatioCalling 1e-3 --logLikelihoodTol 1e-7 --gammaSolverNumBisections 15 --gammaSolverRefinementDepth 5 --psiSolverNumBisections 15 --psiSolverRefinementDepth 5 --numLatents 10 --maximumEMIterations 40 --numTargetSpacePartitions 200 --rddCheckpointingInterval 8 --rddCheckpointingPath hdfs://mb-myoseq-germline-cnv-m:8020/users/mehrtash/tmp/test_pon_true,true,10_creation --verbosity INFO --apiKey AIzaSyDu_-7aNIHQvs6Pkh4SW_dqW4DOeu8OTkA --sparkMaster yarn; ```. and this is the error:. ```; usage: gcloud dataproc jobs submit spark --cluster=CLUSTER [optional flags] [-- JOB_ARGS ...]; ERROR: (gcloud.dataproc.jobs.submit.spark) unrecognized arguments:; -DGATK_STACKTRACE_ON_USER_EXCEPTION=true; ,spark.executor.extraJavaOptions=-Dsamjdk.compression_level=1; -DGATK_STACKTRACE_ON_USER_EXCEPTION=true ,spark.executor.instances=40,spark.executor.memory=8G,spark.driver.memory=20G,spark.executor.extraJavaOptions=-Dorg.bytedeco.javacpp.maxbytes=10gb; -Dorg.bytedeco.javacpp.maxphysicalbytes=20gb; -Ddtype=double; -Dorg.bytedeco.javacpp.maxretries=100; -XX:+UseParNewGC; -XX:ParallelGCThreads=2; -XX:+UseConcMarkSweepGC; -XX:+CMSParallelRemarkEnabled; -XX:ConcGCThreads=2; -XX:CMSInitiatingOccupancyFraction=65,spark.driver.extraJavaOptions=-Dorg.bytedeco.javacpp.maxbytes=10gb; -Dorg.bytedeco.javacpp.maxphysicalbytes=20gb; -Ddtype=double; -Dorg.bytedeco.javacpp.maxretries=100; -XX:+UseParNewGC; -XX:ParallelGCThreads=2; -XX:+UseConcMarkSweepGC; -XX:+CMSParallelRemarkEnabled; -XX:ConcGCThreads=2; -XX:CMSInitiatingOccupancyFraction=65,spark.yarn.executor.memoryOverhead=12000,spark.yarn.driver",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2230#issuecomment-278726095:2823,ERROR,ERROR,2823,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2230#issuecomment-278726095,1,['ERROR'],['ERROR']
Availability," htsjdk.samtools.BAMFileWriter.writeAlignment(BAMFileWriter.java:134); ... 12 more; Caused by: java.io.IOException: Stale file handle; at java.base/sun.nio.ch.FileDispatcherImpl.write0(Native Method); at java.base/sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:62); at java.base/sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:115); at java.base/sun.nio.ch.IOUtil.write(IOUtil.java:80); at java.base/sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:280); at java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74); at java.base/java.nio.channels.Channels.writeFully(Channels.java:97); at java.base/java.nio.channels.Channels.access$000(Channels.java:62); at java.base/java.nio.channels.Channels$1.write(Channels.java:172); at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81); at java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:127); at htsjdk.samtools.util.BinaryCodec.writeBytes(BinaryCodec.java:220). Error type2:. gatk --java-options ""-Xmx32G -XX:ParallelGCThreads=8 -Djava.io.tmpdir=/group/zhougrp2/dguan/tmp"" SplitNCigarReads --spark-runner LOCAL -I 10_mkdup/SAMN05828173_mkdup.bam -R /group/zhougrp2/dguan/00_ref/Gallus_gallus.GRCg6a.dna.toplevel.fa -L /group/zhougrp2/dguan/00_ref/chicken_chr.list -O 11_cigar/SAMN05828173_cigar.bam --create-output-bam-index true --max-reads-in-memory 5000. 00:01:27.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/dguan/anaconda3/envs/Chicken_GTEx/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 21, 2021 12:01:27 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 00:01:27.275 INFO SplitNCigarReads - ------------------------------------------------------------; 00:01:27.276 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.9.0; 00:01:27.276 INFO Sp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7091:61843,Error,Error,61843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7091,1,['Error'],['Error']
Availability," id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:38 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removal of executor 2 requested; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 2; 17/10/11 14:19:38 INFO cluster.YarnScheduler: Cancelling stage 1; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) failed in 10.702 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:28431,ERROR,ERROR,28431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['ERROR'],['ERROR']
Availability," if true, annotate the M2 VCFs using oncotator (to produce a TCGA MAF); ##; ## ** Primary inputs **; ## ref_fasta, ref_fasta_index, ref_dict: reference genome, index, and dictionary; ## tumor_bam, tumor_bam_index, and tumor_sample_name: BAM, index and sample name for the tumor sample (sample name used for output naming); ## normal_bam, normal_bam_index, and normal_sample_name: BAM, index and sample name for the normal sample (optional if running tumor-only); ##; ## ** Primary resources ** (optional but strongly recommended); ## pon, pon_index: optional panel of normals in VCF format containing probable technical artifacts (false positves); ## gnomad, gnomad_index: optional database of known germline variants (see http://gnomad.broadinstitute.org/downloads); ## variants_for_contamination, variants_for_contamination_index: VCF of common variants with allele frequencies fo calculating contamination; ##; ## ** Secondary resources ** (for optional tasks); ## onco_ds_tar_gz, default_config_file: Oncotator datasources and config file; ## sequencing_center, sequence_source: metadata for Oncotator; ##; ## Outputs :; ## - One VCF file and its index with primary filtering applied; secondary filtering and functional annotation if requested.; ##; ## Cromwell version support ; ## - Successfully tested on v27; ##; ## LICENSING : ; ## This script is released under the WDL source code license (BSD-3) (see LICENSE in ; ## https://github.com/broadinstitute/wdl). Note however that the programs it calls may ; ## be subject to different licenses. Users are responsible for checking that they are; ## authorized to run all programs before running this script. Please see the docker ; ## pages at https://hub.docker.com/r/broadinstitute/* for detailed licensing information ; ## pertaining to the included programs. workflow Mutect2 {; # Runtime; String gatk4_jar; File picard_jar; String m2_docker; String oncotator_docker; Int preemptible_attempts; # Workflow options; Int scatter_count; File? in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3341:2253,down,downloads,2253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3341,1,['down'],['downloads']
Availability," in GenotypeGVCFs when using GenomicsDB. ----------. This request was created from a contribution made by Zane Swaydan on June 30, 2022 11:13 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/6972994559643-java-lang-IllegalStateException-in-GenotypeGVCFs-after-GenomicsDBImport-GATK-4-2-6-1](https://gatk.broadinstitute.org/hc/en-us/community/posts/6972994559643-java-lang-IllegalStateException-in-GenotypeGVCFs-after-GenomicsDBImport-GATK-4-2-6-1). \--. I'm using the GenotypeGVCFs function based on GenomicsDBImport database. I've divided the reference into 50 intervals. Some intervals seems ok, but some reports error as following. I used a VCF file in ""--force-output-intervals"" for down stream analysis. I've never seen this error without ""--force-output-intervals"". I've searched for the error message and changed my GATK version to 4.2.6.1 since similar error has been solved as a bug in recent update, but it still not works on my dataset... REQUIRED for all errors and issues: ; ; a) GATK version used:. GenomicsDBImport: GATK 4.2.4.0. GenotypeGVCFs: GATK 4.2.6.1. b) Exact command used:. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xms4G -Xmx16G -XX:+UseParallelGC -XX:ParallelGCThreads=2 -jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R PigeonBatch5/000\_DataLinks/000\_RefSeq/Cliv2.1\_genomic.fasta --intervals 006\_IntervalsSplit\_DBImport\_VCFref/interval\_9.list --force-output-intervals PigeonBatch4/008\_RawVcfGz/MergeVcf/pigeonBatch1234\_filtered.vcf.gz -V gendb://007\_Database\_DBImport\_VCFref/database\_interval\_9 -O 008\_RawVcfGz\_DBImport\_VCFref/001\_DividedIntervals/interval\_9.vcf.gz --tmp-dir TMPDIR --allow-old-rms-mapping-quality-annotation-data --only-output-calls-starting-in-intervals --verbosity ERROR.  ; ; c) Entire program log:. Using GATK jar MySoftwares/gatk-4.2.6.1/gatk-package-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7966:1061,error,errors,1061,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7966,1,['error'],['errors']
Availability," in Travis CI. These usually manifest as a simple ""exited with code 137"" (ie., killed by signal 9) error, but sometimes we get an explicit segfault or out-of-memory error. Examples:. ```; [31mFAILURE: [39m[31mBuild failed with an exception.[39m; * What went wrong:; Execution failed for task ':test'.; [33m> [39mProcess 'Gradle Test Executor 1' finished with non-zero exit value 137; ```. ```; :test[M::bwa_idx_load_from_disk] read 0 ALT contigs; OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000715180000, 719847424, 0) failed; error='Cannot allocate memory' (errno=12). #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 719847424 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid11513.log; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f27ebfe7d9a, pid=11455, tid=0x00007f27e87e5700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libfml.6198146539708364717.jnilib+0xed9a] rld_itr_init+0x4a; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fd2680a350c, pid=11685, tid=0x00007fd2b02bf700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libbwa.5694772191018335324.jnilib+0x850c] bwa_mem2idx+0xcc; ```. The underlying issue in these cases is likely either ""out of memory"" or, perhaps in the case of the seg faults, ""file not found"" or ""malformed file"", but we could greatly improve our ability to interpret Travis failures if we ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3209:1011,error,error,1011,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209,1,['error'],['error']
Availability, inconsistency: seq_len is not the same. Abort!; ... 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':test'.; 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:98); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:68); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:62); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:1227,ERROR,ERROR,1227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability," initialized @4976ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: Started @5092ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:12 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/15 19:43:13 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m/10.240.0.18:8032; 17/11/15 19:43:17 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1510774921124_0001; 17/11/15 19:43:28 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 17/11/15 19:43:35 ERROR org.apache.spark.scheduler.TaskResultGetter: Exception while getting task result; com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySeria",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:4669,Error,Error,4669,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['Error'],['Error']
Availability," intervals that had >1000x coverage.; 16:59:33.036 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 8773016 mapped template names.; 17:00:07.058 INFO StructuralVariationDiscoveryPipelineSpark - Ignoring 19200460 genomically common kmers.; 17:05:25.896 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 34752266 kmers.; 17:10:46.253 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 31945322 unique template names for assembly.; 17:45:06.748 INFO StructuralVariationDiscoveryPipelineSpark - Wrote SAM file of aligned contigs.; 17:45:26.199 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 5716 variants.; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - INV: 231; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 3262; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1065; 17:45:26.210 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1158; 17:45:26.397 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 8, 2017 5:45:26 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 48.71 minutes.; Runtime.totalMemory()=17815830528; ```. This branch with `minCoherentEvidence` set to 7 (and `minEvidenceCount` remaining at 15):. ```; 18:55:30.222 INFO StructuralVariationDiscoveryPipelineSpark - Metadata retrieved.; 18:56:15.451 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 30678 intervals.; 18:56:15.547 INFO StructuralVariationDiscoveryPipelineSpark - Killed 387 intervals that were near reference gaps.; 18:56:45.252 INFO StructuralVariationDiscoveryPipelineSpark - Killed 174 intervals that had >1000x coverage.; 18:57:27.031 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9424481 mapped template names.; 18:58:07.742 INFO StructuralVariationDiscoveryPipelineSpark - Ignoring 19200460 genomically common kmers.; 19:03:21.960 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 3930956",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2684:1892,down,down,1892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2684,1,['down'],['down']
Availability," intervals that had >1000x coverage.; 18:57:27.031 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9424481 mapped template names.; 18:58:07.742 INFO StructuralVariationDiscoveryPipelineSpark - Ignoring 19200460 genomically common kmers.; 19:03:21.960 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 39309565 kmers.; 19:08:31.990 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 34034345 unique template names for assembly.; 19:40:40.149 INFO StructuralVariationDiscoveryPipelineSpark - Wrote SAM file of aligned contigs.; 19:41:00.570 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 6239 variants.; 19:41:00.582 INFO StructuralVariationDiscoveryPipelineSpark - INV: 238; 19:41:00.582 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 3639; 19:41:00.582 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1119; 19:41:00.582 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1243; 19:41:00.767 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 8, 2017 7:41:00 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 46.37 minutes.; ```. This branch with `minCoherentEvidenceCount` set to 4:. ```; 19:48:13.982 INFO StructuralVariationDiscoveryPipelineSpark - Metadata retrieved.; 19:48:57.930 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 52918 intervals.; 19:48:58.053 INFO StructuralVariationDiscoveryPipelineSpark - Killed 417 intervals that were near reference gaps.; 19:49:27.873 INFO StructuralVariationDiscoveryPipelineSpark - Killed 177 intervals that had >1000x coverage.; 19:50:09.183 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 12444440 mapped template names.; 19:50:59.411 INFO StructuralVariationDiscoveryPipelineSpark - Ignoring 19200460 genomically common kmers.; 19:57:19.267 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 62077256 kmers.; 20:03:43.231 INFO StructuralVariationDiscoveryPipelineSpark ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2684:3562,down,down,3562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2684,1,['down'],['down']
Availability," is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 09:38:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.8 MB, free 15.8 GB); 20/08/15 09:38:13 INFO SparkUI: Stopped Spark web UI at http://amarel2.amarel.rutgers.edu:4040; 20/08/15 09:38:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 09:38:13 INFO MemoryStore: MemoryStore cleared; 20/08/15 09:38:13 INFO BlockManager: BlockManager stopped; 20/08/15 09:38:13 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 09:38:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 09:38:13 INFO SparkContext: Successfully stopped SparkContext; 09:38:13.271 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 9:38:13 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=15164506112; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.DefaultClassResolver.writeName(DefaultClassResolver.java:108); at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:99); at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:540); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:76); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575). 20/08/15 09:38:13 INFO ShutdownHookManager: Shutdown h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6750:11574,down,down,11574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750,1,['down'],['down']
Availability," is my command line:; `java -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar ${gatk4_jar} IndexFeatureFile --feature-file ${gvcf} --output ${gvcf}.idx 2>${LOGDIR}/index_candidates.log`. I tried this exact command line with another genome, which worked just fine with output progress report as following for a comparison of the multiple chromosomes processed:; ```; 12:50:38.871 INFO ProgressMeter - Starting traversal; 12:50:38.873 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 12:50:48.876 INFO ProgressMeter - N1:21408210 0.2 5669000 34010598.9; 12:50:58.876 INFO ProgressMeter - N2:13383863 0.3 11960000 35874618.8. ...... 12:55:58.884 INFO ProgressMeter - N19:50063133 5.3 208660000 39122405.2; 12:56:02.409 INFO ProgressMeter - N19:55994806 5.4 210940859 39119265.4; 12:56:02.409 INFO ProgressMeter - Traversal complete. Processed 210940859 total records in 5.4 minutes.; 12:56:02.429 INFO IndexFeatureFile - Successfully wrote index to /storage/ppl/yifang/20190225/data3/samtools_sorted_out/SNPs_candidates.g.vcf.idx; 12:56:02.429 INFO IndexFeatureFile - Shutting down engine; [April 25, 2019 12:56:02 PM CST] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 5.42 minutes.; Runtime.totalMemory()=5618270208; ```; Althought no warning/error messages was issued for the indexing of this big genome, I have tried to debug on 3 things I could think of:. 1. The chromosome and the coordinate are sorted ascendandly, although the chromosome names are not simply numeric continuous because of the A/B subgroup for each chromosome.; 2. The genome size difference, for which no clue was aboserved about the chromosome length limits. ; 3. The chromosome names for this big genome is quite long, but I tried the shorter names as A11 for chr1A_part1, A12 for chr1A_part2, ... B72 for chr7B_part2 (42 chromosomes in total), and the problem stayed exactly the same. Not sure what I may have missed. I appreciate any insight of this problem.; Yifang",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5917:5675,down,down,5675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5917,2,"['down', 'error']","['down', 'error']"
Availability," is necessarily off the table...Maybe something like one of the following could be used just before or during the genotype likelihood calculation:; - something like `filterOverlappingReads` from Mutect2 (https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java#L326); - separate consideration of overlapping reads when calculating genotype likelihoods, as used in UnifiedGenotyper (https://github.com/broadgsa/gatk-protected/blob/aa8764d6c3de146856b174a8674fa787a6311d7c/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/genotyper/DiploidSNPGenotypeLikelihoods.java#L183). As I see it, #4958, which seems to be more related to read likelihood calculation, is where a more involved solution, with more fundamental changes, might be warranted. From my perspective (not being especially familiar with the pairHMM model), an ideal solution would transition the pairHMM from read likelihood to a ""fragment likelihood"" or ""haplotype likelihood"" when information from read pairs is available, even if they aren't overlapping. The idea would be that a modified pairHMM model could produce a single fragment (or haplotype) likelihood for a given read pair. Such an approach would unify the issues of ""merging"" read pairs and phasing in a read-pair aware manner (and potentially also modeling PCR errors). In principle, a ""fragment likelihood""-type approach could even incorporate info from corresponding PCR duplicates to improve the results when sequencing error rates are high. This sort of approach could also flow into the genotype likelihood calculation by providing a single, merged fragment likelihood to consider rather than a separate read likelihood for each read. UPDATE: On further thought, it probably wasn't a good idea for me to use the terms fragment likelihood or haplotype likelihood to distinguish the proposed approach, since the read likelihood is effectively already ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-443558420:1991,avail,available,1991,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-443558420,1,['avail'],['available']
Availability," is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1058,down,downloadInternal,1058,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,2,"['Down', 'down']","['Download', 'downloadInternal']"
Availability," issue. It is always on some small contig (you can see here range is 544, but all cases are small ranges like this one). Everything is the default mutect2 pipeline and params (e.g. [gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta](https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0?prefix=Homo_sapiens_assembly38.fasta&authuser=jkalfon%40broadinstitute.org)) : except the interval file: [gs://ccleparams/region_file_wgs.list](https://console.cloud.google.com/storage/browser/ccleparams?prefix=region_file_wgs.list&authuser=jkalfon%40broadinstitute.org); GATK 4.2.6.1. . Here is the VCF file to annotate `gs://ccleparams/test/CDS-2jucw0.hg38-filtered.vcf.gz`. Here is the stacktrace:. ```; ....; 10:53:39.044 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/2145; 10:53:39.249 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/1069225; 10:53:39.520 INFO Funcotator - Shutting down engine; [July 12, 2022 10:53:39 AM GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 115.46 minutes.; Runtime.totalMemory()=2050490368; java.lang.StringIndexOutOfBoundsException: String index out of range: 544; at java.lang.String.substring(String.java:1963); at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.initializeForInsertion(ProteinChangeInfo.java:293); at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.<init>(ProteinChangeInfo.java:101); at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.create(ProteinChangeInfo.java:399); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:2054); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createCodingRegionFuncotationForProteinCodingFeature(GencodeFuncotationFactory.java:1235); at org.broadinstitute.hellbender.tool",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:1098,down,down,1098,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,1,['down'],['down']
Availability," like this:. ##### ERROR MESSAGE: Invalid command line: No tribble type was provided on the command line and the type of the file could not be determined dynamically. Please add an explicit type tag :NAME listing the correct type from among the supported types:; ##### ERROR Name FeatureType Documentation; ##### ERROR BCF2 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF3 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR ------------------------------------------------------------------------------------------. then I added a name like this:. --variant:VCF $NOW/w-91.raw.g.vcf \; --variant:VCF $NOW/w-92.raw.g.vcf \; --variant:VCF $NOW/w-93.raw.g.vcf \. also met a error like this:. ##### ERROR; ##### ERROR MESSAGE: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; ##### ERROR ------------------------------------------------------------------------------------------. and I change the name like this:. --variant:VCF3 $NOW/w-91.raw.g.vcf \; --variant:VCF3 $NOW/w-92.raw.g.vcf \; --variant:VCF3 $NOW/w-93.raw.g.vcf \. also error:. ##### ERROR MESSAGE: Unable to parse header with error: Your input file has a malformed header: This codec is strictly for VCFv3 and does not support VCFv4.1, for input source: /gss1/home/hjb20181119/panyongpeng/NN1138-2/RIL_genotype/mapping/w-1.raw.g.vcf; ##### ERROR ------------------------------------------------------------------------------------------. I checked my GVCF file and the header is :. ##fileformat=VCFv4.1; ##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FORMAT=<ID=AD,Number=.,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,N",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7315:1449,ERROR,ERROR,1449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7315,3,['ERROR'],['ERROR']
Availability," line: 102; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * What went wrong:; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] A problem occurred evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter]",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:1992,ERROR,ERROR,1992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability," loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ######",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6133,ERROR,ERROR,6133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['ERROR'],['ERROR']
Availability," memory on com2:45501 (size: 2.1 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 565 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88) finished in 0.566 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Job 0 finished: runJob at SparkHadoopMapReduceWriter.scala:88, took 9.524571 s; 17/10/13 18:11:53 INFO io.SparkHadoopMapReduceWriter: Job job_20171013181144_0009 committed.; 17/10/13 18:11:53 INFO server.AbstractConnector: Stopped Spark@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:53 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 17/10/13 18:11:54 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/13 18:11:54 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/13 18:11:54 INFO memory.MemoryStore: MemoryStore cleared; 17/10/13 18:11:54 INFO storage.BlockManager: BlockManager stopped; 17/10/13 18:11:54 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/13 18:11:54 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/13 18:11:54 INFO spark.SparkContext: Successfully stopped SparkContext; 18:11:54.552 INFO PrintReadsSpark - Shutting down engine; [October 13, 2017 6:11:54 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.Pr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:22066,down,down,22066,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['down'],['down']
Availability," merging .sbi files; 2019-06-03 22:34:34 INFO IndexFileMerger:69 - Merging .bai files in temp directory hdfs:///project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.bam.parts/ to hdfs:///project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.bam.bai; 2019-06-03 22:34:48 INFO AbstractConnector:318 - Stopped Spark@6be766d1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-06-03 22:34:48 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4040; 2019-06-03 22:34:48 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-06-03 22:34:48 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-06-03 22:34:48 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-06-03 22:34:48 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-06-03 22:34:48 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-06-03 22:34:48 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-06-03 22:34:49 INFO MemoryStore:54 - MemoryStore cleared; 2019-06-03 22:34:49 INFO BlockManager:54 - BlockManager stopped; 2019-06-03 22:34:49 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-06-03 22:34:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-06-03 22:34:49 INFO SparkContext:54 - Successfully stopped SparkContext; 22:34:49.027 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 10:34:49 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 3.72 minutes.; Runtime.totalMemory()=3829923840; htsjdk.samtools.util.RuntimeIOException: java.io.IOException: Stream closed; at htsjdk.samtools.IndexStreamBuffer.readFully(IndexStreamBuffer.java:23); at htsjdk.samtools.IndexStreamBuffer.readInteger(IndexStreamBuffer.java:56); at htsjdk.samtools.AbstractBAMFileIndex.readIn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:918,down,down,918,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,4,['down'],['down']
Availability," name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966699, Read name UMI-CCG-TGA-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966722, Read name UMI-AGG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966742, Read name UMI-CCG-TCA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966752, Read name UMI-GAA-GAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966784, Read name UMI-CCT-TAT-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966875, Read name UMI-AGG-GGG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966887, Read name UMI-AGG-CCG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966916, Read name UMI-GCT-TCG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966939, Read name UMI-CAA-TGT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966989, Read name UMI-GAA-TCA-7, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966991, Read name UMI-TAG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 967245, Read name UMI-AAG-ATT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 975151, Read name UMI-ACT-CCC-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 1064783, Read name UMI-GGA-GGT-6, Zero-length read without FZ, CS or CQ tag; Maximum output of [100] errors reached.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:10079,ERROR,ERROR,10079,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,11,"['ERROR', 'error']","['ERROR', 'errors']"
Availability," not strict about the state of the cache.; - Currently in order to lower the mapping quality threshold for HaplotypeCaller two separate arguments must be called. This is because the mapping-quality threshold is checked twice, once for the read filter plugin `getToolDefaultArgumentCollections()` which gets instantiated before the HaplotypeCaller arguments are populated, and again before assembly. While the functionality to be stricter about mapping quality for assembly compared to active region discovery might be important it is unclear if this matters and perhaps the latter check can be done away with? ; - I have added a genotype debugging stream that closely matches the debug output stream from DRAGEN (which itself was a reflection of the GATK3 debug out stream). This involved a lot of threading output writers through the codebase and perhaps this is better handled by the ""--debug"" argument like it used to? Thoughts? . Notes: ; - It should be noted that by design all of the added changes to HaplotypeCaller are opt-in, barring errors in implementation.; - This code is measurably slower than vanilla HaplotypeCaller. In particular FRD is a very expensive step that corresponds to ~5-7% of the runtime. This is in part because it has to duplicate many of the steps in the genotyper based on the number of unique mapping qualities present at a site as well as the fact that it performs an O(n^2) number of operations at sites with many possible alleles. There are options to cut down on the cost of this algorithm that moderately impact the results relative to DRAGEN. . This implementation is intended to produce results close to the results on DRAGEN 3.4.12 without stripping away the major improvements made in GATK4, as a result there are a number of areas in which we know we are producing different results: ; - In GATK4 variants that overlap with an upstream deletion will have added to their alleles list a sybmolic '*' deletion alleles which are genotyped as part of the allele ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6634:3909,error,errors,3909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6634,1,['error'],['errors']
Availability," o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45960,AVAIL,AVAILABLE,45960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability," of genotypes will NOT be added for this location. Chromosome chr2L position 19311 (TileDB column 19310) has too many alleles in the combined VCF record : 16 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. 19:44:17.535 INFO ProgressMeter - chr2L:19364 2.8 15000 5324.0; Chromosome chr2L position 19835 (TileDB column 19834) has too many alleles in the combined VCF record : 11 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. 19:44:34.904 INFO ProgressMeter - chr2L:21364 3.1 17000 5471.6; 19:44:47.867 INFO ProgressMeter - chr2L:23364 3.3 19000 5717.8; Chromosome chr2L position 25349 (TileDB column 25348) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. 19:45:00.952 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),57.82864317899994,Cpu time(s),49.25545264700008; [January 13, 2022 7:45:01 PM EST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 4.22 minutes.; Runtime.totalMemory()=2076049408; java.lang.IllegalStateException: Genotype [Ark CTTT/CTTT GQ 24 DP 8 AD 0,8,0,0,0,0,0,0 {SB=0,0,4,4}] does not contain likelihoods necessary to calculate posteriors.; at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.log10NormalizedGenotypePosteriors(AlleleFrequencyCalculator.java:89); at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.effectiveAlleleCounts(AlleleFrequencyCalculator.java:258); at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.calculate(AlleleFrequencyCalculator.java:141); at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:147); a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639:6593,down,down,6593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639,1,['down'],['down']
Availability," of the read before the first unique (and existing) k-mer in each sequence is found. This is partly fixed by the approach taken when we recover dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clear",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/264:1602,down,downstream,1602,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264,2,"['down', 'recover']","['downstream', 'recovery']"
Availability," on the input files I'm using and its difficult for me to interpret the error message. What I'm seeing is,. 1. ERROR LiveListenerBus: SparkListenerBus has already stopped!; 2. Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times; 3. WARN ShutdownHookManager: ShutdownHook '$anon$2' timeout; 4. WARN ShutdownHookManager: ShutdownHook 'ClientFinalizer' timeout; 5. ERROR ShutdownHookManager: ShutdownHookManger shutdown forcefully.; 6. /var/spool/slurmd/job1619084/slurm_script: line 126: syntax error: unexpected end of file. In that order. I'm running this script in parallel on a SLURM scheduler (four cpus with 8Gb mem/cpu). Here is a sample of the last few lines of STDERR, but I'm also attaching the full error output.; [pathseq_TCGA.slurm.1619078_1.err.txt](https://github.com/broadinstitute/gatk/files/1965063/pathseq_TCGA.slurm.1619078_1.err.txt). Thanks so much for any help you can provide!. `; 18/05/01 14:20:59 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.12.137.46, 39719, None),broadcast_1_piece0,StorageLevel(memory, 1 replicas),127561,0)); 18/05/01 14:21:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/05/01 14:23:29 INFO MemoryStore: MemoryStore cleared; 18/05/01 14:23:29 INFO BlockManager: BlockManager stopped; 18/05/01 14:23:29 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/05/01 14:24:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/05/01 14:25:36 INFO SparkContext: Successfully stopped SparkContext; 14:25:37.027 INFO PathSeqPipelineSpark - Shutting down engine; [May 1, 2018 2:25:37 PM EDT] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 37.98 minutes.; Runtime.totalMemory()=23999283200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: L",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:957,ERROR,ERROR,957,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['ERROR'],['ERROR']
Availability," opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.:1,0,0:1:.:0,0,0,0,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:3,0,0:3:.:0,0,0,0,0,0 ./.:7,0,0:7:.:0,0,0,0,0,0 1/1:0,0,0:0:0:45,3,0,3,0,0 ./.:0,0,0 1/1:0,0,1:1:0:45,3,0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1766,error,errors,1766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['error'],['errors']
Availability," operation in Genome STRiP is to ask for the sample ; associated with a read. This requires the header, I would think.; Anyway, my main point was just to stimulate thinking about the value of ; implementing an efficient way to transmit the headers.; It also seems to me that this generalizes to efficient patterns to ; transmit any widely shared data (that is referenced by many serialized ; individual data items) out-of-band. -Bob. On 9/21/15 11:42 AM, droazen wrote:. > @bhandsaker https://github.com/bhandsaker Thanks for chiming in with ; > your thoughts/concerns.; > ; > Under this proposal, the various classes in htsjdk that read and ; > return |SAMRecords| (eg., |SAMReader| & co.) would continue to put the ; > header inside of the records, so we would not be imposing an ; > additional burden on direct clients of htsjdk to check for null ; > headers any more than they do currently. The only difference is that ; > if downstream consumers of |SAMRecords| (like hellbender) choose to ; > strip the header from the records, there would be an explicit contract ; > governing the behavior of headerless |SAMRecords| (as opposed to the ; > status quo, in which the header may be null but behavior is totally ; > undocumented and in some cases inconsistent -- eg., the reference name ; > and index in a headerless |SAMRecord| can get out-of-sync in some cases).; > ; > In additional to documenting/clarifying the behavior of headerless ; > |SAMRecords| and fixing any consistency-related bugs we find when ; > operating without a header, we would also make an effort to document ; > when a class in htsjdk that consumes |SAMRecords| requires that a ; > header be present in the records (such as the various writer classes).; > ; > Does this sound reasonable? It's actually a much more conservative ; > proposal than it may have initially sounded :); > ; > ; > Reply to this email directly or view it on GitHub ; > https://github.com/broadinstitute/hellbender/issues/900#issuecomment-142020109.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910:1365,down,downstream,1365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910,1,['down'],['downstream']
Availability," org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:270); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:155); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:47); at org.apache.logging.log4j.LogManager.getContext(LogManager.java:196); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:599); at org.broadinstitute.hellbender.utils.Utils.<clinit>(Utils.java:72); at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); Caused by: java.net.UnknownHostException: de2c81c88ddc: Temporary failure in name resolution; at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method); at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929); at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324); at java.net.InetAddress.getLocalHost(InetAddress.java:1501); ...13 more. The Genome Analysis Toolkit (GATK) v4.2.6.1; HTSJDK Version: 2.24.1; Picard Version: 2.27.1; Using GATK jar /gatk/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.2.6.1-local.jar -version; ```. This request was created from a contribution made by Pryce Turner on July 29, 2022 03:44 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360078378372--Could-not-determine-local-host-name-#community\_comment\_7692552841755](https://gatk.broadinstitute.org/hc/en-us/community/posts/360078378372--Could-not-determine-local-host-name-#community_comment_7692552841755). \--. Hey 417227834892,. Were you ever able to solve this? I'm running into the same issue with HaplotypeCaller. It still runs, but the error output is potentially disruptive. Thanks!<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/292152'>Zendesk ticket #292152</a>)<br> gz#292152</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7983:2816,error,error,2816,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7983,1,['error'],['error']
Availability," org.broadinstitute.hellbender.Main.mainEntry(Main.java:209); at org.broadinstitute.hellbender.Main.main(Main.java:306). real 481m24.418s; user 581m54.752s; sys 2m49.965s. ```. This run did not complete successfully - the Exception caused it to fail prematurely. . Previously I had seen HaplotypeCaller run out of memory and fail in almost as much time, so I think this and the OOM error are related. The only difference in invocation was that with the OOM failure, I was running with the default for `--max-reads-per-alignment-start` (`50`). This also works just fine with that setting at 15. The failure seems to occur around the same place in the data each time (the end of `chr13`). At that point in the data, there is a very large pileup which is probably instigating this. Additionally, if I remove the `--linked-de-bruijn-graph` argument, this runs just fine with the default setting of `--max-reads-per-alignment-start`. I have a minimally reproductive dataset that I can share which reproduces the OOM error for sure (I'm 99% sure it reproduces this one as well). For the OOM failures, the final logs from HaplotypeCaller look like this:. ```; ./gatk HaplotypeCaller ...; ...; 15:56:23.205 INFO ProgressMeter - Pf3D7_13_v3:2603234 100.5 114070 1134.5; 15:56:33.443 INFO ProgressMeter - Pf3D7_13_v3:2661462 100.7 114420 1136.1; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:56:43.998 INFO ProgressMeter - Pf3D7_13_v3:2730055 100.9 114840 1138.3; 15:56:59.911 INFO ProgressMeter - Pf3D7_13_v3:2798281 101.2 115210 1139.0; 15:59:27.062 INFO ProgressMeter - Pf3D7_13_v3:2861780 103.6 115460 1114.4; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:59:37.457 INFO ProgressMeter - Pf3D7_13_v3:2869697 103.8 115500 1112.9. real 671m24.770s; user 777m30.923s; sys 6m13.682s. $ echo $?; 247; ```. Here is my command-line invocation:; ```; ./ga",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:4956,error,error,4956,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,1,['error'],['error']
Availability, org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultBuildConfigurer.configure(DefaultBuildConfigurer.java:38); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradleLauncher.java:151); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Factories$1.create(Factories.java:22); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationEx,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:3822,ERROR,ERROR,3822,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability, org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:106); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildAc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:5921,ERROR,ERROR,5921,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability, org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:106); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBui,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:5736,ERROR,ERROR,5736,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability, org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:106); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:92); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.ru,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:5551,ERROR,ERROR,5551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability," program; 3) read in the alignments in a GATK tool and filter accordingly. The ambitious version is to write our own simple aligner, eg a kmer-based method like BLAT or BBMap but with all the messy parts for handling big indels, RNA, and proteins removed. Writing our own BWA aligner would be wildly impractical. @takutosato @LeeTL1220 keeping you in the loop. ---. @davidbenjamin commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-275483449). *Even better*: rely on someone else in the group, such as Ted, to write a Java binding for BWA in memory. See broadinstitute/gatk#2367. ---. @davidbenjamin commented on [Sun Apr 23 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-296515266). So. . . given that our pipeline aligns with BWA, it might seem like this is just a redundant and laborious rehashing of the mapping quality score. *However*, the mapping quality only considers multi-mapping within the reference, and therefore doesn't account for mapping errors due to incompleteness of the reference. That is, reads from genomic regions that are not part of the reference (because they're hard to assemble, like centromeres etc) might map well to a unique regions within the reference, and therefore will have fine mapping quality even though they are artifacts. There are published ""decoy genomes"" -- essentially pseudo-contigs of regions missing from the reference, and mapping with BWA in memory to *those* might be very helpful. So, we need to: 1) get our hands on a decoy genome that will play nicely with BWA, and 2) talk to the SV team. ---. @ldgauthier commented on [Mon Apr 24 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-296675311). To be pedantic, the mapping quality also considers how well the read aligns; to its best mapping. In places where a sample has a lot of nearby SNPs; compared to the reference the mapping qualities of the reads are low; compared to reads t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2930:1578,error,errors,1578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2930,1,['error'],['errors']
Availability," pseudochromosome_1:1 21.4 3 0.1; 08:17:48.471 INFO GenomicsDBImport - Done importing batch 3/6; 08:17:48.510 INFO GenomicsDBImport - Importing batch 4 with 6 samples; 08:23:17.675 INFO ProgressMeter - pseudochromosome_1:1 26.9 4 0.1; 08:23:17.675 INFO GenomicsDBImport - Done importing batch 4/6; 08:23:17.709 INFO GenomicsDBImport - Importing batch 5 with 6 samples; 08:31:44.254 INFO ProgressMeter - pseudochromosome_1:1 35.3 5 0.1; 08:31:44.255 INFO GenomicsDBImport - Done importing batch 5/6; 08:31:44.286 INFO GenomicsDBImport - Importing batch 6 with 6 samples; 08:38:39.554 INFO ProgressMeter - pseudochromosome_1:1 42.2 6 0.1; 08:38:39.554 INFO GenomicsDBImport - Done importing batch 6/6; 08:38:39.556 INFO ProgressMeter - pseudochromosome_1:1 42.2 6 0.1; 08:38:39.556 INFO ProgressMeter - Traversal complete. Processed 6 total batches in 42.2 minutes.; 08:38:39.556 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed!; 08:38:39.556 INFO GenomicsDBImport - Shutting down engine; [27 May 2020 08:38:39 CEST] oAB.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 42.25 minutes.; Runtime.totalMemory()=2545942528; Tool returned:; true. (base) xxxxxx@galaxy:~$ gatk --java-options ""-Xmx30g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs -R Reference/File_S16_uT_3_Pseudochromosomes.fasta -V gendb://ABchroneALL -O ABchroneALL.vcf.gz; Using GATK jar /data/xxxxxx/miniconda3/share/gatk4-4.1.6.0-0/gatk-package-4.1.6.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx30g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /data/xxxxxx/miniconda3/share/gatk4-4.1.6.0-0/gatk-package-4.1.6.0-local.jar GenotypeGVCFs -R Reference/File_S16_uT_3_Pseudochromosomes.fasta -V gendb://ABchroneALL -O ABchroneALL.vcf.gz; 09:48:14.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xxxxxx",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6616:7380,down,down,7380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6616,1,['down'],['down']
Availability," request was created from a contribution made by ABours on May 29, 2020 18:23 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360067695771-GenotypeGvcfs-has-formatting-issues-in-both-v4-1-6-0-as-v4-1-7-0. --. Hi,. I'm using v4.1.6.0 of GenotypeGvcfs to make a vcf, out of whole genome data from 19 samples (following your recommendations). When I run ValidateVariants to check the output of GenotypeGvcfs I get a error message, which states that one or more of the ALT allele are actually not in the samples provided. A previous user already found a similar error in ValidateVariants (https://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-), but then for Haplotypecaller, and you have opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:993,error,error,993,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['error'],['error']
Availability," require the Conda environment, but the tool itself will not. But I think this is probably preferable to writing test code to compare HDF5s, minimal though that might be, since the schema might change in the future.; - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs. Could perhaps expand on the `resources` parameter once the required labels are settled.; - [x] Parameter validation.; - [x] Clean up docs for parent walker.; - [x] Decide on required labels. I think ""training"" and ""calibration"" (rather than the legacy ""training"" and ""truth"") might be good candidates. EDIT: Switched ""truth"" to ""calibration"" throughout the codebase.; - [x] Validate privileged labels (snp, training, calibration) in parent walker.; ; Future work:. - [ ] Clean up unlabeled outputs. This includes 1) sorting the corresponding HDF5, and 2) outputting a corresponding sites-only VCF. Unlike the labeled sites, which are written individually to VCF as we traverse them, unlabeled sites are placed into a reservoir of fixed size for subsampling purposes. Thus, we cannot write them to VCF as with labeled sites; furthermore, after traversal, the unlabeled sites are not ordered within the reservoir. Ultimately, the lack of this VCF means that extracted, unlabeled sites cannot be tagged as such by the scoring tool in the final VCF.; - [ ] Consider downsampling of labeled data. This is not done because 1) of the complications just mentioned, 2) we assume that labeled data is precious and that one-time extraction of it will always be relatively cheap, especially compared to training (and that training implementations can always downsample, if needed), and 3) using -L functionality to subset genomic regions is perhaps a cleaner strategy for doing so.; - [x] I think we can probably clean up treatment of allele-specific annotations by automatically detecting whether an annotation is an array type. This would obviate the need for the parameter to turn on allele-specific mode. EDIT: Added in #8131.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059:4128,down,downsampling,4128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059,2,['down'],"['downsample', 'downsampling']"
Availability, runs of these tools) when using NIO:. > java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: All 20 reopens failed. Waited a total of 1918000 ms between attempts; at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:318); at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:571); at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:560); at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:525); at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:458); at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:196); at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:331); at java.io.DataInputStream.read(DataInputStream.java:149); at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:421); at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:394); at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:268); at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); at htsjdk.samtools.BAMF,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631:1254,avail,available,1254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631,1,['avail'],['available']
Availability," same result. Java version is ``` OpenJDK Runtime Environment (build 1.8.0_252-b09) ```; ```; /gatk-4.0.11.0/gatk --java-options ""-Xmx4G"" HaplotypeCaller \; -R GRCh38.p2.fa \; -I RT4_STD.bam \; -ERC GVCF \; -L chr16 \; -O RT4_STD.g.vcf \; -new-qual; ```; - Error message is also different; - First one is :; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00002aaad9f1e54a, pid=7818, tid=0x00002aaaabdce700; #; # JRE version: Java(TM) SE Runtime Environment (8.0_111-b14) (build 1.8.0_111-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_pairhmm_omp1890484777463615571.so+0x6954a] double compute_full_prob_avxd<double>(testcase*)+0x34a; #; # Core dump written. Default location: core or core.7818; #; # An error report file with more information is saved as:; # hs_err_pid7818.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; ```. -Second one is ; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00000035dfe84364, pid=160107, tid=0x00002aaaabdce700; #; # JRE version: Java(TM) SE Runtime Environment (8.0_111-b14) (build 1.8.0_111-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 ); # Problematic frame:; # C [libc.so.6+0x84364]; #; # Core dump written. Default location: core or core.160107; #; # An error report file with more information is saved as:; # hs_err_pid160107.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug. ```. Could this be a bug of problem with my data?. Thanks, ; Wen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7515:1437,error,error,1437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7515,2,['error'],['error']
Availability, scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 18/08/29 10:20:49 ERROR Executor: Exception in task 12.0 in stage 12.0 (TID 3228); ```. I am running version 4.0.8.1 of GATK using openjdk version 1.8.0_212.; The command I am using is:. ```; gatk StructuralVariationDiscoveryPipelineSpark \; --aligner-index-image refrance.fasta.img \; --contig-sam-file contigs-aligned.sam \; --spark-master local[30] \; --kmers-to-ignore kmers_to_ignore.txt \; -R $fasta \; -I $sample.bam \; -O $sample.vcf; ```. Thanks for taking a look!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5145:2742,ERROR,ERROR,2742,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5145,1,['ERROR'],['ERROR']
Availability," screenshot of the bamout file from 3.1. <img width=""1440"" alt=""screen shot 2016-05-31 at 4 56 20 pm"" src=""https://cloud.githubusercontent.com/assets/6998669/15690232/9dfc6992-2750-11e6-94c4-0c055b3ad1bc.png"">; The first green SNP on the left is the one in question. ---. @chandrans commented on [Tue Jun 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1360#issuecomment-225999879). Figured out at Support meeting that the variant SNP is called when you include -allowNonUniqueKmersInRef in the command. . It seems the kmer including the SNP is quite common the region. I am going to tell the user about using the flag. However, I think David will take a look into the code to see what exactly is going on and whether it is a good idea to recommend using the flag in repeat regions. ---. @ldgauthier commented on [Wed Jun 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1360#issuecomment-226191676). Valentin has found that that arg is able to recover a lot of our missed; indels in the pseudo-diploid truth data, so it's worth investigating.; However, I believe when I tried it for MuTect2 against the LUAD data I; introduced a not insignificant number of additional variants, likely false; positives. On Tue, Jun 14, 2016 at 4:06 PM, chandrans <notifications@github.com> wrote:. > Figured out at Support meeting that the variant SNP is called when you; > include -allowNonUniqueKmersInRef in the command.; >; > It seems the kmer including the SNP is quite common the region.; >; > I am going to tell the user about using the flag. However, I think David; > will take a look into the code to see what exactly is going on and whether; > it is a good idea to recommend using the flag in repeat regions.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/1360#issuecomment-225999879>,; > or mute the thread; > <https://github.com/notifications/unsubscri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2916:11712,recover,recover,11712,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2916,1,['recover'],['recover']
Availability," sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 2]; 2019-01-07 11:34:11 INFO TaskSetManager:54 - Starting task 9.1 in stage 0.0 (TID 10, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:11 INFO TaskSetManager:54 - Lost task 2.1 in stage 0.0 (TID 7) on scc-q12.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f) [duplicate 1]; 2019-01-07 11:34:12 INFO TaskSetManager:54 - Starting task 3.3 in stage 0.0 (TID 11, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:12 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 9) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIte",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:33138,ERROR,ERROR,33138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['ERROR'],['ERROR']
Availability," shard 4 / 8...; 14:27:24.879 INFO PostprocessGermlineCNVCalls - Analyzing shard 5 / 8...; 14:27:26.062 INFO PostprocessGermlineCNVCalls - Analyzing shard 6 / 8...; 14:27:26.849 INFO PostprocessGermlineCNVCalls - Analyzing shard 7 / 8...; 14:27:27.893 INFO PostprocessGermlineCNVCalls - Analyzing shard 8 / 8...; 14:27:28.412 INFO PostprocessGermlineCNVCalls - Generating segments...; 14:29:52.532 INFO PostprocessGermlineCNVCalls - Parsing Python output...; 14:29:52.537 INFO PostprocessGermlineCNVCalls - Writing segments VCF file to /bettik/tintest/CNV_Hyperexome/segments/genotyped-segments-SAMPLE_6.vcf.gz...; 14:29:52.703 INFO PostprocessGermlineCNVCalls - Generating denoised copy ratios...; 14:29:53.592 INFO PostprocessGermlineCNVCalls - Writing denoised copy ratios to /bettik/tintest/CNV_Hyperexome/ratios/denoised-copy-ratios-SAMPLE_6.tsv...; 14:29:55.274 INFO PostprocessGermlineCNVCalls - PostprocessGermlineCNVCalls complete.; 14:29:55.275 INFO PostprocessGermlineCNVCalls - Shutting down engine; [December 2, 2022 2:29:55 PM GMT] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 6.03 minutes.; Runtime.totalMemory()=2820145152; Using GATK jar /gatk/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.3.0.0-local.jar PostprocessGermlineCNVCalls --model-shard-path GermlineCNVCaller/GermlineCNVCaller_1_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_2_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_3_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_4_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_5_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_6_of_8-model/ --model-shard-path GermlineCNVCaller/GermlineCNVCaller_7_of_8-model/ --model-shard-path GermlineCNVCalle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8183:5061,down,down,5061,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8183,1,['down'],['down']
Availability," size (119 KB). The maximum recommended task size is 100 KB.; > Test: Test method testAllTargetsHDF5PoNCreationSpark[0](null, src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-control-full.pcov)(org.broadinstitute.hellbender.tools.exome.CreatePanelOfNormalsIntegrationTest) produced standard out/err: 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > ; > ```; > 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > ```; > ; > #; > ; > # A fatal error has been detected by the Java Runtime Environment:; > ; > #; > ; > # SIGSEGV (0xb) at pc=0x000000010a5a9401, pid=2425, tid=8963; > ; > #; > ; > # JRE version: Java(TM) SE Runtime Environment (8.0_91-b14) (build 1.8.0_91-b14); > ; > # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.91-b14 mixed mode bsd-amd64 compressed oops); > ; > # Problematic frame:; > ; > # V [libjvm.dylib+0x1a9401]; > ; > #; > ; > # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; > ; > #; > ; > # An error report file with more information is saved as:; > ; > # /Users/louisb/Workspace/gatk-protected/hs_err_pid2425.log; > ; > #; > ; > # If you would like to submit a bug report, please visit:; > ; > # http://bugreport.java.com/bugreport/crash.jsp; > ; > #; > ; > hs_err_pid2425.log.txt; > https://github.com/broadinstitute/gatk-protected/files/448383/hs_err_pid2425.log.txt; > ; > @yfarjoun https://github.com/yfarjoun Is this similar to the crash you; > saw a while back?; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gatk-protected/issues/659, or mute; > the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0h0xGA8ntZ_9wd53IUeIqTIfWye0ks5qlf_YgaJpZM4JyIZS; > .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2883:3476,error,error,3476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2883,1,['error'],['error']
Availability," spark.executor.extraJavaOptions=-Xss2m`. debug log:; ```; ...; 00:05 DEBUG: [kryo] Write object reference 100367: HLA-DRB1*15:03:01:01; 00:05 DEBUG: [kryo] Write object reference 100369: HLA-DRB1*15:03:01:02; 00:05 DEBUG: [kryo] Write object reference 100371: HLA-DRB1*16:02:01; 21/09/12 22:10:49 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040; 21/09/12 22:10:49 INFO StandaloneSchedulerBackend: Shutting down all executors; 21/09/12 22:10:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 21/09/12 22:10:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/09/12 22:10:49 INFO MemoryStore: MemoryStore cleared; 21/09/12 22:10:49 INFO BlockManager: BlockManager stopped; 21/09/12 22:10:49 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/09/12 22:10:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/09/12 22:10:49 INFO SparkContext: Successfully stopped SparkContext; 22:10:49.533 INFO HaplotypeCallerSpark - Shutting down engine; [September 12, 2021 10:10:49 PM CST] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.09 minutes.; Runtime.totalMemory()=1788346368; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.MapReferenceResolver.useReferences(MapReferenceResolver.java:70); at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:665); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:570); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); ...; ```. related https://github.com/broadinstitute/gatk/issues/6750",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984:1233,down,down,1233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984,2,['down'],['down']
Availability, src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3605617Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3694118Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3740413Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3746092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3759011Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3760984Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3762471Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3764327Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3813516Z [0K; 2022-08-16T00:09:07.3813804Z [0K; 2022-08-16T00:09:07.3814073Z [0K; 2022-08-16T00:09:07.3818970Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.3821035Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplot,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:4022,error,error,4022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability, src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7254348Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7492903Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7498018Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7502319Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7512488Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7514136Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7515610Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7517156Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7642312Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7643965Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:6169,error,error,6169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability, src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T00:09:07.4215495Z @VisibleForTesting; 2022-08-16T00:09:07.4216081Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4251408Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4265184Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4267067Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4271200Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4272874Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4278681Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4292326Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4293163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4296749Z src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4303354Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:15712,down,downsampling,15712,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['down'],['downsampling']
Availability, src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T22:45:53.8175437Z @VisibleForTesting; 2022-08-16T22:45:53.8175712Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8180874Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8265839Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8266584Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8267814Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8268598Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8269986Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8270563Z [0K; 2022-08-16T22:45:53.8270698Z [0K; 2022-08-16T22:45:53.8270832Z [0K; 2022-08-16T22:45:53.8272441Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 31s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/transformers/DRAGENMappingQualityReadTransformer.java:3: error: package com.google.common.annotations does not exist[0K; 2022-08-16T22:45:53.8283859Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.828470,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:17750,down,downsampling,17750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['down'],['downsampling']
Availability," started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43279.; 10:33:07.208 INFO NettyBlockTransferService - Server created on 172.20.19.130:43279; 10:33:07.210 INFO BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 10:33:07.214 INFO BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.221 INFO BlockManagerMasterEndpoint - Registering block manager 172.20.19.130:43279 with 1076.2 GiB RAM, BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.225 INFO BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.226 INFO BlockManager - Initialized BlockManager: BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.345 INFO ContextHandler - Stopped o.s.j.s.ServletContextHandler@7074da1d{/,null,STOPPED,@Spark}; 10:33:07.347 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO Contex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:44886,AVAIL,AVAILABLE,44886,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability," storage cost offender and asked to clean up.) Luckily, I have another CRAM available that I left for testing purposes. I can recapitulate the error with this other CRAM using the old `gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT` jar. ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-launch PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam; ```. Gives the same error at an approximately similar region:; ```; ...; 10:50:54.603 INFO ProgressMeter - chr1:224042054 2.2 11004000 5016945.0; 10:51:04.609 INFO ProgressMeter - chr1:248061327 2.4 11905000 5044206.5; ERROR	2017-10-02 10:51:05	Slice	Reference MD5 mismatch for slice 0:248574592-248771907, AGTGGATGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:1148,down,down,1148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828,1,['down'],['down']
Availability," subsp. enterica serovar Typhimurium str. SL1344, Salmonella eneterica subsp. enterica serovar Typhimurium str. LT2, Fusobacterium nucleatum subsp. nucleatum ATCC 25586). I generate six datasets with 100,000 unpaired reads of length 75 bp (2 datasets from each genome) using Rsubread with simulate.sequencing.error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/007/325/GCF_000007325.1_ASM732v1/GCF_000007325.1_ASM732v1_cds_from_genomic.fna.gz""; SL1344_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/210/855/GCF_000210855.2_ASM21085v2/GCF_000210855.2_ASM21085v2_cds_from_genomic.fna.gz""; LT2_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6705:1141,error,error,1141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705,1,['error'],['error']
Availability," table creation and data loading in LoadData (#7056); - WIP; - tieout scripts; - notes files; - updated diff scripts; - fixed bug...; - add wdl and inputs file for warp pipeline; - reverting logging; - included top level WDL; - use gnarly with BQ extract cohort; - remove unused file; - cleaning up; - tidy; - tidy up before PR; - tidy up before PR; - PR comments; - merge conflict misfires; - added example SQL to create alt allele table from VET; - option to remove PLs; - fixed and enhanced unit test; - removing unused config, causing travis to fail; - add CreateVariantIngestFiles integration test (#7071); - add sampleName (instead of NULL) to error message (#7074); - Update To handle if no data error (#7084); - Memory improvement when writing missing positions to pet (#7098); - added support for loading QUALapprox into VET (#7101); - Add -m flag to gsutil step; add dockstore branch filters to facilitate development (#7104); - updates to ImportGenomes and LoadBigQueryData (#7112); - Add ngs to cohort extract Dockerfile; remove exception catching in extract python script (#7113); - remove problematic storage_location imports (#7119); - Reduce memory and CPU for CreateImportTsvs task, check for files before attempting load (#7121); - add -m flag to gsutil mv step (#7129); - ah_var_store : Add sample file argument to cohort extract (#7117); - Perform full WGS cohort extract scientific tieout for 35 ACMG59 samples (#7106); - Enable Read/Execution Project for BQ Queries (#7136); - ah - optional service account (#7140); - Add load lock file to prevent accidental re-loading of data to BQ (#7138); - #251 Address gvcf no-calls missing QUALapprox and other features (#7146); - Job Add labels to BQ operations from GATK (Issues-199) (#7115); - parse map to list to avoid brackets and spaces in vcf output (#7168); - #259 Inline schema for importgenomes.wdl (#7171); - Created AvroFileReader and unittest, Update ExtractCohort and ExtractCohortEngine (#7174); - #224 Import WDL: handle ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:11236,error,error,11236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,['error'],['error']
Availability," tag; ERROR: Record 187121, Read name UMI-CCG-GCC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187154, Read name UMI-CAA-CTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187181, Read name UMI-CGG-GAG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187209, Read name UMI-CAA-GTT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 279812, Read name UMI-ACT-GGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 327672, Read name UMI-AGT-CGG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 367457, Read name UMI-GGA-TTA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 441607, Read name UMI-AGA-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481504, Read name UMI-AAC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481532, Read name UMI-AAT-CAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481722, Read name UMI-ATA-ATT-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:4667,ERROR,ERROR,4667,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 187154, Read name UMI-CAA-CTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187181, Read name UMI-CGG-GAG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187209, Read name UMI-CAA-GTT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 279812, Read name UMI-ACT-GGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 327672, Read name UMI-AGT-CGG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 367457, Read name UMI-GGA-TTA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 441607, Read name UMI-AGA-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481504, Read name UMI-AAC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481532, Read name UMI-AAT-CAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481722, Read name UMI-ATA-ATT-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:4757,ERROR,ERROR,4757,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 187181, Read name UMI-CGG-GAG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 187209, Read name UMI-CAA-GTT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 279812, Read name UMI-ACT-GGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 327672, Read name UMI-AGT-CGG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 367457, Read name UMI-GGA-TTA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 441607, Read name UMI-AGA-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481504, Read name UMI-AAC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481532, Read name UMI-AAT-CAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481722, Read name UMI-ATA-ATT-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:4847,ERROR,ERROR,4847,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 187209, Read name UMI-CAA-GTT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 279812, Read name UMI-ACT-GGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 327672, Read name UMI-AGT-CGG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 367457, Read name UMI-GGA-TTA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 441607, Read name UMI-AGA-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481504, Read name UMI-AAC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481532, Read name UMI-AAT-CAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481722, Read name UMI-ATA-ATT-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:4937,ERROR,ERROR,4937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 279812, Read name UMI-ACT-GGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 327672, Read name UMI-AGT-CGG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 367457, Read name UMI-GGA-TTA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 441607, Read name UMI-AGA-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481504, Read name UMI-AAC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481532, Read name UMI-AAT-CAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481722, Read name UMI-ATA-ATT-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:5027,ERROR,ERROR,5027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 327672, Read name UMI-AGT-CGG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 367457, Read name UMI-GGA-TTA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 441607, Read name UMI-AGA-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481504, Read name UMI-AAC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481532, Read name UMI-AAT-CAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481722, Read name UMI-ATA-ATT-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:5117,ERROR,ERROR,5117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 367457, Read name UMI-GGA-TTA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 441607, Read name UMI-AGA-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481504, Read name UMI-AAC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481532, Read name UMI-AAT-CAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481722, Read name UMI-ATA-ATT-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:5207,ERROR,ERROR,5207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 441607, Read name UMI-AGA-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481504, Read name UMI-AAC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481532, Read name UMI-AAT-CAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481722, Read name UMI-ATA-ATT-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:5297,ERROR,ERROR,5297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 481504, Read name UMI-AAC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481532, Read name UMI-AAT-CAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481722, Read name UMI-ATA-ATT-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:5387,ERROR,ERROR,5387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 481532, Read name UMI-AAT-CAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481722, Read name UMI-ATA-ATT-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:5477,ERROR,ERROR,5477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 481989, Read name UMI-CGA-CTA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:5658,ERROR,ERROR,5658,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 482114, Read name UMI-GAG-TAA-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:5748,ERROR,ERROR,5748,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 482150, Read name UMI-GCC-GTA-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Recor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:5838,ERROR,ERROR,5838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 482210, Read name UMI-GGT-TCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Reco",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:5928,ERROR,ERROR,5928,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 482222, Read name UMI-GTA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Reco",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:6018,ERROR,ERROR,6018,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 482251, Read name UMI-GTT-TAC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Reco",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:6108,ERROR,ERROR,6108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 541693, Read name UMI-AGG-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Reco",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:6198,ERROR,ERROR,6198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 763643, Read name UMI-GAG-TAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 936121, Read name UMI-CGA-TTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Reco",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:6288,ERROR,ERROR,6288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 763881, Read name UMI-AGC-TTT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 936121, Read name UMI-CGA-TTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 964359, Read name UMI-ACT-TAA-16, Zero-length read without FZ, CS or CQ tag; ERROR: Rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:6378,ERROR,ERROR,6378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 764724, Read name UMI-AAT-ATA-14, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764749, Read name UMI-GCT-GTG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 936121, Read name UMI-CGA-TTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 964359, Read name UMI-ACT-TAA-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965939, Read name UMI-GCA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:6468,ERROR,ERROR,6468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 764766, Read name UMI-AGC-TAG-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 936121, Read name UMI-CGA-TTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 964359, Read name UMI-ACT-TAA-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965939, Read name UMI-GCA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965956, Read name UMI-AAA-ATA-37, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966315, Read name UMI-CTC-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:6649,ERROR,ERROR,6649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 764858, Read name UMI-AGA-GGT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 936121, Read name UMI-CGA-TTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 964359, Read name UMI-ACT-TAA-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965939, Read name UMI-GCA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965956, Read name UMI-AAA-ATA-37, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966315, Read name UMI-CTC-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966349, Read name UMI-ACT-GTT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:6739,ERROR,ERROR,6739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 764950, Read name UMI-CTT-GCC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765124, Read name UMI-CGG-TGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765139, Read name UMI-GGA-GTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765157, Read name UMI-ATA-CTC-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765213, Read name UMI-AGC-TCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765249, Read name UMI-AAG-GAT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765281, Read name UMI-AAG-ACT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765385, Read name UMI-CGA-CGT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765535, Read name UMI-GGG-TTG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765582, Read name UMI-ATG-TAA-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765607, Read name UMI-CCG-CTA-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765620, Read name UMI-AAA-ATT-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 765717, Read name UMI-AGG-TAT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 766523, Read name UMI-GAA-GGA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 822437, Read name UMI-AGA-CCT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 936121, Read name UMI-CGA-TTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 964359, Read name UMI-ACT-TAA-16, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965939, Read name UMI-GCA-GTT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 965956, Read name UMI-AAA-ATA-37, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966315, Read name UMI-CTC-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966349, Read name UMI-ACT-GTT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966385, Read name UMI-ATT-GCA-10, Zero-length read without FZ, CS or CQ tag; ERROR: Re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:6829,ERROR,ERROR,6829,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 966315, Read name UMI-CTC-GAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966349, Read name UMI-ACT-GTT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966385, Read name UMI-ATT-GCA-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966397, Read name UMI-ACC-CGG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966402, Read name UMI-CAG-TGT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966417, Read name UMI-CCG-CCT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966450, Read name UMI-CCC-GAT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966462, Read name UMI-CCG-TCT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966487, Read name UMI-GAT-GTT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966491, Read name UMI-GTG-TTG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966501, Read name UMI-AGA-ATG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966509, Read name UMI-AGT-GGT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966514, Read name UMI-ATC-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:8543,ERROR,ERROR,8543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 966349, Read name UMI-ACT-GTT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966385, Read name UMI-ATT-GCA-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966397, Read name UMI-ACC-CGG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966402, Read name UMI-CAG-TGT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966417, Read name UMI-CCG-CCT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966450, Read name UMI-CCC-GAT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966462, Read name UMI-CCG-TCT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966487, Read name UMI-GAT-GTT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966491, Read name UMI-GTG-TTG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966501, Read name UMI-AGA-ATG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966509, Read name UMI-AGT-GGT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966514, Read name UMI-ATC-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:8633,ERROR,ERROR,8633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 966385, Read name UMI-ATT-GCA-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966397, Read name UMI-ACC-CGG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966402, Read name UMI-CAG-TGT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966417, Read name UMI-CCG-CCT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966450, Read name UMI-CCC-GAT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966462, Read name UMI-CCG-TCT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966487, Read name UMI-GAT-GTT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966491, Read name UMI-GTG-TTG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966501, Read name UMI-AGA-ATG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966509, Read name UMI-AGT-GGT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966514, Read name UMI-ATC-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:8723,ERROR,ERROR,8723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 966402, Read name UMI-CAG-TGT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966417, Read name UMI-CCG-CCT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966450, Read name UMI-CCC-GAT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966462, Read name UMI-CCG-TCT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966487, Read name UMI-GAT-GTT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966491, Read name UMI-GTG-TTG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966501, Read name UMI-AGA-ATG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966509, Read name UMI-AGT-GGT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966514, Read name UMI-ATC-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966699, Read name UMI-CCG-TGA-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966722, Read name UMI-AGG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: R",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:8904,ERROR,ERROR,8904,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 966417, Read name UMI-CCG-CCT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966450, Read name UMI-CCC-GAT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966462, Read name UMI-CCG-TCT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966487, Read name UMI-GAT-GTT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966491, Read name UMI-GTG-TTG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966501, Read name UMI-AGA-ATG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966509, Read name UMI-AGT-GGT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966514, Read name UMI-ATC-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966699, Read name UMI-CCG-TGA-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966722, Read name UMI-AGG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966742, Read name UMI-CCG-TCA-5, Zero-length read without FZ, CS or CQ tag; ERROR: R",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:8994,ERROR,ERROR,8994,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," tag; ERROR: Record 966450, Read name UMI-CCC-GAT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966462, Read name UMI-CCG-TCT-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966487, Read name UMI-GAT-GTT-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966491, Read name UMI-GTG-TTG-3, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966501, Read name UMI-AGA-ATG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966509, Read name UMI-AGT-GGT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966514, Read name UMI-ATC-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966699, Read name UMI-CCG-TGA-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966722, Read name UMI-AGG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966742, Read name UMI-CCG-TCA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966752, Read name UMI-GAA-GAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: R",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:9084,ERROR,ERROR,9084,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability," task 35.0 in stage 0.0 (TID 35), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 6.0 in stage 0.0 (TID 6), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 36.0 in stage 0.0 (TID 36), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 28.0 in stage 0.0 (TID 28), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 7.0 in stage 0.0 (TID 7), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 29.0 in stage 0.0 (TID 29), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 8.0 in stage 0.0 (TID 8), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Stage 0 was cancelled** ; **20/03/05 09:28:58 INFO DAGScheduler: ShuffleMapStage 0 (mapToPair at PSFilter.java:125) failed in 63.548 s due to Job aborted due to stage failure: Task 34 in stage 0.0 failed 1 times, most recent failure: Lost task 34.0 in stage 0.0 (TID 34, localhost, executor driver): com.esotericsoftware.kryo.KryoException: Buffer underflow.** ; **at com.esotericsoftware.kryo.io.Input.require(Input.java:199)** ; **at com.esotericsoftware.kryo.io.Input.readLong(Input.java:686)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet.<init>(LongHopscotchSet.java:83)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:527)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet$Serializer.read(LongHopscotchSet.java:519)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:712)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet.<init>(LargeLongHopscotchSet.java:55)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LargeLongHopscotchSet$Serializer.read(LargeLongHopscotchSet.java:172)** ; **at org.br",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:38034,failure,failure,38034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['failure'],['failure']
Availability," the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled ; ; 14:14:36.866 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output ; ; 14:14:36.866 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output ; ; 14:14:36.876 INFO NativeLibraryLoader - Loading libgkl\_utils.so from jar:file:/home/ngs/biosoft/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_utils.so ; ; 14:14:36.878 INFO NativeLibraryLoader - Loading libgkl\_pairhmm\_omp.so from jar:file:/home/ngs/biosoft/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_pairhmm\_omp.so ; ; 14:14:36.927 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM ; ; 14:14:36.928 INFO IntelPairHmm - Available threads: 8 ; ; 14:14:36.928 INFO IntelPairHmm - Requested threads: 4 ; ; 14:14:36.928 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation ; ; 14:14:37.228 INFO ProgressMeter - Starting traversal ; ; 14:14:37.228 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute ; ; 14:14:38.715 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position chr1:10439 and possibly subsequent; at least 10 samples must have called genotypes ; ; 14:14:47.243 INFO ProgressMeter - chr1:186172 0.2 920 5511.7 ; ; 14:14:57.278 INFO ProgressMeter - chr1:830665 0.3 3650 10922.7 ; ; 14:15:05.692 WARN DepthPerSampleHC - Annotation will not be calculated at position chr1:977935 and possibly subsequent; genotype for sample 8939{JXM}-3 is not called ; ; 14:15:05.692 WARN StrandBiasBySample - Annotation will not be calculated at position chr1:977935 and possibly subsequent; genotype for sample 8939{JXM}-3 is not called ; ; 14:15:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7582:4677,Avail,Available,4677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7582,1,['Avail'],['Available']
Availability," the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of sparse representation of the histogram might indeed be desirable, but I think it should be an exact representation of the full histogram. This would require us to sync up code to emit and consume the representation in both Java and python, so I'd like to avoid it if possible---I think I'd prefer just emitting the ragged matrix, in that case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1596,down,down,1596,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522,2,['down'],['down']
Availability," the inconsistency was introduced in the GermlineCNVCaller step. Its possible that you could edit the files manually so that you dont have to rerun all GermlineCNVCaller shards; for example, you could check that all dictionaries in the output of the good shards (i.e., those that contain intervals that are correctly ordered with respect to either dictionary) are the correct dictionary used to generate the count files, reshard/reorder the intervals in the failing shards and rerun GermlineCNVCaller, then stitch everything back together with PostprocessGermlineCNVCalls. However, I think this will be a rather delicate surgery and it may be easy to mess up. I would just recommend fresh runs of GermlineCNVCaller with the correct dictionary and an appropriately ordered interval list. I would go so far as to recommend you delete and/or never use that dictionary againsuch incorrectly ordered dictionaries are a frequent source of heartbreak!. I would say that the code is working as intended and that the error message is sufficiently informative. However, we could certainly fail earlier, before the expensive GermlineCNVCaller step. As mentioned above, we will need to do some work to enable this; I would suggest:. 1) we enable passing of dictionaries from `-L` Picard interval lists at the engine level (and I would add consistency checks if multiple interval lists are provided here as well),; 2) we add checks to all relevant gCNV tools of read-count dictionaries against the intervals dictionary,; 3) we change the behavior of `CopyNumberArgumentValidationUtils.resolveIntervals` so that it fails if provided an unsorted IAC, rather than sorting the contained intervals w.r.t. the count dictionary upon creation of the returned `SimpleIntervalCollection` (this can be done independently of the first two items and would have caused the failing shard to fail earlier; however, the other two items are required to cause all shards to fail earlier),; 4) we revert the change made to Postproc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249:1087,error,error,1087,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249,2,['error'],['error']
Availability," the log file: ```*** Error in `java: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f6830cf2bf8]; [0x7f684dc31f92]; ```. In each of these occurrences, the filtered vcf file was produced, but the vcf.idx file was missing. Although the java errors occur, the last line of the log denotes the step as a success: (This might be true, but only when the option --create-output-variant-index is set to false.; `SetOperationStatus(copied 0 file(s) to <destinations_folder> succeeded""`. I also performed a test based on machine type. (outside of the full workflow, starting the steps on my own on a separate instance & replicating the steps of the workflow); - Using an instance with 2 vCPU's, 7.5 GB of ram, just ran out of memory.; - Using an instance with 8 vCPU's, 30 GB of ram finished successfully, producing both the filtered vcf & vcf.idx",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:2235,error,errors,2235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262,1,['error'],['errors']
Availability," variants, I noticed an inconsistency in how artificial reads are counted towards the AD. Details:. For the variant at position chr15:93002203 with the reference allele G and alternate allele GA, the VCF output shows:; AD=24,6. `chr15	93002203	.	G	GA	73.60	.	AC=1;AF=0.500;AN=2;BaseQRankSum=0.000;DP=34;ExcessHet=3.0103;FS=21.417;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=2.45;ReadPosRankSum=1.481;SOR=1.028	GT:AD:DP:GQ:PL:SB	0/1:24,6:30:81:81,0,597:22,2,2,4; `. Upon reviewing the bamout IGV image, I confirmed that the artificial reads were not considered informative and were therefore not included in the AD calculation, which aligns with the expected behavior. ![image](https://github.com/user-attachments/assets/06117f01-3a9d-41eb-9296-dbd807b067aa). This behavior, where artificial reads are excluded from the AD calculation, is something I have observed across multiple variants, not just the example provided above. However, a different behavior was observed with another variant at position chr1:31662674 with the reference allele G and alternate allele GGGC. The VCF output for this variant shows:; AD=22,4. `chr1	31662674	.	G	GGGC	52.60	.	AC=1;AF=0.500;AN=2;BaseQRankSum=0.692;DP=30;ExcessHet=3.0103;FS=41.746;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=2.02;ReadPosRankSum=-2.529;SOR=3.219	GT:AD:DP:GQ:PL:SB	0/1:22,4:26:60:60,0,911:0,22,4,0`. In this case, the bamout IGV image shows only 2 insertions excluding the artificial reads, yet the AD includes 4, suggesting that the artificial reads were counted. This is contrary to the behavior observed with the first variant, where artificial reads were not counted. ![image](https://github.com/user-attachments/assets/f9fd5325-06ab-4480-99f9-6f56b60a29b7). Why are artificial reads being included in the AD calculation for some variants but not for others? This inconsistency can lead to confusion and potentially affect downstream analyses. I would appreciate any insights or guidance on this issue. Thank you for your support.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8959:2370,down,downstream,2370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8959,1,['down'],['downstream']
Availability," workflows.; [2019-02-22 23:50:02,53] [info] JobExecutionTokenDispenser stopped; [2019-02-22 23:50:02,53] [info] WorkflowStoreActor stopped; [2019-02-22 23:50:02,61] [info] WorkflowLogCopyRouter stopped; [2019-02-22 23:50:02,61] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2019-02-22 23:50:02,61] [info] WorkflowManagerActor All workflows finished; [2019-02-22 23:50:02,61] [info] WorkflowManagerActor stopped; [2019-02-22 23:50:02,61] [info] Connection pools shut down; [2019-02-22 23:50:02,61] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] SubWorkflowStoreActor stopped; [2019-02-22 23:50:02,61] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2019-02-22 23:50:02,61] [info] JobStoreActor stopped; [2019-02-22 23:50:02,61] [info] CallCacheWriteActor stopped; [2019-02-22 23:50:02,61] [info] KvWriteActor Shutting down: 0 queued messages to process; [2019-02-22 23:50:02,61] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2019-02-22 23:50:02,62] [info] DockerHashActor stopped; [2019-02-22 23:50:02,62] [info] IoProxy stopped; [2019-02-22 23:50:02,62] [info] ServiceRegistryActor stopped; [2019-02-22 23:50:02,65] [info] Database closed; [2019-02-22 23:50:02,65] [info] Stream materializer shut down; Workflow 098a389e-b298-4324-8a8c-9f46f05708b5 transitioned to state Failed; [2019-02-22 23:50:02,75] [info] Automatic shutdown of the async connection; [2019-02-22 23:50:02,75] [info] Gracefully shutdown sentry threads.; [2019-02-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:31220,down,down,31220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,12,['down'],['down']
Availability," your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); GATK GenotypeGVCFs. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I conducted joint-call with GATK GenotypeGVCfs for two samples (proband, and mother). I have identified the maternal variant information filled with ""."" in jointcall.vcf which is the output file of GTAK GenotypeGVCfs (see, figure 1). For chromosome MT, all variant information field values were fileld with ""."", instead of mother's g.vcf. . ; ![image](https://user-images.githubusercontent.com/45510932/207542098-cd4af866-c209-405f-9553-3810275f7d8e.png); Figure 1. Jointcall.vcf of proband, and mother. redbox refers to maternal variant information. . . Except for chromosomes X, Y, and MT, these issues did not occur. In addition, I suspected the false positive variants filtering which is the advantage of GATK jointcall. however, the variants which have ""."" values do not seem to be false positive variants considering AD, DP, and variant allele frequency (VAF). #### Steps to reproduce; GATK version used: 3.8.1; ```; java -jar GenomeAnalysisTK-3.8-1-0-gf15c1c3ef/GenomeAnalysisTK.jar \ ; -T GenotypeGVCFs \; -R Homo_sapiens_assembly38.main_chr.fasta \; --variant proband.hg38.g.vcf.gz \; --variant mother.hg38.g.vcf.gz \; -o output_jointcall.vcf \; --logging_level ERROR; ```. #### Expected behavior; variant info (field_value ) not ""."" . #### Actual behavior; filled with "".""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8129:2550,ERROR,ERROR,2550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8129,1,['ERROR'],['ERROR']
Availability," | 6/100 [00:01<00:25, 3.72it/s]; 15:10:07.113 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0014 +/- 0.0019: 7%|7 | 7/100 [00:01<00:24, 3.72it/s]; 15:10:07.381 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0011 +/- 0.0011: 8%|8 | 8/100 [00:02<00:24, 3.72it/s]; 15:10:07.649 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0008 +/- 0.0009: 10%|# | 10/100 [00:02<00:24, 3.72it/s]; 15:10:08.193 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0006: 11%|#1 | 11/100 [00:02<00:24, 3.70it/s]; 15:10:08.463 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0005 +/- 0.0007: 12%|#2 | 12/100 [00:03<00:23, 3.70it/s]; 15:10:08.732 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0007: 13%|#3 | 13/100 [00:03<00:23, 3.70it/s]; 15:10:09.001 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0004 +/- 0.0005: 13%|#3 | 13/100 [00:03<00:25, 3.45it/s]; 15:10:09.002 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1): 0%| | 0/1 [00:00<?, ?it/s]; 15:10:09.003 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1) ploidy update size: 0.200122: 100%|##########| 1/1 [00:00<00:00, 1605.78it/s]; 15:10:09.004 INFO gcnvkernel.tasks.inference_task_base - (denoising) starting...: 0%| | 0/1000 [00:00<?, ?it/s]; 15:10:09.105 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 2) ELBO: -419.253 +/- 160.674, SNR: 8.0, T: 1.79: 4%|3 | 37/1000 [00:00<00:02, 365.67it/s]; 15:10:09.207 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 2) ELBO: -412.997 +/- 158.620, SNR: 7.8, T: 1.79: 7%|7 | 74/1000 [00:00<00:02, 363.49it/s]; 15:10:09.312 INFO gcnvkernel.tasks.inference",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:12758,error,error,12758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['error'],['error']
Availability," 4.5 21980 4841.3 ; ; 22:11:23.401 INFO ProgressMeter - chr5:115188609 4.7 23170 4914.9 ; ; 22:11:33.498 INFO ProgressMeter - chr5:127089898 4.9 24050 4925.7 ; ; 22:11:33.815 INFO HaplotypeCaller - 69572 read(s) filtered by: MappingQualityReadFilter  ; ; 0 read(s) filtered by: MappingQualityAvailableReadFilter  ; ; 0 read(s) filtered by: MappedReadFilter  ; ; 380 read(s) filtered by: NotSecondaryAlignmentReadFilter  ; ; 0 read(s) filtered by: NotDuplicateReadFilter  ; ; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter  ; ; 0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter  ; ; 0 read(s) filtered by: GoodCigarReadFilter  ; ; 0 read(s) filtered by: WellformedReadFilter  ; ; 69952 total reads filtered ; ; 22:11:33.816 INFO ProgressMeter - chr5:127488298 4.9 24105 4931.6 ; ; 22:11:33.816 INFO ProgressMeter - Traversal complete. Processed 24105 total regions in 4.9 minutes. ; ; 22:11:33.891 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 2.883281574 ; ; 22:11:33.891 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 66.287158269 ; ; 22:11:33.891 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 81.56 sec ; ; 22:11:35.558 INFO HaplotypeCaller - Shutting down engine ; ; \[March 12, 2022 10:11:35 PM CET\] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 4.94 minutes. ; ; Runtime.totalMemory()=1998061568. \===========. See forum topic details at forum guidelines page: [https://gatk.broadinstitute.org/hc/en-us/articles/360053845952-Forum-Guidelines](https://gatk.broadinstitute.org/hc/en-us/articles/360053845952-Forum-Guidelines)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/276551'>Zendesk ticket #276551</a>)<br> gz#276551</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:15408,down,down,15408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['down'],['down']
Availability,"!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman1809483713436863458.so+0x177e] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x60e; #; # Core dump written. Default location: /cromwell_root/core or core.24; #; # An error report file with more information is saved as:; # /cromwell_root/hs_err_pid24.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:1635,error,error,1635,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098,2,['error'],['error']
Availability,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Warning: VariantEval is a BETA tool and is not yet ready for use in production !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\[0m 19:35:29.411 INFO VariantEval - Initializing engine 19:35:29.755 INFO FeatureManager - Using codec VCFCodec to read file file:///cromwell\_root/fc-47de7dae-e8e6-429c-b760-b4ba49136eee/joint\_vcfs/recalibrated/PASS/1kgp.chrX.recalibrated.snp\_indel.pass.vcf.gz 19:35:29.835 INFO VariantEval - Done initializing engine 19:35:29.836 INFO PedReader - Reading PED file /cromwell\_root/fc-47de7dae-e8e6-429c-b760-b4ba49136eee/resources/1kgp/1kgp\_trios.ped with missing fields: \[\] 19:35:29.854 INFO PedReader - Phenotype is other? true 19:35:32.686 INFO VariantEval - Creating 1881 combinatorial stratification states 19:35:32.742 INFO ProgressMeter - Starting traversal 19:35:32.742 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute 19:36:01.819 INFO VariantEval - Shutting down engine \[May 27, 2021 7:36:01 PM UTC\] org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval done. Elapsed time: 0.54 minutes. Runtime.totalMemory()=4964483072 java.lang.IndexOutOfBoundsException: Index: 1, Size: 1 at java.util.ArrayList.rangeCheck(ArrayList.java:653) at java.util.ArrayList.get(ArrayList.java:429) at org.broadinstitute.hellbender.utils.samples.MendelianViolation.isViolation(MendelianViolation.java:180) at org.broadinstitute.hellbender.utils.samples.MendelianViolation.updateViolations(MendelianViolation.java:122) at org.broadinstitute.hellbender.utils.samples.MendelianViolation.countFamilyViolations(MendelianViolation.java:148) at org.broadinstitute.hellbender.tools.walkers.varianteval.evaluators.MendelianViolationEvaluator.update1(MendelianViolationEvaluator.java:122) at org.broadinstitute.hellbender.tools.walkers.varianteval.util.EvaluationContext.apply(EvaluationContext.java:74) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.process",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7304:3626,down,down,3626,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7304,1,['down'],['down']
Availability,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 08:33:37.136 INFO FilterAlignmentArtifacts - Initializing engine; 08:33:37.531 INFO FeatureManager - Using codec VCFCodec to read file file:///data/filteredVCF/in2510-8.orientationFilter.vcf; 08:33:37.586 INFO FilterAlignmentArtifacts - Done initializing engine; 08:33:37.668 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 08:33:37.706 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 08:33:37.707 INFO IntelPairHmm - Available threads: 8; 08:33:37.707 INFO IntelPairHmm - Requested threads: 4; 08:33:37.707 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 08:33:37.708 INFO ProgressMeter - Starting traversal; 08:33:37.708 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007ff7b7dfe32d, pid=849, tid=0x00007ff82e11d700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libgkl_smithwaterman5951765478004985534.so+0x132d] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x1bd; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /home/gatk/hs_err_pid849.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. **RELEVANT FILES**; [hs_err_pid100.log](https://github.com/broadinstitute/gat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7162:5483,error,error,5483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7162,1,['error'],['error']
Availability,"![IMG_9960](https://user-images.githubusercontent.com/11076296/95899038-ee88e280-0d5d-11eb-86bf-272687eb9ac0.jpg). Decided to just sit down and go through the exercise of threading all of the parameter sets by hand after biffing it once. Reproducing above; might be helpful for the reviewer if this goes in, but they may want to independently check it. (Is there a way I could've gotten IntelliJ to do this for me?). I would hope that we could do some refactoring to simplify this a bit, if not model ablation or consolidation of parameters, but I won't attempt it for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816:135,down,down,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816,2,['down'],['down']
Availability,"![image](https://github.com/user-attachments/assets/16384849-3364-454d-86c4-5f6338be3530). I followed the suggestion to turn off the downsampling option, but there was no visible change in the results. Below are the igv images after disabling the downsampling:. Variant: chr15 93002203:; ![image](https://github.com/user-attachments/assets/2c75ae9e-2664-4e6c-95cc-97402d0b16fb). Variant: chr1 31662674:. ![image](https://github.com/user-attachments/assets/2685b254-59b2-4ab5-bdc2-bdfbfeb18ae9)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8959#issuecomment-2304618705:133,down,downsampling,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8959#issuecomment-2304618705,2,['down'],['downsampling']
Availability,![image](https://user-images.githubusercontent.com/38786115/40131493-50819d2a-5964-11e8-9e95-3c834521f7b7.png). I guess you've done something. How can I know that the bug has been fixed? How to download and install the new version? Please help. Thank you.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-389590814:194,down,download,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-389590814,1,['down'],['download']
Availability,"""""""""; gatk]# ./gradlew; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; ............................................; Download https://repo1.maven.org/maven2/commons-codec/commons-codec/1.6/commons-codec-1.6.jar; Executing: git lfs pull --include src/main/resources/large. FAILURE: Build failed with an exception. * Where:; Build file '/data/md1/zhouyajun/biotools/gatk/gatk/build.gradle' line: 102. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 1. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED; """"""; what should I do ?; How can I install GATK4 successful?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4669:24,Down,Downloading,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4669,3,"['Down', 'FAILURE']","['Download', 'Downloading', 'FAILURE']"
Availability,"""G1 Refine#80"" os_prio=0 tid=0x00007ff536ea9800 nid=0x1af0e2 runnable . ""G1 Refine#81"" os_prio=0 tid=0x00007ff536eab800 nid=0x1af0e3 runnable . ""G1 Refine#82"" os_prio=0 tid=0x00007ff536ead000 nid=0x1af0e4 runnable . ""G1 Young RemSet Sampling"" os_prio=0 tid=0x00007ff536eaf000 nid=0x1af0e5 runnable ; ""VM Periodic Task Thread"" os_prio=0 tid=0x00007ff5310eb000 nid=0x1af101 waiting on condition . JNI global references: 13. Heap; garbage-first heap total 5378048K, used 1388875K [0x0000000082000000, 0x0000000800000000); region size 4096K, 334 young (1368064K), 1 survivors (4096K); Metaspace used 49722K, capacity 50240K, committed 50768K, reserved 1093632K; class space used 6018K, capacity 6219K, committed 6268K, reserved 1048576K. ; This is the screen log for GGVCFs command, although I was hoping by adding the flag ""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" I would get more information to share. As it takes 11 hours to get to the point where the error occurs it has been difficult to trouble shoot, I am hoping that I can fix this without rebuilding everything which is why I decided to write. Thanks for any information or suggestions you may have. . Dan; ; Using GATK jar /home/dan_vanderpool/src/gatk-4.2.5.0/gatk-package-4.2.5.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx1600g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /home/dan_vanderpool/src/gatk-4.2.5.0/gatk-package-4.2.5.0-local.jar GenotypeGVCFs -R /home/dan_vanderpool/Wolf_raw_reads/Wolf_genome/GCA_905319855.2_mCanLor1.2_genomic.fa -V gendb://Wolf_Genome_Variantsdb -O All_Wolf_Samples_Joint_Genotypes_Raw.vcf.gz -L /scratch/dan/Wolf_reads_raw/Wolf_GenCov300_Q20_Merged.interval_list -imr ALL --genomicsdb-max-alternate-alleles 10 --max-alternate-alleles 6; 17:49:29.781 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/dan_vanderpool/src/gatk-4.2.5.0/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1049112454:3226,error,error,3226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1049112454,1,['error'],['error']
Availability,"""Partition boundaries are not coordinate sorted"" error when running SV tool in local mode on a full BAM with external evidence",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3717:49,error,error,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3717,1,['error'],['error']
Availability,"""fs.gs.project.id"", value);; }; }. if (working_dir.empty()) {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", ""/"");; } else {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", working_dir.c_str());; }. // Default buffer sizes are huge in the GCS connector. GenomicsDB reads/writes in smaller chunks,; // so the buffer size can be made a little smaller.; hdfsBuilderConfSetStr(builder, ""fs.gs.io.buffersize.write"", ""262144"");. hdfsFS hdfs_handle = hdfsBuilderConnect(builder);; free(value);; return hdfs_handle;; }; ```. This is the error from Travis logs-; ```; Running Test: Test method testWriteToAndQueryFromGCS(org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest); hdfsBuilderConnect(forceNewInstance=1, nn=gs://hellbender-test-logs, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:210); at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:75); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1826); Caused by: com.google.api.client.http.HttpResponseException: 404 Not Found; {""error"":""invalid_request"",""error_description"":""Service account not enabled on this instance""}; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1072); at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:159); at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:493); at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:208); ... 77 more; [GenomicsDB::StorageManagerConfig] Error: Error getting hdfs connection: Connection refused.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888:2144,error,error,2144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888,3,"['Error', 'error']","['Error', 'error']"
Availability,"# Bug Report . ### Affected tool(s) or class(es); PathSeq. ### Affected version(s); - 4.1.6.0. ### Description . I wanted to better understand the PathSeq pipeline (and in particular, the Host Filter step) so I simulated RNA-seq reads from three microbial genomes of interest (Salmonella eneterica subsp. enterica serovar Typhimurium str. SL1344, Salmonella eneterica subsp. enterica serovar Typhimurium str. LT2, Fusobacterium nucleatum subsp. nucleatum ATCC 25586). I generate six datasets with 100,000 unpaired reads of length 75 bp (2 datasets from each genome) using Rsubread with simulate.sequencing.error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6705:606,error,error,606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705,3,['error'],['error']
Availability,"# Bug Report. ## Affected tool(s) or class(es); gatk `GenomicsDBImport ` `GenotypeGVCFs`; ## Affected version(s); The Genome Analysis Toolkit (GATK) v4.5.0.0; ## Description; Hi,; Here is my situation, I'm testing the feasibility of incremental GenomicsDBI have total 400 samples to joint calling, I have no problem directly using `GenomicsDBImport `and `GenotypeGVCFs `for joint calling of all 400 samples. The configuration used is 4c32g for `GenomicsDBImport `and 2c16g for `GenotypeGVCFs`. But when I first built a GenomicsDB of 200 samples using `GenomicsDBImport `successfully, and then use GenomicsDB `--genomicsdb-update-workspace-path` increment 200 samples into the GenomicsDB , use this incremental imported GenomicsDB to `GenotypeGVCFs`. The error happend and report GENOMICSDB_TIMER,Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; Here are my code; ```; gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-workspace-path ~{workspace_dir_name}~{prefix}.~{index} \; --batch-size 50 \; -L ~{intervals} \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-update-workspace-path ~{workspace_dir_name} \; --batch-size 50 \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenotypeGVCFs \; --tmp-dir $PWD \; -R ~{ref} \; -O ~{workspace_dir_name}.vcf.gz \; -G StandardAnnotation \; --only-output-calls-starting-in-intervals \; -V gendb://~{workspace_dir_name} \; -L ~{intervals} \; --merge-input-intervals \; -all-sites; ```; And I found that before report error the number of threads used by GATK increased, but the memory usage did not exceed the maximum limit of the server.; I also cheched `--max-alternate-alleles` and `--genomicsdb-max-alternate-al",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8777:755,error,error,755,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8777,1,['error'],['error']
Availability,"# Bug Report. ### Affected tool(s) or class(es); _Mutect2_. ### Affected version(s); - [x] 4.1.5.0 ~ 4.1.8.1. ### Description ; _Mutation with AF ~2.5% missed by Mutect2 paired-calling. It may be related to M2's active region selection module_. #### Steps to reproduce. * Default (both `--force_active` and `--alleles` are OFF)  **No call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O no_call.vcf.gz -L interval.bed --force-active false -verbosity ERROR; ```. * With force_active ON  **Correct call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O force_active.vcf.gz -L interval.bed --force-active true -verbosity ERROR; ```. * With `--alleles` ON (make use of the above force_active results)  **Correct call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O force_alleles.vcf.gz -L interval.bed --force-active false -verbosity ERROR --alleles force_active.vcf.gz; ```. #### Expected behavior. ```; bcftools query -s cancer -f '%CHROM\t%POS\t%REF\t%ALT\t[%AF{0}]\n' force_alleles.vcf.gz; 12	25378562	C	T	0.024; 12	25378660	A	G	0.014; ```. #### Actual behavior; _Empty output_. #### Other information. <details><summary> IGV screen shot of the mutation <code>12:g.25378562C>T</code></summary>; <img width=""1131"" alt=""igv"" src=""https://user-images.githubusercontent.com/4134899/88393449-3861cc80-cdf0-11ea-8e31-1a99b3b21ed9.png"">; </details>. We used the 1000genomes Phase2 Reference Genome Sequence (hs37d5).; ![ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz](ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz). The cancer and matched normal bams (aligned to hs37d5) to reproduce the above behaviors ([data.zip](https://github.com/broadinstitute/gatk/files/4971930/data.zip)). Thanks,; Richard",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6724:492,ERROR,ERROR,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6724,3,['ERROR'],['ERROR']
Availability,"# Feature request . ### Tool(s) or class(es) involved; HaplotypeCaller, CombineGVCFs, GenotypeGVCFs. ### Description; New capability to go backward from a multi-sample vcf generated by CombineGVCFs or GenotypeGVCFs to individual gvcfs so that a user can joint-call again with another cohort.; This request came about because a [user posted on the forum](https://gatk.broadinstitute.org/hc/en-us/community/posts/360060957571-Empty-vcf-after-GenotypeVCFs-when-combining-already-genotyped-samples) the following scenario:. 1. Cohort: VCF with SNPs called with HC per sample and CombineGVCFs, GATK 3.5 (older samples, no bams available.; 2. Cohort: VCF/gVCF/BAM/fastq available (new samples). GATK 4.1.2.0.; Ideally, combine using joint genotype calling from genotype likelihoods (annotations are available in both VCFs - mixed ploidy.). HOWEVER when using CombineGVCFs to combine the two files the result looked incorrect.; `gatk CombineGVCFs -R ref.fasta -V tetra.vcf.gz -V mixed.vcf.gz -O merged.vcf --tmp-dir $TMPDIR`; Result: For ALT alleles it removes the known allele and replaces it with <NON-REF> for all loci. Even if I run CombineGVCFs with just one of the files `gatk CombineGVCFs -R ref.fasta -V tetra.vcf.gz -O foo.vcf`.; When I then run GenotypeGVCFs only the header of the new, called vcf but nothing below the #CHROM line.; `gatk GenotypeGVCFs -R ref.fasta -V merged.vcf -O merged_GT.vcf --tmp-dir $TMPDIR`. The user came up with this approach, but it is not ideal:. grep -vE ""NON_REF"" mixed.vcf > mixed.mod.vcf # removes all loci with NON_REF as ALT; grep -vE ""NON_REF"" tetra.vcf > tetra.mod.vcf; GATK 3.7 CombineVariants; SelectVariants -select 'set == ""Intersection""'. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6596:622,avail,available,622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6596,3,['avail'],['available']
Availability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2411?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@a49f0b3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2411 +/- ##; ==========================================; Coverage ? 76.206% ; Complexity ? 10814 ; ==========================================; Files ? 750 ; Lines ? 39421 ; Branches ? 6859 ; ==========================================; Hits ? 30041 ; Misses ? 6773 ; Partials ? 2607; ```. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2411?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > ` = absolute <relative> (impact)`, ` = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2411?src=pr&el=footer). Last update [a49f0b3...00efddd](https://codecov.io/gh/broadinstitute/gatk/compare/a49f0b30b69eb3de3263cc976f976cd528721cc5...00efddd232b43006ad4f33e51d9387f507efe6ae?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2411#issuecomment-280715503:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2411#issuecomment-280715503,2,['error'],['error-reference']
Availability,"# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@dc15e61`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #2431 +/- ##; ==========================================; Coverage ? 42.757% ; Complexity ? 5801 ; ==========================================; Files ? 750 ; Lines ? 39425 ; Branches ? 6885 ; ==========================================; Hits ? 16857 ; Misses ? 20600 ; Partials ? 1968; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...s/recalibration/covariates/ReadGroupCovariate.java](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL2NvdmFyaWF0ZXMvUmVhZEdyb3VwQ292YXJpYXRlLmphdmE=) | `86.667% <100%> ()` | `11 <0> (?)` | |; | [...dinstitute/hellbender/utils/report/GATKReport.java](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZXBvcnQvR0FUS1JlcG9ydC5qYXZh) | `40.196% <66.667%> ()` | `16 <0> (?)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > ` = absolute <relative> (impact)`, ` = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=footer). Last update [dc15e61...0d5d1b1](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283404250:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283404250,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3041?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@9ca461c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3041 +/- ##; ==========================================; Coverage ? 79.996% ; Complexity ? 16751 ; ==========================================; Files ? 1139 ; Lines ? 60989 ; Branches ? 9443 ; ==========================================; Hits ? 48789 ; Misses ? 8403 ; Partials ? 3797; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3041#issuecomment-306570934:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3041#issuecomment-306570934,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3044?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@6f5bab9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3044 +/- ##; ==========================================; Coverage ? 80.026% ; Complexity ? 16934 ; ==========================================; Files ? 1142 ; Lines ? 61616 ; Branches ? 9594 ; ==========================================; Hits ? 49309 ; Misses ? 8476 ; Partials ? 3831; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3044?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3044?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `71.622% <100%> ()` | `34 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306604461:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306604461,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3158?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@8ab015d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3158 +/- ##; =========================================; Coverage ? 9.901% ; Complexity ? 2034 ; =========================================; Files ? 1145 ; Lines ? 61641 ; Branches ? 9606 ; =========================================; Hits ? 6103 ; Misses ? 54604 ; Partials ? 934; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310720489:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310720489,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@8ab015d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3159 +/- ##; ==========================================; Coverage ? 62.624% ; Complexity ? 12641 ; ==========================================; Files ? 1145 ; Lines ? 61646 ; Branches ? 9606 ; ==========================================; Hits ? 38605 ; Misses ? 19096 ; Partials ? 3945; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `68.224% <100%> ()` | `22 <0> (?)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `69.231% <100%> ()` | `10 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310752620:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310752620,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3817?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@1baf195`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3817 +/- ##; ==========================================; Coverage ? 63.755% ; Complexity ? 13569 ; ==========================================; Files ? 1164 ; Lines ? 64241 ; Branches ? 9815 ; ==========================================; Hits ? 40957 ; Misses ? 19088 ; Partials ? 4196; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3817#issuecomment-343290782:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3817#issuecomment-343290782,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4288?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@e955657`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4288 +/- ##; ========================================; Coverage ? 79.1% ; Complexity ? 16614 ; ========================================; Files ? 1048 ; Lines ? 59579 ; Branches ? 9730 ; ========================================; Hits ? 47127 ; Misses ? 8675 ; Partials ? 3777; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4288?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...pynumber/gcnv/GermlineCNVPostprocessingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4288/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2djbnYvR2VybWxpbmVDTlZQb3N0cHJvY2Vzc2luZ0VuZ2luZS5qYXZh) | `97.143% <100%> ()` | `15 <0> (?)` | |; | [.../tools/copynumber/PostprocessGermlineCNVCalls.java](https://codecov.io/gh/broadinstitute/gatk/pull/4288/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL1Bvc3Rwcm9jZXNzR2VybWxpbmVDTlZDYWxscy5qYXZh) | `81.159% <100%> ()` | `10 <2> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361348945:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361348945,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4431?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@7838ffd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4431 +/- ##; ==========================================; Coverage ? 79.062% ; Complexity ? 16456 ; ==========================================; Files ? 1047 ; Lines ? 59194 ; Branches ? 9675 ; ==========================================; Hits ? 46800 ; Misses ? 8635 ; Partials ? 3759; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4431?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...kers/variantutils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/4431/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `92.308% <100%> ()` | `14 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367163802:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367163802,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4571?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@4416fd5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `11.765%`. ```diff; @@ Coverage Diff @@; ## master #4571 +/- ##; ==========================================; Coverage ? 17.915% ; Complexity ? 8536 ; ==========================================; Files ? 1943 ; Lines ? 146209 ; Branches ? 16146 ; ==========================================; Hits ? 26194 ; Misses ? 117360 ; Partials ? 2655; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4571?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...e/hellbender/engine/FeatureDataSourceUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4571/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2VVbml0VGVzdC5qYXZh) | `1.488% <0%> ()` | `2 <0> (?)` | |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4571/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `57.246% <66.667%> ()` | `32 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-454184426:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-454184426,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4947?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@39a9d13`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `6.58%`. ```diff; @@ Coverage Diff @@; ## master #4947 +/- ##; ==========================================; Coverage ? 13.338% ; Complexity ? 6396 ; ==========================================; Files ? 2016 ; Lines ? 151745 ; Branches ? 16269 ; ==========================================; Hits ? 20240 ; Misses ? 129234 ; Partials ? 2271; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4947?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ute/hellbender/utils/variant/GATKVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4947/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWQ0ZDb25zdGFudHMuamF2YQ==) | `50% <> ()` | `2 <0> (?)` | |; | [...iantutils/PosteriorProbabilitiesUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4947/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9Qb3N0ZXJpb3JQcm9iYWJpbGl0aWVzVXRpbHNVbml0VGVzdC5qYXZh) | `4.386% <> ()` | `1 <0> (?)` | |; | [...te/hellbender/utils/variant/writers/TLODBlock.java](https://codecov.io/gh/broadinstitute/gatk/pull/4947/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvVExPREJsb2NrLmphdmE=) | `0% <> ()` | `0 <0> (?)` | |; | [...notyper/GenotypeCalculationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4947/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <> ()` | `2 <0> (?)` | |; | [...ender/uti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-400384235:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-400384235,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5026?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@cbbbb7a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #5026 +/- ##; ==========================================; Coverage ? 80.255% ; Complexity ? 27182 ; ==========================================; Files ? 1779 ; Lines ? 132169 ; Branches ? 14721 ; ==========================================; Hits ? 106072 ; Misses ? 20971 ; Partials ? 5126; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5026?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...walkers/bqsr/AnalyzeCovariatesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5026/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQW5hbHl6ZUNvdmFyaWF0ZXNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `12.308% <0%> ()` | `2 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-598916467:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-598916467,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5074?src=pr&el=h1) Report; > Merging [#5074](https://codecov.io/gh/broadinstitute/gatk/pull/5074?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/0c39882f4c2290dc664dd8791c5149d5bed330c4?src=pr&el=desc) will **increase** coverage by `<.001%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5074 +/- ##; ===============================================; + Coverage 86.928% 86.928% +<.001% ; + Complexity 30319 30318 -1 ; ===============================================; Files 1849 1849 ; Lines 140737 140738 +1 ; Branches 15476 15475 -1 ; ===============================================; + Hits 122340 122341 +1 ; Misses 12789 12789 ; Partials 5608 5608; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5074?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `100% <100%> ()` | `18 <3> (-3)` | :arrow_down: |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `77.049% <100%> ()` | `10 <2> ()` | :arrow_down: |; | [...llbender/utils/downsampling/MutectDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvTXV0ZWN0RG93bnNhbXBsZXIuamF2YQ==) | `68.182% <100%> ()` | `17 <0> ()` | :arrow_down: |; | [...dinstitute/hellbender/utils/MathUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL3Rlc3Qva,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-434027785:930,down,downsampling,930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-434027785,1,['down'],['downsampling']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5116?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@43750e9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `93.478%`. ```diff; @@ Coverage Diff @@; ## master #5116 +/- ##; ==========================================; Coverage ? 86.707% ; Complexity ? 29097 ; ==========================================; Files ? 1810 ; Lines ? 134816 ; Branches ? 14939 ; ==========================================; Hits ? 116895 ; Misses ? 12521 ; Partials ? 5400; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5116?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...iscovery/TestUtilsForAssemblyBasedSVDiscovery.java](https://codecov.io/gh/broadinstitute/gatk/pull/5116/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvVGVzdFV0aWxzRm9yQXNzZW1ibHlCYXNlZFNWRGlzY292ZXJ5LmphdmE=) | `95.522% <> ()` | `13 <0> (?)` | |; | [...e/hellbender/tools/spark/sv/utils/SVFileUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5116/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkZpbGVVdGlscy5qYXZh) | `24.691% <> ()` | `4 <0> (?)` | |; | [...tsFromContigAlignmentsSAMSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5116/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9EaXNjb3ZlclZhcmlhbnRzRnJvbUNvbnRpZ0FsaWdubWVudHNTQU1TcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `97.561% <> ()` | `6 <0> (?)` | |; | [...der/tools/spark/sv/discovery/SvDiscoveryUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5116/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlcnlVdGlscy5,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5116#issuecomment-413255793:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5116#issuecomment-413255793,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5321?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@8c696a4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `98.765%`. ```diff; @@ Coverage Diff @@; ## master #5321 +/- ##; ==========================================; Coverage ? 86.906% ; Complexity ? 30311 ; ==========================================; Files ? 1849 ; Lines ? 140500 ; Branches ? 15475 ; ==========================================; Hits ? 122103 ; Misses ? 12788 ; Partials ? 5609; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5321?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...er/tools/funcotator/FuncotatorIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5321/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `85.968% <0%> ()` | `111 <0> (?)` | |; | [...Sources/gencode/DataProviderForPik3caTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5321/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvRGF0YVByb3ZpZGVyRm9yUGlrM2NhVGVzdERhdGEuamF2YQ==) | `98.684% <100%> ()` | `3 <0> (?)` | |; | [...dataSources/gencode/GencodeFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5321/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeS5qYXZh) | `86.294% <100%> ()` | `187 <0> (?)` | |; | [...Sources/gencode/DataProviderForMuc16IndelData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5321/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvRGF0Y,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5321#issuecomment-432877680:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5321#issuecomment-432877680,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5576?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@d7d62d4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5576 +/- ##; =========================================; Coverage ? 87.05% ; Complexity ? 31450 ; =========================================; Files ? 1921 ; Lines ? 144996 ; Branches ? 16064 ; =========================================; Hits ? 126219 ; Misses ? 12934 ; Partials ? 5843; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5576?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ine/GATKPlugin/GATKAnnotationPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5576/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `76.582% <> ()` | `57 <0> (?)` | |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5576/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `83.594% <100%> ()` | `49 <1> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5576#issuecomment-454236513:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5576#issuecomment-454236513,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5787?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@d9fd22f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `12.5%`. ```diff; @@ Coverage Diff @@; ## master #5787 +/- ##; ==========================================; Coverage ? 44.104% ; Complexity ? 19589 ; ==========================================; Files ? 1973 ; Lines ? 147147 ; Branches ? 16215 ; ==========================================; Hits ? 64898 ; Misses ? 77129 ; Partials ? 5120; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5787?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...utils/activityprofile/ActivityProfileUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9hY3Rpdml0eXByb2ZpbGUvQWN0aXZpdHlQcm9maWxlVW5pdFRlc3QuamF2YQ==) | `0.442% <0%> ()` | `1 <0> (?)` | |; | [...ils/optimization/PersistenceOptimizerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplclVuaXRUZXN0LmphdmE=) | `2% <0%> ()` | `1 <0> (?)` | |; | [...utils/downsampling/DownsamplingMethodUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRG93bnNhbXBsaW5nTWV0aG9kVW5pdFRlc3QuamF2YQ==) | `3.448% <0%> ()` | `1 <0> (?)` | |; | [...yper/StandardCallerArgumentCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvblVuaXRUZXN0LmphdmE,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5808?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@70d4303`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `57.895%`. ```diff; @@ Coverage Diff @@; ## master #5808 +/- ##; ==========================================; Coverage ? 87.005% ; Complexity ? 32113 ; ==========================================; Files ? 1974 ; Lines ? 147249 ; Branches ? 16218 ; ==========================================; Hits ? 128114 ; Misses ? 13228 ; Partials ? 5907; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5808?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...walkers/genotyper/GenotypingGivenAllelesUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nR2l2ZW5BbGxlbGVzVXRpbHMuamF2YQ==) | `75% <> ()` | `5 <0> (?)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `88.961% <> ()` | `115 <0> (?)` | |; | [...utils/variant/GATKVariantContextUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzVW5pdFRlc3QuamF2YQ==) | `85.885% <100%> ()` | `163 <4> (?)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `84.892% <44.186%> ()` |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5808#issuecomment-474081532:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5808#issuecomment-474081532,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5810?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@70d4303`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5810 +/- ##; ==========================================; Coverage ? 80.318% ; Complexity ? 30474 ; ==========================================; Files ? 1974 ; Lines ? 147194 ; Branches ? 16197 ; ==========================================; Hits ? 118224 ; Misses ? 23270 ; Partials ? 5700; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5810?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5810/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `88.961% <> ()` | `115 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5810#issuecomment-474086066:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5810#issuecomment-474086066,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5823?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@06df7e8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `75.41%`. ```diff; @@ Coverage Diff @@; ## master #5823 +/- ##; ==========================================; Coverage ? 86.834% ; Complexity ? 32337 ; ==========================================; Files ? 1994 ; Lines ? 149405 ; Branches ? 16492 ; ==========================================; Hits ? 129735 ; Misses ? 13654 ; Partials ? 6016; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5823?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ls/copynumber/gcnv/GermlineCNVNamingConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2djbnYvR2VybWxpbmVDTlZOYW1pbmdDb25zdGFudHMuamF2YQ==) | `0% <> ()` | `0 <0> (?)` | |; | [...ons/CopyNumberPosteriorDistributionCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvQ29weU51bWJlclBvc3RlcmlvckRpc3RyaWJ1dGlvbkNvbGxlY3Rpb24uamF2YQ==) | `73.684% <0%> ()` | `6 <0> (?)` | |; | [...mats/collections/BaselineCopyNumberCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvQmFzZWxpbmVDb3B5TnVtYmVyQ29sbGVjdGlvbi5qYXZh) | `63.636% <100%> ()` | `3 <0> (?)` | |; | [...ls/copynumber/formats/records/LinearCopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5823#issuecomment-475397100:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5823#issuecomment-475397100,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5831?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@d27692d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `91.207%`. ```diff; @@ Coverage Diff @@; ## master #5831 +/- ##; ==========================================; Coverage ? 80.122% ; Complexity ? 30691 ; ==========================================; Files ? 1993 ; Lines ? 149366 ; Branches ? 16486 ; ==========================================; Hits ? 119675 ; Misses ? 23893 ; Partials ? 5798; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5831?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...typecaller/PairHMMLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9QYWlySE1NTGlrZWxpaG9vZENhbGN1bGF0aW9uRW5naW5lLmphdmE=) | `87.662% <> ()` | `38 <0> (?)` | |; | [...alkers/genotyper/GenotypeLikelihoodCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUxpa2VsaWhvb2RDYWxjdWxhdG9yLmphdmE=) | `91.667% <> ()` | `46 <0> (?)` | |; | [...oadinstitute/hellbender/utils/pairhmm/PairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1BhaXJITU0uamF2YQ==) | `78.417% <> ()` | `24 <0> (?)` | |; | [...hellbender/utils/pairhmm/VectorLoglessPairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1ZlY3RvckxvZ2xlc3NQYWlySE1NLmphdmE=) | `86.842% <> ()` | `12 <0> (?)` | |; | [...nder/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-475962016:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-475962016,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5887?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@dcff818`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `92.708%`. ```diff; @@ Coverage Diff @@; ## master #5887 +/- ##; ==========================================; Coverage ? 86.825% ; Complexity ? 32305 ; ==========================================; Files ? 1991 ; Lines ? 149187 ; Branches ? 16484 ; ==========================================; Hits ? 129531 ; Misses ? 13641 ; Partials ? 6015; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5887?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...titute/hellbender/utils/IntervalUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzVW5pdFRlc3QuamF2YQ==) | `91.906% <100%> ()` | `146 <0> (?)` | |; | [...nstitute/hellbender/utils/IntervalMergingRule.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbE1lcmdpbmdSdWxlLmphdmE=) | `100% <100%> ()` | `1 <0> (?)` | |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzLmphdmE=) | `92.083% <100%> ()` | `192 <4> (?)` | |; | [...rgumentcollections/IntervalArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvSW50ZXJ2YWxBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `89.063% <88.636%> ()` | `24 <1> (?)` | |; | [...entcollections/IntervalArgumentCollectionTest.java](,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-483884075:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-483884075,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5913?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@00f1e43`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `73.997%`. ```diff; @@ Coverage Diff @@; ## master #5913 +/- ##; ==========================================; Coverage ? 78.979% ; Complexity ? 30649 ; ==========================================; Files ? 2003 ; Lines ? 150459 ; Branches ? 16657 ; ==========================================; Hits ? 118831 ; Misses ? 25832 ; Partials ? 5796; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5913?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...lkers/coverage/DepthOfCoverageIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvdmVyYWdlL0RlcHRoT2ZDb3ZlcmFnZUludGVncmF0aW9uVGVzdC5qYXZh) | `0.758% <0.758%> ()` | `1 <1> (?)` | |; | [...nstitute/hellbender/utils/IntervalMergingRule.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbE1lcmdpbmdSdWxlLmphdmE=) | `100% <100%> ()` | `1 <0> (?)` | |; | [...org/broadinstitute/hellbender/utils/BaseUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9CYXNlVXRpbHMuamF2YQ==) | `88.462% <100%> ()` | `59 <3> (?)` | |; | [...itute/hellbender/engine/LocusWalkerByInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTG9jdXNXYWxrZXJCeUludGVydmFsLmphdmE=) | `100% <100%> ()` | `7 <7> (?)` | |; | [...llbender/engine/LocusWalkerByIntervalUnitTest.java](https://codecov.i,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-489247144:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-489247144,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5949?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@8e78dc6`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `71.429%`. ```diff; @@ Coverage Diff @@; ## master #5949 +/- ##; ==========================================; Coverage ? 80.152% ; Complexity ? 31063 ; ==========================================; Files ? 2016 ; Lines ? 151429 ; Branches ? 16623 ; ==========================================; Hits ? 121373 ; Misses ? 24201 ; Partials ? 5855; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5949?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5949/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> ()` | `0 <0> (?)` | |; | [...rk/pipelines/BQSRPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5949/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `2.381% <0%> ()` | `1 <0> (?)` | |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5949/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `100% <100%> ()` | `5 <0> (?)` | |; | [...ender/tools/ApplyBQSRUniqueArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5949/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9BcHBseUJRU1JVbmlxdWVBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> ()` | `2 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5949#issuecomment-493932361:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5949#issuecomment-493932361,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5966?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@1a290ae`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5966 +/- ##; ==========================================; Coverage ? 86.934% ; Complexity ? 32787 ; ==========================================; Files ? 2014 ; Lines ? 151468 ; Branches ? 16642 ; ==========================================; Hits ? 131677 ; Misses ? 13729 ; Partials ? 6062; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5966#issuecomment-495791725:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5966#issuecomment-495791725,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/6004?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@20190cb`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `18.142%`. ```diff; @@ Coverage Diff @@; ## master #6004 +/- ##; ==========================================; Coverage ? 72.222% ; Complexity ? 27019 ; ==========================================; Files ? 2017 ; Lines ? 151440 ; Branches ? 16623 ; ==========================================; Hits ? 109373 ; Misses ? 36760 ; Partials ? 5307; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/6004?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...titute/hellbender/tools/walkers/GenotypeGVCFs.java](https://codecov.io/gh/broadinstitute/gatk/pull/6004/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `0% <0%> ()` | `0 <0> (?)` | |; | [...ellbender/tools/walkers/GenotypeGVCFsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6004/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnNVbml0VGVzdC5qYXZh) | `100% <100%> ()` | `21 <3> (?)` | |; | [.../hellbender/tools/walkers/GenotypeGVCFsEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/6004/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnNFbmdpbmUuamF2YQ==) | `15.094% <15.094%> ()` | `17 <17> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6004#issuecomment-502738494:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6004#issuecomment-502738494,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/6011?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@41db9df`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `0.714%`. ```diff; @@ Coverage Diff @@; ## master #6011 +/- ##; =========================================; Coverage ? 7.002% ; Complexity ? 2962 ; =========================================; Files ? 1998 ; Lines ? 150096 ; Branches ? 16654 ; =========================================; Hits ? 10509 ; Misses ? 138811 ; Partials ? 776; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/6011?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/6011/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `59.259% <> ()` | `65 <0> (?)` | |; | [...rgumentcollections/IntervalArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/6011/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvSW50ZXJ2YWxBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `47.917% <> ()` | `11 <0> (?)` | |; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/6011/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `40.909% <> ()` | `17 <0> (?)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/6011/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `21.333% <> ()` | `9 <0> (?)` | |; | [...ute/hellbender/utils/variant/GATKVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6011#issuecomment-520059698:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6011#issuecomment-520059698,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/6033?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@1a290ae`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `96.804%`. ```diff; @@ Coverage Diff @@; ## master #6033 +/- ##; ==========================================; Coverage ? 87.212% ; Complexity ? 32721 ; ==========================================; Files ? 2017 ; Lines ? 150990 ; Branches ? 16122 ; ==========================================; Hits ? 131681 ; Misses ? 13704 ; Partials ? 5605; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/6033?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...otator/dataSources/gencode/GencodeFuncotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/6033/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uLmphdmE=) | `74% <> ()` | `185 <0> (?)` | |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/6033/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `80.303% <> ()` | `24 <0> (?)` | |; | [...dataSources/gencode/GencodeFuncotationBuilder.java](https://codecov.io/gh/broadinstitute/gatk/pull/6033/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uQnVpbGRlci5qYXZh) | `96.825% <> ()` | `30 <0> (?)` | |; | [...ces/gencode/GencodeFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6033/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFj,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6033#issuecomment-511019437:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6033#issuecomment-511019437,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/6039?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@f499656`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `81.513%`. ```diff; @@ Coverage Diff @@; ## master #6039 +/- ##; ==========================================; Coverage ? 87.572% ; Complexity ? 36801 ; ==========================================; Files ? 2044 ; Lines ? 166417 ; Branches ? 19264 ; ==========================================; Hits ? 145735 ; Misses ? 14365 ; Partials ? 6317; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/6039?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...itute/hellbender/utils/report/GATKReportTable.java](https://codecov.io/gh/broadinstitute/gatk/pull/6039/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZXBvcnQvR0FUS1JlcG9ydFRhYmxlLmphdmE=) | `70.522% <100%> ()` | `68 <1> (?)` | |; | [...lbender/tools/walkers/varianteval/VariantEval.java](https://codecov.io/gh/broadinstitute/gatk/pull/6039/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnRldmFsL1ZhcmlhbnRFdmFsLmphdmE=) | `90.769% <100%> ()` | `144 <3> (?)` | |; | [.../varianteval/AlleleFrequencyQCIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6039/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnRldmFsL0FsbGVsZUZyZXF1ZW5jeVFDSW50ZWdyYXRpb25UZXN0LmphdmE=) | `100% <100%> ()` | `3 <3> (?)` | |; | [...nder/metrics/analysis/AlleleFrequencyQCMetric.java](https://codecov.io/gh/broadinstitute/gatk/pull/6039/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9tZXRyaWNzL2FuYWx5c2lzL0FsbGVsZUZyZXF1ZW5jeVFDTWV0cmljLmphdmE=) | `100% <100%> ()` | `1 <1> (?)` | |; | [...s/varianteva,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6039#issuecomment-511868112:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6039#issuecomment-511868112,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/6042?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@8d88f6e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #6042 +/- ##; ==========================================; Coverage ? 87.013% ; Complexity ? 32636 ; ==========================================; Files ? 2011 ; Lines ? 150967 ; Branches ? 16134 ; ==========================================; Hits ? 131361 ; Misses ? 14021 ; Partials ? 5585; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-515177272:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-515177272,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/6043?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@1f31a80`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #6043 +/- ##; ==========================================; Coverage ? 44.078% ; Complexity ? 20088 ; ==========================================; Files ? 2011 ; Lines ? 151051 ; Branches ? 16160 ; ==========================================; Hits ? 66580 ; Misses ? 79486 ; Partials ? 4985; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/6043?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...er/tools/AnalyzeSaturationMutagenesisUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6043/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9BbmFseXplU2F0dXJhdGlvbk11dGFnZW5lc2lzVW5pdFRlc3QuamF2YQ==) | `0.794% <0%> ()` | `2 <0> (?)` | |; | [...hellbender/tools/AnalyzeSaturationMutagenesis.java](https://codecov.io/gh/broadinstitute/gatk/pull/6043/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9BbmFseXplU2F0dXJhdGlvbk11dGFnZW5lc2lzLmphdmE=) | `4.601% <0%> ()` | `0 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6043#issuecomment-511968615:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6043#issuecomment-511968615,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/6054?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@5862989`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `92.032%`. ```diff; @@ Coverage Diff @@; ## master #6054 +/- ##; ==========================================; Coverage ? 87.219% ; Complexity ? 32747 ; ==========================================; Files ? 2013 ; Lines ? 151200 ; Branches ? 16144 ; ==========================================; Hits ? 131875 ; Misses ? 13707 ; Partials ? 5618; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/6054?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [.../hellbender/utils/read/ArtificialReadIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/6054/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0FydGlmaWNpYWxSZWFkSXRlcmF0b3IuamF2YQ==) | `89.655% <100%> ()` | `11 <0> (?)` | |; | [...g/broadinstitute/hellbender/engine/ReadWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/6054/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZFdhbGtlci5qYXZh) | `91.176% <57.143%> ()` | `16 <1> (?)` | |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/6054/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `87.719% <75%> ()` | `103 <1> (?)` | |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/6054/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `90.21% <78.947%> ()` | `64 <14> (?)` | |; | [...RecordAlignmentStartIntervalFilteringIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6054#issuecomment-514429017:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6054#issuecomment-514429017,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/6055?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@74418c3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #6055 +/- ##; =========================================; Coverage ? 7.015% ; Complexity ? 2991 ; =========================================; Files ? 2011 ; Lines ? 150930 ; Branches ? 16124 ; =========================================; Hits ? 10588 ; Misses ? 139581 ; Partials ? 761; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/6055?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...nder/utils/genotyper/UnfilledReadsLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/6055/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvVW5maWxsZWRSZWFkc0xpa2VsaWhvb2RzLmphdmE=) | `0% <> ()` | `0 <0> (?)` | |; | [...institute/hellbender/utils/haplotype/EventMap.java](https://codecov.io/gh/broadinstitute/gatk/pull/6055/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvRXZlbnRNYXAuamF2YQ==) | `0% <> ()` | `0 <0> (?)` | |; | [...otypecaller/HaplotypeCallerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/6055/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <> ()` | `0 <0> (?)` | |; | [...ender/utils/genotyper/ReadLikelihoodsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6055/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvUmVhZExpa2VsaWhvb2RzVW5pdFRlc3QuamF2YQ==) | `2.731% <0%> ()` | `1 <0> (?)` | |; | [...plotypecaller/HaplotypeCallerGenotyping,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-514504406:232,error,error-reference,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-514504406,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7742?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e4c4bfc`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7742 +/- ##; ================================================; Coverage ? 86.282% ; Complexity ? 35195 ; ================================================; Files ? 2170 ; Lines ? 164904 ; Branches ? 17787 ; ================================================; Hits ? 142283 ; Misses ? 16296 ; Partials ? 6325 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7742#issuecomment-1125434428:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7742#issuecomment-1125434428,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7756?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@75b5115`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7756 +/- ##; ================================================; Coverage ? 86.305% ; Complexity ? 35190 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142262 ; Misses ? 16253 ; Partials ? 6322 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7756#issuecomment-1111607163:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7756#issuecomment-1111607163,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7769?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@2381a09`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7769 +/- ##; ================================================; Coverage ? 86.308% ; Complexity ? 35194 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142267 ; Misses ? 16248 ; Partials ? 6322 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7769#issuecomment-1109234666:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7769#issuecomment-1109234666,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7774?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@ba7a26c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7774 +/- ##; ================================================; Coverage ? 86.294% ; Complexity ? 35196 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17774 ; ================================================; Hits ? 142244 ; Misses ? 16266 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7774#issuecomment-1110190208:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7774#issuecomment-1110190208,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7787?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@75b5115`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7787 +/- ##; ================================================; Coverage ? 86.291% ; Complexity ? 35190 ; ================================================; Files ? 2170 ; Lines ? 164877 ; Branches ? 17780 ; ================================================; Hits ? 142274 ; Misses ? 16281 ; Partials ? 6322 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7787#issuecomment-1109095953:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7787#issuecomment-1109095953,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7804?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@f09b162`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head d6347af differs from pull request most recent head 0322dbb. Consider uploading reports for the commit 0322dbb to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #7804 +/- ##; ================================================; Coverage ? 86.282% ; Complexity ? 35192 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142224 ; Misses ? 16282 ; Partials ? 6331 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7804#issuecomment-1108503194:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7804#issuecomment-1108503194,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7807?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@614a0f7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7807 +/- ##; ================================================; Coverage ? 86.295% ; Complexity ? 35191 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142246 ; Misses ? 16265 ; Partials ? 6326 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7807#issuecomment-1108994517:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7807#issuecomment-1108994517,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7812?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d51a4e5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7812 +/- ##; ================================================; Coverage ? 86.303% ; Complexity ? 35194 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17774 ; ================================================; Hits ? 142260 ; Misses ? 16254 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7812#issuecomment-1109734272:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7812#issuecomment-1109734272,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7813?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@2381a09`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7813 +/- ##; ================================================; Coverage ? 86.295% ; Complexity ? 35192 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142246 ; Misses ? 16265 ; Partials ? 6326 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7813#issuecomment-1109871129:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7813#issuecomment-1109871129,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7814?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@2381a09`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7814 +/- ##; ================================================; Coverage ? 86.305% ; Complexity ? 35192 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142263 ; Misses ? 16250 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7814#issuecomment-1109953501:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7814#issuecomment-1109953501,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7821?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d51a4e5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7821 +/- ##; ================================================; Coverage ? 86.305% ; Complexity ? 35194 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17774 ; ================================================; Hits ? 142262 ; Misses ? 16252 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7821#issuecomment-1113595459:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7821#issuecomment-1113595459,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7822?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d51a4e5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7822 +/- ##; ================================================; Coverage ? 86.280% ; Complexity ? 35189 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142221 ; Misses ? 16286 ; Partials ? 6330 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7822#issuecomment-1113604463:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7822#issuecomment-1113604463,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7823?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d77ebf5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7823 +/- ##; ================================================; Coverage ? 51.397% ; Complexity ? 26413 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 84721 ; Misses ? 74715 ; Partials ? 5401 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7823#issuecomment-1113783540:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7823#issuecomment-1113783540,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7827?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@c1c8154`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7827 +/- ##; ================================================; Coverage ? 86.305% ; Complexity ? 35190 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142262 ; Misses ? 16253 ; Partials ? 6322 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7827#issuecomment-1118672823:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7827#issuecomment-1118672823,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7828?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d51a4e5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7828 +/- ##; ================================================; Coverage ? 86.305% ; Complexity ? 35195 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17774 ; ================================================; Hits ? 142262 ; Misses ? 16253 ; Partials ? 6322 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7828#issuecomment-1118553978:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7828#issuecomment-1118553978,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7829?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@02cbbf1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7829 +/- ##; ================================================; Coverage ? 86.303% ; Complexity ? 35189 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142260 ; Misses ? 16254 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7829#issuecomment-1117949846:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7829#issuecomment-1117949846,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7830?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@02cbbf1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7830 +/- ##; ================================================; Coverage ? 86.305% ; Complexity ? 35190 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142262 ; Misses ? 16253 ; Partials ? 6322 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7830#issuecomment-1117943226:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7830#issuecomment-1117943226,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7831?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@9363f15`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7831 +/- ##; ================================================; Coverage ? 86.290% ; Complexity ? 35196 ; ================================================; Files ? 2170 ; Lines ? 164869 ; Branches ? 17784 ; ================================================; Hits ? 142266 ; Misses ? 16275 ; Partials ? 6328 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7831#issuecomment-1118747922:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7831#issuecomment-1118747922,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7832?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@c1c8154`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 9a902a7 differs from pull request most recent head 89b0c4a. Consider uploading reports for the commit 89b0c4a to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #7832 +/- ##; ================================================; Coverage ? 86.303% ; Complexity ? 35194 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17774 ; ================================================; Hits ? 142260 ; Misses ? 16254 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7832#issuecomment-1118881781:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7832#issuecomment-1118881781,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7834?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@9363f15`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7834 +/- ##; ================================================; Coverage ? 86.303% ; Complexity ? 35189 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142260 ; Misses ? 16254 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7834#issuecomment-1118979716:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7834#issuecomment-1118979716,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7841?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@17a5e5e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7841 +/- ##; ================================================; Coverage ? 86.293% ; Complexity ? 35189 ; ================================================; Files ? 2170 ; Lines ? 164876 ; Branches ? 17784 ; ================================================; Hits ? 142277 ; Misses ? 16276 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7841#issuecomment-1122504396:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7841#issuecomment-1122504396,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7843?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@900651f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head dad538e differs from pull request most recent head 42bfa0b. Consider uploading reports for the commit 42bfa0b to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #7843 +/- ##; ================================================; Coverage ? 86.304% ; Complexity ? 35190 ; ================================================; Files ? 2170 ; Lines ? 164844 ; Branches ? 17783 ; ================================================; Hits ? 142267 ; Misses ? 16254 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7843#issuecomment-1122596759:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7843#issuecomment-1122596759,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7844?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@4e7b1f8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7844 +/- ##; ================================================; Coverage ? 86.296% ; Complexity ? 35196 ; ================================================; Files ? 2170 ; Lines ? 164876 ; Branches ? 17783 ; ================================================; Hits ? 142282 ; Misses ? 16270 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7844#issuecomment-1122778803:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7844#issuecomment-1122778803,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7845?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@bfccaf6`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 96b1120 differs from pull request most recent head 3dc3916. Consider uploading reports for the commit 3dc3916 to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #7845 +/- ##; ================================================; Coverage ? 86.305% ; Complexity ? 35190 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142263 ; Misses ? 16251 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7845#issuecomment-1122825571:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7845#issuecomment-1122825571,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7848?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@4e7b1f8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7848 +/- ##; ================================================; Coverage ? 86.304% ; Complexity ? 35189 ; ================================================; Files ? 2170 ; Lines ? 164837 ; Branches ? 17775 ; ================================================; Hits ? 142261 ; Misses ? 16252 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7848#issuecomment-1125359698:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7848#issuecomment-1125359698,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7850?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6767947`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 0ad3c70 differs from pull request most recent head 5b1eb60. Consider uploading reports for the commit 5b1eb60 to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #7850 +/- ##; ================================================; Coverage ? 86.296% ; Complexity ? 35197 ; ================================================; Files ? 2170 ; Lines ? 164876 ; Branches ? 17783 ; ================================================; Hits ? 142282 ; Misses ? 16270 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7850#issuecomment-1126317411:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7850#issuecomment-1126317411,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7852?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@f58e9b2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7852 +/- ##; ================================================; Coverage ? 86.293% ; Complexity ? 35194 ; ================================================; Files ? 2170 ; Lines ? 164876 ; Branches ? 17783 ; ================================================; Hits ? 142277 ; Misses ? 16276 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7852#issuecomment-1127727087:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7852#issuecomment-1127727087,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7853?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6767947`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7853 +/- ##; ================================================; Coverage ? 86.296% ; Complexity ? 35191 ; ================================================; Files ? 2170 ; Lines ? 164876 ; Branches ? 17784 ; ================================================; Hits ? 142282 ; Misses ? 16270 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7853#issuecomment-1129091045:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7853#issuecomment-1129091045,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7855?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@1dc9776`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7855 +/- ##; ================================================; Coverage ? 86.293% ; Complexity ? 35189 ; ================================================; Files ? 2170 ; Lines ? 164876 ; Branches ? 17784 ; ================================================; Hits ? 142277 ; Misses ? 16276 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7855#issuecomment-1129408216:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7855#issuecomment-1129408216,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7856?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@7388851`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7856 +/- ##; ================================================; Coverage ? 86.282% ; Complexity ? 35188 ; ================================================; Files ? 2170 ; Lines ? 164876 ; Branches ? 17784 ; ================================================; Hits ? 142258 ; Misses ? 16292 ; Partials ? 6326 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7856#issuecomment-1130338054:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7856#issuecomment-1130338054,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7857?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8781b56`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7857 +/- ##; ================================================; Coverage ? 86.240% ; Complexity ? 35196 ; ================================================; Files ? 2173 ; Lines ? 165018 ; Branches ? 17793 ; ================================================; Hits ? 142311 ; Misses ? 16380 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7857#issuecomment-1130350019:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7857#issuecomment-1130350019,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7860?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e7539d5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7860 +/- ##; ================================================; Coverage ? 86.296% ; Complexity ? 35197 ; ================================================; Files ? 2170 ; Lines ? 164877 ; Branches ? 17783 ; ================================================; Hits ? 142282 ; Misses ? 16271 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7860#issuecomment-1130663595:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7860#issuecomment-1130663595,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7862?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@4d30135`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7862 +/- ##; ================================================; Coverage ? 86.290% ; Complexity ? 35190 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142282 ; Misses ? 16281 ; Partials ? 6325 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7862#issuecomment-1132259223:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7862#issuecomment-1132259223,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7868?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@a4ac264`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7868 +/- ##; ================================================; Coverage ? 86.296% ; Complexity ? 35191 ; ================================================; Files ? 2170 ; Lines ? 164876 ; Branches ? 17784 ; ================================================; Hits ? 142281 ; Misses ? 16271 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7868#issuecomment-1136246725:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7868#issuecomment-1136246725,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7870?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@91c33df`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7870 +/- ##; ================================================; Coverage ? 86.291% ; Complexity ? 35191 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142284 ; Misses ? 16280 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7870#issuecomment-1136413584:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7870#issuecomment-1136413584,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7874?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@91c33df`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7874 +/- ##; ================================================; Coverage ? 86.297% ; Complexity ? 35196 ; ================================================; Files ? 2170 ; Lines ? 164876 ; Branches ? 17783 ; ================================================; Hits ? 142283 ; Misses ? 16270 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7874#issuecomment-1140129247:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7874#issuecomment-1140129247,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7878?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@00e7d57`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7878 +/- ##; ================================================; Coverage ? 86.290% ; Complexity ? 35195 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17785 ; ================================================; Hits ? 142282 ; Misses ? 16281 ; Partials ? 6325 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7878#issuecomment-1142724637:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7878#issuecomment-1142724637,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7879?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@91c33df`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7879 +/- ##; ================================================; Coverage ? 86.290% ; Complexity ? 35190 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142282 ; Misses ? 16281 ; Partials ? 6325 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7879#issuecomment-1143880023:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7879#issuecomment-1143880023,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7880?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@b48282e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7880 +/- ##; ================================================; Coverage ? 86.290% ; Complexity ? 35190 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142282 ; Misses ? 16281 ; Partials ? 6325 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7880#issuecomment-1145111544:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7880#issuecomment-1145111544,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7881?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@db90162`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7881 +/- ##; ================================================; Coverage ? 86.291% ; Complexity ? 35196 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17785 ; ================================================; Hits ? 142284 ; Misses ? 16280 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7881#issuecomment-1146203150:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7881#issuecomment-1146203150,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7883?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@00e7d57`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7883 +/- ##; ================================================; Coverage ? 85.961% ; Complexity ? 35055 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17785 ; ================================================; Hits ? 141740 ; Misses ? 16868 ; Partials ? 6280 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7883#issuecomment-1147742409:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7883#issuecomment-1147742409,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7888?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0be4453`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7888 +/- ##; ================================================; Coverage ? 86.291% ; Complexity ? 35196 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17785 ; ================================================; Hits ? 142284 ; Misses ? 16280 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7888#issuecomment-1151455175:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7888#issuecomment-1151455175,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7891?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@727c1da`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7891 +/- ##; ================================================; Coverage ? 86.290% ; Complexity ? 35195 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17785 ; ================================================; Hits ? 142282 ; Misses ? 16281 ; Partials ? 6325 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7891#issuecomment-1154070191:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7891#issuecomment-1154070191,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7894?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8e84f0a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7894 +/- ##; ================================================; Coverage ? 86.288% ; Complexity ? 35194 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17785 ; ================================================; Hits ? 142278 ; Misses ? 16288 ; Partials ? 6322 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7894#issuecomment-1155931969:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7894#issuecomment-1155931969,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7896?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@727c1da`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7896 +/- ##; ================================================; Coverage ? 86.291% ; Complexity ? 35191 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142284 ; Misses ? 16280 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7896#issuecomment-1154463035:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7896#issuecomment-1154463035,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7899?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@727c1da`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7899 +/- ##; ================================================; Coverage ? 86.290% ; Complexity ? 35190 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142282 ; Misses ? 16281 ; Partials ? 6325 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7899#issuecomment-1155041780:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7899#issuecomment-1155041780,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7901?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@727c1da`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7901 +/- ##; ================================================; Coverage ? 86.291% ; Complexity ? 35191 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142284 ; Misses ? 16280 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7901#issuecomment-1155619910:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7901#issuecomment-1155619910,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7902?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@89a7d5d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7902 +/- ##; ================================================; Coverage ? 86.289% ; Complexity ? 35190 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142280 ; Misses ? 16283 ; Partials ? 6325 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7902#issuecomment-1155780693:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7902#issuecomment-1155780693,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7903?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@586f3f7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7903 +/- ##; ================================================; Coverage ? 84.757% ; Complexity ? 34663 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 139754 ; Misses ? 18943 ; Partials ? 6191 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7903#issuecomment-1156612074:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7903#issuecomment-1156612074,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7905?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@00f07e9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7905 +/- ##; ================================================; Coverage ? 86.291% ; Complexity ? 35192 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142283 ; Misses ? 16281 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7905#issuecomment-1157642181:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7905#issuecomment-1157642181,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7906?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8e84f0a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7906 +/- ##; ================================================; Coverage ? 86.291% ; Complexity ? 35191 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142283 ; Misses ? 16281 ; Partials ? 6324 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7906#issuecomment-1157763522:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7906#issuecomment-1157763522,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7912?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@00f07e9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7912 +/- ##; ================================================; Coverage ? 86.288% ; Complexity ? 35188 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142278 ; Misses ? 16287 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7912#issuecomment-1163414469:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7912#issuecomment-1163414469,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7913?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8781b56`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7913 +/- ##; ================================================; Coverage ? 86.286% ; Complexity ? 35188 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142276 ; Misses ? 16289 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7913#issuecomment-1163720997:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7913#issuecomment-1163720997,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7915?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@32a6106`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7915 +/- ##; ================================================; Coverage ? 86.288% ; Complexity ? 35194 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17785 ; ================================================; Hits ? 142278 ; Misses ? 16288 ; Partials ? 6322 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7915#issuecomment-1164475910:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7915#issuecomment-1164475910,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7917?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8781b56`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head d353628 differs from pull request most recent head 46e7b4c. Consider uploading reports for the commit 46e7b4c to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #7917 +/- ##; ================================================; Coverage ? 86.288% ; Complexity ? 35194 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17785 ; ================================================; Hits ? 142278 ; Misses ? 16288 ; Partials ? 6322 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7917#issuecomment-1165634658:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7917#issuecomment-1165634658,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7919?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@4b2cf4b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head cb38cde differs from pull request most recent head 4710dfe. Consider uploading reports for the commit 4710dfe to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #7919 +/- ##; ================================================; Coverage ? 16.934% ; Complexity ? 4702 ; ================================================; Files ? 1375 ; Lines ? 82064 ; Branches ? 13014 ; ================================================; Hits ? 13897 ; Misses ? 66106 ; Partials ? 2061 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7919#issuecomment-1167839916:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7919#issuecomment-1167839916,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7923?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@586f3f7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7923 +/- ##; ================================================; Coverage ? 86.286% ; Complexity ? 35188 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142276 ; Misses ? 16289 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7923#issuecomment-1169381087:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7923#issuecomment-1169381087,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7924?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@586f3f7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7924 +/- ##; ================================================; Coverage ? 85.943% ; Complexity ? 35050 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17785 ; ================================================; Hits ? 141710 ; Misses ? 16895 ; Partials ? 6283 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7924#issuecomment-1170065408:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7924#issuecomment-1170065408,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7925?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@874d615`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7925 +/- ##; ================================================; Coverage ? 86.288% ; Complexity ? 35189 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142278 ; Misses ? 16288 ; Partials ? 6322 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7925#issuecomment-1170374559:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7925#issuecomment-1170374559,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7927?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@28ed209`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7927 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35200 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142321 ; Misses ? 16368 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7927#issuecomment-1172484433:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7927#issuecomment-1172484433,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7929?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@874d615`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7929 +/- ##; ================================================; Coverage ? 86.288% ; Complexity ? 35194 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17785 ; ================================================; Hits ? 142278 ; Misses ? 16288 ; Partials ? 6322 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7929#issuecomment-1176794770:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7929#issuecomment-1176794770,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7931?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@4b2cf4b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7931 +/- ##; ================================================; Coverage ? 86.286% ; Complexity ? 35188 ; ================================================; Files ? 2170 ; Lines ? 164888 ; Branches ? 17786 ; ================================================; Hits ? 142276 ; Misses ? 16289 ; Partials ? 6323 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7931#issuecomment-1178275700:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7931#issuecomment-1178275700,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7932?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`sl_sklearnvarianttrain_scalable@16e686c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head a894c2a differs from pull request most recent head 93eebb0. Consider uploading reports for the commit 93eebb0 to get more accurate results. ```diff; @@ Coverage Diff @@; ## sl_sklearnvarianttrain_scalable #7932 +/- ##; ===================================================================; Coverage ? 87.031% ; Complexity ? 37304 ; ===================================================================; Files ? 2238 ; Lines ? 175124 ; Branches ? 18897 ; ===================================================================; Hits ? 152412 ; Misses ? 16010 ; Partials ? 6702 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7932#issuecomment-1179274550:364,error,error-reference,364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7932#issuecomment-1179274550,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7934?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0f9780a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7934 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35198 ; ================================================; Files ? 2173 ; Lines ? 165003 ; Branches ? 17793 ; ================================================; Hits ? 142300 ; Misses ? 16377 ; Partials ? 6326 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7934#issuecomment-1180482832:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7934#issuecomment-1180482832,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7937?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@63108be`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7937 +/- ##; ================================================; Coverage ? 86.240% ; Complexity ? 35192 ; ================================================; Files ? 2173 ; Lines ? 165003 ; Branches ? 17794 ; ================================================; Hits ? 142298 ; Misses ? 16378 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7937#issuecomment-1182288691:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7937#issuecomment-1182288691,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7939?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d3f63e5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #7939 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17792 ; ================================================; Hits ? 142311 ; Misses ? 16378 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7939#issuecomment-1182575332:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7939#issuecomment-1182575332,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7940?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@63108be`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7940 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35200 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142321 ; Misses ? 16368 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7940#issuecomment-1182715238:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7940#issuecomment-1182715238,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7942?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@201df7f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7942 +/- ##; ================================================; Coverage ? 86.240% ; Complexity ? 35197 ; ================================================; Files ? 2173 ; Lines ? 165003 ; Branches ? 17793 ; ================================================; Hits ? 142298 ; Misses ? 16378 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7942#issuecomment-1183531096:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7942#issuecomment-1183531096,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7943?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@c00e54b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7943 +/- ##; ================================================; Coverage ? 86.240% ; Complexity ? 35192 ; ================================================; Files ? 2173 ; Lines ? 165003 ; Branches ? 17794 ; ================================================; Hits ? 142298 ; Misses ? 16378 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7943#issuecomment-1184764712:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7943#issuecomment-1184764712,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7946?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8781b56`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7946 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17792 ; ================================================; Hits ? 142311 ; Misses ? 16378 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7946#issuecomment-1185630152:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7946#issuecomment-1185630152,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7953?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@210a6ae`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7953 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35205 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17792 ; ================================================; Hits ? 142321 ; Misses ? 16368 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7953#issuecomment-1190703955:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7953#issuecomment-1190703955,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7965?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@fc2b7a8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7965 +/- ##; ================================================; Coverage ? 86.235% ; Complexity ? 35200 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142302 ; Misses ? 16385 ; Partials ? 6329 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7965#issuecomment-1198518836:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7965#issuecomment-1198518836,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7969?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8dd4541`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7969 +/- ##; ================================================; Coverage ? 51.377% ; Complexity ? 26423 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 84780 ; Misses ? 74830 ; Partials ? 5406 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7969#issuecomment-1201465963:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7969#issuecomment-1201465963,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7970?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@3e62331`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7970 +/- ##; ================================================; Coverage ? 79.221% ; Complexity ? 33311 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 130727 ; Misses ? 28117 ; Partials ? 6172 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7970#issuecomment-1203044007:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7970#issuecomment-1203044007,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7971?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@3e62331`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7971 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35200 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142321 ; Misses ? 16368 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7971#issuecomment-1203189860:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7971#issuecomment-1203189860,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7972?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0f7e2fd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7972 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35200 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142321 ; Misses ? 16368 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7972#issuecomment-1203827609:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7972#issuecomment-1203827609,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7974?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@798d4e8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7974 +/- ##; ================================================; Coverage ? 79.218% ; Complexity ? 33309 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 130723 ; Misses ? 28119 ; Partials ? 6174 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7974#issuecomment-1204152000:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7974#issuecomment-1204152000,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7981?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@798d4e8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7981 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35205 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17792 ; ================================================; Hits ? 142321 ; Misses ? 16368 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7981#issuecomment-1209321346:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7981#issuecomment-1209321346,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7985?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@42a9382`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7985 +/- ##; ================================================; Coverage ? 86.243% ; Complexity ? 35203 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17792 ; ================================================; Hits ? 142315 ; Misses ? 16376 ; Partials ? 6325 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7985#issuecomment-1211297727:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7985#issuecomment-1211297727,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7989?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0130bb8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7989 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17792 ; ================================================; Hits ? 142311 ; Misses ? 16378 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7989#issuecomment-1215361098:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7989#issuecomment-1215361098,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7993?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0130bb8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #7993 +/- ##; ================================================; Coverage ? 77.030% ; Complexity ? 21708 ; ================================================; Files ? 1375 ; Lines ? 82251 ; Branches ? 13121 ; ================================================; Hits ? 63358 ; Misses ? 13764 ; Partials ? 5129 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7993#issuecomment-1218457451:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7993#issuecomment-1218457451,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7994?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@bed8af2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7994 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35196 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142311 ; Misses ? 16378 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7994#issuecomment-1218491668:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7994#issuecomment-1218491668,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7995?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@bed8af2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #7995 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17792 ; ================================================; Hits ? 142311 ; Misses ? 16378 ; Partials ? 6327 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7995#issuecomment-1218680553:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7995#issuecomment-1218680553,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7998?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@187fe60`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #7998 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35196 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142311 ; Misses ? 16378 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7998#issuecomment-1223005785:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7998#issuecomment-1223005785,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/7999?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@187fe60`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #7999 +/- ##; ================================================; Coverage ? 86.242% ; Complexity ? 35197 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142313 ; Misses ? 16377 ; Partials ? 6326 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7999#issuecomment-1223117817:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7999#issuecomment-1223117817,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8000?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@187fe60`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8000 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17792 ; ================================================; Hits ? 142311 ; Misses ? 16378 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8000#issuecomment-1226089548:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8000#issuecomment-1226089548,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8001?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@aff1c48`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8001 +/- ##; ================================================; Coverage ? 86.242% ; Complexity ? 35202 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17792 ; ================================================; Hits ? 142313 ; Misses ? 16377 ; Partials ? 6326 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8001#issuecomment-1226096473:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8001#issuecomment-1226096473,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8002?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0d914c5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8002 +/- ##; ================================================; Coverage ? 86.242% ; Complexity ? 35202 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17792 ; ================================================; Hits ? 142313 ; Misses ? 16377 ; Partials ? 6326 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8002#issuecomment-1227340828:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8002#issuecomment-1227340828,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8003?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0d914c5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8003 +/- ##; ================================================; Coverage ? 86.242% ; Complexity ? 35196 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142313 ; Misses ? 16376 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8003#issuecomment-1228797455:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8003#issuecomment-1228797455,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8006?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@76c969d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8006 +/- ##; ================================================; Coverage ? 86.243% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17791 ; ================================================; Hits ? 142304 ; Misses ? 16373 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8006#issuecomment-1230953418:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8006#issuecomment-1230953418,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8008?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d52f05d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8008 +/- ##; ================================================; Coverage ? 86.243% ; Complexity ? 35196 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17792 ; ================================================; Hits ? 142304 ; Misses ? 16373 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8008#issuecomment-1233705189:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8008#issuecomment-1233705189,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8009?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@91c9c9c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8009 +/- ##; ================================================; Coverage ? 42.466% ; Complexity ? 23462 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17791 ; ================================================; Hits ? 70070 ; Misses ? 89631 ; Partials ? 5303 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8009#issuecomment-1234678104:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8009#issuecomment-1234678104,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8010?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d3f63e5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8010 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35196 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142311 ; Misses ? 16378 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8010#issuecomment-1238195271:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8010#issuecomment-1238195271,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8011?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@a1a8e57`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head db85dfc differs from pull request most recent head 43247b7. Consider uploading reports for the commit 43247b7 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8011 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35196 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142311 ; Misses ? 16378 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8011#issuecomment-1238575906:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8011#issuecomment-1238575906,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8012?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@51387f1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head e267ca5 differs from pull request most recent head 39de64e. Consider uploading reports for the commit 39de64e to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8012 +/- ##; ================================================; Coverage ? 86.242% ; Complexity ? 35196 ; ================================================; Files ? 2173 ; Lines ? 165016 ; Branches ? 17793 ; ================================================; Hits ? 142313 ; Misses ? 16376 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8012#issuecomment-1238610329:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8012#issuecomment-1238610329,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8014?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@ff05126`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8014 +/- ##; ================================================; Coverage ? 86.243% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17791 ; ================================================; Hits ? 142304 ; Misses ? 16373 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8014#issuecomment-1239801973:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8014#issuecomment-1239801973,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8016?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@08c1ad7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8016 +/- ##; ================================================; Coverage ? 86.243% ; Complexity ? 35196 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17792 ; ================================================; Hits ? 142304 ; Misses ? 16373 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8016#issuecomment-1241258915:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8016#issuecomment-1241258915,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8018?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@3b74d0a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8018 +/- ##; ================================================; Coverage ? 86.226% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17792 ; ================================================; Hits ? 142277 ; Misses ? 16393 ; Partials ? 6334 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8018#issuecomment-1246697846:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8018#issuecomment-1246697846,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8019?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@08c1ad7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8019 +/- ##; ================================================; Coverage ? 86.244% ; Complexity ? 35197 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17792 ; ================================================; Hits ? 142306 ; Misses ? 16372 ; Partials ? 6326 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8019#issuecomment-1247078773:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8019#issuecomment-1247078773,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8020?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0ef7433`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8020 +/- ##; ================================================; Coverage ? 86.244% ; Complexity ? 35197 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17792 ; ================================================; Hits ? 142306 ; Misses ? 16372 ; Partials ? 6326 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8020#issuecomment-1248635546:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8020#issuecomment-1248635546,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8022?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@53cf8a7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8022 +/- ##; ================================================; Coverage ? 86.244% ; Complexity ? 35202 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17791 ; ================================================; Hits ? 142306 ; Misses ? 16372 ; Partials ? 6326 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8022#issuecomment-1249814365:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8022#issuecomment-1249814365,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8023?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0ef7433`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8023 +/- ##; ================================================; Coverage ? 42.707% ; Complexity ? 23947 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17792 ; ================================================; Hits ? 70468 ; Misses ? 89424 ; Partials ? 5112 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8023#issuecomment-1251113593:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8023#issuecomment-1251113593,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8024?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0ef7433`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8024 +/- ##; ================================================; Coverage ? 86.240% ; Complexity ? 35196 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17792 ; ================================================; Hits ? 142300 ; Misses ? 16376 ; Partials ? 6328 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8024#issuecomment-1251325952:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8024#issuecomment-1251325952,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8026?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0ef7433`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8026 +/- ##; ================================================; Coverage ? 86.244% ; Complexity ? 35202 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17791 ; ================================================; Hits ? 142306 ; Misses ? 16372 ; Partials ? 6326 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8026#issuecomment-1252821765:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8026#issuecomment-1252821765,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8029?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@55668c3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8029 +/- ##; ================================================; Coverage ? 86.219% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17791 ; ================================================; Hits ? 142265 ; Misses ? 16405 ; Partials ? 6334 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8029#issuecomment-1255077969:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8029#issuecomment-1255077969,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8034?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0735df7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8034 +/- ##; ================================================; Coverage ? 43.628% ; Complexity ? 21865 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17792 ; ================================================; Hits ? 71988 ; Misses ? 87583 ; Partials ? 5433 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8034#issuecomment-1258126509:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8034#issuecomment-1258126509,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8038?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@55668c3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8038 +/- ##; ================================================; Coverage ? 86.250% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17792 ; ================================================; Hits ? 142316 ; Misses ? 16361 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8038#issuecomment-1259612166:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8038#issuecomment-1259612166,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8039?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@953f68c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8039 +/- ##; ================================================; Coverage ? 86.190% ; Complexity ? 35202 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17791 ; ================================================; Hits ? 142217 ; Misses ? 16455 ; Partials ? 6332 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8039#issuecomment-1260048714:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8039#issuecomment-1260048714,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8042?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@9994658`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8042 +/- ##; ================================================; Coverage ? 86.249% ; Complexity ? 35200 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17792 ; ================================================; Hits ? 142314 ; Misses ? 16362 ; Partials ? 6328 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8042#issuecomment-1261458954:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8042#issuecomment-1261458954,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8044?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@c7df760`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8044 +/- ##; ================================================; Coverage ? 49.580% ; Complexity ? 25392 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17792 ; ================================================; Hits ? 81809 ; Misses ? 77736 ; Partials ? 5459 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8044#issuecomment-1265577285:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8044#issuecomment-1265577285,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8046?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@b088a5c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8046 +/- ##; ================================================; Coverage ? 86.249% ; Complexity ? 35205 ; ================================================; Files ? 2173 ; Lines ? 165004 ; Branches ? 17791 ; ================================================; Hits ? 142314 ; Misses ? 16362 ; Partials ? 6328 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8046#issuecomment-1268749154:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8046#issuecomment-1268749154,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8047?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@01b2880`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 38e90c3 differs from pull request most recent head 07c6b83. Consider uploading reports for the commit 07c6b83 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8047 +/- ##; ================================================; Coverage ? 16.953% ; Complexity ? 4702 ; ================================================; Files ? 1375 ; Lines ? 82247 ; Branches ? 13121 ; ================================================; Hits ? 13943 ; Misses ? 66245 ; Partials ? 2059 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8047#issuecomment-1270103549:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8047#issuecomment-1270103549,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8051?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@5f1f998`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8051 +/- ##; ================================================; Coverage ? 86.248% ; Complexity ? 35205 ; ================================================; Files ? 2173 ; Lines ? 165012 ; Branches ? 17791 ; ================================================; Hits ? 142319 ; Misses ? 16365 ; Partials ? 6328 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8051#issuecomment-1276533038:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8051#issuecomment-1276533038,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8052?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@1c5c486`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8052 +/- ##; ================================================; Coverage ? 86.242% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17794 ; ================================================; Hits ? 142334 ; Misses ? 16379 ; Partials ? 6328 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8052#issuecomment-1276585423:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8052#issuecomment-1276585423,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8055?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@b338cc9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 04f2d5a differs from pull request most recent head 6b737da. Consider uploading reports for the commit 6b737da to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8055 +/- ##; ================================================; Coverage ? 86.233% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165012 ; Branches ? 17791 ; ================================================; Hits ? 142294 ; Misses ? 16388 ; Partials ? 6330 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8055#issuecomment-1279486249:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8055#issuecomment-1279486249,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8056?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@1c5c486`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8056 +/- ##; ================================================; Coverage ? 86.189% ; Complexity ? 35197 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17794 ; ================================================; Hits ? 142248 ; Misses ? 16464 ; Partials ? 6329 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8056#issuecomment-1277830813:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8056#issuecomment-1277830813,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8058?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@4c8abaa`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8058 +/- ##; ================================================; Coverage ? 84.277% ; Complexity ? 34793 ; ================================================; Files ? 2191 ; Lines ? 166324 ; Branches ? 17898 ; ================================================; Hits ? 140173 ; Misses ? 19933 ; Partials ? 6218 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8058#issuecomment-1281360109:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8058#issuecomment-1281360109,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8061?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@2a8c210`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8061 +/- ##; ================================================; Coverage ? 77.048% ; Complexity ? 21714 ; ================================================; Files ? 1375 ; Lines ? 82250 ; Branches ? 13121 ; ================================================; Hits ? 63372 ; Misses ? 13749 ; Partials ? 5129 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8061#issuecomment-1282735799:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8061#issuecomment-1282735799,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8062?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@bde383b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8062 +/- ##; ================================================; Coverage ? 16.944% ; Complexity ? 4702 ; ================================================; Files ? 1375 ; Lines ? 82077 ; Branches ? 13014 ; ================================================; Hits ? 13907 ; Misses ? 66109 ; Partials ? 2061 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8062#issuecomment-1282984387:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8062#issuecomment-1282984387,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8065?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@f2dcc68`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8065 +/- ##; ================================================; Coverage ? 86.249% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17794 ; ================================================; Hits ? 142346 ; Misses ? 16369 ; Partials ? 6326 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8065#issuecomment-1285833953:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8065#issuecomment-1285833953,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8066?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@116db44`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8066 +/- ##; ================================================; Coverage ? 86.250% ; Complexity ? 35205 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17793 ; ================================================; Hits ? 142348 ; Misses ? 16367 ; Partials ? 6326 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8066#issuecomment-1286206647:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8066#issuecomment-1286206647,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8072?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@4c8abaa`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8072 +/- ##; ================================================; Coverage ? 86.251% ; Complexity ? 35201 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17794 ; ================================================; Hits ? 142350 ; Misses ? 16366 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8072#issuecomment-1289703869:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8072#issuecomment-1289703869,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8073?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@116db44`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8073 +/- ##; ================================================; Coverage ? 44.264% ; Complexity ? 24497 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17793 ; ================================================; Hits ? 73053 ; Misses ? 86738 ; Partials ? 5250 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8073#issuecomment-1291001159:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8073#issuecomment-1291001159,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8077?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@290fd23`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8077 +/- ##; ================================================; Coverage ? 86.203% ; Complexity ? 35186 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142274 ; Misses ? 16439 ; Partials ? 6332 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8077#issuecomment-1294050838:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8077#issuecomment-1294050838,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8078?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e6d736b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8078 +/- ##; ================================================; Coverage ? 86.226% ; Complexity ? 35205 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17793 ; ================================================; Hits ? 142309 ; Misses ? 16399 ; Partials ? 6333 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8078#issuecomment-1295426924:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8078#issuecomment-1295426924,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8079?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@18fa298`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8079 +/- ##; ================================================; Coverage ? 86.191% ; Complexity ? 35200 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17794 ; ================================================; Hits ? 142251 ; Misses ? 16460 ; Partials ? 6330 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8079#issuecomment-1295446038:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8079#issuecomment-1295446038,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8082?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@31e8cb7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8082 +/- ##; ================================================; Coverage ? 85.912% ; Complexity ? 35063 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17793 ; ================================================; Hits ? 141790 ; Misses ? 16969 ; Partials ? 6282 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8082#issuecomment-1297544446:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8082#issuecomment-1297544446,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8085?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@7dd6ede`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8085 +/- ##; ================================================; Coverage ? 84.371% ; Complexity ? 34536 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17793 ; ================================================; Hits ? 139246 ; Misses ? 19641 ; Partials ? 6154 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8085#issuecomment-1305698326:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8085#issuecomment-1305698326,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8086?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d1907a8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 308c703 differs from pull request most recent head bd65357. Consider uploading reports for the commit bd65357 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8086 +/- ##; ================================================; Coverage ? 86.240% ; Complexity ? 35200 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17794 ; ================================================; Hits ? 142331 ; Misses ? 16382 ; Partials ? 6328 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8086#issuecomment-1305784256:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8086#issuecomment-1305784256,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8093?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@dfe7b7e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8093 +/- ##; ================================================; Coverage ? 19.702% ; Complexity ? 10708 ; ================================================; Files ? 2173 ; Lines ? 164868 ; Branches ? 17686 ; ================================================; Hits ? 32482 ; Misses ? 129238 ; Partials ? 3148 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8093#issuecomment-1314262080:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8093#issuecomment-1314262080,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8096?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@aa97a09`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8096 +/- ##; ================================================; Coverage ? 55.872% ; Complexity ? 15813 ; ================================================; Files ? 1375 ; Lines ? 82251 ; Branches ? 13123 ; ================================================; Hits ? 45955 ; Misses ? 32140 ; Partials ? 4156 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8096#issuecomment-1316030315:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8096#issuecomment-1316030315,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8101?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@08048f1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8101 +/- ##; ================================================; Coverage ? 86.139% ; Complexity ? 35079 ; ================================================; Files ? 2173 ; Lines ? 164868 ; Branches ? 17686 ; ================================================; Hits ? 142015 ; Misses ? 16519 ; Partials ? 6334 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8101#issuecomment-1322778840:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8101#issuecomment-1322778840,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8104?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@31c3a02`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 8166c60 differs from pull request most recent head 9533722. Consider uploading reports for the commit 9533722 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8104 +/- ##; ================================================; Coverage ? 86.246% ; Complexity ? 35202 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 142345 ; Misses ? 16375 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8104#issuecomment-1325273610:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8104#issuecomment-1325273610,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8108?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@335a1b1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8108 +/- ##; ================================================; Coverage ? 86.210% ; Complexity ? 35186 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17794 ; ================================================; Hits ? 142282 ; Misses ? 16426 ; Partials ? 6333 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8108#issuecomment-1331122539:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8108#issuecomment-1331122539,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8109?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@335a1b1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8109 +/- ##; ================================================; Coverage ? 86.171% ; Complexity ? 35132 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17794 ; ================================================; Hits ? 142218 ; Misses ? 16477 ; Partials ? 6346 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8109#issuecomment-1331159839:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8109#issuecomment-1331159839,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8110?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@335a1b1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8110 +/- ##; ================================================; Coverage ? 86.240% ; Complexity ? 35194 ; ================================================; Files ? 2173 ; Lines ? 165041 ; Branches ? 17794 ; ================================================; Hits ? 142331 ; Misses ? 16383 ; Partials ? 6327 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8110#issuecomment-1331168379:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8110#issuecomment-1331168379,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8113?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@aa97a09`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8113 +/- ##; ================================================; Coverage ? 86.170% ; Complexity ? 35132 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142220 ; Misses ? 16479 ; Partials ? 6346 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8113#issuecomment-1331332637:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8113#issuecomment-1331332637,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8116?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@1412b4e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8116 +/- ##; ================================================; Coverage ? 86.137% ; Complexity ? 35078 ; ================================================; Files ? 2173 ; Lines ? 164868 ; Branches ? 17686 ; ================================================; Hits ? 142013 ; Misses ? 16520 ; Partials ? 6335 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8116#issuecomment-1332758896:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8116#issuecomment-1332758896,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8117?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@116db44`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8117 +/- ##; ================================================; Coverage ? 79.143% ; Complexity ? 33242 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 130622 ; Misses ? 28231 ; Partials ? 6192 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8117#issuecomment-1334429236:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8117#issuecomment-1334429236,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8119?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`rc-vs-651-vat-from-vds@1ae6f4a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## rc-vs-651-vat-from-vds #8119 +/- ##; ==========================================================; Coverage ? 62.890% ; Complexity ? 17159 ; ==========================================================; Files ? 1375 ; Lines ? 82251 ; Branches ? 13123 ; ==========================================================; Hits ? 51728 ; Misses ? 25370 ; Partials ? 5153 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8119#issuecomment-1337575778:355,error,error-reference,355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8119#issuecomment-1337575778,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8133?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@080d66a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8133 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35194 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142336 ; Misses ? 16384 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8133#issuecomment-1355614082:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8133#issuecomment-1355614082,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8135?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@080d66a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8135 +/- ##; ================================================; Coverage ? 86.241% ; Complexity ? 35194 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142336 ; Misses ? 16384 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8135#issuecomment-1358492963:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8135#issuecomment-1358492963,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8137?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@ea3408b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8137 +/- ##; ================================================; Coverage ? 86.242% ; Complexity ? 35199 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 142338 ; Misses ? 16383 ; Partials ? 6324 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8137#issuecomment-1363384269:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8137#issuecomment-1363384269,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8144?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@20409d9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8144 +/- ##; ================================================; Coverage ? 86.238% ; Complexity ? 35194 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142332 ; Misses ? 16387 ; Partials ? 6326 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8144#issuecomment-1371289099:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8144#issuecomment-1371289099,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8150?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6f2e75a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8150 +/- ##; ================================================; Coverage ? 84.446% ; Complexity ? 34169 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 139374 ; Misses ? 19292 ; Partials ? 6379 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8150#issuecomment-1376340935:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8150#issuecomment-1376340935,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8153?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@498a4a6`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8153 +/- ##; ================================================; Coverage ? 85.905% ; Complexity ? 35059 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 141782 ; Misses ? 16981 ; Partials ? 6282 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8153#issuecomment-1378671783:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8153#issuecomment-1378671783,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8155?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@700dacd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8155 +/- ##; ================================================; Coverage ? 67.594% ; Complexity ? 26719 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 111561 ; Misses ? 48033 ; Partials ? 5451 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8155#issuecomment-1378826600:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8155#issuecomment-1378826600,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8156?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@c15e5fc`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8156 +/- ##; ================================================; Coverage ? 86.177% ; Complexity ? 35138 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142231 ; Misses ? 16470 ; Partials ? 6344 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8156#issuecomment-1379689850:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8156#issuecomment-1379689850,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8157?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@9cf8021`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8157 +/- ##; ================================================; Coverage ? 86.184% ; Complexity ? 35511 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17900 ; ================================================; Hits ? 143358 ; Misses ? 16593 ; Partials ? 6388 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1380564322:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1380564322,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8162?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@fedb320`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8162 +/- ##; ================================================; Coverage ? 86.243% ; Complexity ? 35202 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 142340 ; Misses ? 16380 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8162#issuecomment-1382239483:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8162#issuecomment-1382239483,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8165?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8a7b95d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8165 +/- ##; ================================================; Coverage ? 86.215% ; Complexity ? 35195 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 142293 ; Misses ? 16420 ; Partials ? 6332 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8165#issuecomment-1397478481:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8165#issuecomment-1397478481,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8168?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@9cf8021`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8168 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35199 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142347 ; Misses ? 16374 ; Partials ? 6324 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8168#issuecomment-1400871943:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8168#issuecomment-1400871943,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8169?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e706dc0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8169 +/- ##; ================================================; Coverage ? 86.219% ; Complexity ? 35515 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17901 ; ================================================; Hits ? 143416 ; Misses ? 16543 ; Partials ? 6380 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8169#issuecomment-1400896867:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8169#issuecomment-1400896867,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8170?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d1a6df3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 5d5908f differs from pull request most recent head e137c8c. Consider uploading reports for the commit e137c8c to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8170 +/- ##; ================================================; Coverage ? 86.218% ; Complexity ? 35514 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17901 ; ================================================; Hits ? 143414 ; Misses ? 16544 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8170#issuecomment-1401219057:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8170#issuecomment-1401219057,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8172?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@9cf8021`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8172 +/- ##; ================================================; Coverage ? 86.245% ; Complexity ? 35202 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 142343 ; Misses ? 16377 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8172#issuecomment-1402434980:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8172#issuecomment-1402434980,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8173?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@50f4af6`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8173 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35199 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142347 ; Misses ? 16374 ; Partials ? 6324 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8173#issuecomment-1402439098:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8173#issuecomment-1402439098,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8176?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@31c3a02`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8176 +/- ##; ================================================; Coverage ? 86.246% ; Complexity ? 35198 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142345 ; Misses ? 16375 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8176#issuecomment-1405870732:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8176#issuecomment-1405870732,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8178?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e706dc0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 9b6b4fa differs from pull request most recent head 8e375d8. Consider uploading reports for the commit 8e375d8 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8178 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35198 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142347 ; Misses ? 16373 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8178#issuecomment-1409174687:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8178#issuecomment-1409174687,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8182?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@5b34ade`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8182 +/- ##; ================================================; Coverage ? 85.857% ; Complexity ? 35511 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18001 ; ================================================; Hits ? 143392 ; Misses ? 17233 ; Partials ? 6387 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8182#issuecomment-1414516070:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8182#issuecomment-1414516070,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8184?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@39070f0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8184 +/- ##; ================================================; Coverage ? 86.218% ; Complexity ? 35518 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17900 ; ================================================; Hits ? 143414 ; Misses ? 16544 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8184#issuecomment-1416270346:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8184#issuecomment-1416270346,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8187?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d07e773`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8187 +/- ##; ================================================; Coverage ? 86.181% ; Complexity ? 35508 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17901 ; ================================================; Hits ? 143352 ; Misses ? 16601 ; Partials ? 6386 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8187#issuecomment-1419548583:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8187#issuecomment-1419548583,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8188?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@31c3a02`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8188 +/- ##; ================================================; Coverage ? 51.610% ; Complexity ? 26737 ; ================================================; Files ? 2191 ; Lines ? 166351 ; Branches ? 17903 ; ================================================; Hits ? 85854 ; Misses ? 75037 ; Partials ? 5460 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8188#issuecomment-1419590366:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8188#issuecomment-1419590366,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8190?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@fedb320`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8190 +/- ##; ================================================; Coverage ? 85.709% ; Complexity ? 35194 ; ================================================; Files ? 2191 ; Lines ? 166158 ; Branches ? 17793 ; ================================================; Hits ? 142413 ; Misses ? 17435 ; Partials ? 6310 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8190#issuecomment-1419925811:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8190#issuecomment-1419925811,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8191?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0c48d6d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 2d6c381 differs from pull request most recent head 90d3e3f. Consider uploading reports for the commit 90d3e3f to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8191 +/- ##; ================================================; Coverage ? 84.437% ; Complexity ? 34485 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17901 ; ================================================; Hits ? 140452 ; Misses ? 19452 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8191#issuecomment-1419999334:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8191#issuecomment-1419999334,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8193?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d07e773`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8193 +/- ##; ================================================; Coverage ? 86.219% ; Complexity ? 35519 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17900 ; ================================================; Hits ? 143416 ; Misses ? 16543 ; Partials ? 6380 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8193#issuecomment-1423309454:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8193#issuecomment-1423309454,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8200?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d07e773`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8200 +/- ##; ================================================; Coverage ? 79.183% ; Complexity ? 33607 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17900 ; ================================================; Hits ? 131713 ; Misses ? 28399 ; Partials ? 6227 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8200#issuecomment-1428533144:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8200#issuecomment-1428533144,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8202?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@ac04b54`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8202 +/- ##; ================================================; Coverage ? 85.888% ; Complexity ? 35518 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18001 ; ================================================; Hits ? 143444 ; Misses ? 17187 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8202#issuecomment-1429860891:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8202#issuecomment-1429860891,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8206?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6f747d0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8206 +/- ##; ================================================; Coverage ? 85.814% ; Complexity ? 35456 ; ================================================; Files ? 2194 ; Lines ? 167015 ; Branches ? 18002 ; ================================================; Hits ? 143323 ; Misses ? 17292 ; Partials ? 6400 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8206#issuecomment-1432090725:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8206#issuecomment-1432090725,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8207?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@5b34ade`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8207 +/- ##; ================================================; Coverage ? 84.116% ; Complexity ? 34488 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18001 ; ================================================; Hits ? 140484 ; Misses ? 20093 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8207#issuecomment-1432118430:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8207#issuecomment-1432118430,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8210?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@ac04b54`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head b78e14c differs from pull request most recent head 977aec0. Consider uploading reports for the commit 977aec0 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8210 +/- ##; ================================================; Coverage ? 85.484% ; Complexity ? 35314 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18000 ; ================================================; Hits ? 142768 ; Misses ? 17893 ; Partials ? 6351 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8210#issuecomment-1433521735:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8210#issuecomment-1433521735,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8216?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@1ce13b3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8216 +/- ##; ================================================; Coverage ? 85.475% ; Complexity ? 35309 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18000 ; ================================================; Hits ? 142754 ; Misses ? 17906 ; Partials ? 6352 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8216#issuecomment-1440250246:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8216#issuecomment-1440250246,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8220?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@fdbaa14`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8220 +/- ##; ================================================; Coverage ? 85.884% ; Complexity ? 35513 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18001 ; ================================================; Hits ? 143436 ; Misses ? 17195 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8220#issuecomment-1442592799:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8220#issuecomment-1442592799,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8225?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0014005`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8225 +/- ##; ================================================; Coverage ? 85.885% ; Complexity ? 35518 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18000 ; ================================================; Hits ? 143438 ; Misses ? 17194 ; Partials ? 6380 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8225#issuecomment-1448458604:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8225#issuecomment-1448458604,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8229?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6d41adf`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8229 +/- ##; ================================================; Coverage ? 83.987% ; Complexity ? 34800 ; ================================================; Files ? 2194 ; Lines ? 167016 ; Branches ? 18003 ; ================================================; Hits ? 140271 ; Misses ? 20518 ; Partials ? 6227 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8229#issuecomment-1450934113:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8229#issuecomment-1450934113,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8230?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@3a7f6e2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8230 +/- ##; ================================================; Coverage ? 85.837% ; Complexity ? 35510 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18004 ; ================================================; Hits ? 143382 ; Misses ? 17269 ; Partials ? 6388 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8230#issuecomment-1450446401:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8230#issuecomment-1450446401,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8236?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@5645e88`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8236 +/- ##; ================================================; Coverage ? 85.694% ; Complexity ? 35399 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18004 ; ================================================; Hits ? 143142 ; Misses ? 17505 ; Partials ? 6392 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8236#issuecomment-1458701401:345,error,error-reference,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8236#issuecomment-1458701401,2,['error'],['error-reference']
Availability,"## Bug Report . ### Affected tool(s) or class(es); PathSeq. ### Affected version(s); version 4.1.6.0. ### Description ; I am pre-aligning a paired-end RNA-seq dataset to the human host genome using STAR. I get a `Uniquely mapped reads %` of 83.24%. Next, I run PathSeqPipelineSpark using `--is-host-aligned true` and the default options. When I look at the filter-metrics file, I see `PRIMARY_READS` = 1,057,098 and `READS_AFTER_PREALIGNED_HOST_FILTER` = 543,664. #### Steps to reproduce; This is on a dataset that I can't share but I'm happy to reproduce this on a publicly available dataset if you need that. . #### Expected behavior; I would expect >= 83.24% of reads to be filtered by the PREALIGNED_HOST_FILTER step. . #### Actual behavior; < 50% of the reads are filtered by the PREALIGNED_HOST_FILTER step. . Do you have any insight into what's going on? Should I be using an aligner other than STAR? Are there RNA-seq specific instructions for running PathSeq?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6687:575,avail,available,575,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6687,1,['avail'],['available']
Availability,"## Bug Report. ### Affected tool(s) or class(es). All Spark tools that takes parameter `-L`. ### Affected version(s); - [x] Latest public release version [4.0.4.0]; - [x] Latest master branch as of [2018-06-30]. ### Description . When running a Spark tool and passing in interval arguments via the standard `-L` argument, if the interval file (only BED file is tested) is stored in HDFS, we see errors like below. ```; org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: Badly formed genome unclippedLoc: Query interval ""hdfs://shuang-g94794-chmi-chmi3-wgs1-cram-bam-feature-m:8020/data/merged_commonFPDel.bed"" is not valid for this input.; 	at org.broadinstitute.hellbender.utils.GenomeLocParser.getUnambiguousInterval(GenomeLocParser.java:350); 	at org.broadinstitute.hellbender.utils.GenomeLocParser.parseGenomeLoc(GenomeLocParser.java:309); 	at org.broadinstitute.hellbender.utils.IntervalUtils.parseIntervalArguments(IntervalUtils.java:300); 	at org.broadinstitute.hellbender.utils.IntervalUtils.loadIntervals(IntervalUtils.java:226); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.parseIntervals(IntervalArgumentCollection.java:174); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.getTraversalParameters(IntervalArgumentCollection.java:155); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.getIntervals(IntervalArgumentCollection.java:111); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeIntervals(GATKSparkTool.java:514); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:451); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:439); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLinePro",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4852:395,error,errors,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4852,1,['error'],['errors']
Availability,"## Bug Report. ### Affected tool(s) or class(es). FastaAlternateReferenceMaker. ### Affected version(s); - [x] Latest public release version 4.1.4.1; - [ ] Latest master branch as of [date of test?]. ### Description . A null pointer exception in . #### Steps to reproduce. We called variants with HaplotypeCaller & use resulting VCF with FastaAlternateReferenceMaker. See command below, but only reference fasta & HC vcf are given as input (no snp masking or interval list, though error also occurs when using interval list with multiple -L calls). #### Expected behavior. Alternate-adjusted reference file or at least a helpful error message. #### Actual behavior. ```; + latest-gatk/gatk-4.1.4.1/gatk FastaAlternateReferenceMaker -R /g/data/xe2/references/eucalyptus/emel_scott/Emelliodora_CSIROg1_SISH00000000.1.fasta -O consensus_sequences_gatk//CCA0704.fasta.tmp -V pergene_gatk/CCA0704/CCA0704.vcf.gz; Using GATK jar /g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar FastaAlternateReferenceMaker -R /g/data/xe2/references/eucalyptus/emel_scott/Emelliodora_CSIROg1_SISH00000000.1.fasta -O consensus_sequences_gatk//CCA0704.fasta.tmp -V pergene_gatk/CCA0704/CCA0704.vcf.gz; 15:43:14.276 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 03, 2020 3:43:15 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:43:15.230 INFO FastaAlternateReferenceMaker - ------------------------------------------------------------; 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6434:448,mask,masking,448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6434,3,"['error', 'mask']","['error', 'masking']"
Availability,## Bug Report. ### Affected tool(s) or class(es). GermlineCNVCaller. ### Affected version(s). - [x] Latest public release version gatk 4.2.0.0; - [ ] Latest master branch as of [date of test?]. ### Description . The same set of hdf5 works fine with another annotated_intervals.tsv . the stack trace:; ```; 11:52:33.788 INFO GermlineCNVCaller - Aggregating read-count file /SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/; 20210411.GRCh37.gatkcnv.brs/work/92/579e5a48aa9e52cd0e1df603266809/B00HOTD.counts.hdf5 (229 / 347); HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 173 in H5Dread(): can'; t read data; major: Dataset; minor: Read failed; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 550 in H5D__read(): ca; n't read data; major: Dataset; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 543 in H5D__contig; _read(): contiguous read failed; major: Dataset; minor: Read failed; #003: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 517 in H5D__scat; gath_read(): file gather failed; major: Low-level I/O; minor: Read failed; #004: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 253 in H5D__gath; er_file(): read error; major: Dataspace; minor: Read failed; #005: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 873 in H5D__contig; _readvv(): can't perform vectorized sieve buffer read; major: Dataset; minor: Can't operate on object; #006: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5VM.c line 1457 in H5VM_opvv(): ca; n't perform operation; major: Internal error (too specific to document in detail); minor: Can't operate on object; #007: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 696 in H5D_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:532,Error,Error,532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['Error'],['Error']
Availability,"## Bug Report. ### Affected tool(s) or class(es). Mutect2; `; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx130g -jar /gatk/gatk-package-4.1.8.1-local.jar Mutect2 -R /ucsc.hg19.fasta -I my.bam -L /test.bed --f1r2-tar-gz DD.f1r2.tar.gz --force-active --genotype-germline-sites --kmer-size 10 --kmer-size 20 --recover-all-dangling-branches --max-reads-per-alignment-start 0 --native-pair-hmm-threads 33 -O DD.vcf.gz; `. ### Affected version(s); Using GATK jar /gatk/gatk-package-4.1.8.1-local.jar. ### Description ; When bed is created with a reference genome that is not the same as the bam file, an null pointer can occurs. The error is not catched by GATK, and the error is difficult to understand. Here a discussion about it.; https://gatk.broadinstitute.org/hc/en-us/community/posts/360077477391-Haplotype-caller-fails-to-run-GATK-4-1-8-0-and-GATK-4-2-0-0-. The case below occurs when provided bed has been made with the wrong genome reference.; `; 14:25:55.254 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 07, 2021 2:25:55 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:25:55.525 INFO Mutect2 - ------------------------------------------------------------; 14:25:55.525 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.1; 14:25:55.525 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:25:55.525 INFO Mutect2 - Executing as toto on Linux v5.4.123-1.el7.elrepo.x86_64 amd64; 14:25:55.525 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 14:25:55.526 INFO Mutect2 - Start Date/Time: October 7, 2021 2:25:55 PM GMT; 14:25:55.526 INFO Mutect2 - -----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7496:426,recover,recover-all-dangling-branches,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7496,3,"['error', 'recover']","['error', 'recover-all-dangling-branches']"
Availability,"## Bug Report. ### Affected tool(s) or class(es). The Genome Analysis Toolkit (GATK) v4.0.7.0. ### Description . I ran the command line below and get an oom error. I've got the same error when i set the heap memory larger using the param ""--java-option Xmx24g"" . This procedure only crashed when I tried to select INDEL. I've uploaded the vcf file for you to test. command line:; ```shell; disk/juntong/software/gatk-4.0.7.0/gatk SelectVariants -V /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gz -O /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gatk.somatic.indel.vcf.gz -select-type INDEL; ```. log:; ```; Using GATK jar /disk/juntong/software/gatk-4.0.7.0/gatk-package-4.0.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /disk/juntong/software/gatk-4.0.7.0/gatk-package-4.0.7.0-local.jar SelectVariants -V /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gz -O /disk/juntong/huada/V300029595_results/mutect_outputs/V300029595.merged.vcf.gatk.somatic.vcf.gatk.somatic.indel.vcf.gz -select-type INDEL; 05:06:54.800 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/disk/juntong/software/gatk-4.0.7.0/gatk-package-4.0.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 05:06:55.409 INFO SelectVariants - ------------------------------------------------------------; 05:06:55.409 INFO SelectVariants - The Genome Analysis Toolkit (GATK) v4.0.7.0; 05:06:55.409 INFO SelectVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 05:06:55.410 INFO SelectVariants - Executing as juntong@train1 on Linux v3.10.0-1062.1.1.el7.x86_64 amd64; 05:06:55.410 INFO SelectVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_222-b10; 05:06:55.410 INFO SelectVariants -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6254:157,error,error,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6254,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es). ValidateVariants: `--fail-gvcf-on-overlap` / `-no-overlaps`. ### Affected version(s); - [x] Latest public release version: 4.2.6.1; - [ ] ~Latest master branch as of~ [did not test, but affected file hasn't changed since August 2021]. ### Description . If there are overlapping reference blocks when running ValidateVariants with the `-no-overlaps` option, a USER ERROR is outputted after the entire tool finishes running, as shown below:. ```; ***********************************************************************. A USER ERROR has occurred: This GVCF contained overlapping reference blocks. The first overlapping interval is [genomic coordinates here]. ***********************************************************************; ```. This error should be generally helpful, but it appears that the interval that is reported in the error message is the _last_ overlapping interval, not the _first_. I'm not super familiar with java, but I'm guessing that `firstOverlap` might be continuously replaced by `refInterval` if there are multiple overlaps, which is inconsistent with expected behavior. . Potentially relevant lines of code: ; - `-no-overlaps` argument description ([lines 192-201](; https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L192-L201)); - `firstOverlap = refInterval` ([line 275](https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L275)). #### Steps to reproduce. Running ValidateVariants with the `-no-overlaps` flag on a .g.vcf with overlapping intervals will cause this error. More specifically, we're running this within WARP's Exome Germline Single Sample v.3.1.7 WDL release. Our command is as follows:. ```; gatk --java-options ""-Xms6000m -Xmx6500m"" \; ValidateVariants ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103:414,ERROR,ERROR,414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es): Mutect2. ### Affected version(s); gatk 4.2.5. ### Description ; Like most use cases, I acquired a high-confidence, ""consensus"" VCF from a large batch of samples, and I run force-calling on each individual sample again to:; (1) rescue rare variants.; (2) for variants that are not called in a sample, get the REF/ALT counts for them for downstream analysis. However, compared to the first pass (where Mutect2 is in simple germline calling mode), the second pass (force-calling) is extremely slow. Sorry I have not done any precise measurement, but the difference is quite significant. Given my use case, do you still recommend using force-calling? Or is there any alternative, more efficient method? I tried using bcftools call, but that tool has several issues as well such as omitting indels, not supporting multiallelic force-calling etc. #### Steps to reproduce. My command for force-calling is:; ```; ""gatk Mutect2 ""; ""-alleles {input.q_vcf} ""; ""-L {input.q_vcf} ""; ""--genotype-filtered-alleles ""; ""--max-reads-per-alignment-start {params.mrpas} ""; ""-R {params.REF} ""; ""-I {input.sc_bam} ""; ""-O {output.sc_vcf}; ""; ```. I can upload some BAMs for testing if needed. Thanks in advance!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7825:386,down,downstream,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7825,1,['down'],['downstream']
Availability,"## Bug Report. ### Affected tool(s) or class(es); ""gatk PostprocessGermlineCNVCalls"". ### Affected version(s); - docker (broadinstitute/gatk, 4.1.9.0 version). ### Description ; #### Steps to reproduce. This is my command line. ; gatk PostprocessGermlineCNVCalls \; --calls-shard-path CALLS_01 \; --model-shard-path MODEL_01 \; --allosomal-contig chrX \; --allosomal-contig chrY \; --autosomal-ref-copy-number 2 \; --contig-ploidy-calls contig-ploidy-calls \; --sample-index 9 \; --output-genotyped-intervals genotyped-intervals-2016001038.vcf.gz \; --output-genotyped-segments genotyped-segments-2016001038.vcf.gz \; --output-denoised-copy-ratios denoised_copy_ratios-2016001038.tsv. #### Error message ; ![image](https://user-images.githubusercontent.com/33537478/119120932-cab21b80-ba67-11eb-9cd3-bb0af7192799.png). #### Expected behavior; generation of following files; genotyped-intervals-2016001038.vcf.gz, genotyped-segments-2016001038.vcf.gz, denoised_copy_ratios-2016001038.tsv . #### Actual behavior; when making a ""genotyped-segments-2016001038.vcf.gz"" file, tool emits this error message. . ![image](https://user-images.githubusercontent.com/33537478/119120932-cab21b80-ba67-11eb-9cd3-bb0af7192799.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7266:690,Error,Error,690,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7266,2,"['Error', 'error']","['Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); - gatk/scripts/cnv_wdl/germline/cnv_germline_case_workflow.wdl; - gatk/scripts/cnv_wdl/germline/cnv_getmline_cohort_workflow.wdl. ### Affected version(s); - **WDL** file from GATK latest release (4.2.5.0); - **GATK Docker** - latest (4.2.5.0). ### Description ; Accoridng to [GATK Germline CNV WDL instructions](https://github.com/broadinstitute/gatk/blob/master/scripts/cnv_wdl/germline/README.md), I ran cnv_getmline_cohort_workflow.wdl and got data to run cnv_germline_case_workflow.wdl. (contig_ploidy_model_tar file and 40 gcnv_model_tars files). Then I tried to run cnv_germline_case_workflow.wdl with one sample and got an error: ; ```; java.lang.IllegalArgumentException: The number of input call shards must match the number of input model shards.; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); 	at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.validateArgum; ```. PostprocessGermlineCNVCalls only completes correctly if I use only one of the gcnv_model_tars files, but it only produces results for the iterval_list file that is included in the used gcnv_model_tars. #### Case mode files; [case.log](https://github.com/broadinstitute/gatk/files/8186658/case.log); [case-inputs.json.txt](https://github.com/broadinstitute/gatk/files/8186662/case-inputs.json.txt). #### Cohort mode files; [cohort.log](https://github.com/broadinstitute/gatk/files/8186665/cohort.log); [cohort-inputs.json.txt](https://github.com/broadinstitute/gatk/files/8186667/cohort-inputs.json.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7706:680,error,error,680,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7706,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); ApplyBQSRSpark. ### Affected version(s); gatk-4.1.9.0. ### Description ; After roughly 1h of running ApplyBQSRSpark on my WGS BAM, it throws the error `java.io.IOException: Bad file descriptor`.; I then used `samtools quickcheck` to validate the integrity of my BAM file and everything seems fine. The BAM file is coordinate sorted and the duplicates are marked. The size of the BAM file is 142GB. #### Steps to reproduce; This is the command I used:. ```bash; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar gatk-package-4.1.9.0-local.jar ApplyBQSRSpark -R ref-genome.fa -I buffy_coat.sorted.markdup.bam --spark-master local[45] --tmp-dirtmp --bqsr-recal-file buffy_coat_recal_bqsr.table -O buffy_coat.recal.bam; ```. Any help is much appreciated!. Cheers",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7139:195,error,error,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7139,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); ApplyVQSR . ### Affected version(s); gatk-4.2.6.1. ### Description . Getting the following error. However, the chr6.raw.excessHet.vcf.gz does not contain that multiallelic variant site. This variant is the nearest at that location but the error is for a variant at chr6:26914009 with different alleles =[G*, GTGTA, GTGTATA, GTGTGTA] . . `chr6 26914005 . A ATG,G 15390.7 PASS AC=278,2;AF=0.04,0.0002879;AN=6948;AS_BaseQRankSum=-0.2,0.4;AS_FS=0.522,0;AS_InbreedingCoeff=-0.0012,0.1805;AS_MQ=58.75,59.2;AS_MQRankSum=0,-3.2;AS_QD=2.56,0.02;AS_ReadPosRankSum=0.1,0.3;AS_SOR=0.652,0.724;BaseQRankSum=-0.152;DP=118313;ExcessHet=2.9774;FS=0.518;InbreedingCoeff=0.0016;MLEAC=278,2;MLEAF=0.04,0.0002879;MQ=56.9;MQRankSum=-0.962;QD=2.57;ReadPosRankSum=0.193;SOR=0.712; `. ```; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr6:26914009 [VC chr6.raw.excessHet.vcf.gz @ chr6:26914009 Q276902.75 of type=INDEL alleles=[G*, GTGTA, GTGTATA, GTGTGTA] attr={AC=[4269, 29, 5], AF=[0.620, 4.209e-03, ; #### Steps to reproduce; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode INDEL; ```. #### Expected behavior; Create recalibrated vcf file. #### Actual behavior; ```; Caused by:; Process `ApplyRecalibrationIndels` terminated with an error exit status (3). Command executed:. #!/bin/bash; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8054:141,error,error,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8054,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); BaseRecalibratorSpark; BQSRPipelineSpark. ### Affected version(s); 4.1.0.0. ### Description ; We are running into a problem using BaseRecalibratorSpark. The tool fails soon after starting. The same error appears with the same bam file on different machines. Additionally, vanilla BaseRecalibrator works just fine on these bams (so I don't think the issue is with the bam). They are all suffering from the same/similar stacktrace. We've had BaseRecalibratorSpark work fine on other bam files. Additionally, changing the number of threads still results in the same stacktrace. I've also tried running the BQSRPipelineSpark to see if that would suffer the same issue and it fails in the same manner. Additionally, I've run ValidateSamFile. There are some reads missing their mates, but this hasn't presented an issue in other tools (including vanilla BaseRecalibrator). Searching thru the forum, I found an old issue with a similar stacktrace, but that issue appears to occur in GATK 2.4: https://gatkforums.broadinstitute.org/gatk/discussion/3265/bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(D",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:248,error,error,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Build. ### Affected version(s); - [X] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; ```; =======================<phase: build >============================; ===> Building for gatk-4.2.6.1_1. Welcome to Gradle 7.5.1!. Here are the highlights of this release:; - Support for Java 18; - Support for building with Groovy 4; - Much more responsive continuous builds; - Improved diagnostics for dependency resolution. For more details see https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). FAILURE: Build failed with an exception. * Where:; Build file '/wrkdirs/usr/ports/biology/gatk/work/gatk-4.2.6.1/build.gradle' line: 15. * What went wrong:; Plugin [id: 'de.undercouch.download', version: '4.1.2'] was not found in any of the following sources:. - Gradle Core Plugins (plugin is not in 'org.gradle' namespace); - Plugin Repositories (could not resolve plugin artifact 'de.undercouch.download:de.undercouch.download.gradle.plugin:4.1.2'); Searched in the following repositories:; Gradle Central Plugin Repository; ```. #### Steps to reproduce; regular build. Version: 4.2.6.1; Java-17; FreeBSD 13.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7984:658,FAILURE,FAILURE,658,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7984,4,"['FAILURE', 'down']","['FAILURE', 'download']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); CalculateContamination. ### Affected version(s); - [x] Latest public release version 4.1.8.1. ### Description . There appears to be an error mode where if not a lot of sites are provided, the contamination estimation tool will estimate the error on contamination as 0.0. We should change this to either error out if enough sites are not provided, or modify the calculation to correctly reflect the uncertainty in contamination.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6727:185,error,error,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6727,3,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); CollectMultipleMetrics. ### Affected version(s); 4.1.2.0. ### Description ; CollectMultipleMetrics performs Percent-encoding of input paths. When running this tool as a step of a packed CWL workflow with Cromwell, this causes a `No such file or directory` error. The input file; ```; /cromwell-executions/transform_pack.cwl#main/0cd8a732-b482-4b8e-ba6e-34d244620ded/call-picard_collectmultiplemetrics/inputs/-733038737/dbsnp_144.hg38.vcf.gz; ```; becomes; ```; file:///cromwell-executions/transform_pack.cwl%23main/0cd8a732-b482-4b8e-ba6e-34d244620ded/call-picard_collectmultiplemetrics/inputs/-733038737/dbsnp_144.hg38.vcf.gz; ```; and can not be found. #### Expected behavior; The tool should collect metrics without error. #### Actual behavior; `CollectMultipleMetrics`; ```; Job main.metrics.metrics.cwl.gatk_collectmultiplemetrics:NA:1 exited with return code 3 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /mnt/scratch/runpack/cromwell-executions/transform_pack.cwl#main/8f58079f-1b94-40a9-873f-41e8d765644d/call-metrics/transform_pack.cwl#metrics.cwl/2a15d912-9a75-44dc-a723-b9f2dba439b3/call-gatk_collectmultiplemetrics/execution/stderr.; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/transform_pack.cwl#main/8f58079f-1b94-40a9-873f-41e8d765644d/call-metrics/transform_pack.cwl#metrics.cwl/2a15d912-9a75-44dc-a723-b9f2dba439b3/call-gatk_collectmultiplemetrics/tmp.a2640a46; 20:19:59.771 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/bin/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Thu May 09 20:20:00 UTC 2019] CollectMultipleMetrics --INPUT /cromwell-executions/transform_pack.cwl#main/8f58079f-1b94-40a9-873f-41e8d765644d/call-metrics/transform_pack.cwl#metrics.cwl/2a15d912-9a75-44dc-a723-b9f2dba439b3/call-gatk_colle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5931:306,error,error,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5931,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); CollectReadCounts . ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [x] Latest master branch as of [10/6/2020]. ### Description ; GATK CollectReadCounts successfully processes some reads but then throws an ArrayIndexOutOfBoundsException in the middle of the file. Console output below. I was able to successfully run CollectReadCounts on ~16k other crams, but received the same error on 3 of them (although the last coordinate reported by ProgressMeter was different for each). The error does not occur if I subset out chromosome 6 reads from the main cram file and run CollectReadCounts on each file separately. I don't see any obvious formatting issue with my crams from a quick skim over lines immediately following the last reported coordinate. ; ```; > java -jar gatk-package-4.1.8.1-local.jar CollectReadCounts \; -I input.cram \; --read-index input.cram.crai \; -L my_intervals.bed \; --interval-merging-rule OVERLAPPING_ONLY \; --reference hg38.fa \; --format TSV \; -O output.tsv. 16:56:30.581 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.581 INFO CollectReadCounts - The Genome Analysis Toolkit (GATK) v4.1.8.1; 16:56:30.581 INFO CollectReadCounts - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:56:30.582 INFO CollectReadCounts - Executing as isaac@LAPTOP-K5UOQS3A on Linux v4.19.104-microsoft-standard amd64; 16:56:30.582 INFO CollectReadCounts - Java runtime: Java HotSpot(TM) 64-Bit Server VM v14.0.1+7; 16:56:30.582 INFO CollectReadCounts - Start Date/Time: October 6, 2020 at 4:56:30 PM EDT; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.583 INFO CollectReadCounts - HTSJDK Version: 2.23.0; 16:56:30.584 INFO CollectReadCounts - Picard Version: 2.22.8; 16:56:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6865:454,error,error,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - GATK 4.1.8.1 (Latest release as of 08/24/20). ### Description ; User is running CombineGVCFs and getting a java error java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52). This issue was discussed at the GATK Office Hours meeting. ### Associated forum post; https://gatk.broadinstitute.org/hc/en-us/community/posts/360072644931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect wheth",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766:203,error,error,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - [X] Latest public release version [4.2.5.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; The auto-generated wdl for CombineGVCFs on dockstore won't work because it doesn't have any inputs for the indices of the input vcfs. This means GATK cannot access the vcf indices because they never get localized, so the workflow fails. . #### Steps to reproduce; Take any vcfs and run them through the workflow to get an error about missing indices. . #### Expected behavior; Including the indices in the task inputs will allow them to get localized along with the vcfs so GATK can operate normally. . #### Actual behavior; You get an error saying it requires index files to proceed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7681:526,error,error,526,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7681,2,['error'],['error']
Availability,## Bug Report. ### Affected tool(s) or class(es); CountReadsSpark. ### Affected version(s); gatk-4.0.12.0. ### Description ; Reading cram generates the following error when running CountReadsSpark on yarn. . ```; ./gatk-4.0.12.0/gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.12.0/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.12.0/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:13:11.050 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:13:11.275 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:162,error,error,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); FilterMutectCalls and possibly Mutect2. ### Affected version(s); GATK 4.1.7.0, still occurs in 4.1.8.1. ### Description ; User running Mutect2 in mitochondrial mode and ERC BP_RESOLUTION. Mutect2 is successful, however filter mutect calls has error message; `java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN`. Possible similar issue: #6202 ; Complete stack trace:. ```; Running:. java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx22G -Djava.io.tmpdir=/nobackup/lnsingh/MTRNA/tmp -jar /nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar FilterMutectCalls --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityNotZeroReadFilter --disable-read-filter MappingQualityAvailableReadFilter --mitochondria-mode true -R /nobackup/lnsingh/MTRNA/lib/rCRS.fa -V /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz -L MT -O /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.filtered.gvcf.gz. 07:33:14.927 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityNotZeroReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityAvailableReadFilter) is not enabled by this tool. 07:33:15.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so. Sep 20, 2020 7:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6850:293,error,error,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [ ] Latest master branch as of [June 22, 2018]. ### Description ; If there are no variants in the input VCF that are rendered in the MAF, the MAF file is blank. It should contain a header. This will cause problems in downstream tools expecting a valid MAF. #### Expected behavior; A MAF that is empty except for a header. #### Actual behavior; A zero-byte file. #### Possible solution; MafOutputRenderer can use the metadata to create a header.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4937:306,down,downstream,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4937,1,['down'],['downstream']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [ ] Latest master branch as of [June 26, 2018]. ### Description ; This happens when there are transcripts with different gene names that overlap a variant. Error is in `createFuncotationsOnVariant` ... . #### Expected behavior; One transcript is selected. #### Actual behavior; One transcript per overlapping gene name is selected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4952:245,Error,Error,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4952,1,['Error'],['Error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [x] Latest public release version [4.2.1.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; When processing a VCF with tumor and matched normal into a MAF, the `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` fields are not populated. #### Steps to reproduce. `gatk --java-options -Xmx2048m Funcotator --data-sources-path /cromwell_root/datasources_dir --ref-version hg38 --output-file-format MAF -R /cromwell_root/getzlab-workflows-reference_files-oa/hg38/gdc/GRCh38.d1.vd1.fa -V` [`C3N-02729.vcf.gz`](https://github.com/broadinstitute/gatk/files/6977700/C3N-02729.vcf.gz) `-O C3N-02729.maf --annotation-default normal_barcode:C3N-02729_N --annotation-default tumor_barcode:C3N-02729_T --annotation-default Center:broadinstitute.org --annotation-default source:Unknown --transcript-selection-mode BEST_EFFECT`. (NOTE: reference files available at `gs://getzlab-workflows-reference_files-oa/hg38/gdc`). #### Expected behavior; `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` fields should be populated as appropriate based on the `GT` field for the matched normal in the VCF. #### Actual behavior; `Match_Norm_Seq_Allele1` and `Match_Norm_Seq_Allele2` are populated with `__UNKNOWN__`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7408:950,avail,available,950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7408,1,['avail'],['available']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); All. ### Description ; Since we expect users to write config files manually, we need to have some enforcement of naming rules. At the least, to disallow spaces in the name and version fields. There are many places throughout the code where we assume that there will be no spaces. Additionally, I hear from users that they want any Funcotator tsv outputs to never have spaces (or tabs or other special characters -- ""_"", ""-"" are obviously okay). . We can solicit users about which special characters are okay, but definitely disallow spaces and tabs. #### Steps to reproduce; Add a space to the Gencode datasource config (name or version field) and try to funcotate a segment file. #### Expected behavior; No errors and no spaces in the field names. #### Actual behavior; Exception in gene list output renderer.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5937:795,error,errors,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5937,1,['error'],['errors']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); GATK 4.1.0.0. ### Description ; Funcotator does not perform any annotation on a minimal VCF with canonical cancer variants and returns the following error:. ```; 23:28:30.519 INFO Funcotator - Initializing Funcotator Engine...; 23:28:30.523 INFO Funcotator - Creating a VCF file for output: file:xxx/sandbox/idh.funcotated.vcf; 23:28:30.541 INFO ProgressMeter - Starting traversal; 23:28:30.541 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:28:30.652 INFO ProgressMeter - unmapped 0.0 15 8108.1; 23:28:30.652 INFO ProgressMeter - Traversal complete. Processed 15 total variants in 0.0 minutes.; 23:28:30.652 WARN Funcotator - ================================================================================; 23:28:30.652 WARN Funcotator - _ _ _ __ __ _ _ _ _; 23:28:30.652 WARN Funcotator - | || || | \ \ / /_ _ _ __ _ __ (_)_ __ __ _ | || || |; 23:28:30.652 WARN Funcotator - | || || | \ \ /\ / / _` | '__| '_ \| | '_ \ / _` | | || || |; 23:28:30.653 WARN Funcotator - |_||_||_| \ \V V / (_| | | | | | | | | | | (_| | |_||_||_|; 23:28:30.653 WARN Funcotator - (_)(_)(_) \_/\_/ \__,_|_| |_| |_|_|_| |_|\__, | (_)(_)(_); 23:28:30.653 WARN Funcotator - |___/; 23:28:30.653 WARN Funcotator - --------------------------------------------------------------------------------; 23:28:30.653 WARN Funcotator - Only IGRs were produced for this dataset. This STRONGLY indicates that this; 23:28:30.653 WARN Funcotator - run was misconfigured.; 23:28:30.653 WARN Funcotator - You MUST check your data sources to make sure they are correct for these data.; 23:28:30.653 WARN Funcotator - ================================================================================; ```. There is no reason to assume that there is any issue with the data sources or run parameters. They have worked fine using a different VCF that had completed INFO tags. #### Steps to reproduce; Run Funcotator",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5777:236,error,error,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); gatk-4.1.8.0; funcotator_dataSources.v1.7.20200521s. ### Description . I am trying to use Funcotator to annotate the variants that I have already detected. Unfortunatelly, after a few seconds Funcotator stops with the error:. > java.lang.IllegalArgumentException: Unexpected value: lncRNA. I have no idea what is wrong and I did not find this error in the internet. Can it be a problem with JRE?. Full log below. #### Steps to reproduce. `~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF`. #### Expected behavior. Foncotator annotates my variants. #### Actual behavior. > (base) [pkus@master1 mutect_test]$ ~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > Using GATK jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar Funcotator --variant filtered_variants/P1.vcf.gz --reference /home/pkus/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path /home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > 15:16:39.460 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/int",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708:305,error,error,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GATK 4.1.0.0 AnalyzeCovariates. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; The csv produced by AnalyzeCovariates is invalid. It doesn't escape commas in fields, resulting in an error in the R script. #### Steps to reproduce; If you have a comma in the readgroup in a BAM, this will happen. #### Expected behavior; It should produce valid csv files, and then be able to properly produce the plots. #### Actual behavior; Commas in read group names result in malformed (unescaped) csv where it's impossible to parse fields properly. This results in the following R script error:; ```; Error in read.table(file = file, header = header, sep = sep, quote = quote, :; more columns than column names; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5739:325,error,error,325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5739,3,"['Error', 'error']","['Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); GATK Haplotype caller. ### Affected version(s); - [x] Latest public release version [4.1.0.0]; - [ ] Latest master branch as of [date of test?]. The Genome Analysis Toolkit (GATK) v4.1.0.0; HTSJDK Version: 2.18.2; Picard Version: 2.18.25. ### Description ; HaplotypeCaller is outputting variants which have a no-call as the ALT, which breaks a bunch of downstream tools, this is new behavior in 4.1, AFAICT. ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	s1564	s1741	s1851	s1852	s1862	s1901	s1912	s1971	s2017	s2021	s2026	s2056	s2100	s2102	s2104	s2122	s2124	s2151	s2157; 1	937796	.	T	.	179.65	.	AN=38;DP=31;MMQ=60;MQ=60.00	GT:AD:DP	0/0:0:0	0/0:0:0	0/0:4:4	0/0:0:0	0/0:1:1	0/0:1:1	0/0:0:0	0/0:0:0	0/0:2:2	0/0:0:0	0/0:1:1	0/0:3:3	0/0:1:1	0/0:8:8	0/0:1:1	0/0:0:0	0/0:2:2	0/0:7:7	0/0:0:0; ```. #### Steps to reproduce; I'm not doing anything special, so I suspect these variants should exist in other projects as well. I'm doing batch calling on several samples simultaneously; an example:. ```; unset JAVA_HOME && export PATH=/home/rdk4/local/share/bcbio/anaconda/bin:$PATH && gatk --java-options '-Xms4g -Xmx5000m -XX:+UseSerialGC -Djava.io.tmpdir=/n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/bcbiotx/tmpTSg0hJ' HaplotypeCaller -R /n/app/bcbio/dev/genomes/Hsapiens/GRCh37/seq/GRCh37.fa --annotation MappingQualityRankSumTest --annotation MappingQualityZero --annotation QualByDepth --annotation ReadPosRankSumTest --annotation RMSMappingQuality --annotation BaseQualityRankSumTest --annotation FisherStrand --annotation MappingQuality --annotation DepthPerAlleleBySample --annotation Coverage -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2017/s2017-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2056/s2056-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-variants/work/align/s2122/s2122-sort.bam -I /n/data1/cores/bcbio/PIs/rudy_tanzi/tau-exome/tau-var",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5650:403,down,downstream,403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650,1,['down'],['downstream']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GATK Haplotypecaller . ### Affected version(s); (4.3.0.0 and 4.2.6.1). ### Description ; We used Haplotypecaller in GVCF mode (initially in 4.2.6.1, then again with 4.3.0.0) for one of our human samples. These samples were joint-genotyped with ~2.7k exomes. The exact command used was - . ```gatk HaplotypeCaller -R ""$ref_hg38"" -I input.bam -L twist.bed -ERC GVCF -ip 50 -O test_latest.gvcf.gz -bamout test_bamout_latest.bam --tmp-dir /mnt/exome/tmp/```. Below is a screenshot of the bamout file (top track) and the recalibrated BAM file (bottom track). . ![image](https://user-images.githubusercontent.com/32951653/224249117-ab13800f-5b3c-42f1-b349-993ae182620f.png). As shown in screenshot, there are only 2 reads supporting the alternate allele, however the gvcf.gz file has the below entry for the variant - . ```chr5 176530208 . T C,<NON_REF> 2717.64 . BaseQRankSum=0.975;DP=179;ExcessHet=0.0000;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=0.000;RAW_MQandDP=644400,179;ReadPosRankSum=10.927 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 0|1:68,102,0:170:99:0|1:176530208_T_C:2725,0,1279,2928,1584,4512:176530208:38,30,37,65```. This variant is called as a heterozygous variant ```0|1``` with read frequency of ```68,102,0```, which would mean 68 reads supporting the ref allele, 102 reads supporting the alt C allele and 0 reads supporting the <NON_REF> allele. After joint-genotyping, the variant was classified as LOW_VQSLOD. #### Steps to reproduce; Let us know how to share the BAM file subset and let us know if the error is reproducible. #### Expected behavior; Ideally, if the variant had been called, its read frequency should have been represented more accurately. #### Actual behavior; The read frequencies are not matching up.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8238:1552,error,error,1552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8238,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GATK PostprocessGermlineCNVCalls. ### Affected version(s); v4.4.0.0. ### Description ; Run GTAK on a batch of WES samples with `PostprocessGermlineCNVCalls` encountered: ""Records were not strictly sorted in dictionary order.""; I tried to detect germline CNV in cohort mode on 25 WES samples by the official tutorial. At first, I didn't perform scatter and the step `PostprocessGermlineCNVCalls` was very time-consuming but eventually worked. So I split the reference genome into 45 parts to save time. It's OK for the first sample but there was an error ""Records were not strictly sorted in dictionary order."" from the second sample. I was really annoyed by it. `03:12:39.275 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/xiangxd/project/software/callers/gatk_4.4/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 03:12:39.467 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 03:12:39.473 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.4.0.0; 03:12:39.474 INFO PostprocessGermlineCNVCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 03:12:39.475 INFO PostprocessGermlineCNVCalls - Executing as xiangxd@cu07 on Linux v3.10.0-327.el7.x86_64 amd64; 03:12:39.475 INFO PostprocessGermlineCNVCalls - Java runtime: Java HotSpot(TM) 64-Bit Server VM v20.0.2+9-78; 03:12:39.477 INFO PostprocessGermlineCNVCalls - Start Date/Time: April 15, 2024, 3:12:39AM CST; 03:12:39.477 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 03:12:39.478 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 03:12:39.495 INFO PostprocessGermlineCNVCalls - HTSJDK Version: 3.0.5; 03:12:39.496 INFO PostprocessGermlineCNVCalls - Picard Version: 3.0.0; 03:12:39.497 INFO PostprocessGermlineCNVCalls - Built for Spark Vers",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:598,error,error,598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,1,['error'],['error']
Availability,## Bug Report. ### Affected tool(s) or class(es); GATK ReblockGVCF. ### Affected version(s); - 4.2.5.0 and 4.2.6.1. ### Description ; I am running ReblockGVCF on GVCF's that are haplotyped on version 4.0.1.4. About 1 out of 500 samples crash with the following error:; `ReblockGVCF fails by an exception:No shortest ALT at 464564654 across alleles: [*]`. Complete error message:. ```; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr4::464564654[VC /bug.g.vcf.gz @ ; ```; redacted; ```. ] filters=; at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:145); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:136); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7961:261,error,error,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7961,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GATK v4.1.4.0 using FilterMutectCalls. ### Affected version(s); - [x] Latest public release version `4.1.4.0` installed from conda release `gatk4-4.1.4.0-1`; - [ ] Latest master branch as of [date of test?]. ### Description ; This issue reports the same error that is reported in #6237, but on the latest release, and in a mitochondrial calling setting. My command is:; ```bash; gatk FilterMutectCalls -V MT.vcf.gz\; -R human_g1k_v37.main.fasta\; -O MT.filtered.vcf.gz\; --stats MT.vcf.gz.stats\; --mitochondria-mode; ```. I get the following output to STDERR:; ```; 11:15:57.152 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/warkre/miniconda3/envs/gatk4.1.4.0/share/gatk4-4.1.4.0-1/gatk-package-4.1.4.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 07, 2019 11:15:57 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:15:57.328 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.328 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.4.0; 11:15:57.328 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:15:57.328 INFO FilterMutectCalls - Executing as warkre@fuji on Linux v4.9.0-9-amd64 amd64; 11:15:57.328 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 11:15:57.329 INFO FilterMutectCalls - Start Date/Time: November 7, 2019 11:15:57 AM CET; 11:15:57.329 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.329 INFO FilterMutectCalls - ------------------------------------------------------------; 11:15:57.329 INFO FilterMutectCalls - HTSJDK Version: 2.20.3; 11:15:57.329 INFO FilterMutectCalls - Picard Version: 2.21.1; 11:15:57.329 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:304,error,error,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GatherTranches. ### Affected version(s); Latest public release version 4.2.6.1. ### Description ; I ran `VariantRecalibrator` in scattered (using intervals) mode and now trying to gather the scattered tranches into a single file but somehow the number of novel variants is < 0. This is the exact error:; `Invalid tranche - no. variants is < 0 : known 90357410 novel -1894637320`. #### Steps to reproduce; ```; inputs_cmdl = ' '.join([f'--input {t}' for t in tranches]); j.command(; f""""""set -euo pipefail; gatk --java-options -Xms6g \\; GatherTranches \\; --mode SNP \\; {inputs_cmdl} \\; --output {j.out_tranches}""""""; ); ```. #### Expected behavior; Gathered scattered VQSLOD tranches into a single file. #### Actual behavior; Fails because of what seems like an integer overflow according to @ldgauthier; ```; org.broadinstitute.hellbender.exceptions.GATKException: Invalid tranche - no. variants is < 0 : known 90357410 novel -1894637320; 	at org.broadinstitute.hellbender.tools.walkers.vqsr.Tranche.<init>(Tranche.java:37); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VQSLODTranche.<init>(VQSLODTranche.java:37); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VQSLODTranche.mergeAndConvertTranches(VQSLODTranche.java:205); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VQSLODTranche.mergeAndConvertTranches(VQSLODTranche.java:139); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.GatherTranches.doWork(GatherTranches.java:80); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbende",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7859:346,error,error,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7859,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GenomeDBImport. ### Affected version(s); ```; 01:22:35.395 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.2.0.0; 01:22:35.395 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:22:35.481 INFO GenomicsDBImport - Executing as vr6@node-14-20 on Linux v5.4.0-90-generic amd64; 01:22:35.481 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_282-b08; 01:22:35.482 INFO GenomicsDBImport - Start Date/Time: 10 December 2021 01:22:34 UTC. ```. ### Description . It seems that is possible for some IO error affecting the production of the output tile-db file/folder that is ignored by the reslt of the tool run resulting in a falsely succesful completion. One won't realize of it unil tries to use that db with genotype-gvcfs. STDERR: . ```; Dec 10, 2021 1:22:35 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 01:22:35.395 INFO GenomicsDBImport - ------------------------------------------------------------; 01:22:35.395 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.2.0.0; 01:22:35.395 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:22:35.481 INFO GenomicsDBImport - Executing as vr6@node-14-20 on Linux v5.4.0-90-generic amd64; 01:22:35.481 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_282-b08; 01:22:35.482 INFO GenomicsDBImport - Start Date/Time: 10 December 2021 01:22:34 UTC; 01:22:35.482 INFO GenomicsDBImport - ------------------------------------------------------------; 01:22:35.482 INFO GenomicsDBImport - ------------------------------------------------------------; 01:22:35.483 INFO GenomicsDBImport - HTSJDK Version: 2.24.0; 01:22:35.483 INFO GenomicsDBImport - Picard Version: 2.25.0; 01:22:35.483 INFO GenomicsDBImport - Built for Spa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:631,error,error,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport / GenotypeGVCFs. ### Affected version(s); 4.3.0.0. ### Description ; When creating a GenomicsDB datastore, the created folder has permissions set to 700 (recursivelly).; As such, when trying to jointly calling genotypes using the GenotypeGVCFs, one encounters error:; ERROR: Couldn't create GenomicsDBFeatureReader. #### Steps to reproduce; - Create a datastore using GenomicsDBImport, e.g. ; gatk ... --genomicsdb-workspace-path IWANNAKILLYOU. - Recursively change access permission to the thus created genomicsdb; chmod 700 -R ./IWANNAKILLYOU. - Run the GenotypeGVCFs; gatk ... --variant gendb://IWANNAKILLYOU. #### Expected behavior; GenotypeGVCFs should initialize the engine normally and start processing the intervals as expected. #### Actual behavior; GenotypeGVCFs intializes the engine and throws out and error; ERROR: Couldn't create GenomicsDBFeatureReader. #### Proposed solution; Mention anywhere in the docs the genomicsdb datastore should be made readable to other users, i.e., change permissions to at least 744 if not do a 766.; Or just make sure the ./IWANNAKILLYOU has proper permissions from the get go. Much obliged",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233:327,error,error,327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); -4.1.8.1, 4.1.6.0. ### Description ; Two users are running GenomicsDBImport and getting a Duplicate Sample Name Error and both have reported that they do not have duplicate sample names in their map files. @nalinigans @mlathara does this look like a user issue or bug with GenomicsDBImport?. ### First Example; Please see this link for more info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072797951--GenomicsDBException-Duplicate-sample-name-found-?page=1#community_comment_360012681791. `gatk --java-options ""-Xmx16g -Xms16g"" GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz`. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -Xms16g -jar /afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; 16:16:35.954 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:16:36.003 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/libgkl_compression5245166187604030095.so; Aug 28, 2020 4:16:36 PM s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:205,Error,Error,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['Error'],['Error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; GenotypeGVCFs won't joint call DRAGEN mitochondrial data because of the DRAGEN somatic output format. We should be able to use the DRAGEN SQ in place of Mutect2's TLOD (see line 279 in GenotypeGVCFsEngine); Note that DRAGEN SQ is a Phred-scaled double. #### Steps to reproduce; DRAGEN somatic GVCF entries from version 3.8.4 look like:; chrM 1 . G <NON_REF> . weak_evidence END=1 GT:AD:DP:SQ:MIN_DP 0/0:112,1579:1691:0:1691. Run GenotypeGVCFs with -V to a file like that (reference GenotypeGVCFsIntegrationTest::testGenotypingForSomaticGVCFs() for more details); Must include `--input-is-somatic` as of now. #### Expected behavior; The task should run to completion, calculating a site quality store using the DRAGEN SQ value. #### Actual behavior; Error from AlleleFrequencyCalculator about not having PLs or GQ.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7840:955,Error,Error,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7840,1,['Error'],['Error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); GermlineCNVCaller. ### Affected version(s); - GATK4 4.0.5.1. ### Description ; I'm trying to do a germline CNV calling with 387 exomes samples (I know it's a lot). The CollectReadCounts and DetermineGermlineContigPloidy were successfull. But for the GermlineCNVCaller I got what I think is a Python ""cannot allocate memory"" error. I tried to specify to the JVM a max memory to allocate ``` --java-options ""-Xmx192G"" ``` , but no improvements. The machine I'm working on got 32 threads and 192 Gb RAM. #### Steps to reproduce; I guess try to do a CNV calling with a large cohort. #### Output; ```10:56:25.124 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/tintest/miniconda2/share/gatk4-4.0.5.1-0/gatk-package-4.0.5.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:56:25.342 INFO GermlineCNVCaller - ------------------------------------------------------------; 10:56:25.343 INFO GermlineCNVCaller - The Genome Analysis Toolkit (GATK) v4.0.5.1; 10:56:25.344 INFO GermlineCNVCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:56:25.345 INFO GermlineCNVCaller - Executing as tintest@dahu39 on Linux v4.9.0-6-amd64 amd64; 10:56:25.346 INFO GermlineCNVCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_121-b15; 10:56:25.347 INFO GermlineCNVCaller - Start Date/Time: July 25, 2018 10:56:24 AM CEST; 10:56:25.348 INFO GermlineCNVCaller - ------------------------------------------------------------; 10:56:25.349 INFO GermlineCNVCaller - ------------------------------------------------------------; 10:56:25.350 INFO GermlineCNVCaller - HTSJDK Version: 2.15.1; 10:56:25.351 INFO GermlineCNVCaller - Picard Version: 2.18.2; 10:56:25.352 INFO GermlineCNVCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:56:25.353 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:56:25.354 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053:374,error,error,374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053,1,['error'],['error']
Availability,## Bug Report. ### Affected tool(s) or class(es); GetSampleName. ### Affected version(s); 4.2.6.1. ### Description ; when running gatk GetSampleName on a cram file you get the following error:. > A USER ERROR has occurred: A reference file is required when using CRAM files. A reference is specified with the -R command line argument. however the command does work and it does output the sample name without requiring a reference genome. #### Steps to reproduce; gatk GetSampleName -I $input_cram_path -O GetSampleName.txt. #### Expected behavior; no USER ERROR. #### Actual behavior; USER ERROR outputted to STDOUT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8059:186,error,error,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8059,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); GnarlyGenotyper. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]; - [x] 4.2.3 - snapshot -> https://console.cloud.google.com/gcr/images/broad-dsde-methods/US/gatk_subset_dragen_allele_frac@sha256:f5e93bda2278f1c999bd9def027c6851eeb098736b47a93469c524863b46c21f/details. ### Description ; WDL joint genotyping using GnarlyGenotyper after ReblockGVCF (fixed on the snapshot above). #### Steps to reproduce; Joint Genotyper wdl pipeline with ""GatkJointGenotyping.useGnarlyGenotyper"": true , **samples from DRAGEN 3.8+**. #### Expected behavior; Complete the pipeline. #### Actual behavior; Failing with diploid error on Sexual Chromosomes. Hello again everyone.; First of all, thank you@ldgauthierto send us that snapshot docker. It kind of solved reblock problem. As feedback here, I tried with the newest GATK version (4.2.5) as it modified ReblockGVCF, but it didn`t work.; Anyway, I have another issue here...; While I was using only one or few chromosomes, the pipeline with reblock + gnarly was working fine. Once I added all chromosomes I started to get this type of error (GnarlyGenotyper):. ```; A USER ERROR has occurred: Bad input: This tool assumes diploid genotypes, but sample NA18668 has ploidy 1 at position chrY:2789135. or. A USER ERROR has occurred: Bad input: This tool assumes diploid genotypes, but sample NA14734 has ploidy 1 at position chrX:36667858. ```; I checked every failed log, and it's all related to the sexual chromosomes. Any thought/tip about that? ; ps.: From chr1 to chr22 it worked fine!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7690:732,error,error,732,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7690,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller 4.1 with -ERC GVCF. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; It would appear that variants covered by a spanning deletion are not output with phasing information even when surrounded by phased variants on either side. Since one of the alleles is covered by an upstream deletion phase is known, but the genotype itself is not phased and no phase set is attached. The following is a cut-down example from a gVCF:. ```; chr6 51618169 . GT G,<NON_REF> 948.60 . DP=94 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 0|1:32,39,0:71:3,4,0:29,35,0:99:0|1:51618169_GT_G:956,0,808,1054,926,1980:51618169:3,29,4,35; chr6 51618170 . T *,G,<NON_REF> 776.01 . DP=92 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 1/2:2,39,30,0:71:1,4,2,0:1,35,28,0:99:3533,786,723,1141,0,956,2837,916,1206,2757:1,1,6,63; chr6 51618171 . G <NON_REF> . . END=51618173 GT:DP:GQ:MIN_DP:PL 0/0:90:99:90:0,120,1800; chr6 51618174 . A G,<NON_REF> 1001.60 . DP=89 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 0|1:33,41,0:74:3,4,0:30,37,0:99:0|1:51618169_GT_G:1009,0,803,1108,926,2034:51618169:3,30,4,37; ```. You can see that the SNP at 51618170 is flanked by phased variants at 51618169 and 51618174, but is output with unphased genotype and no `PS` (or `PID/PGT`). I'm not entirely sure if this is on purpose for some reason I don't understand, or simply an edge case in the phasing code that's handled incorrectly. #### Steps to reproduce; Run HC on reads with three variants, starting with a deletion, a variant spanned by the deletion and a variant just beyond the deletion. FWIW I've requested permission to share an example case from real data and am awaiting an answer. #### Expected behavior; I think the spanned variant should be output with phasing information, e.g. in the above case I would expect (abbreviated):. ```; chr6 51618169 . GT G,<NON_REF> ... GT:DP:PS 0|1:71:51618169; chr6 51618170 .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5651:551,down,down,551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651,1,['down'],['down']
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller GVCF mode. ### Affected version(s); GATK 4.1.8.0 . ### Description ; Discussed on the GATK forum: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072760032-HaplotypeCaller-NullPointerException-Error. Command: ; `gatk --java-options ""-Xmx4g"" HaplotypeCaller -R hg19.fa.gz -I test.bam -O test.g.vcf.gz -ERC GVCF`. #### Stack Trace. ```; 17:08:11.229 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 27, 2020 5:08:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:08:12.021 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.028 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.0; 17:08:12.028 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:08:12.038 INFO HaplotypeCaller - Executing as zepengmu@midway2-0243.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 17:08:12.038 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 17:08:12.039 INFO HaplotypeCaller - Start Date/Time: August 27, 2020 5:08:11 PM CDT; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Version: 2.22.0; 17:08:12.039 INFO HaplotypeCaller - Picard Version: 2.22.8; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:08:12.040 INFO HaplotypeCal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783:271,Error,Error,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783,1,['Error'],['Error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [4.3.0.0 ] Latest public release version . ### Description ; I'm attempting to run HaplotypeCaller on Ultima flow based bams with the ""--flow-mode STANDARD"" and ""--likelihood-calculation-engine FlowBasedHMM"" arguments. However, I'm getting the following error ""java.lang.IllegalArgumentException: read must be flow based: 180652-BC94-0022826568 chr1:14585-14703"". The bams were created from fastqs provided directly from Ultima, so they are definitely flow-based. One question I have: how does HaplotypeCaller determine if a read is flow-based or not? Is this specified in the Read Groups?. #### Steps to reproduce; gatk --java-options ""-Xmx4g"" HaplotypeCaller -R hg38.fa --flow-mode STANDARD --likelihood-calculation-engine FlowBasedHMM -I [bam] -O [bam%.BQSRapplied.bam].GATK.vcf.gz. #### Expected behavior; HaplotypeCaller should complete successfully. #### Actual behavior; HaplotypeCaller fails, expecting flow-based reads",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8112:348,error,error,348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8112,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [?] Latest public release version [version?]; - [x] Latest master branch as of Sept 10, 2019. ### Description ; Contamination estimate doesn't appear to be taken into account for reference blocks in GVCFs. #### Steps to reproduce; I'm looking at expected integration test results with uncontaminated (src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.CEUTrio.HiSeq.WGS.b37.NA12878.calls.20.10100000-10150000.vcf) vs. 15% contaminated (src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.CEUTrio.HiSeq.WGS.b37.NA12878.CONTAMINATED.WITH.HCC1143.NORMALS.15PCT.20.10100000-10150000.postIndelRefConfUpdate.g.vcf). #### Expected behavior; Contaminated calls should have lower depth because the reads are being downsampled (in a biased way) by the contamination fraction. #### Actual behavior; In the expected HC integration test results I'm seeing for 0 contamination; 20 10132770 . A <NON_REF> . . END=10132770 GT:DP:GQ:MIN_DP:PL 0/0:57:99:57:0,120,1800. For 15% contamination:; 20 10132770 . A <NON_REF> . . END=10132770 GT:DP:GQ:MIN_DP:PL 0/0:56:99:56:0,120,1800. The pileup has 55 (I'm not going down the rabbit hole of the bonus reads), so I would expect the contaminated GVCF to have < 55 DP. The variants look good in some places and less good in others. Looking through the code, I don't see anywhere the contamination estimate would be used for reference confidence. I suspect @davidbenjamin has been harboring a desire to update the contamination model anyway.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6152:856,down,downsampled,856,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6152,2,['down'],"['down', 'downsampled']"
Availability,## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.2.0.0]. ### Description ; HaplotypeCaller fails with the following java error:. ```*** Error in `java': munmap_chunk(): invalid pointer: 0x00007f1da5980f00 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x7f3e4)[0x7f1daaec73e4]; /var/tmp/rwilton/libgkl_smithwaterman14257239252565866950.so(_Z21runSWOnePairBT_avx512iiiiPhS_iiaPcPs+0x338)[0x7f05b3b50f48]; /var/tmp/rwilton/libgkl_smithwaterman14257239252565866950.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)```. #### Steps to reproduce; Using properly-aligned paired-end reads from GIAB reference sample HG002 (NA24385) with GRCh38.p12. Please see the attached log file for parameterization and stderr log:; [vcall.swbug.log](https://github.com/broadinstitute/gatk/files/6275740/vcall.swbug.log). #### Expected behavior; No error. #### Actual behavior; See above and attached log file. Thank you in advance for having a look at this!. Richard Wilton; Johns Hopkins University,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7187:203,error,error,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7187,3,"['Error', 'error']","['Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); No version information yet, [here is the forum link](https://gatk.broadinstitute.org/hc/en-us/community/posts/360075181171-HaplotypeCaller-Shutting-down-engine-Encountering-a-large-genome) for information. ### Description ; A user wrote into the forum with an error message while HaplotypeCaller was creating the output variant index with an issue of how many bins needed to be created. They have a large genome with long contig(s). We discussed at the GATK Office Hours meeting about adding a check to find this issue so that there is an error or warning before running HaplotypeCaller instead of at the end of the process. A snippet of the error message can be found at the forum post.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6992:240,down,down-engine-Encountering-a-large-genome,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6992,4,"['down', 'error']","['down-engine-Encountering-a-large-genome', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar. ### Description . When run on the 30x 1000 genomes samples, I am getting this error. Not an issue on other crams we have. ```; /restricted/projectnb/genpro/github/gatk/gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; Using GATK jar /rprojectnb2/genpro/github/gatk/build/libs/gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /rprojectnb2/genpro/github/gatk/build/libs/gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; 14:39:56.283 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/rprojectnb2/genpro/github/gatk/build/libs/gatk-package-4.1.9.0-33-g31df35b-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 10, 2021 2:39:56 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:39:56.484 INFO HaplotypeCaller - ------------------------------------------------------------; 14:39:56.484 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.9.0-33-g31df35b-SNAPSHOT; 14:39:56.484 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:39:56.485 INFO HaplotypeCaller - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.6.1.el7.x86_64 amd64; 14:39:56.485 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 14:39:56.485 INFO HaplotypeCaller - Start Date/Time: February 10",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076:223,error,error,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); In the tutorial ""[(How to part I) Sensitively detect copy ratio alterations and allelic segments](https://gatk.broadinstitute.org/hc/en-us/articles/360035531092)"", users are asked to install R components using [install_R_packages.R](https://github.com/broadinstitute/gatk/blob/4.0.1.1/scripts/docker/gatkbase/install_R_packages.R). . ### Affected version(s); Latest public release version [4.5.0.0]. ### Description ; Running the script with `Rscript install_R_packages.R` results in the following error:. `Error in download.file(p, destfile, method, mode = ""wb"", ...) : ; cannot open URL 'http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz'; In addition: Warning message:; In download.file(p, destfile, method, mode = ""wb"", ...) :; cannot open URL 'http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz': HTTP status was '404 Not Found'`. This can be fixed by changing line [35 of install_R_packages.R](https://github.com/broadinstitute/gatk/blob/4.0.1.1/scripts/docker/gatkbase/install_R_packages.R#L35) from `hmmUrl = ""http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz""` to `hmmUrl = ""http://cran.r-project.org/src/contrib/HMM_1.0.1.tar.gz""`. . The script runs as expected once this change is made. #### Steps to reproduce; Run `Rscript install_R_packages.R`. #### Expected behavior; Successfully installs all necessary R packages with the correct versions. #### Actual behavior; Fails to install the 'HMM' package.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8638:548,error,error,548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8638,4,"['Error', 'down', 'error']","['Error', 'download', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); IndexFeatureFile. ### Affected version(s); - [x] Latest master branch as of [1/6/2020]. ### Description ; When running IndexFeatureFile on a compressed vcf stored on GCS, tool fails, error message:. ```; A USER ERROR has occurred: Error while trying to create index for dir/file.vcf.gz. Error was: ; htsjdk.tribble.TribbleException.FeatureFileDoesntExist: Unable to open the input file, most ; likely the file doesn't exist., for input source: /dir/file.vcf.gz; ```; When running on an uncompressed vcf on GCS, the tool succeeds. I've traced the issue to `SeekableStreamFactory.getStreamFor` in htsjdk, which gets called from `IndexFactory.initIndexableBlockCompressedStream` (also in htsdjk), and doesn't appear to handle GCS paths correctly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6348:233,error,error,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6348,4,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); LeftAlignAndTrimVariants. ### Affected version(s); I've only tested with v4.2.2.0. ### Description ; When running LeftAlignAndTrimVariants the program exited with a message that said:; ""A USER ERROR has occurred: Input files reference and features have incompatible contigs: No overlapping contigs found.; reference contigs = [chr1, chr2, chr3, chr4, chr5, chr6, chr7, chr8, chr9, chr10, chr11, chr12, chr13, chr14, chr15, chr16, chr17, chr18, chr19, chr20, chr21, chr22, chrX, chrY, chrM, chr1_KI270706v1_random, chr1_KI270707v1_random, chr1_KI270708v1_random, chr1_KI270709v1_random, chr1_KI270710v1_random, chr1_KI270711v1_random, chr1_KI270712v1_random, chr1_KI270713v1_random, chr1_KI270714v1_random, chr2_KI270715v1_random, chr2_KI270716v1_random, chr3_GL000221v1_random, chr4_GL000008v2_random, chr5_GL000208v1_random, chr9_KI270717v1_random, chr9_KI270718v1_random, chr9_KI270719v1_random, chr9_KI270720v1_random, chr11_KI270721v1_random, chr14_GL000009v2_random, chr14_GL000225v1_random, chr14_KI270722v1_random, chr14_GL000194v1_random, chr14_KI270723v1_random, chr14_KI270724v1_random, chr14_KI270725v1_random, chr14_KI270726v1_random, chr15_KI270727v1_random, chr16_KI270728v1_random, chr17_GL000205v2_random, chr17_KI270729v1_random, chr17_KI270730v1_random, chr22_KI270731v1_random, chr22_KI270732v1_random, chr22_KI270733v1_random, chr22_KI270734v1_random, chr22_KI270735v1_random, chr22_KI270736v1_random, chr22_KI270737v1_random, chr22_KI270738v1_random, chr22_KI270739v1_random, chrY_KI270740v1_random, chrUn_KI270302v1, chrUn_KI270304v1, chrUn_KI270303v1, chrUn_KI270305v1, chrUn_KI270322v1, chrUn_KI270320v1, chrUn_KI270310v1, chrUn_KI270316v1, chrUn_KI270315v1, chrUn_KI270312v1, chrUn_KI270311v1, chrUn_KI270317v1, chrUn_KI270412v1, chrUn_KI270411v1, chrUn_KI270414v1, chrUn_KI270419v1, chrUn_KI270418v1, chrUn_KI270420v1, chrUn_KI270424v1, chrUn_KI270417v1, chrUn_KI270422v1, chrUn_KI270423v1, chrUn_KI270425v1, chrUn_KI270429v1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7538:243,ERROR,ERROR,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7538,1,['ERROR'],['ERROR']
Availability,"## Bug Report. ### Affected tool(s) or class(es); M2 WDL. ### Description ; If you pass an empty array for artifact_modes (i.e. artifact_modes = []) to the `FilterByOrientationBias` task when `run_orientation_bias_filter` is true, it will create an erroneous command line. #### Expected behavior; The orientation bias filter should not run, or should not do anything. #### Actual behavior; UNCONFIRMED: The tool will crash due to erroneous command line invocation (`... -AM -P ...`) which should yield an error that `""-P""` is not a valid artifact mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5025:505,error,error,505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5025,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); MarkDuplicatesSpark . ### Affected version(s); - Latest public release version [4.4.0.0]. ### Description . I am working on 40X human WGS data, running MarkDuplicatesSpark on the computation node of a cluster with 40 cores and 192GB RAM. MarkDuplicatesSpark usually hangs and never finish (even after few days) with log as below:. ```; 11:26:29.511 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.511 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:29.512 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.512 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folde",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:609,failure,failures,609,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,2,['failure'],['failures']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2 `--max-mnp-distance 0`. ### Affected version(s); - [X] Latest public release version [4.2.6.1]. ### Description; Same issue than described here: https://github.com/broadinstitute/gatk/issues/6473; ```; singularity exec docker://broadinstitute/gatk:4.2.6.1 gatk Mutect2 \; -R NC_000962.3.fa \; -I input.bam \; -O output.vcf \; --annotation StrandBiasBySample \; --num-matching-bases-in-dangling-end-to-recover 1 \; --max-reads-per-alignment-start 75 \; --max-mnp-distance 0; ```. And a MNP remains:; ```; grep -P ""NC_000962.3\t761155"" output.vcf; NC_000962.3 761155 . C T,G . . AS_SB_TABLE=0,0|9,9|0,2;DP=20;ECNT=1;MBQ=0,17,23;MFRL=0,311,334;MMQ=60,60,60;MPOS=31,40;POPAF=7.30,7.30;TLOD=44.10,3.01GT:AD:AF:DP:F1R2:F2R1:FAD:SB 0/1/2:0,18,2:0.807,0.143:20:0,5,0:0,4,1:0,15,2:0,0,9,11; ```. #### Expected behavior; ```; grep -P ""NC_000962.3\t761155"" output.vcf; NC_000962.3 761155 . C T [...]; NC_000962.3 761155 . C G [...]; ```. BAM, BAI, and VCF here: [files.zip](https://github.com/broadinstitute/gatk/files/8488204/files.zip). Cheers!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7782:459,recover,recover,459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7782,1,['recover'],['recover']
Availability,## Bug Report. ### Affected tool(s) or class(es); Mutect2 in tumour-normal mode. ### Affected version(s); - 4.2.6.1; - 4.2.0.0. ### Description ; Mutect2 crashes with an error:; ```; 16:53:19.984 INFO Mutect2 - Shutting down engine; [25 May 2022 16:53:19 BST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=1632632832; java.lang.NullPointerException; 	at htsjdk.samtools.ComparableSamRecordIterator.compareTo(ComparableSamRecordIterator.java:68); 	at htsjdk.samtools.ComparableSamRecordIterator.compareTo(ComparableSamRecordIterator.java:36); 	at java.util.PriorityQueue.siftUpComparable(PriorityQueue.java:656); 	at java.util.PriorityQueue.siftUp(PriorityQueue.java:647); 	at java.util.PriorityQueue.offer(PriorityQueue.java:344); 	at htsjdk.samtools.MergingSamRecordIterator.addIfNotEmpty(MergingSamRecordIterator.java:161); 	at htsjdk.samtools.MergingSamRecordIterator.<init>(MergingSamRecordIterator.java:94); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:429); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.iterator(ReadsPathDataSource.java:336); 	at org.broadinstitute.hellbender.engine.MultiIntervalLocalReadShard.iterator(MultiIntervalLocalReadShard.java:134); 	at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.<init>(AssemblyRegionIterator.java:86); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:188); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instan,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7872:170,error,error,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7872,2,"['down', 'error']","['down', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2, HaplotypeCaller; ./gatk Mutect2 -I scripts/microbial/mtb/samples/D1CLVACXX.1.Solexa-125092.aligned.bam -R scripts/microbial/mtb/Mycobacterium_tuberculosis_H37Rv.fasta -O test.vcf --num-matching-bases-in-dangling-end-to-recover 1 --max-reads-per-alignment-start 75. ### Affected version(s); Latest master branch as of 2/18/21. ### Description ; java.lang.ArrayIndexOutOfBoundsException: Index 25 out of bounds for length 25; 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.extendDanglingPathAgainstReference(AbstractReadThreadingGraph.java:913); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.mergeDanglingHead(AbstractReadThreadingGraph.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.recoverDanglingHead(AbstractReadThreadingGraph.java:542); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.recoverDanglingHeads(AbstractReadThreadingGraph.java:447); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.getAssemblyResult(ReadThreadingAssembler.java:685); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.createGraph(ReadThreadingAssembler.java:664); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assemble(ReadThreadingAssembler.java:549); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assembleKmerGraphsAndHaplotypeCall(ReadThreadingAssembler.java:195); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.runLocalAssembly(ReadThreadingAssembler.java:160); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7085:278,recover,recover,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7085,2,['recover'],"['recover', 'recoverDanglingHead']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2, multi-sample (2 samples) in Tumor-only mode. ### Affected version(s); - version 4.1.5.0, works fine on 4.1.4.1 and 4.1.4.0. ### Description ; Among my cohort of ~100 samples, mutect2 calling using reference genome hg38+alt+decoy (e.g. as provided in the gatk bundle) fails for one sample at a very specific location (chrUn_KI270748v1:61595-61748), returning an index out of range error. Slightly reducing the range removes the issue (e.g., calling on chrUn_KI270748v1:61596-61748), so it looks like an issue with the estimation of the number of repeats. This is not the most important location, but the error could affect more important calls for other people. The log is the following: ; ```gatk Mutect2 --java-options ""-Xmx15G"" -R /data/references/Homo_sapiens/GATK/hg38/Homo_sapiens_assembly38.fasta -I test1.bam -I test2.bam -O tests.vcf -L test_err.bed ; Using GATK jar /home/alcalan/.conda/mutect2-cd161e2f51ff2240ce6390abc942bbdd/share/gatk4-4.1.5.0-1/gatk-package-4.1.5.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15G -jar /home/alcalan/.conda/mutect2-cd161e2f51ff2240ce6390abc942bbdd/share/gatk4-4.1.5.0-1/gatk-package-4.1.5.0-local.jar Mutect2 -R /data/references/Homo_sapiens/GATK/hg38/Homo_sapiens_assembly38.fasta -I test1.bam -I test2.bam -O tests.vcf -L test_err.bed; 10:34:24.578 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/alcalan/.conda/mutect2-cd161e2f51ff2240ce6390abc942bbdd/share/gatk4-4.1.5.0-1/gatk-package-4.1.5.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Mar 23, 2020 10:34:24 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:34:24.819 INFO Mutect2 - ---------------------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6516:439,error,error,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6516,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - GATK v4.1.8.1. ### Description ; Hi, ; I am new to GATK so I hope this is not something trivial I overlooked. I called somatic variants using `Mutect2` (GATK v4.1.8.1) and wished to filter the results using `FilterMutectCalls`. I am running GATK via a docker container as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. ``` bash; ./gatk Mutect2 -I:tumor 1st.chr1.bam -I:normal 2nd.chr1.bam -O variants.vcf.gz --min-pruning 8 -R reference.chr1.fa; ```; I repeated this three times, the last time to make sure whether the .vcf.stats is being generated or not. This was a test run using the input filtered for chr1 using `samtools view -b`. I though this was the reason for getting the error message about Contig 2 not being present. ```bash; ...; 18:39:03.207 INFO ProgressMeter - 1:282722440 448.7 1529870 3409.8; 18:39:06.592 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 19.218222963000002; 18:39:06.592 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5376.604473962; 18:39:06.593 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 12201.77 sec; 18:39:06.594 INFO Mutect2 - Shutting down engine; [August 25, 2020 6:39:06 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 448.75 minutes.; Runtime.totalMemory()=12349079552; ***********************************************************************. A USER ERROR has occurred: Contig 2 not present in the sequence dictionary [1]. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Is there any way of getting around this and generating .vcf.stats without repeating a lengthy variant calling `Mutect2`? Is this a problem introdu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6768:840,error,error,840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768,1,['error'],['error']
Availability,## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of 7/18/18. ### Description ; When running Mutect yesterday on Mitochondrial data I got the following error:; ```; java.lang.IllegalArgumentException: Invalid interval. Contig:chrM start:-4 end:65. 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:728); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:86); 	at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:48); 	at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); 	at org.broadinstitute.hellbender.transformers.ReadTransformer$$Lambda$107/1786040872.apply(Unknown Source); 	at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:42); 	at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:14); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.fillDownsampledReadsCache(ReadsDownsamplingIterator.java:69); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.advanceToNextRead(ReadsDownsamplingIterator.java:55); 	at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.<init>(ReadsDownsamplingIterator.java:34); 	at org.broadinstitute.hellbender.engine.MultiIntervalLocalReadShard.iterator(MultiIntervalLocalReadShard.java:149); 	at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.<init>(AssemblyRegionIterator.java:109); 	at org.broadinstitute.hellbend,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5036:264,error,error,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5036,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [x] Latest public release version [2.1]; - [x] Latest master branch as of [2018-09-13]. ### Description ; The VCF header line; ""##Mutect Version=x.y""; causes problems for some VCF readers. Each header line is required to be a key-value pair and a space character is not expected in the key. (The VCF specification is not clear on this matter, but I've never encountered a space character in a VCF header key before.); Making VCF files that are easily readable by downstream tools should be in the interest of Mutect2. #### Steps to reproduce; Create a VCF file using Mutect2 and look at the header. #### Expected behavior; output; ""##MutectVersion=2.1"". #### Actual behavior; output; ""##Mutect Version=2.1""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5183:549,down,downstream,549,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5183,1,['down'],['downstream']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); 4.1.8.1. ### Description ; A user is getting a java.lang.NullPointerException when running Mutect2. As discussed at GATK Office Hours 09/28/20, it seems to be an issue where the BAM contigs are not present in the reference sequence dictionary. We discussed an improvement with either the filter for this problem or the error message. Complete stack trace:; ```; Using GATK jar GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -jar /GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar Mutect2 -R ref/Homo_sapiens_assembly38.fasta -I SRR_MM10_2pass_recal.bam --germline-resource /af-only-gnomad.hg38.vcf.gz --panel-of-normals ref/1000g_pon.hg38.vcf.gz -O SRR_somatic_mutect.vcf.gz; 13:24:08.400 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 25, 2020 1:24:08 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:24:08.556 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:24:08.557 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:24:08.557 INFO Mutect2 - Executing as xxx on Linux v3.10.0-1127.18.2.el7.x86_64 amd64; 13:24:08.557 INFO Mutect2 - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_192-b12; 13:24:08.557 INFO Mutect2 - Start Date/Time: September 25, 2020 1:24:08 PM BST; 13:24:08.557 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6851:403,error,error,403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); GATK version 4.2.5.0, run from the `us.gcr.io/broad-gatk/gatk:4.2.5.0` docker image. ### Description ; Rarely (~0.1%) within exomes that were sequenced at Broad (by GP), we encounter the error message whose stack trace is shown below. This occurs during batch processing, but it is specific to the .CRAM files: running Mutect2 on the same file produces the same error, and running Mutect2 on other files with the same arguments works fine. The files that trigger this error have contents that match the Broad GP-produced .md5 checksum, and they also pass `samtools quickcheck`. #### Steps to reproduce; (The variables are filled in as one might reasonably expect.); ```sh; /gatk/gatk --java-options ""-Xmx${RAM}G"" \; Mutect2 \; --input ${cram} \; --reference ${REFERENCE_FASTA} \; --panel-of-normals ${PON} \; --germline-resource ${GNOMAD} \; --intervals ${INTERVALS} \; --output ${unfiltered}; ```. #### Expected behavior; In all other cases, somatic variant calling proceeds successfully. #### Actual behavior; ```; 00:17:31.944 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 00:17:32.225 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.226 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.2.5.0; 00:17:32.226 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 00:17:32.227 INFO Mutect2 - Executing as root@8d398eecd56e on Linux v5.10.90+ amd64; 00:17:32.227 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 00:17:32.228 INFO Mutect2 - Start Date/Time: April 5, 2022 12:17:31 AM GMT; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.229 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755:271,error,error,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755,3,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); PlotModeledSegments. ### Affected version(s); Confirmed with 4.1.3, but also any version before this that uses optparse. ### Description ; The R package `optparse` is used in the R script `PlotModeledSegments.R` for plotting. The latest version of `optparse` (1.6.4) has been updated to include a check that the short-name of an option is only 1 character. ; See here: https://github.com/trevorld/r-optparse/commit/66acec58645f7401fc365bb769a72751671c2114; The `PlotModeledSegments.R` script in gatk has this line:; ```make_option(c(""--sample_name"", ""-sample_name""), dest=""sample_name"", action=""store""),```; which will now make `optparse` throw an error. #### Steps to reproduce; Install `optparse 1.6.4` and run `gatk PlotModeledSegments`. #### Expected behavior; The Rscript should parse the inputs and run. #### Actual behavior; PlotModeledSegments.R gives an error",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6207:698,error,error,698,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6207,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); PrintReads, and probably most other ROD-based tools. ### Affected version(s); GATK v4.1.0. ### Description ; I downloaded a .bam from SRA (https://www.ncbi.nlm.nih.gov/sra/SRX4114173[accn]); and ran gatk PrintReads to extract subregions based on a picard-style interval list. . The bug is that PrintReads ran without any warnings or errors and silently dropped some (though not all) reads that it should have included based on the interval list. It does include these reads if I run it with an interval list that just contains that one interval I'm interested in, but not if I include it among many other intervals. The interval list is sorted based on the .bam's sequence dictionary (by running ; `picard BedToIntervalList --SEQUENCE_DICTIONARY ../SRR7205167.1.bam --SORT -I GRCh38_intervals.bed -O GRCh38_intervals.sorted.list`). . The underlying issue as far as I can tell, is that the .bam reads are sorted, but not in the same order as its sequence dictionary. . This might be related to https://github.com/broadinstitute/gatk/issues/101. #### Expected behavior; I think GATK should fail with an error when this occurs. Otherwise it's easy for users to miss the data loss and end up with incorrect analyses. #### Actual behavior; Silently drops data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6065:161,down,downloaded,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6065,3,"['down', 'error']","['downloaded', 'error', 'errors']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); Reblock | JointGenotype. ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; We found a bug while running the latest JointGenotype pipeline (2.0.2). We are working with Dragen data (version 3.6.3); The error:. <details><summary>OPEN ERROR HERE</summary>; <p>. + gatk --java-options -Xms8g GenomicsDBImport --genomicsdb-workspace-path genomicsdb --batch-size 50 -L /tmp/scratch/cromwell-dragen-us-west-2/cromwell-execution/GatkJointGenotyping/7dd18ebe-29ca-47b1-b71a-56b99c362789/call-SplitIntervalList/glob-d928cd0f5fb17b6bd5e635f48c18ccfb/0073-scattered.interval_list --sample-name-map sample_name_map --reader-threads 5 --merge-input-intervals --consolidate; --; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/tmp/scratch/cromwell-dragen-us-west-2/cromwell-execution/GatkJointGenotyping/7dd18ebe-29ca-47b1-b71a-56b99c362789/call-ImportGVCFs/shard-73/tmp.9a65c1fc; 18:46:55.750 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 01, 2021 6:46:55 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:46:55.894 INFO GenomicsDBImport - ------------------------------------------------------------; 18:46:55.894 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.2.3.0; 18:46:55.895 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:46:55.895 INFO GenomicsDBImport - Executing as root@ip-10-10-156-13.us-west-2.compute.internal on Linux v4.14.243-185.433.amzn2.x86_64 amd64; 18:46:55.895 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 18:46:55.895 INFO GenomicsDBImport - Start Date/Time: December 1, 2021 6:46:55 PM GMT; 18",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7589:341,error,error,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7589,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); ReblockGVCF. ### Affected version(s); - [x ] Latest public release version [version?] _**GATK 4.2.6.1**_; - [ ] Latest master branch as of [date of test?]. ### Description ; We ran ReblockGVCF in 549 samples with the newest GATK (4.2.6.1). 8 of them returned the error similar to the message below . `org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chrM:1 [VC /tmp/scratch/prs-sabe-files/GRAR/2031812880_AJ.hard-filtered.gvcf.gz @ chrM:1 Q. of type=SYMBOLIC alleles=[G*, <NON_REF>] attr={END=1} GT=[[2031812880_AJ G*/G* DP 1691 AD 112,1579 {MIN_DP=1691, SQ=0}]] filters=weak_evidence`. and right below, we could find in all of them; `Caused by: org.broadinstitute.hellbender.exceptions.UserException$BadInput: Bad input: Homozygous reference genotypes must contain GQ or PL. Both are missing for hom ref genotype at chrM:1`. All the ""failed samples"" produced a broken output, in this case, missing the chrM (and the alt chr, such as HLA, chr1_alt etc)... It was weird because on WDL it returned as **_Success_** job... We need all the samples with a proper output to run the JointGenotype pipeline with the Reblocked Dragen samples output. #### Steps to reproduce; I'll share with you the chrM:1 from GVCF from a sample with no error; `chrM	1	.	G	<NON_REF>	.	PASS	END=72	GT:AD:DP:GQ:MIN_DP:PL:SPL:ICNT	0/0:2441,2:2443:99:1613:0,120,1800:0,255,255:40,13`. And now, the chrM:1 from a sample with the error; `chrM	1	.	G	<NON_REF>	.	weak_evidence	END=1	GT:AD:DP:SQ:MIN_DP	0/0:112,1579:1691:0:1691`. #### Expected behavior; No broken output. #### Actual behavior; Failing in a few samples, breaking the expected output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7797:313,error,error,313,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7797,3,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); StructuralVariationDiscoveryPipelineSpark . ### Affected version(s); GATK 4.1.2.0. ### Description . At end of run on a Hadoop cluster, the job aborts.... services=List(),; started=false); 2019-05-14 17:07:05 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-05-14 17:07:05 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-05-14 17:07:05 INFO MemoryStore:54 - MemoryStore cleared; 2019-05-14 17:07:05 INFO BlockManager:54 - BlockManager stopped; 2019-05-14 17:07:05 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-05-14 17:07:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-05-14 17:07:05 INFO SparkContext:54 - Successfully stopped SparkContext; 17:07:05.631 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 14, 2019 5:07:05 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 41.02 minutes.; Runtime.totalMemory()=23321378816; java.lang.IllegalArgumentException: Wrong FS: hdfs://scc:-1/project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.contig-sam-file.sam, expected: hdfs://scc; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105); at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:397); at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:393); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:393); at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:337); at org.apache.hadoop.fs.FileSystem.create",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942:881,down,down,881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942,1,['down'],['down']
Availability,"## Bug Report. ### Affected tool(s) or class(es); TransferReadTags. ### Affected version(s); - [X] Latest public release version [gatk-4.3.0.0]. ### Description ; When traversing the reads in both aligned (target) and unaligned (the one with the desired tag) BAMs an error is thrown complaining about a read `found in the aligned bam is not found in the unmapped bam`. However the reads exists. It looks like the `traverse` function that uses the lexicographic order difference between both query names will find a _negative_ `diff` and assume that the read in the aligned BAM is missing in the uBAM. However, with Illumina read headers it seems almost guaranteed that this is going to be an issue since the y-coord (the last colon-separated field in the header) often has numbers with different number of digits. The lexicographical comparison will fail to adjust when comparing two read names where the length of the read in the target BAM is larger than the length of the read in the uBAM. . This is the `traverse` function that throws the error:; https://github.com/broadinstitute/gatk/blob/2b0a558fdb9fdf654e796d5d69a092e26345583b/src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/TransferReadTags.java#L109-L145 . #### Steps to reproduce; Run `TransferReadTags` with an Illumina sequenced aligned BAM. I can provide dummy files if needed, but should be easy to reproduce. The following example should help illustrate the issue:. ```sh; $ /data/reddylab/software/gatk/gatk-4.3.0.0/gatk TransferReadTags \; --output /data/reddylab/Alex/tmp/TEST_BAM.with_umis.bam \; --read-tags RX \; --unmapped-sam /data/reddylab/Alex/tmp/TEST_BAM.umi.nsorted.ubam \; --input /data/reddylab/Alex/tmp/TEST_BAM.nsorted.bam; ```. Produces the following output:; ```; Using GATK jar /gpfs/fs1/data/reddylab/software/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8147:267,error,error,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8147,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator. ### Affected version(s); - [X] Latest public release version [4.5.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; As of v1.3.0 the `scales` R package turns the use of deprecated values for the `space` parameter into a hard error, resulting in the VariantRecalibrator R-script terminating with the following message:. > The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as of scales 0.3.0. This parameter is used repeatedly in the generated R-script via. ```R; scale_fill_gradient(high=""green"", low=""red"", space=""rgb""); ```. #### Steps to reproduce. ```shell; $ R --version; R version 4.1.2 (2021-11-01) -- ""Bird Hippie""; $ rm -rf ~/R; $ R; > install.packages(""ggplot2"", repos=""https://cloud.r-project.org/""); > packageVersion(""scales""); [1] 1.3.0; > quit(); $ gatk --version; The Genome Analysis Toolkit (GATK) v4.5.0.0; HTSJDK Version: 4.1.0; Picard Version: 3.1.1; $ gatk VariantRecalibrator [arguments omitted for brevity]; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.9339186078473502558';source('/path/to/rscript.r');; Stdout: ; Stderr: Error:; ! The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as; of scales 0.3.0.; Backtrace:; ; 1. base::source(""/path/to/rscript.r""); 2.  base::withVisible(eval(ei, envir)); 3.  base::eval(ei, envir); 4.  base::eval(ei, envir); 5. ggplot2::scale_fill_gradient(high = ""green"", low = ""red"", space = ""rgb""); 6. ggplot2::continuous_scale(...); 7.  ggplot2::ggproto(...); 8.  rlang::list2(...); 9. scales::seq_gradient_pal(low, high, space); 10. scales::pal_gradient_n(c(low, high), space = space); 11. lifecycle::deprecate_stop(""0.3.0"", ""pal_gradient_n(space = 'only supports be \""Lab\""')""); 12. lifecycle:::deprecate_stop0(msg); 13. rlang::cnd_signal(...); Execution halted; $ R; > install.packages(""remot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664:320,error,error,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; ; ### Affected version(s); -All versions after 4.1.4.1, including 4.1.9.0. ### Description ; A user on the forum reported an error message that does not give position information when reporting an allele problem in the reference. A similar issue in FilterVariantTranches was previously discussed at #6701 however the fix only changed FilterVariantTranches. We discussed adding a change with VariantRecalibrator that would also fix other GATK tools when this issue comes up. ; Forum Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360074618292-New-version-of-GATK-leads-to-VariantRecalibrator-error-. #### Command; `~/bin/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963:196,error,error,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963,2,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; Resource Bundle. ### Affected version(s); Resource Bundle downloaded 21. July 2020 (ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/ OR https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0;tab=objects?prefix=). ### Description ; The available dataset lack information for FS, SOR etc. but this parameter are necessary for the best practice workflow of the VariantRecalibrator and cannot be added with the VariantAnnotator as the individual information is not included. #### Steps to reproduce; Run VariantRecalibrator with the publicly available reference files. And the recommended parameter settings. gatk --java-options ""-Xmx24g -Xms24g"" VariantRecalibrator \; -V ${inputfile} \; --trust-all-polymorphic \; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 \; -an FS -an ReadPosRankSum -an MQRankSum -an QD -an SOR \; -mode INDEL \; --max-gaussians 4 \; -resource:mills,known=false,training=true,truth=true,prior=12 ${gatk_ref}Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ${gatk_ref}Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz \; -resource:dbsnp,known=true,training=false,truth=false,prior=2 ${gatk_ref}/Homo_sapiens_assembly38.dbsnp138.vcf \; -O ${fileprefix}_indels.recal \; --tranches-file ${fileprefix}_indels.tranches. #### Expected behavior; Calculation of VQSLOD tranches. #### Actual behavior; A USER ERROR has occurred: Bad input: Values for FS annotation not detected for ANY training variant in the input callset. VariantAnnotator may be used to add these annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6715:129,down,downloaded,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6715,4,"['ERROR', 'avail', 'down']","['ERROR', 'available', 'downloaded']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); _FilterAlignmentArtifacts_. ### Affected version(s); - [x] Latest public release version [4.1.4.1]. ### Description ; FilterAlignmentArtifacts consistently errors out with segmentation faults or IllegalArgumentExceptions. I've attached the log files for each of these errors below.; [invalid_interval.log](https://github.com/broadinstitute/gatk/files/4017907/invalid_interval.log); [seg_fault.log](https://github.com/broadinstitute/gatk/files/4017908/seg_fault.log). #### Steps to reproduce; The command to reproduce both errors is the same, and I have attached it below.; [realignment_filter.txt](https://github.com/broadinstitute/gatk/files/4017918/realignment_filter.txt); The BWA mem index I'm using is hg38, however the BAM that I am realigning from is hg19; thus, the reference argument is the hg19 fasta. I am happy to transfer zip files containing the other files need to reproduce this. Just let me know where to send them. #### Expected behavior; _FilterAlignmentArtifacts_. #### Actual behavior; _Errors_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6344:206,error,errors,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6344,4,"['error', 'fault']","['errors', 'faults']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); _FilterMutectCalls_. ### Affected version(s); - gatk-4.1.0.0 (_latest_). ### Description . Hi,. I am using _Mutect2_ (v4.1.0.0) and similar to a previous bug reported on `AF=.`, _FilterMutectCalls_ seems to complain about MPOS fields having a value of `.`. No intermediate processing was done between _Mutect2_ and _FilterMutectCalls_. Below the error stack trace :. ```; 17:13:28.491 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data-ddn/home/anthony/sbx/mutect2/work/conda/gatk4-mutect2-nf-bcf605d6af4c0524a368d3d105898641/share/gatk4-4.1.0.0-0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 17:13:30.503 INFO FilterMutectCalls - ------------------------------------------------------------; 17:13:30.503 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.0.0; 17:13:30.504 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:13:30.504 INFO FilterMutectCalls - Executing as anthony@node063 on Linux v2.6.32-220.el6.x86_64 amd64; 17:13:30.504 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 17:13:30.504 INFO FilterMutectCalls - Start Date/Time: February 17, 2019 5:13:28 PM CET; 17:13:30.504 INFO FilterMutectCalls - ------------------------------------------------------------; 17:13:30.505 INFO FilterMutectCalls - ------------------------------------------------------------; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Version: 2.18.2; 17:13:30.505 INFO FilterMutectCalls - Picard Version: 2.18.25; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:13:30.505 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:13:30.506 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:13:30.506 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5684:396,error,error,396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5684,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [ ] Latest public release version GATK 4.1.9.0 with data version funcotator_dataSources.v1.7.20200521g. ### Description . #### Steps to reproduce. I'm trying to run GATK Funcotator using the funcotator_dataSources.v1.7.20200521g data download. The command line that I'm using is:; ```; gatk Funcotator \; --variant cohort.vcf.gz \; --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa \; --ref-version hg38 \; --data-sources-path funcotator_dataSources.v1.7.20200521g \; --output cohort.funcotator.vcf.gz \; --output-file-format VCF; ```. If I run that command line without the `gnomad_*.tar.gz`'s expanded, it works fine and annotates my `cohort.vcf.gz` into `cohort.funcotator.vcf.gz`. . Following the directions at [Funcotator Information and Tutorial - 1.1.2.2.1: enabling gnomAD](https://gatk.broadinstitute.org/hc/en-us/articles/360035889931-Funcotator-Information-and-Tutorial#1.1.2.2.1), if I expand both `gnomAD_exome.tar.gz` and `gnomAD_genome.tar.gz`, funcotator dies at startup with a `400 Bad Request` error. This also happens if I expand either one of the `gnomad_*.tar.gz` files individually. . #### Expected behavior; Funcotator annotates my VCF and includes gnomAD annotations in the output VCF. . #### Actual behavior. Crash with 400 Bad Request:. ```; Using GATK jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar Funcotator --variant cohort.vcf.gz --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa --ref-version hg38 --data-sources-path funcotator_dataSources.v1.7.20200521g --output cohort.funcotator.vcf.gz --output-file-format VCF; 14:24:33.589 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/share/gatk4-4.1.9.0-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926:325,down,download,325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926,1,['down'],['download']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [x] Latest public release version [version v4.1.4.1]; - [ ] Latest master branch as of [date of test?]. ### Description . Hi @jonn-smith , I saw you often address Funcotator related issues, so I thought this might be of interest to you. I ran funcotator on a vcf created by mutect2 from RNA-seq data. The vcf includes a large deletion in the GABARAP gene, and when Funcotator processes this annotation, it dies with an error about a query that extends past the end of a contig:. > htsjdk.samtools.SAMException: Query asks for data past end of contig. Query contig ENST00000571253.1|ENS; G00000170296.9|OTTHUMG00000102156.3|OTTHUMT00000440082.2|AC120057.8-003|GABARAP|837|UTR5:1-753|CDS:754-8; 37| start:1 stop:895 contigLength:837; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(Ca; chingIndexedFastaSequenceFile.java:316); at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource; .java:78); at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource; .java:64); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.; getFivePrimeUtrSequenceFromTranscriptFasta(GencodeFuncotationFactory.java:744); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createUtrFuncotation(GencodeFuncotationFactory.java:1568); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:983); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:78",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345:510,error,error,510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Mutect2_. ### Affected version(s); - GATK 4.1.4.1. ### Description ; When running Mutect2 (from GATK v4.1.4.1) using the following command:. `gatk Mutect2 -R [path to grch37-1kg.fa] -I testcase.bam -O pon.vcf`. to create a PoN on NovaSeq WGS-data processed through the best practice pipeline (with the BQSR-steps run through the Spark-enabled tools, and bwa mem with -Y flag) I get the following error in multiple regions:. [Stacktrace](https://www.dropbox.com/s/d2n5zflj9u11oj8/stacktrace.png?dl=0). AFAIK this is related to the new code path introduced in #6240 and seem to be triggered when there are more than 2 reads supporting a fragment but all of them are either duplicate reads or supplemntary/secondary alignments. Any input is greatly appreciated. I guess a temporary fix is to use the --independent-mates flag (although haven't tried it yet -- how much worse mutation calling performance do one incur when using that flag?). #### Steps to reproduce; Use the following small test case .bam-file as input to the command specified above:. [Testcase](https://www.dropbox.com/s/hilcj3aj0jnjdmh/testcase.bam?dl=0). #### Expected behavior; Completion of mutect2 without Exception. #### Actual behavior; Early termination of the mutect2 run due to raising an exception when trying to create a fragment with no read data to back it up. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6310:447,error,error,447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6310,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _ReadsPipelineSpark_ with --spark-runner SPARK. ### Affected version(s); - 4.1.4. ### Description ; @tomwhite I was asked to tag you, please let me know if you think anyone else should look at this. This issue is created from a forum bug report (https://gatkforums.broadinstitute.org/gatk/discussion/24511/error-in-readspipelinespark-version-4-1-4/p1). More information can be requested if necessary. Stack trace copied below:; > A USER ERROR has occurred: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf because writing failed with exception concat: target file /gatk-test2/WES2019-022_S4_out.vcf.parts/output is empty; > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInternal(FSNamesystem.java:2303); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInt(FSNamesystem.java:2257); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concat(FSNamesystem.java:2219); > at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.concat(NameNodeRpcServer.java:829); > at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.concat(AuthorizationProviderProxyClientProtocol.java:285); > at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.concat(ClientNamenodeProtocolServerSideTranslatorPB.java:580); > at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); > at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617); > at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2278); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2274); > at java.security.AccessController.doPrivileged(Native Method); > at javax.security.auth.Subject.doAs(Subject.java:422); > at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroup",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6218:356,error,error-in-readspipelinespark-version-,356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6218,2,"['ERROR', 'error']","['ERROR', 'error-in-readspipelinespark-version-']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [x] Latest public release version 4.1.7.0. ### Description . The following error message is output:. A USER ERROR has occurred: Bad input: Is the input a file of segment variant contexts? Variant context does not represent a copy number segment: [VC null @ 6:4130448-4130544 Q. of type=SYMBOLIC alleles=[C*, <DEL>] attr={END=4130544, Num_Probes=1, Segment_Call=-, Segment_Mean=-30.018694} GT=[] filters=. The local info in the segment file is:; 5 176563624 180687750 618 -0.053122 0; 6 203183 4128317 205 0.046724 0; 6 4130448 4130544 1 -30.018694 -; 6 4130545 6168103 42 -0.085445 0; 6 6174562 17463556 490 0.022415 0; 6 17493361 25510885 347 0.080520 0. This is a bad error message. The minimum size for a segment to be processed is 150 bases and that variant is only 96 bases, so it's failing that validation. #### Expected behavior; Should process variant without producing error. Hat tip: @jonn-smith for figuring out the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6575:195,error,error,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6575,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [x] Latest public release version 4.2.2.0. ### Description . Running apt-get inside docker image fails. #### Steps to reproduce. (base) fleharty@wm3b9-dfa docker % docker run -it broadinstitute/gatk:4.2.2.0; Unable to find image 'broadinstitute/gatk:4.2.2.0' locally; 4.2.2.0: Pulling from broadinstitute/gatk; a7fe112a8303: Already exists ; Digest: sha256:32175c3c7c1fb9f5bd6650183c9c5cf26fb822dddb0cad0123d48c33124b6065; Status: Downloaded newer image for broadinstitute/gatk:4.2.2.0; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# apt-get update; Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]; Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] ; Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB] ; Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB] ; Get:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:551,Down,Downloaded,551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,1,['Down'],['Downloaded']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - any version with basename(basename()) function call. (e.g. latest version on master). ### Description ; ```; ""Failed to evaluate 'output_basename' (reason 1 of 1): Evaluating basename(basename(tumor_reads, "".bam""), "".cram"") failed: Failed to interpret 'CDS-00rz9N.hg38' as a file path input for basename (reason 1 of 1): java.lang.IllegalArgumentException: Could not build the path ""CDS-00rz9N.hg38"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, Google Cloud Storage, DRS. Failures: ; HTTP: CDS-00rz9N.hg38 does not have an http or https scheme (IllegalArgumentException); Google Cloud Storage: Path ""CDS-00rz9N.hg38"" does not have a gcs scheme (IllegalArgumentException); DRS: CDS-00rz9N.hg38 does not have a drs scheme. (IllegalArgumentException); Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems""; ```; #### Steps to reproduce; Just run the mutect2.wdl on terra it seems create the issue (maybe using a bam filepath with a name in ""gs://[path]/[NAME].hg38.bam"". #### Expected behavior; I think using basename(basename( is not working with the new version of terra, I would expect another solution with an if on the name end or something.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7485:654,Failure,Failures,654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7485,1,['Failure'],['Failures']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. /gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/CalculateContamination.java; /gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/ContaminationModel.java. ### Affected version(s); - [x] Latest public release version - v4.2.0.0 (also detected on previous versions) ; - [x] Latest master branch as of 03/30/2021. ### Description ; **ContaminationModel**; **Problem:**; Where errorDepth is greater than oppositeDepth, the output contamination is reported as **0 contamination** , which can be misinterpreted by the end user. calculateContaminationFromHoms receives the list of pileups PileupSummary; It iterates from 0.4 INITIAL_MAF_THRESHOLD down to zero. In each iteration pileups are selected using multiple, different strategies.; When the stdError exit condition is met (i.e., stdError < (contamination* MIN_RELATIVE_ERROR +MIN_ABSOLUTE_ERROR)), it reports out the contamination and stdError values. The issue is that this stdError exit condition is also met when contamination = 0, because in this case, stdError is also equal to 0, and thus is always less than the minimum value for (contamination * MIN_RELATIVE_ERROR [0.2] + MIN_ABSOLUTE_ERROR [0.001]), which cannot be less than 0.001. . final double stdError = homs.isEmpty() ? 1 : Math.sqrt(homs.stream().mapToDouble(ps -> {; final double d = ps.getTotalCount();; final double f = 1 - oppositeAlleleFrequency.applyAsDouble(ps);; return (1 - f) * d * contamination * ((1 - contamination) + f * d * contamination);; }).sum()) / totalDepthWeightedByOppositeFrequency;. ** return (1 - f) * d * contamination * ((1 - contamination) + f * d * contamination);**. Root cause:; At the first MAF iteration where errorDepth is greater than oppositeDepth, contamination is set to 0 (according to the code logic shown below), the function exits the iteration process, and no further MAF thresholds are t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177:521,error,errorDepth,521,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177,2,"['down', 'error']","['down', 'errorDepth']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. `SortSamSpark --sort-order coordinate`. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. `4.4.0.0`. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. An error occurs when using SortSamSpark to sort the large BAM file that contain long reads only (90x human wgs, min. read length>10kbp).; However, if the large BAM file contains short reads, it executes normally. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. ```shell; sysctl -w vm.max_map_count=2147483642; gatk SortSamSpark \; --input HG002-NA24385-GM24385.bam \; --output HG002-NA24385-GM24385.sorted.bam \; --sort-order coordinate \; --java-options ""-XX:+UnlockDiagnosticVMOptions -XX:GCLockerRetryAllocationCount=96 -XX:+UseNUMA -XX:+UseZGC -Xmx1794G"" \; --tmp-dir . \; -- \; --spark-runner LOCAL --spark-master local[96] --conf spark.local.dir=./tmp --conf spark.port.maxRetries=61495; ```. #### Expected behavior; _Tell us what should happen_. Output a sorted BAM file. #### Actual behavior; _Tell us what happens instead_. `java.lang.OutOfMemoryError: Required array length ? is too large`. The last lines of the log file.; ```; 11:00:42.884 INFO BlockManagerInfo - Removed taskresult_15758 on 172.20.19.130:43279 in memory (size: 10.5 MiB, free: 1076.2 GiB); 11:00:42.888 INFO TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool; 11:00:42.902 INFO DAGScheduler - ResultStage 0 (sortByKey at SparkUtils.java:165) finished in 1652.742 s; 11:00:42.915 INFO DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job; 11:00:42.916 INFO TaskSchedulerImpl - Killing all running ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:390,error,error,390,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_; CalibrateDragstrModel; ### Affected version(s); - [ ] Latest public release version [gatk/4.2.0.0]. ### Description . gatk 4.2.0.0 CalibrateDragstrModel produces the following stacktrace.... ```; 13:55:31.187 INFO CalibrateDragstrModel - Initializing engine; 13:55:33.395 INFO CalibrateDragstrModel - Done initializing engine; 13:55:33.396 INFO ProgressMeter - Starting traversal; 13:55:33.396 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 13:55:42.364 INFO CalibrateDragstrModel - Shutting down engine; [April 4, 2021 1:55:42 PM EDT] org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=2384986112; java.lang.IllegalArgumentException: Start cannot exceed end.; at htsjdk.samtools.util.IntervalTree.put(IntervalTree.java:74); at htsjdk.samtools.util.IntervalTree.merge(IntervalTree.java:137); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$ShardReadBuffer.add(CalibrateDragstrModel.java:949); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$1.tryAdvance(CalibrateDragstrModel.java:798); at java.util.Spliterator.forEachRemaining(Spliterator.java:326); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.collectCaseStatsSequencial(CalibrateDragstrModel.java:459); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.traverse(CalibrateDragstrModel.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:623,down,down,623,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['down'],['down']
Availability,"## Bug Report. ### Affected tool(s) or class(es); _VariantEval, -O, --output_. ### Affected version(s); - [X] Latest public release version [4.1.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; Program starts then terminates with error:; `***********************************************************************`; `A USER ERROR has occurred: Couldn't read file file:///[.....]/X034.eval.grp. Error was: It doesn't exist.`; `***********************************************************************`. Note: The error is not thrown, and VariantEval completes successfully, if a zero-byte file with the name passed with the `-o` or `--output` arguments is created before executing VariantEval; For this example: `touch X034.eval.grp`. #### Steps to reproduce; Command line:; `gatk VariantEval -R $ref -L autosomes.list --eval W034.raw.annotated.vcf.gz --dbsnp dbsnp.vcf.gz -O X034.eval.grp`. #### Expected behavior; Expect the program to create its own output file (as other GATK tools do). #### Actual behavior; Terminates with error (above). ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5674:255,error,error,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5674,5,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); `Funcotator`. ### Affected version(s); GATK 4.1.0.0 release. ### Description . Functotator MAF output does not properly show genotypes from somatic multi-tumor VCF files produced using M2. It looks like only genotypes from the first tumor sample are shown, but there are no errors or messages to point the user to this fact. Only a single `tumor_sample` and `normal_sample` are reported in the MAF header:. ```; ##normal_sample=xxx; ##source=FilterMutectCalls; ##source=Funcotator; ##source=Mutect2; ##tumor_sample=xxx; ```. Conversely, instructing `Funcotator` to output VCF format properly adds the annotation to the INFO field while retaining the FORMAT-level genotypes works well. However, in this case the VCF header also only lists a single tumor_sample (take note: this is a separate bug, though mostly aesthetics) despite all tumor genotypes being included. #### Steps to reproduce; Run Funcotator with output format set to MAF on any multi-tumor VCF file. #### Expected behavior; Either one of:; 1. `Funcotator` should return an error when trying to process multi-tumor VCF to MAF output; 2. `Funcotator` MAF should output multiple lines per funcotation for each tumor sample, indicating the comparison in the `Tumor_Sample_Barcode` and `Normal_Sample_Barcode` columns.; 3. `Funcotator` should not output genotype information when processing multi-tumor VCF to MAF (this could also be an additional Funcotator parameter that must be switched on when requesting MAF output). #### Actual behavior; Funcotator runs without errors or warnings and the output file is missing genotypes for the other tumor samples",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5687:324,error,errors,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5687,3,['error'],"['error', 'errors']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); `Funcotator`. ### Affected version(s); GATK 4.1.0.0 release. ### Description ; Funcotator returns a `NullPointerException` when trying to output compressed VCF:. ```; 15:35:26.085 INFO Funcotator - Creating a VCF file for output: XXXX; 15:35:26.125 INFO ProgressMeter - Starting traversal; 15:35:26.125 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; log4j:WARN No appenders could be found for logger (org.broadinstitute.hellbender.tools.funcotator.dataSources.vcf.VcfFuncotationFactory).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 15:35:26.328 INFO Funcotator - Shutting down engine; [February 15, 2019 3:35:26 PM EST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.18 minutes.; Runtime.totalMemory()=3391094784; java.lang.NullPointerException; at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeFeature(TabixIndexCreator.java:106); at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeIndex(TabixIndexCreator.java:129); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.close(IndexingVariantContextWriter.java:177); at htsjdk.variant.variantcontext.writer.VCFWriter.close(VCFWriter.java:231); at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRenderer.close(VcfOutputRenderer.java:137); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.closeTool(Funcotator.java:883); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:970); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5683:761,down,down,761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5683,1,['down'],['down']
Availability,"## Bug Report. ### Affected tool(s) or class(es); `GenomicsDBImport` (writing to a GCS bucket). ### Affected version(s). `4.2.3.0`. ### Description . Running `GenomicsDBImport` on 264 whole genome GVCFs, each of ~1GB size (called with HaplotypeCaller and blocked with only one bin threshold `-GQB 20`). Doing that on 50 genome intervals generated by `SplitIntervals`, so 50 `GenomicsDBImport` jobs write 50 DBs to a GCS bucket. 49 of them worked successfully, however one have failed with the following error:. ```sh; [TileDB::FileSystem] Error: (write_to_file) GCS: Only the last of the uploadable parts can be less than 5MB, try increasing TILEDB_UPLOAD_BUFFER_SIZE to at least 5MB ; ```. #### Steps to reproduce. Can't produce a small reproducible examples because it only happens with the full dataset. However, below is the command that I ran. . ```sh; gatk --java-options -Xms16g GenomicsDBImport \; --genomicsdb-workspace-path gs://cpg-seqr-main-analysis/seqr_loader/v0/genomicsdbs/interval_0_outof_50 \; --batch-size 50 -L 0000-scattered.interval_list \; --sample-name-map sample_map.csv \; --reader-threads 16 \; --merge-input-intervals \; --consolidate; ```. * `sample_map.csv` contains GCS paths to the GVCFs.; * `0000-scattered.interval_list` is one interval generated by calling SplitIntervals to make 50 intervals. #### Expected behavior. Finish without an error, write DB to the specified bucket. #### Actual behavior. Throws a TileDB error. . Does it have to do with the `--consolidate` flag? I couldn't find what `TILEDB_UPLOAD_BUFFER_SIZE` means, but the [TileDB docs](https://docs.tiledb.com/main/how-to/configuration) reference ""sm.consolidation.buffer_size"" with the default size of 50000000 (50MB?). I'll try rerunning without consolidation. Full log:. ```sh; Using GATK jar /root/micromamba/share/gatk4-4.2.3.0-1/gatk-package-4.2.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribbl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7653:503,error,error,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7653,2,"['Error', 'error']","['Error', 'error']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); `PrintReadsSpark`. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . I first encountered this type of error in a prototype tool I'm writing, so to dig further about what's happening, I run our simplest Spark tool&mdash;`PrintReadsSpark`. `PrintReadsSpark` reports errors when intervals are specified in a BED file (see command given in the stack trace). * Scenario 1: run with a WGS bam and give intervals via `-L PATH_TO_BED_FILE`, error is reported; * Scenario 2: run with the WGS bam and give intervals via `-L chrX:[0-9]+-[0-9]+`, no error; * Scenario 3: run with bam that is shrunk from the WGS bam by including reads only in the union of intervals, then with `-L PATH_TO_BED_FILE`, no error; * Scenario 4: run with bam that is shrunk from the WGS bam by including reads only in the union of intervals, then with `-L chrX:[0-9]+-[0-9]+`, no error; * Scenario 5: download the shrunken bam to local machine and run `PrintReadsSpark` with `-L PATH_TO_BED_FILE`, no error. Stack trace from scenario 1:; ```; ./gatk PrintReadsSpark \; -I hdfs://shuang-small-m:8020/data/HG00512.cram.samtools1_9.bam \; -O hdfs://shuang-small-m:8020/results/temp.bam \; -L hdfs://shuang-small-m:8020/data/intervals.bed \; -- \; --spark-runner GCS \; --cluster shuang-small \; --project broad-dsde-methods. Using GATK jar /Users/shuang/GATK/gatk/build/libs/gatk-spark.jar; found cached jar: gs://broad-dsde-methods/shuang/tmp/gatk-jars/gatk-spark_5710525a8758807e46bbb660ac998e63.jar. Replacing spark-submit style args with dataproc style args. --cluster shuang-small --project broad-dsde-methods -> --cluster shuang-small --project broad-dsde-methods --properties spark.kryoserializer.buffer.max=512m,spark.driver.maxResultSize=0,spark.driver.userClassPathFirst=false,spark.io.compression.codec=lzf,spark.yarn.executor.memoryOverhead=600,spark.driver.extraJavaOptions=-DGATK_STA",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:243,error,error,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,8,"['down', 'error']","['download', 'error', 'errors']"
Availability,"## Bug Report. ### Affected tool(s) or class(es); gatk GenotypeGVCFs. ### Affected version(s); - [X] Latest public release version [GATK 4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; Files generated by 'gatk GenotypeGVCFs' with french locale in February (Fvrier in french) August (Aot) or December (Dcembre) have ISO-8859-1 encoding instead of UTF-8 encoding. Indeed, the output files have this line:. `##GATKCommandLine=<ID=GenotypeGVCFs,CommandLine=""GenotypeGVCFs --output /volumes/vol002/COVID/GenomicDB/vcf/COVID.05022021.int00.vcf.gz --variant gendb://dbtot/int00 --reference /volumes/vol002/reference/human_g1k_v37.fasta --tmp-dir /volumes/vol002/COVID/GenomicDB/tmp/tmpint00 --include-non-variant-sites false --merge-input-intervals false --input-is-somatic false --tumor-lod-to-emit 3.5 --allele-fraction-error 0.001 --keep-combined-raw-annotations false --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 30.0 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --num-reference-samples-if-no-call 0 --genomicsdb-use-bcf-codec false --genomicsdb-shared-posixfs-optimizations false --only-output-calls-starting-in-intervals false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7081:848,error,error,848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7081,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); gatk MarkDuplicatesSpark. ### Affected version(s); - GATK 4.2.6.1; - Spark 3.2.1. ### Description ; File sizes are different between MarkDuplicates and MarkDuplicatesSpark (run locally). file sizes:; input cram: 1094584927; output bam (MarkDuplicates): 2839215419; output bam (MarkDuplicatesSpark): 3536690732. #### Steps to reproduce; command:. `java -Xmx200G -jar /opt/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar MarkDuplicatesSpark \; -I file.cram \; -O file_sorted_markduplicates.bam \; -M file_markduplicates_metrics.txt \; -R homo_sapiens.fa`. #### Expected behavior; output bam should be the same size (or very similar) between MarkDuplicates and MarkDuplicatesSpark. Note: this is when using the local version of the gatk package, using the spark version I get the following error:. `Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/spark/Partitioner; 	at java.lang.Class.getDeclaredConstructors0(Native Method); 	at java.lang.Class.privateGetDeclaredConstructors(Class.java:2671); 	at java.lang.Class.getConstructors(Class.java:1651); 	at org.broadinstitute.hellbender.utils.ClassUtils.canMakeInstances(ClassUtils.java:31); 	at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:319); 	at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:180); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.lang.ClassNotFoundException: org.apache.spark.Partitioner; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:387); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:418); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:351); 	... 8 more`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8007:833,error,error,833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8007,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool(s) or class(es); gatk SortVcf. ### Affected version(s); Mac OS X 10.16 x86_64; OpenJDK 64-Bit Server VM 1.8.0_322-b06; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.4.1. ### Description ; SortVcf finishes sorting and writes out a VCF, but then fails with java.lang.ArrayIndexOutOfBoundsException when generating the tabix index. To work around this, I can run with --CREATE_INDEX false and then run `tabix` to generate the index.; ```; INFO	2022-05-06 12:14:45	SortVcf	wrote 675,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:41,521,469; INFO	2022-05-06 12:14:45	SortVcf	wrote 700,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:61,833,861; INFO	2022-05-06 12:14:45	SortVcf	wrote 725,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:78,534,676; INFO	2022-05-06 12:14:45	SortVcf	wrote 750,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:100,707,682; INFO	2022-05-06 12:14:45	SortVcf	wrote 775,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:117,527,190; INFO	2022-05-06 12:14:45	SortVcf	wrote 800,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:134,613,380; INFO	2022-05-06 12:14:45	SortVcf	wrote 825,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:153,780,108; INFO	2022-05-06 12:14:45	SortVcf	wrote 850,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:173,329,831; INFO	2022-05-06 12:14:46	SortVcf	wrote 875,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:192,133,262; [Fri May 06 12:14:46 EDT 2022] picard.vcf.SortVcf done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=2855272448; To get help, see http://broadinstitute.github.io/picard/index.html#G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7838:202,avail,available,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7838,1,['avail'],['available']
Availability,"## Bug Report. ### Affected tool(s) or class(es); gatkcondaenv.yml from gatk-4.3.0.0.zip downloaded from https://github.com/broadinstitute/gatk/releases. ### Affected version(s); - [ ] Latest public release version [4.3.0.0]. ### Description ; I downloaded gatk-4.3.0.0.zip from https://github.com/broadinstitute/gatk/releases, unzip it on my linux server, and installed gatk by runnimg command line:; conda env create -n gatk -f gatkcondaenv.yml; After installing ended, I checked my installed gatk version and found it be 3.8-1-0-gf15c1c3ef but not installed 4.3.0.0. Any solution?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8120:89,down,downloaded,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8120,2,['down'],['downloaded']
Availability,"## Bug Report. ### Affected tool(s) or class(es); mutect2. ### Affected version(s); 4.1.7.0. ### Description ; I several times now observed an IndexOutOfBoundException in Mutect2. ; Seems to be file specific.; I run this in nextflow 19.10.0. I am open for hints. ; Kind regards!. ```; Command error:; 14:15:19.210 INFO ProgressMeter - 17:44868376 34.1 8548240 250606.9; 14:15:29.214 INFO ProgressMeter - 17:57594001 34.3 8591020 250636.0; 14:15:39.219 INFO ProgressMeter - 17:70805091 34.4 8635430 250711.9; 14:15:49.219 INFO ProgressMeter - 17:79595935 34.6 8665160 250363.6; 14:15:59.220 INFO ProgressMeter - 18:8951018 34.8 8700660 250184.4; 14:16:09.220 INFO ProgressMeter - 18:18750419 34.9 8733540 249932.1; 14:16:19.220 INFO ProgressMeter - 18:33362396 35.1 8782590 250142.7; 14:16:29.221 INFO ProgressMeter - 18:47557520 35.3 8830240 250311.5; 14:16:39.224 INFO ProgressMeter - 18:61732084 35.4 8877870 250478.0; 14:16:49.230 INFO ProgressMeter - 18:75390202 35.6 8923700 250591.9; 14:16:59.238 INFO ProgressMeter - 19:4254509 35.8 8947170 250079.8; 14:17:09.252 INFO ProgressMeter - 19:13499637 35.9 8978420 249787.8; 14:17:19.268 INFO ProgressMeter - 19:23216815 36.1 9011160 249539.8; 14:17:29.278 INFO ProgressMeter - 19:31344990 36.3 9038470 249145.0; 14:17:39.298 INFO ProgressMeter - 19:41157554 36.4 9071590 248912.2; 14:17:49.867 INFO ProgressMeter - 19:42798895 36.6 9077130 247866.1; 14:17:59.042 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.15517662000000002; 14:17:59.043 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 13.012444101000002; 14:17:59.043 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 45.65 sec; 14:17:59.043 INFO Mutect2 - Shutting down engine; [May 15, 2020 2:17:59 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 36.79 minutes.; Runtime.totalMemory()=3793223680; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0; at java.util.ArrayList.rangeCheck(Ar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6605:293,error,error,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6605,1,['error'],['error']
Availability,"## Bug Report. ### Affected tool; CreateSomaticPanelOfNormals. ### Affected version; Tested on version 4.1.8.0 (likely commit 3e921c6, GenomicsDB 1.3.0 #6654). ### Description ; Panel of normals generated from version 4.1.8.0 has some ~28% less records (~52% less ALT alleles) than one created with 4.1.7.0 (tested at commit 9cc92e3) with all input data and arguments unchanged. The GenomicsDB version does not seem to matter as PoN created running CreateSomaticPanelOfNormals on 4.1.8.0 has the result is about the same regardless of whether GenomicsDBImport was run on 4.1.7.0 or 4.1.8.0. CreateSomaticPanelOfNormals on 4.1.7.0 fails to run on the new GenomicsDBs. |Mutect2|GenomicsDB|CreateSomaticPanelOfNormals|Output|; |---|---|---|---|; |4.1.7.0|4.1.7.0|4.1.7.0|100% alleles (reference)|; |4.1.8.0|4.1.8.0|4.1.7.0|expected error|; |4.1.7.0|4.1.7.0|4.1.8.0|48% alleles|; |4.1.8.0|4.1.8.0|4.1.8.0|48% alleles|. #### Steps to reproduce; The PoN was created with GRCh38, scattered over chromosomes. Mutect command:; ```; $gatk/gatk --java-options ""-Xmx4G"" Mutect2 \; 	-R $reference -L $chr \; 	-I $bam --max-mnp-distance 0 \; 	-O @out1@; ```. GenomicsDBImport command:; ```; $gatk/gatk --java-options ""-Xms8G -Xmx8G"" GenomicsDBImport \; 	-R $reference -L $chr \; 	--sample-name-map ${inputGenomicsDB.out1} \; 	--genomicsdb-workspace-path @folder1@; ```. CreateSomaticPanelOfNormals:; ```; $gatk/gatk --java-options ""-Xms8G"" CreateSomaticPanelOfNormals \; 	-R $reference -V gendb://@folder1@ -O @out1@ \; 	--germline-resource $gnomad \; 	--max-germline-probability 0.5; ```. #### Expected behavior; Based on description of the GenomicsDB 1.3.0 update, CreateSomaticPanelOfNormals is expected to behave similarly in 4.1.8.0 as before with the output PoN containing a similar number of variants. #### Actual behavior; 28% of PoN records (52% alleles) are missing in 4.1.8.0 compared to 4.1.7.0. Although all spanning deletions are dropped in the new version, they account for only a small portion of th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744:829,error,error,829,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744,1,['error'],['error']
Availability,"## Bug Report. ### Affected version(s); - Latest master branch as of 1/12/2022. ### Description ; When I tried to build from the github repo, I received the following error:. FAILURE: Build failed with an exception. * Where:; Build file '/gatk/build.gradle' line: 688. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Could not resolve all files for configuration ':runtimeClasspath'.; > Could not find biz.k11i:xgboost-predictor:0.3.0.; Searched in the following locations:; - https://repo.maven.apache.org/maven2/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - https://oss.sonatype.org/content/repositories/snapshots/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - file:/root/.m2/repository/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; Required by:; project :. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. #### Steps to reproduce; `git clone https://github.com/broadinstitute/gatk.git`; `cd gatk/`; `./gradlew bundle`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7636:167,error,error,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7636,2,"['FAILURE', 'error']","['FAILURE', 'error']"
Availability,"## Bug Report. ### Description . When using the ""latest"" tag on the docker, it points to 4.1.2.0 which is an earlier version. wm462-624:resources fleharty$ docker run -it broadinstitute/gatk:latest; (gatk) root@3b6ada003edd:/gatk# java -jar gatk.jar -version; The Genome Analysis Toolkit (GATK) v4.1.2.0; HTSJDK Version: 2.19.0; Picard Version: 2.19.0; (gatk) root@3b6ada003edd:/gatk# . A docker with version 4.1.3.0 exists when the tag is specified directly.; wm462-624:resources fleharty$ docker run -it broadinstitute/gatk:4.1.3.0; Unable to find image 'broadinstitute/gatk:4.1.3.0' locally; 4.1.3.0: Pulling from broadinstitute/gatk; Digest: sha256:e37193b61536cf21a2e1bcbdb71eac3d50dcb4917f4d7362b09f8d07e7c2ae50; Status: Downloaded newer image for broadinstitute/gatk:4.1.3.0; (gatk) root@efd300ea536a:/gatk# java -jar gatk.jar -version; The Genome Analysis Toolkit (GATK) v4.1.3.0; HTSJDK Version: 2.20.1; Picard Version: 2.20.5",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6132:727,Down,Downloaded,727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6132,1,['Down'],['Downloaded']
Availability,"## Bug Report. ### GermlineCNVCaller. ### Affected version(s); - [ ] (GATK) v4.2.1.0. ### Description ; Java exception raised when aggregating counts for samples with a name shorter than 3 characters. For example, in the pasted logs, it errors out when processing sample with interval read counts in `94.mkdup.sort.rg.tsv`. And I found removing the sample from the list of files would avoid the error. . ### Logs:. `; 06:49:05.526 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/713.mkdup.sort.rg.tsv (40 / 323); 06:49:07.999 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/252.mkdup.sort.rg.tsv (41 / 323); 06:49:10.433 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/547.mkdup.sort.rg.tsv (42 / 323); 06:49:13.341 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/154.mkdup.sort.rg.tsv (43 / 323); 06:49:15.782 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/651.mkdup.sort.rg.tsv (44 / 323); 06:49:18.251 INFO GermlineCNVCaller - Aggregating read-count file output/gCNV/bulkDNAseq_BGI/F20FTSAPHT0350_MUSyfqR/count_tsv/94.mkdup.sort.rg.tsv (45 / 323); 06:49:20.605 INFO GermlineCNVCaller - Shutting down engine; [August 13, 2021 6:49:20 AM GMT] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 2.27 minutes.; Runtime.totalMemory()=2076049408; java.lang.IllegalArgumentException: Prefix string too short; at java.io.File.createTempFile(File.java:2001); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFileInDirectory(IOUtils.java:685); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFile(IOUtils.java:666); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.lambda$writeIntervalSubsetReadCountFiles$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7410:237,error,errors,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7410,2,['error'],"['error', 'errors']"
Availability,"## Bug Report. ### Tool; FilterAlignmentArtifacts. ### Affected version(s); 4.2.0.0 and 4.1.9.0, run from local jar or docker. ### Description ; FilterAlignmentArtifacts crushes repetitively in the same position of the input mutect2 vcf `m2.vcf.gz` (chrX:63457865). But, it finishes task successfully when only the last variant from the output file is present in the input vcf file. ; I cut the input vcf around the troublesome variant to reproduce the error on a smaller input and: ; 1. Error did not occur when the input was very small ; 2. FilterAlignmentArtifacts finished run at different variant (chrX:73769127) when analyzing the smaller input (`test.vcf.gz`) . The log issue looks very similar to that described here [#7162)](https://github.com/broadinstitute/gatk/issues/7162), but the *Problematic frame* information is different. ; As suggested in this issue [#5690](https://github.com/broadinstitute/gatk/issues/5690), the problem disappears when using gatk 4.1.3.0 on the same inputs. . log:; ```bash; 17:37:20.674 INFO ProgressMeter - chr20:43968267 10.6 44000 4132.2; 17:37:38.646 INFO ProgressMeter - chr22:22736335 10.9 45000 4110.5; 17:37:52.672 INFO ProgressMeter - chrX:7000139 11.2 46000 4113.9; 17:38:05.421 INFO ProgressMeter - chrX:26360893 11.4 47000 4125.0; 17:38:17.207 INFO ProgressMeter - chrX:44917184 11.6 48000 4141.4; 17:38:29.312 INFO ProgressMeter - chrX:77681733 11.8 49000 4155.3; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fc0ccec5cdb, pid=15987, tid=15988; #; # JRE version: OpenJDK Runtime Environment (11.0.11+9) (build 11.0.11+9-Ubuntu-0ubuntu2.18.04); # Java VM: OpenJDK 64-Bit Server VM (11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0x97cdb] cfree+0x31b; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/k",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7247:453,error,error,453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7247,2,"['Error', 'error']","['Error', 'error']"
Availability,"## Bug Report. - OS: Arch Linux; - Java: 17. ### Affected version(s); - [x] Latest public release version [version?]. ### Description . Firstly, I run `./gradle localJar`. ```; Downloading https://services.gradle.org/distributions/gradle-7.5.1-bin.zip; ...........10%............20%...........30%............40%...........50%............60%...........70%............80%...........90%............100%. Welcome to Gradle 7.5.1!. Here are the highlights of this release:; - Support for Java 18; - Support for building with Groovy 4; - Much more responsive continuous builds; - Improved diagnostics for dependency resolution. For more details see https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; Executing: git lfs pull --include src/main/resources/large. FAILURE: Build failed with an exception. * Where:; Build file '/build/gatk/src/gatk/build.gradle' line: 104. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 17s; ```; However, I already install git-lfs; ```; git-lfs usr/; git-lfs usr/bin/; git-lfs usr/bin/git-lfs; git-lfs usr/share/; git-lfs usr/share/licenses/; git-lfs usr/share/licenses/git-lfs/; git-lfs usr/share/licenses/git-lfs/LICENSE; git-lfs usr/share/man/; git-lfs usr/share/man/man1/; git-lfs usr/share/man/man1/git-lfs-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-clean.1.gz; git-lfs usr/share/man/man1/git-lfs-clone.1.gz; git-lfs usr/share/man/man1/git-lfs-dedup.1.gz; git-lfs usr/share/man/man1/git-lfs-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:177,Down,Downloading,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,2,"['Down', 'FAILURE']","['Downloading', 'FAILURE']"
Availability,"## Bug Report. Hi @jamesemery and @sooheelee ,. Thanks very much for looking into: https://github.com/broadinstitute/gatk/issues/5230. I am running into one additional error. Reads that contain an insert spanning the full length of the read are causing an exception in SplitNCigarReads. ### Affected tool(s) or class(es); SplitNCigarReads. ### Affected version(s); - Tested on 4.0.3.0 and also branch: je_splitNCigarReadsSplitError (gatk-4.0.10.0-4-gb0f0ab3). ### Description ; SplitNCigarReads gives an Exception when a read that is entirely an insertion is encountered. By contrast, HaplotypeCaller does not seem to have a problem with these reads. Example read:; ```; seq.1028598	163	chr20	3146413	60	100I	=	3146307	-106	CCAATAATTCGACCCTATAAATGATGACCTCCGTTATCGGAAGGGCACAGAACCGTCAGCCGCAACACCAGCAGCTGTAGGCCCTGCTGGGCGCGCTGGG	8;72442435768::8443224764768:84:7534457962;99:787;628:7557;::7:72878:7;:7;:8754;9:::87:8799:7:7:87::	YA:Z:chr20:3145675:600M138N208I599M	MC:Z:100M	PG:Z:MarkDuplicates	RG:Z:1	NH:i:1	HI:i:1	YM:i:0	nM:i:100	YO:Z:chr20:3146278:+:56S44M	MQ:i:60	AS:i:140	YX:i:49	mc:i:3146406	ms:i:2300; ```. #### Steps to reproduce; Command line:; ```; gatk \; --java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true' \; SplitNCigarReads \; --reference $REF \; --input 100I_rna.bam \; --output gatk.split.bam \; > split.log 2>&1; ```. A tiny BAM file illustrating the problem is attached (it is gzipped to allow Github upload).; [100I_rna.bam.gz](https://github.com/broadinstitute/gatk/files/2456955/100I_rna.bam.gz). #### Actual behavior; Here is the stacktrace:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Parameters to GenomeLocParser are incorrect:The stop position 3146412 is less than start 3146413 in contig chr20. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: Badly formed genome unclippedLo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5293:168,error,error,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5293,1,['error'],['error']
Availability,"## Bug Report. Hi there,; So I downloaded the gatk-4.4-0.0.zip and unzipped it for using gatk. I also created the conda env using the gatkcondaenv.yml and used conda to install java ""1.7.0_91"". But when I run ./gatk --list I got this error message: . `; ./gatk --list; Using GATK jar /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar --help; Error: Invalid or corrupt jarfile /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; `; Next, I moved on to git clone the gatk repository, trying to build gatk. Again, I stay in the java ""1.7.0_91"" gatk env that I already created. But I got this error msg this time:; `; ./gradlew localJar; Gradle 7.5.1 requires Java 1.8 or later to run. You are currently using Java 1.7.; `; When I switch back to the server default java (1.8.0_292-b10), i got another error msg.; `; java -version; openjdk version ""1.8.0_292""; OpenJDK Runtime Environment (build 1.8.0_292-b10); OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode). ./gradlew localJar. > Configure project :; Warning: using Java 1.8 but only Java 17 has been tested. FAILURE: Build failed with an exception. * Where:; Build file '/home/athchu/bin/gatk/build.gradle' line: 141. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > A Java 17 compatible (Java 17 or later) version is required to build GATK, but 1.8 was found. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org; `; So to sum up, my issues are :; 1) downloaded gatk-4.4.0.0 but it contained invalid jar file and i ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8432:31,down,downloaded,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8432,4,"['Error', 'down', 'error']","['Error', 'downloaded', 'error']"
Availability,"## Bug Report. Not a bug, but a question. See **Description section** below. It could also be related to things not being labelled correctly in this repository. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - 4. ### Description . Looking around at https://github.com/broadinstitute/gatk/issues?q=label%3AFuncotator+is%3Aclosed I noticed that not much happened since April 2022. Is there no more active development/maintenance planned for Funcotator? Or are the labels misleading? I am planning on writing a generic parser for Funcotator output, but would like to know a bit more about this project's status before investing in this. Thanks. #### Steps to reproduce; See https://github.com/broadinstitute/gatk/issues?q=label%3AFuncotator+is%3Aclosed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8154:440,mainten,maintenance,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8154,1,['mainten'],['maintenance']
Availability,"## Bug Report. Originally reported by @ldgauthier via slack. ### Affected tool(s) or class(es); CalibrateDragstrModel. ### Affected version(s); - [X ] Latest public release version [4.2.0.0]. ### Description ; An out-of-memory exception when running the aforementioned tool in at least one of many samples. Location where the error occur does not seem to be always the same but it was fixable by increasing memory over 15Gb. #### Steps to reproduce. Since I'm not sure the data is public I won't disclose its location nor ID in this issue. Let's call it the ""SAMPLE"" in ""SAMPLE.cram"":. ```; gatk --java-options ""-Dsamjdk.reference_fasta=Homo_sapiens_assembly38.fasta -Xmx2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" \; CalibrateDragstrModel \; -R Homo_sapiens_assembly38.fasta \; -I SAMPLE.cram \; -str Homo_sapiens_assembly38.str \; -O SAMPLE.final.cram.dragstr \; --parallel \; --verbosity DEBUG; ```. ```Homo_sapiens_assembly38.str``` depends only on the reference and ca be composed using this:. ```; gatk ComposeSTRFile -R Homo_sapiens_assembly38.fasta -O Homo_sapiens_assembly38.str; ```. #### Expected behavior; Completes without issues. #### Actual behavior; a Java Out-of-Memory error is throw and the execution finished without results.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7189:326,error,error,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7189,2,['error'],['error']
Availability,"## Bug Report; ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - version 4.1.0.8. ### Description ; I know this issue has been brought up before but I still cannot find a solution. When I run CombineGVCFs, the error indicates the first locus where there is a NON_REF allele. For example:. HiC_scaffold_2 12497 . T TC,* . My full process is as follows:; I run HaplotypeCaller on individual sample files using the -ERC GVCF command.; I combine the individual g.vcf files using CombineGVCFs. I do this separately for the three species I ultimately want to merge, although they are all mapped to the same reference genome.; I call multisample genotypes with GenotypeGVCFs, again for each species separately. At this point a sample that will fail the process in the future will look like:; HiC_scaffold_2 12497 . T TC,<NON_REF>. I now merge the multispecies genotyped files together using CombineGVCFs.; But then when I go to run GenotypeGVCFs, there is an error wherever there are more than two alleles. And as shown at the top of the message what was a <NON_REF> becomes a * and I get the message: ERROR input alleles must contain <NON_REF>. #### Expected behavior; I expected the g.vcf files to genotype across multiple samples so I can move forward with analyses. Is the problem that I'm running CombineGVCFs and GenotypeGVCFs twice? And somehow that is changing <NON_REF> into * ?. I appreciate any advice.; With thanks,; Emily",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7737:236,error,error,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7737,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report; ### Affected tool(s). MuTect2; ### Affected version(s). version 3.6; ### Description. A user reported that when he input a BAM file that has multiple sample names to MuTect2, the tool mseems to run fine but outputs an empty VCF. Because MuTect2 cannot run on multiple samples, there should be an error message that lets the user know he/she cannot have multiple samples in the BAM file.; #### Expected behavior. There should be an error message telling the user to input only single sample BAM files, and the run should fail.; #### Actual behavior. The tool runs to completion but outputs an empty VCF. [Original Forum Post](http://gatkforums.broadinstitute.org/gatk/discussion/comment/33336#Comment_33336). ---",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2203:311,error,error,311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2203,2,['error'],['error']
Availability,"## Bug Report; ### Version Information; GenomicsDBImport 4.1.9.0. ### Summary; A user posted on the forum with an error from GenomicsDBImport. @nalinigans @mlathara Can you determine what is causing this java.lang.IndexOutOfBoundsException?. This request was created from a contribution made by vivekruhela on January 12, 2021 19:16 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076396392-No-Output-from-GenomicsDBImport](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076396392-No-Output-from-GenomicsDBImport). \--. Dear GATK Team,. I am using GATK version 4.1.9.0 for my WES data pipeline. In order to get accurate somatic call, I am trying to generate the Panel of Normal (PON) using GenomicsDBImport module of GATK. While using GenomicsDBImport for PON generation, I am not getting any output from my command. Here is the command I used to print the stack trace:. ```; gatk GenomicsDBImport \\ ; ; \-R /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.fasta \\ ; ; \--variant normal1.vcf \\ ; ; \--variant normal2.vcf \\ ; ; \--variant normal3.vcf \\ ; ; \--variant normal4.vcf \\ ; ; \--variant normal5.vcf \\ ; ; \--variant normal6.vcf \\ ; ; \--variant normal7.vcf \\ ; ; \--variant normal8.vcf \\ ; ; \--variant normal9.vcf \\ ; ; \--variant normal10.vcf \\ ; ; \--variant normal11.vcf \\ ; ; \--variant normal12.vcf \\ ; ; \--variant normal13.vcf \\ ; ; \--variant normal14.vcf \\ ; ; \--variant normal15.vcf \\ ; ; \--variant normal16.vcf \\ ; ; \--variant normal17.vcf \\ ; ; .... ; ; \--variant normal80.vcf \\ ; ; \--genomicsdb-workspace-path pon\_db \\ ; ; \--tmp-dir /tmp1 \\ ; ; \-L /gatk\_bundle/hglft\_genome\_3bc14\_d6f440.bed \\ ; ; \--sequence-dictionary /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.dict \\ ; ; \--reader-threads 15 \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'; ```. Here For interval list, I have downloaded the hg38 target interval from GATK resource bundle and converted into hg19 format us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7037:114,error,error,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037,1,['error'],['error']
Availability,"## Bug Report; 18:47:11.757 INFO Funcotator - Shutting down engine; [September 19, 2021 6:47:11 PM CST] org.broadinstitute.hellbender.tools; .funcotator.Funcotator done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=1885339648; **org.broadinstitute.hellbender.exceptions.GATKException: Unable to query; the database for geneName: WASH7P**; ....; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.ins; tanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.ins; tanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Mai; n.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); **Caused by: org.sqlite.SQLiteException: [SQLITE_IOERR_LOCK] I/O error i; n the advisory file locking logic (disk I/O error)**; at org.sqlite.core.DB.newSQLException(DB.java:909); ### Affected version(s); GATK 4.1.9.0. ### Description ; GATK Funcotator [SQLITE_IOERR_LOCK] I/O error in the advisory file locking logic (disk I/O error). I downloaded the data-sources by ""gsutil cp gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521s.tar.gz ."". I can't find useful information for this error. Thank you. #### Steps to reproduce; Using GATK jar /lustre1/ruibinxi_pkuhpc/ljx/software/gatk-4.1.9.0/gatk-; package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_i; o_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjd; k.compression_level=2 -jar /lustre1/ruibinxi_pkuhpc/ljx/software/gatk-4; .1.9.0/gatk-package-4.1.9.0-local.jar Funcotator -R /home/ruibinxi_pkuh; pc/lustre1/ljx/reference_genomes/hg38_bwa/hg38.fa -V /home/ruibinxi_pku; hpc/lustre1/ljx/data/raodn/WES/GATK/P14P_filtered.vcf.gz -O /home/ruibi; nxi_pkuhpc/lustre1/ljx/data/raodn/WES/GATK/P14P_filtered_funcotator.maf; --output-file-format MAF --data-sources-path /home/ruibinx",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7474:55,down,down,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7474,3,"['down', 'error']","['down', 'error']"
Availability,"## Bug Report; GenotypeGVCFs stuck indefinitely at ""Initializing engine"" step. ### Affected tool(s) or class(es); gatk GenotypeGVCFs; ### Affected version(s); GATK v4.1.4.1 (installed in a `conda` convironment from the bioconda channel), on a RHEL server 7.6 (Maipo). ### Description ; Following the recommended pipeline of HaplotypeCaller, GenomicsDBImport and then GenotypeGVCFs, the last command hangs indefinitely and from the log file, it seems like it doesn't get past the ""Initialize engine"" step. This is an example of the standard error stream (after the `GenotypeGVCFs` job reached 20 hours wall time and was killed) :; ```; 22:28:44.293 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/export/user/home/miniconda3/envs/aDNA/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.; jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 10:28:44 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 22:28:44.639 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.4.1; 22:28:44.640 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:28:44.640 INFO GenotypeGVCFs - Executing as user@gc-prd-hpcn002 on Linux v3.10.0-957.27.2.el7.x86_64 amd64; 22:28:44.640 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 22:28:44.640 INFO GenotypeGVCFs - Start Date/Time: December 17, 2020 10:28:44 PM AEST; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7007:540,error,error,540,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007,1,['error'],['error']
Availability,"## Bug Report; HaplotypeCaller. ### Affected version(s); 4.3.0. ### Description ; A plot of the frequency distribution of GQ values associated with variants reported by HaplotypeCaller demonstrates ""periodicity"". The following counts GQ values for TP variant calls (data from HG002, aligned to GRCh38 with three different read aligners, chr14 only):. ![GQdist HC](https://user-images.githubusercontent.com/8249753/215591505-06b76118-cdbf-4b04-ae70-55acaaf8fce9.png). Most of the distribution is periodic on GQ values that are even multiples of 3. This is seen in the data for this plot: [GCdist.xlsx](https://github.com/broadinstitute/gatk/files/10540627/GCdist.xlsx). In addition, about 80% of the reported variants were associated with GQ=99 (not plotted here). This kind of thing might be an artifact of the algorithm used to compute GQ. For example, underlying data such as MAPQ might be manifesting the same periodicity, which is then ""passed through"" to GQ. It might also be an implementation error. For example, premature rounding or the use of an integer variable instead of a floating point variable might lead to inadvertent quantization of a result. But this is just speculation, given only that the distribution would be expected to be smooth, not periodic. #### Steps to reproduce; A little bit of awk should suffice to pull GQ values from a plain-text VCF file. #### Expected behavior; No periodicity in the frequency distribution of GQ values. For example, here is the distribution of GQ values for the same three sets of read mappings but with variants called with DeepVariant:. ![GQdist DV](https://user-images.githubusercontent.com/8249753/215611788-9372cec8-7841-4d90-b137-b3f950902fba.png). In addition, about 15% of the reported variants were associated with GQ=99 (not plotted here). #### Actual behavior; (As above.). Thanks for any insight you can provide on this!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8179:999,error,error,999,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8179,1,['error'],['error']
Availability,"## Bug Report; Hi, we are using the dockstore version of the GATK variant calling pipeline that leverages mutect 2:; [github.com/broadinstitute/gatk/mutect2:4.1.8.1](https://dockstore.org/workflows/github.com/broadinstitute/gatk/mutect2:4.1.8.1). We're processing human glioma data, and currently we are making it through much of the pipeline, but failing on `GetPileupSummaries`. There's a thread about it on the discussion board [here] (https://gatk.broadinstitute.org/hc/en-us/community/posts/6179012337819-No-Pileup-Tables). . We are specifying a file for `variants_for_contamination`, and a file for `variants_for_contamination_idx` in the workflow, but the index is never passed to `GetPileupSummaries`, and it fails with this enigmatic error message:. ```; A USER ERROR has occurred: An index is required but was not found for file gs://bruce-processed-data/Prins_Cloughesy_Neoadjuvant/terra_reference_files/small_exac_common_3.hg38.vcf.gz. Support for unindexed block-compressed files has been temporarily disabled. Try running IndexFeatureFile on the input.; ```. If you check out the source code in [mutect2.wdl](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl), you can see that that input variable `variants_for_contamination_idx`, which we have thoughtfully set and passed into the workflow, is never actually used in `GetPileupSummaries`. I'm not even sure there is an option to pass the index, from reading the [docs](https://gatk.broadinstitute.org/hc/en-us/articles/360037593451-GetPileupSummaries). Here is an example of how the command is being called within our workflow:. ```; gatk --java-options ""-Xmx149500m"" GetPileupSummaries -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://fc-d31bc4e7-6d10-4dc4-a585-5895ab2346f3/cfce2061-efd6-449e-bdc9-a7ff2b633644/PreProcessingForVariantDiscovery_GATK4/b4adf777-4f97-425c-b3e2-b37c9d927667/call-GatherBamFiles/SRR7588418.hg38.bam --interval-set-rule INTERSECTION ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7935:743,error,error,743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7935,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Bug Report; I run the CNNScoreVariants as tutorial, but it can't continue and always stuck as the following picture, and the programme isn't stop by any error. By the way I can't find gatkcondaenv.yml in anywhere. Can you upload it in the github, so that I can check ; whether the bug is caused by loss of some python dependencies. ### Affected tool(s) or class(es); CNNScoreVariants. ### Affected version(s); GATK4.3.0.0. ### Description ; ![image](https://github.com/broadinstitute/gatk/assets/92069388/be7c63ca-d64f-4689-86ad-b06f867cfd45)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8827:156,error,error,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8827,1,['error'],['error']
Availability,"## Bug Report; I was running the JointDiscovery pipeline as a part of the GATK Best Practices pipeline. I am running this on many vcf files (~150) called by the HaplotypeCaller. I am getting this error: . ```; 19:01:58.009 WARN VariantDataManager - WARNING: Very large training set detected. Downsampling to 2500000 training variants.; 19:04:18.918 INFO VariantRecalibrator - Shutting down engine; [September 16, 2019 7:04:18 PM EDT] org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator done. Elapsed time: 912.93 minutes.; Runtime.totalMemory()=3204972544; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; 	at org.broadinstitute.hellbender.tools.walkers.vqsr.MultivariateGaussian.<init>(MultivariateGaussian.java:31); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.GaussianMixtureModel.<init>(GaussianMixtureModel.java:34); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibratorEngine.generateModel(VariantRecalibratorEngine.java:43); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.onTraversalSuccess(VariantRecalibrator.java:625); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:895); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. I believe this is derived from an error earlier in the log, since the `stderr` gives the same Java heap space error: ; ```; [2019-09-16 19:05:59,50] [error] WorkflowManagerActor Workflow 9f7a01a4-0632-4817-8622-aa51e520abf1 failed (during ExecutingWorkflowState): Job JointGe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165:196,error,error,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165,3,"['Down', 'down', 'error']","['Downsampling', 'down', 'error']"
Availability,"## Bug Report; JDK8 is no longer available for the current stable Debian release (buster). Trying to run gatk with an OpenJDK11 install fails. I anticipate a WONTFIX since this is dependency related, but I figured it would be good to let people know. ### Affected tool(s) or class(es); GATKRead, probably others too. ### Affected version(s); - [x] Latest public release version [4.1.2.0]; - [ ] Latest master branch as of [didn't test]. ### Description ; ```; Exception in thread ""main"" java.lang.IncompatibleClassChangeError: Inconsistent constant pool data in classfile for class org/broadinstitute/hellbender/transformers/ReadTransformer. Method 'org.broadinstitute.hellbender.utils.read.GATKRead lambda$identity$d67512bf$1(org.broadinstitute.hellbender.utils.read.GATKRead)' at index 65 is CONSTANT_MethodRef and should be CONSTANT_InterfaceMethodRef; 	at org.broadinstitute.hellbender.transformers.ReadTransformer.identity(ReadTransformer.java:30); 	at org.broadinstitute.hellbender.engine.GATKTool.makePreReadFilterTransformer(GATKTool.java:345); 	at org.broadinstitute.hellbender.engine.GATKTool.getTransformedReadStream(GATKTool.java:374); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:93); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. This error seems related to the JRE version. You can still install JDK8 manually but that's not ideal for many users. #### Steps to reproduce; Run GATK on OpenJDK11. ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053:33,avail,available,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053,1,['avail'],['available']
Availability,"## Bug Report; When I use output files of CombineGVCFs to run GenotypeGVCFs, it seems no problem at beginning. However, several hours later, it suddenly shot down. The fatal error occur. ### Affected tool(s) or class(es); GenotypeGVCFs, only use arguments: -R, -V, -O, -all-sites. ### Affected version(s); GATK4 v4.1.9.0. ### Description . A fatal error has been detected by the Java Runtime Environment:. SIGBUS (0x7) at pc=0x00002acb0aee41d3, pid=14508, tid=0x00002acb0f80b700. JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode linux-amd64 compressed oops); Problematic frame:; C [libc.so.6+0x1501d3] __memmove_ssse3_back+0x1a13. Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again. If you would like to submit a bug report, please visit:; http://bugreport.java.com/bugreport/crash.jsp. --------------- T H R E A D ---------------. Current thread (0x00002acb10021800): GCTaskThread [stack: 0x00002acb0f70b000,0x00002acb0f80c000] [id=14511]. siginfo: si_signo: 7 (SIGBUS), si_code: 2 (BUS_ADRERR), si_addr: 0x00000003ea598000. Registers:; RAX=0x00000003ea593600, RBX=0x00002acb0f80aa00, RCX=0x00000000000059c8, RDX=0x0000000000000f48; RSP=0x00002acb0f80a928, RBP=0x00002acb0f80a950, RSI=0x000000044246f290, RDI=0x00000003ea597fa0; R8 =0x00000003ea593600, R9 =0x0000000057ed72f0, R10=0x00000003c0000000, R11=0x00002acb0af16b50; R12=0x0000000000000b3d, R13=0x00000000000059e8, R14=0x00002acb0f80aa00, R15=0x0000000010490000; RIP=0x00002acb0aee41d3, EFLAGS=0x0000000000010206, CSGSFS=0x0000000000000033, ERR=0x0000000000000006; TRAPNO=0x000000000000000e. Top of Stack: (sp=0x00002acb0f80a928); 0x00002acb0f80a928: 00002acb0ba575c6 00000003c5a14ae8; 0x00002acb0f80a938: 0000000000412400 000000001048e05a; 0x00002acb0f80a948: 00002acb0c077d00 00002acb0f80a9a0; 0x00002acb0f80a958: 00002acb0ba155e8 00002acb0c03f148; 0x00002a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7008:158,down,down,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7008,3,"['down', 'error']","['down', 'error']"
Availability,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:67,error,error,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,2,['error'],['error']
Availability,"## Description; A user wants to run Funcotator with a mouse sample but has an issue running IndexFeatureFile. The GencodeGTF parser is specific to human data. Funcotator could be useful for users with non-human data if there is a workaround for these errors. ### GATK Information; GATK 4.1.9.0; gatk IndexFeatureFile -I gencode.vM25.annotation.gtf; This request was created from a contribution made by T. Li on January 25, 2021 04:37 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-). #### Error Log. ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar IndexFeatureFile -I gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.081 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 25, 2021 4:33:13 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.195 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.1.9.0-SNAPSHOT ; ; 04:33:13.195 INFO IndexFeatureFile - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 04:33:13.195 INFO IndexFeatureFile - Executing as root@b4c480938d0d on Linux v5.4.0-1029-aws amd64 ; ; 04:33:13.195 INFO IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7054:251,error,errors,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054,4,"['Error', 'error']","['Error', 'Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file', 'errors']"
Availability,"## Documentation request. ### Description ; I propose that installation of gcc be added to the instructions on the GATK Github README.md. If gcc is not installed, HaplotypeCaller complains that the AVX instruction set is not available, even when it is. It falls back to slower LOGLESS_CACHING PairHMM. The fault is missing libgomp1, which is a required dependency of gcc. Since this documentation request is related to a ""bug"" that comes about from not installing necessary libraries, I'll include the bug report format below, in case someone else searches for solutions to this problem, as suggested by @lbergelson. ### Affected tool(s) or class(es); _HaplotypeCaller_, or any other tool that uses _PairHMM_. ### Affected version(s); -I think all as of _2019-06-20_. I tested on release version _4.1.2.0_. #### Steps to reproduce; Run HaplotypeCaller from a released jar on an Ubuntu VM that supports the AVX instruction set. Critically, do *NOT* install gcc on the VM. Installing gcc fixes this problem. #### Expected behavior; If you install gcc, that results in the installation of libgomp1, which allows the Intel library to load and use AVX acceleration. You could probably install libgomp1 on its own, but I did not test that.; > 14:51:01.013 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; > 14:51:01.015 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; > 14:51:01.053 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; > 14:51:01.053 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; > 14:51:01.054 INFO IntelPairHmm - Available threads: 16; > 14:51:01.054 INFO IntelPairHmm - Requested threads: 8; > 14:51:01.054 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation. #### Actual b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6012:225,avail,available,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6012,2,"['avail', 'fault']","['available', 'fault']"
Availability,"## Documentation request. ### Description ; I was unable to successfully follow the R setup instructions required to run integration tests locally. I don't know whether this is a general concern regarding initial setup on Mac OS X High Sierra 10.13.6, or the problem is specific to my system. . #### R installation itself; Expected: `brew install R` would install R with all necessary core functionality.; Actual: `brew install R` installed a version of R without X11 support. The binary I downloaded from [CRAN](https://cran.r-project.org/bin/macosx/) had the proper support. #### R package installation; Expected `sudo Rscript scripts/docker/gatkbase/install_R_packages.R` would install the necessary packages for R scripts needed.; Actual: Failure to compile source packages, with an error like `clang: error: unsupported option '-fopenmp'`. I made some attempts to update my local `clang` but was unsuccessful. Instead, I installed the packages at the R prompt:; ```; $ R; > install.packages('ggplot2'); > install.packages('reshape'); > install.packages('gplots'); > install.packages('gridExtra'); > install.packages('gsalib'); > install.packages('data.table'); > quit(); ```. After doing so, my test run `TEST_TYPE=integration ./gradlew shadowJar test` succeeded.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5389:490,down,downloaded,490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5389,4,"['Failure', 'down', 'error']","['Failure', 'downloaded', 'error']"
Availability,"## Documentation request. ### Tool(s) or class(es) involved; GermlineCNVCaller. ### Description ; I'm trying to get a pipeline running to call germline CNVs on small cohorts (20-40) PCR free whole genome samples sequenced to ~45X depth. I'm running into problems figuring out how wide to scatter the analysis, and how to allocate resources. It would be incredibly helpful to have some very clear guidelines about how number of samples and the number of intervals within each scatter affect both runtime and memory usage. Here's what I've been able to infer from the WDL pipelines, tool docs and experimentation (though I suspect some of it is wrong):. 1. Memory usage is approximately proportional to number of samples, number of intervals, number of bias covariates and max copy number. What the docs don't say is what the default is for the number of bias covariates _and_ how to take these numbers and project an approximate memory usage. 2. It would appear that GermlineCNVCaller will, by default, attempt to use all CPU cores available on the machine. From the WDL I see that setting environment variables `MKL_NUM_THREADS` and `OMP_NUM_THREADS` seems to control the parallelism? It would be nice if `GermlineCNVCaller` took a `--threads` and then set these before spawning the python process. 3. Runtime? This would be really nice to have some guidelines around as I get wildly varying results depending on how I'm running. My experimentation is with a) 20 45X WGS samples, b) bin size = 500bp, c) running on a 96-core general purpose machine at AWS with 384GB of memory. My first attempt a) scattered the genome into 48 shards of approximately 115k bins each, representing ~50mb of genome and b) ran 24 jobs concurrently but failed to set the environment variables to control parallelism. In that attempt the first wave of jobs were still running after 24 hours and getting close to finishing up the initial de-noising epoch, with 3/24 having failed due to memory allocation failures. My secon",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6166:1031,avail,available,1031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6166,1,['avail'],['available']
Availability,"## Documentation request. ### Tool(s) or class(es) involved; Mutect2 and FilterMutectCalls. ### Description ; Because both `M2ArgumentCollection` and `M2FiltersArgumentCollection` extend `AssemblyBasedCallerArgumentCollection`, both `Mutect2` and `FilterMutectCalls` display all assembly and caller arguments in the documentation/help even if those arguments don't actually do anything. For example both tools have the argument `--contamination-fraction-to-filter` which has the description:. ```; Fraction of contamination in sequencing data (for all samples) to aggressively remove. If this fraction is greater is than zero, the caller will aggressively attempt to remove contamination ; through biased down-sampling of reads. Basically, it will ignore the contamination fraction of reads for ; each alternate allele. So if the pileup contains N total bases, then we will try to remove ; (N * contamination fraction) bases for each alternate allele.; ```. This argument definitely doesn't do anything in `FilteMutectCalls` but I also don't think it's hooked up to do anything in `Mutect2` either (at least when I tried giving it a high value I still got the same calls). This is by design because Mutect has other ways of handling contamination, but the argument is still displayed in both tools' documentation which is confusing. There are other arguments that have the same issue where it's unclear if they do anything in Mutect or not.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5352:705,down,down-sampling,705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5352,1,['down'],['down-sampling']
Availability,"## Documentation request. ### Tool(s) or class(es) involved; Readme for M2 in https://github.com/broadinstitute/gatk/tree/master/scripts/mutect2_wdl. ### Description ; This is the text currently in the readme, it needs to be updated to feature Funcotator instead of Oncotator:. > Functional annotation (Oncotator); > ; > The M2 WDL can optionally run oncotator for functional annotation and produce a TCGA MAF from the M2 VCF. Oncotator is not a GATK4 tool and is provided in the M2 WDL as a convenience. There are several notes and caveats; > ; > Several parameters should be passed in to populate the TCGA MAF metadata fields. Default values are provided, though we recommend that you specify the values. These parameters are ignored if you do not run oncotator.; > ; > Several fields in a TCGA MAF cannot be generated by M2 and oncotator, such as all fields relating to validation alleles. These will need to be populated by a downstream process created by the user.; > ; > Oncotator does not enforce the TCGA MAF controlled vocabulary, since it is often too restrictive for general use. This is up to the user to specify correctly. Therefore, we cannot guarantee that a TCGA MAF generated here will pass the TCGA Validator. If you are unsure about the ramifications of this statement, then it probably does not concern you.; > ; > More information about Oncotator can be found at: http://archive.broadinstitute.org/cancer/cga/oncotator",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5889:930,down,downstream,930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889,1,['down'],['downstream']
Availability,"## Documentation request. There are multiple statistical terminology errors, especially misuses of the term ""likelihood,"" in [Assigning per-sample genotypes (HaplotypeCaller)](https://gatk.broadinstitute.org/hc/en-us/articles/360035890511). The statistics are difficult enough without pervasive misuse of statistical terminology in the documentation of software considered a _de facto_ standard, which IMO makes this fairly serious. This is a follow-on report to #7577 . ----. 1. The heading ""Calculating genotype likelihoods using Bayes' Theorem"" should read ""Calculating genotype **posteriors** using Bayes' Theorem"" The Contents section needs corresponding correction, of course.; 2. The quote: ""...when we used the PairHMM to produce the likelihoods of each read against each haplotype, and then marginalized them to find the likelihoods of each read for each allele under consideration"" **should read** ""...when we used the PairHMM to produce **P(read|haplotype),** and then marginalized them to find the **likelihoods of each allele** under consideration.""; 3. The quote: ""...the point of calculating this likelihood is to determine..."" **should read** ""...the point of calculating this **posterior** is to determine..."". ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7581:69,error,errors,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7581,1,['error'],['errors']
Availability,"## Documentation system request. Currently, the tooldoc generation system does not separate arguments that relate to deployment decisions like compute platform (eg `--gcs-project-for-requester-pays`) from the ones that modify the analytical or processing behavior of the tools. This adds to the cognitive burden involved in sorting through all the options available for a given tool. We'd like to have a separate category for these arguments so that they would be isolated from the rest. . In addition, there are a bunch of convenience arguments in the common args section that have more to do with how we're running the tool than its analysis behavior, and could also be consolidated into this separate category (or their own category but that might be too granular). Examples below are from the popular tool [SelectVariants](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_tools_walkers_variantutils_SelectVariants.php):. #### Arguments that would be stratified as platform args. `--cloud-index-prefetch-buffer`; `--cloud-prefetch-buffer`; `--disable-bam-index-caching`; `--gcs-max-retries`; `--gcs-project-for-requester-pays`. #### Arguments that would be stratified as convenience args. `--arguments_file` ; `--help` ; `--version` ; `--create-output-bam-index` ; `--create-output-bam-md5`; `--create-output-variant-index`; `--create-output-variant-md5`; `--gatk-config-file`; `--QUIET`; `--seconds-between-progress-updates`; `--tmp-dir`; `--use-jdk-deflater`; `--use-jdk-inflater`; `--verbosity`; `--showHidden` -> I thought we had got rid of hidden args??. These could also be stratified as convenience but one could argue they affect tool behavior qualitatively:. `--disable-sequence-dictionary-validation`; `--lenient`; `--read-validation-stringency`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5234:356,avail,available,356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5234,1,['avail'],['available']
Availability,"## Feature request / documentation request. ### Tool(s) or class(es) involved; Reading files from non-public GCS paths. ### Description; I did not have Application Default Credentials set up when I tried to read from a private bucket. This failed, as expected. Could we add a comment explaining that running `gcloud auth application-default login` is the necessary step to making this work? I didn't see anything on the forum about how to solve this. The solution was in the comments to #2394. ### Observed; GATK errored out with a stack trace:; ```; code: 401; message: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; reason: required; location: Authorization; retryable: false; com.google.cloud.storage.StorageException: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:415); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:198); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:195); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); at com.google.cloud.RetryHelper.run(RetryHelper.java:74); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:195); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:673); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:429); at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); ```. ```; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized; {; ""code"" : 401,; ""errors"" : [ {; ""domain"" : ""global"",; ""location"" : ""Authoriza",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5468:513,error,errored,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5468,1,['error'],['errored']
Availability,"## Feature request and Question. Original question was posted in GATK forum https://gatkforums.broadinstitute.org/gatk/discussion/12026/how-to-do-downsampling,; but it seems to me that the question should be posted here to ask the developer team. ### Tool(s) or class(es) involved; PrintReads. ### Description. In GATK4, printReads doesn't have an option to do downsample to coverage anymore. Is there any reason for that ? Or is there any update suggestions to do the same thing but migrating it from GATK3 to GATK4 ? The forum maintainer told me in original discussion that there is a `DownsampleSam` function in picard, but it can't be used to downsample to coverage directly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5075:146,down,downsampling,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5075,4,"['Down', 'down']","['DownsampleSam', 'downsample', 'downsampling']"
Availability,"## Feature request. ### DRAGEN-GATK release?!!; Hello GATK team, ; - When will the DRAGEN-GATK version will be release officially? I have seen the online forum of Eric brans and Illumina head explaining GATK and DRAGEN about the open source version, a month back! I searched for DRAGEN-GATK update release in both the illumina website and GATK, couldn't find it? can anyone help me to get updated GATK.. and do I need dragen 3.4 for that? till 3.4.12 I haven't seen any mention of GATK in that.. which version I should download?. - Is there any feature in upcoming GATK to find STR variants.. If its in progress when it will get release?; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6912:519,down,download,519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6912,1,['down'],['download']
Availability,"## Feature request. ### Mutect2. ### Description ; In general, Mutet2 can correctly determine whether a mutation is located in the STR region, but if a mutation is not in the str region strictly, it will not be labeled as STR or any other meaningful label. In practical use, we hope that a mutation located next to the str region can also be labeled as STR, or other labels that can be used to judge, as this is crucial for correctly determining the reliability of the mutation. ; In the following example, if the mutation is determined to be STR, our filtering script will filter it out because it is obvious that the mutation is located after a series of T, which may be caused by sequencing errors. But Mutect2 did not determine it as STR, and it was determined as PASS. Eventually, the mutation was reported in our product report, and we manually deleted the site after discovering it.; ![image](https://github.com/broadinstitute/gatk/assets/66426093/4264e2a0-cefd-4a9d-92e0-69a45f26857c); ![a1d7589a482f73dfa528dd11bb24a305](https://github.com/broadinstitute/gatk/assets/66426093/f1e72d0b-eec7-4cfb-aa88-4b3077cdeab5). #### Steps to reproduce; Here are the bam, bed, shell and output files:; [chr11_108121426.zip](https://github.com/broadinstitute/gatk/files/11549460/chr11_108121426.zip). #### Expected behavior; We hope that a mutation located next to the str region can also be labeled as STR, or other labels that can be used to determine it.; Please evaluate whether it can be implemented in a later version, which is very important for us. Thank you very much!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8340:450,reliab,reliability,450,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8340,2,"['error', 'reliab']","['errors', 'reliability']"
Availability,"## Feature request. ### Tool involved - GATK cnv_somatic_pair_workflow version 4.2.0.0; Link to main wdl - https://dockstore.org/workflows/github.com/broadinstitute/gatk/cnv_somatic_pair_workflow:4.2.0.0?tab=files. ### Description; Requesting for addition of a new feature called the `IndexFeatureFile` to be added as initial step in the `Funcotate_Segment` task of the `cnv_somatic_pair_workflow` wdl . **Detailed description:** ; An error was encountered while running the CNVSomaticPairWorkflow: `A USER ERROR has occurred: Input /cromwell_root/fc-a21facc8-da03-4987-bb5b-dfadbfda2747/a923baec-ddd9-429a-b046-1f03c5ebda64/CNVSomaticPairWorkflow/42ba0311-ba93-4fdd-9b5e-bd7348c0ad42/call-CallCopyRatioSegmentsTumor/AMP-18-003-TIS.called.seg must support random access to enable traversal by intervals. If it's a file, please index it using the bundled tool IndexFeatureFile`. - The FuncotateSegments task is asking an index file for the seg file, which is unusual to create an index for seg; - The same command from the cnv wdl was tested on-prem (Broad server using ish) by transferring all required files on-prem, this was done to replicate the error and find a solution without wasting compute money or resources on Terra; - To fix the issue, we initially ran Indexfilefeature tool (on-prem) for creating index file for the seg file, using the following command. ; `gatk IndexFeatureFile -I seg file`; - And then ran the main command `./gatk --java-options -Xmx2000m FuncotateSegments --data-sources-path data_sources_directory --ref-version hg19 --output-file-format SEG -R fasta_file_path --segments seg_file_path -O output_file_path/{basename}.seg.funcotated.tsv -L interval_list_path --transcript-selection-mode CANONICAL`. After this was complete, annotated file was generated correctly. In conclusion - the error identified is that `Indexfilefeature` tool had to be run as the first step. Requesting this change to be incorporated into `cnv_somatic_funcotate_seg_workflow.wdl`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7294:435,error,error,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7294,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## Feature request. ### Tool(s) or class(es) involved. (sv) VCF producing tool(s). ### Description. The VCF spec allows `POS` column to take value 0, when the suspected event is at a telomere.; The given example is in section 5.4.5 (see example event illustrated in Figure 6 and VCF records below the figure).; However, currently GATK writes VCF via `VariantContext`'s, which defines coordinate 0 as illegal.; I can of course push this feature request to htsjdk, if that is deemed more appropriate. **UPDATE**; Looking back at the error message, it is actually the `SimpleInterval` that I use for constructing the `VariantContext` throwing the error message.; Temporary workaround would be to ""hack"" the POS to be 1 or N, and warn using an INFO annotation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5915:531,error,error,531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5915,2,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved. CreateSomaticPanelOfNormals. ### Description. Currently, CreateSomaticPanelOfNormals emits sites-only VCFs. Some downstream tools require full VCFs, as could be created previously in the PON CombineVariants workflow. Perhaps this feature will be covered when CombineVariants becomes available, but I believe it may still be desirable if CreateSomaticPanelOfNormals could pass `--sites-only-vcf-output=false` to allow full VCFs to be returned. This would permit calculation of mapping bias using allele frequencies of the normal samples. Thank you for your tremendous service developing this tool. Sincerely,. Andrew",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5649:168,down,downstream,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5649,2,"['avail', 'down']","['available', 'downstream']"
Availability,"## Feature request. ### Tool(s) or class(es) involved. Mutect2. ### Description. Currently the AD tag reports read depth, but most downstream tools expect this flag to report fragment dept. ; Add flag to M2 to modify behavior of AD and AF tags to reflect fragment counts.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7490:131,down,downstream,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7490,1,['down'],['downstream']
Availability,"## Feature request. ### Tool(s) or class(es) involved. SV pipeline, Funcotator, etc. ### Description. In trying to build test data for SV, time and time again we face the problem of not being able to find actual desired events on the two chromosomes 20 and 21, hence end up having to painfully perform all kinds of coordinate hacks in order to have enough test coverage. It seems that the Funcotator team is also facing a similar issue. Therefore it will be great if the whole reference genome for HG38, and maybe HG19 as well, can be included in the tests, so that tool developers spend less time worrying about hassles in moving real events to chr20 and chr21. One of the potential downside is obvious: it increases the repo size and time for running tests (downloading a bigger file) on Travis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5111:684,down,downside,684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5111,2,['down'],"['downloading', 'downside']"
Availability,"## Feature request. ### Tool(s) or class(es) involved. [ReferenceConfidenceVariantContextMerger](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java). ### Description. In the case that VariantContexts with too many alternate alleles are passed to the joint genotyper, the genotype calculator used in the merger can experience an OOM:; ```; java.lang.OutOfMemoryError: Java heap space at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculator.genotypeIndexMap(GenotypeLikelihoodCalculator.java:522); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:541); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:116); ```. For a ~ reasonable number of alternate alleles, this site is filtered by the [genotyping engine](https://github.com/broadinstitute/gatk/blob/48afe160c9cfba5a82e40a6be9c8a555066271d1/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L380-L388), but it would be helpful if the merger also had a limit to avoid fatal errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6962:1407,error,errors,1407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6962,1,['error'],['errors']
Availability,"## Feature request. ### Tool(s) or class(es) involved; All WDL tests (Mutect2, CNV, Mitochondria pipeline, etc). ### Description; I'd like to be able to include tasks in GATK WDLs that use NIO (tasks with `String input_file` rather than `File input_file`). When I tried this with local git lfs files I got an error saying that the file could not be found (even though the file was being downloaded correctly). I then tried putting the file in `gs://hellbender/test/resources/large`, but when the tool tried to run on travis I got a permission error (see below). It would be great if the WDL tests all ran in the cloud since that's the main way we expect to run these WDLs. It would also be great it the local tests could account for NIO tasks (especially as we want to make more tasks use NIO in the future). ```; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified. It is possible to skip checking for Compute Engine metadata by specifying the environment variable NO_GCE_CHECK=true.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:227); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:438); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:239); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:236); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); at com.google.cloud.RetryHelper.run(RetryHelper.java:76); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:235); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:687); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.asse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5855:309,error,error,309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5855,4,"['Error', 'down', 'error']","['Error', 'downloaded', 'error']"
Availability,"## Feature request. ### Tool(s) or class(es) involved; CNNScoreVariants and perhaps other tools. ### Description; It would be nice to take stdout as the input. For example, when it is necessary to pass raw VCF from caller to CNNScoreVariants. In the current version, an error is produced. ```; zcat /home/platon/Dissertation/Exp/ngs_test/no_filtered.vcf.gz | gatk CNNScoreVariants \; -V /dev/stdin \; -R /home/platon/Dissertation/Exp/ngs_test/homo_sapiens/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \; -O /home/platon/Dissertation/Exp/Output; ```. ```; Using GATK jar /home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar CNNScoreVariants -V /dev/stdin -R /home/platon/Dissertation/Exp/ngs_test/homo_sapiens/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz -O /home/platon/Dissertation/Exp/Output; 18:04:27.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 26, 2020 6:04:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:04:27.246 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.246 INFO CNNScoreVariants - The Genome Analysis Toolkit (GATK) v4.1.8.1; 18:04:27.246 INFO CNNScoreVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:04:27.246 INFO CNNScoreVariants - Executing as platon@platon-VivoBook-ASUSLaptop-X712FA-X712FA on Linux v5.4.0-42-generic amd64; 18:04:27.246 INFO CNNScoreVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 18:04:27.247",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6749:270,error,error,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749,1,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved; DepthOfCoverage --intervals parameter. ### Description; Please supply an example of how intervals should be used. I just want to run DepthOfCoverage over the entire reference sequence (imho this should be the default and make --include optional), but cant work out how to do this. I tried. DepthOfCoverage other_parameters --intervals 1-30000; DepthOfCoverage other_parameters --intervals 1:30000. Both gave errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7155:463,error,errors,463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7155,1,['error'],['errors']
Availability,"## Feature request. ### Tool(s) or class(es) involved; Docker image. ### Description; We've been using this function in the GATK-SV WDLs to estimate the appropriate `-XmX` Java parameter for GATK tools:; ```; function getJavaMem() {; # get JVM memory in MiB by getting total memory from /proc/meminfo; # and multiplying by java_mem_fraction; cat /proc/meminfo \; | awk -v MEM_FIELD=""$1"" '{; f[substr($1, 1, length($1)-1)] = $2; } END {; printf ""%dM"", f[MEM_FIELD] * ~{default=""0.85"" java_mem_fraction} / 1024; }'; }; JVM_MAX_MEM=$(getJavaMem MemTotal); echo ""JVM memory: $JVM_MAX_MEM""; gatk --java-options ""-Xmx${JVM_MAX_MEM}"" ; ```; We've found this to be a reliable method because it uses the VM's actual memory rather than what was requested, which can be less than what is actually provided. This would be a generally useful utility function to build into the Docker for use across GATK WDLs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7941:553,echo,echo,553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7941,2,"['echo', 'reliab']","['echo', 'reliable']"
Availability,"## Feature request. ### Tool(s) or class(es) involved; Funcotator (auxiliary file). ### Description; We have a preferred transcript list for hg19 (i.e. GENCODE v19), but we do not have one for hg38 (latest version supported by Funcotator -- currently v29). There is a script in the oncotator repository for helping to create this list, but it does not have the manual curation. Please see @LeeTL1220 for details on this process. The oncotator datasource download page has the automatically-generated transcript list for gencode v19 alongside the automatically-generated+manual curation list. That can be used to suss out differences. Automatically-generated list was obtained by aligning transcripts to uniprot. I am not sure how the transcript IDs changed between GENCODE v19 and v29. So the complexity of this issue is still a bit unknown.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5914:454,down,download,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5914,1,['down'],['download']
Availability,"## Feature request. ### Tool(s) or class(es) involved; Funcotator. ### Description; Currently, the location of config files that specify the formats for SEG file output are hardcoded in the FuncotatorEngine. These should be available to to override via parameters to the FuncotatorEngine during initialization.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5962:224,avail,available,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5962,1,['avail'],['available']
Availability,"## Feature request. ### Tool(s) or class(es) involved; GATK PrintReads. ### Description; - Currently, this tool appears to consider reads independently of their mate, therefore if one partner is filtered and the other is not the SAM flags for the remaining read will be incorrect (indeed resulting BAMs from this tool fail GATK ValidateSamReads with error MATE_NOT_FOUND). ; - Here is a flagstat of one of these BAMs produced from this tool (note that there are no singleton reads listed, but they actually present -- you can even see this in the read1 and read2 counts; these counts should be equal if there are no supplementary, secondary, and/or singleton reads):. ```; 179466279 + 0 in total (QC-passed reads + QC-failed reads); 0 + 0 secondary; 0 + 0 supplementary; 0 + 0 duplicates; 179466279 + 0 mapped (100.00% : N/A); 179466279 + 0 paired in sequencing; 89740338 + 0 read1; 89725941 + 0 read2; 179466279 + 0 properly paired (100.00% : N/A); 179466279 + 0 with itself and mate mapped; 0 + 0 singletons (0.00% : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. - I have two suggestions:; - Add a `--remove-mates` option that would ensure that if one read in a pair does not pass the read filters, the read pair will be filtered.; - Alternatively, add an `--update-flags` option that would update the filtered-in mate's SAM flags to be technically correct (i.e. if the read's partner was filtered, remove the 0x1, 0x2, 0x8, 0x20, 0x40, and 0x80 flags if they were present)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6839:350,error,error,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6839,1,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved; GenomicsDBImport(v4.1.8.1). ### Description; Hello, I was construct to genomicdb using GenomicDBImport and import gvcf file for update genomicdb(Command). but since my server was shut down, during GenomicDBImport process, process is broke down. After I tried to GenomicDBImport same command for overwrite genomicdb and encounter to error message(error message).; ; In this case, should genomicdb be recreated from scratch? How to update the gvcf file I want to update? what should I do?. ### Command. java -jar $GATK GenomicsDBImport \; -L chr${1} \; -V $File_PATH/4762/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4763/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4764/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4765/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4767/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; --genomicsdb-update-workspace-path $DB_PATH/test_database \; --genomicsdb-shared-posixfs-optimizations true \; --max-num-intervals-to-import-in-parallel 5 \; --reader-threads 10 \; --tmp-dir $Script_PATH/tmp. ### Error message. 10:49:12.018 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/mone/OMICS/Tools/Programs/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 18, 2021 10:49:12 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:49:12.231 INFO GenomicsDBImport - ------------------------------------------------------------; 10:49:12.232 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 10:49:12.232 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:49:12.232 INFO GenomicsDBImport - Executing as chowoo1023@bdcm04 on Linux v3.10.0-514.2.2.el7.x86_64 amd64; 10:49:12.232 INFO GenomicsDBImport - Java runtim",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7324:239,down,down,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7324,4,"['down', 'error']","['down', 'error']"
Availability,"## Feature request. ### Tool(s) or class(es) involved; GenomicsDBImport. ### Description; Users get confused by this error message: `A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader`; `Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$249250621 at workspace: ...; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed`. In one of our [docs](https://gatk.broadinstitute.org/hc/en-us/articles/360035889971--How-to-Consolidate-GVCFs-for-joint-calling-with-GenotypeGVCFs), we offer this advice, but this is not a proper argument in the GATK tool docs yet:; _If youre working on a POSIX filesystem (e.g. Lustre, NFS, xfs, ext4 etc), you must set the environment variable TILEDB_DISABLE_FILE_LOCKING=1 before running any GenomicsDB tool. If you dont, you will likely see an error like Could not open array genomicsdb_array at workspace:[...]_. **This request is to add a proper argument to deal with this scenario in GenomicsDBImport and to document it in the tool docs.**",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6519:117,error,error,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6519,6,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"## Feature request. ### Tool(s) or class(es) involved; GermlineCNVCaller / PostprocessGermlineCNVCalls. ### Description; The VCF produced by the germline CNV calling workflow could be nicer. TBH the VCF output feels like a bit of an afterthought compared to the other outputs. This seems common for CNV callers, but I was hoping the VCF produced by the GATK would be more complete. Things that would make the VCF easier to use/interpret with downstream tooling:. 1. `##contig` lines in the header. `PostprocessGermlineCNVCalls` takes in a sequence dictionary, and I was surprised that isn't used in generating the VCF.; 2. Every record in the VCF has both `<DUP>` and `<DEL>` as alts even though the VCF is single-sample and a given sample can only be duplicated _or_ deleted. This makes quick text-searching of the VCF difficult and means one has to parse the genotypes to determine if the record represents a duplication or deletion in the sample.; 3. QUAL is `.` for all events. There are various quality scores in the FORMAT/GENOTYPE fields. It would be nice if either the preferred one of those or some other quality measure could be emitted into the QUAL field.; 4. There's nothing in the VCF that gives any indication of the observed read depth or correlated measures, only the called CN. Having either the mean depth over the segment or the raw & denoised copy ratios for the segment etc. would be helpful for manual review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6167:442,down,downstream,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6167,1,['down'],['downstream']
Availability,"## Feature request. ### Tool(s) or class(es) involved; LearnReadOrientation (& others I believe). ### Description; Wondering if you would consider modifying the exit status for 'java.lang.OutOfMemoryError` to reflect it being a memory-related error, perhaps `137`? This would help with pipelines that will retry with more memory in response to a memory-related error. The exit status is currently a generic `1`:. ```; Command exit status:; 1. ...; [March 23, 2023 at 5:50:17 AM GMT] org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModel done. Elapsed time: 2,210.83 minutes.; Runtime.totalMemory()=7796817920; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; at org.apache.commons.math3.linear.Array2DRowRealMatrix.<init>(Array2DRowRealMatrix.java:61); at org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelEngine.<init>(LearnReadOrientationModelEngine.java:131); at org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModel.doWork(LearnReadOrientationModel.java:163); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /gatk/gatk-package-4.4.0.0-local.jar; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8264:243,error,error,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8264,2,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved; M2 WDL and FC deployment of M2. ### Description; We should specify the same file listed in the GATK forum (https://gatkforums.broadinstitute.org/gatk/discussion/4154/howto-install-and-run-oncotator-for-the-first-time), which can be downloaded from: https://personal.broadinstitute.org/lichtens/oncobeta/tx_exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt; This should be used as the default transcript selection list for funcotator (@jonn-smith I assume that funcotator and oncotator use the same format for this file. Please confirm.). The only time you would not want this file is if you are not running on hg19. For other references, ideally, we would want different lists. - This list needs to be put into a bucket (gatk-best-practices?); - Please notify @bshifaw for deployment in the FC featured workspace in the appropriate funcotator parameter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5841:287,down,downloaded,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5841,1,['down'],['downloaded']
Availability,"## Feature request. ### Tool(s) or class(es) involved; MuTect2 wdl (mutect2.wdl), task Funcotate. ### Description; May I know if it sounds like a good idea to add a option to skip the ""Extract our data sources"" part in mutect2.wdl. I am using mutect2.wdl in HPC system and all the data sources and gnomad for Funcotate were unzipped and ready to use. So there is no need to ""Extract data sources"" every time (and save time and resources). I can change it and make a pull request if it sounds like a good idea. The code in mutect2.wdl that I'm going to make an option to skip listed below:. # Extract our data sources:; echo ""Extracting data sources zip file...""; mkdir datasources_dir; tar zxvf ~{data_sources_tar_gz} -C datasources_dir --strip-components 1; DATA_SOURCES_FOLDER=""$PWD/datasources_dir"". # Handle gnomAD:; if ~{use_gnomad} ; then; echo ""Enabling gnomAD...""; for potential_gnomad_gz in gnomAD_exome.tar.gz gnomAD_genome.tar.gz ; do; if [[ -f ~{dollar}{DATA_SOURCES_FOLDER}/~{dollar}{potential_gnomad_gz} ]] ; then; cd ~{dollar}{DATA_SOURCES_FOLDER}; tar -zvxf ~{dollar}{potential_gnomad_gz}; cd -; else; echo ""ERROR: Cannot find gnomAD folder: ~{dollar}{potential_gnomad_gz}"" 1>&2; false; fi; done; fi. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6731:619,echo,echo,619,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6731,4,"['ERROR', 'echo']","['ERROR', 'echo']"
Availability,"## Feature request. ### Tool(s) or class(es) involved; SelectVariants/GenotypeGVCFs/GnarlyGenotyper. ### Description; GenomicsDBExportConfiguration allows for the following to be configured - currently they are mostly hardcoded - `produceGTField`, `produceGTWithMinPLValueForSpanningDeletions`, `setSitesOnlyQuery`, `maxDiploidAltAllelesThatCanBeGenotyped` and `maxGenotypeCount`. Most of this functionality was implemented to support various use cases at some point. Look at the current arguments for subsetting/downsampling/filtering/joint genotyping in the tools and hook existing tool arguments with GenomicsDBExportConfiguration as needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6456:513,down,downsampling,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6456,1,['down'],['downsampling']
Availability,"## Feature request. ### Tool(s) or class(es) involved; ValidateBasicSomaticShortMutations . ### Description; It turns out that this tool is doing a subset of the CGA tool, MutationValidator. Originally, the understanding (by both DSP and CGA) was the the GATK tool was doing a different algorithm, but this turned out to be incorrect. We should rename the GATK tool perhaps to SomaticShortMutationValidator and cite MutationValidator. Any relevant WDL should be updated to prevent unnecessary workflow failures. @davidbenjamin . (citation does not exist as per last offline meeting with CGA)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5871:502,failure,failures,502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5871,1,['failure'],['failures']
Availability,"## Feature request. ### Tool(s) or class(es) involved; VariantFiltration. ### Description; While running variantFiltration, I have encountered the following error:; ```; java.lang.NumberFormatException: For input string: ""nan""; at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043); at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); at java.lang.Double.parseDouble(Double.java:538); at org.apache.commons.jexl2.JexlArithmetic.toDouble(JexlArithmetic.java:1016); at org.apache.commons.jexl2.JexlArithmetic.compare(JexlArithmetic.java:699); at org.apache.commons.jexl2.JexlArithmetic.lessThan(JexlArithmetic.java:774); at org.apache.commons.jexl2.Interpreter.visit(Interpreter.java:967); at org.apache.commons.jexl2.parser.ASTLTNode.jjtAccept(ASTLTNode.java:18); at org.apache.commons.jexl2.Interpreter.interpret(Interpreter.java:232); at org.apache.commons.jexl2.ExpressionImpl.evaluate(ExpressionImpl.java:65); at htsjdk.variant.variantcontext.JEXLMap.evaluateExpression(JEXLMap.java:186); at htsjdk.variant.variantcontext.JEXLMap.get(JEXLMap.java:95); at htsjdk.variant.variantcontext.JEXLMap.get(JEXLMap.java:15); at htsjdk.variant.variantcontext.VariantContextUtils.match(VariantContextUtils.java:338); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.matchesFilter(VariantFiltration.java:379); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.filter(VariantFiltration.java:338); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.apply(VariantFiltration.java:298); at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:153); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5582:157,error,error,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582,1,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_, _DataSourceFuncotationFactory_. ### Description; Funcotator should support NIO for data sources and data sources backing files.; In addition, the data source readers should be updated to support multiple backing files to support the `gnomAD` case (http://gnomad.broadinstitute.org/downloads).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5348:350,down,downloads,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5348,1,['down'],['downloads']
Availability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_. ### Description; Currently the data sources for the clinical pipeline work contain ExAC. This must be updated to use gnomAD. The change will require a new release of the data sources which must be connected to the data source downloader tool. Additionally, these new data sources must be validated in four ways:; - By visually inspecting the gnomAD source file for correctness.; - By verifying that the source file for gnomAD does not contain special characters.; - By validating that the source file for gnomAD is a valid VCF (assuming it is used VCF format).; - By running a large file and spot checking at least 10 variants for correctness. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5259:295,down,downloader,295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5259,1,['down'],['downloader']
Availability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_. ### Description; When running Funcotator on a large VCF, it can take several hours to complete, but each variant row is handled separately, row 1 and row 5 million are equally likely to have problems. Currently, a sufficiently malformed variant row causes it to crash and leave partial output. . It would be much friendlier if the true crash problems (e.g. something like ""invalid interval"") were saved and the crash-causing variant lines reported in bulk at completion, sending an OS exit code/error then. . It might even be a configurable option to exit immediately or save until end. . I do think it is appropriate to crash if a problem is encountered while parsing the header lines.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7097:564,error,error,564,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7097,1,['error'],['error']
Availability,"## Feature request. ### Tool(s) or class(es) involved; _GATK VariantEval_. ### Description; Currently, if I provide a VCF to VariantEval together with a dbSNP file, but the input VCF does not variants on all chromosomes or contigs from the dbSNP, the tool will fail. ; The current solution is to always check the input VCF for all chromosomes/contigs where mutations exist, and then filter the dbSNP file to keep only the entries with those some chromosomes. ; Would it be possible to allow for the use of a full dbSNP file with GATK VariantEval, regardless of whether the input VCF has variants on all chromosomes that exist in the dbSNP or not?. More info on a forum post as well: ; https://gatk.broadinstitute.org/hc/en-us/community/posts/360072397571-VariatEval-ERROR-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6855:766,ERROR,ERROR,766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6855,1,['ERROR'],['ERROR']
Availability,## Feature request. ### Tool(s) or class(es) involved; _GencodeFuncotationFactory_. ### Description; Currently the mitochondrial contig is determined using a simple string comparison by contig name. ; This determination is then used to decode the mitochondrial protein sequence (which gets decoded differently than the normal gene sequences). Make this more robust by detecting the mito contig based on the reference used.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5364:358,robust,robust,358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5364,1,['robust'],['robust']
Availability,"## Feature request. ### Tool(s) or class(es) involved; `SelectVariants`. ### Description; In order to run SelectVariants with VCF inputs that are in separate locations from their index files or to stream SelectVariants using https from Azure blob storage, we need a way to provide the index file in a separate argument from the `-V` input. @jamesemery started thinking this through (copying this from slack):. > In `featureDataSource.getTribbleFeatureReader()` we currently initialize the datasources in `getFeatureReader()` which gets called by `VariantWalker.initializeDrivingVariants()` . You could stick an override into that where you thread down the path for the index source through that path and optionally (only if the index is explicitly supplied by the user) push it down into the `getTribbleFeatureReader()` calls at the bottom of the stack there. @droazen any thoughts on this? @VJalili Would adding this feature to `SelectVariants` be useful for your pipelines at all?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8568:647,down,down,647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8568,2,['down'],['down']
Availability,"## Feature request. Make joint genotyping functionality available as a publicly accessible function to another class/program without passing through the GATK command line interface. ### Tool(s) or class(es) involved; VariantContext; GenotypeGVCFs; Underlying engine classes. ### Description; For various use cases where our pipelines produce in-memory VariantContext objects it would be faster and easier to pass these directly to a joint genotyping function and extract the results back into memory rather than writing to VCF, running the GenotypeGVCFs pipeline via the command line interface and then re-ingesting the resultant VCFs. From discussions during the GATK Working Group meetings it appears this request is similar in principle to existing functionality for the HaplotypeCaller that was implemented by ""extracting the engine"" from the HaplotypeCaller walkers so that it can be instantiated outside the command line utility. Ideally, this implementation should make it possible to instantiate any necessary engine classes pass VariantContext objects directly to the GenotypeGVCFs.apply or GenotypeGVCFs.regenotypeVC and receive the re-genotyped VariantContext objects back for further processing from Java code. . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5910:56,avail,available,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5910,1,['avail'],['available']
Availability,## Feature request. The mitochondria pipeline should have new annotations and filters in Mutect2 and FilterMutectCalls. This is being addressed in #5193. An accompanying best practices WDL should also be developed and eventually be available in Firecloud. I'll update here once the PR is merged and has been released.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5310:232,avail,available,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5310,1,['avail'],['available']
Availability,"## Feature request; ### HaplotypeCaller; When running HaplotypeCaller, I get tens of thousands of lines like the following:; ```; 13:02:04.113 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 13:02:04.113 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 13:02:04.113 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 13:02:04.113 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; ```; The problem is they are not informative: you can't tell what position/region caused them. Resulting repetitive messages are redundant.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5912:771,redundant,redundant,771,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912,1,['redundant'],['redundant']
Availability,"## Feature request; ### Tool(s) involved. Engine; ### Description. An ENUM with several levels of minimalism. Main use case: keeping down the lines of SQ. As put by @eitanbanks . > One thing that option would do would be to _not_ print out all of the reference contigs. While it's not terrible in b37, you should know that hg38 has thousands upon thousands of contigs and it's such a pain to have them all in the header. Simplest way to do this imho (and I would advocate making it the default GATK behavior): write to VCF header SQ lines representing only the contigs for which we have calls. More discussion needed to define exactly what options should distinguished.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2233:133,down,down,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2233,1,['down'],['down']
Availability,## Feature request; ### Tool(s) involved. VariantRecalibrator; ### Description. A user reported he gets an `##### ERROR MESSAGE: No data found.` from VariantRecalibrator when running with -an MQ twice. There should be a check for this and an error message letting the user know he/she has specified the same annotation twice. . [Original Forum Post](http://gatkforums.broadinstitute.org/gatk/discussion/comment/33592#Comment_33592). ---,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2221:114,ERROR,ERROR,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2221,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"## First, add variables to HelpConstants.java ; at <https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/help/HelpConstants.java>. These need to be under _group definitions_ as well as under _supercategory_. E.g.:; ```; public final static String DOC_CAT_READFILTERS = ""Read Filters"";; public final static String DOC_CAT_READFILTERS_SUMMARY = ""Read Filters used by the engine to select reads to be included for analysis"";; ...; // supercat Utilities; groupToSuperCategory.put(DOC_CAT_READFILTERS, DOC_SUPERCAT_UTILITIES);; ```. - group name variable and descriptor: DOC_CAT_ANNOTATORS = ""Annotation Modules""; - group summary variable and descriptor: DOC_CAT_ANNOTATORS_SUMMARY = ""Annotations available to HaplotypeCaller, Mutect2 and VariantAnnotator""; - super category: Utilities (same group as read filters). This is now in <https://github.com/broadinstitute/gatk/pull/3835/commits/320b64a0391b751f4a738100fe854d243b02f2b4>. ---; ## SOP ; https://github.com/broadinstitute/gatk/pull/3835. [1] Add feature tag and define elements to all annotation modules in <https://github.com/broadinstitute/gatk/tree/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator>. E.g. the tag looks thus:; ```; @DocumentedFeature(groupName=HelpConstants.DOC_CAT_READFILTERS, groupSummary=HelpConstants.DOC_CAT_READFILTERS_SUMMARY, summary = ""Keep only reads that are first of pair""); ```; - group name variable: DOC_CAT_ANNOTATORS; - group summary variable: DOC_CAT_ANNOTATORS_SUMMARY; - summary specific to the annotation module. ### For copy-pasting:; ```; @DocumentedFeature(groupName=HelpConstants.DOC_CAT_ANNOTATORS, groupSummary=HelpConstants.DOC_CAT_ANNOTATORS_SUMMARY, summary = """"); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344383546:740,avail,available,740,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344383546,1,['avail'],['available']
Availability,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532:525,Error,Error,525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532,6,"['Error', 'down', 'error']","['Error', 'downstream', 'error']"
Availability,"## System; * Mac OS X 10.11.6 x86_64; * Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27. ## Problem; I'm trying to update my project ([ReadTools](https://github.com/magicDGS/ReadTools)) to the latest version of GATK and this dependency throws the following error with some of my gradle tests and while running an uber-jar (using `--use_jdk_deflater false`):. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011d925644, pid=7088, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression8215566221555962564.dylib+0x1644] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid7088.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Find attached the log: [hs_err_pid7088.log.txt](https://github.com/broadinstitute/gatk/files/652421/hs_err_pid7088.log.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315:256,error,error,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315,3,['error'],['error']
Availability,"## What is an A+ tooldoc example?; @vdauwera @ldgauthier, could either or both of you help your fellow developers out with what you consider an A+ tool doc? @mwalker174 and others have asked for this. It would help those new to GATK tool documentation immensely. In the meanwhile, here are some from me, in order of increasing complexity, and just to start the discussion. - [PrintReads](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_gatk_tools_walkers_readutils_PrintReads.php) gives three flavors although the utility of the first two commands may be questionable.; - [HaplotypeCaller](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_gatk_tools_walkers_haplotypecaller_HaplotypeCaller.php) gives overview, breaks down the steps (with easy-read spacing and formatting), select usage examples for various contexts, caveats and a special note on ploidy. There is even an `Additional Notes` section with useful information. I might think of merging the last two sections somehow if I had to do it over.; - [SelectVariants](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_gatk_tools_walkers_variantutils_SelectVariants.php) gives many different usage examples, appropriate for such a versatile tool. @ldgauthier says [CalculateGenotypePosteriors](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_gatk_tools_walkers_variantutils_CalculateGenotypePosteriors.php) is solid and [VariantsToTable](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_gatk_tools_walkers_variantutils_VariantsToTable.php) and, again, [SelectVariants](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_gatk_tools_walkers_variantutils_SelectVariants.php) are good too. @vdauwera interjects saying SelectVariants has too many alternate command examples but agrees it is solid.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-348013707:803,down,down,803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-348013707,1,['down'],['down']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8282?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0f24625`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8282 +/- ##; ================================================; Coverage ? 86.097% ; Complexity ? 35607 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18007 ; ================================================; Hits ? 143884 ; Misses ? 16802 ; Partials ? 6433 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8282#issuecomment-1520851049:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8282#issuecomment-1520851049,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8295?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0b4e305`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8295 +/- ##; ================================================; Coverage ? 86.188% ; Complexity ? 35524 ; ================================================; Files ? 2192 ; Lines ? 166470 ; Branches ? 17917 ; ================================================; Hits ? 143478 ; Misses ? 16606 ; Partials ? 6386 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8295#issuecomment-1520727759:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8295#issuecomment-1520727759,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8301?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0f24625`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8301 +/- ##; ================================================; Coverage ? 76.562% ; Complexity ? 21800 ; ================================================; Files ? 1390 ; Lines ? 83084 ; Branches ? 13237 ; ================================================; Hits ? 63611 ; Misses ? 14308 ; Partials ? 5165 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8301#issuecomment-1529211297:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8301#issuecomment-1529211297,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8312?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@928ffe9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8312 +/- ##; ================================================; Coverage ? 86.193% ; Complexity ? 35520 ; ================================================; Files ? 2192 ; Lines ? 166470 ; Branches ? 17918 ; ================================================; Hits ? 143485 ; Misses ? 16600 ; Partials ? 6385 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8312#issuecomment-1544190557:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8312#issuecomment-1544190557,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8316?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6a0b1a4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 1104159 differs from pull request most recent head 20463d5. Consider uploading reports for the commit 20463d5 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8316 +/- ##; ================================================; Coverage ? 79.161% ; Complexity ? 33612 ; ================================================; Files ? 2192 ; Lines ? 166470 ; Branches ? 17917 ; ================================================; Hits ? 131780 ; Misses ? 28458 ; Partials ? 6232 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8316#issuecomment-1545955543:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8316#issuecomment-1545955543,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8321?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@ebe4835`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8321 +/- ##; ================================================; Coverage ? 85.819% ; Complexity ? 35381 ; ================================================; Files ? 2193 ; Lines ? 166544 ; Branches ? 17929 ; ================================================; Hits ? 142926 ; Misses ? 17273 ; Partials ? 6345 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8321#issuecomment-1547837528:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8321#issuecomment-1547837528,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8322?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@fe981fa`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 86da2fb differs from pull request most recent head 6008c58. Consider uploading reports for the commit 6008c58 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8322 +/- ##; ================================================; Coverage ? 42.495% ; Complexity ? 24044 ; ================================================; Files ? 2193 ; Lines ? 166544 ; Branches ? 17930 ; ================================================; Hits ? 70773 ; Misses ? 90620 ; Partials ? 5151 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8322#issuecomment-1548080149:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8322#issuecomment-1548080149,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8324?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@c575ff8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 8aea303 differs from pull request most recent head 6c21de9. Consider uploading reports for the commit 6c21de9 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8324 +/- ##; ================================================; Coverage ? 16.773% ; Complexity ? 4707 ; ================================================; Files ? 1391 ; Lines ? 83142 ; Branches ? 13184 ; ================================================; Hits ? 13945 ; Misses ? 67132 ; Partials ? 2065 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8324#issuecomment-1550371424:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8324#issuecomment-1550371424,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8325?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e3f2d8a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8325 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143481 ; Misses ? 16674 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8325#issuecomment-1550378961:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8325#issuecomment-1550378961,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8326?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@b64a252`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8326 +/- ##; ================================================; Coverage ? 86.193% ; Complexity ? 35521 ; ================================================; Files ? 2192 ; Lines ? 166470 ; Branches ? 17918 ; ================================================; Hits ? 143485 ; Misses ? 16601 ; Partials ? 6384 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8326#issuecomment-1551765161:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8326#issuecomment-1551765161,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8330?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@fe981fa`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8330 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35524 ; ================================================; Files ? 2193 ; Lines ? 166544 ; Branches ? 17929 ; ================================================; Hits ? 143486 ; Misses ? 16670 ; Partials ? 6388 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8330#issuecomment-1558063589:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8330#issuecomment-1558063589,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8334?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@40947ed`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8334 +/- ##; ================================================; Coverage ? 84.259% ; Complexity ? 34805 ; ================================================; Files ? 2193 ; Lines ? 166537 ; Branches ? 17924 ; ================================================; Hits ? 140323 ; Misses ? 19984 ; Partials ? 6230 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8334#issuecomment-1557679635:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8334#issuecomment-1557679635,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8336?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@85205fc`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 4fd48f7 differs from pull request most recent head 464e594. Consider uploading reports for the commit 464e594 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8336 +/- ##; ================================================; Coverage ? 86.086% ; Complexity ? 35457 ; ================================================; Files ? 2193 ; Lines ? 166541 ; Branches ? 17928 ; ================================================; Hits ? 143368 ; Misses ? 16765 ; Partials ? 6408 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8336#issuecomment-1557856438:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8336#issuecomment-1557856438,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8343?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@55a471a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8343 +/- ##; ================================================; Coverage ? 85.976% ; Complexity ? 35405 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; ================================================; Hits ? 143199 ; Misses ? 16965 ; Partials ? 6393 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8343#issuecomment-1561893562:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8343#issuecomment-1561893562,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8344?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0feb524`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8344 +/- ##; ================================================; Coverage ? 86.121% ; Complexity ? 35510 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143425 ; Misses ? 16723 ; Partials ? 6390 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8344#issuecomment-1563346001:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8344#issuecomment-1563346001,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8348?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0b41b51`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8348 +/- ##; ================================================; Coverage ? 86.159% ; Complexity ? 35516 ; ================================================; Files ? 2193 ; Lines ? 166537 ; Branches ? 17924 ; ================================================; Hits ? 143486 ; Misses ? 16666 ; Partials ? 6385 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8348#issuecomment-1568779341:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8348#issuecomment-1568779341,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8350?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@a191f2d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8350 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143481 ; Misses ? 16673 ; Partials ? 6384 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8350#issuecomment-1577427313:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8350#issuecomment-1577427313,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8360?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@5b72ceb`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8360 +/- ##; ================================================; Coverage ? 86.156% ; Complexity ? 35518 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143483 ; Misses ? 16672 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8360#issuecomment-1588172867:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8360#issuecomment-1588172867,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8365?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@1dafc33`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8365 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143481 ; Misses ? 16673 ; Partials ? 6384 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8365#issuecomment-1591745229:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8365#issuecomment-1591745229,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8374?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@af4f273`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8374 +/- ##; ================================================; Coverage ? 86.158% ; Complexity ? 35518 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143485 ; Misses ? 16670 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8374#issuecomment-1601747660:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8374#issuecomment-1601747660,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8375?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@90aa0fd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 96b13ac differs from pull request most recent head 16fbf89. Consider uploading reports for the commit 16fbf89 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8375 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143481 ; Misses ? 16674 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1603090906:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1603090906,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8376?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@1ce25db`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8376 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35521 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17925 ; ================================================; Hits ? 143481 ; Misses ? 16674 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8376#issuecomment-1603277688:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8376#issuecomment-1603277688,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8377?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@37fe914`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8377 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143481 ; Misses ? 16674 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8377#issuecomment-1603168821:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8377#issuecomment-1603168821,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8379?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@90aa0fd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8379 +/- ##; ================================================; Coverage ? 76.504% ; Complexity ? 21795 ; ================================================; Files ? 1392 ; Lines ? 83134 ; Branches ? 13184 ; ================================================; Hits ? 63601 ; Misses ? 14369 ; Partials ? 5164 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8379#issuecomment-1603351488:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8379#issuecomment-1603351488,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8388?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@901644f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head c92dbdd differs from pull request most recent head e3308ca. Consider uploading reports for the commit e3308ca to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8388 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35521 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17925 ; ================================================; Hits ? 143481 ; Misses ? 16674 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8388#issuecomment-1610169170:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8388#issuecomment-1610169170,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8392?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@90aa0fd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8392 +/- ##; ================================================; Coverage ? 86.088% ; Complexity ? 35461 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17925 ; ================================================; Hits ? 143370 ; Misses ? 16767 ; Partials ? 6401 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8392#issuecomment-1612198935:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8392#issuecomment-1612198935,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8399?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@09989de`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8399 +/- ##; ================================================; Coverage ? 86.160% ; Complexity ? 35524 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17925 ; ================================================; Hits ? 143489 ; Misses ? 16665 ; Partials ? 6384 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8399#issuecomment-1615122400:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8399#issuecomment-1615122400,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8401?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e90d90e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8401 +/- ##; ================================================; Coverage ? 84.260% ; Complexity ? 34807 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 140325 ; Misses ? 19983 ; Partials ? 6230 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8401#issuecomment-1621702563:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8401#issuecomment-1621702563,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8404?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@60581fe`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8404 +/- ##; =======================================================; Coverage ? 86.161% ; Complexity ? 35519 ; =======================================================; Files ? 2194 ; Lines ? 166533 ; Branches ? 17926 ; =======================================================; Hits ? 143487 ; Misses ? 16663 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1625475765:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1625475765,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8412?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@5580ca0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8412 +/- ##; ================================================; Coverage ? 86.162% ; Complexity ? 35523 ; ================================================; Files ? 2194 ; Lines ? 166533 ; Branches ? 17925 ; ================================================; Hits ? 143488 ; Misses ? 16663 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8412#issuecomment-1631098665:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8412#issuecomment-1631098665,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8422?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@da60534`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8422 +/- ##; =======================================================; Coverage ? 44.447% ; Complexity ? 24788 ; =======================================================; Files ? 2194 ; Lines ? 166533 ; Branches ? 17925 ; =======================================================; Hits ? 74019 ; Misses ? 87209 ; Partials ? 5305 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8422#issuecomment-1638661867:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8422#issuecomment-1638661867,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8423?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@7a144d3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 4e40c14 differs from pull request most recent head 26fa502. Consider uploading reports for the commit 26fa502 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8423 +/- ##; ================================================; Coverage ? 16.791% ; Complexity ? 4708 ; ================================================; Files ? 1392 ; Lines ? 83169 ; Branches ? 13248 ; ================================================; Hits ? 13965 ; Misses ? 67144 ; Partials ? 2060 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8423#issuecomment-1638762697:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8423#issuecomment-1638762697,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8424?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@7a144d3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8424 +/- ##; ================================================; Coverage ? 86.151% ; Complexity ? 35524 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; ================================================; Hits ? 143491 ; Misses ? 16683 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8424#issuecomment-1638931132:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8424#issuecomment-1638931132,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8426?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@154bee2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head f2867f5 differs from pull request most recent head 9321715. Consider uploading reports for the commit 9321715 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8426 +/- ##; ================================================; Coverage ? 79.133% ; Complexity ? 33606 ; ================================================; Files ? 2194 ; Lines ? 166533 ; Branches ? 17926 ; ================================================; Hits ? 131783 ; Misses ? 28520 ; Partials ? 6230 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8426#issuecomment-1640973922:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8426#issuecomment-1640973922,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8429?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@260c334`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head bb8dc75 differs from pull request most recent head b95a16b. Consider uploading reports for the commit b95a16b to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8429 +/- ##; =======================================================; Coverage ? 86.152% ; Complexity ? 35525 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143493 ; Misses ? 16682 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8429#issuecomment-1644346011:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8429#issuecomment-1644346011,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8433?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@154bee2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head aef01b7 differs from pull request most recent head 2f49bf3. Consider uploading reports for the commit 2f49bf3 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8433 +/- ##; ================================================; Coverage ? 86.152% ; Complexity ? 35524 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; ================================================; Hits ? 143493 ; Misses ? 16681 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8433#issuecomment-1648453095:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8433#issuecomment-1648453095,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8434?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@f44e924`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8434 +/- ##; =======================================================; Coverage ? 86.152% ; Complexity ? 35521 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143493 ; Misses ? 16682 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8434#issuecomment-1648724092:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8434#issuecomment-1648724092,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8437?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d37e34b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8437 +/- ##; ================================================; Coverage ? 84.375% ; Complexity ? 34492 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; ================================================; Hits ? 140533 ; Misses ? 19588 ; Partials ? 6436 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8437#issuecomment-1650218483:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8437#issuecomment-1650218483,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8441?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@295bfbd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8441 +/- ##; =======================================================; Coverage ? 85.977% ; Complexity ? 35409 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143201 ; Misses ? 16965 ; Partials ? 6391 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8441#issuecomment-1654080894:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8441#issuecomment-1654080894,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8444?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@576423f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8444 +/- ##; =======================================================; Coverage ? 79.127% ; Complexity ? 33613 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 131792 ; Misses ? 28536 ; Partials ? 6229 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8444#issuecomment-1658465758:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8444#issuecomment-1658465758,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8446?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@d0eaafe`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head d699778 differs from pull request most recent head 0211678. Consider uploading reports for the commit 0211678 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8446 +/- ##; =======================================================; Coverage ? 86.154% ; Complexity ? 35521 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143495 ; Misses ? 16680 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8446#issuecomment-1660633770:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8446#issuecomment-1660633770,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8448?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@d488339`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8448 +/- ##; =======================================================; Coverage ? 86.151% ; Complexity ? 35524 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143491 ; Misses ? 16683 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8448#issuecomment-1661011654:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8448#issuecomment-1661011654,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8449?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@5a9d64a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8449 +/- ##; =======================================================; Coverage ? 86.152% ; Complexity ? 35524 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143493 ; Misses ? 16681 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8449#issuecomment-1661006980:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8449#issuecomment-1661006980,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8451?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@5a9d64a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8451 +/- ##; =======================================================; Coverage ? 86.085% ; Complexity ? 35463 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143380 ; Misses ? 16775 ; Partials ? 6402 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8451#issuecomment-1662329609:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8451#issuecomment-1662329609,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8452?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@58a7756`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8452 +/- ##; =======================================================; Coverage ? 86.155% ; Complexity ? 35524 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143498 ; Misses ? 16677 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8452#issuecomment-1664274127:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8452#issuecomment-1664274127,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8454?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@1685694`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8454 +/- ##; =======================================================; Coverage ? 86.154% ; Complexity ? 35523 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143496 ; Misses ? 16678 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8454#issuecomment-1666193340:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8454#issuecomment-1666193340,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8457?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@20e5496`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8457 +/- ##; =======================================================; Coverage ? 86.155% ; Complexity ? 35524 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143498 ; Misses ? 16677 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8457#issuecomment-1668684607:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8457#issuecomment-1668684607,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8459?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6cc161c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #8459 +/- ##; ================================================; Coverage ? 86.052% ; Complexity ? 35407 ; ================================================; Files ? 2194 ; Lines ? 166374 ; Branches ? 17820 ; ================================================; Hits ? 143168 ; Misses ? 16816 ; Partials ? 6390 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1670225203:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1670225203,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8465?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@f839eb0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8465 +/- ##; ================================================; Coverage ? 86.154% ; Complexity ? 35523 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; ================================================; Hits ? 143496 ; Misses ? 16678 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8465#issuecomment-1673782679:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8465#issuecomment-1673782679,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8469?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@d8bc38d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8469 +/- ##; =======================================================; Coverage ? 86.121% ; Complexity ? 35516 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143440 ; Misses ? 16727 ; Partials ? 6390 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8469#issuecomment-1674793264:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8469#issuecomment-1674793264,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8471?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@f839eb0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8471 +/- ##; ================================================; Coverage ? 86.154% ; Complexity ? 35523 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; ================================================; Hits ? 143496 ; Misses ? 16678 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8471#issuecomment-1675482821:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8471#issuecomment-1675482821,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8478?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@c1efb6f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8478 +/- ##; =======================================================; Coverage ? 85.979% ; Complexity ? 35409 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143204 ; Misses ? 16961 ; Partials ? 6392 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8478#issuecomment-1680714556:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8478#issuecomment-1680714556,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8480?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@c1efb6f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8480 +/- ##; =======================================================; Coverage ? 85.978% ; Complexity ? 35410 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143202 ; Misses ? 16962 ; Partials ? 6393 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8480#issuecomment-1680729482:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8480#issuecomment-1680729482,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8487?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6cc161c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 92d2629 differs from pull request most recent head eb060d8. Consider uploading reports for the commit eb060d8 to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #8487 +/- ##; ================================================; Coverage ? 86.051% ; Complexity ? 35406 ; ================================================; Files ? 2194 ; Lines ? 166374 ; Branches ? 17820 ; ================================================; Hits ? 143166 ; Misses ? 16817 ; Partials ? 6391 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1696195651:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1696195651,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8488?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@f839eb0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head cfe9df2 differs from pull request most recent head b162855. Consider uploading reports for the commit b162855 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8488 +/- ##; =======================================================; Coverage ? 86.086% ; Complexity ? 35464 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143382 ; Misses ? 16774 ; Partials ? 6401 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8488#issuecomment-1686937041:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8488#issuecomment-1686937041,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8491?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@dc1b3e9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8491 +/- ##; =======================================================; Coverage ? 62.505% ; Complexity ? 17244 ; =======================================================; Files ? 1392 ; Lines ? 83169 ; Branches ? 13248 ; =======================================================; Hits ? 51985 ; Misses ? 26001 ; Partials ? 5183 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8491#issuecomment-1690577393:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8491#issuecomment-1690577393,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8493?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@dc1b3e9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8493 +/- ##; =======================================================; Coverage ? 86.086% ; Complexity ? 35460 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143382 ; Misses ? 16774 ; Partials ? 6401 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8493#issuecomment-1691609046:357,error,error-reference,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8493#issuecomment-1691609046,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8507?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@3a2adec`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 883fc2e differs from pull request most recent head 9387e9a. Consider uploading reports for the commit 9387e9a to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #8507 +/- ##; ================================================; Coverage ? 70.645% ; Complexity ? 28786 ; ================================================; Files ? 2195 ; Lines ? 166413 ; Branches ? 17828 ; ================================================; Hits ? 117563 ; Misses ? 43183 ; Partials ? 5667 ; ```. :loudspeaker: Thoughts on this report? [Let us know!](https://about.codecov.io/pull-request-comment-report/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1699284129:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1699284129,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8509?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@a4bed50`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head c9e4c3f differs from pull request most recent head 85b7a3b. Consider uploading reports for the commit 85b7a3b to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #8509 +/- ##; ================================================; Coverage ? 85.524% ; Complexity ? 39841 ; ================================================; Files ? 2420 ; Lines ? 189649 ; Branches ? 20685 ; ================================================; Hits ? 162196 ; Misses ? 20184 ; Partials ? 7269 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8509#issuecomment-1702911638:350,error,error-reference,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8509#issuecomment-1702911638,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8175?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8217073`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8175 +/- ##; ================================================; Coverage ? 85.880% ; Complexity ? 35515 ; ================================================; Files ? 2194 ; Lines ? 167029 ; Branches ? 18006 ; ================================================; Hits ? 143444 ; Misses ? 17204 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8175#issuecomment-1405736974:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8175#issuecomment-1405736974,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8197?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@4a1c203`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8197 +/- ##; ================================================; Coverage ? 83.979% ; Complexity ? 34803 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18005 ; ================================================; Hits ? 140278 ; Misses ? 20534 ; Partials ? 6227 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8197#issuecomment-1441167372:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8197#issuecomment-1441167372,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8205?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d07e773`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8205 +/- ##; ================================================; Coverage ? 83.980% ; Complexity ? 34807 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18004 ; ================================================; Hits ? 140279 ; Misses ? 20533 ; Partials ? 6227 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8205#issuecomment-1431939059:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8205#issuecomment-1431939059,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8214?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d07e773`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8214 +/- ##; ================================================; Coverage ? 85.887% ; Complexity ? 35515 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18001 ; ================================================; Hits ? 143442 ; Misses ? 17190 ; Partials ? 6380 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8214#issuecomment-1439187114:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8214#issuecomment-1439187114,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8250?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@291bfd0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head f840dcb differs from pull request most recent head f8fb2ec. Consider uploading reports for the commit f8fb2ec to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8250 +/- ##; ================================================; Coverage ? 85.467% ; Complexity ? 35312 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18004 ; ================================================; Hits ? 142764 ; Misses ? 17923 ; Partials ? 6352 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8250#issuecomment-1476982396:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8250#issuecomment-1476982396,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8254?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@291bfd0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8254 +/- ##; ================================================; Coverage ? 85.700% ; Complexity ? 35403 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18004 ; ================================================; Hits ? 143152 ; Misses ? 17496 ; Partials ? 6391 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8254#issuecomment-1477885334:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8254#issuecomment-1477885334,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8260?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@bb6806b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8260 +/- ##; ================================================; Coverage ? 16.665% ; Complexity ? 4707 ; ================================================; Files ? 1392 ; Lines ? 83713 ; Branches ? 13263 ; ================================================; Hits ? 13951 ; Misses ? 67697 ; Partials ? 2065 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8260#issuecomment-1480347954:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8260#issuecomment-1480347954,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8261?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@291bfd0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8261 +/- ##; ================================================; Coverage ? 85.873% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18005 ; ================================================; Hits ? 143442 ; Misses ? 17216 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8261#issuecomment-1481911828:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8261#issuecomment-1481911828,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8262?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@c0535f2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8262 +/- ##; ================================================; Coverage ? 85.875% ; Complexity ? 35516 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18005 ; ================================================; Hits ? 143444 ; Misses ? 17214 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8262#issuecomment-1482752379:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8262#issuecomment-1482752379,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8268?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0f24625`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8268 +/- ##; ================================================; Coverage ? 86.097% ; Complexity ? 35609 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 143884 ; Misses ? 16800 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1487572354:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1487572354,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8269?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@17afee4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8269 +/- ##; ================================================; Coverage ? 42.749% ; Complexity ? 23842 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 71442 ; Misses ? 90265 ; Partials ? 5412 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8269#issuecomment-1489046738:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8269#issuecomment-1489046738,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8274?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@2dd76f7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 7f8aebc differs from pull request most recent head f968453. Consider uploading reports for the commit f968453 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8274 +/- ##; ================================================; Coverage ? 85.874% ; Complexity ? 35522 ; ================================================; Files ? 2194 ; Lines ? 167046 ; Branches ? 18005 ; ================================================; Hits ? 143449 ; Misses ? 17216 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8274#issuecomment-1489429332:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8274#issuecomment-1489429332,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8278?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8217073`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8278 +/- ##; ================================================; Coverage ? 85.882% ; Complexity ? 35522 ; ================================================; Files ? 2194 ; Lines ? 167029 ; Branches ? 18005 ; ================================================; Hits ? 143448 ; Misses ? 17200 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8278#issuecomment-1496591221:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8278#issuecomment-1496591221,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8281?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@23a64a7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8281 +/- ##; ================================================; Coverage ? 85.845% ; Complexity ? 35511 ; ================================================; Files ? 2194 ; Lines ? 167029 ; Branches ? 18005 ; ================================================; Hits ? 143386 ; Misses ? 17254 ; Partials ? 6389 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8281#issuecomment-1501927327:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8281#issuecomment-1501927327,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8284?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e2b2e5c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8284 +/- ##; ================================================; Coverage ? 86.098% ; Complexity ? 35610 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 143886 ; Misses ? 16799 ; Partials ? 6434 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8284#issuecomment-1504030123:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8284#issuecomment-1504030123,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8286?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@ce3a5c7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8286 +/- ##; ================================================; Coverage ? 86.096% ; Complexity ? 35609 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 143882 ; Misses ? 16802 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8286#issuecomment-1505472967:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8286#issuecomment-1505472967,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8289?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@4ab6bde`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8289 +/- ##; ================================================; Coverage ? 86.096% ; Complexity ? 35605 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18007 ; ================================================; Hits ? 143882 ; Misses ? 16802 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8289#issuecomment-1507734807:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8289#issuecomment-1507734807,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8298?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@a2ffeb8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8298 +/- ##; ================================================; Coverage ? 86.096% ; Complexity ? 35609 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 143882 ; Misses ? 16802 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8298#issuecomment-1523456501:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8298#issuecomment-1523456501,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8300?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@daeae13`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8300 +/- ##; ================================================; Coverage ? 84.201% ; Complexity ? 34893 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18007 ; ================================================; Hits ? 140716 ; Misses ? 20123 ; Partials ? 6280 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8300#issuecomment-1527978078:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8300#issuecomment-1527978078,2,['error'],['error-reference']
Availability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8303?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@daeae13`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8303 +/- ##; ================================================; Coverage ? 44.523% ; Complexity ? 24872 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 74407 ; Misses ? 87356 ; Partials ? 5356 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8303#issuecomment-1529946227:346,error,error-reference,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8303#issuecomment-1529946227,2,['error'],['error-reference']
Availability,"### Affected class(es); All test classes in GATK (and downstream projects) extending `BaseTest`. ### Affected version(s); - [x] Latest public release version; - [x] Latest master branch. ### Description ; The GATK toolkit assumes `US` locale (set in a `Main` static method), which in turn produces all the test files using the `US` locale; if the test suite is run in a different locale, it might fail unexpectedly. For example, if the locale has a comma-separated decimals instead of dot-separated, comparing the expected file output with `US` locale against the generated by the tests fail. . #### Expected behavior; `BaseTest` should set the locale in a `@BeforeSuite` method (or static method) to set the assumptions of the toolkit to all tests (also for downstream toolkits). #### Actual behavior; `BaseTest` picks default locale.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5012:54,down,downstream,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5012,2,['down'],['downstream']
Availability,"### Affected tool(s) or class(es). VariantFiltration. ### Affected version(s). Master 2021-01 onwards. ### Description . VariantFiltration's --invalidate-previous-filters prevent any output variant to be marked as PASS even if it passes the filters that are passed to that run of the filtration tool. What I would expect is that variants that pass the current set of filters will be marked as PASS regarless whether they were filtered or not filtered (PASS, or '.') in the input. . Perhaps the case is that this option is not meant.to be used with current/new filters being specified as to provide a way to revert previous filtration, but in that case it should fail if new filters are specified. #### Steps to reproduce. Just try it out with a VCF with some filters already applied and run VF with additional filters that will not result in all variants to be filtered. . You will see that no output variant is set To PASS but rather are kept as unknown '.' . #### Expected behavior. Either it does fail if a new filter is applied in the same tool run or passing variants filter are setlp to Pw. #### Actual behavior. Described above, no error message and no pass variants only ""."" ones.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7608:1139,error,error,1139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7608,1,['error'],['error']
Availability,"### Affected tool(s) or class(es); GenotypeGVCFs is reporting:; ```. [TileDB::ArrayIterator] Error: Cannot advance iterator; Buffer overflow.; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : VariantArrayCellIterator increment failed; TileDB error message : [TileDB::ArrayIterator] Error: Cannot advance iterator; Buffer overflow; ```. ### Affected version(s); ```; Using GATK jar /home/xuql/miniconda3/share/gatk4-4.2.6.1-1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/xuql/miniconda3/share/gatk4-4.2.6.1-1/gatk-package-4.2.6.1-local.jar --version; The Genome Analysis Toolkit (GATK) v4.2.6.1; HTSJDK Version: 2.24.1; Picard Version: 2.27.1. ```. ### Description ; Hi, I developed AnchorWave to call long indels(could be a couple of Mb). We are trying to connect the AnchorWave variant calling result with GATK to generate VCF files. We generated whole genome alignments for 26 maize accession via AnchorWave. And we wrote out own code to generate GVCF files from the outputs of AnchorWave. Those GVCF files works well with GATK GenomicsDBImport. While, the `GenotypeGVCFs` function is reporting `Buffer overflow` errors and could generate the complete VCF files. . Here is the command we used:. ```; gatk --java-options ""-Xmx100g"" GenotypeGVCFs -R Zm-B73-REFERENCE-NAM-5.0.fa -stand-call-conf 0 -ploidy 1 -V gendb:///home/xuql/NAM_anchorwave_song/NAM_out_gatk9 -O gatk9.vcf.gz --cloud-prefetch-buffer 10000 --cloud-index-prefetch-buffer 10000 --genomicsdb-max-alternate-alleles 110 --max-alternate-alleles 100 --tmp-dir /home/xuql/NAM_anchorwave_song/temp9 --gcs-max-retries 1000; ```; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7976:93,Error,Error,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7976,4,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6750:312,error,error,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750,2,['error'],['error']
Availability,"### Affected tool(s) or class(es); docker version GATK:4.1.1.0. ### Affected version(s); ; latest release. ### Description ; Funcotator shuts down part way through job. A configuration problem @ google?; [funcotator_crash.txt](https://github.com/broadinstitute/gatk/files/3652568/funcotator_crash.txt). RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: www.googleapis.com; ; ### Description . 04:13:19.667 INFO ProgressMeter - 15:85753672 1834.2 199000 108.5; 04:17:42.593 INFO VcfFuncotationFactory - dbSNP 9606_b150 cache hits/total: 0/0; 04:17:42.593 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/1402; 04:17:42.593 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/162233; 04:17:42.665 INFO Funcotator - Shutting down engine; [September 25, 2019 4:17:42 AM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 1,845.78 minutes.; Runtime.totalMemory()=4523032576; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: www.googleapis.com; at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:318); at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182:142,down,down,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182,2,['down'],['down']
Availability,"### Affected tool(s) or class(es); gatk DownsampleSam. ### Affected version(s); GATK v4.3.0.0. ### Description ; Input cram file (gs://broad-public-datasets/CHM1_CHM13_WGS2/CHM1_CHM13_WGS2.cram) ; has NM tags, but the downsampled output file no longer has them. My command-line is ; ```; gatk DownsampleSam REFERENCE_SEQUENCE=/hg38.fa I=CHM1_CHM13_WGS2.cram P=0.5 CREATE_INDEX=true O=CHM1_CHM13_WGS2.downsampled.bam ; ```. Some downstream tools require NM tags, so I have to run . `samtools calmd CHM1_CHM13_WGS2.downsampled.bam /hg38.fa`. to re-add it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8558:40,Down,DownsampleSam,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8558,6,"['Down', 'down']","['DownsampleSam', 'downsampled', 'downstream']"
Availability,"### Affected tool(s) or class(es); gatk PrintReads. ### Affected version(s); v4.1.4.1. ### Description ; Command like; ```; java -Xms2g -Xmx3g -jar gatk.jar PrintReads --gcs-project-for-requester-pays my-project -R hg38.fa -I gs://some-bucket/data.cram -L loci.interval_list -L UNMAPPED -O data.loci.bam; ```; crashes near the end with this error:; ```. 05:03:04.672 INFO PrintReads - Shutting down engine; [March 1, 2020 5:03:04 AM EST] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 18.22 minutes.; Runtime.totalMemory()=3094872064; htsjdk.samtools.util.RuntimeEOFException: java.nio.channels.ClosedChannelException; 	at htsjdk.samtools.CRAMFileReader.queryUnmapped(CRAMFileReader.java:413); 	at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.queryUnmapped(SamReader.java:543); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:129); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:111); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:27); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:13); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6475:341,error,error,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6475,2,"['down', 'error']","['down', 'error']"
Availability,"### Affected tool(s); IntervalListTools. ### Affected version(s); GATK 4.0.3.0. ### Description; Ive been getting the following error when executing IntervalListTools in gatk4 . `SECOND_LIST must be null when ACTION is CONCAT, found []. Please put all the inputs in INPUT for this ACTION.`. I can replicate the error when manually executing the command on gatk4 docker but the same command works fine on gitc using picard. COMMANDS; latest gatk4 docker; `/gatk/gatk IntervalListTools --SCATTER_COUNT 6 --SUBDIVISION_MODE BALANCING_WITHOUT_INTERVAL_SUBDIVISION_WITH_OVERFLOW --UNIQUE true --SORT true --INPUT /gatk/interval/Homo_sapiens_assembly19_1000genomes_decoy.whole_genome.interval_list`; gitc 2.3.3-1513176735; `java -Xms1g -jar /usr/gitc/picard.jar IntervalListTools SCATTER_COUNT=6 SUBDIVISION_MODE=BALANCING_WITHOUT_INTERVAL_SUBDIVISION_WITH_OVERFLOW UNIQUE=true SORT=true INPUT=/gatk/interval/Homo_sapiens_assembly19_1000genomes_decoy.whole_genome.interval_list`. INPUT:; gs://broad-references/Homo_sapiens_assembly19_1000genomes_decoy/Homo_sapiens_assembly19_1000genomes_decoy.whole_genome.interval_list",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4619:129,error,error,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4619,2,['error'],['error']
Availability,"### Affected tool; - CollectReadCounts. ### Affected version; - The Genome Analysis Toolkit (GATK) v4.2.3.0; - HTSJDK Version: 2.24.1. Downloaded from https://github.com/broadinstitute/gatk/releases/download/4.2.3.0/gatk-4.2.3.0.zip. ### Description ; When calling `CollectReadCounts` tool with symlink as input BAM-file, `java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE` occurs. Symlinks seem to work fine with Picard BAM-tools as well as `HaplotypeCaller` and `Mutect2`. Probably HTSJDK level issue, but popped up exception is kind of misleading. #### Stacktrace:; ```; java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE; at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:863); at htsjdk.samtools.MemoryMappedFileBuffer.<init>(MemoryMappedFileBuffer.java:23); at htsjdk.samtools.AbstractBAMFileIndex.<init>(AbstractBAMFileIndex.java:64); at htsjdk.samtools.CachingBAMFileIndex.<init>(CachingBAMFileIndex.java:56); at htsjdk.samtools.BAMFileReader.getIndex(BAMFileReader.java:418); at htsjdk.samtools.BAMFileReader.createIndexIterator(BAMFileReader.java:931); at htsjdk.samtools.BAMFileReader.query(BAMFileReader.java:612); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.query(SamReader.java:550); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.queryOverlapping(SamReader.java:417); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:130); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.<init>(SamReaderQueryingIterator.java:69); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:412); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.iterator(ReadsPathDataSource.java:336); at java.lang.Iterable.spliterator(Iterable.java:101); at org.broadinstitute.hellbender.utils.Utils.stream(Utils.java:1176); at org.broadinstitute.hellbender.engine.GATKTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7579:135,Down,Downloaded,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7579,2,"['Down', 'down']","['Downloaded', 'download']"
Availability,"### Background: jar dependency hell. Getting GATK to compile with the gcloud-java-nio dependency is already a little bit of a struggle because of conflicting versions of the com.google.protobuf class (see #2013). Running it on Dataproc results in a version conflict somewhere else, probably linked to the jars that are automatically included on Dataproc. Getting gcloud-java-nio to work on vanilla Spark runs into the exact same category of problems (dependency conflicts), see eg. [this question on StackOverflow](http://stackoverflow.com/questions/38536004/spark-java-noclassdeffounderror-when-adding-dependency/38575957#38575957). The root of the problem is that both Hadoop and GCloud-Java rely on the same core Google libraries (Guava, Protobuf), but they use different versions that are incompatible. Java is not currently able to have two different versions of the same library at once, so instead you end up forcing one version of the other. Neither version appears to work for all of our dependencies, so we have a problem.; ### Workaround. Barring improvements in Java, our only way forward may be to use a shaded ""fat jar"" version of gcloud-java-nio that (i) includes all of its dependencies in a single jar and (ii) renames the shared dependencies so they won't conflict with what eg. Hadoop brings in. Luckily, gcloud-java-nio already builds such a jar by default. However that jar is not published on Maven Central. So the solution is to download the gcloud-java-nio source code, compile it ourselves (without any modification), and use the resulting jar (target/gcloud-java-nio-0.2.7-SNAPSHOT-shaded.jar). . This solution works for both vanilla Spark and GATK. I suspect it would be acceptable for us to directly include that jar in our source tree so that our own users wouldn't have to take any special steps to use GATK: just compile and run, as usual. Let's discuss. CC: @droazen @lbergelson",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2044:1452,down,download,1452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2044,1,['down'],['download']
Availability,"### Bug Report. Hi, after installing the conda environment and running `conda activate gatk` without errors, I seem to still have a problem importing the gcnvkernel module. Is there a way I can install it through pip or what is something I may have done wrong? I already went over the README and standard documentation, and don't think I missed a step. ### Affected tool(s) or class(es); gvnvkernel, other expected modules. #### Expected behavior; Generate output file from my VCF. #### Actual behavior; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /home/gamer456148/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar GermlineCNVCaller --input var.vcf --run-mode CASE --contig-ploidy-calls X/prefix-calls --output-prefix regular.vcf --output testfile.vcf; 21:21:12.277 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/gamer456148/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 23, 2020 9:21:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 21:21:12.543 INFO GermlineCNVCaller - ------------------------------------------------------------; 21:21:12.544 INFO GermlineCNVCaller - The Genome Analysis Toolkit (GATK) v4.1.4.1; 21:21:12.544 INFO GermlineCNVCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:21:12.544 INFO GermlineCNVCaller - Executing as gamer456148@gamer456148-Inspiron-15-7579 on Linux v4.15.0-88-generic amd64; 21:21:12.544 INFO GermlineCNVCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_191-b12; 21:21:12.544 INFO GermlineCNVCaller - Start Date/Time: February 23, 2020 9:21:12 PM EST; 21:21:12.544 INFO GermlineCNVCaller - -------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6467:101,error,errors,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6467,1,['error'],['errors']
Availability,"### Bug Report; When running the StructuralVariationDiscoveryPipelineSpark, I am getting the following error:. ```; java.lang.UnsatisfiedLinkError:`/tmp/jp102/libfml.833188020007107749.jnilib: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /tmp/jp102/libfml.833188020007107749.jnilib); at java.lang.ClassLoader$NativeLibrary.load(Native Method); at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824); at java.lang.Runtime.load0(Runtime.java:809); at java.lang.System.load(System.java:1086); at org.broadinstitute.hellbender.utils.fermi.FermiLiteAssembler.loadNativeLibrary(FermiLiteAssembler.java:157); at org.broadinstitute.hellbender.utils.fermi.FermiLiteAssembler.<init>(FermiLiteAssembler.java:24); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FermiLiteAssemblyHandler.apply(FermiLiteAssemblyHandler.java:72); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FermiLiteAssemblyHandler.apply(FermiLiteAssemblyHandler.java:23); at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.sp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5145:103,error,error,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5145,1,['error'],['error']
Availability,"### Goal; Our team try to explore the usage of GATK Spark tool for our internal WES and WGS data. ## Bug Report. ### Affected tool(s) or class(es); BwaSpark and ReadsPipelineSpark. ### Affected version(s); - [ X ] Latest public release version [gatk 4.0.11.0]. ### Description ; For both tools, we encountered an issue when the driver shutdown the command as the screenshot. However, for the bwaspark, the alignment ratio seems to be unaffected by the error, but the lines number of the VCF file from ReadsPipelineSpark varies randomly, and quite different from the non-spark version of GATK 4.0.5.2. #### Steps to reproduce; Before running the tool, we generated the image index for whole genome by using the fasta file from GATK official ftp site, and uploaded the reference file to Hadoop HDFS. ``` bash; gatk-4.0.11.0/gatk BwaMemIndexImageCreator -I Homo_sapiens_assembly38.fasta -O Homo_sapiens_assembly38.fasta.img; ```. and then, we preprocess our pair end fastq files into unaligned ubam file as, ; ``` bash; java -jar picard.jar FastqToSam \; F1=R1.fastq.gz; F2=R2.fastq.gz; O=unaligned_reads.bam \; SM=sample001 \; PL=illumina \; RG=rg001; ```. For BwaSpark, we used,; ``` {bash}; ../gatk-4.0.11.0/gatk --java-options ""-Dgatk.spark.debug=true -XX:+PrintGCDetails"" BwaSpark -I hdfs://ns/user/root/test/unaligned_reads.bam -O hdfs://ns/user/root/test/test3.bam -R hdfs://ns/user/root/Homo_sapiens_assembly38.fasta --spark-runner SPARK --spark-master spark://master:7077 -- --num-executors 4 --driver-memory 4g --executor-cores 10 --executor-memory 20g; ```. For ReadsPipelineSpark, we used, ; ``` {bash}; time_gatk ""ReadsPipelineSpark --tmp-dir /tmp --align true -I hdfs://ns/user/root/test/unaligned_reads.bam -O hdfs://ns/user/root/test/test10.vcf -R hdfs://ns/user/root/Homo_sapiens_assembly38.fasta --known-sites hdfs://ns/user/root/Homo_sapiens_assembly38.dbsnp138.vcf -pairHMM AVX_LOGLESS_CACHING --max-reads-per-alignment-start 50"" 4 44 88g 12g; ```. #### Expected behavior; Both tool s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5481:452,error,error,452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5481,1,['error'],['error']
Availability,"### Instructions. ## Bug Report. ### Affected tool(s) or class(es); FilterMutectCalls. ### Affected version(s); - [ ] Latest public release version [4.1.4.1]. ### Description ; Header is missing description for ""##FILTER=<ID=PASS"" , it causes inaccurate parsing of VCF . #### Steps to reproduce; Run the FilterMutectCalls on any mutect2 VCF available . Thanks, ; Nick",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6426:341,avail,available,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6426,1,['avail'],['available']
Availability,"### Instructions. ## Bug Report; ### Affected tool(s) or class(es); - tools: HaplotypeCaller perhaps Mutec. ; - classes: AlleleLikelihoods. ### Affected version(s); - [ X] Latest public release version [version?]; - [ X] Latest master branch as of [date of test?]. ### Description ; Right before calling annotators HC engine adds filtered reads as additional evidence in the AlleleLikelihoods instance that is passed down to the annotators. The code requests the new evidence to have 0.0 likelihoods so label them as uninformative. However due to an error in how the lk arrays are ""extended"" inside the AlleleLikelihoods these reads inherit past reads (removed) zombie likelihoods instead. Fix is easy. as simple as remove this enclosing ```if``` in AlleleLikelihoods, and simply executed its body; always:. ```; line 793:; if (initialLikelihood != 0.0) // the default array new value.; {; for (int a = 0; a < alleleCount; a++) {; Arrays.fill(sampleValues[a], sampleEvidenceCount, newSampleEvidenceCount, initialLikelihood);; }; }; ```. #### Steps to reproduce. Debug and active region with filtered reads. . #### Expected behavior. Those reads won't contribute to AD or DP. #### Actual behavior. They do contribute, at random, to those count annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7153:417,down,down,417,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7153,2,"['down', 'error']","['down', 'error']"
Availability,"### Instructions. Dear GATK team,. I am encountering an error when using the mutect2 function in ""gatk-4.2.6.1"". Whenever I enable the ""--disable-tool-default-read-filters"" option, I receive a java.lang.ArrayIndexOutOfBoundsException error. Since I need to call SNVs for RNA-seq data, I first split the bam file by chromosome, and then perform markduplicate and splitNcigar in two steps. I found that when I use the bam file obtained after using the splitNcigar function to run mutect2, the same error still occurs, even if I don't disable the -read-filters. Therefore, I suspect that the error may be introduced by splitNcigar. Thus, I tried running mutect2 directly on the bam file after markduplicate. If the --disable-tool-default-read-filters option is not set, the command runs successfully. However, once it is set, the same error occurs. ----. ## Bug Report; [February 28, 2023 10:46:30 AM CST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2394947584; java.lang.ArrayIndexOutOfBoundsException; at java.lang.System.arraycopy(Native Method); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHardClipBases(ClippingOp.java:216); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:69); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:142); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipLowQualEnds(ReadClipper.java:251); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipLowQualEnds(ReadClipper.java:255); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipLowQualEnds(ReadClipper.java:263); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:132); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:270); at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8224:56,error,error,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8224,5,['error'],['error']
Availability,"### Instructions. I'm running on :; gatk 4.3.0.0. ; 88 cpu ; 128G mem ; 538 samples. Chrom 11-22 don't have problems, but 1-11 don't work.; What should I do?; thanks. ```; java -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/solivehong/miniconda3/envs/bio_base/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar GenotypeGVCFs -R /data/reference/update_gatk_v0/Homo_sapiens_assembly38.fasta -V gendb://Genomicsdb.2 -O /storage/project/collaborators/UH_Burdentest/1.running/genotypeGvcf/UH_Burdentest2222.vcf --tmp-dir /storage/GenomesDbimport/Agilent_WES/tmp -L chr2 -G StandardAnnotation --only-output-calls-starting-in-intervals --use-new-qual-calculator -D /data/reference/update_gatk_v0//Homo_sapiens_assembly38.dbsnp138.vcf; 20:09:21.335 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 20:09:21.383 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/solivehong/miniconda3/envs/bio_base/share/gatk4-4.3.0.0-0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 20:09:21.521 INFO GenotypeGVCFs - ------------------------------------------------------------; 20:09:21.521 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.3.0.0; 20:09:21.521 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 20:09:21.521 INFO GenotypeGVCFs - Executing as solivehong@solivehong on Linux v5.10.0-25-amd64 amd64; 20:09:21.521 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v11.0.13+7-b1751.21; 20:09:21.522 INFO GenotypeGVCFs - Start Date/Time: September 23, 2023 at 8:09:21 PM CST; 20:09:21.522 INFO GenotypeGVCFs - ------------------------------------------------------------; 20:09:21.522 INFO GenotypeGVCFs - ----------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8527:941,Redundant,Redundant,941,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8527,1,['Redundant'],['Redundant']
Availability,"### Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Feature request. ### Tool(s) or class(es) involved; `SplitIntervals`. ### Description; Just tried changes from #7157 and they work perfectly. However:. - `SplitIntervals` starts the scatter files counting from 0. Would it be possible to allow the user to specify the starting value (e.g. 1 instead of 0)?; - Also noted that if I have a `bed` file with 3 intervals and ask `SplitIntervals` to scatter it into 6 files, it just creates 3 files. I think it would be nice if `SplitIntervals` would check it and complain if more scatters were requested than intervals are available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7548:1737,avail,available,1737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7548,1,['avail'],['available']
Availability,"### Instructions. gatk version 4.4.0.0. When I run gatk GenotypeGVCFs, it shows this error; ; A USER ERROR has occurred: Bad input: Presence of '-RAW_MQ' annotation is detected. This GATK version expects key RAW_MQandDP with a tuple of sum of squared MQ values and total reads over variant genotypes as the value. This could indicate that the provided input was produced with an older version of GATK. Use the argument '--allow-old-rms-mapping-quality-annotation-data' to override and attempt the deprecated MQ calculation. There may be differences in how newer GATK versions calculate DP and MQ that may result in worse MQ results. Use at your own risk. ----. ##; I use gatk 4.2 and gatk 4.4 to run gatk HaplotypeCaller,respectively. And then use gatk CombineGVCFs (4.4) to combine all ""gvcf.gz"" files. . Please tell me how to solve the above problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8574:85,error,error,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8574,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"### Instructions; I use PathSeqPipelineSpark to analyze 10x Visium spatial transcribed data.; I did not download the data from the database on the GATK official website. But I prepared the database according to the tutorial [https://gatk.broadinstitute.org/hc/en-us/articles/360035889911--How-to-Run-the-Pathseq-pipeline] by myself.; The analysis has no results, and I don't know the reason for the lack of results. ## software / environment / log file informations; Using GATK jar /mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx750g -jar /mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar PathSeqPipelineSpark --input CRC_16/outs/possorted_genome_bam.bam --filter-bwa-image hsa_GRCh38/genome.fa.img --kmer-file hsa_GRCh38/genome.hss --min-clipped-read-length 60 --microbe-dict 16SrRNA/bacteria.16SrRNA.dict --microbe-bwa-image 16SrRNA/bacteria.16SrRNA.fa.img --taxonomy-file 16SrRNA/16SrRNA.db --output pathseq/CRC_16.pathseq.complete.bam --scores-output pathseq/CRC_16.pathseq.complete.csv --is-host-aligned false --filter-duplicates false --min-score-identity .7 --tmp-dir pathseq/tmp; 13:19:23.776 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/icfs/work/singlecelldevelopment/software/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:19:28.982 INFO PathSeqPipelineSpark - ------------------------------------------------------------; 13:19:28.982 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.3.0.0; 13:19:28.982 INFO PathSeqPipelineSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:19:28.983 INFO PathSeqPipelineSpark - Executing as singlecellproject@d01.capitalbiotech.local on Linux v3.10.0-514.16.1.el7.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8339:104,down,download,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8339,1,['down'],['download']
Availability,"### Interestingly, I can in fact create a PoN from PCOV counts for my refined cohort (bifem). ; I almost did not run this thinking I would encounter the same error as the bad cohort (1kgmix). I had some inkling that perhaps results may be different (see my question below) and I wanted to square off my matrix of results. So I ran this just now. That I created a PoN for the bad cohort first on Friday is solely due to it finishing its counting well before the bifem cohort. One question I had on Friday was how the zero counts were counted. If the various samples have zero counts for different targets, or per target only some samples had zero counts and samples varied for each target, then does the QC look across the 2-D array for zero count patterns or just per 1-D dataset?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310877132:158,error,error,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310877132,1,['error'],['error']
Availability,"### Summary ; A user wrote in to the forum regarding running FilterSamReads through GATK and the output bam file has formatting issues. After they sent in a bug report, I found that the exit code is getting written to the bam file, causing this issue. . This request was created from a contribution made by rcorbett on February 03, 2021 23:47 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076905711-filterSamReads-stdout-format-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076905711-filterSamReads-stdout-format-error). #### GATK Info; FilterSamReads 4.1.9.0 and 4.0.10.0; Command to stdout:; `gatk FilterSamReads -I subsampled.bam -O /dev/stdout --READ_LIST_FILE read_names.txt --FILTER excludeReadList --VALIDATION_STRINGENCY SILENT --QUIET > test_stdout.bam`; Log:; ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar FilterSamReads -I subsampled.bam -O /dev/stdout --READ_LIST_FILE read_names.txt --FILTER excludeReadList --VALIDATION_STRINGENCY SILENT --QUIET; 20:54:45.405 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; INFO	2021-02-12 20:54:45	FilterSamReads	Filtering [presorted=true] subsampled.bam -> OUTPUT=stdout [sortorder=coordinate]; INFO	2021-02-12 20:54:45	SAMFileWriterFactory	Unknown file extension, assuming BAM format when writing file: file:///dev/stdout; INFO	2021-02-12 20:54:45	FilterSamReads	6 SAMRecords written to stdout. ```; Check file:; `gunzip -c -d -f test_stdout.bam | head -n 5`; ```; Tool returned:; 0. ?[[lW?m?$?^?q???k????zg?x}?s???mE??r#U???/Qm'dkUM???????zCBB?!*?V*?#; <Q!QU?; ```; Bam file using -0; `gunzip -c -d -f test_outbam.bam | head -n 5`; ```; BAM?2@",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7080:454,error,error,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7080,2,['error'],['error']
Availability,"### Summary; A user running Mutect2 in GATK 4.1.9.0 was inputting an interval list using the -XL option and received an error message that did not illuminate the problem. Their intervals file was made using BedToIntervalList and was a picard-style interval list. The final solution they found was the [correct extension](https://gatk.broadinstitute.org/hc/en-us/articles/360035531852-Intervals-and-interval-lists), .interval_list. ### Example 1; Using .intervallist extension, the error message said the interval was not valid; `A USER ERROR has occurred: Badly formed genome unclippedLoc: Query interval ""combinedblacklist.intervallist"" is not valid for this input`. ### Example 2; Using .intervals extension, the error message said the interval list was badly formed and not valid; `A USER ERROR has occurred: Badly formed genome unclippedLoc: Query interval ""@HD VN:1.6 SO:coordinate"" is not valid for this input.`. <br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/113538'>Zendesk ticket #113538</a>)<br>gz#113538</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7095:120,error,error,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7095,5,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"### Summary; In the AnalyzeCovariates documentation, there is mention of the previous GATK3 method to obtain recalibration tables before and after BQSR. There does not seem to be that functionality in GATK4. If there is, it is not well documented. ### User Request. This request was created from a contribution made by ISmolicz on February 17, 2021 12:03 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360077098031-Error-when-trying-to-generate-the-second-recalibration-table-for-AnalyzeCovariates](https://gatk.broadinstitute.org/hc/en-us/community/posts/360077098031-Error-when-trying-to-generate-the-second-recalibration-table-for-AnalyzeCovariates). \--. Dear GATK Team,. In previous GATK4 versions, I understand there was a -bqsr option to use with BaseRecalibrator so that a second recalibration table could be generated and then submitted to AnalyzeCovariates. However, it appears this option is longer available as I receive the following error with GATK version 4.1.9.0:. A USER ERROR has occurred: -bqsr is not a recognized option. The command used:. gatk BaseRecalibrator \\ ; \--input input.bam \\ ; \-R ucsc.hg19.fasta \\ ; \--known-sites dbsnp\_138.hg19.vcf \\ ; \--known-sites Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf \\ ; \--known-sites 1000G\_phase1.indels.hg19.sites.vcf \\ ; \-bqsr sample.recal\_data.grp \\ ; \--output sample.recal\_data\_2.grp \\ ; \--tmp-dir $TMPDIR. Please could you confirm the current method used to generate the second recalibration table with GATK 4.1.9.0?. Unfortunately I could not identify the current method, including in the \[Base Quality Score Recalibration (BQSR)\](/hc/en-us/articles/360035890531-Base-Quality-Score-Recalibration-BQSR- ""Base Quality Score Recalibration (BQSR)"")documentation. Thank you for your time and help.<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/113534'>Zendesk ticket #113534</a>)<br>gz#113534</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7096:437,Error,Error-when-trying-to-generate-the-second-recalibration-table-for-AnalyzeCovariates,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7096,5,"['ERROR', 'Error', 'avail', 'error']","['ERROR', 'Error-when-trying-to-generate-the-second-recalibration-table-for-AnalyzeCovariates', 'available', 'error']"
Availability,"### bug reports. hi guys :; ; Hi all, when I run gatk (version: 4.5.0.0) CombineGVCFs to combine 240 8 ploidy samples gvcf, it reports the error as below; ![image](https://github.com/broadinstitute/gatk/assets/48479509/4b2e42bb-f8f1-487b-9c06-ce513d94aef7). how call i solve it? replace CombineGVCFs with GenomicsDBimport ?; I think even though I got the merged gvcf file  this error is also will be reported when I run GenotypeGVCF?; I look forward to your suggestions; have a good day!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8842:139,error,error,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8842,2,['error'],['error']
Availability,"############################################ | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpack_file; flatten=not filename.endswith('.whl'); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 482, in unzip_file; zipfp = open(filename, 'rb'); FileNotFoundError: [Errno 2] Datei oder Verzeichnis nicht gefunden: '/BioinfSoftware/build/gatkPythonPackageArchive.zip'. CondaValueError: pip returned an error; ```. Thanks also to all the other ones for their good hints for using germlineCNV caller.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:2741,down,download,2741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460,3,"['down', 'error']","['download', 'error']"
Availability,"#3925 introduced a conda dependency on libgcc-ng=7.2.0, which works in Travis since its available or Ubuntu, but fails to resolve for osx. Its not clear to me what the options are, but we need to resolve this one way or another.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4074:88,avail,available,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4074,1,['avail'],['available']
Availability,"#6055 Bug Report. ### Affected tool(s) or class(es); PostprocessGermlineCNVCalls. ### Affected version(s); 4.1.8.1. ### Description ; Process of calling copy number segments and consolidate sample results with PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order.""; I tried to detect germline copy number in cohort mode on 73 wgs samples by [this](https://gatk.broadinstitute.org/hc/en-us/articles/360035531152--How-to-Call-common-and-rare-germline-copy-number-variants) tutorial.To do this, i split genome into 10 parts.At the last stage PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order"", when i use all parts.; [scattered.1-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457466/scattered.1-10.interval_list.txt); [scattered.2-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457467/scattered.2-10.interval_list.txt); [scattered.3-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457468/scattered.3-10.interval_list.txt); [scattered.4-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457469/scattered.4-10.interval_list.txt); [hg19.dict.txt](https://github.com/broadinstitute/gatk/files/5457474/hg19.dict.txt). But if you use the first three, the program works out. - ; `12:43:27.310 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:43:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:43:27.439 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:43:27.439 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:43:27.439 INFO PostprocessGermlineCNVCalls - For supp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924:250,error,error,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924,2,['error'],['error']
Availability,"#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change backticks to single quotes in several error messages - causing shell to attempt to execute. (#7995); - VS-598 - Minor update to AoU Documentation. (#7994); - Allow for incremental addition of data to alt_allele [VS-52] (#7993); - Minor AoU Documentation Update (#7999); - Batch population of alt_allele table from vet_ tables [VS-265] (#7998); - Change drop_state to NONE for Ingest/Extract [VS-607] (#8000); - python -> python3 (#8001); - Generate Hail import/export script [VS-605] (#8002); - clearer error when values are missing (#7939); - Ah [VS-565] output intervals and sample list (#8010); - make CreateAltAlleleTable task volatile (#8011); - Restore withdrawn [VS-581] (#8006); - Km gvs add storage cost and cleanup doc (#8012); - Updating documentation to reflect the changed outputs [VS-565] (#8014); - File of callset samples -> samples marked as 'withdrawn' in GVS [VS-436] (#8009); - fix quota guide",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:27342,error,error,27342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['error'],['error']
Availability,"$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **20/03/05 09:28:58 ERROR TaskSetManager: Task 34 in stage 0.0 failed 1 times; aborting job** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Cancelling stage 0** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 30.0 in stage 0.0 (TID 30), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 9.0 in stage 0.0 (TID 9), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 1.0 in stage 0.0 (TID 1), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 31.0 in stage 0.0 (TID 31), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 2.0 in stage 0.0 (TID 2), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:32678,ERROR,ERROR,32678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['ERROR'],['ERROR']
Availability,"$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 16/11/16 23:25:11 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-0,5,main]; java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:13222,ERROR,ERROR,13222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['ERROR'],['ERROR']
Availability,"%|5 | 5/100 [00:01<00:25, 3.72it/s]; 15:10:06.844 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0013 +/- 0.0014: 6%|6 | 6/100 [00:01<00:25, 3.72it/s]; 15:10:07.113 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0014 +/- 0.0019: 7%|7 | 7/100 [00:01<00:24, 3.72it/s]; 15:10:07.381 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0011 +/- 0.0011: 8%|8 | 8/100 [00:02<00:24, 3.72it/s]; 15:10:07.649 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0008 +/- 0.0009: 10%|# | 10/100 [00:02<00:24, 3.72it/s]; 15:10:08.193 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0006: 11%|#1 | 11/100 [00:02<00:24, 3.70it/s]; 15:10:08.463 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0005 +/- 0.0007: 12%|#2 | 12/100 [00:03<00:23, 3.70it/s]; 15:10:08.732 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0007: 13%|#3 | 13/100 [00:03<00:23, 3.70it/s]; 15:10:09.001 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0004 +/- 0.0005: 13%|#3 | 13/100 [00:03<00:25, 3.45it/s]; 15:10:09.002 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1): 0%| | 0/1 [00:00<?, ?it/s]; 15:10:09.003 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1) ploidy update size: 0.200122: 100%|##########| 1/1 [00:00<00:00, 1605.78it/s]; 15:10:09.004 INFO gcnvkernel.tasks.inference_task_base - (denoising) starting...: 0%| | 0/1000 [00:00<?, ?it/s]; 15:10:09.105 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 2) ELBO: -419.253 +/- 160.674, SNR: 8.0, T: 1.79: 4%|3 | 37/1000 [00:00<00:02, 365.67it/s]; 15:10:09.207 INFO gcnvkernel.tasks.inference_task_base - (",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:12606,error,error,12606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['error'],['error']
Availability,"'t have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0h8AF8wYzkbHSmAu4-8n5TE8GtOUks5tN6MfgaJpZM4RoUzm>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:1525,avail,available,1525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725,2,['avail'],['available']
Availability,"(1) I am studying GMS mappability scores. To the best of my knowledge, it is the only such analysis that considers both paired-end reads and base calling error rate characteristic of Illumina machines. We could feed the GMS score as a feature file to the coverage collector tool for filtering. (2) I am also working on the ""optimal strategy"" for different SV types. (3) @samuelklee, do we get the same wavy pattern in other samples in the same region? in other words, it is sample-specific or region-specific?. (4) While fragment-based GC correction is difficult (and probably unnecessary) to perform without keeping a full index of aligned reads (like GS), it might be worthwhile to at least collect per-sample per-interval fragment-based average GC content (perhaps along with other summaries such as average fragment length, MQ, etc). It is easy to show that that the difference between full fragment-based GC correction and correction only using the observed average fragment GC content for the pile-up is of the order of the curvature of the GC curve, which is presumably small. We could collect these statistics either on-the-go during coverage collection, or from the sparse counts table as you suggested before (most sensible approach, once we figure out a way to represent sparse tensors).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372413152:154,error,error,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372413152,1,['error'],['error']
Availability,"(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); ```. Now using the latest jar `gatk-4.beta.5` in the same command: . ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam; ```. I see that the run goes past the problem region. ; ```; ...; 10:56:39.570 INFO ProgressMeter - chr1:179846959 2.2 9271000 4228249.1; 10:56:49.572 INFO ProgressMeter - chr1:198702508 2.4 9889000 4191438.3; 10:56:59.631 INFO ProgressMeter - chr1:219611298 2.5 10821000 4282152.8; 10:57:09.660 INFO ProgressMeter - chr1:242292327 2.7 11691000 4339428.9; 10:57:19.665 INFO ProgressMeter - chr2:6849819 2.9 12102000 4230137.4; 10:57:29.667 INFO ProgressMeter - chr2:26448455 3.0 12672000 4185516.5; 10:57:39.696 INFO ProgressMeter - chr2:48688700 3.2 13582000 4251349.9; 10:57:49.698 INFO ProgressMeter - chr2:74009861 3.4 14355000 4270478.5; ...; ```; I'll let this finish (and post again if there is an error), but I suspect the issue is solved. Thank you @cmnbroad for the fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:4260,error,error,4260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828,1,['error'],['error']
Availability,(HardAlleleFilter.java:16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$0(ErrorProbabilities.java:27) ; ; at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321) ; ; at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:25) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:138) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:154) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapA,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:8298,Error,ErrorProbabilities,8298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['Error'],['ErrorProbabilities']
Availability,(Note that the failure in the cloud tests is expected due to an ongoing GCS bucket region migration -- it should clear up next week),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8318#issuecomment-1546280764:15,failure,failure,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8318#issuecomment-1546280764,2,['failure'],['failure']
Availability,(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 ERROR Executor: Exception in task 518.0 in stage 0.0 (TID 518); java.io.FileNotFoundException: /home/data/WGS/F002/F002.sort.bam (Too many open files); 	at java.io.FileInputStream.open0(Native Method); 	at java.io.FileInputStream.open(FileInputStream.java:195); 	at java.io.FileInputStream.<init>(FileInputStream.java:138); 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:106); 	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:202); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:349); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:147); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:222); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); 	at org.apache.spa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:4767,ERROR,ERROR,4767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['ERROR'],['ERROR']
Availability,"(Reported in #5130). We had a user report that when a variant is within 10 base pairs from the end of the chromosome (as defined by the reference dictionary), `ReferenceBases` throws a String index out of range error. This bug was in the annotation prior to #4895. What #4895 did was that it made the `ReferenceBases` annotation part of `StandardMutectAnnotation,` which turned on `RefernceBases` by default, and that led to the user getting the error.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5151:211,error,error,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5151,2,['error'],['error']
Availability,(SV) slim down REF column for CPX variants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4970:10,down,down,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4970,1,['down'],['down']
Availability,(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:337); 	... 32 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [cb87810a-0133-42b3-a954-363b62adce39] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:5141,ERROR,ERROR,5141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,2,['ERROR'],['ERROR']
Availability,(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:152); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:175); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:161); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:338); 	... 33 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [acdae2af-e0ce-4822-87f5-dcd165d85cf4] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:10707,ERROR,ERROR,10707,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,2,['ERROR'],['ERROR']
Availability,(Travis failure looks to be a transient issue getting https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/com/github/samtools/htsjdk/2.11.0-18-ga35b420-SNAPSHOT/htsjdk-2.11.0-18-ga35b420-20170925.132250-2.jar),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332294764:8,failure,failure,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332294764,1,['failure'],['failure']
Availability,"(assumes that #2457 is already complete); Currently, the docker image creation will grab all the local files, which is prone to error. The github hash/tag parameters are simply to determine how to tag the image in docker hub. In gatk-protected, we used to actually grab the source code from github in the Dockerfile. I'm not suggesting we go back to this model. What we might want to consider:; The build_docker.sh script could download the github hash/tag to a temp dir and then build the docker image from the temp dir. This solution would be more robust and would decrease errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2700:128,error,error,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2700,4,"['down', 'error', 'robust']","['download', 'error', 'errors', 'robust']"
Availability,"(https://github.com/samtools/htsjdk/issues/1115); I am getting an error using gatk's VariantRecalibrator:. `htsjdk.tribble.TribbleException: Line 104: there aren't enough columns for line entrainScore=0.7203;HW=4.306476E-6 (we expected 9 tokens, and saw 1 ), for input source: file:///share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/2ce78a09-433b-48eb-83d0-1fa1771d1181/call-SNPsVariantRecalibratorCreateModel/inputs/share/ClusterShare/biodata/contrib/evaben/hs37d5x/vcf/1000G_omni2.5.b37.vcf`. I am having trouble getting to the bottom of the issue. I cannot find the string 'entrainScore=0.7203;HW=4.306476E-6' in the vcf file, and Line 104 is part of the header (I think Line 104 refers to tribble source though). Gatks ValidateVariants does not have any issues with the vcf file, and looking visually with bcftools I cannot see an issue either. . Can anyone suggest further diagnosis steps? Should I take this to GATK issue tracker?. The VCF file is here: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/1000G_omni2.5.b37.vcf. Here is the gatk command line: ; ```; gatk --java-options ""-Xmx100g -Xms100g"" \; VariantRecalibrator \; -V /share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/2ce78a09-433b-48eb-83d0-1fa1771d1181/call-SNPsVariantRecalibratorCreateModel/inputs/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/2ce78a09-433b-48eb-83d0-1fa1771d1181/call-SitesOnlyGatherVcf/execution/NA12878.sites_only.vcf.gz \; -O NA12878.snps.recal \; --tranches-file NA12878.snps.tranches \; -trust-all-polymorphic \; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.8 -tranche 99.6 -tranche 99.5 -tranche 99.4 -tranche 99.3 -tranche 99.0 -tranche 98.0 -tranche 97.0 -tranche 90.0 \; -an QD -an MQRankSum -an ReadPosRankSum -an FS -an MQ -an SOR -an DP \; -mode SNP \; -sample-every 10 \; --output-model NA12878.snps.model.report \; --max-gaussians 6 \; -resource hapmap,known=false,training=true,truth=true,prior=",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4761:66,error,error,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4761,1,['error'],['error']
Availability,"(s),0,Cpu time(s),0,#critical path,0; GENOMICSDB_TIMER,Fetch from VCF,Wall-clock time(s),0.052394,Cpu time(s),0.0522175,Critical path wall-clock time(s),0.050241,Cpu time(s),0.0500711,#critical path,55; GENOMICSDB_TIMER,Combining cells,Wall-clock time(s),0.008567,Cpu time(s),0.00855882,Critical path wall-clock time(s),0.004002,Cpu time(s),0.00399618,#critical path,29; GENOMICSDB_TIMER,Flush output,Wall-clock time(s),0,Cpu time(s),0,Critical path wall-clock time(s),0,Cpu time(s),0,#critical path,0; GENOMICSDB_TIMER,Sections time,Wall-clock time(s),0.061053,Cpu time(s),0.0609081,Critical path wall-clock time(s),0,Cpu time(s),0,#critical path,0; GENOMICSDB_TIMER,Time in single thread phase(),Wall-clock time(s),0.000112,Cpu time(s),0.00010141,Critical path wall-clock time(s),0,Cpu time(s),0,#critical path,0; GENOMICSDB_TIMER,Time in read_all(),Wall-clock time(s),0.061276,Cpu time(s),0.0611596,Critical path wall-clock time(s),0,Cpu time(s),0,#critical path,0; WARNING: No valid combination operation found for INFO field DS - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field HaplotypeScore - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; WARNING: No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; [E::bcf_hdr_add_sample] Duplicated sample name 'HG00096'. Results: SUCCESS (0 tests, 0 successes, 0 failures, 0 skipped); :test FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':test'.; > Process 'Gradle Test Executor 1' finished with non-zero exit value 134; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2634#issuecomment-298740693:8072,failure,failures,8072,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2634#issuecomment-298740693,2,"['FAILURE', 'failure']","['FAILURE', 'failures']"
Availability,"(this is mainly relevant for Picard tools, which often have lots of log.info() calls). CommandLineProgram's VERBOSITY is set to INFO by default, which is reasonable when you're actually interacting with a tool, but quickly gets spammy when running unit tests. I propose injecting VERBOSITY=ERROR (the strictest setting) into CommandLineProgramTest to avoid this. This would fix https://github.com/broadinstitute/hellbender/issues/134",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/147:290,ERROR,ERROR,290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147,1,['ERROR'],['ERROR']
Availability,"(you should see it in the travis logs where the tests are all being executed, a bunch of download statements)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5155#issuecomment-418509789:89,down,download,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5155#issuecomment-418509789,1,['down'],['download']
Availability,") + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</n",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5934:2514,error,error,2514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5934,1,['error'],['error']
Availability,) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsList(CommonInfo.java:274) ; ; at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsIntList(CommonInfo.java:282) ; ; at htsjdk.variant.variantcontext.VariantContext.getAttributeAsIntList(VariantContext.java:827) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.DuplicatedAltReadFilter.areAllelesArtifacts(DuplicatedAltReadFilter.java:26) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.HardAlleleFilter.calculateErrorProbabilityForAlleles(HardAlleleFilter.java:16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$0(ErrorProbabilities.java:27) ; ; at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321) ; ; at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:25) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:7422,error,errorProbabilities,7422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['error'],['errorProbabilities']
Availability,"):. 1. Check input and output files for readability/writability as soon as; possible.; 2. Delete incomplete outputs in case of caught exception.; 3. Return non-zero value in case of error. On Sun, Mar 3, 2019 at 4:45 PM samuelklee <notifications@github.com> wrote:. > Just finished switching over all of the CNV tools to fail early if; > directories are not writeable---or do not exist and cannot be; > created---only to realize that this behavior is inconsistent with that of; > Picard IntervalListTools (which is used in the gCNV pipeline).; >; > That tool fails early if the output directory is not writeable or does not; > exist, and although there is a code path later that suggests that output; > directories should be created, it is not reached due to this early fail. It; > might be that this inconsistency was introduced in; > broadinstitute/picard#1208; > <https://github.com/broadinstitute/picard/pull/1208> and I did not catch; > it in my PR. @yfarjoun <https://github.com/yfarjoun> any opinions what; > the intended behavior should be? Are there any conventions for Picard tools; > in general?; >; > Perhaps we could enforce this at the engine level (maybe checks that are; > triggered by annotations such as suggested in #141; > <https://github.com/broadinstitute/gatk/issues/141>, if possible)? But; > this would only work for GATK tools and would still rely on the diligence; > of developers.; >; > In any case, I'll decide on and document a convention for the CNV tools,; > but I think it might be a quixotic dream to enforce consistent; > behavior---especially without breaking things downstream which may rely on; > existing, inconsistent behavior...; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4825#issuecomment-469067676>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0knrip3kZgweCbYoBj3fwGvlDdPEks5vTEKEgaJpZM4USOnb>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-470113262:1683,down,downstream,1683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-470113262,1,['down'],['downstream']
Availability,"); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:303); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:301); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 18/07/24 21:02:27 ERROR org.apache.spark.scheduler.TaskSetManager: Task 1 in stage 0.0 failed 4 times; aborting job; 18/07/24 21:02:27 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 21:02:27.703 INFO PrintReadsSpark - Shutting down engine; [July 24, 2018 9:02:27 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.32 minutes.; Runtime.totalMemory()=2463629312; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 7, shuang-small-m.c.broad-dsde-methods.internal, executor 2): htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsj",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:11106,ERROR,ERROR,11106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['ERROR'],['ERROR']
Availability,"); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 18/07/24 21:02:27 ERROR org.apache.spark.scheduler.TaskSetManager: Task 1 in stage 0.0 failed 4 times; aborting job; 18/07/24 21:02:27 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 21:02:27.703 INFO PrintReadsSpark - Shutting down engine; [July 24, 2018 9:02:27 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.32 minutes.; Runtime.totalMemory()=2463629312; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 7, shuang-small-m.c.broad-dsde-methods.internal, executor 2): htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:977); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFile",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:11621,failure,failure,11621,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['failure'],['failure']
Availability,"); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). #### Steps to reproduce; Run the MarkDuplicatesSpark in a local SPARK cluster. The following function return a null, which cause the exception. public static String getLibrary( final GATKRead read, final SAMFileHeader header, String defaultLibrary) {; final SAMReadGroupRecord readGroup = getSAMReadGroupRecord(read, header);; String library = readGroup != null ? readGroup.getLibrary() : null;; return library==null? defaultLibrary : library;; }. public EmptyFragment(GATKRead read, SAMFileHeader header, Map<String, Byte> headerLibraryMap) {; super(0, null);; this.R1R = read.isReverseStrand();; this.key = ReadsKey.getKeyForFragment(ReadUtils.getStrandedUnclippedStart(read),; isRead1ReverseStrand(),; ReadUtils.getReferenceIndex(read, header),; headerLibraryMap.get(ReadUtils.getLibrary(read, header, LibraryIdGenerator.UNKNOWN_LIBRARY)));; }. #### Expected behavior; MarkDuplicatesSpark should success finish. #### Actual behavior; The MarkDuplicatesSpark run failure. ----. ## Feature request. ### Tool(s) or class(es) involved; SPARK, Hadoop HDFS. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:5400,failure,failure,5400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['failure'],['failure']
Availability,"); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibratorEngine.generateModel(VariantRecalibratorEngine.java:43); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.onTraversalSuccess(VariantRecalibrator.java:625); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:895); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. I believe this is derived from an error earlier in the log, since the `stderr` gives the same Java heap space error: ; ```; [2019-09-16 19:05:59,50] [error] WorkflowManagerActor Workflow 9f7a01a4-0632-4817-8622-aa51e520abf1 failed (during ExecutingWorkflowState): Job JointGenotyping.SNPsVariantRecalibratorClassic:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /path/to/stderr.; ```. I have read past issues (https://gatkforums.broadinstitute.org/gatk/discussion/23880/java-heap-space) regarding this that may suggest it is a bug. It has pointed me to increasing the available heap memory through the primary command of -Xmx. Is this the way to do it? ; ```; java -Xmx600G -Dconfig.file=' + re.sub('input.json', 'overrides.conf', input_json) + ' -jar ' + args.cromwell_path + ' run ' + re.sub('input.json', 'joint-discovery-gatk4.wdl', input_json) + ' -i ' + input_json; ```; where I substitute in the corresponding config, json, and wdl files. . Is 600G enough? Each vcf is ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165:1760,error,error,1760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165,3,['error'],['error']
Availability,"); ----------------------------------------------------------------; Wed Oct 11 14:25:24 CST 2017:; Booting Derby version The Apache Software Foundation - Apache Derby - 10.11.1.1 - (1616546): instance a816c00e-015f-0a1b-f1bd-00002ce33928 ; on database directory /tmp/spark-98953d35-8594-4907-b4a5-0870f1d17b3e/metastore with class loader sun.misc.Launcher$AppClassLoader@5c647e05 ; Loaded from file:/opt/cloudera/parcels/CDH-5.12.1-1.cdh5.12.1.p0.3/jars/derby-10.11.1.1.jar; java.vendor=Oracle Corporation; java.runtime.version=1.8.0_91-b14; user.dir=/opt/Software/gatk; os.name=Linux; os.arch=amd64; os.version=3.10.0-514.el7.x86_64; derby.system.home=null; Database Class Loader started - derby.database.classpath=''; 17/10/11 14:25:33 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.1.0-cdh5.12.1; 17/10/11 14:25:33 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException; SQL context available as sqlContext. **./gradlew bundle**; **[root@com1 gatk]# ./gradlew bundle; when I executed the command ./gradlew bundle it appeared the error in the last did this matter**. .......; [loading ZipFileIndexFileObject[/root/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.6.5/d50be1723a09be903887099ff2014ea9020333/jackson-databind-2.6.5.jar(com/fasterxml/jackson/databind/annotation/JsonSerialize$Inclusion.class)]]; [loading ZipFileIndexFileObject[/root/.gradle/caches/modules-2/files-2.1/org.apache.logging.log4j/log4j-core/2.5/7ed845de1dfe070d43511fab1784e6c4118398/log4j-core-2.5.jar(org/apache/logging/log4j/core/config/plugins/PluginVisitorStrategy.class)]]; [done in 5759 ms]; 1 error; :gatkTabComplete FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkTabComplete'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/opt/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240:2699,avail,available,2699,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240,1,['avail'],['available']
Availability,); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:[192](https://github.com/broadinstitute/gatk/actions/runs/5547450688/jobs/10131043668#step:12:192)); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReadsIntegrationTest.testLargeFileThatForcesSnappyUsage(SplitNCigarReadsIntegrationTest.java:85); Caused by:; htsjdk.samtools.util.RuntimeIOException: Write error; BinaryCodec in writemode; streamed file (filename not available); at htsjdk.samtools.util.BinaryCodec.writeBytes(BinaryCodec.java:222); at htsjdk.samtools.util.BlockCompressedOutputStream.writeGzipBlock(BlockCompressedOutputStream.java:444); at htsjdk.samtools.util.BlockCompressedOutputStream.deflateBlock(BlockCompressedOutputStream.java:408); at htsjdk.samtools.util.BlockCompressedOutputStream.write(BlockCompressedOutputStream.java:301); at htsjdk.samtools.util.BinaryCodec.writeBytes(BinaryCodec.java:220); at htsjdk.samtools.util.BinaryCodec.writeBytes(BinaryCodec.java:212); at htsjdk.samtools.BAMRecordCodec.encode(BAMRecordCodec.java:168); at htsjdk.samtools.BAMFileWriter.writeAlignment(BAMFileWriter.java:134); ... 15 more; Caused by:; java.io.IOException: No space left on device; at sun.nio.ch.FileDispatcherImpl.write0(Native Method); at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60); at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93); at sun.nio.ch.IOUtil.write(IOUtil.java:65); ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1635002002:2048,error,error,2048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1635002002,2,"['avail', 'error']","['available', 'error']"
Availability,")=2088763392; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:554); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:543); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:512); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:326); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:3447,avail,available,3447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564,1,['avail'],['available']
Availability,")=4191682560; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:554); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:543); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:512); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:326); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:4259,avail,available,4259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881,1,['avail'],['available']
Availability,* A previouus change left a reference to an uninitialized property in build.gradle.; This caused a crash when trying to produce an error message warning that the JDK was not found. Ex: Caused by: groovy.lang.MissingPropertyException: Could not get unknown property 'requiredJavaVersion' for root project 'gatk' of type org.gradle.api.Project; * Fix the crash by removing the reference to the missing property.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6676:131,error,error,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6676,1,['error'],['error']
Availability,* Add a table of contents.; * Update out-of-date information.; * Merge in information from the old gatk-protected README; * Add section on git-lfs; * Add section on downloading GATK4; * Add section on documentation generation; * Add section on zenhub; * Remove no-longer-needed protected-root directory. Resolves #2775; Resolves #2978; Resolves #2487; Resolves #2461,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3158:165,down,downloading,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158,1,['down'],['downloading']
Availability,* Add contig and start position to error message in setMatePosition; * Extract the check to a shared method with setPosition so it's not inconsistent; * Improves the unhelpful error reported in https://github.com/broadinstitute/gatk/issues/6776,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6779:35,error,error,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6779,2,['error'],['error']
Availability,"* Added MinGqVariantFilterBase; * * loads VCF, pedigree, UCSC genome tract, and truth data; * * calculates variant overlap with genome tracts; * * forms matrices, tensors, and other helping data for machine learning; * * provides for TRAIN and FILTER modes; * * provides functions for calculating loss given assigned min GQ values; * * computes best estimate of truth data used for training xgboost model; * Added XGBoostMinGqVariantFilter; * * calculates new GQ based on gradient boosting; * Added PropertiesTable for loading VCF properties into tensors; * Added TractOverlapDetector for computing overlap properties with; UCSC genome tracts. Training loss is based on weighted combination of heredity and truth; data, broken down by variant category.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7705:727,down,down,727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7705,1,['down'],['down']
Availability,* Adding a beta version of http-nio which allows streaming http files and seeking within them.; * This allows using https urls including signed urls to access remote files.; * Bams/crams can be read by specifying the index manually. Automatic index resolution does not work correctly at the moment.; * known caveats; * some methods are not implement in the nio filesystem library yet; * failures are not retryied. I'm currently fighting with sonatype to get a real release pushed out... it seems close...,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6526:387,failure,failures,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6526,1,['failure'],['failures']
Availability,"* Adding a new GATKTool level argument `--variant-output-interval-filtering-mode` which allows filtering output variants according to the input interval list. This replaces `--only-output-calls-starting-in-intervals` which was available in GenotypeGvcfs and GnarlyGenotyper. It works by adding a filtering decorator to the vcf writers created through `GATKTool.createVCFWriter`. ; There are several different filtering modes:; `STARTS_IN`, `ENDS_IN`, `OVERLAPS`, `CONTAINED`, and `ANYWHERE`. The default for tools is not to apply the decorator, but they may optionally change that behavior by overriding the new `getDefaultVariantOutputFilterMode`. `--variant-output-interval-filtering-mode STARTS_IN` is equivalent to the previous behavior of `--only-output-calls-starting-in-intervals true`. MockVcfWriter is now a testUtils class. The naming is a bit awkward so improvements would be helpful. This doesn't fix the weird behavior in HaplotypeCaller but does allow subsetting unique shards with SelectVariants and other variant outputting tools. We could adapt this to apply to bam outputs as well if that seems useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6388:227,avail,available,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6388,1,['avail'],['available']
Availability,* Fixed cost calculation to ignore duplicate rows caused by preemption.; * Resetting tolerances to 5% across the board.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8813:85,toler,tolerances,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8813,1,['toler'],['tolerances']
Availability,* Fixing an obscure error in an error message in GATKAnnotationPluginDescription.; * entrySet was called instead of values as a result everything was always filtered from the error message. Noticed this one completely by chance.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5444:20,error,error,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5444,3,['error'],['error']
Availability,* Have GvsCreateVATfromVDS.wdl take sites-only-vcf as an optional input.; * Added logic to allow/disallow CopyFile to overwrite. [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/bb8906d4-7111-4fd1-a723-b5616b354c23) is a passing run using an existing sites-only VCF.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9c8be4d5-f707-4c54-bde5-18d9d23cde66) is a run where it tried to generate the sites-only VCF. Failing because of Echo issues with creating VDS.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8f8cc493-b0ff-4d8c-8813-6c463dbf17c0) is an integration test. It's failing in ValidateVDS on two paths (the ones that create VDSes) since this is based off of EchoCallset branch - this is expected,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8866:516,Echo,Echo,516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8866,2,['Echo'],"['Echo', 'EchoCallset']"
Availability,* I introduced a compile error because my branch wasn't rebased on the changes to ArgumentsBuilder,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6483:25,error,error,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6483,1,['error'],['error']
Availability,* Implemented a suggestion from an ancient TODO in ApplyBQSRArgumentCollection which was waiting for a now available barclay feature,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6438:107,avail,available,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6438,1,['avail'],['available']
Availability,* Java 8 doesn't come by default on many machines now. Updating the; README with advice about where to download a java8 jdk.; * Part of https://github.com/broadinstitute/gatk/issues/6024,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6025:103,down,download,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6025,1,['down'],['download']
Availability,* PrintWriter doesn't throw exceptions on write failures and might therefore lead to unexpectedly trunacated data being produced without any notification; * replacing it's use in MetricsUtils and MafOutputRenderer where it might cause problems; * partial fix for https://github.com/broadinstitute/gatk/issues/5458,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5461:48,failure,failures,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5461,1,['failure'],['failures']
Availability,* Removing 2 redundant abstract methods by pulling them up to the base class,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6560:13,redundant,redundant,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6560,1,['redundant'],['redundant']
Availability,"* Should be runnable on-demand using a convenient mechanism (eg., reviewer types a command on a github PR). * Should be robust enough to provide confidence that a substantial change to a stable variant-calling tool is safe to merge. * Should cover performance as well as correctness. * Output may be a report that a human has to read (do not need automated pass/fail). * Implement for `HaplotypeCaller` and CNV tools first (with help of @LeeTL1220), then work with other teams to get test coverage for their tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4630:120,robust,robust,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4630,1,['robust'],['robust']
Availability,* When running recursive deletion file hooks we now catch all exceptions and log them at DEBUG level instead of letting them propagate.; * This should reduce confusion when test have deletion failures.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6125:192,failure,failures,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6125,1,['failure'],['failures']
Availability,"* added a reference parameter to FeatureData source and FeatureManager methods; * genomicsDB requires a reference, previously this was being passed; through by hardcoding it in the required json files; * json files are now autogenerated by the importer tool, but the; reference wasn't being handled correctly. * updated the various walkers to pass the reference through if available. * gendb:// paths now point to the workspace directory instead of a; directory of jsons. * removed the ability to specify array, vidmap.json, and; callset.json paths in the importer tool since we now rely on the; structure and naming of the files when loading; moved some constants to GenomicsDBConstants. * updated GenomicsDBIntegration tests to use the new importer instead of a; prepackaged and very brittle set of json files. fixed a bug in GenomicsDBImporterIntegrationTests that made both tests; write to the same workspace",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2626:373,avail,available,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2626,1,['avail'],['available']
Availability,"* changing the key hash we use to download R package keys on travis from an insecure 32 bit hash that has been compromised to a more secure longer hash; * we will no longer be installing the ""Totally Legit Signing Key""; * see https://evil32.com/ for a summary of the problem",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5214:34,down,download,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5214,1,['down'],['download']
Availability,* creating utils to spin up a Dataproc cluster which will shut itself down after a brief interval of inactivity (10 minutes idle or 30 minutes total); * adding tests which spin up a cluster and run PrintReadsSpark on them; * updating gatk-launch to be aware of new GCLOUD_HOME environment variable. first round of #2298,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3767:70,down,down,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3767,1,['down'],['down']
Availability,* update gradle wrapper 8.2.1 -> 8.10.2; * remove 'versions' plugin because we don't use it; * update gradle plugins to new versions; * shadow plugin changed maintainers and coordinates com.github.johnrengelman.shadow:8.1.1 -> com.gradleup.shadow:8.3.3; * git-version 0.5.1 -> 3.1.0; * sonatype scan 2.6.1 -> 2.8.3; * download 5.4.0 -> 5.6.0; * use tasks.register() which is the newer style,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8998:318,down,download,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8998,1,['down'],['download']
Availability,* updating google-cloud-java 0.59.0 -> 0.62.0; * this includes retries on 502 errors see https://github.com/GoogleCloudPlatform/google-cloud-java/pull/3557,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194:78,error,errors,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194,1,['error'],['errors']
Availability,"**. Note this has been renamed from PathSeqKmerSpark. Input:; 1) Host reference FASTA; 2) False positive probability (0 create a hash set, >0 to create a Bloom filter); 3) Kmer length (1-31); 4) Kmer base indices to mask (optional). Output:; 1) Serialized kmer Hopscotch set (.hss) or Bloom filter (.bfi) file. For each reference record, the tool generates a list of long's containing the canonicalized/masked kmers. The result is a Collection<long[]> variable, which is then converted to either a PSKmerSet (Hopscotch set) or PSKmerBloomFilter, depending on the desired false positive probability. . The PSKmerSet/BloomFilter classes are basically wrappers for LargeLongHopscotchSet and LongBloomFilter, respectively. They both inherit PSKmerCollection, which provides a contains() function for querying new kmers for set membership and makes loading the kmers for filtering more convenient. These classes also store the kmer size, mask, and false positive probability. They also handle canonicalization/masking on queried kmers. **PathSeqFilterSpark tool**. Input:; 1) Input BAM; 2) Host kmer set file (optional); 3) Host reference bwa image (optional). Output:; 1) BAM containing paired reads that still have mates; 2) BAM containing unpaired reads / reads whose mates were filtered out; 3) Metrics file containing read counts and elapsed wall time at each step (optional). Filtering steps performed on each read:; - If the user sets the --isHostAligned, the read will first be filtered if it is aligned sufficiently well ; - Alignment info is stripped; - A series of quality filters (same as in the previous version of this tool); - Kmerized and filtered out if at least a threshold number of kmers are in the host set (default 1); - Aligned to the host reference and filtered if it maps sufficiently well; - Sequence duplicates are removed. Other:; -Fixed bugginess in very large LongBloomFilters by changing a size variable from int to long. ; - Also realized we can't get away with using just ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3115:1259,mask,masking,1259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3115,1,['mask'],['masking']
Availability,"**;BQHIST=5,1,0,0,1,11,2,0,0,0,14,2,0,0,1,15,1,0,0,0,16,1,0,0,0,17,0,2,0,0,18,2,0,0,1,19,6,0,1,0,20,25,0,2,2,21,13,0,1,2,22,20,0,3,3,23,2,1,2,1,24,6,0,2,0,25,21,1,4,7,26,33,0,5,6,27,18,0,0,7,28,29,0,0,4,29,26,2,4,8,30,161,4,5,51,31,263,2,3,51,32,129,2,3,22,33,41,0,0,0,34,15,0,0,0,35,20,0,0,0,36,19,0,0,0,37,12,0,0,0,38,1,0,0,0,39,9,0,0,0,41,18,0,0,0,44,26,0,0,0;BaseQRankSum=-6.431;ClippingRankSum=-7.714;DP=1323;ECNT=1;FS=0.000;LikelihoodRankSum=-7.886;MBQ=31,30,26,30;MFRL=6590,6585,4819,6586;MMQ=60,60,60,60;MPOS=16,15,7;MQ=59.98;MQ0=0;MQRankSum=0.000;NALOD=0.569,1.49,1.49;NCC=0;NCount=0;NLOD=27.80,30.51,30.97;OCM=0;POPAF=6.00,6.00,6.00;REF\_BASES=GAACTTGCTTCTTTTTTTTGC;RPA=8,9,10,11;RU=T;ReadPosRankSum=5.751;SOR=1.152;STR;Samples=TCGA-NJ-A55R-01A-11R-A262-07;TLOD=284.47,51.82,3.50 GT:AD:AF:DP:F1R2:F2R1:SB 0/1/2/3:819,166,35,14:0.161,0.034,0.014:1034:365,76,17,4:440,87,17,8:16,803,6,209 0/0:103,1,0,0:0.017,8.250e-03,8.221e-03:104:50,1,0,0:52,0,0,0:26,77,0,1. The error log that FilterMutectCalls emited was listed below:. Using GATK jar /home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar FilterMutectCalls -R /public1/data/resources/ref\_genome/GRCh38/GRCh38.d1.vd1.fa -V somatic\_mutation/Mutect2/test.vcf.gz -O somatic\_mutation/FilterMutectCalls/test.vcf.gz ; ; 11:03:39.517 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/lqh/software/GATK-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jun 04, 2021 11:03:49 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:03:49.968 INFO FilterMutectCalls - --------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:2363,error,error,2363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['error'],['error']
Availability,"**Command**; `gatk VariantEval -eval SimpleExample.vcf.gz -O output_gatk_variantEval.txt`. I got the following error; ```; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: VariantEval is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 14:37:10.767 INFO VariantEval - Initializing engine; 14:37:11.138 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/justinzhang/daiichi/SimpleExample.vcf.gz; 14:37:11.268 INFO VariantEval - Done initializing engine; 14:37:11.278 INFO VariantEval - Creating 3 combinatorial stratification states; 14:37:11.281 INFO ProgressMeter - Starting traversal; 14:37:11.282 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:37:11.454 INFO ProgressMeter - unmapped 0.0 250 87719.3; 14:37:11.454 INFO ProgressMeter - Traversal complete. Processed 250 total variants in 0.0 minutes.; 14:37:11.454 INFO VariantEval - Finalizing variant report; 14:37:11.455 INFO VariantEval - Shutting down engine; [October 11, 2019 2:37:11 PM EDT] org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=386924544; **java.lang.NullPointerException**; 	at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.getnProcessedLoci(VariantEval.java:822); 	at org.broadinstitute.hellbender.tools.walkers.varianteval.evaluators.CountVariants.finalizeEvaluation(CountVariants.java:184); 	at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.onTraversalSuccess(VariantEval.java:709); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1050); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(C",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6212:111,error,error,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6212,1,['error'],['error']
Availability,"**Problem:**; Looking at the runtime block for the funcotator task in the Mutect2 WDL workflow, it doesn't look like `default_disk_space_gb` or `default_ram_mb` has any role in changing the VM resource settings. I dont see them being used at all in the rest of the task block. The correct parameters to change to adjust the memory and disk space for this task are `small_task_mem` and `small_task_disk`. **Suggestion**; Remove `default_disk_space_gb` or `default_ram_mb` variables since they are not being used in the task. This makes it less confusing when users need to adjust the resources being used, they can simply use the `small_task_mem` and `small_task_disk` variables; or ; Have the `default_disk_space_gb` and `default_ram_mb` variables be used in the runtime block with the `select_first` function that way users have the option to adjust the resources being used, and if not the task can use the default runtime_params dictionary values. This allows funcotator its own separate variables for adjusting resources. Workflow Link: ; https://github.com/broadinstitute/gatk/blob/79a4cda5e045a7f62cc7ed61d102fabc3637fafb/scripts/mutect2_wdl/mutect2.wdl#L1101. User Question Link:; https://gatk.broadinstitute.org/hc/en-us/community/posts/360068111052-Mutect2-Funcotator-error-?page=1#community_comment_360011181392",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6680:1278,error,error,1278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680,1,['error'],['error']
Availability,"**Summary**: ; A user reported `java.io.IOException: Stream closed` error with ApplyBQSRSpark. GATK 4.0.9.0 runs fine but when the user upgraded to gatk 4.1.1.0 version, they see his error. **User Report**:; I am getting the below error when running gatk-variant pipeline of bcbio. Bcbio using gatk 4.1.1.0 version. ; When I run ApplyBQSRSpark using GATK 4.0.9.0, it runs fine without any issues. Here is the command; **; gatk ApplyBQSRSpark --input test-sort.bam --output test-sort-recal.bam --bqsr-recal-file test-sort-recal.grp --static-quantized-quals 10 --static-quantized-quals 20 --static-quantized-quals 30 --spark-master local[8] --conf spark.local.dir=scratch/ --conf spark.driver.host=localhost --conf spark.network.timeout=800 --jdk-deflater --jdk-inflater**. Here is the error. [April 28, 2019 10:11:25 AM AST] org.broadinstitute.hellbender.tools.spark.ApplyBQSRSpark done. Elapsed time: 0.15 minutes.; Runtime.totalMemory()=874512384; **htsjdk.samtools.util.RuntimeIOException: java.io.IOException: Stream closed**; at htsjdk.samtools.IndexStreamBuffer.readFully(IndexStreamBuffer.java:23); at htsjdk.samtools.IndexStreamBuffer.readLong(IndexStreamBuffer.java:62); at htsjdk.samtools.AbstractBAMFileIndex.readLong(AbstractBAMFileIndex.java:436); at htsjdk.samtools.AbstractBAMFileIndex.query(AbstractBAMFileIndex.java:311); at htsjdk.samtools.CachingBAMFileIndex.getQueryResults(CachingBAMFileIndex.java:159); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:43); at htsjdk.samtools.BAMIndexMerger.processIndex(BAMIndexMerger.java:16); at org.disq_bio.disq.impl.file.IndexFileMerger.mergeParts(IndexFileMerger.java:90); at org.disq_bio.disq.impl.formats.bam.BamSink.save(BamSink.java:132); at org.disq_bio.disq.HtsjdkReadsRddStorage.write(HtsjdkReadsRddStorage.java:225); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:155); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(Rea",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5919:68,error,error,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5919,4,['error'],['error']
Availability,**UPDATE**; Add proposed heuristic alignment filtering/picking of long reads for later cpx SV resolving.; Solves #3221 . . Changed `AlignedContig` by adding a boolean field to signal if several equally good alignment configurations exist for downstream analysis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3432:242,down,downstream,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3432,1,['down'],['downstream']
Availability,"**Update:**. Here's how the coverage looks like using `CollectReadCounts` (w/ and w/o MQ > 30 filter) vs. `CollectFragmentCounts`. The lines are offset by +10 and +20 for better visibility. Summary: marked improvement in all cases, however, the error modes are different. `CollectFragmentCounts` tends to underestimate the size of SV regions and uniformly leads to coverage depletion near the breakpoints, `CollectReadCounts` estimates the size of SV regions better, however, coverage near the breakpoints tend to be less predictable (sometimes depletion, sometimes accumulation). Still, IGV seems to do the best job. Any improvement over `CollectReadCounts` requires using supplementary alignment information (e.g. weight sharing among supplementary alignments; this will likely fix the coverage asymmetry of translocation breakpoints), read clipping information, and mismatches. The latter two require a base-level coverage collection strategy (like IGV and `CollectTargetBaseCallCoverage`). _Unbalanced translocation:_. ![unbtr-1](https://user-images.githubusercontent.com/15305869/37840319-1aba29ce-2e93-11e8-9d41-b9eafe450b6d.png). ![unbtr-2](https://user-images.githubusercontent.com/15305869/37840320-1bfff9a8-2e93-11e8-9842-39824f9fad64.png). ![unbtr-3](https://user-images.githubusercontent.com/15305869/37840321-1d82fa00-2e93-11e8-88ec-d7c40876594e.png). _Balanced translocation:_. ![baltr-1](https://user-images.githubusercontent.com/15305869/37840331-26a0962e-2e93-11e8-8dcf-0e69c8e45146.png). _Inversion:_. ![inv-1](https://user-images.githubusercontent.com/15305869/37840347-2f0d2f8e-2e93-11e8-8d36-64367951e7f2.png). ![inv-2](https://user-images.githubusercontent.com/15305869/37840350-306dedbe-2e93-11e8-9837-53369f5fb1f0.png). _Deletion:_. ![del-1](https://user-images.githubusercontent.com/15305869/37840366-3a32c0ea-2e93-11e8-99dc-d949985616d9.png). _Tandem Duplication:_. ![dup-1](https://user-images.githubusercontent.com/15305869/37840373-42052542-2e93-11e8-8891-fa9f79cc9f70.png",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375720743:245,error,error,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375720743,1,['error'],['error']
Availability,"**changes in this PR:**; - resolves specops issue #247 - ImportGenomes.wdl takes Array[File] from data table as vcf input; - refactor LoadBigQueryData.wdl back into ImportGenomes; - returns an error if the `bq load` step fails (workflow was silently succeeding when this step failed); - checks existence of tables using `bq show` rather than the csv file - this should still be safe against a race condition because of @ericsong 's refactoring to prevent the `CreateTables` step from being scattered; - run CreateTables at the start (don't wait for CreateImportTsvs); - does NOT use a preemptible VM for the LoadTables step, to minimize (though not eliminate) the possibility of loading a duplicate set of data (see specops issue #248 for further discussion). **testing:**; - these changes were tested in Terra, BQ outputs checked and verified",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7112:193,error,error,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7112,1,['error'],['error']
Availability,"*before*: GATK crashes with a stack trace. The stack trace contains useful; info, but:; * it's hard to read; * it doesn't include the name of the file we cannot access. *now*, a better message that addresses both issues:; > A USER ERROR has occurred: Couldn't read file gs://(...). Error was:; > 401: Anonymous users does not have storage.objects.get access to object (...). Additional information (including a stack trace) is displayed if the; user specifies `--verbosity=DEBUG`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417:231,ERROR,ERROR,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"+ blaunch -no-wait -z hpcgenomicn24 /spark-1.6.2-bin-hadoop2.6//bin/spark-class org.apache.spark.deploy.worker.Worker spark://hpcgenomicn24:6311 -c 16; + echo --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; + /spark-1.6.2-bin-hadoop2.6//bin/spark-submit --master spark://hpcgenomicn24:6311 --conf spark.executor.memory=2g --conf spark.driver.memory=2g --conf spark.local.dir=/gpfs/ngsdata/sparkcache --class org.broadinstitute.hellbender.Main /gpfs/software/spark/gatk4onspark.jar PrintReadsSpark -I /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O /gpfs/home/tpathare/test/; 23:25:07.475 INFO IntelGKLUtils - Trying to load Intel GKL library from:; 	jar:file:/gpfs/software/spark/gatk4onspark.jar!/com/intel/gkl/native/libIntelGKL.so; 23:25:07.552 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [November 16, 2016 11:25:07 PM AST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output /gpfs/home/tpathare/test/ --input /gpfs/home/tpathare/gatk/src/test/resources/NA12878.chr17_69k_70k.dictFix.bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:154,echo,echo,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['echo'],['echo']
Availability,", 2016 at 3:27 PM, Louis Bergelson notifications@github.com; wrote:. > I got a segfault while running CreatePanelOfNormalsIntegrationTest.; > Subsequent runs were unable to reproduce it.; > ; > 18:03:07.573 WARN TaskSetManager:70 - Stage 181 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > Test: Test method testAllTargetsHDF5PoNCreationSpark[0](null, src/test/resources/org/broadinstitute/hellbender/tools/exome/create-pon-control-full.pcov)(org.broadinstitute.hellbender.tools.exome.CreatePanelOfNormalsIntegrationTest) produced standard out/err: 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > ; > ```; > 18:03:07.612 WARN TaskSetManager:70 - Stage 182 contains a task of very large size (119 KB). The maximum recommended task size is 100 KB.; > ```; > ; > #; > ; > # A fatal error has been detected by the Java Runtime Environment:; > ; > #; > ; > # SIGSEGV (0xb) at pc=0x000000010a5a9401, pid=2425, tid=8963; > ; > #; > ; > # JRE version: Java(TM) SE Runtime Environment (8.0_91-b14) (build 1.8.0_91-b14); > ; > # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.91-b14 mixed mode bsd-amd64 compressed oops); > ; > # Problematic frame:; > ; > # V [libjvm.dylib+0x1a9401]; > ; > #; > ; > # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; > ; > #; > ; > # An error report file with more information is saved as:; > ; > # /Users/louisb/Workspace/gatk-protected/hs_err_pid2425.log; > ; > #; > ; > # If you would like to submit a bug report, please visit:; > ; > # http://bugreport.java.com/bugreport/crash.jsp; > ; > #; > ; > hs_err_pid2425.log.txt; > https://github.com/broadinstitute/gatk-protected/files/448383/hs_err_pid2425.log.txt; > ; > @yfarjoun https://github.com/yfarjoun Is this similar to the crash you; > saw a while back?; > ; > ; > You are receiving this beca",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2883:2907,error,error,2907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2883,1,['error'],['error']
Availability,", 2022 12:17:31 AM GMT; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.229 INFO Mutect2 - HTSJDK Version: 2.24.1; 00:17:32.230 INFO Mutect2 - Picard Version: 2.25.4; 00:17:32.230 INFO Mutect2 - Built for Spark Version: 2.4.5; 00:17:32.231 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 00:17:32.231 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 00:17:32.231 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 00:17:32.232 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:17:32.232 INFO Mutect2 - Deflater: IntelDeflater; 00:17:32.232 INFO Mutect2 - Inflater: IntelInflater; 00:17:32.233 INFO Mutect2 - GCS max retries/reopens: 20; 00:17:32.233 INFO Mutect2 - Requester pays: disabled; 00:17:32.233 INFO Mutect2 - Initializing engine; 00:17:33.373 INFO Mutect2 - Shutting down engine; [April 5, 2022 12:17:33 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=361234432; htsjdk.samtools.cram.CRAMException: Attempt to create a bai entry for an unmapped slice with unexpected alignment start (0) or span (-2147483647) values; 	at htsjdk.samtools.cram.BAIEntry.<init>(BAIEntry.java:60); 	at htsjdk.samtools.cram.BAIEntry.<init>(BAIEntry.java:83); 	at htsjdk.samtools.cram.CRAIIndex.openCraiFileAsBaiStream(CRAIIndex.java:89); 	at htsjdk.samtools.SamIndexes.asBaiSeekableStreamOrNull(SamIndexes.java:91); 	at htsjdk.samtools.CRAMFileReader.initWithStreams(CRAMFileReader.java:203); 	at htsjdk.samtools.CRAMFileReader.<init>(CRAMFileReader.java:194); 	at htsjdk.samtools.SamReaderFactory$SamReaderFactoryImpl.open(SamReaderFactory.java:432); 	at htsjdk.samtools.SamReaderFactory.open(SamReaderFactory.java:106); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.<init>(ReadsPathDataSource.java:245); 	at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755:2772,down,down,2772,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755,1,['down'],['down']
Availability,", I experience some issues with GenotypeGVCFs in GATK version 4.0.3.0. It cannot open ""genomicsdb\_array"" although the directory of genomicsdb\_array does exist. I found someone else has reported this issue here: [https://sites.google.com/a/broadinstitute.org/legacy-gatk-forum-discussions/2018-04-11-2017-12-02/11184-Could-not-open-array-genomicsdbarray-at-workspace-from-GenotypeGVCFs-in-GATK-4000](https://sites.google.com/a/broadinstitute.org/legacy-gatk-forum-discussions/2018-04-11-2017-12-02/11184-Could-not-open-array-genomicsdbarray-at-workspace-from-GenotypeGVCFs-in-GATK-4000), but except for using the latest version of GATK, it seems like there are no other solutions. I was wondering that how do I fix the issues with GATK 4.0.3.0? Does anyone have a better solution?. I also tried GenotypeGVCFs in GATK 4.2.1.0, but there is a problem in terms of MQ calculation. So I think it's better to stick to the same GATK version in the whole workflow. A USER ERROR has occurred: Bad input: Presence of '-RAW\_MQ' annotation is detected. ; ; This GATK version expects key RAW\_MQandDP with a tuple of sum of squared MQ values and total reads over variant genotypes as the value. ; ; This could indicate that the provided input was produced with an older version of GATK. ; ; Use the argument '--allow-old-rms-mapping-quality-annotation-data' to override and attempt the deprecated MQ calculation. ; ; There may be differences in how newer GATK versions calculate DP and MQ that may result in worse MQ results. Use at your own risk. Another question is related to the fasta file:. I downloaded the reference data in the link of [https://console.cloud.google.com/storage/browser/gatk-legacy-bundles/b37](https://console.cloud.google.com/storage/browser/gatk-legacy-bundles/b37), when I noticed that this is an old database, I have already generated GVCF files. It seems like GenotypeGVCFs does not understand the FAI index file. error informaion; ================. \[E::fai\_read\] Could not unde",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7442:5935,ERROR,ERROR,5935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7442,1,['ERROR'],['ERROR']
Availability,", but I'll try to answer a few of them here:. > Q1: you compared pon and paired in https://gatkforums.broadinstitute.org/dsde/discussion/11682#4; > so are you implying we should just use PON, anothing you also gived a question ""Should we include our particular tumors matched normal in the PoN"", is there a definite answer?. Section 4.2 of the tutorial compares 1) denoising using a PoN containing multiple normal samples, and 2) denoising using a PoN containing only the matched normal. Assuming that the samples contained in the panel of normals are representative of the systematic biases present in the case samples (i.e., all samples were sequenced similarly), then option 1 will almost certainly yield better results. You can include the matched normals of tumor case samples in the PoN if you are really pressed for normal samples. However, you should be aware of the implications this might have for denoising those normals as cases; that is, you should be sure to select an appropriate number of eigensamples to use for denoising---if you use all available eigensamples, you will end up denoising away the copy-ratio signal of those samples entirely. > Q2: I am really puzzled about the function CollectAllelicCounts, we have CollectReadCounts why need CollectAllelicCounts, both of them need bam, what is the relationship between PON and paired , my innner heart is Paralytic. CollectReadCounts counts the number of reads that overlap genomic bins (the size of which you can select, typically ~100bp-1kb); these counts are used to estimate copy ratio. In contrast, CollectAllelicCounts counts the number of alt and ref bases in the pileup at genomic sites; these allelic counts are used to estimate minor-allele fraction. > how can we understand this, though I know this fucntion has many possiboe inputs.; > but some has only normal inputs, how is related to tunor? thanks a lot. The possible inputs to ModelSegments are `denoised-copy-ratios`, `allelic-counts`, and `normal-allelic-coun",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5404#issuecomment-439184102:1142,avail,available,1142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5404#issuecomment-439184102,1,['avail'],['available']
Availability,", line 674, in exec_module; File ""<frozen importlib._bootstrap_external>"", line 780, in get_code; File ""<frozen importlib._bootstrap_external>"", line 832, in get_data; OSError: [Errno 23] Too many open files in system: '/gatk/local_mnt/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64/tmp_yxu5we5/__init__.py'; Error in atexit._run_exitfuncs:; Traceback (most recent call last):; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 1492, in _on_atexit; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 1295, in clear_old; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 746, in refresh; OSError: [Errno 23] Too many open files in system: '/gatk/local_mnt/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64'; 23:39:07.445 DEBUG ScriptExecutor - Result: 1; 23:39:07.447 INFO GermlineCNVCaller - Shutting down engine; [February 22, 2019 11:39:07 PM UTC] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 2.14 minutes.; Runtime.totalMemory()=2305818624; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/tmp.cd408023/cohort_denoising_calling.1650827882847090378.py --ploidy_calls_path=/gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/execution/contig-ploidy-calls-dir --output_calls_path=/gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/execution/out/csi_batch1-4_wes_gcnv_pon-calls --output_tracking_path=/gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:22280,down,down,22280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['down'],['down']
Availability,",MedGen:C3463824,OMIM:614286,Orphanet:ORPHA52688|MeSH:D015179,MedGen:CN236642|MedGen:C2239176,OMIM:114550,Orphanet:ORPHA88673,SNOMED_CT:187769009,SNOMED_CT:25370001		Acute_myeloid_leukemia|Brainstem_glioma|Neoplasm_of_brain|Myelodysplastic_syndrome|Colorectal_Neoplasms|Hepatocellular_carcinoma		NC_000015.9:g.90631838C>T	no_assertion_criteria_provided	Pathogenic/Likely_pathogenic			single_nucleotide_variant	SO:0001483			IDH2:3418	SO:0001583|missense_variant	2	121913503		375987								HGNC:5383	Approved	gene with protein product	protein-coding gene		""isocitrate dehydrogenase 2 (NADP+), mitochondrial""			15q26.1	2017-03-24		2016-04-28		1.1.1.42	ENSG00000182054					CCDS10359, CCDS76792	OTTHUMG00000149815	147650	NM_001289910	P48735	ENSG00000182054	uc002box.4		B2R6L6|B4DFL2|Q96GT3	true	false		false	false		false	false	false	IDH2:3418	falsfalse	false	false	false	true	false	false	false	false	false	true	false	false	false	true	true	false	false	true	true	true	3	false	0	false		false	false	false	SNV	0x050268000a05000002100120	1	false	133	rs121913503																						3418	90631838	false	SITE	[745, 640|576, 448]			2483	1	93	[35, 32]	[139, 140]	[60, 60]	19						7.30	93				2809.17 ; ```. It seems that it does not matter if I choose hg19 oder 38. I used `funcotator_dataSources.v1.7.20200521s` as reference.; The call for hg38 was (I slightly shortened it for readability - usually it runs in nextflow - the hg19 call was more or less the same - the -L file is usually not only for IDH2 and has a interval_list format instead of .bed):. ```; gatk Funcotator -R reference/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta -V mutect2_out.vcf -O funcotator_out.maf --output-file-format MAF --data-sources-path reference/funcotator_dataSources.v1.7.20200521s/ --ref-version hg38 -L reference/idh2_r172.bed; ```. I will create an example test set as soon as I can, have reproducible errors for you. If you already have a hint for me to try, I would be happy to hear from you. Best regards,; Daniel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064:4305,error,errors,4305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064,1,['error'],['errors']
Availability,"- 162.710, SNR: 8.3, T: 1.80: 100%|##########| 1000/1000 [00:01<00:00, 521.12it/s]; 15:10:05.229 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1): 0%| | 0/100 [00:00<?, ?it/s]; 15:10:05.502 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 1.0000 +/- 0.0000: 1%|1 | 1/100 [00:00<00:26, 3.68it/s]; 15:10:05.772 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0046 +/- 0.0049: 2%|2 | 2/100 [00:00<00:26, 3.69it/s]; 15:10:06.039 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0023 +/- 0.0037: 3%|3 | 3/100 [00:00<00:26, 3.71it/s]; 15:10:06.307 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0016 +/- 0.0036: 4%|4 | 4/100 [00:01<00:25, 3.72it/s]; 15:10:06.575 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0018 +/- 0.0019: 5%|5 | 5/100 [00:01<00:25, 3.72it/s]; 15:10:06.844 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0013 +/- 0.0014: 6%|6 | 6/100 [00:01<00:25, 3.72it/s]; 15:10:07.113 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0014 +/- 0.0019: 7%|7 | 7/100 [00:01<00:24, 3.72it/s]; 15:10:07.381 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0011 +/- 0.0011: 8%|8 | 8/100 [00:02<00:24, 3.72it/s]; 15:10:07.649 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0008 +/- 0.0009: 10%|# | 10/100 [00:02<00:24, 3.72it/s]; 15:10:08.193 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0006: 11%|#1 | 11/100 [00:02<00:24, 3.70it/s]; 15:10:08.463 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0005 +/- 0.0007: 12%|#2 | 12/100 [00:03<00:23, 3.70it/s]; 15:10:08.732 I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:11707,error,error,11707,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['error'],['error']
Availability,"- 18:33362396 35.1 8782590 250142.7; 14:16:29.221 INFO ProgressMeter - 18:47557520 35.3 8830240 250311.5; 14:16:39.224 INFO ProgressMeter - 18:61732084 35.4 8877870 250478.0; 14:16:49.230 INFO ProgressMeter - 18:75390202 35.6 8923700 250591.9; 14:16:59.238 INFO ProgressMeter - 19:4254509 35.8 8947170 250079.8; 14:17:09.252 INFO ProgressMeter - 19:13499637 35.9 8978420 249787.8; 14:17:19.268 INFO ProgressMeter - 19:23216815 36.1 9011160 249539.8; 14:17:29.278 INFO ProgressMeter - 19:31344990 36.3 9038470 249145.0; 14:17:39.298 INFO ProgressMeter - 19:41157554 36.4 9071590 248912.2; 14:17:49.867 INFO ProgressMeter - 19:42798895 36.6 9077130 247866.1; 14:17:59.042 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.15517662000000002; 14:17:59.043 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 13.012444101000002; 14:17:59.043 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 45.65 sec; 14:17:59.043 INFO Mutect2 - Shutting down engine; [May 15, 2020 2:17:59 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 36.79 minutes.; Runtime.totalMemory()=3793223680; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0; at java.util.ArrayList.rangeCheck(ArrayList.java:657); at java.util.ArrayList.get(ArrayList.java:433); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$27(SomaticGenotypingEngine.java:351); at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(Double",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6605:1737,down,down,1737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6605,1,['down'],['down']
Availability,- Add more detail to error message so that it will be more usful for ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4498:21,error,error,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4498,1,['error'],['error']
Availability,"- Adds size similarity criterion to SVConcordance and SVCluster tools. This is particularly useful for accurately matching smaller SVs that have a high degree of breakpoint uncertainty, in which case reciprocal overlap does not work well. PESR/mixed variant types must have size similarity, reciprocal overlap, and breakend window criteria met. Depth-only variants may have either size similarity + reciprocal overlap OR breakend window criteria met (or both).; - Rewrites some of the linkage logic to be simpler to read.; - Fixes a rare bug with `SortedMultiset` in `SVClusterEngine` that sometimes caused records with identical start positions to get lost.; - Removes null record attributes to avoid `.` INFO/FORMAT fields, which cause a parsing error with Integer types.; - Add check that the vcf header contigs are sorted in the same order.; - Retain FILTER and QUAL fields in output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8257:748,error,error,748,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8257,1,['error'],['error']
Availability,"- Appears in `VCFOutputRenderer`... not sure if this is an issue in the `MAFOutputRenderer`. I am not sure what the exact error is here, but how can I have multiple IGR funcotations for a single variant? I believe that a single variant can be IGR only or not IGR at all, even when looking at multiple transcripts. Perhaps the error is that the variant is being queried by largest gene footprint and then being rendered for transcripts that do not overlap the variant?. For example:; ```; |hg19|chr19|9091811|9091811|IGR||SNP|G|G|A|||+||||||0.5286783042394015|GAGGGTTTCAGCATGGACAGG|||hg19|chr19|9091811|9091811|IGR||SNP|G|G|A|||+||||||0.5286783042394015|GAGGGTTTCAGCATGGACAGG||MUC16|hg19|chr19|9091811|9091811|SILENT||SNP|G|G|A|g.chr19:9091811G>A|ENST00000397910.4|-|1|208|c.4C>T|c.(4-6)Ctg>Ttg|p.L2L|0.5286783042394015|GAGGGTTTCAGCATGGACAGG|IGR_ANNOTATON_%3B_IGR_ANNOTATON||hg19|chr19|9091811|9091811|IGR||SNP|G|G|A|||+||||||0.5286783042394015|GAGGGTTTCAGCATGGACAGG|||hg19|chr19|9091811|9091811|IGR||SNP|G|G|A|||+||||||0.5286783042394015|GAGGGTTTCAGCATGGACAGG||MUC16|hg19|chr19|9091811|9091811|SILENT||SNP|G|G|A|g.chr19:9091811G>A|ENST00000397910.4|-|1|208|c.4C>T|c.(4-6)Ctg>Ttg|p.L2L|0.5286783042394015|GAGGGTTTCAGCATGGACAGG|IGR_ANNOTATON_%3B_IGR_ANNOTATON; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4810:122,error,error,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4810,2,['error'],['error']
Availability,- Deprecated FuncotatorUtils.getCodingSequence (until its fixed).; - Added a more descriptive error message when the reference does not contain sequence information for a given position.; - Fixed all args to be kabob case.; - Fixed high-level Funcotator documentation. Fixes #4021,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4063:94,error,error,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4063,1,['error'],['error']
Availability,- Error that was missed in testing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4045:2,Error,Error,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4045,1,['Error'],['Error']
Availability,- For support and documentation go to https://software.broadinstitute.org/gatk/; 18:04:27.246 INFO CNNScoreVariants - Executing as platon@platon-VivoBook-ASUSLaptop-X712FA-X712FA on Linux v5.4.0-42-generic amd64; 18:04:27.246 INFO CNNScoreVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 18:04:27.247 INFO CNNScoreVariants - Start Date/Time: 26  2020 . 18:04:27 MSK; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Version: 2.23.0; 18:04:27.247 INFO CNNScoreVariants - Picard Version: 2.22.8; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:04:27.247 INFO CNNScoreVariants - Deflater: IntelDeflater; 18:04:27.247 INFO CNNScoreVariants - Inflater: IntelInflater; 18:04:27.247 INFO CNNScoreVariants - GCS max retries/reopens: 20; 18:04:27.247 INFO CNNScoreVariants - Requester pays: disabled; 18:04:27.247 INFO CNNScoreVariants - Initializing engine; 18:04:27.481 INFO CNNScoreVariants - Shutting down engine; [26  2020 . 18:04:27 MSK] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=362807296; ***********************************************************************. A USER ERROR has occurred: Couldn't read file file:///dev/stdin. Error was: It isn't a regular file. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6749:3108,down,down,3108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749,3,"['ERROR', 'Error', 'down']","['ERROR', 'Error', 'down']"
Availability,"- I sneaked in another change where I pass in a single file containing a list of input_vcfs instead of an array of input_vcfs. I made this because Terra couldn't save my inputs when I passed in 700 samples.; - Most of the logic was moved into `CreateTables`, including the determination for what files to load. It would have been cleaner to move all of the file loading logic into `LoadTable` but the current approach cuts down the on the number of `gsutil ls` calls made and more importantly, only spins up a shard if there are files to load.; - I pushed the logic into a separate workflow because I wanted to refactor it as two tasks and I couldn't find a way to get a Task to call another Task without wrapping it in a workflow.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7056:423,down,down,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7056,1,['down'],['down']
Availability,"- Loading libgkl_pairhmm.dylib from jar:file:/Users/loeblabm11/bioinformatics/programs/GATK/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib; 12:18:12.368 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 12:18:12.368 WARN IntelPairHmm - Ignoring request for 4 threads; not using OpenMP implementation; 12:18:12.369 INFO PairHMM - Using the AVX-accelerated native PairHMM implementation; 12:18:12.403 INFO ProgressMeter - Starting traversal; 12:18:12.403 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 12:18:22.403 INFO ProgressMeter - chr1:75065650 0.2 250240 1501440.0; 12:18:29.713 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.009098343; 12:18:29.713 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.121747383; 12:18:29.713 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.42 sec; 12:18:29.763 INFO Mutect2 - Shutting down engine; [April 11, 2018 12:18:29 PM PDT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.31 minutes.; Runtime.totalMemory()=1781006336; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.utils.locusiterator.ReadStateManager.readStartsAtCurrentPosition(ReadStateManager.java:132); 	at org.broadinstitute.hellbender.utils.locusiterator.ReadStateManager.collectPendingReads(ReadStateManager.java:159); 	at org.broadinstitute.hellbender.utils.locusiterator.LocusIteratorByState.lazyLoadNextAlignmentContext(LocusIteratorByState.java:315); 	at org.broadinstitute.hellbender.utils.locusiterator.LocusIteratorByState.hasNext(LocusIteratorByState.java:252); 	at org.broadinstitute.hellbender.utils.locusiterator.IntervalAlignmentContextIterator.advanceAlignmentContext(IntervalAlignmentContextIterator.java:104); 	at org.broadinstitute.hellbender.utils.locusiterator.IntervalAlignmentContextIterator.advanceAlignmentContextToCurrentInterval(IntervalAlignmentContextI",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665:4069,down,down,4069,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665,1,['down'],['down']
Availability,- M2 WDL will now default to having the orientation bias filter (`FilterByOrientationBias`) turned on. Closes #5016 ; - Empty artifact modes parameter will no longer cause failure in `FilterByOrientationBias`. Instead the task `FilterByOrientationBias` will not run. Closes #5025,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5019:172,failure,failure,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5019,1,['failure'],['failure']
Availability,- Modified the files so that we can build libVectorLoglessPairHMM.so on Ubuntu/ppc64le platform; - Restored and modified the files for 128-bit vector that are on GATK3; - Added a new file to replace AVX with POWER8 vector instructions; - [Question] Is any unit test included in the repository to test the library?; - Confirmed that the library was built on Ubuntu 15.10/ppc64le. ```; ./gradlew installAll; :downloadGsaLibFile UP-TO-DATE; :extractIntelDeflater; :compileJava; :processResources; :classes; :compileVectorLoglessPairHMMSharedLibraryVectorLoglessPairHMMCpp; :linkVectorLoglessPairHMMSharedLibrary; :copySharedLib; :jar; :startScripts; :installDist; :sparkJar; :installSpark; :installAll. BUILD SUCCESSFUL; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748:407,down,downloadGsaLibFile,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748,1,['down'],['downloadGsaLibFile']
Availability,- Moved `OutputSortingBuffer` class used by `SVCluster` into `SVClusterEngine` to unify clustering code across tools; - Fixes an issue where no-call genotypes caused an error in `JointGermlineCNVSegmentation`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7779:169,error,error,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7779,1,['error'],['error']
Availability,- Now will count downloads of all artifacts in github releases instead of just the first one.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8418:17,down,downloads,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8418,1,['down'],['downloads']
Availability,"- Processing 29268134 bp from intervals; 19:13:26.834 WARN IndexUtils - Feature file ""/cga/bass/Chunyang/ref/hg19/1000G_phase1.snps.high_confidence.b37.vcf.gz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 19:13:26.973 INFO ASEReadCounter - Done initializing engine; 19:13:26.977 INFO ProgressMeter - Starting traversal; 19:13:26.977 INFO ProgressMeter - Current Locus Elapsed Minutes Loci Processed Loci/Minute; 19:13:27.118 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:835092; 19:13:27.118 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:835132; 19:13:27.118 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:835133; ... ; ...; ...; 19:13:28.229 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:29617944; 19:13:28.230 WARN ASEReadCounter - Ignoring site: variant is not het at postion: 1:29618025; 19:13:28.231 INFO ASEReadCounter - 0 read(s) filtered by: ValidAlignmentStartReadFilter; 0 read(s) filtered by: ValidAlignmentEndReadFilter; 0 read(s) filtered by: HasReadGroupReadFilter; 0 read(s) filtered by: MatchingBasesAndQualsReadFilter; 0 read(s) filtered by: SeqIsStoredReadFilter; 51 read(s) filtered by: NotDuplicateReadFilter; 63 read(s) filtered by: NotSecondaryAlignmentReadFilter; 3 read(s) filtered by: MappedReadFilter; 117 total reads filtered; 19:13:28.231 INFO ProgressMeter - 1:29618022 0.0 110019 5264067.0; 19:13:28.231 INFO ProgressMeter - Traversal complete. Processed 110019 total loci in 0.0 minutes.; 19:13:28.233 INFO ASEReadCounter - Shutting down engine; [June 14, 2021 7:13:28 PM UTC] org.broadinstitute.hellbender.tools.walkers.rnaseq.ASEReadCounter done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2303197184; ; . output.txt:. contig position variantID refAllele altAllele refCount altCount totalCount lowMAPQDepth lowBaseQDepth rawDepth otherBases improperPairs. . Thanks for your help!. Chunyang",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7314:4993,down,down,4993,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7314,1,['down'],['down']
Availability,"- Reference allele is too long (209) at position chr1:10238; skipping that record. Set --max-indel-length >= 209; 12:55:32.500 INFO LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10254; skipping that record. Set --max-indel-length >= 204; 12:55:32.502 INFO LeftAlignAndTrimVariants - Reference allele is too long (207) at position chr1:10276; skipping that record. Set --max-indel-length >= 207; 12:55:32.536 INFO ProgressMeter - unmapped 0.0 295 178787.9; 12:55:32.536 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 12:55:32.536 INFO LeftAlignAndTrimVariants - 133 variants trimmed; 12:55:32.536 INFO LeftAlignAndTrimVariants - 10 variants skipped because the reference allele was too long. The longest had a reference allele length of 245. To not skip these variants set --max-indel-length >= 245; 12:55:32.536 INFO LeftAlignAndTrimVariants - 0 variants left aligned; 12:55:32.542 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 12:55:32 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Docume",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:5546,down,down,5546,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,1,['down'],['down']
Availability,- Relaxes restrictions for allowed samples in SVConcordance: the tool can now accept eval/truth VCFs with arbitrary sample sets and will have genotype concordance metrics computed on the intersection of the sample sets. All available samples are still used for AF/AC annotations. Integration tests added for cases when the samples sets are overlapping but not equal.; - Small additional improvements for sites-only VCFs: concordance annotations will now be `.` instead of `NaN` for example. Integration test added for this case.; - Improved behavior for eval AF annotations: these will not be recalculated if they already exist.; - Improved behavior for truth AF annotations: these will now only be recalculated if they don't exist in the input truth VCF.; - Updated tool doc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8211:224,avail,available,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8211,1,['avail'],['available']
Availability,"- Released new data sources to google bucket and FTP site for both somatic and germline (clinical pipeline); - Updated data source download URL to point to the bucket for v1.6.20190124; - Updated minimum version of data sources to v1.6.20190124. With the release and these changes, the following issues are addressed:. Fixes #5259 ; Fixes #5428 ; Fixes #5429",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5614:131,down,download,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5614,1,['down'],['download']
Availability,"- Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandle",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8993,AVAIL,AVAILABLE,8993,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"- Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8600,AVAIL,AVAILABLE,8600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"- Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8732,AVAIL,AVAILABLE,8732,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,- Updated data sources to include variant sites for symbolic alleles.; - Fixed tests to be correct for new logic.; - Now has tests for symbollic alternate alleles and masked alleles. Fixes #5402,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5406:167,mask,masked,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5406,1,['mask'],['masked']
Availability,- Using codec VCFCodec to read file file:///SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/20221123.hs38me.NTS299.ultrares/work/34/f4[0/1667]a7bb49eaece47a172e2d/TMP/jeter.vcf.gz ; 18:15:23.374 WARN IntelInflater - Zero Bytes Written : 0 ; 18:15:23.385 WARN IntelInflater - Zero Bytes Written : 0 ; 18:15:23.403 INFO IntervalArgumentCollection - Processing 1028 bp from intervals ; 18:15:23.411 INFO HaplotypeCaller - Done initializing engine ; 18:15:23.430 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/LAB-DATA/BiRD/users/lindenbaum-p/packages/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so ; 18:15:23.475 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/LAB-DATA/BiRD/users/lindenbaum-p/packages/gatk/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so ; 18:15:23.651 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM ; 18:15:23.651 INFO IntelPairHmm - Available threads: 4 ; 18:15:23.651 INFO IntelPairHmm - Requested threads: 4 ; 18:15:23.651 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation ; 18:15:23.671 INFO ProgressMeter - Starting traversal ; 18:15:23.671 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute ; 18:15:26.788 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position chr1:30191420 and possibly subsequent; at least 10 samples must have called genotypes ; 18:15:27.190 WARN DepthPerSampleHC - Annotation will not be calculated at position chr1:30477350 and possibly subsequent; genotype for sample B00I9EL is not called; 18:15:35.547 INFO ProgressMeter - chr1:32128426 0.2 40 202.1 ; 18:15:48.416 INFO ProgressMeter - chr1:36398656 0.4 80 194.0 ; 18:15:51.025 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.012874514 ; 18:15:51.026 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5.818477527000001; 18:1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8106:4949,Avail,Available,4949,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8106,1,['Avail'],['Available']
Availability,"- added custom classes `ExtractCohortRecord` and `ExtractCohortFilterRecord` that implement `Locatable`; - refactored attribute building from these records; - now that the records are `Locatable`s, can use `OverlapDetector` to filter locations down to only desired intervals (including excluded sites); - removed queryMode `QUERY` and associated querying from options",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7181:244,down,down,244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7181,1,['down'],['down']
Availability,"- chrM:8920 58.4 62766000 1073951.1 ; ; 12:07:04.855 INFO ProgressMeter - chrM:9385 58.6 62814000 1071582.7 ; ; 12:07:14.867 INFO ProgressMeter - chrM:10083 58.8 62865000 1069408.5 ; ; 12:07:24.914 INFO ProgressMeter - chrM:10943 59.0 62904000 1067032.5 ; ; 12:07:34.942 INFO ProgressMeter - chrX:12975129 59.1 63028000 1066113.4 ; ; 12:07:44.971 INFO ProgressMeter - chrX:41349821 59.3 63179000 1065654.6 ; ; 12:07:54.982 INFO ProgressMeter - chrX:48923158 59.5 63296000 1064631.8 ; ; 12:08:05.013 INFO ProgressMeter - chrX:68535195 59.6 63444000 1064128.8 ; ; 12:08:15.047 INFO ProgressMeter - chrX:102632989 59.8 63592000 1063627.8 ; ; 12:08:25.159 INFO ProgressMeter - chrX:111294586 60.0 63723000 1062822.9 ; ; 12:08:35.207 INFO ProgressMeter - chrX:129516349 60.1 63932000 1063338.7 ; ; 12:08:45.361 INFO ProgressMeter - chrX:153743608 60.3 64037000 1062095.6 ; ; 12:08:56.075 INFO ProgressMeter - chrY:302910 60.5 64182000 1061357.1 ; ; 12:13:04.075 INFO SplitNCigarReads - Shutting down engine ; ; \[August 19, 2020 12:13:04 PM CEST\] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 64.67 minutes. ; ; Runtime.totalMemory()=11648630784 ; ; java.lang.IllegalArgumentException: contig must be non-null and not equal to \*, and start must be >= 1 ; ; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setMatePosition(SAMRecordToGATKReadAdapter.java:197) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.setPredictedMateInformation(OverhangFixingManager.java:445) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.splitNCigarRead(SplitNCigarReads.java:212) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.lambda$traverseReads$1(SplitNCigarReads.java:181) ; ; at org.broadinstitute.hellbender.engine.MultiplePassReadWalker.lambda$forEachRead$0(MultiplePassReadWalker.java:60) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6776:30972,down,down,30972,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776,1,['down'],['down']
Availability,- error message was not updated when arguments were changed....,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5969:2,error,error,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5969,1,['error'],['error']
Availability,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1144:2,error,error,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144,5,"['ERROR', 'avail', 'error']","['ERROR', 'available', 'error']"
Availability,- expanding unit tests to actually replicate the error if we have a regression.; - applied fix that sorts the output.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3795:49,error,error,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3795,1,['error'],['error']
Availability,- fixup for problem with fully specified `file:///` names that I introduced in #1450 ; - adding test for fully specified `file:///` url; - adding additional tests to `ReadSparkSink` for HDFS; - tests for writing to HDFS using `MiniDFSCluster`; - tests for overwriting existing HDFS paths; - fixed instance of Wrong FileSystem exception in `ReadSparkSink`; - refactored `ReadSparkSink` to remove duplication; - adding `MiniClusterUtils`; - revising existing code using `MiniDFSCluster` to go through `MiniClusterUtils`; - had to make the minicluster dependency a compile time instead of test dependency so downstream projects can make use of MiniClusterUtils.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1461:605,down,downstream,605,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1461,1,['down'],['downstream']
Availability,"- improved baits count annotator (""lazy"" post processing); - included bait counts as a multiplicative bias in TargetCoverageSexGenotypeCalculator; - improved info and warn log messages in TargetCoverageSexGenotyper; - interval exclusion via CLI args for TargetCoverageSexGenotyper; - soft target filtering using masks; - more extensive unit/integration tests for TargetCoverageSexGenotyper; - integration test for annotate targets w/ bait counts; - missing test resource files from gatk-protected repo; - address PR review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3183:312,mask,masks,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183,1,['mask'],['masks']
Availability,"- new ""lazy"" annotation mode in TargetAnnotator (a hack for generating annotations that can not be done with a state-less FeatureWalker); - baits count target annotation; - included bait count as a multiplicative bias in TargetCoverageSexGenotypeCalculator; - improved info and warn log messages in TargetCoverageSexGenotyper; - interval exclusion via CLI args for TargetCoverageSexGenotyper (PAR regions can not be blacklisted via CLI arguments); - soft target filtering using masks; - more extensive unit/integration tests for TargetCoverageSexGenotyper; - integration test for annotate targets w/ bait counts",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2813:478,mask,masks,478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2813,1,['mask'],['masks']
Availability,"- pid=225671 tid=225691 No valid combination operation found for INFO field AN - the field will NOT be part of INFO fields in the generated VCF records; 18:24:15.434 info NativeGenomicsDB - pid=225671 tid=225691 No valid combination operation found for INFO field FS - the field will NOT be part of INFO fields in the generated VCF records; 18:24:15.435 info NativeGenomicsDB - pid=225671 tid=225691 No valid combination operation found for INFO field QD - the field will NOT be part of INFO fields in the generated VCF records; 18:24:15.435 info NativeGenomicsDB - pid=225671 tid=225691 No valid combination operation found for INFO field SOR - the field will NOT be part of INFO fields in the generated VCF records; 18:24:22.489 INFO GenotypeGVCFs - Done initializing engine; 18:24:24.770 INFO ProgressMeter - Starting traversal; 18:24:24.771 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 18:25:30.829 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.055026962999999963,Cpu time(s),0.049579712000000026; [June 19, 2022 6:25:30 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.35 minutes.; Runtime.totalMemory()=3063414784; java.lang.IllegalStateException: Genotype has no likelihoods: [10 G/G GQ 15 DP 5]; 	at org.broadinstitute.hellbender.utils.GenotypeUtils.computeDiploidGenotypeCounts(GenotypeUtils.java:89); 	at org.broadinstitute.hellbender.tools.walkers.annotator.ExcessHet.calculateEH(ExcessHet.java:96); 	at org.broadinstitute.hellbender.tools.walkers.annotator.ExcessHet.annotate(ExcessHet.java:84); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.addInfoAnnotations(VariantAnnotatorEngine.java:355); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:334); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1159695894:4331,down,down,4331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1159695894,1,['down'],['down']
Availability,"- reduced retries for task calling write API because if it fails more than once, chances are it will continue to fail because the import process was stopped before completion; - hopefully made the error message less scary, also included table number for easier cleanup. Closes https://broadworkbench.atlassian.net/browse/VS-267",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7680:197,error,error,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7680,1,['error'],['error']
Availability,"- version; GATK4.2.6.1. Hi, ; When I use the following command to genotype a single g vcf file, the output **alt depth**(ref depth is ok) in the FORMAT column ; are missing. ```; gatk GenotypeGVCFs -R ucsc.hg19.fasta -verbosity ERROR -all-sites true -stand-call-conf 0 --dbsnp dbsnp_138.hg19.vcf -V 0003.g.vcf -O 0003.4.2.6.1.vcf ; ```; For example, `AD:DP 2,1013:1116`, `1116` is for the total depth(DP), and `2,1013` is for the ref depth, however, the **alt allele depth** is missing. is this a bug? Or did I miss something?. ```; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">. #input ; chr19	45923653	.	A	G,<NON_REF>	31988.06	.	BaseQRankSum=-1.361;DP=1149;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;MQRankSum=0.000;RAW_MQandDP=4136400,1149;ReadPosRankSum=-1.250	GT:AD:DP:GQ:PL:SB	1/1:2,1013,101:1116:99:32002,2966,0,32008,3040,32082:1,1,538,576. #output ; chr19	45923653	rs11615	A	G	31988.06	.	AC=2;AF=1.00;AN=2;BaseQRankSum=-1.361e+00;DB;DP=1149;ExcessHet=0.0000;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;MQRankSum=0.00;QD=31.52;ReadPosRankSum=-1.250e+00;SOR=0.764	GT:AD:DP:GQ:PL	1/1:2,1013:1116:99:32002,2966,0. ```; Best,; xiucz",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7980:228,ERROR,ERROR,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7980,1,['ERROR'],['ERROR']
Availability,"---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No ove",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:2630,ERROR,ERROR,2630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,3,['ERROR'],['ERROR']
Availability,"------------------------------------------------------------------------------------------------; A USER ERROR has occurred: Traversal by intervals was requested but some input files are not indexed.; Please index all input files:. samtools index /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; --------------------------------------------------------------------------------------------------------------------. This was weird since I set a correct index file as an input, but after some investigation, I realized that ; the error seemed to be occurring when the bucket path where BAM index was located was different from that of BAM file ; For example, if you look at this log below, . `Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam to /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!; 2021/09/29 15:46:14 Localizing input drs://dg.4DFC:ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1 -> /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Requester Pays project ID is Some(vanallen-firecloud-nih); Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai to /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!`. C345.TCGA-A3-3373-11A-01D-1421-08.5.bam and C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; were successfully downloaded, but since these TCGA files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487:1297,down,download,1297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487,1,['down'],['download']
Availability,----------------------------------------------------------; 16:46:04.318 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.320 INFO VariantsToTable - HTSJDK Version: 2.23.0; 16:46:04.320 INFO VariantsToTable - Picard Version: 2.23.3; 16:46:04.320 INFO VariantsToTable - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:46:04.321 INFO VariantsToTable - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:46:04.321 INFO VariantsToTable - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:46:04.321 INFO VariantsToTable - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:46:04.321 INFO VariantsToTable - Deflater: IntelDeflater; 16:46:04.322 INFO VariantsToTable - Inflater: IntelInflater; 16:46:04.322 INFO VariantsToTable - GCS max retries/reopens: 20; 16:46:04.322 INFO VariantsToTable - Requester pays: disabled; 16:46:04.322 INFO VariantsToTable - Initializing engine; 16:46:04.805 INFO FeatureManager - Using codec VCFCodec to read file file:///home/india/Downloads/Galaxy57-%5BMerged_file.vcf%5D.vcf; 16:46:04.896 INFO VariantsToTable - Done initializing engine; 16:46:04.917 WARN VariantsToTable - Allele-specific fields will only be split if splitting multi-allelic variants is specified (`--split-multi-allelic` or `-SMA`; 16:46:04.918 INFO ProgressMeter - Starting traversal; 16:46:04.918 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 16:46:05.217 INFO VariantsToTable - Shutting down engine; [16 October 2020 at 4:46:05 PM IST] org.broadinstitute.hellbender.tools.walkers.variantutils.VariantsToTable done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=132120576; htsjdk.tribble.TribbleException: partial missing values for GL field; 	at htsjdk.variant.variantcontext.GenotypeLikelihoods.parseDeprecatedGLString(GenotypeLikelihoods.java:269); 	at htsjdk.variant.variantcontext.GenotypeLikelihoods.fromGLField(GenotypeLikelihoods.java:78); 	at htsjdk.variant.vcf.AbstractVCFCodec.cre,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6897:3016,Down,Downloads,3016,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897,1,['Down'],['Downloads']
Availability,"---------------------------------------------------; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Version: 2.13.2; 01:13:16.077 INFO HaplotypeCaller - Picard Version: 2.17.2; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 01:13:16.078 INFO HaplotypeCaller - Deflater: IntelDeflater; 01:13:16.078 INFO HaplotypeCaller - Inflater: IntelInflater; 01:13:16.078 INFO HaplotypeCaller - GCS max retries/reopens: 20; 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 01:13:16.078 INFO HaplotypeCaller - Initializing engine; 01:13:17.087 INFO HaplotypeCaller - Shutting down engine; [January 18, 2020 1:13:17 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2216689664; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); 	at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:621); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:563); 	at org.bro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-575601220:2030,down,down,2030,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-575601220,1,['down'],['down']
Availability,"---------------------------------------------------; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Version: 2.13.2; 01:13:16.077 INFO HaplotypeCaller - Picard Version: 2.17.2; 01:13:16.077 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 01:13:16.078 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 01:13:16.078 INFO HaplotypeCaller - Deflater: IntelDeflater; 01:13:16.078 INFO HaplotypeCaller - Inflater: IntelInflater; 01:13:16.078 INFO HaplotypeCaller - GCS max retries/reopens: 20; 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 01:13:16.078 INFO HaplotypeCaller - Initializing engine; 01:13:17.087 INFO HaplotypeCaller - Shutting down engine; [January 18, 2020 1:13:17 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2216689664; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:621); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:563); at org.broadinstit",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6384:2030,down,down,2030,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6384,1,['down'],['down']
Availability,"---------------------------------------------; 21:21:12.544 INFO GermlineCNVCaller - ------------------------------------------------------------; 21:21:12.544 INFO GermlineCNVCaller - HTSJDK Version: 2.21.0; 21:21:12.544 INFO GermlineCNVCaller - Picard Version: 2.21.2; 21:21:12.544 INFO GermlineCNVCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 21:21:12.544 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 21:21:12.544 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 21:21:12.545 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 21:21:12.545 INFO GermlineCNVCaller - Deflater: IntelDeflater; 21:21:12.545 INFO GermlineCNVCaller - Inflater: IntelInflater; 21:21:12.545 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 21:21:12.545 INFO GermlineCNVCaller - Requester pays: disabled; 21:21:12.545 INFO GermlineCNVCaller - Initializing engine; 21:21:14.339 INFO GermlineCNVCaller - Shutting down engine; [February 23, 2020 9:21:14 PM EST] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=281542656; java.lang.RuntimeException: A required Python package (""gcnvkernel"") could not be imported into the Python environment. This tool requires that the GATK Python environment is properly established and activated. Please refer to GATK README.md file for instructions on setting up the GATK Python environment.; 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:205); 	at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.onStartup(GermlineCNVCaller.java:286); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6467:2966,down,down,2966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6467,1,['down'],['down']
Availability,"-------------------------------------------; 16:26:35.422 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 16:26:35.423 INFO GenotypeGVCFs - Picard Version: 2.22.8; 16:26:35.423 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:26:35.423 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:26:35.426 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:26:35.426 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:26:35.427 INFO GenotypeGVCFs - Deflater: IntelDeflater; 16:26:35.427 INFO GenotypeGVCFs - Inflater: IntelInflater; 16:26:35.427 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 16:26:35.427 INFO GenotypeGVCFs - Requester pays: disabled; 16:26:35.427 INFO GenotypeGVCFs - Initializing engine; 16:26:37.201 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading MBR failed.; 16:26:39.459 INFO GenotypeGVCFs - Shutting down engine; [January 6, 2021 4:26:39 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=2303197184; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; [ccastane9@andersserver-01 GenomicsDB]$ bash *_genotype.3.sh; Using GATK jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Xmx16g -jar /data1/_software/gatk-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402:3030,Error,Error,3030,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402,1,['Error'],['Error']
Availability,"-------------------------------------------; 16:27:54.145 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 16:27:54.145 INFO GenotypeGVCFs - Picard Version: 2.22.8; 16:27:54.145 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:27:54.145 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:27:54.145 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:27:54.146 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:27:54.146 INFO GenotypeGVCFs - Deflater: IntelDeflater; 16:27:54.146 INFO GenotypeGVCFs - Inflater: IntelInflater; 16:27:54.146 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 16:27:54.146 INFO GenotypeGVCFs - Requester pays: disabled; 16:27:54.146 INFO GenotypeGVCFs - Initializing engine; 16:27:55.873 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading MBR failed.; 16:27:58.483 INFO GenotypeGVCFs - Shutting down engine; [January 6, 2021 4:27:58 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=2231894016; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402:6385,Error,Error,6385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402,1,['Error'],['Error']
Availability,"-------------------------------------------; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 21:16:35.498 INFO GenotypeGVCFs - Picard Version: 2.22.8; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 21:16:35.498 INFO GenotypeGVCFs - Deflater: IntelDeflater; 21:16:35.499 INFO GenotypeGVCFs - Inflater: IntelInflater; 21:16:35.499 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 21:16:35.499 INFO GenotypeGVCFs - Requester pays: disabled; 21:16:35.499 INFO GenotypeGVCFs - Initializing engine; 21:16:36.737 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading MBR failed.; 21:16:38.472 INFO GenotypeGVCFs - Shutting down engine; [January 17, 2021 9:16:38 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2551709696; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-761953839:4498,Error,Error,4498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-761953839,1,['Error'],['Error']
Availability,"---------------------------------------; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 13:56:52.187 INFO GenotypeGVCFs - Picard Version: 2.22.8; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:3198,Error,Error,3198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,1,['Error'],['Error']
Availability,"-------------------------------------; 15:38:00.019 INFO GenotypeGVCFs - HTSJDK Version: 3.0.1; 15:38:00.019 INFO GenotypeGVCFs - Picard Version: 2.27.5; 15:38:00.019 INFO GenotypeGVCFs - Built for Spark Version: 2.4.5; 15:38:00.019 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:38:00.019 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:38:00.020 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:38:00.020 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:38:00.020 INFO GenotypeGVCFs - Deflater: IntelDeflater; 15:38:00.020 INFO GenotypeGVCFs - Inflater: IntelInflater; 15:38:00.020 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 15:38:00.020 INFO GenotypeGVCFs - Requester pays: disabled; 15:38:00.020 INFO GenotypeGVCFs - Initializing engine; 15:38:00.590 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.4.3-6069e4a; 15:38:00.652 INFO GenotypeGVCFs - Shutting down engine; [March 14, 2023 3:38:00 PM CET] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2326265856; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:463); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:365); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:319); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:291); at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); at or",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1468228918:2913,down,down,2913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1468228918,1,['down'],['down']
Availability,"---------------------------------; 23:41:16.953 INFO ApplyBQSR - HTSJDK Version: 2.21.2; 23:41:16.953 INFO ApplyBQSR - Picard Version: 2.21.9; 23:41:16.953 INFO ApplyBQSR - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:41:16.953 INFO ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:41:16.953 INFO ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 23:41:16.953 INFO ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:41:16.953 INFO ApplyBQSR - Deflater: IntelDeflater; 23:41:16.953 INFO ApplyBQSR - Inflater: IntelInflater; 23:41:16.953 INFO ApplyBQSR - GCS max retries/reopens: 20; 23:41:16.953 INFO ApplyBQSR - Requester pays: disabled; 23:41:16.953 INFO ApplyBQSR - Initializing engine; 23:41:17.460 INFO ApplyBQSR - Done initializing engine; 23:41:17.527 INFO ProgressMeter - Starting traversal; 23:41:17.527 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 23:41:17.849 INFO ApplyBQSR - Shutting down engine; [February 26, 2020 11:41:17 PM EST] org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSR done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2411724800; java.lang.IllegalStateException: The covariates table is missing ReadGroup S3_2 in RecalTable0; 	at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:752); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.keyForReadGroup(ReadGroupCovariate.java:81); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.recordValues(ReadGroupCovariate.java:53); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.StandardCovariateList.recordAllValuesInStorage(StandardCovariateList.java:133); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527); 	at org.broadinstitute.hellbender.transformers.BQSRReadTr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6242#issuecomment-592005237:7326,down,down,7326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6242#issuecomment-592005237,1,['down'],['down']
Availability,"------------------------------. This was weird since I set a correct index file as an input, but after some investigation, I realized that ; the error seemed to be occurring when the bucket path where BAM index was located was different from that of BAM file ; For example, if you look at this log below, . `Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam to /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!; 2021/09/29 15:46:14 Localizing input drs://dg.4DFC:ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1 -> /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Requester Pays project ID is Some(vanallen-firecloud-nih); Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai to /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!`. C345.TCGA-A3-3373-11A-01D-1421-08.5.bam and C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; were successfully downloaded, but since these TCGA files use DRS URI, they were copied to two separate cromwell folders. /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai. And GATK doesn't seem to recognize BAM index when it is not inside a same folder. ; Could you maybe add symlink for the BAM and BAI files in the WDL script? . Tha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487:1705,down,download,1705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487,1,['down'],['download']
Availability,"----------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_20050601_V5.2, LmjF08_01_20050601_V5.2, LmjF09_01_20050601_V5.2, LmjF06_01_20050601_V5.2, LmjF12_01_20050601_V5.2, LmjF16_01_20050601_V5.2, LmjF17_01_20050601_V5.2, LmjF20_01_20050601_V5.2, LmjF22_01_20050601_V5.2, LmjF26_01_20050601_V5.2]; ##### ERROR reference contigs = [LmjLV39_01, L",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:3677,Error,Error,3677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['Error'],['Error']
Availability,"--------------------------; 13:56:52.186 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 13:56:52.187 INFO GenotypeGVCFs - Picard Version: 2.22.8; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:3120,Error,Error,3120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,1,['Error'],['Error']
Availability,"--------------------------; 16:26:35.421 INFO GenotypeGVCFs - ------------------------------------------------------------; 16:26:35.422 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 16:26:35.423 INFO GenotypeGVCFs - Picard Version: 2.22.8; 16:26:35.423 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:26:35.423 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:26:35.426 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:26:35.426 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:26:35.427 INFO GenotypeGVCFs - Deflater: IntelDeflater; 16:26:35.427 INFO GenotypeGVCFs - Inflater: IntelInflater; 16:26:35.427 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 16:26:35.427 INFO GenotypeGVCFs - Requester pays: disabled; 16:26:35.427 INFO GenotypeGVCFs - Initializing engine; 16:26:37.201 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading MBR failed.; 16:26:39.459 INFO GenotypeGVCFs - Shutting down engine; [January 6, 2021 4:26:39 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=2303197184; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; [ccastane9@andersserver-01 GenomicsDB]$ bash *_genotype.3.sh; Using GATK jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402:2952,Error,Error,2952,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402,1,['Error'],['Error']
Availability,"--------------------------; 16:27:54.144 INFO GenotypeGVCFs - ------------------------------------------------------------; 16:27:54.145 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 16:27:54.145 INFO GenotypeGVCFs - Picard Version: 2.22.8; 16:27:54.145 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:27:54.145 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:27:54.145 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:27:54.146 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:27:54.146 INFO GenotypeGVCFs - Deflater: IntelDeflater; 16:27:54.146 INFO GenotypeGVCFs - Inflater: IntelInflater; 16:27:54.146 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 16:27:54.146 INFO GenotypeGVCFs - Requester pays: disabled; 16:27:54.146 INFO GenotypeGVCFs - Initializing engine; 16:27:55.873 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading MBR failed.; 16:27:58.483 INFO GenotypeGVCFs - Shutting down engine; [January 6, 2021 4:27:58 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=2231894016; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402:6307,Error,Error,6307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402,1,['Error'],['Error']
Availability,"--------------------------; 21:16:35.497 INFO GenotypeGVCFs - ------------------------------------------------------------; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 21:16:35.498 INFO GenotypeGVCFs - Picard Version: 2.22.8; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 21:16:35.498 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 21:16:35.498 INFO GenotypeGVCFs - Deflater: IntelDeflater; 21:16:35.499 INFO GenotypeGVCFs - Inflater: IntelInflater; 21:16:35.499 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 21:16:35.499 INFO GenotypeGVCFs - Requester pays: disabled; 21:16:35.499 INFO GenotypeGVCFs - Initializing engine; 21:16:36.737 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading MBR failed.; 21:16:38.472 INFO GenotypeGVCFs - Shutting down engine; [January 17, 2021 9:16:38 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2551709696; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-761953839:4420,Error,Error,4420,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-761953839,1,['Error'],['Error']
Availability,"----------------. This was weird since I set a correct index file as an input, but after some investigation, I realized that ; the error seemed to be occurring when the bucket path where BAM index was located was different from that of BAM file ; For example, if you look at this log below, . `Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam to /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!; 2021/09/29 15:46:14 Localizing input drs://dg.4DFC:ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1 -> /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Requester Pays project ID is Some(vanallen-firecloud-nih); Attempting to download gs://gdc-tcga-phs000178-controlled/KIRC/DNA/WXS/BI/ILLUMINA/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai to /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; Successfully activated service account; Will continue with download. Activated service account credentials for: [kd5mqbpsed8lzz0kyz9tvkht-3274@dcf-prod.iam.gserviceaccount.com]; Download complete!`. C345.TCGA-A3-3373-11A-01D-1421-08.5.bam and C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai; were successfully downloaded, but since these TCGA files use DRS URI, they were copied to two separate cromwell folders. /cromwell_root/dg.4DFC_3615e55e-6aa3-43e7-8d7b-6f2824071971/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam; /cromwell_root/dg.4DFC_ab4d57fa-bfff-4a48-bd96-f2866ecfe0e1/C345.TCGA-A3-3373-11A-01D-1421-08.5.bam.bai. And GATK doesn't seem to recognize BAM index when it is not inside a same folder. ; Could you maybe add symlink for the BAM and BAI files in the WDL script? . Thanks,; Seunghun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487:1985,down,download,1985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487,3,"['Down', 'down']","['Download', 'download', 'downloaded']"
Availability,----------------; 12:55:32.084 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 12:55:32.084 INFO LeftAlignAndTrimVariants - Picard Version: 2.18.7; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:55:32.084 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 12:55:32.084 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 12:55:32.084 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 12:55:32.084 INFO LeftAlignAndTrimVariants - Initializing engine; 12:55:32.275 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 12:55:32.361 INFO LeftAlignAndTrimVariants - Done initializing engine; 12:55:32.435 INFO ProgressMeter - Starting traversal; 12:55:32.436 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 12:55:32.488 INFO LeftAlignAndTrimVariants - Reference allele is too long (245) at position chr1:10146; skipping that record. Set --max-indel-length >= 245; 12:55:32.493 INFO LeftAlignAndTrimVariants - Reference allele is too long (225) at position chr1:10178; skipping that record. Set --max-indel-length >= 225; 12:55:32.495 INFO LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --max-indel-length >= 221; 12:55:32.496 INFO LeftAlignAndTrimVariants - Reference allele is too long (223) at position chr1:10218; skipping that record. Set --max-indel-length >= 223; 12:55:32.497 INFO LeftAlignAndTrimVariants - Reference allele is too long (212,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:3133,Down,Downloads,3133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,1,['Down'],['Downloads']
Availability,----------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 16:34:35.415 INFO LeftAlignAndTrimVariants - Picard Version: 2.18.7; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:34:35.415 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 16:34:35.415 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 16:34:35.415 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 16:34:35.415 INFO LeftAlignAndTrimVariants - Initializing engine; 16:34:35.646 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 16:34:35.732 INFO LeftAlignAndTrimVariants - Done initializing engine; 16:34:35.809 INFO ProgressMeter - Starting traversal; 16:34:35.809 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 16:34:35.866 INFO LeftAlignAndTrimVariants - Reference allele is too long (245) at position chr1:10146; skipping that record. Set --maxIndelSize >= 245; 16:34:35.872 INFO LeftAlignAndTrimVariants - Reference allele is too long (225) at position chr1:10178; skipping that record. Set --maxIndelSize >= 225; 16:34:35.874 INFO LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --maxIndelSize >= 221; 16:34:35.874 INFO LeftAlignAndTrimVariants - Reference allele is too long (223) at position chr1:10218; skipping that record. Set --maxIndelSize >= 223; 16:34:35.875 INFO LeftAlignAndTrimVariants - Reference allele is too long (212) at position ch,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:3190,Down,Downloads,3190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494,1,['Down'],['Downloads']
Availability,"----------------; 17:24:16.503 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 17:24:16.503 INFO LeftAlignAndTrimVariants - Picard Version: 2.18.7; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:24:16.503 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 17:24:16.503 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 17:24:16.503 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 17:24:16.503 INFO LeftAlignAndTrimVariants - Initializing engine; 17:24:16.738 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 17:24:16.829 INFO LeftAlignAndTrimVariants - Done initializing engine; 17:24:16.909 INFO ProgressMeter - Starting traversal; 17:24:16.910 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 17:24:17.021 INFO ProgressMeter - unmapped 0.0 295 160909.1; 17:24:17.021 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 17:24:17.027 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 5, 2018 5:24:17 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=246939648; Tool returned:; 0 variants left aligned; ```. md5; ```; WMCF9-CB5:shlee$ md5 zeta_snippet_leftalign_maxindelsize250_headless.txt; MD5 (zeta_snippet_leftalign_maxindelsize250_headless.txt) = 46f5fbb0613094c2ad489edb4e050f74; ```; Retains same number of records as original.; ```; chr1 10144 . T",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:3170,Down,Downloads,3170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543,1,['Down'],['Downloads']
Availability,"----------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 17:52:19.132 INFO LeftAlignAndTrimVariants - Picard Version: 2.18.7; 17:52:19.132 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:52:19.132 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:52:19.132 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:52:19.132 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:52:19.132 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 17:52:19.132 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 17:52:19.132 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 17:52:19.132 INFO LeftAlignAndTrimVariants - Initializing engine; 17:52:19.351 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 17:52:19.434 INFO LeftAlignAndTrimVariants - Done initializing engine; 17:52:19.514 INFO ProgressMeter - Starting traversal; 17:52:19.514 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 17:52:19.654 INFO ProgressMeter - unmapped 0.0 295 126428.6; 17:52:19.655 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 17:52:19.661 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 5, 2018 5:52:19 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=247463936; Tool returned:; 0 variants left aligned; WMCF9-CB5:shlee$ gzcat zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz | grep -v '##' | less; WMCF9-CB5:shlee$ gzcat zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz | grep -v '##' | wc -l; 448; WMCF9-CB5:shlee$ gzcat z",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:3271,Down,Downloads,3271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971,1,['Down'],['Downloads']
Availability,"------------; INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; INFO GenotypeGVCFs - Picard Version: 2.21.2; INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; INFO GenotypeGVCFs - Deflater: IntelDeflater; INFO GenotypeGVCFs - Inflater: IntelInflater; INFO GenotypeGVCFs - GCS max retries/reopens: 20; INFO GenotypeGVCFs - Requester pays: disabled; INFO GenotypeGVCFs - Initializing engine; ```. Run starts, a few variants are detected. Then It gets stuck in a region for about 30 minutes, and prints an out-of-memory error:. ```; INFO ProgressMeter - chrom2:4323711 0.3 2000 7859.6; INFO ProgressMeter - chrom2:4325583 0.6 3000 4753.5; INFO ProgressMeter - chrom2:4327262 0.8 4000 5010.5; INFO ProgressMeter - chrom2:4333146 1.1 7000 6493.1; INFO GenotypeGVCFs - Shutting down engine; ```. ```; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; at java.util.Arrays.copyOf(Arrays.java:3332); at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124); at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:448); at java.lang.StringBuilder.append(StringBuilder.java:136); at htsjdk.tribble.util.ParsingUtils.split(ParsingUtils.java:266); at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:375); at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:328); at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:48); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:70); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:181); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); at org.b",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574329688:2066,down,down,2066,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574329688,1,['down'],['down']
Availability,"-----------; 20:11:35.530 INFO CombineGVCFs - HTSJDK Version: 2.24.0; 20:11:35.530 INFO CombineGVCFs - Picard Version: 2.25.0; 20:11:35.530 INFO CombineGVCFs - Built for Spark Version: 2.4.5; 20:11:35.530 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 20:11:35.530 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 20:11:35.531 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 20:11:35.531 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 20:11:35.531 INFO CombineGVCFs - Deflater: IntelDeflater; 20:11:35.531 INFO CombineGVCFs - Inflater: IntelInflater; 20:11:35.531 INFO CombineGVCFs - GCS max retries/reopens: 20; 20:11:35.531 INFO CombineGVCFs - Requester pays: disabled; 20:11:35.531 INFO CombineGVCFs - Initializing engine; 20:11:35.957 INFO FeatureManager - Using codec VCFCodec to read file file:///fs/scratch/PHS0338/appz/elprep-v5.0.2/PA113.vcf.gz; 20:11:35.969 INFO CombineGVCFs - Shutting down engine; [June 13, 2021 8:11:35 PM GMT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=1772093440; ***********************************************************************; A USER ERROR has occurred: An index is required but was not found for file /fs/scratch/PHS0338/appz/elprep-v5.0.2/PA113.vcf.gz. Support for unindexed block-compressed files has been temporarily disabled. Try running IndexFeatureFile on the input. ***********************************************************************. Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; Using GATK jar /gatk/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.2.0.0-local.jar CombineGVCFs -R /users/PHS0338/jpac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7311:3587,down,down,3587,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7311,1,['down'],['down']
Availability,"---------; 14:39:24.082 INFO DetermineGermlineContigPloidy - HTSJDK Version: 2.18.2; 14:39:24.082 INFO DetermineGermlineContigPloidy - Picard Version: 2.18.25; 14:39:24.083 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:39:24.083 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:39:24.083 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:39:24.083 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:39:24.083 INFO DetermineGermlineContigPloidy - Deflater: IntelDeflater; 14:39:24.083 INFO DetermineGermlineContigPloidy - Inflater: IntelInflater; 14:39:24.083 INFO DetermineGermlineContigPloidy - GCS max retries/reopens: 20; 14:39:24.083 INFO DetermineGermlineContigPloidy - Requester pays: disabled; 14:39:24.083 INFO DetermineGermlineContigPloidy - Initializing engine; 14:39:26.111 INFO DetermineGermlineContigPloidy - Shutting down engine; [May 26, 2019 2:39:26 PM UTC] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=1511522304; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException:; python exited with 1; Command Line: python -c import gcnvkernel. Stdout:; Stderr: Traceback (most recent call last):; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configdefaults.py"", line 1738, in filter_compiledir; os.makedirs(path, 0o770) # read-write-execute for user and group; File ""/opt/miniconda/envs/gatk/lib/python3.6/os.py"", line 210, in makedirs; makedirs(head, mode, exist_ok); File ""/opt/miniconda/envs/gatk/lib/python3.6/os.py"", line 220, in makedirs; mkdir(name, mode); PermissionError: [Errno 13] Permission denied: '/root/.theano'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/miniconda/e",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081:2401,down,down,2401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081,1,['down'],['down']
Availability,"------; 16:46:49.699 INFO Mutect2 - HTSJDK Version: 2.15.1; 16:46:49.699 INFO Mutect2 - Picard Version: 2.18.2; 16:46:49.699 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:46:49.699 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:46:49.700 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:46:49.700 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:46:49.700 INFO Mutect2 - Deflater: IntelDeflater; 16:46:49.700 INFO Mutect2 - Inflater: IntelInflater; 16:46:49.700 INFO Mutect2 - GCS max retries/reopens: 20; 16:46:49.700 INFO Mutect2 - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 16:46:49.700 INFO Mutect2 - Initializing engine; 16:46:49.995 INFO FeatureManager - Using codec VCFCodec to read file file:///home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz; 16:46:50.064 INFO Mutect2 - Shutting down engine; [November 6, 2019 4:46:50 PM CST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2394947584; org.broadinstitute.hellbender.exceptions.GATKException: Error initializing feature reader for path /home/vip/data/Mutect2/af-only-gnomad.raw.sites.hg19.vcf.gz; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:357); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:308); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:255); 	at org.broadinstitute.hellbender.engine.FeatureManager.addToFeatureSources(FeatureManager.java:202); 	at org.broadinstitute.hellbender.engine.FeatureManager.initializeFeatureSources(FeatureManager.java:182); 	at org.broadinstitute.hellbender.engine.FeatureManager.<init>(FeatureManager.java:153); 	at org.broadinstitute.hellbender.engine.GATKTool.initializeFeature",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6248:2842,down,down,2842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6248,1,['down'],['down']
Availability,"----. ## Bug Report. ### Affected tool(s) or class(es); - GATK; - gcnvkernel ; - theano. ### Affected version(s); - GATK 4.1.0.0; - gcnvkernel 0.0.7; - theano 0.9.0; - GCC 7.3.0. ### Description ; I have installed the python package theano(which is a requirement of gcnvkernel) with python 3.6.6 which is compiled with gcc 7.3.0. I am not using the conda environment to install these packages.; Then i tried to run theano-nose, but is giving me the following error:. ```sh. $ theano-nose; --; ; You can find the C code in this temporary file: /tmp/theano_compilation_error_gp0ar1kx; library inux-gnu/7.3.0/crtbeginS.o: is not found.; library inux-gnu/7.3.0/crtbeginS.o: is not found.; library inux-gnu/7.3.0/crtbeginS.o(.text+0x1a): is not found.; library inux-gnu/7.3.0/crtbeginS.o(.text+0x6b): is not found.; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 81, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 105, in <module>; actual_version, force_compile, _need_reload)); ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""${INSTALLDIRGATK}/bin/theano-nose"", line 11, in <module>; load_entry_point('Theano==1.0.4', 'console_scripts', 'theano-nose')(); File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/bin/theano_nose.py"", line 207, in main; result = main_function(); File ""${INSTALLDIRGATK}/lib/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:459,error,error,459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['error'],['error']
Availability,"----. ## Bug Report. ### Affected tool(s) or class(es); - Tool/class name(s), special parameters: GenomicsDBImport. ### Affected version(s); - Version: gatk4-4.4.0.0-0. ### Description ; Hello,. I have been having an issue come up when utilizing `GenomicsDBImport`. This issue has happened when using a range of samples and shard counts (8 - 1000 samples, shard count of up to 2000). My current example is an attempt to joint call 1000 samples together. I will submit the jobs and 1-2 of the shards (of the ~100 concurrently running) will throw a `malloc(): unaligned tcache chunk detected`. When I resubmit that shard, it will usually rerun without a problem. Or if I kill all jobs and resubmit, a different shard will throw the malloc error. . I have run approximately 20 tests and I seem to get this failure 2/3 times. However, it only arises on the initial submission and not when additional jobs are submitted as previous shards complete. Please note that the 1000 samples have successfully been imported into the GenomicsDB but this error seems to persist somewhat randomly across multiple machines. . Thank you for your assistance! . #### Steps to reproduce. - Command used (omitting paths to 1000 samples for brevity) for one of the failed shards. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8g -jar /gpfs/gpfs_de6000/home/dalegre/miniconda3/envs/GOASTv4.0/share/gatk4-4.4.0.0-0/gatk-package-4.4.0.0-local.jar GenomicsDBImport -V [samples 1-1002] --genomicsdb-workspace-path results/jointcalling/genomicsDB/temp_0882_of_2000_DB --merge-input-intervals false --bypass-feature-reader --tmp-dir temp --max-num-intervals-to-import-in-parallel 10 --batch-size 50 --intervals results/germline/interval/temp_0882_of_2000/scattered.interval_list --genomicsdb-shared-posixfs-optimizations true; ```. #### Expected behavior; All shards are imported into the GenomicsDB successfu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8683:737,error,error,737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8683,2,"['error', 'failure']","['error', 'failure']"
Availability,----. ## Bug Report. ### Affected tool(s) or class(es); GATK LiftoverVcf. ### Affected version(s); gatk/4.1.7.0. ### Description . The LiftoverVcf generates the following error. The error occurs with SVs where the INFO/END is not also lifted over. This results in INFO/END before the site start position which triggers the error.; ```; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar LiftoverVcf -I b37/HG002_SVs_Tier1_v0.6.vcf.gz -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz -CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 10:20:35.165 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Sun Jul 26 10:20:35 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6725:171,error,error,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725,3,['error'],['error']
Availability,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:235,Error,Error,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,6,"['Error', 'error']","['Error', 'error']"
Availability,"----. ## Bug Report. ### Affected tool(s) or class(es); gatk CombineGVCFs. ### Affected version(s); - [v4.1.8.1]. ### Description ; When I am using CombineGVCFs to join the two raw_variants.vcf files derived from HaplotypeCaller, it throws an error: KEY END found in VariantContext field INFO at chr1:20094 but this key isn't defined in the VCFHeader. However, when I checked original files, there is no KEY END in INFO. #### Steps to reproduce; The command line I used is:; `~/biosoft/gatk-4.1.8.1/gatk --jave-options ""-Xmx30G"" CombineGVCFs -R ${REF} -V first_raw_variants.vcf -V second_variants.vcf -O cohort.g.vcf.gz`; In which, ${REF} refers to the human reference file. #### Expected behavior; It should return a combined gvcf file. #### Actual behavior; An error happened, as described in above. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7728:243,error,error,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7728,2,['error'],['error']
Availability,"----. ## Bug Report; Hi, I'm trying the CNV detection pipeline from GATK: https://gatk.broadinstitute.org/hc/en-us/categories/360002310591; However, when running the Determine Germline Contig Ploidy step, I stumble upon this error. Please guide me to solve this problem. ### Affected tool(s) or class(es); ```; gatk DetermineGermlineContigPloidy \; -L /home/nguyen/RB1/RB1.cohort.gc.filtered.interval_list \; --interval-merging-rule OVERLAPPING_ONLY \; -I ... (63 tsv files output from CollectReadCounts); ```. ### Affected version(s); - GATK 4.1.6.1; ### Description ; Full error log:; ```; Traceback (most recent call last):; File ""/tmp/cohort_determine_ploidy_and_depth.380621677219090732.py"", line 119, in <module>; ploidy_task.engage(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 339, in engage; converged_continuous = self._update_continuous_posteriors(); File ""/home/nguyen/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/tasks/inference_task_base.py"", line 395, in _update_continuous_posteriors; assert not np.isnan(loss), ""The optimization step for ELBO update returned a NaN""; AssertionError: The optimization step for ELBO update returned a NaN; 11:09:59.446 DEBUG ScriptExecutor - Result: 1; 11:09:59.447 INFO DetermineGermlineContigPloidy - Shutting down engine; [April 28, 2020 11:09:59 AM ICT] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=623902720; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/cohort_determine_ploidy_and_depth.380621677219090732.py --sample_coverage_metadata=/tmp/samples-by-coverage-per-contig8606344533091962323.tsv --output_calls_path=/home/nguyen/Exec/gatk-4.1.6.0/ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6573:225,error,error,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6573,2,['error'],['error']
Availability,"----; User Report; ----. We are also experiencing a problem wherein GATK 4.0.5.1 GenotypeGVCFs processes hang for many hours. . The last thing our processes logged was the same as reported here:; ```; 08:48:23.075 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.044110324,Cpu time(s),0.026897973000000006; ```. This particular job ran for about 3m before outputting this line, then stayed running (but apparently doing nothing) for 8 hours before we killed it. . It is one of 1996 jobs that all did pretty much exactly the same thing in a similar time frame - in all cases these were the last two lines logged but GATK failed to terminate afterwards. At the same time, we did have about 8k jobs finish successfully and exit 0, so it appears that the rate at which this happens is (at least for our workload) is around 20%. Don't know yet whether or not this behaviour is deterministic. More on that later. . This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/50019#Comment_50019",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4973:244,down,down,244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4973,1,['down'],['down']
Availability,"--denoised-copy-ratios` and `--allelic-counts` arguments, e.g.:. ```; gatk ModelSegments ; --normal-allelic-counts normal.allelicCounts.tsv (this is only used for het genotyping); --denoised-copy-ratios normal.denoisedCR.tsv; --denoised-copy-ratios tumor-1.denoisedCR.tsv; ...; --denoised-copy-ratios tumor-N.denoisedCR.tsv; --allelic-counts normal.allelicCounts.tsv; --allelic-counts tumor-1.allelicCounts.tsv; ...; --allelic-counts tumor-N.allelicCounts.tsv \; -O .; --output-prefix joint-segmentation; ```. This will perform both het genotyping and joint segmentation, but will yield a Picard interval-list `joint-segmentation.interval_list` as its sole output. (Although we could proceed to perform MCMC model inference on each sample in series, we'll stop at segmentation to enforce the scattering of inference across samples, which will be quicker.) We can also allow for copy-ratio-only and allelic-count-only modes. Users can use this joint segmentation in their own downstream tools, but we can also allow ModelSegments to ingest it via in a new `--segments` argument:. ```; gatk ModelSegments; --normal-allelic-counts normal.allelicCounts.tsv (equivalently, we could omit this and adjust minimum-total-allele-count-case, as is done in the WDL); --allelic-counts normal.allelicCounts.tsv; --denoised-copy-ratios normal.denoisedCR.tsv; --segments joint-segmentation.interval_list; -O .; --output-prefix normal. gatk ModelSegments; --normal-allelic-counts normal.allelicCounts.tsv; --allelic-counts tumor-1.allelicCounts.tsv; --denoised-copy-ratios tumor-1.denoisedCR.tsv; --segments joint-segmentation.interval_list; -O .; --output-prefix tumor-1. ...; ```. Each scatter of ModelSegments will run as before, aside from skipping the segmentation step in favor of using the joint segmentation. We will repeat the het-genotyping step, but this is cheap and it's probably better to repeat it to make sure filtering is applied consistently. It would also require more changes to the command line to",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549:1320,down,downstream,1320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549,1,['down'],['downstream']
Availability,"-3.8.1 ...; git checkout --quiet refs/tags/3.8-1; GIT NEW branch -->; repository: https://github.com/broadgsa/gatk.git; at the commit: f2ed14489851ff2c00da3dcab9ad0b8f5ccec200; >>> Source unpacked in /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work; >>> Preparing source in /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1 ...; Equivalent maven command; mvn -Dmaven.repo.local=/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/.m2/repository verify '-Ddisable.shadepackage'; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1/public/gatk-root/pom.xml, line 15, column 3; @ ; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR] ; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1/pom.xml) has 1 error; [ERROR] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR] ; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR] ; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException; ```. I cannot say if `git checkout -f` is used, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4685#issuecomment-383184514:2106,error,error,2106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4685#issuecomment-383184514,11,"['ERROR', 'error']","['ERROR', 'error', 'errors']"
Availability,"-873f-41e8d765644d/call-metrics/transform_pack.cwl#metrics.cwl/2a15d912-9a75-44dc-a723-b9f2dba439b3/call-gatk_collectmultiplemetrics/inputs/-733038737/dbsnp_144.hg38.vcf.gz --TMP_DIR . --REFERENCE_SEQUENCE /cromwell-executions/transform_pack.cwl#main/8f58079f-1b94-40a9-873f-41e8d765644d/call-metrics/transform_pack.cwl#metrics.cwl/2a15d912-9a75-44dc-a723-b9f2dba439b3/call-gatk_collectmultiplemetrics/inputs/-733038737/GRCh38.d1.vd1.fa --ASSUME_SORTED true --STOP_AFTER 0 --INCLUDE_UNPAIRED false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu May 09 20:20:00 UTC 2019] Executing as root@6b3fc2da5b97 on Linux 4.15.0-48-generic amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-2ubuntu0.18.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.2.0; WARNING 2019-05-09 20:20:00 CollectMultipleMetrics The CollectBaseDistributionByCycle program does not support a metric accumulation level, but METRIC_ACCUMULATION_LEVEL was overridden in the command line. CollectBaseDistributionByCycle will be run against the entire input.; WARNING 2019-05-09 20:20:00 CollectMultipleMetrics The MeanQualityByCycle program does not support a metric accumulation level, but METRIC_ACCUMULATION_LEVEL was overridden in the command line. MeanQualityByCycle will be run against the entire input.; WARNING 2019-05-09 20:20:00 CollectMultipleMetrics The QualityScoreDistribution program does not support a metric accumulation level, but METRIC_ACCUMULATION_LEVEL was overridden in the command line. QualityScoreDistribution will be run against the entire input.; WARNING 2019-05-09 20:20:00 CollectMultipleMetrics The CollectQualityYieldMetrics program does not support a metric accumulation level, but METRIC_ACCUMUL",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5931:3647,avail,available,3647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5931,1,['avail'],['available']
Availability,"-Created a new class of tool, IntervalWalker, that processes a single interval at a time,; with the ability to query optional overlapping sources of reads, reference data, and/or; features/variants. Current implementation is simple/naive with no special caching;; performance issues will be addressed once we port this traversal type to dataflow. -Added the ability for VariantWalkers to access contextual reads/reference/feature data. -To enable the above changes, migrated most of the engine to use SimpleIntervals rather; than GenomeLocs. This allows for the creation of Context objects in traversals where there; is not necessarily a sequence dictionary available (eg., VariantWalker). -Moved shared arguments/code from Walker classes up into GATKTool. Still some issues; related to marking engine-wide arguments as optional/required on a per-traversal or; per-tool basis, but tickets have been created for these. -Since there isn't yet an htsjdk release that contains SimpleInterval, temporarily; checked a copy of it into our repo, which we can remove the next time we; rev htsjdk. TODOs:. -We currently still require a sequence dictionary to actually parse intervals in; IntervalArgumentCollection. This is due entirely to our support of intervals without; specific stop positions (eg., ""chr1"" and ""chr1:1+"") -- for these intervals we must; look up the stop position in a sequence dictionary. This means that IntervalWalkers; currently require at least one input that contains a sequence dictionary (although; VariantWalkers do not). We should look into ways of relaxing this restriction. Resolves #109",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/297:658,avail,available,658,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/297,1,['avail'],['available']
Availability,"-DRB1*15:01:01:04 (11056 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:02:01 (10313 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:03:01:01 (11567 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:03:01:02 (11569 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*16:02:01 (11005 bp); 16:16:37.546 INFO IntervalArgumentCollection - Processing 28770581 bp from intervals; 16:16:37.548 INFO GenomicsDBImport - Done initializing engine; 16:16:37.548 INFO GenomicsDBImport - Callset Map JSON file will be re-written to /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1/callset.json; 16:16:37.548 INFO GenomicsDBImport - Incrementally importing to array - /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1/genomicsdb_array; 16:16:37.549 INFO ProgressMeter - Starting traversal; 16:16:37.550 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 16:16:38.061 INFO GenomicsDBImport - Shutting down engine; [August 28, 2020 4:16:38 PM PDT] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=16464216064; org.genomicsdb.exception.GenomicsDBException: Duplicate sample name found: SSC00007. Sample was originally in /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; at org.genomicsdb.importer.extensions.CallSetMapExtensions.checkDuplicateCallsetsForIncrementalImport(CallSetMapExtensions.java:270); at org.genomicsdb.importer.extensions.CallSetMapExtensions.mergeCallsetsForIncrementalImport(CallSetMapExtensions.java:241); at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:222); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:743); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(Co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:8122,down,down,8122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['down'],['down']
Availability,"-Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp -Xmx3g -jar /home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-packa ; ; ge-4.2.5.0-local.jar HaplotypeCaller -R /home/gvandeweyer/elprep\_streaming/reference/hg19.fasta -I /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam -O results/wesep-229191-f.vcf --alleles ../wesid-226998-m.haplotypecaller.final.vcf.gz -L 0005-scattered.inter ; ; val\_list -bamout results/wesep-229191-f.variants.bam -G StandardAnnotation -G StandardHCAnnotation --dragen-mode --dragstr-params-path /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam.params ; ; 22:06:39.332 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default ; ; 22:06:39.337 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default ; ; 22:06:39.383 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/gvandeweyer/miniconda3/envs/ELPREP/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Mar 12, 2022 10:06:39 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 22:06:39.543 INFO HaplotypeCaller - ------------------------------------------------------------ ; ; 22:06:39.543 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.2.5.0 ; ; 22:06:39.543 INFO HaplotypeCaller - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 22:06:39.543 INFO HaplotypeCaller - Executing as [gvandeweyer@ngsvm-pipelines.uza.be](mailto:gvandeweyer@ngsvm-pipelines.uza.be) on Linux v4.4.0-210-generic am",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:4281,Redundant,Redundant,4281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['Redundant'],['Redundant']
Availability,-SNAPSHOT-test.jar]; 2022-08-16T22:45:53.6382333Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6383952Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:4: error: package com.google.common.base does not exist; 2022-08-16T22:45:53.6523417Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6548080Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6571861Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6588890Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6621393Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6631099Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6638787Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6653787Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6657039Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6658760Z src/main/java/org/broadinstitute/hellbender/e,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:2989,error,error,2989,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"-SORTING_COLLECTION_SIZE_RATIO 0.25 --TAG_DUPLICATE_SET_MEMBERS false --REMOVE_SEQUENCING_DUPLICATES false --TAGGING_POLICY DontTag --CLEAR_DT true --DUPLEX_UMI false --ADD_PG_TAG_TO_READS true --ASSUME_SORTED false --DUPLICATE_SCORING_STRATEGY SUM_OF_BASE_QUALITIES --PROGRAM_RECORD_ID MarkDuplicates --PROGRAM_GROUP_NAME MarkDuplicates --READ_NAME_REGEX <optimized capture of last three ':' separated fields as numeric values> --OPTICAL_DUPLICATE_PIXEL_DISTANCE 100 --MAX_OPTICAL_DUPLICATE_SET_SIZE 300000 --VERBOSITY INFO --QUIET false --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Sep 14, 2023 1:41:23 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Thu Sep 14 01:41:23 PDT 2023] Executing as ionadmin@proton-torrent-server on Linux 2.6.32-21-server amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_201-b09; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.2.0; INFO 2023-09-14 01:41:23 MarkDuplicates Start of doWork freeMemory: 2396610552; totalMemory: 2423259136; maxMemory: 61084270592; INFO 2023-09-14 01:41:23 MarkDuplicates Reading input file and constructing read end information.; INFO 2023-09-14 01:41:23 MarkDuplicates Will retain up to 221319820 data points before spilling to disk. ### Affected version(s); gatk 4.1.2.0. ### Description ; the output information is just stopped at ""INFO 2023-09-14 01:41:23 MarkDuplicates Will retain up to 221319820 data points before spilling to disk."", it should runs more information out. and there is no output for the rmdup bam. #### Expected behavior; it should finish it running and output the result. ## Feature request. ### Tool(s) or class(es) involved; JAVA_HOME = /usr/lib/jvm/jdk1.8.0_201/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8520:2708,avail,available,2708,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8520,1,['avail'],['available']
Availability,"-b12) (build 1.8.0_151-b12); # Java VM: OpenJDK 64-Bit Server VM (25.151-b12 mixed mode linux-amd64 compressed oops); # Derivative: IcedTea 3.6.0; # Distribution: Custom build (Tue Nov 21 11:22:36 GMT 2017); # Problematic frame:; # C [libgomp.so.1+0x7fab] omp_get_max_threads+0xb; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /beegfs/work/iiipe01/Exome-Test/work/1e/fc972c6b14c8006857230849630a49/hs_err_pid85482.log; #; # If you would like to submit a bug report, please include; # instructions on how to reproduce the bug and visit:; # http://icedtea.classpath.org/bugzilla; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. ``` . Here's the `hs_err` file:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00002b5f92e39fab, pid=85482, tid=0x00002b5f56e60ae8; #; # JRE version: OpenJDK Runtime Environment (8.0_151-b12) (build 1.8.0_151-b12); # Java VM: OpenJDK 64-Bit Server VM (25.151-b12 mixed mode linux-amd64 compressed oops); # Derivative: IcedTea 3.6.0; # Distribution: Custom build (Tue Nov 21 11:22:36 GMT 2017); # Problematic frame:; # C [libgomp.so.1+0x7fab] omp_get_max_threads+0xb; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # If you would like to submit a bug report, please include; # instructions on how to reproduce the bug and visit:; # http://icedtea.classpath.org/bugzilla; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. --------------- T H R E A D ---------------. Current thread (0x00005648765c2000): JavaThread ""main"" [_thread_in_native, id=85483, stack(0x00002b5f56d60000,0x00002b5f56e60aa8)]. siginf",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:4933,error,error,4933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['error'],['error']
Availability,"-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.912 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.8.1; 09:38:05.912 INFO HaplotypeCallerSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:38:05.912 INFO HaplotypeCallerSpark - Executing as xc278@amarel2.amarel.rutgers.edu on Linux v3.10.0-1062.9.1.el7.x86_64 amd64; 09:38:05.912 INFO HaplotypeCallerSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_232-b09; 09:38:05.913 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6750:1482,Redundant,Redundant,1482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750,1,['Redundant'],['Redundant']
Availability,-biology/gatk-9999/work/gatk-9999/build.gradle:143); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:90); 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	... 58 more; 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] BUILD FAILED; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.987 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] Total time: 29.153 secs; ```. ```; root# su - portage; portage$ cd /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/; portage$ git lfs pull --include src/main/resources/large; No default remote. Errors logged to /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T221032.955218097.log; Use `git lfs logs last` to view the log.; portage$ cat /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T221032.955218097.log; git-lfs/2.3.4 (GitHub; linux amd64; go 1.10); git version 2.16.3. $ git-lfs pull --include src/main/resources/large; No default remote. No remotes defined. Current time in UTC: ; 2018-04-20 20:10:32. ENV:; LocalWorkingDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999; LocalGitDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalGitStorageDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalMediaDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects; LocalReferenceDir=; TempDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/tmp; ConcurrentTransfers=3; TusTransfers=false; BasicTransfersOnly=false; SkipDownloadErrors=,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:15031,Error,Errors,15031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['Error'],['Errors']
Availability,"-disable_sampler=false --disable_annealing=false --interval_list=/tmp/die9s/intervals671187352630642175.tsv --contig_ploidy_prior_table=/media/Berechnungen/CNV_analysis/GATK4/ploidy_priors.tsv --output_model_path=/media/Berechnungen/CNV_analysis/GATK4/normal_cohort-model; Stdout:; Stderr: File ""/tmp/die9s/cohort_determine_ploidy_and_depth.9149389425697869853.py"", line 84; sample_metadata_collection: gcnvkernel.SampleMetadataCollection = gcnvkernel.SampleMetadataCollection(); ^; SyntaxError: invalid syntax. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:316); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:215); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); ```. Have you seen an error like this before? Do you have an idea where it is coming from?. Thanks a lot in advance; Stefan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125:3650,error,error,3650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125,1,['error'],['error']
Availability,"-dont-trim-active-regions true`:. ```; chr11 6411935 rs3838786 TGCTGGC CGCTGGC,T,<NON_REF> 4029.06 . DB;DP=118;ExcessHet=3.0103;MLEAC=1,1,0;MLEAF=0.500,0.500,0.00;RAW_MQandDP=424800,118;REF_BASES=ATGGGCCTGGTGCTGGCGCTG GT:AD:DP:F1R2:F2R1:GQ:PL:SB 1/2:0,62,40,0:102:0,31,23,0:0,31,17,0:99:4046,1646,1982,2435,0,2437,4113,1933,2560,4431:0,0,54,48; ```. and the second one didn't:. ```; chr11 6411935 rs3838786 TGCTGGC T,CGCTGGC,<NON_REF> 2308.64 . BaseQRankSum=-1.312;ClippingRankSum=0.877;DB;DP=119;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSum=0.000;RAW_MQandDP=428400,119;REF_BASES=ATGGGCCTGGTGCTGGCGCTG;ReadPosRankSum=0.255 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 0/2:7,0,65,0:72:1,0,34,0:6,0,31,0:99:2316,2364,2996,0,269,1897,2506,2977,1274,3798:1,6,34,31; ```. Note how in the second case, there are two alts in the gVCF, but only one of them has depth!. The only way to recover these cases is to run with `--dont-trim-active-regions`, but that make the HC run approximately 5 times slower, which is obviously not ideal. What I'd like to suggest is that the HC have some automated way to detect when this kind of error is likely to happen or has happened, and work around it. My suggestion(s) would be:. 1. I _think_ this really only happens in repetitive regions. I wonder if it would be possible to have the HC automatically trim active regions when assembly at kmer size 10 works, and disable it when it has to escalate to a higher kmer size? . 2. Trim the active region, but retain the untrimmed active region also. Genotype using the trimmed region. If any allele receives count=0, re-genotype using the untrimmed regions. My thought here is that I think not trimming the active regions really only makes a difference at a small fraction of sites, on the order of 1/1000, but to rescue those sites we have to pay a 5x performance penalty at every site. It would be great if trimming could be auto-disabled at only those sites that are problematic, so we could have our cake and eat it too.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5791:2174,error,error,2174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5791,1,['error'],['error']
Availability,"-hadoop2; 17/11/27 20:39:45 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at droazen-test-cluster-m/10.240.0.10:8032; 17/11/27 20:39:47 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1511814592376_0002; 17/11/27 20:39:52 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@7fbe38a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 20:39:52.363 INFO CountReadsSpark - Shutting down engine; [November 27, 2017 8:39:52 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=630718464; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:340); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:74); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsRea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:5978,Error,Error,5978,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['Error'],['Error']
Availability,"-imr OVERLAPPING\_ONLY \\ ; ; \--contig-ploidy-calls ploidy-calls \\ ; ; \--annotated-intervals Twist\_Exome\_Target\_hg38\_preprocessed\_annotated.interval\_list \\ ; ; \-I 13-20.counts.hd5 \\ ; ; \-I 722.counts.hd5 \\ ; ; \-I D19047.counts.hd5 \\ ; ; \-I F24F1.counts.hd5 \\ ; ; \-I NS.counts.hd5 \\ ; ; \-I TBC039.counts.hd5 \\ ; ; \-I VP.counts.hd5 \\ ; ; \-I WES002.counts.hd5 \\ ; ; \-I WES02.counts.hd5 \\ ; ; \-I 17062-T1-.counts.hd5 \\ ; ; \-I 18001-M1-.counts.hd5 \\ ; ; \-I 516.counts.hd5 \\ ; ; \-I 533.counts.hd5 \\ ; ; \-I NBH.counts.hd5 \\ ; ; \-I ADN492.counts.hd5 \\ ; ; \-I WES607.counts.hd5 \\ ; ; \--class-coherence-length 1000.0 \\ ; ; \--cnv-coherence-length 1000.0 \\ ; ; \--enable-bias-factors true \\ ; ; \--interval-psi-scale 1.0E-6 \\ ; ; \--log-mean-bias-standard-deviation 0.01 \\ ; ; \--sample-psi-scale 1.0E-6 \\ ; ; \--output cohort16 \\ ; ; \--output-prefix cohort16 \\ ; ; \--verbosity DEBUG \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'. Error:. java.lang.IllegalArgumentException: Prefix string ""NS"" too short: length must be at least 3 ; ; at java.base/java.io.File.createTempFile(File.java:2104) ; ; at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFileInDirectory(IOUtils.java:685) ; ; at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFile(IOUtils.java:666) ; ; at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.lambda$writeIntervalSubsetReadCountFiles$1(GermlineCNVCaller.java:430) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.IntPipeline$1$1.accept(IntPipeline.java:180) ; ; at java.base/java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:104) ; ; at java.base/java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:699) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeli",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7591:2289,Error,Error,2289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7591,1,['Error'],['Error']
Availability,-jdk-deflater true -R ref.rename.fa -V test.vcf.gz -O test_geno.vcf.gz. ### Error log 1. 21:12:43.028 INFO GenotypeGVCFs - Shutting down engine; [20211220 091243] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 6.12 minutes.; Runtime.totalMemory()=4856479744; htsjdk.samtools.SAMFormatException: Did not inflate expected amount; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:147); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:458); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:196); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:331); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:257); 	at htsjdk.tribble.readers.PositionalBufferedStream.fill(PositionalBufferedStream.java:132); 	at htsjdk.tribble.readers.PositionalBufferedStream.read(PositionalBufferedStream.java:84); 	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284); 	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326); 	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178); 	at java.io.InputStreamReader.read(InputStreamReader.java:184); 	at htsjdk.tribble.readers.LongLineBufferedReader.fill(LongLineBufferedReader.java:140); 	at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:300); 	at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:356); 	at htsjdk.tribble.readers.SynchronousLineReader.readLine(SynchronousLi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7614:1671,avail,available,1671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7614,1,['avail'],['available']
Availability,-new-qual error issue,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5000:10,error,error,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5000,1,['error'],['error']
Availability,-rev135-1.24.1.jar;E:\repository\com\google\cloud\google-cloud-firestore\0.61.0-beta\google-cloud-firestore-0.61.0-beta.jar;E:\repository\com\google\cloud\google-cloud-core-grpc\1.43.0\google-cloud-core-grpc-1.43.0.jar;E:\repository\com\google\protobuf\protobuf-java\3.6.0\protobuf-java-3.6.0.jar;E:\repository\io\grpc\grpc-protobuf\1.13.1\grpc-protobuf-1.13.1.jar;E:\repository\io\grpc\grpc-protobuf-lite\1.13.1\grpc-protobuf-lite-1.13.1.jar;E:\repository\io\grpc\grpc-context\1.13.1\grpc-context-1.13.1.jar;E:\repository\com\google\api\gax-grpc\1.30.0\gax-grpc-1.30.0.jar;E:\repository\org\threeten\threetenbp\1.3.3\threetenbp-1.3.3.jar;E:\repository\com\google\api\grpc\proto-google-cloud-firestore-v1beta1\0.26.0\proto-google-cloud-firestore-v1beta1-0.26.0.jar;E:\repository\com\google\auto\value\auto-value\1.4\auto-value-1.4.jar;E:\repository\io\grpc\grpc-netty-shaded\1.13.1\grpc-netty-shaded-1.13.1.jar;E:\repository\io\grpc\grpc-core\1.13.1\grpc-core-1.13.1.jar;E:\repository\com\google\errorprone\error_prone_annotations\2.1.2\error_prone_annotations-2.1.2.jar;E:\repository\io\opencensus\opencensus-contrib-grpc-metrics\0.12.3\opencensus-contrib-grpc-metrics-0.12.3.jar;E:\repository\io\grpc\grpc-stub\1.13.1\grpc-stub-1.13.1.jar;E:\repository\io\grpc\grpc-auth\1.13.1\grpc-auth-1.13.1.jar;E:\repository\io\opencensus\opencensus-api\0.15.0\opencensus-api-0.15.0.jar;E:\repository\io\opencensus\opencensus-contrib-grpc-util\0.15.0\opencensus-contrib-grpc-util-0.15.0.jar;E:\repository\com\google\guava\guava\20.0\guava-20.0.jar;E:\repository\org\slf4j\slf4j-api\1.7.30\slf4j-api-1.7.30.jar;E:\repository\io\netty\netty-codec-http\4.1.49.Final\netty-codec-http-4.1.49.Final.jar;E:\repository\io\netty\netty-common\4.1.49.Final\netty-common-4.1.49.Final.jar;E:\repository\io\netty\netty-buffer\4.1.49.Final\netty-buffer-4.1.49.Final.jar;E:\repository\io\netty\netty-codec\4.1.49.Final\netty-codec-4.1.49.Final.jar;E:\repository\io\netty\netty-handler\4.1.49.Final\netty-handler-4.1.49.Final.j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:9389,error,errorprone,9389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['error'],['errorprone']
Availability,"-seqr-main-analysis/seqr_loader/v0/genomicsdbs/interval_0_outof_50/callset.json; 14:26:53.640 INFO GenomicsDBImport - Complete VCF Header will be written to gs://cpg-seqr-main-analysis/seqr_loader/v0/genomicsdbs/interval_0_outof_50/vcfheader.vcf; 14:26:53.640 INFO GenomicsDBImport - Importing to workspace - gs://cpg-seqr-main-analysis/seqr_loader/v0/genomicsdbs/interval_0_outof_50; 14:26:56.113 INFO GenomicsDBImport - Starting batch input file preload; 14:26:57.968 INFO GenomicsDBImport - Finished batch preload; 14:26:57.968 INFO GenomicsDBImport - Importing batch 1 with 50 samples; 15:59:12.833 INFO GenomicsDBImport - Done importing batch 5/6; 15:59:12.833 INFO GenomicsDBImport - Starting batch input file preload; 15:59:13.218 INFO GenomicsDBImport - Finished batch preload; 15:59:13.218 INFO GenomicsDBImport - Importing batch 6 with 14 samples; [TileDB::FileSystem] Error: (write_to_file) GCS: Only the last of the uploadable parts can be less than 5MB, try increasing TILEDB_UPLOAD_BUFFER_SIZE to at least 5MB path=seqr_loader/v0/genomicsdbs/interval_0_outof_50/chr1$1$61698845/__64761969-0f52-4be1-a7c5-264d6dd36465140686419941120_1643299495929/__book_keeping.tdb.gz; [TileDB::StorageBuffer] Error: (gzip_write_buffer) Cannot write bytes path=seqr_loader/v0/genomicsdbs/interval_0_outof_50/chr1$1$61698845/__64761969-0f52-4be1-a7c5-264d6dd36465140686419941120_1643299495929/__book_keeping.tdb.gz; [TileDB::StorageBuffer] Error: (write_buffer) Cannot compress and/or write bytes path=seqr_loader/v0/genomicsdbs/interval_0_outof_50/chr1$1$61698845/__64761969-0f52-4be1-a7c5-264d6dd36465140686419941120_1643299495929/__book_keeping.tdb.gz; 16:39:59.490 INFO GenomicsDBImport - Done importing batch 6/6; 16:40:00.293 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed!; 16:40:00.293 INFO GenomicsDBImport - Shutting down engine; [January 27, 2022 at 4:40:00 PM UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 133.15 minutes.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7653:6139,Error,Error,6139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7653,3,"['Error', 'down']","['Error', 'down']"
Availability,"-us/community/posts/360072644931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766:1475,echo,echo,1475,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766,1,['echo'],['echo']
Availability,". ---; ## FindBreakpointEvidenceSpark. 1. Assembles and aligns contigs of genomic breakpoint regions associated with structural variants ; 2. Overview and Notes could use finessing but let's leave this for next year. One thing to include is a reference to FermiLite for those seeking more information. A publication would be best. And `6. ` from above. ---; ## StructuralVariationDiscoveryPipelineSpark. 1. Runs the structural variant discovery workflow on a single sample in Spark ; 2. Fyi we sanction a ""Caveats"" section, which is likely more appropriate for the PE expectation and the fact that low coverage data less than 30x will give suboptimal results. Also, should mention this workflow is meant only for WGS. Or is it the case one case use exome data? Second note on BwaMemIndexImageCreator could be consolidated with the same under Inputs. Same with third note. And `6. ` from above. ---; ## SvDiscoverFromLocalAssemblyContigAlignmentsSpark. 1. ""Parse"" is vague. Please clarify one-line summary.; 2. Again place up top ""This tool is used in development and should not be of interest to most researchers."". ---; ## ParallelCopyGCSDirectoryIntoHDFSSpark. 1. Let's explain the acronyms or their use context, e.g.; Parallel copy a file or directory from Google Cloud Storage into the HDFS format used in Spark. 2. GCS refers to Google Cloud Storage and HDFS to Hadoop Distributed File System. The latter is used in Spark ... - What is the difference between RDD (resilient distributed datasets) and HDFS? ; - Can I use globbing? ; - Why do I need this tool in the SV pipeline? ; - Can the tool run in Spark and nonSpark modes?. And `6. ` from above.; ```; gatk ParallelCopyGCSDirectoryIntoHDFSSpark \; --input-gcs-path gs://my-bucket/my-data-directory/ \; --output-hdfs-directory hdfs://my-dataproc-spark-cluster-m:8020/my-data \; -- \; --sparkRunner GCS \; --cluster my-dataproc-spark-cluster; ```; - Can we update the example command so it is more concrete, e.g. takes a BAM or multiple BAMs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451:4884,resilien,resilient,4884,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451,2,['resilien'],['resilient']
Availability,". As @pdexheimer pointed out: . > I think the bug here is in HaplotypeCaller. It technically generated a malformed (g)VCF by using an ambiguous allele for the reference. I don't know what the fix is, though. You can't have an ActiveRegionWalker skip over the ambiguous bases since it operates on a whole region. And a post hoc check in HC would be simple enough for SNVs, but what happens when the ambiguous site is part of a larger deletion?. Needs advice on what the behavior / solution should be by @akiezun @vruano . This Issue was generated from your [forums](http://gatkforums.broadinstitute.org/discussion/4858/reference-bases-with-ambiguity-codes-in-dbsnp/p1) . ---. @vruano commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/829#issuecomment-85093784). In general, don't know how HC behaves with ambiguous reference bases at all.... I would not be surprised if it just crashes or outputs garbage. Perhaps this should be part of a larger effort to make sure HC, Combine- and GenotypeGVCFs are robust on ambiguous calls. To start, currently GATK/Picard handles bases as uppercase single `byte' representation of the corresponding character. Since we are investing (a mostly wasting) 8 bits already, we could change into a bit mask representation that would allow for quick comparison of ambiguous and non-ambigous base call using bit-wise operations. NO_CALL = 0, A = 1, C = 2, G = 4, T/U = 8, N = 15, etc... . Handling ambiguous reference base calls... IMO the easiest and clearest is to disambiguate using a standard alphabetical priority, A, C, G or T whichever is the first compatible base is the reference. Then we just generate non-ambigous output accordingly to this choice. . We can provide separate tools to re-ambiguate the output or reselect the reference allele as the population major allele, so making the user very aware of this. For example he/she should have an decision-making input as to how we are supposed to handle het calls where both a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2914:1237,robust,robust,1237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2914,1,['robust'],['robust']
Availability,". I think any upstream padding doesnt matter. If you have a multi-nucleotide polymorphism that starts upstream of 1050 but spans 1050, this job wouldnt be responsible for calling that. The prior job, which has an interval set upstream of this one should call it. I think GenomicsDbImport's behavior is fine here. If you have a multi-NT variant that starts within 1050-1150, but extends outside (i.e. deletion or insertion starting at 1148), this could be a problem. The GenomicsDB workspace created with the interval 1:1050-1150 lacks the information to score that, right? The workspace created using the more permissive SelectVariants->GenomicsDBImport contains that downstream information and presumably would make the same call as if GenotypeGVCFs was given the intact chromosome as input, right?. However, it seems that if I simply create the workspace with a reasonably padded interval (adding 1kb should be more than enough for Illumina, right?), and then run GenotypeGVCFs with the original, unpassed interval, then the resulting workspace should contain all available information and GenotypeGVCFs should be able to make the same call as if it was given a whole-chromosome workspace as input. . Does that logic seem right? . ```; # The Input gVCF; 1	1040	.	A	<NON_REF>	.	.	END=1046	GT:DP:GQ:MIN_DP:PL	0/0:15:24:14:0,24,360; 1	1047	.	T	<NON_REF>	.	.	END=1047	GT:DP:GQ:MIN_DP:PL	0/0:14:4:14:0,4,418; 1	1048	.	G	<NON_REF>	.	.	END=1141	GT:DP:GQ:MIN_DP:PL	0/0:19:26:12:0,26,411; 1	1142	.	C	T,<NON_REF>	115.64	.	BaseQRankSum=-2.237;DP=19;MQRankSum=-2.312;RAW_GT_COUNT=0,1,0;RAW_MQandDP=43640,19;ReadPosRankSum=0.851	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0|1:15,4,0:19:99:0|1:1142_C_T:123,0,551,168,563,731:1142:9,6,2,2; 1	1143	.	G	<NON_REF>	.	.	END=1168	GT:DP:GQ:MIN_DP:PL	0/0:17:37:16:0,37,475; 1	1169	.	G	A,<NON_REF>	123.64	.	BaseQRankSum=-1.808;DP=18;MQRankSum=-1.313;RAW_GT_COUNT=0,1,0;RAW_MQandDP=30190,18;ReadPosRankSum=1.331	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0|1:14,4,0:18:99:0|1:1142_C_T:131,0,455,168,46",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221558244:2306,avail,available,2306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221558244,2,['avail'],['available']
Availability,". If you're not sure what to include or not just ask. I like the idea of keeping the GATK3 tests working as we go along. We should make a clear distinction between the old and new tests though. Ideally the GATK3 tests would be in a separate commit that we can just delete at the end, but that can get unwieldy if the files in the commit need to change as we go along. Alternatively you could isolate them into a separate directory. They should either be disabled or made dependent on a test method (see the `@Test` annotation properties `enabled` and `dependsOn`) that is easily toggled so they can be run locally, but don't run on the CI server. Otherwise the CI server build will always fail. In general, its really helpful to have the first commit in the PR contain the completely unmodified GATK3 source files. It makes it much easier for the reviewer to see what changed for the port. I noticed that you have 2 new plugins included in this. I'm not sure if that was suggested by someone on the GATK team (I'm wondering if we want to go down that path...) but I can tell you that the existing plugins required an enormous amount of test development and review iteration. If we do decide to make them plugins, I think it would be a good idea to do so in a separate PR. Also, if we choose to make an AbstractPlugin base class, we may want that to live in the Barclay repo. As @magicdgs points out, master already has your previous commits, so you should start by rebasing on that. Ideally, the branch would have the following commits before we start the first review cycle:. 1. A single commit containing the unmodified GATK3 source (unmodified with the exception that if a file is renamed for GATK4, its helpful to rename the GATK3 version in this commit so it's easy to compare in the next commit). This commit doesn't have to compile or run - its just to make the review process easier for us, and will be deleted at some point. I can help with how to get this into your branch if you like.; 2. Y",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352:1725,down,down,1725,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352,2,['down'],['down']
Availability,". Note that changing the ARD priors does change the *names* of the expected files, since the transform is appended to the corresponding variable name. DetermineGermlineContigPloidy and PostprocessGermlineCNVCalls are missing exact-match tests and should probably have some, but I'll leave that to someone else.; - [x] Update other python integration tests.; - [x] Clean up some of the changes to the priors.; - [x] Clean up some TODO comments that I left to track code changes that might result in changed numerics. I'll try to go through and convert these to PR comments in an initial review pass.; - [x] Test over multiple shards on WGS and WES. Probably some scientific tests on ~100 samples in both cohort and case mode would do the trick. We should also double check runtime/memory performance (I noted ~1.5x speedups, but didn't measure carefully; I also want to make sure the changes to posterior sampling didn't introduce any memory issues). @mwalker174 will ping you when a Docker is ready! Might be good to loop in Isaac and/or Jack as well.; - [x] Perhaps add back the fix for 2-interval shards in https://github.com/broadinstitute/gatk/pull/8180, which I removed since the required functionality wasn't immediately available in Pytensor. Not sure if this actually broke things though---need to check. (However, I don't actually think this is a very important use case to support...); - [x] Delete/deprecate/etc. CNN tools/tests as appropriate. Note that this has to be done concurrently, since we remove Tensorflow. @droazen perhaps I can take a first stab at this in a subsequent commit to this PR once more of the gCNV dust settles and/or has undergone a preliminary review? EDIT: Disabled integration/WDL tests. We should add some deprecation messages to the tools---we can note that they should still work in previous environments but will be untested. I might set up a separate PR for deletion, to be done at the appropriate time (but I call dibs on this, can't have @davidbenjamin o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:3063,ping,ping,3063,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,1,['ping'],['ping']
Availability,". Out of curiosity, we tried building the docker again without samtools, so in theory, the only possible change is that when each docker is built, apt update is run. The differences are small, but is that expected? That with and without samtools, and if `apt` packages change, mutect2 could be influenced?. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_; I can't replicate scenario 1 in the table because it was built in 2019, so apt packages were different then.; Scenario 2 dockerPull: `docker pull kfdrc/gatk:4.1.1.0`; Scenario 3 dockerPull: `docker pull pgc-images.sbgenomics.com/d3b-bixu/gatk:4.1.1.0`; Scenario 4 dockerPull: `docker pull migbro/gatk:4.1.1.0L`. No samtools Dockerfile:; ```; FROM ubuntu:18.04; LABEL maintainer=""Miguel Brown (brownm28@email.chop.edu)"". ENV GATK4_VERSION 4.1.1.0. RUN apt update && apt install -y openjdk-8-jdk python wget unzip libgomp1; \; wget -q https://github.com/broadinstitute/gatk/releases/download/${GATK4_VERSION}/gatk-${GATK4_VERSION}.zip; \; unzip gatk-${GATK4_VERSION}.zip; \; mv gatk-${GATK4_VERSION}/gatk* . && rm -rf gatk-${GATK4_VERSION}*; \; apt remove -y wget; ```. Yes samtools Dockerfile:; ```; FROM ubuntu:18.04; LABEL maintainer=""Miguel Brown (brownm28@email.chop.edu)"". ENV GATK4_VERSION 4.1.1.0. RUN apt update && apt install -y openjdk-8-jdk python wget unzip libgomp1 tabix samtools; \; wget -q https://github.com/broadinstitute/gatk/releases/download/${GATK4_VERSION}/gatk-${GATK4_VERSION}.zip; \; unzip gatk-${GATK4_VERSION}.zip; \; mv gatk-${GATK4_VERSION}/gatk* . && rm -rf gatk-${GATK4_VERSION}*; \; apt remove -y wget; ```. #### Expected behavior; _Tell us what should happen_; All `PASS` var counts are the same; #### Actual behavior; _Tell us what happens instead_; `PASS` var counts vary slightly +/- samtools and year docker built; ----; Thank you for your time!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7269:2014,down,download,2014,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7269,2,['down'],['download']
Availability,"...` yields the following snippet:. ```; Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.downsampling.ReservoirDownsamplerUnitTest > testReservoirDownsampler[29](TestDataProvider(ReservoirDownsamplerTest: reservoirSize=10000 totalReads=10000 expectedNumReadsAfterDownsampling=10000 expectedNumDiscardedItems=0)) STANDARD_ERROR; 01:40:10.641 WARN gatk - Running test: TestDataProvider(ReservoirDownsamplerTest: reservoirSize=10000 totalReads=10000 expectedNumReadsAfterDownsampling=10000 expectedNumDiscardedItems=0); Finished 130000 tests; Finished 140000 tests. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest STANDARD_ERROR; 01:40:14.522 WARN NativeLibraryLoader - Unable to load libgkl_pairhmm_fpga.so from native/libgkl_pairhmm_fpga.so (/tmp/libgkl_pairhmm_fpga17703278887667828152.so: libgkl_pairhmm_shacc.so: cannot open shared object file: No such file or directory); #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fe1a5cd00f2, pid=6969, tid=6997; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P"" (or dumping to /home/travis/build/broadinstitute/gatk/core.6969); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid6969.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #; Starting process 'Gradle Test Executor 2'. Working directory: /home/travis/build/broadinstitute/gatk Command: /usr/local/lib/jvm/openjdk11/bin/java -Dgatk.spark.debug -Dorg.gradle.native=false -Dsamjdk.compression_level=2 -Dsamjdk.use_asyn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-607332088:983,error,error,983,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-607332088,1,['error'],['error']
Availability,"...and test, naturally. Issue #3735 reports that transient errors can cause the auth server to return ""403 Forbidden"" and, in turn, cause us to fail. This PR attempts to work around this situation by retrying a few times on these errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3739:59,error,errors,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3739,2,['error'],['errors']
Availability,...ls/genomicsdb/GenomicsDBImportIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5378/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnRJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `88.47% <100%> ()` | `80 <0> ()` | :arrow_down: |; | [...s/spark/pathseq/PSBuildReferenceTaxonomyUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5378/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTQnVpbGRSZWZlcmVuY2VUYXhvbm9teVV0aWxzLmphdmE=) | `87.742% <100%> ()` | `43 <1> ()` | :arrow_down: |; | [...ls/walkers/mutect/CreateSomaticPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/5378/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHMuamF2YQ==) | `93.846% <100%> ()` | `21 <0> ()` | :arrow_down: |; | [...ls/downsampling/AlleleBiasedDownsamplingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5378/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvQWxsZWxlQmlhc2VkRG93bnNhbXBsaW5nVXRpbHMuamF2YQ==) | `79.31% <100%> ()` | `24 <0> ()` | :arrow_down: |; | [...kers/vqsr/VariantGaussianMixtureModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5378/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVmFyaWFudEdhdXNzaWFuTWl4dHVyZU1vZGVsVW5pdFRlc3QuamF2YQ==) | `83.019% <100%> ()` | `13 <0> ()` | :arrow_down: |; | [...rg/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5378/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzLmphdmE=) | `73.148% <100%> ()` | `98 <1> ()` | :arrow_down: |; | [.../walkers/vqsr/TruthSensitivityTrancheUnitTest.java](https://codecov.io/gh/broadinstit,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-446352022:2845,down,downsampling,2845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-446352022,1,['down'],['downsampling']
Availability,"./gatk-launch --help prints ""A USER ERROR has occurred: '--help' is not a valid command.""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1301:36,ERROR,ERROR,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1301,1,['ERROR'],['ERROR']
Availability,".0.4.0/bin/gatk"" --java-options ""-Xmx8g -Xms8g"" \; GenotypeGVCFs \; -R ""/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e64f393e-2ac6-43e6-9b20-cbfa905e7c33/call-GenotypeGVCFs/shard-17/inputs/1017648146/Homo_sapiens_assembly38.fasta"" \; -O ""$tmp_vcf"" \; -D ""/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e64f393e-2ac6-43e6-9b20-cbfa905e7c33/call-GenotypeGVCFs/shard-17/inputs/1017648146/Homo_sapiens_assembly38.dbsnp138.vcf"" \; -G StandardAnnotation \; --only-output-calls-starting-in-intervals \; --use-new-qual-calculator \; -V gendb://""$genomicsdb"" \; -L ""chr18:1-80373285"". ""/share/ClusterShare/software/contrib/evaben/gatk/prebuilt/4.0.4.0/bin/gatk"" --java-options ""-Xmx8g -Xms8g"" \; VariantFiltration \; --filter-expression ""ExcessHet > 54.69"" \; --filter-name ExcessHet \; -O ""output.vcf.gz"" \; -V ""$tmp_vcf""; ```. And a SGE hard memory limit of 40G (GenotypeGVCFs has -Xmx8g).; On gatk 4.0.4.0 I see peak memory usage of 15.7G, while with gatk 4.0.6.0 I get:. ```; ...; 19:06:23.757 INFO GenotypeGVCFs - Initializing engine; 19:06:24.785 INFO FeatureManager - Using codec VCFCodec to read file file:///share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e9bf8c5e-3e70-476a-99a2-833f9d38cb2f/call-GenotypeGVCFs/shard-0/inputs/1017648146/Homo_sapiens_assembly38.dbsnp138.vcf; terminate called after throwing an instance of 'std::length_error'; what(): vector::_M_default_append; ```. It seems unlikely to be just a performance regression, maybe something is wrong with my commandline/inputs that only the new version is revealing. This may be in the genomicsdb part of the codebase, as that is the input file I am reading. . [stderr of failure (4.0.6.0) ](https://github.com/broadinstitute/gatk/files/2204252/gengvcferr.txt); [stderr of success (4.0.4.0) ](https://github.com/broadinstitute/gatk/files/2204253/gengvcfgood.txt); [script of failure](https://github.com/broadinstitute/gatk/files/2204254/gengvcfscript.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5024:2461,failure,failure,2461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5024,2,['failure'],['failure']
Availability,.065%)` | `115 <17> (-43)` | |; | [.../utils/smithwaterman/SmithWatermanJavaAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/6015/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5KYXZhQWxpZ25lci5qYXZh) | `91.469% <96.226%> (-2.648%)` | `50 <0> (+4)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/6015/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/6015/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/6015/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/6015/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/6015/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | ... and [1215 more](https://codecov.io/gh/broadinstitute/gatk/pull/6015/diff?s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6015#issuecomment-505902726:3077,down,downsampling,3077,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6015#issuecomment-505902726,1,['down'],['downsampling']
Availability,".1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Bl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:10831,failure,failures,10831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['failure'],['failures']
Availability,".2 14260000 4500268.2. 10:46:40.543 INFO ProgressMeter - chr1:178147829 3.3 14969000 4487827.8. 10:46:50.551 INFO ProgressMeter - chr1:186125500 3.5 15636000 4464516.0. 10:47:00.555 INFO ProgressMeter - chr1:194986011 3.7 16297000 4441809.8. 10:47:10.565 INFO ProgressMeter - chr1:203560084 3.8 17001000 4432191.5. 10:47:20.577 INFO ProgressMeter - chr1:211951736 4.0 17700000 4421996.7. 10:47:30.580 INFO ProgressMeter - chr1:220837654 4.2 18418000 4417386.9. 10:47:40.592 INFO ProgressMeter - chr1:229536819 4.3 19156000 4417642.0. 10:47:50.595 INFO ProgressMeter - chr1:237917173 4.5 19861000 4410598.8. 10:48:00.598 INFO ProgressMeter - chr1:246682719 4.7 20561000 4403066.6. 10:48:10.604 INFO ProgressMeter - chr2:6733404 4.8 21270000 4397838.6. 10:48:20.605 INFO ProgressMeter - chr2:15144861 5.0 21942000 4385607.8. 10:48:30.607 INFO ProgressMeter - chr2:24131740 5.2 22650000 4381143.4. 10:48:40.610 INFO ProgressMeter - chr2:32916253 5.3 23467000 4397382.8. 10:48:43.217 INFO LeftAlignIndels - Shutting down engine. [August 18, 2020 10:48:43 AM EDT] org.broadinstitute.hellbender.tools.LeftAlignIndels done. Elapsed time: 5.40 minutes. Runtime.totalMemory()=2076049408. java.lang.IllegalArgumentException: the range cannot contain negative indices. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:108). at org.broadinstitute.hellbender.utils.IndexRange.shift(IndexRange.java:73). at org.broadinstitute.hellbender.utils.IndexRange.shiftLeft(IndexRange.java:77). at org.broadinstitute.hellbender.utils.read.AlignmentUtils.leftAlignIndels(AlignmentUtils.java:735). at org.broadinstitute.hellbender.tools.LeftAlignIndels.apply(LeftAlignIndels.java:78). at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6765:5817,down,down,5817,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765,1,['down'],['down']
Availability,.21.2; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:43:15.241 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:43:15.241 INFO FastaAlternateReferenceMaker - Deflater: IntelDeflater; 15:43:15.241 INFO FastaAlternateReferenceMaker - Inflater: IntelInflater; 15:43:15.241 INFO FastaAlternateReferenceMaker - GCS max retries/reopens: 20; 15:43:15.241 INFO FastaAlternateReferenceMaker - Requester pays: disabled; 15:43:15.241 INFO FastaAlternateReferenceMaker - Initializing engine; 15:43:17.851 INFO FeatureManager - Using codec VCFCodec to read file file:///g/data/xe2/users/stephen-rodgers/pergene_gatk/CCA0704/CCA0704.vcf.gz; 15:43:17.912 INFO FastaAlternateReferenceMaker - Done initializing engine; 15:43:17.913 INFO FastaAlternateReferenceMaker - Shutting down engine; [3 February 2020 at 3:43:17 pm AEDT] org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=118489088; java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.fasta.FastaReferenceMaker.closeTool(FastaReferenceMaker.java:141); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1052); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6434:3986,down,down,3986,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6434,1,['down'],['down']
Availability,".277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3680; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1141; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1266; 10:28:46.483 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 4, 2017 10:28:46 AM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=3954180096. ==============. feature.vcf. 13:51:48.490 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6543 variants.; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 229; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3679; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1365; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1270; 13:51:48.770 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 5, 2017 1:51:48 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=4026531840; ```. No variants that were dropped are simple variants, and they are expected to be brought back with the correct interpretation once complex sv PR series are fully coded. __Two known issues__:; 1. Arguably, these calls may not have high confidence since we are likely NOT having the duplicated region fully assembled. But we could develop a filter later and be less stringent in the discovery stage.; 2. The inserted sequence mapping annotation is still an issue we need to iron out, in the sense that when one ref span is a completely enclosed in the other with some bases in the larger ref span uncovered by the the smaller ref span (i.e. a true containment from both boundaries instead of a one-boundary coincidence), there's actually insert sequence between the two copies ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3668:1601,down,down,1601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3668,1,['down'],['down']
Availability,.364 INFO FilterAlignmentArtifacts - Requester pays: disabled; 01:39:03.364 WARN FilterAlignmentArtifacts - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 01:39:03.364 INFO FilterAlignmentArtifacts - Initializing engine; 01:39:07.644 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf; 01:39:08.399 INFO FilterAlignmentArtifacts - Done initializing engine; 01:39:09.523 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 01:39:09.565 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 01:39:09.566 INFO IntelPairHmm - Available threads: 4; 01:39:09.566 INFO IntelPairHmm - Requested threads: 4; 01:39:09.566 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 01:39:09.567 INFO ProgressMeter - Starting traversal; 01:39:09.567 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; munmap_chunk(): invalid pointer; Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx11500m -jar /root/gatk.jar FilterAlignmentArtifacts -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -V gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf -I gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/209d1183-ed9a-4755-a4b3-d595797640ea/P,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:5083,Avail,Available,5083,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860,1,['Avail'],['Available']
Availability,".38;HWP=1.0000;InbreedingCoeff=-0.0030;MLEAC=80;MLEAF=1.064e-03;MQ=59.45;MQ0=0;MQRankSum=0.306;NCC=2;QD=0.50;ReadPosRankSum=-1.290e-01;VQSLOD=2.18;culprit=QD; 14 45369723 . T TG 12376.8 PASS AC=182;AF=2.420e-03;AN=75210;BaseQRankSum=-1.810e-01;CCC=75210;ClippingRankSum=0.00;DP=1041458;FS=0.000;GQ_MEAN=67.78;GQ_STDDEV=20.59;HWP=1.0000;InbreedingCoeff=-0.0033;MLEAC=121;MLEAF=1.609e-03;MQ=59.77;MQ0=0;MQRankSum=0.410;NCC=2;QD=1.24;ReadPosRankSum=-1.100e-01;VQSLOD=2.08;culprit=QD; 19 8193948 . C CG 2846.04 PASS AC=102;AF=1.356e-03;AN=75204;BaseQRankSum=0.337;CCC=75204;ClippingRankSum=0.513;DP=1255955;FS=0.000;GQ_MEAN=76.78;GQ_STDDEV=24.97;HWP=1.0000;InbreedingCoeff=-0.0017;MLEAC=65;MLEAF=8.643e-04;MQ=59.81;MQ0=0;MQRankSum=0.514;NCC=5;QD=0.69;ReadPosRankSum=-1.050e-01;VQSLOD=2.07;culprit=QD. ---. @ldgauthier commented on [Thu Mar 12 2015](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-78600061). Are the VQSR output graphs for the ExAC dataset available anywhere? I really want to know what the QD distribution and fit for the indels look like. ---. @eitanbanks commented on [Fri Mar 13 2015](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-78798219). Thanks for looking into this. It's definitely a problem. ---. @ldgauthier commented on [Tue Mar 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/868#issuecomment-82372578). A lot of the training data for ExAC INDELs are low QD; ![image](https://cloud.githubusercontent.com/assets/6578548/6687531/218c719c-cc82-11e4-8e76-5fd6e9b09f9e.png); About 35% of these training INDELs are multiallelic, compared with 47% of training INDELs with QD <= 2. QD for SNPs has much smaller variance (and a lot more data); ![image](https://cloud.githubusercontent.com/assets/6578548/6688722/0696c90a-cc8c-11e4-8b61-7c812246abb2.png); For SNPs 14% overall are multiallelic with 13% of QD <= 2.0 SNPs being multiallelic. So it's not a huge surprise that low QD indels pass because there's a fair amount",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2508:5128,avail,available,5128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2508,1,['avail'],['available']
Availability,".4126674Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:41: error: cannot find symbol; 2022-08-16T00:09:07.4127264Z private static BiMap<Log.LogLevel, java.util.logging.Level> javaUtilLevelNamespaceMap;; 2022-08-16T00:09:07.4127999Z symbol: class BiMap; 2022-08-16T00:09:07.4128334Z location: class LoggingUtils; 2022-08-16T00:09:07.4137968Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:13: error: package com.google.common.base does not exist; 2022-08-16T00:09:07.4139500Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:14: error: package com.google.common.io does not exist; 2022-08-16T00:09:07.4190745Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4198885Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:242: error: cannot find symbol; 2022-08-16T00:09:07.4199424Z @VisibleForTesting; 2022-08-16T00:09:07.4200130Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4200630Z location: class ReferenceConfidenceVariantContextMerger; 2022-08-16T00:09:07.4211864Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:7: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4214985Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T00:09:07.4215495Z @VisibleForTesting; 2022-08-16T00:09:07.4216081Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4251408Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4265184Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4267067Z src/m",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:14293,error,error,14293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,".455:0.025,0.025,0.950; WMCF9-CB5:working shlee$ gzcat 2_normalforpon.vcf.gz | grep 'chrX\t153909841'; chrX	153909841	.	C	A	.	.	DP=11;ECNT=1;POP_AF=1.000e-03;P_GERMLINE=-2.169e-04;TLOD=14.94	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:MBQ:MCL:MFRL:MMQ:MPOS:REF_F1R2:REF_F2R1:SA_MAP_AF:SA_POST_PROB	0/1:6,5:0.455:3:2:0.400:30,33:0,0:191,278:60,60:11,20:1:5:0.404,0.444,0.455:0.025,0.025,0.950; WMCF9-CB5:working shlee$ gzcat 3_discard_practice_pon.vcf.gz | grep 'chrX'; ##contig=<ID=chrX,length=156040895>; ##contig=<ID=chrX_KI270880v1_alt,length=284869>; ##contig=<ID=chrX_KI270881v1_alt,length=144206>; ##contig=<ID=chrX_KI270913v1_alt,length=274009>; chrX	132097402	.	TACAC	T,TAC	.	.	.; ```; This site should have been called in the PoN. Finally, for the `-vcfs` parameter, if I provide a list of files, one per line, the tool errors with; ```; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file, for input source: /Users/shlee/Desktop/August2017_tutorial_dev/working/list_of_normals_for_pon.txt; 	at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:253); 	at htsjdk.tribble.TribbleIndexedFeatureReader.<init>(TribbleIndexedFeatureReader.java:101); 	at htsjdk.tribble.TribbleIndexedFeatureReader.<init>(TribbleIndexedFeatureReader.java:126); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:110); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:74); 	at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:58); 	at org.broadinstitute.hellbender.tools.walkers.mutect.CreateSomaticPanelOfNormals.doWork(CreateSomaticPanelOfNormals.java:122); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3510:2723,error,error,2723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510,1,['error'],['error']
Availability,".652,0.724;BaseQRankSum=-0.152;DP=118313;ExcessHet=2.9774;FS=0.518;InbreedingCoeff=0.0016;MLEAC=278,2;MLEAF=0.04,0.0002879;MQ=56.9;MQRankSum=-0.962;QD=2.57;ReadPosRankSum=0.193;SOR=0.712; `. ```; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr6:26914009 [VC chr6.raw.excessHet.vcf.gz @ chr6:26914009 Q276902.75 of type=INDEL alleles=[G*, GTGTA, GTGTATA, GTGTGTA] attr={AC=[4269, 29, 5], AF=[0.620, 4.209e-03, ; #### Steps to reproduce; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode INDEL; ```. #### Expected behavior; Create recalibrated vcf file. #### Actual behavior; ```; Caused by:; Process `ApplyRecalibrationIndels` terminated with an error exit status (3). Command executed:. #!/bin/bash; /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk --java-options -Xms5g ApplyVQSR -O indel.recalibrated.vcf.gz -V chr6.raw.excessHet.vcf.gz -AS --recal-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.recal --use-allele-specific-annotations --tranches-file /restricted/projectnb/kageproj/gatk/pVCF.vqsr/indels.tranches --truth-sensitivity-filter-level 99.0 --create-output-variant-index true -mode INDEL. Command exit status:; 3. Command output:; (empty). Command error:; 23:21:52.354 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:22:02.735 INFO ProgressMeter - chr6:1162012 0.2 25000 144494.8; 23:22:12.789 INFO ProgressMeter - chr6:2449556 0.3 53000 155623.0; 23:22:23.019 INFO ProgressMeter - chr6:3663394 0.5 82000 160448.7; 23:22:33.257 INFO ProgressMeter - chr6:4991347 0.7 112000 164291.1; 23:22:43.683 INFO ProgressMeter - chr6:6325045 0.9 141000",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8054:1656,error,error,1656,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8054,1,['error'],['error']
Availability,".670 INFO CNNScoreVariants - Inflater: IntelInflater ; ; 11:17:58.671 INFO CNNScoreVariants - GCS max retries/reopens: 20 ; ; 11:17:58.671 INFO CNNScoreVariants - Requester pays: disabled ; ; 11:17:58.671 INFO CNNScoreVariants - Initializing engine ; ; WARNING: BAM index file /media/analyst/Data/WES/73318/73318\_WES\_hg19\_recalibrated.sorted.bai is older than BAM /media/analyst/Data/WES/73318/73318\_WES\_hg19\_recalibrated.sorted.bam ; ; 11:17:58.969 INFO FeatureManager - Using codec VCFCodec to read file file:///media/analyst/Data/WES/73318/73318\_80\_IDTv1.vcf.gz ; ; 11:17:59.079 INFO CNNScoreVariants - Done initializing engine ; ; 11:17:59.081 INFO NativeLibraryLoader - Loading libgkl\_utils.so from jar:file:/home/analyst/anaconda3/envs/snakemake\_env/share/gatk4-4.2.5.0-0/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl\_utils.so ; ; 11:17:59.187 INFO CNNScoreVariants - Done scoring variants with CNN. ; ; 11:17:59.187 INFO CNNScoreVariants - Shutting down engine ; ; \[April 25, 2022 at 11:17:59 AM CEST\] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.01 minutes. ; ; Runtime.totalMemory()=1895825408 ; ; java.lang.NullPointerException ; ;   at org.broadinstitute.hellbender.utils.runtime.ProcessControllerAckResult.hasMessage(ProcessControllerAckResult.java:49) ; ;   at org.broadinstitute.hellbender.utils.runtime.ProcessControllerAckResult.getDisplayMessage(ProcessControllerAckResult.java:69) ; ;   at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.waitForAck(StreamingProcessController.java:229) ; ;   at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.waitForAck(StreamingPythonScriptExecutor.java:216) ; ;   at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.sendSynchronousCommand(StreamingPythonScriptExecutor.java:183) ; ;   at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.onTraversalStart(CNNScoreVaria",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811:5316,down,down,5316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811,1,['down'],['down']
Availability,".8125227Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:41: error: cannot find symbol; 2022-08-16T22:45:53.8125528Z private static BiMap<Log.LogLevel, java.util.logging.Level> javaUtilLevelNamespaceMap;; 2022-08-16T22:45:53.8125793Z symbol: class BiMap; 2022-08-16T22:45:53.8126059Z location: class LoggingUtils; 2022-08-16T22:45:53.8134767Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:13: error: package com.google.common.base does not exist; 2022-08-16T22:45:53.8135486Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:14: error: package com.google.common.io does not exist; 2022-08-16T22:45:53.8163449Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8167163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:245: error: cannot find symbol; 2022-08-16T22:45:53.8167305Z @VisibleForTesting; 2022-08-16T22:45:53.8167581Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8167809Z location: class ReferenceConfidenceVariantContextMerger; 2022-08-16T22:45:53.8173821Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:7: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8175307Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T22:45:53.8175437Z @VisibleForTesting; 2022-08-16T22:45:53.8175712Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8180874Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8265839Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8266584Z src/m",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:16331,error,error,16331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,".963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.REFERENCE_FASTA : null; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_CRAM_REF_DOWNLOAD : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Deflater IntelDeflater; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Inflater IntelInflater; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Initializing engine; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4769b07b] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@5ef60048].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4769b07b] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@5ef60048].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; l",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296871363:1733,ERROR,ERROR,1733,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296871363,1,['ERROR'],['ERROR']
Availability,".981 INFO HaplotypeCaller - Inflater: JdkInflater; 15:47:00.981 INFO HaplotypeCaller - GCS max retries/reopens: 20; 15:47:00.981 INFO HaplotypeCaller - Requester pays: disabled; 15:47:00.981 INFO HaplotypeCaller - Initializing engine; 15:47:15.632 INFO HaplotypeCaller - Done initializing engine; 15:47:20.372 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 15:47:20.380 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/glier_ubuntu/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 15:47:20.391 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/glier_ubuntu/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 15:47:20.423 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 15:47:20.423 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 15:47:20.423 INFO IntelPairHmm - Available threads: 40; 15:47:20.423 INFO IntelPairHmm - Requested threads: 4; 15:47:20.423 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 15:47:22.213 INFO ProgressMeter - Starting traversal; 15:47:22.213 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 15:47:22.231 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 15:47:22.231 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 15:47:22.239 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.00 sec; 15:47:22.240 INFO HaplotypeCaller - Shutting down engine; [May 13, 2020 at 3:47:22 p.m. EDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.38 minutes.; Runtime.totalMemory()=3212836864; Exception in thread ""main"" java.lang.IncompatibleClassChangeError: Inconsistent constant pool data in classfile for class org/broadinstitute/hellbender/transformers",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6604:6250,Avail,Available,6250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6604,1,['Avail'],['Available']
Availability,.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:161); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:112); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:95); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(GradleBuildController.java:66); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:7110,ERROR,ERROR,7110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,".CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 18/05/01 14:30:35 WARN ShutdownHookManager: ShutdownHook '$anon$2' timeout, java.util.concurrent.TimeoutException; java.util.concurrent.TimeoutException; 	at java.util.concurrent.FutureTask.get(FutureTask.java:205); 	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:67); 18/05/01 14:31:09 WARN ShutdownHookManager: ShutdownHook 'ClientFinalizer' timeout, java.util.concurrent.TimeoutException; java.util.concurrent.TimeoutException; 	at java.util.concurrent.FutureTask.get(FutureTask.java:205); 	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:67); 18/05/01 14:31:10 INFO ShutdownHookManager: Shutdown hook called; 18/05/01 14:31:15 INFO ShutdownHookManager: Deleting directory /tmp/abd30/spark-3f28d2e3-59d7-40f9-bba3-42d61eff6c6a; 18/05/01 14:31:20 ERROR ShutdownHookManager: ShutdownHookManger shutdown forcefully.; Using GATK jar /gpfs/fs0/home/abd30/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gpfs/fs0/home/abd30/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar PathSeqPipelineSpark --input /data/shenlab/abd/TCGA_microbiome/tmp_WXS_colorectal_all/TCGA-AH-6643-11A-01D-1826-10_hg19_Illumina_gdc_realn.bam --kmer-file /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/host_ref/pathseq_host.bfi --filter-bwa-image /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/host_ref/pathseq_host.fa.img --microbe-bwa-image /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/pathogen_ref/pathseq_microbe.fa.img --microbe-fasta /data/shenlab/abd/TCGA_microbiome/pathseq_bundle/pathogen_ref/pathseq_microbe.fa --taxonom",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:5723,ERROR,ERROR,5723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['ERROR'],['ERROR']
Availability,".ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoade",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5867,ERROR,ERROR,5867,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['ERROR'],['ERROR']
Availability,.ExceptionInInitializerError; 	at org.genomicsdb.GenomicsDBUtils.createTileDBWorkspace(GenomicsDBUtils.java:37); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.overwriteCreateOrCheckWorkspace(GenomicsDBImport.java:883); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.onTraversalStart(GenomicsDBImport.java:605); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1046); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: org.genomicsdb.exception.GenomicsDBException: Could not load genomicsdb native library; 	at org.genomicsdb.GenomicsDBUtilsJni.<clinit>(GenomicsDBUtilsJni.java:33); 	... 10 more; Caused by: java.lang.UnsatisfiedLinkError: /tmp/libtiledbgenomicsdb8918780584607909502.so: libcurl.so.4: cannot open shared object file: No such file or directory; 	at java.lang.ClassLoader$NativeLibrary.load(Native Method); 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941); 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824); 	at java.lang.Runtime.load0(Runtime.java:809); 	at java.lang.System.load(System.java:1086); 	at org.genomicsdb.GenomicsDBLibLoader.loadLibraryFromJar(GenomicsDBLibLoader.java:147); 	at org.genomicsdb.GenomicsDBLibLoader.loadLibrary(GenomicsDBLibLoader.java:47); 	at org.genomicsdb.GenomicsDBUtilsJni.<clinit>(GenomicsDBUtilsJni.java:30); 	... 10 more. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24378/error-while-running-genomicsdbimport/p1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6122:2901,error,error-while-running-genomicsdbimport,2901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6122,1,['error'],['error-while-running-genomicsdbimport']
Availability,".Main.main(Main.java:292); ```. ## Cases when the error does not occur; * If I rename `test a` folder in `test-a` as previously said.; * If I copy my current `test a` in the `/tmp/` directory (`/tmp/test a/`). This may suggest that the path length plays a role.; * If I renamed the VCF files (first VCF becomes `a.vcf.gz`, second `b.vcf.gz`) (`gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O out.vcf.gz`).; * If I rename the first VCF file with as many `a` character as characters found in the original filename. (aaaaaaaaaaaaaaaaaa.vcf.gz).; * If I rename the first VCF by replacing all alphabetical character with a (aaaa_aaaa2.aa_a7_1.vcf.gz); * If I introduce random `_` in the file name (aaaa_aaa_aaaa_aaaa.vcf.gz).; * If I rename the first VCF file by removing the first character (`cerc_prod2.SM_V7_1.vcf.gz` -> `erc_prod2.SM_V7_1.vcf.gz`); * If I rename the first VCF file by introducing a letter at the beginning (`cerc_prod2.SM_V7_1.vcf.gz` -> `ccerc_prod2.SM_V7_1.vcf.gz`). It really seems that the combination of the path lengh, white space and particular filename triggers this. I cannot get my head around this. I don't think this is coming from the content of the VCF as it works well in some cases. Let me know if you need me to make other tests. Fred. ----. ## Update. I investigated a little further after thinking about the tests I did. Because modifying the VCF filename did not trigger the issue and because of the presence of `tabix` related modules in the traces, I decided to see if removing `tbi` file will avoid having the error message. And it did!. After recreating the `tbi` file (`tabix data/calling/cerc_prod2.SM_V7_1.vcf.gz`), the error message appeared again. So it does not seem related to malformed index file. However, index file seems part of the problem. After renaming `test a` folder in `test-a` with the old or new index file, I did not get any error (as usual). Here is my tabix version in case:; ```bash; $ tabix -h. Version: 1.10.2; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241:8624,error,error,8624,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241,3,['error'],['error']
Availability,.SeekableGCSStream.seek(SeekableGCSStream.java:103); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.<init>(SeekableGCSStream.java:59); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAMFile(BAMIO.java:67); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAM(BAMIO.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:178); 	... 20 more; Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized; Anonymous users does not have storage.objects.get access to object mw-pathseq-test/hs37d5cs.reads.sorted.bam.; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:4792); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.openStream(SeekableGCSStream.java:121); 	... 25 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [5b3d4225-0547-4aa9-8a83-ab26460aa2d2] entered state [ERROR] while waiting for [DONE].,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929:11105,ERROR,ERROR,11105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929,2,['ERROR'],['ERROR']
Availability,".ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:46436,AVAIL,AVAILABLE,46436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,".ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:33:07.382 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3e5b2630{/api,null,AVAILABLE,@Spark}; 10:33:07.383 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1b6e4761{/jobs/job/kill,null,AVAILABLE,@Spark}; 10:33:07.384 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@642ec6{/stages/stage/kill,null,AVAILABLE,@Spark}; 10:33:07.389 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:46796,AVAIL,AVAILABLE,46796,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,.SocketException: Connection reset; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 41 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSock,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:5235,avail,available,5235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['avail'],['available']
Availability,.SocketException: Connection reset; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSock,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8723,avail,available,8723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['avail'],['available']
Availability,".USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:3559,ERROR,ERROR,3559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,1,['ERROR'],['ERROR']
Availability,.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2735); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:522); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:150); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:82); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:109); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:167); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [42925293-731b-47bb-8e5e-7f375d9c3490] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289:6934,ERROR,ERROR,6934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289,2,['ERROR'],['ERROR']
Availability,".broadinstitute.org/hc/en-us/community/posts/4409429876123--Did-not-inflate-expected-amount-Error). \--. Hi! I'm doing WGS analysis of a pedigree of three individuals using GATK 4.2.0.0. Everything went on well for the first individual. However, in the step of generating gvcf file from bam file, I encountered the error \[htsjdk.samtools.SAMFormatException: Did not inflate expected amount\] in the other two of the individuals. Please help me! Thank you in advance!. a) GATK version used:. GATK 4.2.0.0. b) Exact command used:. java -jar /home/ngs/biosoft/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar \\ ; ; HaplotypeCaller \\ ; ; \-R /media/ngs/NGS0/Database/RefSeq/Homo\_sapiens\_NCBI\_GRCh38Decoy/Homo\_sapiens/NCBI/GRCh38Decoy/Sequence/WholeGenomeFasta/NewIndex/genome.fa \\ ; ; \-I /media/ngs/BAM5T/WGS\_analysis/Data/9\_BQSRBam/Ped-San-3\_merged\_realigned\_bqsr.bam \\ ; ; \-ERC GVCF \\ ; ; \-O /media/ngs/BAM5T/WGS\_analysis/Data/10\_gvcf/Ped-San-3\_merged\_realigned\_bqsr.g.vcf. c) Entire error log:. 14:14:32.075 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/ngs/biosoft/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Nov 01, 2021 2:14:32 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 14:14:32.573 INFO HaplotypeCaller - ------------------------------------------------------------ ; ; 14:14:32.573 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.2.0.0 ; ; 14:14:32.573 INFO HaplotypeCaller - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 14:14:32.573 INFO HaplotypeCaller - Executing as ngs@ngs-linux on Linux v5.8.0-59-generic amd64 ; ; 14:14:32.573 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_292-8u292-b10-0ubuntu1~20.04-b10 ; ; 14:14:32.573 INFO HaplotypeCall",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7582:1387,error,error,1387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7582,1,['error'],['error']
Availability,.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:230); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$RunTasksAction.execute(DefaultGradleLauncher.java:227); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:56); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:161); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:112); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:95); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.GradleBuildController.run(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:6225,ERROR,ERROR,6225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,".collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(34,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(60,WrappedArray()); 20:38:37.897 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [January 12, 2018 8:38:37 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 42.74 minutes.; Runtime.totalMemory()=16692805632; org.apache.spark.SparkExceptio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:5216,ERROR,ERROR,5216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['ERROR'],['ERROR']
Availability,.common.annotations does not exist; 2022-08-16T00:09:07.4431538Z [0K; 2022-08-16T00:09:07.4431680Z [0K; 2022-08-16T00:09:07.4431811Z [0K; 2022-08-16T00:09:07.4432994Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 49s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.4435974Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T00:09:07.4436105Z @VisibleForTesting; 2022-08-16T00:09:07.4436380Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4436641Z location: class CommandLineProgram; 2022-08-16T00:09:07.4436930Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:120: error: cannot find symbol; 2022-08-16T00:09:07.4437094Z @VisibleForTesting; 2022-08-16T00:09:07.4437369Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4437519Z location: class FeatureInput<T>; 2022-08-16T00:09:07.4437725Z where T is a type-variable:; 2022-08-16T00:09:07.4437925Z T extends Feature declared in class FeatureInput; 2022-08-16T00:09:07.4438276Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:251: error: cannot find symbol; 2022-08-16T00:09:07.4438417Z @VisibleForTesting; 2022-08-16T00:09:07.4438677Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4438873Z location: class PosteriorProbabilitiesUtils; 2022-08-16T00:09:07.4439223Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:271: error: cannot find symbol; 2022-08-16T00:09:07.4439362Z @VisibleForTesting; 2022-08-16T00:09:07.4439618Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4439806Z location: class PosteriorPr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:20596,error,error,20596,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,.common.primitives does not exist; 2022-08-16T00:09:07.4037886Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:200: error: cannot find symbol; 2022-08-16T00:09:07.4038351Z @VisibleForTesting; 2022-08-16T00:09:07.4038957Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4039323Z location: class CountingReadFilter; 2022-08-16T00:09:07.4039849Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T00:09:07.4040311Z @VisibleForTesting; 2022-08-16T00:09:07.4040921Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4041294Z location: class CountingVariantFilter; 2022-08-16T00:09:07.4054361Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4060164Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T00:09:07.4060614Z @VisibleForTesting; 2022-08-16T00:09:07.4061233Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4061591Z location: class ReadFilter; 2022-08-16T00:09:07.4083439Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4092135Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4107682Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4116317Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4117746Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not ex,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:11933,error,error,11933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,.common.primitives does not exist; 2022-08-16T22:45:53.8023734Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:200: error: cannot find symbol; 2022-08-16T22:45:53.8023874Z @VisibleForTesting; 2022-08-16T22:45:53.8024147Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8024320Z location: class CountingReadFilter; 2022-08-16T22:45:53.8024635Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T22:45:53.8024772Z @VisibleForTesting; 2022-08-16T22:45:53.8025036Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8025212Z location: class CountingVariantFilter; 2022-08-16T22:45:53.8032154Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8035089Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T22:45:53.8035234Z @VisibleForTesting; 2022-08-16T22:45:53.8035505Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8035658Z location: class ReadFilter; 2022-08-16T22:45:53.8087327Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8103864Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8113680Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8117654Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8118430Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not ex,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:13971,error,error,13971,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,".copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.LongPipeline.reduce(LongPipeline.java:438); 	at java.util.stream.LongPipeline.sum(LongPipeline.java:396); 	at java.util.stream.ReferencePipeline.count(ReferencePipeline.java:526); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.annotate(CountNs.java:46); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:268); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:192); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:233); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:232); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291). #### Steps to reproduce. There is a clinical sample that results in this error. For that reason I cannot provide the data here, but I can work with the team to debug.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6336:3177,error,error,3177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6336,1,['error'],['error']
Availability,.exec.GradleBuildController.run(GradleBuildController.java:66); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:8194,ERROR,ERROR,8194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,.exec.GradleBuildController.run(GradleBuildController.java:66); 22:05:55.977 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:41); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:79); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:51); 22:05:55.978 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:59); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:47); 22:05:55.979 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:7342,ERROR,ERROR,7342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); 11:54:40.434 [ERROR] [o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:4707,ERROR,ERROR,4707,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,".executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); 	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 17/10/18 17:35:58 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/10/18 17:35:58 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-1,5,main]; java.lang.OutOfMemoryError: Java heap space; 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:208); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hadoop_bam.BAMRecordReader.nextKeyValue(BAMRecordReader.java:225); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182); 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$13.hasNe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:5988,ERROR,ERROR,5988,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['ERROR'],['ERROR']
Availability,".fasta \; -I ""$MASTER_NODE""/data/smallCram.cram \; -O ""$MASTER_NODE""/""$PROJECT_DIR""/fastq \; --exclusionIntervals gs://sv-data-dsde-dev/reference/GRCh38.kill.intervals \; --kmersToIgnore gs://sv-data-dsde-dev/reference/Homo_sapiens_assembly38.dups \; --kmerIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/kmerIntervals \; --breakpointEvidenceDir ""$MASTER_NODE""/""$PROJECT_DIR""/evidence \; --breakpointIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/intervals \; --qnameIntervalsMapped ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsMapped \; --qnameIntervalsForAssembly ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsForAssembly \; --maxFASTQSize 10000000 \; -- \; --sparkRunner GCS \; --cluster svdev-caller; ```. ========================. On the other hand, we see a similar error if the input is changed to the same file but stored in a google bucket (although the cited cause is different):. ```; ***********************************************************************. A USER ERROR has occurred: Failed to read bam header from gs://sv-data-dsde-dev/test_data/smallCram.cram; Caused by:null. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: A USER ERROR has occurred: Failed to read bam header from gs://sv-data-dsde-dev/test_data/smallCram.cram; Caused by:null; 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:381); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:361); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.Com",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:5472,ERROR,ERROR,5472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['ERROR'],['ERROR']
Availability,".j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAIL",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:46195,AVAIL,AVAILABLE,46195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,".j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:33:07.382 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3e5b2630{/api,null,AVAILABLE,@Spark}; 10:33:07.383 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1b6e4761{/jobs/job/kill,null,AVAILABLE,@Spark}; 10:33:07.384 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@642ec6{/stages/stage/kill,null,AVAILABLE,@Spark}; 10:33:07.389 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3fe5ad73{/metrics/json,null,AVAILABLE,@Spark}; 10:33:07.397 INFO SortSamSpark - Spark verbosity set to INFO (see --spark-verbosity argument); 10:33:07.450 INFO GoogleHadoopFileSystemBase - GHFS version: 1.9.4-hadoop3; 10:33:08.183 INFO MemoryStore - Block broadcast_0 stored as values in memory (estimated size 268.7 KiB, free 1076.2 GiB); 10:33:08.581 INFO MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 41.8 KiB, free 1076.2 GiB); 10:33:08.585 INFO BlockManagerInfo - Added broadcast_0_piece0 in memory on 172.20.19.130:43279 (size: 41.8 KiB, free: 1076.2 GiB); 10:33:08.591 INFO SparkContext - Created broadcast 0 from newAPIHadoopFile at PathSplitSource.java:96; 10:33:09.126 INFO MemoryStore - Block broadcast_1 stored as values in mem",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:47632,AVAIL,AVAILABLE,47632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,".jar /. RUN curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash; RUN apt-get install -y git-lfs; RUN git lfs install; RUN apt-get install unzip; RUN apt-get install wget; RUN apt-get install git. RUN mkdir /gatk; RUN apt-get update && apt-get install -y python git mlocate htop && export JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF8 && \; wget https://github.com/broadinstitute/gatk/releases/download/4.0.4.0/gatk-4.0.4.0.zip && unzip gatk-4.0.4.0.zip -d tmp && mv tmp/gatk-4.0.4.0/* /gatk && cp /spark/conf/spark-defaults.conf.template /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.enabled true"" >> /spark/conf/spark-defaults.conf && \; echo ""spark.eventLog.dir file:///spark/logs/"" >> /spark/conf/spark-defaults.conf. ENV PATH=""$PATH:/spark/bin""; ```; I have this configurations for docker-compose:; - Spark. ```; version: '3'; services:; spark-master:; image: atahualpa/spark-master:GATK4.0.4; networks:; - workbench; deploy:; replicas: 1; mode: replicated; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8080; env_file:; - ./hadoop.env; ports:; - 8333:8080; - 4040:4040; - 6066:6066; - 7077:7077; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/fastq/:/fastq/; - /data0/NGS-SparkGATK/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - reference-image:/reference_image. reference:; image: vzzarr/reference:hg19_img; networks:; - workbench; deploy:; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:1327,failure,failure,1327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['failure'],['failure']
Availability,".java:306). real 481m24.418s; user 581m54.752s; sys 2m49.965s. ```. This run did not complete successfully - the Exception caused it to fail prematurely. . Previously I had seen HaplotypeCaller run out of memory and fail in almost as much time, so I think this and the OOM error are related. The only difference in invocation was that with the OOM failure, I was running with the default for `--max-reads-per-alignment-start` (`50`). This also works just fine with that setting at 15. The failure seems to occur around the same place in the data each time (the end of `chr13`). At that point in the data, there is a very large pileup which is probably instigating this. Additionally, if I remove the `--linked-de-bruijn-graph` argument, this runs just fine with the default setting of `--max-reads-per-alignment-start`. I have a minimally reproductive dataset that I can share which reproduces the OOM error for sure (I'm 99% sure it reproduces this one as well). For the OOM failures, the final logs from HaplotypeCaller look like this:. ```; ./gatk HaplotypeCaller ...; ...; 15:56:23.205 INFO ProgressMeter - Pf3D7_13_v3:2603234 100.5 114070 1134.5; 15:56:33.443 INFO ProgressMeter - Pf3D7_13_v3:2661462 100.7 114420 1136.1; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:56:43.998 INFO ProgressMeter - Pf3D7_13_v3:2730055 100.9 114840 1138.3; 15:56:59.911 INFO ProgressMeter - Pf3D7_13_v3:2798281 101.2 115210 1139.0; 15:59:27.062 INFO ProgressMeter - Pf3D7_13_v3:2861780 103.6 115460 1114.4; Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); Dangling End recovery killed because of a loop (getReferencePathForwardFromKmer); 15:59:37.457 INFO ProgressMeter - Pf3D7_13_v3:2869697 103.8 115500 1112.9. real 671m24.770s; user 777m30.923s; sys 6m13.682s. $ echo $?; 247; ```. Here is my command-line invocation:; ```; ./gatk --java-options ""-Xmx100000m -Xms25000m"" \; HaplotypeCaller \; -R /juffowup2/malaria/references/PlasmoDB-61_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8440:5030,failure,failures,5030,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8440,1,['failure'],['failures']
Availability,".java:36); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:117); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ClassNotFoundException: org.xerial.snappy.LoadSnappy; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 11 more. We can find snappy-java in <INST_DIR>/build/install/gatk/lib/snappy-java-1.1.1.7.jar, but it does not have a LoadSnappy class. Renaming the snappy-java jar file so gatk cannot find it allows FastqToSam to run through. ---. @akiezun commented on [Thu Jun 30 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-229843043). thanks for the report. Can you provide the whole commandline you used?. ---. @huangk3 commented on [Thu Sep 15 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-247467619). Hi @akiezun I experience the same error when running gate-launch FastqToSam. My command line is:; ""./gatk_launch FastqToSam -SM ""test"" -F1 $fq1 -F2 $fq2 -O test.spark.sam -SO coordinate -R $ref --STRIP_UNPAIRED_MATE_NUMBER true --VALIDATION_STRINGENCY LENIENT -PL ILLUMINA --CREATE_INDEX true"". My Spark version is 2.0.0; Thanks!. ---. @lbergelson commented on [Mon Sep 19 2016](https://github.com/broadinstitute/gatk-protected/issues/587#issuecomment-248086238). @huangk3 Unfortunately Adam moved on to a different job so he's longer working on GATK. . I believe this is the same problem as https://github.com/broadinstitute/gatk/issues/2026 and has been patched in gatk public with https://github.com/broadinstitute/gatk/pull/2028. You might try using FastqToSam in the public repo, or wait and try a new version of protected that incorporates an updated gatk public (coming soon..)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2868:2685,error,error,2685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2868,1,['error'],['error']
Availability,.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3936070Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3937759Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.3941846Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3952011Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3953755Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3960718Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3962332Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3968675Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3978229Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3984771Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:8704,error,error,8704,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7810436Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7857595Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.7861943Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7871768Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7873510Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7881195Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7882811Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7889039Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7926431Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7973092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:10742,error,error,10742,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,".local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:2408,Down,Downsampling,2408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,2,"['Down', 'down']","['Downsampling', 'downsampling']"
Availability,.newByteChannel(CloudStorageFileSystemProvider.java:305); 	at java.nio.file.Files.newByteChannel(Files.java:361); 	at java.nio.file.Files.newByteChannel(Files.java:407); 	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newInputStream(CloudStorageFileSystemProvider.java:482); 	at java.nio.file.Files.newInputStream(Files.java:152); 	at java.nio.file.Files.newBufferedReader(Files.java:2784); 	at java.nio.file.Files.lines(Files.java:3744); 	at java.nio.file.Files.lines(Files.java:3785); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorDataSourceDownloader.readSha256SumFromPath(FuncotatorDataSourceDownloader.java:277); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorDataSourceDownloader.downloadDataSources(FuncotatorDataSourceDownloader.java:252); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorDataSourceDownloader.downloadAndValidateDataSources(FuncotatorDataSourceDownloader.java:230); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorDataSourceDownloader.doWork(FuncotatorDataSourceDownloader.java:203); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: com.google.cloud.storage.StorageException: connect timed out; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:4861,down,downloadAndValidateDataSources,4861,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['down'],['downloadAndValidateDataSources']
Availability,".onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; 11:00:54.078 INFO AbstractConnector - Stopped Spark@2f829853{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}; 11:00:54.091 INFO SparkUI - Stopped Spark web UI at http://172.20.19.130:4040; 11:00:54.122 INFO MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!; 11:00:54.175 INFO MemoryStore - MemoryStore cleared; 11:00:54.175 INFO BlockManager - BlockManager stopped; 11:00:54.193 INFO BlockManagerMaster - BlockManagerMaster stopped; 11:00:54.211 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!; 11:00:54.302 INFO SparkContext - Successfully stopped SparkContext; 11:00:54.303 INFO SortSamSpark - Shutting down engine; [August 11, 2024 at 11:00:54 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.SortSamSpark done. Elapsed time: 27.81 minutes.; Runtime.totalMemory()=1926292832256; org.apache.spark.SparkException: Job aborted.; at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:106); at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsNewAPIHadoopDataset$1(PairRDDFunctions.scala:1078); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:406); at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopDataset(PairRDDFunctions.scala:1076); at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsNewAPIHadoopFile$2(PairRDDFunctions.scala:995); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:24605,down,down,24605,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['down'],['down']
Availability,".py#L215); [gcnvkernel model_denoising_calling.py](https://github.com/broadinstitute/gatk/blob/4e1741896bcd04d70493f94b082dd0d27023f14c/src/main/python/org/broadinstitute/hellbender/gcnvkernel/models/model_denoising_calling.py); [gcnvkernel io_metadata.py write_sample_coverage_metadata function](https://github.com/broadinstitute/gatk/blob/4e1741896bcd04d70493f94b082dd0d27023f14c/src/main/python/org/broadinstitute/hellbender/gcnvkernel/io/io_metadata.py#L16); [theano scan_op.py](https://github.com/Theano/Theano/blob/master/theano/scan_module/scan_op.py). ### Affected version(s); - [x] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I'm getting a strange error (see below) when running a nf-core module test. I am using test files, which are obviously smaller as for short testing times i.e. the provided bam file only provides mapped reads for a small section of the genome. #### Steps to reproduce; Run the following to create and interactive container and mount the required zip folder ([gatk_test.tar.gz](https://github.com/broadinstitute/gatk/files/10022295/gatk_test.tar.gz)):; ```docker run -it -v /path/to/gatk_test_dir:/mnt/gatk_test broadinstitute/gatk bash```; If you bash the `gatk_germlinecnvcaller.sh` within the provided zip folder in a gatk4 Docker container. #### Expected behavior; gatk GermlineCNVCaller should run as expected. #### Actual behavior; ```TypeError: ('The following error happened while compiling the node', forall_inplace,cpu,scan_fn}(Elemwise{Maximum}[(0, 0)].0, Subtensor{int64:int64:int8}.0, Subtensor{int64:int64:int8}.0, IncSubtensor{InplaceSet;:int64:}.0, Elemwise{mul,no_inplace}.0, Subtensor{int64::}.0, Elemwise{sub,no_inplace}.0), '\n', ""Inconsistency in the inner graph of scan 'scan_fn' : an input and an output are associated with the same recurrent state and should have the same type but have type 'TensorType(float64, row)' and 'TensorType(float64, matrix)' respectively."")```. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8097:1955,error,error,1955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8097,1,['error'],['error']
Availability,.read(BlobReadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocket,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:7008,avail,available,7008,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['avail'],['available']
Availability,".s.ServletContextHandler@2bdb5e0f{/storage/rdd/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2262f0d8{/environment,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59e082f8{/environment/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d43cc9{/executors,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@656ec00d{/executors/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed25612{/executors/threadDump,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56e5c8fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9e33a6a{/static,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b3fc6d8{/,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed31735{/api,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@351e89fc{/jobs/job/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15586843{/stages/stage/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.131.101.159:4040; 17/10/13 18:11:34 INFO spark.SparkContext: Added JAR file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar at spark://10.131.101.159:45754/jars/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar with timestamp 1507889494965; 17/10/13 18:11:35 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecut",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:8404,AVAIL,AVAILABLE,8404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,".s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e99e2cb{/static,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478967eb{/,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f2b39a{/api,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18c880ea{/jobs/job/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6afbe6a1{/stages/stage/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:56 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.4:4040; 18/01/09 18:30:56 INFO spark.SparkContext: Added JAR file:/opt/NfsDir/BioDir/GATK4/gatk/build/libs/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar at spark://192.168.1.4:38793/jars/gatk-package-4.beta.5-50-g8d666b6-SNAPSHOT-spark.jar with timestamp 1515493856032; 18/01/09 18:30:56 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 18/01/09 18:30:57 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:9816,AVAIL,AVAILABLE,9816,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,".s.j.s.ServletContextHandler@3a588b5f{/storage/rdd,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bdb5e0f{/storage/rdd/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2262f0d8{/environment,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@59e082f8{/environment/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44d43cc9{/executors,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@656ec00d{/executors/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed25612{/executors/threadDump,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56e5c8fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9e33a6a{/static,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b3fc6d8{/,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ed31735{/api,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@351e89fc{/jobs/job/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15586843{/stages/stage/kill,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.131.101.159:4040; 17/10/13 18:11:34 INFO spark.SparkContext: Added JAR file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar at spark://10.131.101.159:45754/jars/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar wit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:8279,AVAIL,AVAILABLE,8279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,".s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10:33:07.371 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@42172065{/executors/threadDump/json,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@8e77c5b{/static,null,AVAILABLE,@Spark}; 10:33:07.380 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@49741274{/,null,AVAILABLE,@Spark}; 10:33:07.382 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3e5b2630{/api,null,AVAILABLE,@Spark}; 10:33:07.383 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1b6e4761{/jobs/job/kill,null,AVAILABLE,@Spark}; 10:33:07.384 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@642ec6{/stages/stage/kill,null,AVAILABLE,@Spark}; 10:33:07.389 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3fe5ad73{/metrics/json,null,AVAILABLE,@Spark}; 10:33:07.397 INFO SortSamSpark - Spark verbosity set to INFO (see --spark-verbosity argument); 10:33:07.450 INFO GoogleHadoopFileSystemBase - GHFS version: 1.9.4-hadoop3; 10:33:08.183 INFO MemoryStore - Block broadcast_0 stored as values in memory (estimated size 268.7 KiB, free 1076.2 GiB); 10:33:08.581 INFO MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 41.8 KiB, free 1076.2 GiB); 10:33:08.585 INFO BlockManagerInfo - Added broadcast_0_piece0 in memory on 172.20.19.130:43279 (size: 41.8 KiB, free: 1076.2 GiB); 10:33:08.591 INFO SparkContext - Created broadcast 0 from newAPIHadoopFile at PathSplitSource.java:96; 10:33:09.126 INFO MemoryStore - Block broadcast_1 stored as values in memory (estimated size 268.7 KiB, free 1076.2 GiB); 10:33:09.142 INFO MemoryStore - Block broadcast_1_piece0 stored as bytes ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:47755,AVAIL,AVAILABLE,47755,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,".s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07.366 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7e8783b0{/environment/json,null,AVAILABLE,@Spark}; 10:33:07.367 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@53d2f0ec{/executors,null,AVAILABLE,@Spark}; 10:33:07.369 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@14d36bb2{/executors/json,null,AVAILABLE,@Spark}; 10:33:07.370 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4452e13c{/executors/threadDump,null,AVAILABLE,@Spark}; 10",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:46075,AVAIL,AVAILABLE,46075,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,".samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:36); 	at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); 	at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:124); 	at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.samtools.SAMException: Exception creating BAM index for record i 1/2 76b aligned read.; 	at htsjdk.samtools.BAMIndexer.processAlignment(BAMIndexer.java:119); 	at htsjdk.samtools.BAMFileWriter.writeAlignment(BAMFileWriter.java:139); 	... 5 more; Caused by: htsjdk.samtools.SAMException: IOException in BinaryBAMIndexWriter reference 0; 	at htsjdk.samtools.BinaryBAMIndexWriter.writeReference(BinaryBAMIndexWriter.java:151); 	at htsjdk.samtools.BAMIndexer.advanceToReference(BAMIndexer.java:138); 	at htsjdk.samtools.BAMIndexer.processAlignment(BAMIndexer.java:115); 	... 6 more; Caused by: java.nio.channels.ClosedByInterruptException; 	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202); 	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:216); 	at java.nio.channels.Channels.writeFullyImpl(Channels.java:78); 	at java.nio.channels.Channels.writeFully(Channels.java:101); 	at java.nio.channels.Channels.access$000(Channels.java:61); 	at java.nio.channels.Channels$1.write(Channels.java:174); 	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82); 	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140); 	at htsjdk.samtools.BinaryBAMIndexWriter.writeReference(BinaryBAMIndexWriter.java:149); 	... 8 more; ```. One of the logs is here: https://storage.googleapis.com/hellbender-test-logs/build_reports/12617.7/tests/test/index.html. We saw a whole host of those cigar validation errors you're seeing when we updated htsdjk the last time, it's a new validation that wasn't previously checked in htsjdk, so a lot of the test files had errors in them that no one had ever noticed/bothered fixing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-329967977:2158,error,errors,2158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-329967977,2,['error'],['errors']
Availability,".setPosition(SAMRecordToGATKReadAdapter.java:89); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:147); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:128); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:332); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:335); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:84); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:238); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:478); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$580(HaplotypeCallerSpark.java:203) ; ```. At first glance this looks like a problem with unmapped reads, but these are filtered out by the tool. So it's more likely to be in the clipping logic. It's hard to diagnose since it doesn't say which read caused it, and it's slow to reproduce as it is running on a large input. Any thoughts @lbergelson, @droazen?. ---. @lbergelson commented on [Sat May 27 2017](https://github.com/broadinstitute/gatk-protected/issues/1091#issuecomment-304466112). @tomwhite Is it possible you could upload the bam file somewhere on google cloud along with the command line you used? It's not obvious to me where the error is being caused. It's painful to debug anything on a 160GB file, but I think we can probably do a binary search on the file and find the bad location pretty quickly. I.e. throw compute at the problem instead of human time...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013:2089,error,error,2089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013,1,['error'],['error']
Availability,".soohee1k.hdf5 (15 / 24); 21:55:02.822 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG03642.lc.soohee1k.hdf5 (16 / 24); 21:55:04.931 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG03742.lc.soohee1k.hdf5 (17 / 24); 21:55:06.457 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA18525.lc.soohee1k.hdf5 (18 / 24); 21:55:07.933 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA18939.lc.soohee1k.hdf5 (19 / 24); 21:55:09.347 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA19017.lc.soohee1k.hdf5 (20 / 24); 21:55:11.068 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA19625.lc.soohee1k.hdf5 (21 / 24); 21:55:13.479 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA19648.lc.soohee1k.hdf5 (22 / 24); 21:55:15.323 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA20502.lc.soohee1k.hdf5 (23 / 24); 21:55:17.219 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/NA20845.lc.soohee1k.hdf5 (24 / 24); 01:27:10.674 INFO GermlineCNVCaller - Germline denoising and CNV calling complete.; 01:27:10.676 INFO GermlineCNVCaller - Shutting down engine; [May 29, 2018 1:27:10 AM UTC] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 212.70 minutes.; Runtime.totalMemory()=5764022272; Tool returned:; SUCCESS; ```. Would be great to have a summary of useful information, e.g. (but not limited to):. - Total number of epochs (INFO level); - ELBO value and SNR value etc for the final epochs (INFO level); - Whether convergence was achieved or not (WARN if not). Currently, the only way to get all three pieces of information is through setting `--verbosity DEBUG`, which makes for very long stdouts that go well beyond what tmux saves.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4826:6339,down,down,6339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4826,1,['down'],['down']
Availability,".tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:1332,Error,Error,1332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,1,['Error'],['Error']
Availability,".tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq_v75_37.tsv; 15:41:54.798 INFO Funcotator - Initializing Funcotator Engine...; 15:41:54.811 INFO Funcotator - Creating a MAF file for output: file:/home/shiyang/Project/BGB900_101/TSO_result/test.maf; 15:41:54.826 INFO ProgressMeter - Starting traversal; 15:41:54.827 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 15:41:54.853 INFO VcfFuncotationFactory - ClinVar_VCF 20180401 cache hits/total: 0/0; 15:41:54.854 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 15:41:54.860 INFO Funcotator - Shutting down engine; [August 19, 2020 3:41:54 PM CST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2588409856; htsjdk.tribble.TribbleException$MalformedFeatureFile: Error parsing LineIteratorImpl(SynchronousLineReader) at the first queried after chr1:2489658, for input source: file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:532); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.<init>(TribbleIndexedFeatureReader.java:441); at htsjdk.tribble.TribbleIndexedFeatureReader.query(TribbleIndexedFeatureReader.java:297); at org.broadinstitute.hellbender.engine.FeatureDataSource.refillQueryCache(FeatureDataSource.java:567); at org.broadinstitute.hellbender.engine.FeatureDataSource.queryAndPrefetch(FeatureDataSource.java:536); at org.broadinstitute.hellbender.engine.FeatureManager.getFeatures(FeatureManager.java:352); at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:173); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.queryFeaturesFromFeatureContext(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:20542,Error,Error,20542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['Error'],['Error']
Availability,"//media/deepak/EXTRA/FUNCOTATOR_DATA/DATA_SOURCES/data_source_3/hg38/Cosmic.db; .; .; .; .; .; .; .; . 16:01:43.969 INFO DataSourceUtils - Resolved data source file path: file:///home/deepak/software_library/gatk-4.1.7.0/dnaRepairGenes.20180524T145835.csv -> file:///media/deepak/EXTRA/FUNCOTATOR_DATA/DATA_SOURCES/data_source_8/hg38/dnaRepairGenes.20180524T145835.csv; 16:01:43.979 INFO Funcotator - Initializing Funcotator Engine...; 16:01:43.983 INFO Funcotator - Creating a VCF file for output: file:/home/deepak/software_library/gatk-4.1.7.0/variants.funcotated.vcf; 16:01:44.020 INFO ProgressMeter - Starting traversal; 16:01:44.020 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 16:01:44.068 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr1:1-10454 due to alternate allele: <NON_REF>; 16:01:44.116 INFO VcfFuncotationFactory - dbSNP 9606_b150 cache hits/total: 0/0; 16:01:44.121 INFO Funcotator - Shutting down engine; [12 May, 2020 4:01:44 PM IST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.14 minutes.; Runtime.totalMemory()=2889875456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:-9 end:10464; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:733); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createReferenceSnippet(FuncotatorUtils.java:1439); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getBasesInWindowAroundReferenceAllele(FuncotatorUtils.java:1468); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationForSymbolicAltAllele(GencodeFuncotationFactory.java:2560); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.Genc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:6100,down,down,6100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['down'],['down']
Availability,"/01 14:20:59 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.12.137.46, 39719, None),broadcast_1_piece0,StorageLevel(memory, 1 replicas),127561,0)); 18/05/01 14:21:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/05/01 14:23:29 INFO MemoryStore: MemoryStore cleared; 18/05/01 14:23:29 INFO BlockManager: BlockManager stopped; 18/05/01 14:23:29 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/05/01 14:24:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/05/01 14:25:36 INFO SparkContext: Successfully stopped SparkContext; 14:25:37.027 INFO PathSeqPipelineSpark - Shutting down engine; [May 1, 2018 2:25:37 PM EDT] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 37.98 minutes.; Runtime.totalMemory()=23999283200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: Lost task 20.0 in stage 1.0 (TID 891, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 131031 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.schedul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:1951,failure,failure,1951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['failure'],['failure']
Availability,"/05/23 13:20:18 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1163; 23/05/23 13:20:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[73] at mapToPair at BamSink.java:91) (first 15 tasks are for partitions Vector(0)); 23/05/23 13:20:18 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks; 23/05/23 13:20:18 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 1973, localhost, executor driver, partition 0, PROCESS_LOCAL, 7662 bytes); 23/05/23 13:20:18 INFO Executor: Running task 0.0 in stage 30.0 (TID 1973); 23/05/23 13:20:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks; 23/05/23 13:20:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms; 23/05/23 13:20:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 23/05/23 13:20:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 23/05/23 13:20:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 23/05/23 13:20:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 23/05/23 13:20:18 INFO FileOutputCommitter: Saved output of task 'attempt_20230523132018_0073_r_000000_0' to file:pathseq/CRC_16.pathseq.complete.bam.parts; 23/05/23 13:20:18 INFO SparkHadoopMapRedUtil: attempt_20230523132018_0073_r_000000_0: Committed; 23/05/23 13:20:18 INFO Executor: Finished task 0.0 in stage 30.0 (TID 1973). 1149 bytes result sent to driver; 23/05/23 13:20:18 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 1973) in 184 ms on localhost (executor driver) (1/1); 23/05/23 13:20:18 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool ; 23/05/23 13:20:18 INFO DAGScheduler: ResultStage 30 (runJob at SparkHadoopWriter.scala:78) finished i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8339:52464,failure,failures,52464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8339,2,['failure'],['failures']
Availability,"/13 18:11:34 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 17/10/13 18:11:34 INFO storage.DiskBlockManager: Created local directory at /tmp/hdfs/blockmgr-ea0e0669-2981-4277-80a0-a67eddf1001d; 17/10/13 18:11:34 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering OutputCommitCoordinator; 17/10/13 18:11:34 INFO util.log: Logging initialized @3816ms; 17/10/13 18:11:34 INFO server.Server: jetty-9.3.z-SNAPSHOT; 17/10/13 18:11:34 INFO server.Server: Started @3902ms; 17/10/13 18:11:34 INFO server.AbstractConnector: Started ServerConnector@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:34 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@710ae6a7{/jobs,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7b211077{/jobs/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62b0bf85{/jobs/job,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f07d414{/jobs/job/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40faff12{/stages,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@223967ea{/stages/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5d7f1e59{/stages/stage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68e47e7{/stages/stage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16ac4d3d{/stages/pool,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.Ser",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:5885,AVAIL,AVAILABLE,5885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4002426Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4005459Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T00:09:07.4005923Z @VisibleForTesting; 2022-08-16T00:09:07.4006520Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4006876Z location: class PileupElement; 2022-08-16T00:09:07.4015304Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4023160Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4025208Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4026746Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4037886Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:200: error: cannot find symbol; 2022-08-16T00:09:07.4038351Z @VisibleForTesting; 2022-08-16T00:09:07.4038957Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4039323Z location: class CountingReadFilter; 2022-08-16T00:09:07.4039849Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T00:09:07.4040311Z @VisibleForTesting; 2022-08-16T00:09:07.4040921Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4041294Z location: class CountingVariantFilter; 2022-08-16T00:09:07.4054361Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:10777,error,error,10777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7993443Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7996577Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T22:45:53.7997033Z @VisibleForTesting; 2022-08-16T22:45:53.7997778Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.7998135Z location: class PileupElement; 2022-08-16T22:45:53.8006697Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8013274Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8014882Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8016302Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8023734Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:200: error: cannot find symbol; 2022-08-16T22:45:53.8023874Z @VisibleForTesting; 2022-08-16T22:45:53.8024147Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8024320Z location: class CountingReadFilter; 2022-08-16T22:45:53.8024635Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T22:45:53.8024772Z @VisibleForTesting; 2022-08-16T22:45:53.8025036Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8025212Z location: class CountingVariantFilter; 2022-08-16T22:45:53.8032154Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:12815,error,error,12815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5934:1002,error,error,1002,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5934,1,['error'],['error']
Availability,"/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5934:1285,error,error,1285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5934,1,['error'],['error']
Availability,"/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:106: error: unmappable character for encoding ASCII; * SOR = ln(5.7284) + ln(0.2385) ??? ln(0.7559) = 1.7454427755 + (-1.433) ??? (-0.2798) = 0.592; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <nobr>???-initial-tumor-lod</nobr> to 0, <nobr>???-tumor-lod-to-emit</nobr> to 0, <nobr>--af-of-alleles-not-in-resource</nobr> to; ^; /usr/ports/biology/gatk/work/gatk-4.1.2.0/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2.java:137: error: unmappable character for encoding ASCII; * Specifically, the mode sets <n",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5934:1568,error,error,1568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5934,1,['error'],['error']
Availability,/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.g,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:2563,ERROR,ERROR,2563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3962332Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3968675Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3978229Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3984771Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3993495Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4002426Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4005459Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T00:09:07.4005923Z @VisibleForTesting; 2022-08-16T00:09:07.4006520Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4006876Z location: class PileupElement; 2022-08-16T00:09:07.4015304Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4023160Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4025208Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:4: error: package com.google.commo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:9802,error,error,9802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7882811Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7889039Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7926431Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7973092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7983013Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7993443Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7996577Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T22:45:53.7997033Z @VisibleForTesting; 2022-08-16T22:45:53.7997778Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.7998135Z location: class PileupElement; 2022-08-16T22:45:53.8006697Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8013274Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8014882Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:4: error: package com.google.commo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:11840,error,error,11840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,/cw-test-m:8020/output/variants/inv_del_ins.vcf -R hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.2bit --aligner-index-image /mnt/1/reference/Homo_sapiens_assembly38.fasta.img --exclusion-intervals hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.intervals --kmers-to-ignore hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.kmers --cross-contigs-to-ignore hdfs://cw-test-m:8020/reference/Homo_sapiens_assembly38.kill.alts --breakpoint-intervals hdfs://cw-test-m:8020/output/intervals --fastq-dir hdfs://cw-test-m:8020/output/fastq --contig-sam-file hdfs://cw-test-m:8020/output/assemblies.sam --target-link-file hdfs://cw-test-m:8020/output/target_links.bedpe --exp-variants-out-dir hdfs://cw-test-m:8020/output/experimentalVariantInterpretations -- --spark-runner GCS --cluster cw-test --num-executors 20 --driver-memory 30G --executor-memory 30G --conf spark.yarn.executor.memoryOverhead=5000 --conf spark.network.timeout=600 --conf spark.executor.heartbeatInterval=120 --conf spark.driver.userClassPathFirst=false; ```. It failed near the end of the pipeline. Here is the tail of the log:. ```; 20:38:14.368 INFO StructuralVariationDiscoveryPipelineSpark - Used 3549 evidence target links to annotate assembled breakpoints; 20:38:14.462 INFO StructuralVariationDiscoveryPipelineSpark - Called 662 imprecise deletion variants; 20:38:14.492 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 7234 variants.; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INV: 184; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4486; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1170; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1394; 18/01/12 20:38:16 WARN org.apache.spark.scheduler.TaskSetManager: Stage 17 contains a task of very large size (2518 KB). The maximum recommended task size is 100 KB.; 18/01/12 20:38:22 WARN org.apache.spark.scheduler.TaskSetManager: Stage 18 contains a task o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:1230,heartbeat,heartbeatInterval,1230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['heartbeat'],['heartbeatInterval']
Availability,"/data/project/naangda_panel_20230228/output/mutect/probe/normal_mutect/sssss4.filtered.mutect2.vcf -O /data/project/naangda_panel_20230228/output/mutect/Funcotator/sssss4.funcocator.maf --output-file-format MAF --data-sources-path /data/Homo_sapiens/Homo_sapiens_38/funcotator/funcotator_dataSources.v1.7.20200521s/ --ref-version hg38. code2; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /root/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator -R /data/Homo_sapiens/Homo_sapiens_38/Homo_sapiens_assembly38.fasta -V /data/project/naangda_panel_20230228/output/mutect/probe/normal_mutect/sssss4.filtered.mutect2.vcf -O /data/project/naangda_panel_20230228/output/mutect/Funcotator/sssss4.funcocator.maf --output-file-format MAF --data-sources-path /data/Homo_sapiens/Homo_sapiens_38/funcotator/funcotator_dataSources.v1.7.20200521s/ --ref-version hg38. what's the problem with the program?; 1. I had download database, why error ""com.google.cloud.storage.StorageException: Connection reset"" happened?; 2. why I got only a file with title but no records like this, what should I do to solve this problem. ## Funcotator 4.1.8.1 | Date 20233731T033757 | Gencode 34 CANONICAL | Achilles 110303 | ClinVar_VCF 20180429_hg38 | Cosmic v84 | CosmicFusion v84 | CosmicTissue v83 | Familial_Cancer_Genes 20110905 | Gencode_XHGNC 90_38 | Gencode_XRefSeq 90_38 | HGNC Nov302017 | Oreganno 20160119 | Simple_Uniprot 2014_12 | dbSNP 9606_b151; Hugo_Symbol	Entrez_Gene_Id	Center	NCBI_Build	Chromosome	Start_Position	End_Position	Strand	Variant_Classification	Variant_Type	Reference_Allele	Tumor_Seq_Allele1	Tumor_Seq_Allele2	dbSNP_RSdbSNP_Val_Status	Tumor_Sample_Barcode	Matched_Norm_Sample_Barcode	Match_Norm_Seq_Allele1	Match_Norm_Seq_Allele2	Tumor_Validation_Allele1	Tumor_Validation_Allele2	Match_Norm_Validation_Allele1	Match_Norm_Valida",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275:2366,down,download,2366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275,2,"['down', 'error']","['download', 'error']"
Availability,/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3921838Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3936070Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3937759Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.3941846Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3952011Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3953755Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3960718Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3962332Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3968675Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3978229Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annot,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:8491,error,error,8491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7798240Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7810436Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7857595Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.7861943Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7871768Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7873510Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7881195Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7882811Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7889039Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7926431Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annot,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:10529,error,error,10529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/cram/HG02759.alt_bwamem_GRCh38DH.20150826.GWD.exome.cram`. (I was a high storage cost offender and asked to clean up.) Luckily, I have another CRAM available that I left for testing purposes. I can recapitulate the error with this other CRAM using the old `gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT` jar. ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-launch PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam; ```. Gives the same error at an approximately similar region:; ```; ...; 10:50:54.603 INFO ProgressMeter - chr1:224042054 2.2 11004000 5016945.0; 10:51:04.609 INFO ProgressMeter - chr1:248061327 2.4 11905000 5044206.5; ERROR	2017-10-02 10:51:05	Slice	Reference MD5 mismatch for slice 0:248574592-248771907, AGTGGATGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:995,ERROR,ERROR,995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828,1,['ERROR'],['ERROR']
Availability,"/hg19.fa.gz). Any feedback leading to resolving the issue is greatly appreciated. a) Picard version:. 2.21.6-SNAPSHOT. b) Command script:. java -jar picard.jar CollectGcBiasMetrics \\ ; ; I=sorted.sam \\ ; ; O=gc\_bias\_metrics.txt \\ ; ; CHART=gc\_bias\_metrics.pdf \\ ; ; S=summary\_metrics.txt \\ ; ; R=hg19.fa \\ ; ; SCAN\_WINDOW\_SIZE=1000. c) Error log:. MINIMUM\_GENOME\_FRACTION=1.0E-5 IS\_BISULFITE\_SEQUENCED=false METRIC\_ACCUMULATION\_LEVEL=\[ALL\_READS\] ALSO\_IGNORE\_DUPLICATES=false ASSUME\_SORTED=true STOP\_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION\_STRINGENCY=STRICT COMPRESSION\_LEVEL=5 MAX\_RECORDS\_IN\_RAM=500000 CREATE\_INDEX=false CREATE\_MD5\_FILE=false GA4GH\_CLIENT\_SECRETS=client\_secrets.json USE\_JDK\_DEFLATER=false USE\_JDK\_INFLATER=false ; ; \[Tue Jan 07 16:48:19 PST 2020\] Executing as [akoch@hpc5-0-3.local](mailto:akoch@hpc5-0-3.local) on Linux 2.6.32-431.11.2.el6.x86\_64 amd64; OpenJDK 64-Bit Server VM 1.8.0\_181-b13; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.21.6-SNAPSHOT ; ; INFO 2020-01-07 16:51:24 SinglePassSamProgram Processed 1,000,000 records. Elapsed time: 00:00:33s. Time for last 1,000,000: 27s. Last read position: chr5:92,832,908 ; ; INFO 2020-01-07 16:51:53 SinglePassSamProgram Processed 2,000,000 records. Elapsed time: 00:01:01s. Time for last 1,000,000: 28s. Last read position: chr11:121,228,669 ; ; \[Tue Jan 07 16:52:25 PST 2020\] picard.analysis.CollectGcBiasMetrics done. Elapsed time: 4.10 minutes. ; ; Runtime.totalMemory()=4236247040 ; ; To get help, see [http://broadinstitute.github.io/picard/index.html#GettingHelp](http://broadinstitute.github.io/picard/index.html#GettingHelp) ; ; Exception in thread ""main"" htsjdk.samtools.SAMException: Exception counting mismatches for read XXXXXXXX0434501/1 32b aligned to chrX:51305151-51305182. ; ; at htsjdk.samtools.util.SequenceUtil.countMismatches(SequenceUtil.java:490) ; ; at htsjdk.samtools.util.SequenceUtil.countMismatches(SequenceUt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6372:1950,avail,available,1950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6372,1,['avail'],['available']
Availability,"/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 16:51:51.764 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/vlad/bcbio/anaconda/share/gatk4-4.0b5-0/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 16:51:51.795 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 16:51:51.796 INFO IntelPairHmm - Available threads: 32; 16:51:51.796 INFO IntelPairHmm - Requested threads: 4; 16:51:51.796 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 16:51:51.815 INFO ProgressMeter - Starting traversal; 16:51:51.815 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 16:51:51.881 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 16:51:51.881 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 16:51:51.881 INFO HaplotypeCaller - Shutting down engine; [16 November 2017 4:51:51 PM] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=1640497152; java.lang.IllegalArgumentException: contig must be non-null and not equal to *, and start must be >= 1; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setPosition(SAMRecordToGATKReadAdapter.java:92); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.applyHARDCLIP_BASES(ClippingOp.java:381); at org.broadinstitute.hellbender.utils.clipping.ClippingOp.apply(ClippingOp.java:73); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:145); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.clipRead(ReadClipper.java:126); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:330); at org.broadinstitute.hellbender.utils.clipping.ReadClipper.hardClipSoftClippedBases(ReadClipper.java:333); at org.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3845:9365,down,down,9365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845,1,['down'],['down']
Availability,"/io_commons.py"", line 98, in assert_output_path_writable; filehandle = open(filename, 'w'); PermissionError: [Errno 13] Permission denied: '/home/shlee/gcc/hc24_soohee1k_chr1-model/write_tester'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/shlee/cohort_denoising_calling.7832183760446168530.py"", line 151, in <module>; args.output_model_path)(); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/io/io_denoising_calling.py"", line 28, in __init__; io_commons.assert_output_path_writable(output_path); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/io/io_commons.py"", line 102, in assert_output_path_writable; raise IOError(""The output path \""{0}\"" is not writeable"".format(output_path)); OSError: The output path ""/home/shlee/gcc/hc24_soohee1k_chr1-model"" is not writeable; 16:26:00.659 DEBUG ScriptExecutor - Result: 1; 16:26:00.662 INFO GermlineCNVCaller - Shutting down engine; [May 27, 2018 4:26:00 PM UTC] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 2,255.34 minutes.; Runtime.totalMemory()=8207728640; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/shlee/cohort_denoising_calling.7832183760446168530.py --ploidy_calls_path=/home/shlee/gcnv/coverage_1k/hc24_soohee1kall_ploidy-calls --output_calls_path=/home/shlee/gcc/hc24_soohee1k_chr1-calls --modeling_interval_list=/tmp/shlee/intervals1147946183347323472.tsv --output_model_path=/home/shlee/gcc/hc24_soohee1k_chr1-model --enable_explicit_gc_bias_modeling=False --read_count_tsv_files /tmp/shlee/sample-04516283083315244626.tsv /tmp/shlee/sample-17497576995757363646.tsv /tmp/shlee/sample-21271002324475135098.tsv /tmp/shlee/sample-36985602309924438312.tsv /tmp/shlee/sample-44773997237633003175.tsv /tmp/shlee/sample-55563425618633690228.tsv /tmp/shlee/sample-66588087553393228850.tsv /tmp/shlee/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825:1135,down,down,1135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825,1,['down'],['down']
Availability,"/lib/ext/localedata.jar,/gatk/gatk-package-unspecified-SNAPSHOT-local.jar,/jars/gatk-package-4.2.6.1-50-g40182c7-SNAPSHOT-testDependencies.jar,/jars/gatk-package-4.2.6.1-50-g40182c7-SNAPSHOT-test.jar]; 2022-08-16T22:45:53.6382333Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6383952Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:4: error: package com.google.common.base does not exist; 2022-08-16T22:45:53.6523417Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6548080Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6571861Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6588890Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6621393Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6631099Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6638787Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6653787Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6657039Z src/main/java/org/broadinstitute",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:2808,error,error,2808,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"/native/HDF5-prefix/src/HDF5/src/H5Fio.c line 120 in H5F_block_read(; ): read through metadata accumulator failed; major: Low-level I/O; minor: Read failed; #009: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Faccum.c line 263 in H5F__accum_r; ead(): driver read request failed; major: Low-level I/O; minor: Read failed; #010: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5FDint.c line 204 in H5FD_read(): ; driver read request failed; major: Virtual File Layer; minor: Read failed; #011: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5FDsec2.c line 725 in H5FD_sec2_re; ad(): file read failed: time = Wed Apr 14 11:52:33 2021; , filename = '/SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/20210411.GRCh37.gatkcnv.brs/work/92/579e5a48aa9e52cd0; e1df603266809/B00HOTD.counts.hdf5', file descriptor = 250, errno = 121, error message = 'Remote I/O error', buf = ; 0x2b6ebddf38e8, total read size = 384, bytes this sub-read = 384, bytes actually read = 18446744073709551615, offs; et = 712120; major: Low-level I/O; minor: Read failed; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5D.c line 826 in H5Dvlen_reclaim(); : invalid dataspace; major: Invalid arguments to routine; minor: Inappropriate type; 11:52:33.796 INFO GermlineCNVCaller - Shutting down engine; [April 14, 2021 11:52:33 AM CEST] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed t; ime: 0.90 minutes.; Runtime.totalMemory()=2374500352; Exception in thread ""main"" java.lang.InternalError: H5DreadVL_str: failed to read variable length strings; 	at ncsa.hdf.hdf5lib.H5.H5DreadVL(Native Method); 	at org.broadinstitute.hdf5.HDF5File.lambda$readStringArray$0(HDF5File.java:161); 	at org.broadinstitute.hdf5.HDF5File.readDataset(HDF5File.java:349); 	at org.broadinstitute.hdf5.HDF5File.readStringArray(HDF5File.java:150); 	at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:3025,error,error,3025,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,3,"['Error', 'error']","['Error', 'error']"
Availability,"/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1 ...; git checkout --quiet refs/tags/3.8-1; GIT NEW branch -->; repository: https://github.com/broadgsa/gatk.git; at the commit: f2ed14489851ff2c00da3dcab9ad0b8f5ccec200; >>> Source unpacked in /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work; >>> Preparing source in /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1 ...; Equivalent maven command; mvn -Dmaven.repo.local=/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/.m2/repository verify '-Ddisable.shadepackage'; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1/public/gatk-root/pom.xml, line 15, column 3; @ ; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR] ; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1/pom.xml) has 1 error; [ERROR] Non-parseable POM /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /scratch/var/tmp/portage/sci-biology/gatk-3.8.1/work/gatk-3.8.1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR] ; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR] ; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException; ```. I can",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4685#issuecomment-383184514:1883,ERROR,ERROR,1883,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4685#issuecomment-383184514,3,['ERROR'],['ERROR']
Availability,"/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7514136Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7515610Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7517156Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7642312Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7643965Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7645667Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7690890Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7738985Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7739852Z symbol: class RangeMap; 2022-08-16T22:45:53.7740332Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7740892Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7741707Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7743523Z symbol: class Range; 2022-08-16T22:45:53.7743866Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7747579Z src/main/java/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:7121,error,error,7121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:80: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?; if len(args) is 0 or (len(args) is 1 and (args[0] == ""--help"" or args[0] == ""-h"")):; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:80: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?; if len(args) is 0 or (len(args) is 1 and (args[0] == ""--help"" or args[0] == ""-h"")):; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:117: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?; if len(args) is 1 and args[0] == ""--list"":; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:308: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?; if call([""gsutil"", ""-q"", ""stat"", gcsjar]) is 0:; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:312: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?; if call([""gsutil"", ""cp"", jar, gcsjar]) is 0:; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:467: SyntaxWarning: ""is not"" with a literal. Did you mean ""!=""?; if not len(properties) is 0:; /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:471: SyntaxWarning: ""is not"" with a literal. Did you mean ""!=""?; if not len(filesToAdd) is 0:; Using GATK jar /home/warkre/miniconda3/envs/gatk4.1.4.0/share/gatk4-4.1.4.0-1/gatk-package-4.1.4.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/warkre/miniconda3/envs/gatk4.1.4.0/share/gatk4-4.1.4.0-1/gatk-package-4.1.4.0-local.jar FilterMutectCalls -V mu.2.vcf -R human_g1k_v37.main.fasta -O MT.filtered.vcf.gz --stats MT.vcf.gz.stats --mitochondria-mode; ```. The made-up VCF contains a single variant:; ```; MT 100 . G C . . DP=3;ECNT=3;MBQ=0,10;MFRL=0,10;MMQ=10,10;MPOS=10;OCM=0;POPAF=3.40;RPA=5,6;RU=C;STR;TLOD=5.88 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:0,2:0.750:2:0,1:0,1:0,0,0,2; ```. The stats file contains the lines:; ```; statistic	value; callable	0.0; ```. I hope this is enough to reproduce the error.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:15492,error,error,15492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['error'],['error']
Availability,"0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0; ```; Running `$HOME/gatk-4.0.11.0/gatk --java-options ""-Xmx4g"" HaplotypeCaller -R $HOME/GRCh37files/hs37d5.fa -I /mnt/fast/test.bam -O test.out.vcf.gz -L 22 --genotyping-mode GENOTYPE_GIVEN_ALLELES --alleles test.vcf.gz`, the resulting error is:; ```; java.lang.IllegalStateException: Allele in genotype GGTTTGTTT not in the variant context [GGTTTGTTT*, GGTTTGTTTGTTT, GGTTTGTTTGTTTGTTT, G]; at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:228); at org.broadinst",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5355:40982,error,error,40982,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5355,1,['error'],['error']
Availability,"0 ALT contigs; OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000715180000, 719847424, 0) failed; error='Cannot allocate memory' (errno=12). #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 719847424 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid11513.log; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f27ebfe7d9a, pid=11455, tid=0x00007f27e87e5700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libfml.6198146539708364717.jnilib+0xed9a] rld_itr_init+0x4a; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fd2680a350c, pid=11685, tid=0x00007fd2b02bf700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libbwa.5694772191018335324.jnilib+0x850c] bwa_mem2idx+0xcc; ```. The underlying issue in these cases is likely either ""out of memory"" or, perhaps in the case of the seg faults, ""file not found"" or ""malformed file"", but we could greatly improve our ability to interpret Travis failures if we were more careful about checking return values from system calls. Eg., in the function below from the BWA bindings we could check the return values of the `mmap()` and `calloc()` calls, and die with an appropriate error message if they fail:. ```; bwaidx_t* jnibwa_openIndex( int fd ) {; struct stat statBuf;; if ( fstat(fd, &statBuf) == -1 ) return 0;; uint8_t* mem = mmap(0, statBuf.st_size, PROT_READ, MAP_SHARED, fd, 0);; close(fd);; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3209:1449,error,error,1449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209,1,['error'],['error']
Availability,0 INFO IOUtils - Extracting file: ./a_mutated.orientation_priors; 14:55:54.771 INFO IOUtils - Extracting file: ./h_mutated.orientation_priors; 14:55:54.771 INFO IOUtils - Extracting file: ./j_mutated.orientation_priors; 14:55:54.855 INFO ProgressMeter - Starting traversal; 14:55:54.856 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:55:54.857 INFO FilterMutectCalls - Starting pass 0 through the variants; 14:56:05.368 INFO ProgressMeter - 1:2019484 0.2 16000 91332.9; 14:56:15.521 INFO ProgressMeter - 1:4008750 0.3 35000 101621.1; 14:56:26.027 INFO ProgressMeter - 1:5856032 0.5 55000 105867.6; ...; 19:37:05.295 INFO ProgressMeter - GL000209.1:48811 281.2 30739000 109323.8; 19:37:15.543 INFO ProgressMeter - GL000224.1:65537 281.3 30758000 109324.9; 19:37:25.847 INFO ProgressMeter - GL000248.1:21736 281.5 30768000 109293.8; 19:37:25.906 INFO FilterMutectCalls - Finished pass 0 through the variants; 19:50:04.590 INFO FilterMutectCalls - Shutting down engine; [9 January 2020 7:50:04 PM] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 294.19 minutes.; Runtime.totalMemory()=14966849536; java.lang.IllegalArgumentException: Values in probability array sum to a negative number NaN; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:731); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeSumToOne(MathUtils.java:731); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.performEMIteration(SomaticClusteringModel.java:336); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:306); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:158); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:159,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-572799341:3937,down,down,3937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-572799341,2,['down'],['down']
Availability,"0 INFO IntelPairHmm - Available threads: 1; 17:08:13.260 INFO IntelPairHmm - Requested threads: 4; 17:08:13.261 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 17:08:13.261 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 17:08:13.346 INFO ProgressMeter - Starting traversal; 17:08:13.346 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 17:08:17.401 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes. 17:08:43.866 INFO ProgressMeter - chr1:1053465 0.5 3780 7431.7. ...Many lines in between and then... 19:11:09.189 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.190328316; 19:11:09.189 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 398.5135636; 19:11:09.190 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 258.73 sec; 19:11:09.190 INFO HaplotypeCaller - Shutting down engine; [August 27, 2020 7:11:09 PM CDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 122.97 minutes.; Runtime.totalMemory()=2764046336; java.lang.NullPointerException; at org.broadinstitute.hellbender.engine.AssemblyRegion.getReference(AssemblyRegion.java:309); at org.broadinstitute.hellbender.engine.AssemblyRegion.getAssemblyRegionReference(AssemblyRegion.java:330); at org.broadinstitute.hellbender.engine.AssemblyRegion.getAssemblyRegionReference(AssemblyRegion.java:316); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.createReferenceHaplotype(AssemblyBasedCallerUtils.java:175); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.referenceModelForNoVariation(HaplotypeCallerEngine.java:688); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:522); at org.broadinstitute.hellbender.tools.walkers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783:4461,down,down,4461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783,1,['down'],['down']
Availability,0%> (+0.131%)` | `44 <0> (+2)` | :arrow_up: |; | [...ellbender/tools/walkers/vqsr/CNNScoreVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50cy5qYXZh) | `17.621% <25%> (-62.823%)` | `7 <0> (-38)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5837#issuecomment-476864170:2529,down,downsampling,2529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5837#issuecomment-476864170,1,['down'],['downsampling']
Availability,"0-All.vcf.gz.tbi is out of date (index older than input file). Use IndexFeatureFile to make a new index. ; ; 14:50:13.556 WARN IndexUtils - Feature file ""/mnt/d/GenLab/WES/db/00-common\_all.vcf.gz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file ; ; 14:50:13.609 WARN IndexUtils - Index file /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz.tbi is out of date (index older than input file). Use IndexFeatureFile to make a new index. ; ; 14:50:13.615 INFO FilterVariantTranches - Done initializing engine ; ; 14:50:13.638 INFO ProgressMeter - Starting traversal ; ; 14:50:13.639 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute ; ; 14:50:13.642 INFO FilterVariantTranches - Starting pass 0 through the variants ; ; 14:50:13.857 INFO FilterVariantTranches - Filtered 0 SNPs out of 4 and filtered 0 indels out of 0 with INFO score: CNN\_2D. ; ; 14:50:13.871 INFO FilterVariantTranches - Shutting down engine ; ; \[July 6, 2020 2:50:13 PM MSK\] org.broadinstitute.hellbender.tools.walkers.vqsr.FilterVariantTranches done. Elapsed time: 0.02 minutes. ; ; Runtime.totalMemory()=721944576 ; ; htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\* ; ; at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.determineReferenceAllele(GATKVariantContextUtils.java:209) ; ; at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.isAlleleInList(GATKVariantContextUtils.java:164) ; ; at org.broadinstitute.hellbender.tools.walkers.vqsr.FilterVariantTranches.firstPassApply(FilterVariantTranches.java:187) ; ; at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701:6596,down,down,6596,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701,1,['down'],['down']
Availability,"0.100;MQ=60.00;MQRankSum=0.000;QD=0.46;ReadPosRankSum=-0.300;SOR=2.792 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:85,3:88:34:66,0,34,78,132,196,276,380,528,782,6199; contig00001 8244 . T C 43.68 . AC=1;AF=0.100;AN=10;BaseQRankSum=-0.838;ClippingRankSum=0.000;DP=80;FS=15.529;MLEAC=1;MLEAF=0.100;MQ=60.00;MQRankSum=0.000;QD=0.55;ReadPosRankSum=-1.716;SOR=2.783 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:77,3:80:31:69,0,31,71,119,178,251,347,482,716,5872; contig00001 8846 . C T 72.68 . AC=1;AF=0.100;AN=10;BaseQRankSum=0.659;ClippingRankSum=0.000;DP=88;FS=2.385;MLEAC=1;MLEAF=0.100;MQ=59.93;MQRankSum=0.273;QD=0.83;ReadPosRankSum=-4.696;SOR=1.102 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:84,4:88:31:98,0,31,72,124,186,264,366,510,759,3392; contig00001 9854 . A G 42.69 . AC=1;AF=0.100;AN=10;BaseQRankSum=0.463;ClippingRankSum=0.000;DP=79;FS=11.687;MLEAC=1;MLEAF=0.100;MQ=60.00;MQRankSum=0.000;QD=0.55;ReadPosRankSum=1.267;SOR=2.799 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:74,3:77:29:68,0,29,66,111,166,235,324,450,665,2970; contig00001 19796 . A G 34.70 . AC=1;AF=0.100;AN=10;BaseQRankSum=-2.543;ClippingRankSum=0.000;DP=66;FS=10.825;MLEAC=1;MLEAF=0.100;MQ=60.00;MQRankSum=0.000;QD=0.53;ReadPosRankSum=-0.600;SOR=0.829 GT:AD:DP:GQ:PL 0/0/0/0/0/0/0/0/0/1:63,3:66:23:60,0,23,54,93,140,199,275,384,572,2745; contig00001 20699 . T C 47.70 . AC=1;AF=0.100;AN=10;BaseQRankSum=0.326;ClippingRankSum=0.000;DP=66;FS=2.442;MLEAC=1;MLEAF=0.1; ```. When I run . ```gatk VariantFiltration -V GenomeA.rawSNPs.vcf -filter ""QD < 20.0"" --filter-name ""snp_def"" -O test.vcf```. or. ```gatk VariantFiltration -R ../GenomeA_contigs.fa -V GenomeA.rawSNPs.vcf -filter ""QD < 20.0"" --filter-name ""snp_def"" -O test.vcf```. I get the following error:. ```A USER ERROR has occurred: Invalid argument '>'.```. I tried to use different operators and style ```""""``` rather than ```''``` but the error is still the same.; I was hoping that there is a mistake in my code but it seems to be a bug to me.; I run on a HPC with a slurm managing system. ; Thank you",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6241:1975,error,error,1975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6241,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,0.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:68); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:62); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:1647,ERROR,ERROR,1647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"0.805 INFO GenomicsDBImport - Callset Map JSON file will be written to /lustre/data_single_cell/sperm1/mydatabase/callset.json; > 21:21:20.805 INFO GenomicsDBImport - Complete VCF Header will be written to /lustre/data_single_cell/sperm1/mydatabase/vcfheader.vcf; > 21:21:20.805 INFO GenomicsDBImport - Importing to array - /lustre/data_single_cell/sperm1/mydatabase/genomicsdb_array; > 21:21:20.805 INFO ProgressMeter - Starting traversal; > 21:21:20.805 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; > 21:21:22.001 INFO GenomicsDBImport - Importing batch 1 with 2 samples; > 21:22:18.128 INFO ProgressMeter - chr22:1 1.0 1 1.0; > 21:22:18.128 INFO GenomicsDBImport - Done importing batch 1/1; > 21:22:18.129 INFO ProgressMeter - chr22:1 1.0 1 1.0; > 21:22:18.129 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 1.0 minutes.; > 21:22:18.129 INFO GenomicsDBImport - Import completed!; > 21:22:18.129 INFO GenomicsDBImport - Shutting down engine; > [May 25, 2020 9:22:18 PM CST] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 1.01 minutes.; > Runtime.totalMemory()=1821900800; > Tool returned:; > true. This is the result of GenomicsDBImport. -[ 201] callset.json; -[4.0K] chr22$1$50818468; |-[4.0K] __3d7b0c29-9d8b-4748-a08a-c1e0a9136cf647572466251520_1590412882146; ||-[133K] AD.tdb; ||-[ 54K] AD_var.tdb; ||-[3.2M] ALT.tdb; ||-[ 77K] ALT_var.tdb; ||-[ 85K] BaseQRankSum.tdb; ||-[192K] __book_keeping.tdb.gz; ||-[4.1M] __coords.tdb; ||-[1011K] DP_FORMAT.tdb; ||-[114K] DP.tdb; ||-[3.5M] END.tdb; ||-[108K] ExcessHet.tdb; ||-[ 64K] FILTER.tdb; ||-[ 0] FILTER_var.tdb; ||-[1.1M] GQ.tdb; ||-[2.9M] GT.tdb; ||-[120K] GT_var.tdb; ||-[ 64K] ID.tdb; ||-[ 0] ID_var.tdb; ||-[ 64K] InbreedingCoeff.tdb; ||-[1.0M] MIN_DP.tdb; ||-[128K] MLEAC.tdb; ||-[ 32K] MLEAC_var.tdb; ||-[128K] MLEAF.tdb; ||-[ 36K] MLEAF_var.tdb; ||-[ 82K] MQRankSum.tdb; ||-[ 98K] PGT.tdb; ||-[5.8K] PGT_var.tdb; ||-[ 99K] PID.tdb; ||-[ 15",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6627:7285,down,down,7285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6627,1,['down'],['down']
Availability,0.bam --reference /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta --genotypePonSites false --af_of_alleles_not_in_resource 0.001 --log_somatic_prior -6.0 --tumor_lod_to_emit 3.0 --initial_tumor_lod 2.0 --max_population_af 0.01 --normal_lod 2.2 --annotation Coverage --annotation DepthPerAlleleBySample --annotation TandemRepeat --annotation OxoGReadCounts --annotation ClippedBases --annotation ReadPosition --annotation BaseQuality --annotation MappingQuality --annotation FragmentLength --annotation StrandArtifact --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.001 --indel_heterozygosity 1.25E-4 --heterozygosity_stdev 0.01 --standard_min_confidence_threshold_for_calling 10.0 --max_alternate_alleles 6 --max_genotype_count 1024 --sample_ploidy 2 --genotyping_mode DISCOVERY --contamination_fraction_to_filter 0.0 --o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3514:2857,recover,recoverDanglingHeads,2857,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514,3,"['error', 'recover']","['errorCorrectKmers', 'errorCorrectReads', 'recoverDanglingHeads']"
Availability,"00 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Djava.io.tmpdir=tmp --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Djava.io.tmpdir=tmp --deploy-mode client --executor-memory 80G --driver-memory 30g --num-executors 40 --executor-cores 4 --conf spark.yarn.submit.waitAppCompletion=false --name A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr --files file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa.img,file:///restricted/projectnb/casa/ref/GRCh38_ignored_kmers.txt --conf spark.yarn.executor.memoryOverhead=5000 --conf spark.network.timeout=600 --conf spark.executor.heartbeatInterval=120 /share/pkg/gatk/4.1.0.0/install/bin/gatk-package-4.1.0.0-spark.jar StructuralVariationDiscoveryPipelineSpark -R file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img --kmers-to-ignore GRCh38_ignored_kmers.txt --contig-sam-file hdfs:///project/casa/gcad/adsp.cc/sv//A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.contig-sam-file -I hdfs:///project/casa/gcad/adsp.cc/cram/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.cram -O hdfs:///project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.sv.vcf --spark-master yarn. ```. #### Expected behavior. Run to completion with SV vcf output. #### Actual behavior. ```; 2019-02-17 16:25:48 INFO TaskSetManager:54 - Finished task 85.0 in stage 5.0 (TID 1031) in 28293 ms on scc-q09.scc.bu.edu (executor 30) (74/189); 2019-02-17 16:25:48 INFO BlockManagerInfo:54 - Removed taskresult_1031 on scc-q09.scc.bu.edu:40204 in memory (size: ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:2339,heartbeat,heartbeatInterval,2339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['heartbeat'],['heartbeatInterval']
Availability,"00 GT:AD:DP 0/0:37:37 ; ; chr5 125895106 . G . 73.78 . AN=2;DP=28;MQ=60.00 GT:AD:DP 0/0:28:28 ; ; chr5 125895113 . G . 68.78 . AN=2;DP=25;MQ=60.00 GT:AD:DP 0/0:25:25. Position 125894866 is present in the --alleles file, and is genotyped correctrly as homozygous reference in the current sample. The following three positions are not present in the --alleles file, and do not contain an ALT allele in the output file ( dot for ALT). without '--alleles', these positions are not outputted.. Is this expected behaviour, and if so, why are they emitted ?. notes : ; ; \- same output is observed without threading , ; ; \- same output is observed without dragen mode. ; ; \- --alleles is taken from a normal HC run. ; ; \- roughly the same heterozygous calls & hom.ALT calls are made with/without --alleles (which is expected behaviour). \=======================. REQUIRED for all errors and issues: ; ; a) GATK version used: 4.2.5.0. b) Exact command used:. gatk --java-options ""-Djava.io.tmpdir=/tmp -Xmx3g"" HaplotypeCaller \\ ; ; -R /home/gvandeweyer/elprep\_streaming/reference/hg19.fasta \\ ; ; -I /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam \\ ; ; -O results/wesep-229191-f.vcf \\ ; ; --alleles affected\_alleles.vcf \\ ; ; -L 0005-scattered.interval\_list \\ ; ; -bamout results/wesep-229191-f.variants.bam \\ ; ; -G StandardAnnotation -G StandardHCAnnotation \\ ; ; --dragen-mode \\ ; ; --dragstr-params-path /home/gvandeweyer/elprep\_streaming/results/wesep-229191-f.bam.params \\ ; ; --native-pair-hmm-threads 2.  ; ; c) Entire program log:. (ELPREP) gvandeweyer@ngsvm-pipelines:~/elprep\_streaming/VariantCalling\_Test/scattered$ gatk --java-options ""-Djava.io.tmpdir=/tmp -Xmx3g"" HaplotypeCaller -R /home/gvandeweyer/elprep\_streaming/reference/hg19.fasta -I /home/gvandeweyer/elprep\_streaming/results/wesep- ; ; 229191-f.bam -O resul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7741:1805,error,errors,1805,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7741,1,['error'],['errors']
Availability,"008v2_random:7168-7691 Q. of type=SYMBOLIC alleles=[T*, <NON_REF>] attr={END=7691} GT=[[NA12878 T*/T* GQ 0 DP 0 PL 0,0,0 {MIN_DP=0}]] filters= added out of order currentReferenceIndex: 25, referenceIndex:37; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:242); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:93); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:56); at org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more; 21/04/13 07:32:25 INFO SparkUI: Stopped Spark web UI at http://wgs-cntech-online-it:4040; 21/04/13 07:32:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/04/13 07:32:25 INFO MemoryStore: MemoryStore cleared; 21/04/13 07:32:25 INFO BlockManager: BlockManager stopped; 21/04/13 07:32:25 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/04/13 07:32:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/04/13 07:32:25 INFO SparkContext: Successfully stopped SparkContext; 07:32:25.095 INFO HaplotypeCallerSpark - Shutting down engine; ```. ### Affected tool(s) or class(es); HaplotypeCallerSpark. ### Affected version(s); - gatk-4.1.9.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:24005,down,down,24005,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['down'],['down']
Availability,"00: 1%|1 | 1/100 [00:00<00:26, 3.68it/s]; 15:10:05.772 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0046 +/- 0.0049: 2%|2 | 2/100 [00:00<00:26, 3.69it/s]; 15:10:06.039 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0023 +/- 0.0037: 3%|3 | 3/100 [00:00<00:26, 3.71it/s]; 15:10:06.307 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0016 +/- 0.0036: 4%|4 | 4/100 [00:01<00:25, 3.72it/s]; 15:10:06.575 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0018 +/- 0.0019: 5%|5 | 5/100 [00:01<00:25, 3.72it/s]; 15:10:06.844 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0013 +/- 0.0014: 6%|6 | 6/100 [00:01<00:25, 3.72it/s]; 15:10:07.113 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0014 +/- 0.0019: 7%|7 | 7/100 [00:01<00:24, 3.72it/s]; 15:10:07.381 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0011 +/- 0.0011: 8%|8 | 8/100 [00:02<00:24, 3.72it/s]; 15:10:07.649 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0008 +/- 0.0009: 10%|# | 10/100 [00:02<00:24, 3.72it/s]; 15:10:08.193 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0006: 11%|#1 | 11/100 [00:02<00:24, 3.70it/s]; 15:10:08.463 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0005 +/- 0.0007: 12%|#2 | 12/100 [00:03<00:23, 3.70it/s]; 15:10:08.732 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0007: 13%|#3 | 13/100 [00:03<00:23, 3.70it/s]; 15:10:09.001 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0004 +/- 0.0005: 13%|#3 | 13/100 [00:03<00:25, 3.45it/s]; 15:10:09",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:12005,error,error,12005,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['error'],['error']
Availability,"00:05:56.230 info NativeGenomicsDB - pid=40375 tid=40376 No valid combination operation found for INFO field SOR - the field will NOT be part of INFO fields in the generated VCF records; 00:05:56.776 INFO IntervalArgumentCollection - Processing 105581 bp from intervals; 00:05:56.847 INFO GenotypeGVCFs - Done initializing engine; 00:05:57.036 INFO ProgressMeter - Starting traversal; 00:05:57.036 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr16:10185 the annotation AS_VarDP=59|115|0 was not a numerical value and was ignored; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Reducible annotation 'AS_VarDP' detected, add -G StandardAnnotation -G AS_StandardAnnotation to the command to annotate in the final VC with this annotation.; 00:07:26.991 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.02938786500000001,Cpu time(s),0.029037034000000003; [August 25, 2021 12:07:27 AM EDT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.55 minutes.; Runtime.totalMemory()=1807745024; java.lang.NullPointerException; at java.util.HashMap.putMapEntries(HashMap.java:500); at java.util.HashMap.putAll(HashMap.java:784); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:211); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:130); at org.broadinstitute.hellbender.tools.walkers.Genotype",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:7691,down,down,7691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['down'],['down']
Availability,00:09:07.3962332Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3968675Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3978229Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3984771Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3993495Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4002426Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4005459Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T00:09:07.4005923Z @VisibleForTesting; 2022-08-16T00:09:07.4006520Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4006876Z location: class PileupElement; 2022-08-16T00:09:07.4015304Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4023160Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4025208Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4026746Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:5: error: package com.google.common.primitives does n,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:9971,error,error,9971,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,00:09:07.4436641Z location: class CommandLineProgram; 2022-08-16T00:09:07.4436930Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:120: error: cannot find symbol; 2022-08-16T00:09:07.4437094Z @VisibleForTesting; 2022-08-16T00:09:07.4437369Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4437519Z location: class FeatureInput<T>; 2022-08-16T00:09:07.4437725Z where T is a type-variable:; 2022-08-16T00:09:07.4437925Z T extends Feature declared in class FeatureInput; 2022-08-16T00:09:07.4438276Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:251: error: cannot find symbol; 2022-08-16T00:09:07.4438417Z @VisibleForTesting; 2022-08-16T00:09:07.4438677Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4438873Z location: class PosteriorProbabilitiesUtils; 2022-08-16T00:09:07.4439223Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:271: error: cannot find symbol; 2022-08-16T00:09:07.4439362Z @VisibleForTesting; 2022-08-16T00:09:07.4439618Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4439806Z location: class PosteriorProbabilitiesUtils; 2022-08-16T00:09:07.4465668Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/DefaultGATKVariantAnnotationArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4466113Z [done in 2417 ms]; 2022-08-16T00:09:07.4466222Z 1 error; 2022-08-16T00:09:07.4466340Z 101 warnings; 2022-08-16T00:09:07.4466481Z expected [0] but found [1]; 2022-08-16T00:09:07.4466753Z at org.testng.Assert.fail(Assert.java:97); 2022-08-16T00:09:07.4466991Z at org.testng.Assert.assertEqualsImpl(Assert.java:136); 2022-08-16T00:09:07.4467199Z at org.testng.Assert.assertEquals(Assert.java:118); 2022-08-16T00:09:07.4467407Z at org.testng.Assert.assertEquals(Assert.java:839); 2022-08-16T00:09:07.4468069Z at org.broadinstitute.hellbender.utils.help.DocumentationGenerationIn,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:21421,error,error,21421,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"01405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \; gzip -d > GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. samtools faidx GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. java -jar picard.jar \; CreateSequenceDictionary \; R=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; O=GCA_000001405.15_GRCh38_no_alt_analysis_set.dict. (echo ""##fileformat=VCFv4.2""; \; echo ""##contig=<ID=chrX,length=156040895>""; \; echo -e ""#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO""; \; echo -e ""chrX\t1052617\t.\tC\tCAAAGGCTGCAATGTGAATGAATTTTTGGAAATAGCCCTAATGCTCATCTATGAAGGAGTGATAAACACAGCATCCTTTATCCATGCAATGGAATATTATGCAGTCTAGAAAAGGAATAAGGCTCTGACAAAAGACTGCAATATGTATGAATTTTGGAAACAGCCCTACTGCCCATCTATAAAGGAATGGATAAACACAGCATAGTTCATCTATACAATGCAATATTATAATGGAATATTATGCAGCCTGGAACAGGAACAAGGCTCTGAG\t.\t.\t."") | \; bgzip > input.vcf.gz; \; tabix -f input.vcf.gz. (echo -e ""@HD\tVN:1.6\tGO:none\tSO:coordinate""; \; echo -e ""@SQ\tSN:chrX\tLN:156040895""; \; echo -e ""@RG\tID:ID\tPL:ILLUMINA\tPU:ID\tLB:LIBRARY\tSM:SAMPLE"") | \; samtools view -Sb -o input.bam; \; samtools index input.bam. gatk-4.1.2.0/gatk HaplotypeCaller \; -R GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \; -I input.bam \; -O output.vcf.gz \; --genotyping-mode GENOTYPE_GIVEN_ALLELES \; --alleles input.vcf.gz; ```. I get the following error:. ```; java.lang.IllegalArgumentException: Cigar cannot be null; 	at org.broadinstitute.hellbender.utils.read.AlignmentUtils.consolidateCigar(AlignmentUtils.java:716); 	at org.broadinstitute.hellbender.utils.haplotype.Haplotype.setCigar(Haplotype.java:193); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.addGivenAlleles(AssemblyBasedCallerUtils.java:350); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:291); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6037:1299,echo,echo,1299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6037,2,['echo'],['echo']
Availability,"01413230/document This method uses a low-rank approximation to the kernel to obtain an approximate segmentation in linear complexity in time and space. In practice, performance is actually quite impressive!. The implementation is relatively straightforward, clocking in at ~100 lines of python. Time complexity is O(log(maximum number of segments) * number of data points) and space complexity is O(number of data points * dimension of the kernel approximation), which makes use for WGS feasible. Segmentation of 10^6 simulated points with 100 segments takes about a minute and tends to recover segments accurately. Compare this with CBS, where segmentation of a WGS sample with ~700k points takes ~10 minutes---and note that these ~700k points are split up amongst ~20 chromosomes to start!. There are a small number of parameters that can affect the segmentation, but we can probably find good defaults in practice. What's also nice is that this method can find changepoints in moments of the distribution other than the mean, which means that it can straightforwardly be used for alternate-allele fraction segmentation. For example, all segments were recovered in the following simulated multimodal data, even though all of the segments have zero mean:. ![baf](https://user-images.githubusercontent.com/11076296/29100464-ad687946-7c79-11e7-99e4-962ab93709b4.png). Replacing the SNP segmentation in ACNV (which performs expensive maximum-likelihood estimation of the allele-fraction model) with this method would give a significant speedup there. Joint segmentation is straightforward and is simply given by addition of the kernels. However, complete data is still required. Given such a fast heuristic, I'm more amenable to augmenting this method with additional heuristics to clean up or improve the segmentation if necessary. We can also use it to initialize our more sophisticated HMM models, as well. @LeeTL1220 @mbabadi @davidbenjamin I'd be interested to hear your thoughts, if you have any.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-321121666:1263,recover,recovered,1263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-321121666,2,['recover'],['recovered']
Availability,"015f-0a1b-f1bd-00002ce33928 ; on database directory /tmp/spark-98953d35-8594-4907-b4a5-0870f1d17b3e/metastore with class loader sun.misc.Launcher$AppClassLoader@5c647e05 ; Loaded from file:/opt/cloudera/parcels/CDH-5.12.1-1.cdh5.12.1.p0.3/jars/derby-10.11.1.1.jar; java.vendor=Oracle Corporation; java.runtime.version=1.8.0_91-b14; user.dir=/opt/Software/gatk; os.name=Linux; os.arch=amd64; os.version=3.10.0-514.el7.x86_64; derby.system.home=null; Database Class Loader started - derby.database.classpath=''; 17/10/11 14:25:33 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.1.0-cdh5.12.1; 17/10/11 14:25:33 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException; SQL context available as sqlContext. **./gradlew bundle**; **[root@com1 gatk]# ./gradlew bundle; when I executed the command ./gradlew bundle it appeared the error in the last did this matter**. .......; [loading ZipFileIndexFileObject[/root/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.6.5/d50be1723a09be903887099ff2014ea9020333/jackson-databind-2.6.5.jar(com/fasterxml/jackson/databind/annotation/JsonSerialize$Inclusion.class)]]; [loading ZipFileIndexFileObject[/root/.gradle/caches/modules-2/files-2.1/org.apache.logging.log4j/log4j-core/2.5/7ed845de1dfe070d43511fab1784e6c4118398/log4j-core-2.5.jar(org/apache/logging/log4j/core/config/plugins/PluginVisitorStrategy.class)]]; [done in 5759 ms]; 1 error; :gatkTabComplete FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkTabComplete'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/opt/Software/gatk/build/tmp/gatkTabComplete/jadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 7.431 secs",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240:3430,error,error,3430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240,2,"['FAILURE', 'error']","['FAILURE', 'error']"
Availability,"019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:36703,failure,failure,36703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['failure'],['failure']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:5382,reliab,reliable,5382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:5592,reliab,reliable,5592,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:6222,reliab,reliable,6222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:5802,reliab,reliable,5802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:6012,reliab,reliable,6012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:6432,reliab,reliable,6432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:6642,reliab,reliable,6642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:6852,reliab,reliable,6852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:7062,reliab,reliable,7062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr15_KI270727v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:7272,reliab,reliable,7272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr16_KI270728v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270736v1_ra;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:7482,reliab,reliable,7482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_GL000205v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270736v1_ra; Stderr: Traceback (most recent call last):; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 884, in __call__; self.fn() if output_subset is None else\",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:7692,reliab,reliable,7692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270729v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270736v1_ra; Stderr: Traceback (most recent call last):; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 884, in __call__; self.fn() if output_subset is None else\; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 989, in rval; r = p(n, [x[0] for x in i], o); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-pa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:7902,reliab,reliable,7902,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr17_KI270730v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270736v1_ra; Stderr: Traceback (most recent call last):; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 884, in __call__; self.fn() if output_subset is None else\; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 989, in rval; r = p(n, [x[0] for x in i], o); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 978, in p; self, node); File ""theano/scan_module/scan_perform.pyx"", line 215, in theano.scan_module.scan_perform.perform (/home/shlee/.theano/compiledir_Linux-4.13--g",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:8112,reliab,reliable,8112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270731v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270732v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270733v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270734v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270735v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.384 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr22_KI270736v1_ra; Stderr: Traceback (most recent call last):; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 884, in __call__; self.fn() if output_subset is None else\; File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 989, in rval; r = p(n, [x[0] for x in i], o); File ""/home/shlee/anaconda3/envs/gatk/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 978, in p; self, node); File ""theano/scan_module/scan_perform.pyx"", line 215, in theano.scan_module.scan_perform.perform (/home/shlee/.theano/compiledir_Linux-4.13--gcp-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64/scan_perform/mod.cpp:2628); NotImplementedError: We didn't implemented yet the case where scan do 0 iteration. During handling of the above exception, another e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:8322,reliab,reliable,8322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"02 59335904 target_189887_IL9R NaN; Y 59335905 59336289 target_189888_IL9R NaN; Y 59336290 59336776 target_189889_IL9R NaN; Y 59336840 59337486 target_189890_IL9R NaN; Y 59337698 59338400 target_189891_IL9R NaN; Y 59338503 59339109 target_189892_IL9R NaN; Y 59339943 59340528 target_189893_IL9R NaN; Y 59342236 59343330 target_189894_IL9R NaN. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242767764). @davidbenjamin could you please take a look? it sounds like it could be a problem with the reference missing these regions. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242774747). OK it turns out that the reference is hard masked and has ""N"" in that region. Nevertheless, we shouldn't get NaNs. In my opinion, the correct behavior is to drop targets on which GC percentage can not be defined + emit informative error messages. ---. @davidbenjamin commented on [Sun Sep 11 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-246177779). I will address this. ---. @mbabadi commented on [Tue Sep 27 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-250018497). @davidbenjamin also, CorrectGCBias produces NaNs when a sample has very low coverage. I think the correct behavior is this:. (1) when annotating targets, it is OK to produce NaNs on targets whose GC bias can not be determined. When correcting for GC bias, those targets must be removed altogether. (2) if the bias curve can not be determined (let's say because of low coverage), the tool should remove that sample from the collection and emit appropriate warning messages. If all samples are removed, the tool should produce a bad input error. ---. @mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-302466279). @asmirnov239 can you review and if the issue is resolved, close?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2882:4836,error,error,4836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2882,1,['error'],['error']
Availability,022-08-16T22:45:53.6895571Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6965286Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6965863Z * Returns the STR period at a given position.??; 2022-08-16T22:45:53.6972650Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6973221Z * Returns the STR period at a given position.??; 2022-08-16T22:45:53.6981573Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7254348Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7492903Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7498018Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7502319Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7512488Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7514136Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7515610Z src/main/java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:5444,error,error,5444,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"03:15:02.578 INFO IntervalArgumentCollection - Processing <redacted> bp from intervals; 03:15:02.588 INFO HaplotypeCaller - Done initializing engine; 03:15:02.590 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 03:15:02.593 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:15:02.598 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 03:15:02.599 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 03:15:02.599 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 03:15:02.601 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 03:15:02.601 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 03:15:02.623 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:15:02.667 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 03:15:02.667 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 03:15:02.667 INFO IntelPairHmm - Available threads: 16; 03:15:02.667 INFO IntelPairHmm - Requested threads: 32; 03:15:02.667 WARN IntelPairHmm - Using 16 available threads, but 32 were requested; 03:15:02.667 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; ```. Any insight into what's going on and how to diagnose it would be greatly appreciated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6889:6459,Avail,Available,6459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889,2,"['Avail', 'avail']","['Available', 'available']"
Availability,"03:51:59.222 INFO GenotypeGVCFs - Initializing engine; 03:51:59.571 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63; 11:51:59.957 info NativeGenomicsDB - pid=1480681 tid=1480682 No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; 11:51:59.957 info NativeGenomicsDB - pid=1480681 tid=1480682 No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; 11:51:59.957 info NativeGenomicsDB - pid=1480681 tid=1480682 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 03:52:00.341 INFO GenotypeGVCFs - Done initializing engine; 03:52:00.369 INFO ProgressMeter - Starting traversal; 03:52:00.369 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 03:52:00.377 INFO GenotypeGVCFs - Shutting down engine; [July 13, 2023 at 3:52:00 AM UTC] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2583691264; java.lang.IllegalStateException: There are no sources based on those query parameters; at org.genomicsdb.reader.GenomicsDBFeatureIterator.<init>(GenomicsDBFeatureIterator.java:167); at org.genomicsdb.reader.GenomicsDBFeatureReader.query(GenomicsDBFeatureReader.java:152); at org.broadinstitute.hellbender.engine.FeatureDataSource.refillQueryCache(FeatureDataSource.java:569); at org.broadinstitute.hellbender.engine.FeatureDataSource.queryAndPrefetch(FeatureDataSource.java:538); at org.broadinstitute.hellbender.engine.FeatureDataSource.query(FeatureDataSource.java:504); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$2(VariantLocusWalker.java:149); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8415:4097,down,down,4097,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8415,1,['down'],['down']
Availability,"065741193890473.csv'; 22:13:30.002 INFO AnalyzeCovariates - Generating plots file './sample_analysis/SRR25308851/SRR25308851_recalibration_plots.pdf'; 22:13:30.518 INFO AnalyzeCovariates - Shutting down engine; [August 7, 2023 at 10:13:30 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=113246208; org.broadinstitute.hellbender.utils.R.RScriptExecutorException:; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10708586791705723928';source('/tmp/BQSR.12372590345390592260.R'); /tmp/AnalyzeCovariates13996065741193890473.csv /attach/data/vinit/human_exome/test/./sample_analysis/SRR25308851/SRR25308851_before_recal_data.table /attach/data/vinit/human_exome/test/./sample_analysis/SRR25308851/SRR25308851_recalibration_plots.pdf; Stdout:; Stderr:; Attaching package: gplots. The following object is masked from package:stats:. lowess. Error in names(x) <- value :; 'names' attribute [6] must be the same length as the vector [1]; Calls: source ... finishTable -> .gsa.assignGATKTableToEnvironment -> colnames<-; In addition: Warning messages:; 1: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 2: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 3: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 4: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 5: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; Execution halted. at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:79); at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:18); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:112); at org.broadinstitute.hellbender.utils.R.RScriptExec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8456:3572,Error,Error,3572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8456,1,['Error'],['Error']
Availability,"07, 2021 12:21 UTC. . Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4403256366107--java-lang-ArrayIndexOutOfBoundsException-32772-while-running-GenotypeGVCFs](https://gatk.broadinstitute.org/hc/en-us/community/posts/4403256366107--java-lang-ArrayIndexOutOfBoundsException-32772-while-running-GenotypeGVCFs). \--. i don't get an error but the massge java.lang.ArrayIndexOutOfBoundsException: 32772 ; ; i use : GATK version used: 4.2.0 ; ; b) Exact command used this line for Geomics DBImport. gatk GenomicsDBImport -V MA1.g.vcf -V MA2.g.vcf -V MA3.g.vcf -V MH1.g.vcf -V MH2.g.vcf -V MH3.g.vcf -V F4\_1.g.vcf -V F4\_2.g.vcf -V F4\_3.g.vcf --genomicsdb-workspace-path my\_database1AB -L 1A -L 1B -L 2A -L 2B -L 3A -L 3B -L 4A -L 4B -L 5A -L 5B -L 6A -L 6B -L 7A -L 7B. and this for GenotypeGVCFs. gatk --java-options ""-Xmx12g -Xms12g"" GenotypeGVCFs -R Triticum\_dicoccoides.WEWSeq\_v.1.0.dna.toplevel.fa -V gendb://my\_database -O output.vcf.gz --new-qual --tmp-dir temp/. c) Entire error log:. Using GATK jar /home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx12g -Xms12g -jar /home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R Triticum\_dicoccoides.WEWSeq\_v.1.0.dna.toplevel.fa -V gendb://my\_database -O output.vcf.gz --new-qual --tmp-dir temp/ ; ; 14:28:22.448 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 07, 2021 2:28:22 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 14:28:22.617 INFO Genoty",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7348:1555,error,error,1555,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7348,1,['error'],['error']
Availability,"07.226 INFO BlockManager - Initialized BlockManager: BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.345 INFO ContextHandler - Stopped o.s.j.s.ServletContextHandler@7074da1d{/,null,STOPPED,@Spark}; 10:33:07.347 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07.365 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@38a27ace{/environment,null,AVAILABLE,@Spark}; 10:33:07",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45593,AVAIL,AVAILABLE,45593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,"07.3902980Z symbol: class RangeMap; 2022-08-16T00:09:07.3903340Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3903864Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3904505Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3905250Z symbol: class Range; 2022-08-16T00:09:07.3905751Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3906273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T00:09:07.3906908Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T00:09:07.3907793Z symbol: class Range; 2022-08-16T00:09:07.3908125Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3910592Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3914013Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3921838Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3936070Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3937759Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.3941846Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:7333,error,error,7333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"08-16T00:09:07.3760984Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3762471Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3764327Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3813516Z [0K; 2022-08-16T00:09:07.3813804Z [0K; 2022-08-16T00:09:07.3814073Z [0K; 2022-08-16T00:09:07.3818970Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.3821035Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3823794Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3891049Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3891593Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3892257Z symbol: class RangeMap; 2022-08-16T00:09:07.3892601Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3893126Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3893670Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3894352Z symbol: class Range; 2022-08-16T00:09:07.3894678Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3897711Z src/main/java/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:5083,error,error,5083,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"08d8af33 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: 4.beta.1; [July 24, 2017 5:56:53 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 10.81 minutes.; Runtime.totalMemory()=4191682560; htsjdk.samtools.util.RuntimeIOException: /PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam has invalid uncompressedLength: -966754216; 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:530); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:519); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:326); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824:4066,avail,available,4066,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824,1,['avail'],['available']
Availability,"09:15:51.135 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:15:51.135 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:15:51.135 INFO SelectVariants - Deflater: IntelDeflater; 09:15:51.135 INFO SelectVariants - Inflater: IntelInflater; 09:15:51.135 INFO SelectVariants - GCS max retries/reopens: 20; 09:15:51.135 INFO SelectVariants - Requester pays: disabled; 09:15:51.136 INFO SelectVariants - Initializing engine; 09:15:52.547 INFO FeatureManager - Using codec VCFCodec to read file file:///dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR/ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.gz; 09:15:53.171 INFO IntervalArgumentCollection - Processing 248956422 bp from intervals; 09:15:53.221 INFO SelectVariants - Done initializing engine; 09:15:53.390 INFO ProgressMeter - Starting traversal; 09:15:53.390 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:15:53.479 INFO SelectVariants - Shutting down engine; [June 27, 2019 9:15:53 AM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2131755008; htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 3433: The VCF specification does not allow for whitespace in the INFO field; . Offending field value was ""AC=1;AF=9.671e-04;AN=1034;AS_BaseQRankSum=-1.550;AS_FS=8.334;AS_InbreedingCoeff=-0.3147;AS_MQ=31.69;AS_MQRankSum=-0.200;AS_QD=28.73;AS_ReadPosR; ankSum=nul;AS_SOR=2.235;BaseQRankSum=-1.381e+00;DP=40368;ExcessHet=160.0000;FS=8.334;InbreedingCoeff=-0.3147;MLEAC=7;MLEAF=6.770e-03;MQ=37.13;MQRankSum=0.126;QD=2.46;SOR=2.; 235 GT:AD:DP:GQ:PGT:PID:PL:PS 0/0:75,0:75:0:.:.:0,0,1525; `. However, from the error message I cannot see any whitespace in the INFO field. The /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR/ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.gz is the output of following command:. `gatk4.1.0.0 --java-options '-X",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6021:2998,down,down,2998,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6021,1,['down'],['down']
Availability,"0:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on fdbd4e9f571c4f8489ec11d570585d56000000.internal.cloudapp.net:46619 (size: 35.5 KB, free: 9.2 GB); 21/01/12 15:50:33 INFO SparkContext: Created broadcast 1 from newAPIHadoopFile at PathSplitSource.java:96; 21/01/12 15:50:33 INFO FileInputFormat: Total input files to process : 1; 21/01/12 15:50:33 INFO SparkUI: Stopped Spark web UI at http://fdbd4e9f571c4f8489ec11d570585d56000000.internal.cloudapp.net:4040; 21/01/12 15:50:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/01/12 15:50:33 INFO MemoryStore: MemoryStore cleared; 21/01/12 15:50:33 INFO BlockManager: BlockManager stopped; 21/01/12 15:50:33 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/01/12 15:50:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/01/12 15:50:33 INFO SparkContext: Successfully stopped SparkContext; 15:50:33.855 INFO MarkDuplicatesSpark - Shutting down engine; [January 12, 2021 at 3:50:33 PM EST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:5756,down,down,5756,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['down'],['down']
Availability,"0:33:07.225 INFO BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.226 INFO BlockManager - Initialized BlockManager: BlockManagerId(driver, 172.20.19.130, 43279, None); 10:33:07.345 INFO ContextHandler - Stopped o.s.j.s.ServletContextHandler@7074da1d{/,null,STOPPED,@Spark}; 10:33:07.347 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6556471b{/jobs,null,AVAILABLE,@Spark}; 10:33:07.349 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@7cdb05aa{/jobs/json,null,AVAILABLE,@Spark}; 10:33:07.351 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5cb76070{/jobs/job,null,AVAILABLE,@Spark}; 10:33:07.352 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@443ac5b8{/jobs/job/json,null,AVAILABLE,@Spark}; 10:33:07.354 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@753e4eb5{/stages,null,AVAILABLE,@Spark}; 10:33:07.355 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@63318b56{/stages/json,null,AVAILABLE,@Spark}; 10:33:07.357 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@462f8fe9{/stages/stage,null,AVAILABLE,@Spark}; 10:33:07.358 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@b2e1df3{/stages/stage/json,null,AVAILABLE,@Spark}; 10:33:07.359 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@6cf3b3d7{/stages/pool,null,AVAILABLE,@Spark}; 10:33:07.360 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@55c20a91{/stages/pool/json,null,AVAILABLE,@Spark}; 10:33:07.361 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@3ba96967{/storage,null,AVAILABLE,@Spark}; 10:33:07.362 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@1237cade{/storage/json,null,AVAILABLE,@Spark}; 10:33:07.363 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@4509b7{/storage/rdd,null,AVAILABLE,@Spark}; 10:33:07.364 INFO ContextHandler - Started o.s.j.s.ServletContextHandler@5dbc4598{/storage/rdd/json,null,AVAILABLE,@Spark}; 10:33:07",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:45473,AVAIL,AVAILABLE,45473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['AVAIL'],['AVAILABLE']
Availability,"0:38:16.247 INFO MarkDuplicatesSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:38:16.247 INFO MarkDuplicatesSpark - Executing as hcaoad@hhnode-ib-16 on Linux v3.10.0-1062.el7.x86_64 amd64; 10:38:16.247 INFO MarkDuplicatesSpark - Java runtime: OpenJDK 64-Bit Server VM v17.0.8-internal+0-adhoc..src; 10:38:16.247 INFO MarkDuplicatesSpark - Start Date/Time: October 18, 2023 at 10:38:16 AM HKT; 10:38:16.247 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 10:38:16.247 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 10:38:16.248 INFO MarkDuplicatesSpark - HTSJDK Version: 3.0.5; 10:38:16.248 INFO MarkDuplicatesSpark - Picard Version: 3.0.0; 10:38:16.248 INFO MarkDuplicatesSpark - Built for Spark Version: 3.3.1; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:38:16.249 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:38:16.249 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 10:38:16.249 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 10:38:16.250 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 10:38:16.250 INFO MarkDuplicatesSpark - Requester pays: disabled; 10:38:16.250 INFO MarkDuplicatesSpark - Initializing engine; 10:38:16.250 INFO MarkDuplicatesSpark - Done initializing engine; 10:38:17.179 INFO SparkContext - Running Spark version 3.3.0; ```. #### Steps to reproduce; The most wired thing is that this issue is very hard to reproduce. When running the command for hundreds of samples, this always happens to a few samples. However, if I re-submit my job for the failed sample, this error may just disappear. As the whole log file is too big, I can upload it later if need. Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:5491,error,error,5491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['error'],['error']
Availability,"0:50.177 INFO SparkContext - Starting job: runJob at SparkHadoopWriter.scala:83; 11:00:50.278 INFO DAGScheduler - Registering RDD 14 (mapToPair at SparkUtils.java:161) as input to shuffle 0; 11:00:50.291 INFO DAGScheduler - Got job 1 (runJob at SparkHadoopWriter.scala:83) with 44262 output partitions; 11:00:50.291 INFO DAGScheduler - Final stage: ResultStage 2 (runJob at SparkHadoopWriter.scala:83); 11:00:50.291 INFO DAGScheduler - Parents of final stage: List(ShuffleMapStage 1); 11:00:50.296 INFO DAGScheduler - Missing parents: List(ShuffleMapStage 1); 11:00:50.300 INFO DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at mapToPair at SparkUtils.java:161), which has no missing parents; 11:00:53.974 INFO TaskSchedulerImpl - Cancelling stage 1; 11:00:53.974 INFO TaskSchedulerImpl - Killing all running tasks in stage 1: Stage cancelled; 11:00:53.975 INFO DAGScheduler - ShuffleMapStage 1 (mapToPair at SparkUtils.java:161) failed in 3.609 s due to Job aborted due to stage failure: Task serialization failed: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); at java.base/jdk.internal.util.ArraysSupport.newLength(ArraysSupport.java:642); at java.base/java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:100); at java.base/java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:130); at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41); at java.base/java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1862); at java.base/java.io.ObjectOutputStream.write(ObjectOutputStream.java:714); at org.apache.spark.util.Utils$$anon$2.write(Utils.scala:160); at com.esotericsoftware.kryo.io.Output.flush(Output.java:185); at com.esotericsoftware.kryo.io.Output.close(Output.java:196); at org.apache.spar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:4324,failure,failure,4324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['failure'],['failure']
Availability,0Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6571861Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6588890Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6621393Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6631099Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6638787Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6653787Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6657039Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6658760Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6739776Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6889124Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6895571Z src/main/java/org/broadinstitute/hellbender/tools/walkers/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:3529,error,error,3529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	3|0	0|0	3|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	2|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	1|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|3	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|3	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	1|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|1	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0	0|0; ```; And indeed, with that `--alleles` input with a single condensed record, HaplotypeCaller runs without error.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5355:73921,error,error,73921,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5355,1,['error'],['error']
Availability,"1 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9774,AVAIL,AVAILABLE,9774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"1 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8865,AVAIL,AVAILABLE,8865,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"1 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Start",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8465,AVAIL,AVAILABLE,8465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"1 2016](https://github.com/broadinstitute/gatk-protected/issues/806). An issue encountered with gatk-protected ""SparkGenomeReadCounts"" tool is a non-helpful ""null"" error message. A non-helpful error ""null"" message was printed by gatk-protected with the command-line below; during the course of trying to use it on/in FireCloud:. ```; + java -Xmx48g -jar fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar SparkGenomeReadCounts --outputFile this.entity_id.coverage.tsv --reference fc-e2421839-93d5-4ed5-8861-593f00364e54/Homo_sapiens_assembly19.fasta --input firecloud-tcga-open-access/tutorial/bams/C835.HCC1143_BL.4.bam --binsize 5000; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; .....; ......; ......; proceeding with flushing remote transports.; ***********************************************************************. null. ***********************************************************************; ```. To try to make a more helpful error message appear I added a ""catch"" block after a call to runTool in instanceMainPostParseArgs in file CommandLineProgram.java and got a more helpful message about a missing dictionary file: . try {; return runTool();; } ; catch(Exception e) {; e.getStackTrace();; }. java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:204); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:152); Caused by: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:988,error,error,988,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,1,['error'],['error']
Availability,"1 INFO BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 00:09:41.681 INFO BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 00:09:41.681 INFO BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 00:09:41.682 INFO BaseRecalibrator - Deflater: JdkDeflater ; ; 00:09:41.682 INFO BaseRecalibrator - Inflater: JdkInflater ; ; 00:09:41.682 INFO BaseRecalibrator - GCS max retries/reopens: 20 ; ; 00:09:41.682 INFO BaseRecalibrator - Requester pays: disabled ; ; 00:09:41.682 INFO BaseRecalibrator - Initializing engine ; ; 00:09:41.884 WARN IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:09:41.888 WARN IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:09:42.030 WARN IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:09:42.036 INFO BaseRecalibrator - Shutting down engine ; ; \[August 21, 2022 at 12:09:42 AM CST\] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.01 minutes. ; ; Runtime.totalMemory()=1140850688 ; ; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec ; ;   at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:535) ; ;   at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:482) ; ;   at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:397) ; ;   at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:373) ; ;   at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:319) ; ;   at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:291) ; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:5164,down,down,5164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['down'],['down']
Availability,1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-29T18:18:04.002441351Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-29T18:18:04.002446409Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-29T18:18:04.002493533Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-29,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:2264,Error,ErrorProbabilities,2264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['Error'],['ErrorProbabilities']
Availability,1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-29T18:18:04.002441351Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-29T18:18:04.002446409Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-29T18:18:04.002493533Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-29,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:2264,Error,ErrorProbabilities,2264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['Error'],['ErrorProbabilities']
Availability,1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-30T13:35:51.795607447Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-30T13:35:51.795775473Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-30T13:35:51.795944490Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-30,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:2265,Error,ErrorProbabilities,2265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227,1,['Error'],['ErrorProbabilities']
Availability,"1) sure, different parallelization might change the thinking. As I pointed out in a different thread, if your recommendation is still to copy the workspace prior to merging/appending to it, then the distributed processing still means copying the original, and to my thinking copying each contig's folder into a new workspace, vs. copying each contig into the same workspace is basically the same overhead. We also tend to keep the long-lived copy on our warm storage, with processing happening on our cluster's lustre filesystem. . 2) Again, i dont think it's necessarily right to assume every job will operate on the same set of intervals. We generally would use the same pattern, but there are legitimate cases in which different intervals/job would better match the cluster's availability. If we're appending a limited number of samples and our cluster is busy, we might want to scatter using more intervals/job since each job would finish fairly quickly and the practical reality is fewer total jobs would complete quicker. if we are performing an operation that requires a lot of time/job (like creating a new workspace or appending a lot of samples), we might do one job/contig. It's also worth pointing out that macaque has 1000s of small unplaced contigs, and therefore we almost never do a simple 1:1 job:contig scheme.; ; 3) When I was originally thinking about how to scatter/gather the creation of a combined gVCF, the overhead of re-merging was huge. There was zero point in taking the per-contig gVCFs and concat/bgzipping a new one, just to split it again. When I started down this road, my idea was to make a folder holding each gVCF, and a top-level JSON file to map contig->filepath, so code could intelligently work with these. The latter essentially describes the structure of a GenomicsDB workspace. Unlike concatenating gVCFS, the overhead of moving directories around is practically zero. Sure, I could make a folder of GenomicsDB workspaces, but if I'm already moving them, wha",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-640881049:779,avail,availability,779,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-640881049,2,['avail'],['availability']
Availability,1); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:303); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:301); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [5838bd7dec2d4533ad090ce03ecc7c0c] entered state [ERROR] while waiting for [DONE].; ```. #### Steps to reproduce. See command given in stack trace above.; WGS bam is available at ; `gs://broad-dsde-methods/shuang/tmp/HG00512.cram.samtools1_9.bam` ; and ; `gs://broad-dsde-methods/shuang/tmp/HG00512.cram.samtools1_9.bam.bai`. Interval list BED file content given below. ```; chrX	67113957	67114130; chrX	71903370	71903687; chrX	74330484	74330552; chrX	75379902	75379965; chrX	78441355	78441953; ```. #### Expected behavior; Pass. #### Actual behavior; Error! This could be related to ticket #2722,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:22761,ERROR,ERROR,22761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,4,"['ERROR', 'Error', 'avail']","['ERROR', 'Error', 'available']"
Availability,"1. @nalinigans It's a very reasonable question. It's true, the --avoid-nio flag is technically redundant. You can recreate it with a combination of other flags. I added it because ; a) I didn't realize that was the when I started adding it. ; b) The combination of flags was kind of complicated so it was helpful to have something that gave you clear instructions about what you needed to enable. I think we could merge them, although I think there is one sanity check we do even when -bypass-feature-reader is turned on, that we need to turn off. I basically added ""something that works for Megan's project right now."" . 2. Yes, the various cases were getting complicated and I had a bug when -V was enabled so I just disabled it as an option. It would make sense to add -V support for azure files. I just didn't do it because I was in a rush and I figured it was better to disable it than to have it potentially be wrong. . 3. Yeah, that's the error I saw. It's definitely better than nothing. It would be great if it could be propagated back up to the java layer as a Java exception though. It currently ends the program with SIGABORT I think which doesn't play that nicely with various reporting and retry mechanisms. No super high priority, but nice if you have the cycles.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8632#issuecomment-1865021020:95,redundant,redundant,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8632#issuecomment-1865021020,4,"['error', 'redundant']","['error', 'redundant']"
Availability,"1. Add new arg `genomicsdb-shared-posixfs-optimizations` to help with shared posix filesystems like NFS and Lustre. This turns on `disable file locking` and for GenomicsDB import it minimizes writes to disks. The performance on some of the gatk datasets for the import of about 10 samples went from 23.72m to 6.34m on NFS which was comparable to importing to a local filesystem. Hopefully this helps with Issue #6487 and #6627. Also, fixes Issue #6519.; 2. This version of GenomicsDB also uses pre-compression filters for offset and compression files for new workspaces and genomicsdb arrays. The total sizes for a GenomicsDB workspace using the same dataset as above and the 10 samples went from 313MB to 170MB with no change in import and query times. Smaller GenomicsDB arrays also help with performance on distributed and cloud file systems.; 3. This version has added support to handle MNVs similar to deletions as described in Issue #6500. See [GenomicsDB PR 88](https://github.com/GenomicsDB/GenomicsDB/pull/88). Thanks @kgururaj.; 4. There is added support in the GenomicsDBImporter to have multiple contigs in the same GenomicsDB partition/array. This will hopefully help import times in cases where users have many thousands of contigs. See [GenomicsDB PR 91](https://github.com/GenomicsDB/GenomicsDB/pull/91). Changes will be needed from the gatk side to avail this support. Thanks @mlathara.; 5. Logging has been improved somewhat with the native C/C++ code using [spdlog](https://github.com/gabime/spdlog) and [fmt](https://github.com/fmtlib/fmt) and the Java layer using apache log4j and log4j.properties provided by the application. Also, info messages like `No valid combination operation found for INFO field AA - the field will NOT be part of INFO fields in the generated VCF records` will only be output once for the operation. Also see open PR #6514 for code to actually suppress these warnings for known fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6654:1366,avail,avail,1366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6654,1,['avail'],['avail']
Availability,"1. I tried removing `chr` in the bed file, and I am getting the same error.; 2. I tried re-doing of liftover but I am getting the same result.; 3. All problems will be solved if I have target intervals for hg19. So if it is there in the gatk bundle, please let me know, from where I can get it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-760639689:69,error,error,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-760639689,1,['error'],['error']
Availability,"1. We need a script to take snapshots of the [GATK total downloads page](https://somsubhra.com/github-release-stats/?username=broadinstitute&repository=gatk) every month and report the number of times each release was downloaded.; 2. We should change the GATK download link on [this page of the GATK website](https://gatk.broadinstitute.org/hc/en-us) and have it point at a script that records the IP addresses of users before redirecting to github. That way we can have another source of GATK downloads metrics.; 3. Github reports the traffic on GATK repo [here](https://github.com/broadinstitute/gatk/graphs/traffic). It tracks the number of clones and the number of visitors. However, github saves this data only for one week, so we will need an automated script to take snapshots of the page and store the metrics.; 4. In the same way track the total number of download from bioconda from [this](https://anaconda.org/bioconda/gatk4) page.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6946:57,down,downloads,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6946,5,['down'],"['download', 'downloaded', 'downloads']"
Availability,"1. Wrap `SeekablePathStream` in the tribble feature readers with a `Function<SeekableByteChannel, SeekableByteChannel>`. 2. Mirror what was done in https://github.com/broadinstitute/gatk/pull/2331 for `FeatureDataSource`: propagate cloud prefetching buffer sizes from `GATKTool` down to `FeatureDataSource`, create wrapper functions within `FeatureDataSource`, and pass down to htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2375:279,down,down,279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2375,2,['down'],['down']
Availability,"1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletCont",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7418,AVAIL,AVAILABLE,7418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,1.457 INFO FeatureManager - Using codec VCFCodec to read file file:///local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.dbsnp138.vcf; 01:51:51.507 INFO BaseRecalibrationEngine - The covariates being used here: ; 01:51:51.507 INFO BaseRecalibrationEngine - ReadGroupCovariate; 01:51:51.507 INFO BaseRecalibrationEngine - QualityScoreCovariate; 01:51:51.507 INFO BaseRecalibrationEngine - ContextCovariate; 01:51:51.507 INFO BaseRecalibrationEngine - CycleCovariate; 01:51:51.517 INFO FeatureManager - Using codec VCFCodec to read file file:///local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.known_indels.vcf; 20/04/29 01:51:51 ERROR Executor: Exception in task 581.0 in stage 0.0 (TID 581); org.broadinstitute.hellbender.exceptions.GATKException: Error initializing feature reader for path /local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.known_indels.vcf; at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:383); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:335); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:222); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6578:2697,Error,Error,2697,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6578,1,['Error'],['Error']
Availability,"1.9. ### Description ; Starting with GATK4.1.7, the AF annotation in the changed from '0' to '.'. This change is cause downstream issues with our processing pipeline. #### Steps to reproduce; CMD using 4.1.6:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.6.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.6.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,0:68:12,15,0:21,18,0:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. CMD using 4.1.7:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.7.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.7.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,.:68:12,15,.:21,18,.:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. The above 4.1.7 site matches 4.1.8 and 4.1.9. For 4.1.7, The first sample in the VCF lists the 'AF' as ""0.515,."", while in version 4.1.6, AF is represented as ""0.515,0""; ----. ## Feature request. Can the most recent build of 4.1.9 be changed to represent these AF annotations with '0' instead of '.'?. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6938:2427,down,downstream,2427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6938,1,['down'],['downstream']
Availability,1.GRCh37.gatkcnv.brs/work/92/579e5a48aa9e52cd0e1df603266809/B00HOTD.counts.hdf5 (229 / 347); HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 173 in H5Dread(): can'; t read data; major: Dataset; minor: Read failed; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dio.c line 550 in H5D__read(): ca; n't read data; major: Dataset; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 543 in H5D__contig; _read(): contiguous read failed; major: Dataset; minor: Read failed; #003: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 517 in H5D__scat; gath_read(): file gather failed; major: Low-level I/O; minor: Read failed; #004: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dscatgath.c line 253 in H5D__gath; er_file(): read error; major: Dataspace; minor: Read failed; #005: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 873 in H5D__contig; _readvv(): can't perform vectorized sieve buffer read; major: Dataset; minor: Can't operate on object; #006: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5VM.c line 1457 in H5VM_opvv(): ca; n't perform operation; major: Internal error (too specific to document in detail); minor: Can't operate on object; #007: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Dcontig.c line 696 in H5D__contig; _readvv_sieve_cb(): block read failed; major: Dataset; minor: Read failed; #008: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fio.c line 120 in H5F_block_read(; ): read through metadata accumulator failed; major: Low-level I/O; minor: Read failed; #009: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Faccum.c line 263 in H5F__accum_r; ead(): driver read request f,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:1405,error,error,1405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['error'],['error']
Availability,1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 41 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocket,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:5302,avail,available,5302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['avail'],['available']
Availability,1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocket,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8790,avail,available,8790,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['avail'],['available']
Availability,"1/Cosmic.db -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cosmic/hg19/Cosmic.db; 15:41:51.190 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.annotation.REORDERED.gtf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.190 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; 15:41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO Dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:18350,error,errors,18350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['error'],['errors']
Availability,"10.888 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : fals; 08:27:10.888 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : tru; 08:27:10.888 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : fals; 08:27:10.888 INFO Mutect2 - Deflater: IntelDeflate; 08:27:10.889 INFO Mutect2 - Inflater: IntelInflate; 08:27:10.889 INFO Mutect2 - GCS max retries/reopens: 2; 08:27:10.889 INFO Mutect2 - Requester pays: disable; 08:27:10.889 INFO Mutect2 - Initializing engin; 08:27:11.333 INFO Mutect2 - Done initializing engin; 08:27:11.381 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_utils.s; 08:27:11.383 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.s; 08:27:11.426 INFO **IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHM**; 08:27:11.427 INFO IntelPairHmm - Available threads: 4; 08:27:11.428 INFO IntelPairHmm - Requested threads: 4; 08:27:11.428 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementatio; 08:27:11.432 INFO Mutect2 - Shutting down engin; [April 23, 2019 8:27:11 AM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.09 minutes.; Runtime.totalMemory()=190840832; java.lang.IllegalArgumentException: samples cannot be empt; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.ReferenceConfidenceModel.<init>(ReferenceConfidenceModel.java:116); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticReferenceConfidenceModel.<init>(SomaticReferenceConfidenceModel.java:38); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.<init>(Mutect2Engine.java:149); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.onTraversalStart(Mutect2.java:286); 	at org.br",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-485729136:2815,Avail,Available,2815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-485729136,1,['Avail'],['Available']
Availability,"1000 8953837.7; 15:22:58.267 INFO ProgressMeter - chr1:155131495 4.2 37471000 8957853.6; 15:23:08.313 INFO ProgressMeter - chr1:161688288 4.4 39051000 8976244.0; 15:23:18.314 INFO ProgressMeter - chr1:168387593 4.5 40651000 8999225.2; 15:23:28.331 INFO ProgressMeter - chr1:174890255 4.7 42191000 9007247.9; 15:23:38.353 INFO ProgressMeter - chr1:181322766 4.9 43731000 9014563.6; 15:23:48.390 INFO ProgressMeter - chr1:187703141 5.0 45241000 9014994.8; 15:23:58.429 INFO ProgressMeter - chr1:194472259 5.2 46831000 9030709.2; 15:24:08.429 INFO ProgressMeter - chr1:201344987 5.4 48445000 9051051.7; 15:24:18.433 INFO ProgressMeter - chr1:207948168 5.5 50041000 9066794.7; 15:24:28.449 INFO ProgressMeter - chr1:214803619 5.7 51681000 9089033.2; 15:24:38.487 INFO ProgressMeter - chr1:221753713 5.9 53331000 9111140.9; ///////; 16:47:24.218 INFO ProgressMeter - unmapped 88.6 792343000 8941352.3; 16:47:34.221 INFO ProgressMeter - unmapped 88.8 793813000 8941119.4; 16:47:44.239 INFO ProgressMeter - unmapped 88.9 795293000 8940974.8; 16:47:54.256 INFO ProgressMeter - unmapped 89.1 796783000 8940944.5; 16:48:04.283 INFO ProgressMeter - unmapped 89.3 798253000 8940673.7; 16:48:14.335 INFO ProgressMeter - unmapped 89.5 799653000 8939579.7; 16:48:24.361 INFO ProgressMeter - unmapped 89.6 801133000 8939425.6; 16:48:34.392 INFO ProgressMeter - unmapped 89.8 802633000 8939486.6; 16:48:44.420 INFO ProgressMeter - unmapped 90.0 804113000 8939330.0; 16:48:54.443 INFO ProgressMeter - unmapped 90.1 805593000 8939182.3; 16:48:58.375 INFO CountReads - No reads filtered by: WellformedReadFilter; 16:48:58.376 INFO ProgressMeter - unmapped 90.2 806177853 8939171.6; 16:48:58.376 INFO ProgressMeter - Traversal complete. Processed 806177853 total reads in 90.2 minutes.; 16:48:58.376 INFO CountReads - Shutting down engine; [January 2, 2019 4:48:58 PM EST] org.broadinstitute.hellbender.tools.CountReads done. Elapsed time: 90.25 minutes.; Runtime.totalMemory()=10568073216; Tool returned:; 806177853. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450983210:6306,down,down,6306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450983210,1,['down'],['down']
Availability,"10:33:37.508 INFO Mutect2 - Start Date/Time: August 28, 2019 at 10:33:35 AM GMT; 10:33:37.509 INFO Mutect2 - ------------------------------------------------------------; 10:33:37.509 INFO Mutect2 - ------------------------------------------------------------; 10:33:37.510 INFO Mutect2 - HTSJDK Version: 2.20.1; 10:33:37.510 INFO Mutect2 - Picard Version: 2.20.5; 10:33:37.510 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:33:37.511 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:33:37.511 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:33:37.511 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:33:37.513 INFO Mutect2 - Deflater: IntelDeflater; 10:33:37.513 INFO Mutect2 - Inflater: IntelInflater; 10:33:37.514 INFO Mutect2 - GCS max retries/reopens: 20; 10:33:37.514 INFO Mutect2 - Requester pays: disabled; 10:33:37.514 INFO Mutect2 - Initializing engine; 10:33:37.874 INFO Mutect2 - Shutting down engine; [August 28, 2019 at 10:33:37 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=161480704; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:769); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:711); at org.broadinstitute.hellbender.engin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6142:2758,down,down,2758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6142,1,['down'],['down']
Availability,"112,0:0.00:0:0:3730,0:62:50	0/1:66,70:0.534:25:41:2209,2350:26:40; chr6	33442919	.	A	C	.	alt_allele_in_normal	ECNT=1;HCNT=32;MAX_ED=.;MIN_ED=.;NLOD=2.94;TLOD=6.35	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/0:88,17:0.193:4:13:0.765:2231,128:38:50	0/1:123,29:0.156:13:16:0.552:3124,283:60:60; chr6	71886972	.	TC	T	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=2.41;RPA=2,1;RU=C;STR;TLOD=14.12	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:10,0:0.00:0:0:282,0:3:7	0/1:14,5:0.278:0:4:384,148:6:8; chr6	71886972	.	TC	T	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=2.41;RPA=2,1;RU=C;STR;TLOD=14.12	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:10,0:0.00:0:0:282,0:3:7	0/1:14,5:0.278:0:4:384,148:6:8; chr6	118314029	.	TTTCAGGA	T	.	PASS	ECNT=1;HCNT=16;MAX_ED=.;MIN_ED=.;NLOD=20.42;TLOD=80.46	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:69,0:0.00:0:0:2115,0:35:34	0/1:68,26:0.261:13:10:2100,793:37:29; ```. **output to non-block-compressed gives desired error**; ```; WMCF9-CB5:precomputed_results shlee$ java -jar $PICARD GatherVcfs I=split3_8.vcf.gz I=split2_8.vcf.gz O=../test_gathervcf_split8_overlap2.vcf; [Wed Jun 07 14:56:26 EDT 2017] picard.vcf.GatherVcfs INPUT=[split3_8.vcf.gz, split2_8.vcf.gz] OUTPUT=../test_gathervcf_split8_overlap2.vcf VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=true CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [Wed Jun 07 14:56:26 EDT 2017] Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Picard version: 2.9.2-SNAPSHOT; INFO	2017-06-07 14:56:26	GatherVcfs	Checking inputs.; INFO	2017-06-07 14:56:26	GatherVcfs	Checking file headers and first records to ensure compatibility.; INFO	2017-06-07 14:56:27	GatherVcfs	Gathering by conventional means.; [Wed Jun 07 14:56:27 EDT 2017] picard.vcf.GatherVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=257425408; To get help, see http://br",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306889518:4301,error,error,4301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306889518,1,['error'],['error']
Availability,"11:05:38.056 INFO CountVariantsSpark - Shutting down engine; [May 12, 2016 11:05:38 AM AST] org.broadinstitute.hellbender.tools.spark.pipelines.CountVariantsSpark done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=3114270720; htsjdk.tribble.TribbleException: Input stream does not contain a BCF encoded file; BCF magic header info not found, at record 0 with position 0:; at htsjdk.variant.bcf2.BCF2Codec.error(BCF2Codec.java:492); at htsjdk.variant.bcf2.BCF2Codec.readHeader(BCF2Codec.java:153); at org.seqdoop.hadoop_bam.BCFSplitGuesser.<init>(BCFSplitGuesser.java:109); at org.seqdoop.hadoop_bam.BCFSplitGuesser.<init>(BCFSplitGuesser.java:89); at org.seqdoop.hadoop_bam.VCFInputFormat.addGuessedSplits(VCFInputFormat.java:254); at org.seqdoop.hadoop_bam.VCFInputFormat.fixBCFSplits(VCFInputFormat.java:242); at org.seqdoop.hadoop_bam.VCFInputFormat.getSplits(VCFInputFormat.java:221); at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:95); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1910); at org.apache.spark.rdd.RDD.count(RDD.scala:1121); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:445); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:47); at org.broadinstitute.hellbender.tools.spark.pipelines.CountVariantsSpark.runTool(CountVariantsSpark.java:39); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1815:48,down,down,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1815,2,"['down', 'error']","['down', 'error']"
Availability,11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:3973,ERROR,ERROR,3973,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:49); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:31); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:37); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120); 11:54:40.435 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.launcher.daemon.server.exec.ResetD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:8797,ERROR,ERROR,8797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"1209008209559916471805773_0002_m_000000_3: Committed. Elapsed time: 3 ms.; 23/11/16 12:09:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 4103 bytes result sent to driver; 23/11/16 12:09:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 10327 ms on SRINIVASiNDRARAVI (executor driver) (2/2); 23/11/16 12:09:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 23/11/16 12:09:10 INFO DAGScheduler: ResultStage 2 (parquet at StudentAws.scala:36) finished in 10.361 s; 23/11/16 12:09:10 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job; 23/11/16 12:09:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished; 23/11/16 12:09:10 INFO DAGScheduler: Job 2 finished: parquet at StudentAws.scala:36, took 10.369237 s; 23/11/16 12:09:10 INFO FileFormatWriter: Start to commit write Job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; 23/11/16 12:09:10 ERROR FileFormatWriter: Aborting job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method); 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793); 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249); 	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454); 	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:33",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:1891,ERROR,ERROR,1891,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['ERROR'],['ERROR']
Availability,"13 15:46:56 EDT 2020] CreateSequenceDictionary --OUTPUT /media/glier_ubuntu/4TB/Javad_Final/5-trinity/Fastajavad_Trinity/Trinity.dict --REFERENCE /media/glier_ubuntu/4TB/Javad_Final/5-trinity/Fastajavad_Trinity/Trinity.fasta --TRUNCATE_NAMES_AT_WHITESPACE true --NUM_SEQUENCES 2147483647 --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; May 13, 2020 3:46:57 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Wed May 13 15:46:57 EDT 2020] Executing as glier_ubuntu@glierubuntu-Precision-7920-Tower on Linux 4.15.0-99-generic amd64; OpenJDK 64-Bit Server VM 11.0.7+10-post-Ubuntu-2ubuntu218.04; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.1.0; [Wed May 13 15:46:57 EDT 2020] picard.sam.CreateSequenceDictionary done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2107637760; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; picard.PicardException: /media/glier_ubuntu/4TB/Javad_Final/5-trinity/Fastajavad_Trinity/Trinity.dict already exists. Delete this file and try again, or specify a different output file.; 	at picard.sam.CreateSequenceDictionary.doWork(CreateSequenceDictionary.java:209); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:295); 	at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Using GATK jar /home/glier_ubuntu/gatk-4.1.1.0/g",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6604:2118,avail,available,2118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6604,1,['avail'],['available']
Availability,"132 INFO PostprocessGermlineCNVCalls - Analyzing shard 5 / 8...; 23:46:11.901 INFO PostprocessGermlineCNVCalls - Analyzing shard 6 / 8...; 23:46:12.730 INFO PostprocessGermlineCNVCalls - Analyzing shard 7 / 8...; 23:46:14.288 INFO PostprocessGermlineCNVCalls - Analyzing shard 8 / 8...; 23:46:15.617 INFO PostprocessGermlineCNVCalls - Generating segments...; 01:48:30.792 INFO PostprocessGermlineCNVCalls - Parsing Python output...; 01:48:30.875 INFO PostprocessGermlineCNVCalls - Writing segments VCF file to /srv/scratch/testardqu/CNV_Hyperexome/segments_joint/genotyped-segments-SAMPLE_6.vcf.gz...; 01:48:46.860 INFO PostprocessGermlineCNVCalls - Generating denoised copy ratios...; 01:48:47.487 INFO PostprocessGermlineCNVCalls - Writing denoised copy ratios to /srv/scratch/testardqu/CNV_Hyperexome/ratios_joint/denoised-copy-ratios-SAMPLE_6.tsv...; 01:48:47.773 INFO PostprocessGermlineCNVCalls - PostprocessGermlineCNVCalls complete.; 01:48:47.773 INFO PostprocessGermlineCNVCalls - Shutting down engine; [December 6, 2022 1:48:47 AM GMT] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 123.29 minutes.; Runtime.totalMemory()=7257194496; Using GATK jar /gatk/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms4g -Djava.io.tmpdir=/srv/scratch/testardqu/CNV_Hyperexome/tmp/ -jar /gatk/gatk-package-4.3.0.0-local.jar PostprocessGermlineCNVCalls --model-shard-path /srv/scratch/testardqu/CNV_Hyperexome/GermlineCNVCaller/GermlineCNVCaller_1_of_8-model/ --model-shard-path /srv/scratch/testardqu/CNV_Hyperexome/GermlineCNVCaller/GermlineCNVCaller_2_of_8-model/ --model-shard-path /srv/scratch/testardqu/CNV_Hyperexome/GermlineCNVCaller/GermlineCNVCaller_3_of_8-model/ --model-shard-path /srv/scratch/testardqu/CNV_Hyperexome/GermlineCNVCaller/GermlineCNVCaller_4_of_8-model/ --model-shard-path /s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8183:11131,down,down,11131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8183,1,['down'],['down']
Availability,"13:24:09.472 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 13:24:09.473 INFO IntelPairHmm - Available threads: 24; 13:24:09.473 INFO IntelPairHmm - Requested threads: 4; 13:24:09.473 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 13:24:09.501 INFO ProgressMeter - Starting traversal; 13:24:09.502 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 13:24:19.721 INFO ProgressMeter - chr1:634040 0.2 2460 14443.7; 13:24:29.736 INFO ProgressMeter - chr1:1564703 0.3 7220 21409.5; .; .; .; 15:28:55.286 INFO ProgressMeter - chrM:12891 124.8 11474080 91967.0; 15:29:08.985 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 10.162159898; 15:29:08.986 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 1047.646162184; 15:29:08.986 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 1077.35 sec; 15:29:08.986 INFO Mutect2 - Shutting down engine; [September 25, 2020 3:29:08 PM BST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 125.01 minutes.; Runtime.totalMemory()=7713325056; java.lang.NullPointerException; at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:98); at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:49); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:42); at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:14); at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.fillCache(PushToPullIterator.java:72); at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.advanceTo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6851:4470,down,down,4470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851,1,['down'],['down']
Availability,"13Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3746092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3759011Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3760984Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3762471Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3764327Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3813516Z [0K; 2022-08-16T00:09:07.3813804Z [0K; 2022-08-16T00:09:07.3814073Z [0K; 2022-08-16T00:09:07.3818970Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.3821035Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3823794Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3891049Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3891593Z final RangeMap<Integer, Range<Integer>>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:4560,error,error,4560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"15:33:59.328 INFO GenomicsDBImport - Done initializing engine; 23 Feb 2022 15:33:59,334 DEBUG: 	15:33:59.329 INFO GenomicsDBImport - Callset Map JSON file will be re-written to /home/exacloud/gscratch/prime-seq/workDir/0950f56b-7565-103a-a738-f8f3fc8675d2/Job2.work/WGS_1852_consolidated.gdb/callset.json; 23 Feb 2022 15:33:59,339 DEBUG: 	15:33:59.330 INFO GenomicsDBImport - Incrementally importing to workspace - /home/exacloud/gscratch/prime-seq/workDir/0950f56b-7565-103a-a738-f8f3fc8675d2/Job2.work/WGS_1852_consolidated.gdb; 23 Feb 2022 16:28:45,048 DEBUG: 	16:28:45.047 INFO GenomicsDBImport - Done importing batch 1/5; 23 Feb 2022 17:29:49,240 DEBUG: 	17:29:49.226 INFO GenomicsDBImport - Done importing batch 2/5; 23 Feb 2022 18:26:19,107 DEBUG: 	18:26:19.105 INFO GenomicsDBImport - Done importing batch 3/5; 23 Feb 2022 19:20:18,500 DEBUG: 	19:20:18.478 INFO GenomicsDBImport - Done importing batch 4/5; 24 Feb 2022 16:51:19,017 DEBUG: 	[TileDB::utils] Error: (gzip_handle_error) Cannot decompress with GZIP: inflateInit error: Z_MEM_ERROR; 24 Feb 2022 16:51:19,048 DEBUG: 	[TileDB::Codec] Error: Could not decompress with GZIP.; 24 Feb 2022 16:51:19,056 DEBUG: 	[TileDB::ReadState] Error: Cannot decompress tile for /home/exacloud/gscratch/prime-seq/workDir/0950f56b-7565-103a-a738-f8f3fc8675d2/Job2.work/WGS_1852_consolidated.gdb/2$1$196197964/__e7217c9e-767d-4295-b75a-9162c22c6996139785909643008_1613563029631/END.tdb.; 24 Feb 2022 16:51:51,388 DEBUG: 	16:51:51.388 erro NativeGenomicsDB - pid=225263 tid=225739 VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,405 DEBUG: 	TileDB error message : ; 24 Feb 2022 16:51:51,412 DEBUG: 	terminate called after throwing an instance of 'VariantStorageManagerException'; 24 Feb 2022 16:51:51,419 DEBUG: 	 what(): VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,427 DEBUG: 	TileDB error message : ; 24 Feb ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022:1357,Error,Error,1357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022,3,"['Error', 'error']","['Error', 'error']"
Availability,16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$0(ErrorProbabilities.java:27) ; ; at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321) ; ; at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:25) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:138) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:154) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPip,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:8324,Error,ErrorProbabilities,8324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['Error'],['ErrorProbabilities']
Availability,"1625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-NISTSampleHeadToHead/BenchmarkComparison/d1047505-b7bc-455d-851f-fbed8d81e895/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-NISTSampleHeadToHead/BenchmarkComparison/d1047505-b7bc-455d-851f-fbed8d81e895/call-BenchmarkVCFControlSample/Benchmark/5388d7b6-6bcd-451d-9a4e-925b386ecd0c/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""95.03499722222222"",; ""NIST evalHCsystemhours"": ""0.17304166666666665"",; ""NIST evalHCwallclockhours"": ""67.81165555555557"",; ""NIST evalHCwallclockmax"": ""3.691061111111111"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-NISTSampleHeadToHead/BenchmarkComparison/d1047505-b7bc-455d-851f-fbed8d81e895/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-NISTSampleHeadToHead/BenchmarkComparison/d1047505-b7bc-455d-851f-fbed8d81e895/call-BenchmarkVCFTestSample/Benchmark/faae76f3-8378-4271-9822-5d2587113415/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-CreateHTMLReport/cacheCopy/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748:21401,error,errors,21401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748,1,['error'],['errors']
Availability,167581Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8167809Z location: class ReferenceConfidenceVariantContextMerger; 2022-08-16T22:45:53.8173821Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:7: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8175307Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T22:45:53.8175437Z @VisibleForTesting; 2022-08-16T22:45:53.8175712Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8180874Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8265839Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8266584Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8267814Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8268598Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8269986Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8270563Z [0K; 2022-08-16T22:45:53.8270698Z [0K; 2022-08-16T22:45:53.8270832Z [0K; 2022-08-16T22:45:53.8272441Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 31s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:17423,error,error,17423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5111,ERROR,ERROR,5111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['ERROR'],['ERROR']
Availability,"17.402 INFO ProgressMeter - chr20:26553705 51.1 64000 1252.3; 12:17:04.504 INFO ProgressMeter - chr20:29573718 52.9 65000 1228.9; 12:18:23.620 INFO ProgressMeter - chr20:30705782 54.2 66000 1217.5; 12:20:09.590 INFO ProgressMeter - chr21:5249184 56.0 67000 1196.9; 12:22:03.446 INFO ProgressMeter - chr21:10481328 57.9 68000 1175.0; 12:23:03.667 INFO ProgressMeter - chr22:11316842 58.9 69000 1171.9; 12:24:57.983 INFO ProgressMeter - chr22:16127710 60.8 70000 1151.6; 12:26:31.457 INFO ProgressMeter - chr22:25997978 62.3 71000 1138.9; 12:27:09.230 INFO ProgressMeter - chrX:29806474 63.0 72000 1143.4; 12:27:53.073 INFO ProgressMeter - chrX:67820874 63.7 73000 1146.0; 12:29:03.144 INFO ProgressMeter - chrX:86707912 64.9 74000 1140.8; 12:30:07.160 INFO ProgressMeter - chrX:114791793 65.9 75000 1137.5; 12:30:59.264 INFO ProgressMeter - chrX:141227354 66.8 76000 1137.6; 12:31:52.052 INFO ProgressMeter - chrX:153138333 67.7 77000 1137.6; 12:33:18.782 INFO FilterAlignmentArtifacts - Shutting down engine; [February 24, 2023 12:33:18 PM CST] org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts done. Elapsed time: 69.15 minutes.; Runtime.totalMemory()=12185501696; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr1_KI270708v1_random:2666 [VC /raid/tmp/82/68cd46b704bab21cb8661465e5c2b8/WGS-NA12878.filtered.vcf @ chr1_KI270708v1_random:2666 Q. of type=SNP alleles=[T*, A] attr={AS_FilterStatus=SITE, AS_SB_TABLE=[7, 9|3, 11], DP=30, ECNT=2, GERMQ=13, MBQ=[33, 37], MFRL=[317, 323], MMQ=[48, 47], MPOS=47, POPAF=7.30, ROQ=83, TLOD=47.80} GT=GT:AD:AF:DP:F1R2:F2R1:FAD:SB 0/1:16,14:0.486:30:8,9:5,4:15,14:7,9,3,11 filters=; at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:145); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8221:9875,down,down,9875,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8221,1,['down'],['down']
Availability,"18:02:08.659 INFO ProgressMeter - chr1:189989846 6.2 11368000 1838773.1; 18:02:18.685 INFO ProgressMeter - chr1:196788442 6.3 11527000 1815428.1; 18:02:28.690 INFO ProgressMeter - chr1:201317675 6.5 11862000 1820376.8; 18:02:38.693 INFO ProgressMeter - chr1:204176575 6.7 12290000 1839012.8; 18:02:48.701 INFO ProgressMeter - chr1:207325661 6.8 12708000 1855250.2; 18:02:58.737 INFO ProgressMeter - chr1:211941783 7.0 13001000 1852781.7; 18:03:08.789 INFO ProgressMeter - chr1:217052843 7.2 13270000 1847019.0; 18:03:18.840 INFO ProgressMeter - chr1:222942848 7.4 13509000 1837446.7; 18:03:28.843 INFO ProgressMeter - chr1:227016956 7.5 13856000 1842855.4; 18:03:38.858 INFO ProgressMeter - chr1:230704130 7.7 14213000 1849294.6; 18:03:48.900 INFO ProgressMeter - chr1:235326795 7.9 14501000 1846539.8; 18:03:58.915 INFO ProgressMeter - chr1:239911899 8.0 14790000 1844143.5; 18:04:08.930 INFO ProgressMeter - chr1:246522306 8.2 15003000 1832561.8; 18:04:17.556 INFO BaseRecalibrator - Shutting down engine; [May 24, 2019 6:04:17 PM EDT] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 8.39 minutes.; Runtime.totalMemory()=4407164928; htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at htsjdk.tribble.readers.TabixReader$IteratorImpl.next(TabixReader.java:427); 	at htsjdk.tribble.readers.TabixIteratorLineReader.readLine(TabixIteratorLineReader.java:46); 	at htsjdk.tribble.TabixFeatureReader$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5968:7745,down,down,7745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5968,1,['down'],['down']
Availability,"18Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7502319Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7512488Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7514136Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7515610Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:5: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7517156Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:6: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7642312Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7643965Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7645667Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7690890Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7738985Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7739852Z symbol: class RangeMap; 2022-08-16T22:45:53.7740332Z location: c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:6707,error,error,6707,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"1: 97%|#########7| 970/1000 [00:01<00:00, 416.04it/s]; 15:10:05.229 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -426.199 +/- 162.710, SNR: 8.3, T: 1.80: 100%|##########| 1000/1000 [00:01<00:00, 521.12it/s]; 15:10:05.229 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1): 0%| | 0/100 [00:00<?, ?it/s]; 15:10:05.502 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 1.0000 +/- 0.0000: 1%|1 | 1/100 [00:00<00:26, 3.68it/s]; 15:10:05.772 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0046 +/- 0.0049: 2%|2 | 2/100 [00:00<00:26, 3.69it/s]; 15:10:06.039 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0023 +/- 0.0037: 3%|3 | 3/100 [00:00<00:26, 3.71it/s]; 15:10:06.307 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0016 +/- 0.0036: 4%|4 | 4/100 [00:01<00:25, 3.72it/s]; 15:10:06.575 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0018 +/- 0.0019: 5%|5 | 5/100 [00:01<00:25, 3.72it/s]; 15:10:06.844 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0013 +/- 0.0014: 6%|6 | 6/100 [00:01<00:25, 3.72it/s]; 15:10:07.113 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0014 +/- 0.0019: 7%|7 | 7/100 [00:01<00:24, 3.72it/s]; 15:10:07.381 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0011 +/- 0.0011: 8%|8 | 8/100 [00:02<00:24, 3.72it/s]; 15:10:07.649 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0008 +/- 0.0009: 10%|# | 10/100 [00:02<00:24, 3.72it/s]; 15:10:08.193 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0006: 11%|#1 | 11/100 [00:02<00:24, 3.70it/s]; 15:10:08.463 INFO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:11558,error,error,11558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['error'],['error']
Availability,"1:644:1:1; chr22	19895477	CNV_chr22_19895477_19901476	N	<DUP>	2.30	.	END=19901476	GT:CN:NP:QA:QS:QSE:QSS	./.:3:6:1:2:1:0; chr22	19901477	CNV_chr22_19901477_19946476	N	<DEL>	123.62	.	END=19946476	GT:CN:NP:QA:QS:QSE:QSS	1/1:0:45:0:124:1:1; chr22	19946477	CNV_chr22_19946477_19971476	N	<DUP>	6.86	.	END=19971476	GT:CN:NP:QA:QS:QSE:QSS	./.:3:25:0:7:2:1; chr22	19971477	CNV_chr22_19971477_20003000	N	<DEL>	198.68	.	END=20003000	GT:CN:NP:QA:QS:QSE:QSS	1/1:0:32:0:199:2:2. ```. #### Actual behavior. - `gatkgermlinecnvcaller_genotyped-intervals-COHORT_0.woTimestamp.vcf` (`##contig` cut from header and only first 5 `chr22` CNVs present). ```; ##fileformat=VCFv4.2; ##FORMAT=<ID=CN,Number=1,Type=Integer,Description=""Copy number maximum a posteriori value"">; ##FORMAT=<ID=CNLP,Number=.,Type=Integer,Description=""Copy number log posterior (in Phred-scale) rounded down"">; ##FORMAT=<ID=CNQ,Number=1,Type=Integer,Description=""Genotype call quality as the difference between the best and second best phred-scaled log posterior scores"">; ##FORMAT=<ID=GT,Number=1,Type=Integer,Description=""Genotype"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""End coordinate of the variant"">; ##contig=<ID=chr1,length=248956422,assembly=GRCh38.d1.vd1>; ...; ##contig=<ID=HPV-mSD2,length=7300,assembly=GRCh38.d1.vd1>; ##source=PostprocessGermlineCNVCalls; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	E07002_normal; chr1	10000	CNV_chr1_10000_10999	N	<DEL>,<DUP>	.	.	END=10999	GT:CN:CNLP:CNQ	1:0:0,78,88,96,104,111:78; chr1	11000	CNV_chr1_11000_11999	N	<DEL>,<DUP>	.	.	END=11999	GT:CN:CNLP:CNQ	1:0:0,80,85,88,90,93:80; chr1	12000	CNV_chr1_12000_12999	N	<DEL>,<DUP>	.	.	END=12999	GT:CN:CNLP:CNQ	1:0:0,89,101,110,119,126:89; chr1	13000	CNV_chr1_13000_13999	N	<DEL>,<DUP>	.	.	END=13999	GT:CN:CNLP:CNQ	1:0:0,89,96,101,105,108:89; chr1	14000	CNV_chr1_14000_14999	N	<DEL>,<DUP>	.	.	END=14999	GT:CN:CNLP:CNQ	1:0:0,86,91,94,96,98:86; chr1	15000	CNV_chr1_15000_15999	N	<DEL>,<DUP>	.	.	END=15999	GT:CN:CNLP:CNQ	1:0:0,83,89,94,99,103:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8619:19664,down,down,19664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8619,1,['down'],['down']
Availability,1bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 2018-03-09T13:13:41.330127806Z 13:13:41.329 INFO GenotypeGVCFs - Initializing engine; 2018-03-09T13:13:44.528605497Z 13:13:44.528 INFO GenotypeGVCFs - Done initializing engine; 2018-03-09T13:13:45.237843760Z 13:13:45.235 INFO ProgressMeter - Starting traversal; 2018-03-09T13:13:45.237903383Z 13:13:45.235 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 2018-03-09T13:13:56.665869885Z 13:13:56.662 INFO ProgressMeter - chr13:82078938 0.2 13000 68265.4; 2018-03-09T13:14:07.517952300Z 13:14:07.517 INFO ProgressMeter - chr13:82096938 0.4 31000 83475.5; 2018-03-09T13:14:17.546110604Z 13:14:17.545 INFO ProgressMeter - chr13:82123938 0.5 58000 107706.6; 2018-03-09T13:14:28.760222694Z 13:14:28.759 INFO ProgressMeter - chr13:82144938 0.7 79000 108905.4; 2018-03-09T13:14:39.292149466Z 13:14:39.289 INFO ProgressMeter - chr13:82169938 0.9 104000 115440.1; 2018-03-09T13:14:49.877851947Z 13:14:49.873 INFO ProgressMeter - chr13:82193938 1.1 128000 118815.6; 2018-03-09T13:15:01.109839332Z 13:15:01.106 INFO ProgressMeter - chr13:82224938 1.3 159000 125741.4; 2018-03-09T13:15:11.237868051Z 13:15:11.234 INFO ProgressMeter - chr13:82250938 1.4 185000 129071.3; 2018-03-09T13:15:22.457899462Z 13:15:22.455 INFO ProgressMeter - chr13:82284938 1.6 219000 135157.4; 2018-03-09T13:15:32.561846058Z 13:15:32.556 INFO ProgressMeter - chr13:82319938 1.8 254000 142003.9; 2018-03-09T13:15:42.624917849Z 13:15:42.624 INFO ProgressMeter - chr13:82348938 2.0 283000 144647.3; 2018-03-09T13:32:20.050317641Z 13:32:20.049 INFO ProgressMeter - chr13:82369938 18.6 304000 16361.5; 2018-03-09T13:47:24.213333084Z 13:47:24.212 INFO ProgressMeter - chr13:82373938 33.6 308000 9153.2; 2018-03-09T14:21:34.139657997Z 14:21:34.139 INFO ProgressMeter - chr13:82377938 67.8 312000 4600.7; 2018-03-10T07:14:27.162870189Z 07:14:27.161 INFO GenotypeGVCFs - Shutting down engine; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4518:4759,down,down,4759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518,1,['down'],['down']
Availability,1cb8661465e5c2b8/WGS-NA12878.filtered.vcf; 11:24:10.814 INFO FilterAlignmentArtifacts - Done initializing engine; 11:24:10.816 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 11:24:10.817 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 11:24:10.818 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 11:24:10.818 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 11:24:10.957 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 11:24:10.980 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 11:24:10.980 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 11:24:10.981 INFO IntelPairHmm - Available threads: 80; 11:24:10.981 INFO IntelPairHmm - Requested threads: 4; 11:24:10.981 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 11:24:10.981 INFO ProgressMeter - Starting traversal; 11:24:10.981 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 11:25:26.222 INFO ProgressMeter - chr1:32527418 1.3 1000 797.5; 11:26:14.235 INFO ProgressMeter - chr1:103944651 2.1 2000 973.6; 11:26:59.367 INFO ProgressMeter - chr1:121884881 2.8 3000 1069.0; 11:28:22.595 INFO ProgressMeter - chr1:124412677 4.2 4000 953.8; 11:30:27.936 INFO ProgressMeter - chr1:146326436 6.3 5000 795.9; 11:31:16.814 INFO ProgressMeter - chr1:151781328 7.1 6000 845.4; 11:31:47.039 INFO ProgressMeter - chr1:222591703 7.6 7000 920.9; 11:32:23.165 INFO ProgressMeter - chr2:33832294 8.2 8000 975.2; 11:32:57.177 INFO ProgressMeter - chr2:90283356 8.8 9000 1026.2; 11:34:06.535 INFO ProgressMeter - chr2:93744700 9.9 10000 1007.5; 11:34:46.020 IN,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8221:4295,Avail,Available,4295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8221,1,['Avail'],['Available']
Availability,2 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --; GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVC; FGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotR; ecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredSc; aledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_scor; e 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3845:4463,recover,recoverDanglingHeads,4463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3845,3,"['error', 'recover']","['errorCorrectKmers', 'errorCorrectReads', 'recoverDanglingHeads']"
Availability,"2 GiB); 11:00:49.999 INFO MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 56.6 KiB, free 1076.2 GiB); 11:00:49.999 INFO BlockManagerInfo - Added broadcast_3_piece0 in memory on 172.20.19.130:43279 (size: 56.6 KiB, free: 1076.2 GiB); 11:00:50.000 INFO SparkContext - Created broadcast 3 from broadcast at ReadsSparkSink.java:146; 11:00:50.033 INFO MemoryStore - Block broadcast_4 stored as values in memory (estimated size 2.1 MiB, free 1076.2 GiB); 11:00:50.045 INFO MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 56.6 KiB, free 1076.2 GiB); 11:00:50.045 INFO BlockManagerInfo - Added broadcast_4_piece0 in memory on 172.20.19.130:43279 (size: 56.6 KiB, free: 1076.2 GiB); 11:00:50.045 INFO SparkContext - Created broadcast 4 from broadcast at BamSink.java:76; 11:00:50.120 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:00:50.120 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:00:50.177 INFO SparkContext - Starting job: runJob at SparkHadoopWriter.scala:83; 11:00:50.278 INFO DAGScheduler - Registering RDD 14 (mapToPair at SparkUtils.java:161) as input to shuffle 0; 11:00:50.291 INFO DAGScheduler - Got job 1 (runJob at SparkHadoopWriter.scala:83) with 44262 output partitions; 11:00:50.291 INFO DAGScheduler - Final stage: ResultStage 2 (runJob at SparkHadoopWriter.scala:83); 11:00:50.291 INFO DAGScheduler - Parents of final stage: List(ShuffleMapStage 1); 11:00:50.296 INFO DAGScheduler - Missing parents: List(ShuffleMapStage 1); 11:00:50.300 INFO DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at mapToPair at SparkUtils.java:161), which has no missing parents; 11:00:53.974 INFO TaskSchedulerImpl - Cancelling stage 1; 11:00:53.974 INFO TaskSchedulerImpl - Killing all running tasks in stage 1: Stage cancelled; 11:00:53.975 INFO DAGScheduler - ShuffleMapStage 1 (mapToPair at ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:3304,failure,failures,3304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['failure'],['failures']
Availability,"2); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:09 ERROR scheduler.TaskSetManager: Task 16 in stage 0.0 failed 4 times; aborting job; 13:14:09.675 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 1:14:09 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.97 minutes.; Runtime.totalMemory()=937426944; org.apache.spark.SparkException: Job aborted due to stage failure: Task 16 in stage 0.0 failed 4 times, most recent failure: Lost task 16.3 in stage 0.0 (TID 11, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:12366,ERROR,ERROR,12366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['ERROR'],['ERROR']
Availability,"2, xx.xx.xx.xx, executor 0, partition 0, PROCESS_LOCAL, 4956 bytes); 18/04/23 20:42:02 INFO TaskSetManager: Lost task 0.2 in stage 0.0 (TID 2) on xx.xx.xx.xx, executor 0: java.lang.IllegalStateException (unread block data) [duplicate 2]; 18/04/23 20:42:02 INFO TaskSetManager: Starting task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0, partition 0, PROCESS_LOCAL, 4956 bytes); 18/04/23 20:42:02 INFO TaskSetManager: Lost task 0.3 in stage 0.0 (TID 3) on xx.xx.xx.xx, executor 0: java.lang.IllegalStateException (unread block data) [duplicate 3]; 18/04/23 20:42:02 ERROR TaskSetManager: Task 0 in stage 0.0 failed 4 times; aborting job; 18/04/23 20:42:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool; 18/04/23 20:42:02 INFO TaskSchedulerImpl: Cancelling stage 0; 18/04/23 20:42:02 INFO DAGScheduler: ResultStage 0 (first at ReadsSparkSource.java:221) failed in 11.519 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:15313,failure,failure,15313,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['failure'],['failure']
Availability,"2.23.0; 14:50:59.204 INFO FilterMutectCalls - Picard Version: 2.23.3; 14:50:59.204 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:50:59.204 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:50:59.204 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:50:59.205 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:50:59.205 INFO FilterMutectCalls - Deflater: IntelDeflater; 14:50:59.205 INFO FilterMutectCalls - Inflater: IntelInflater; 14:50:59.205 INFO FilterMutectCalls - GCS max retries/reopens: 20; 14:50:59.205 INFO FilterMutectCalls - Requester pays: disabled; 14:50:59.205 INFO FilterMutectCalls - Initializing engine; 14:51:00.692 INFO FeatureManager - Using codec VCFCodec to read file file:///workdir/mparment/data/process/A2683/PTC2_unfiltered.vcf.gz; 14:51:01.406 INFO FilterMutectCalls - Done initializing engine; 14:51:02.360 INFO FilterMutectCalls - Shutting down engine; [December 12, 2020 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6996:3242,down,down,3242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996,1,['down'],['down']
Availability,"200 # sigle interval from 100-200 on chr1.; chr1 { 100-200 } # same; chr1 { # same; 100-200; }; * 100-200 # 100-200 at every contig.; chr1,chr2 100-200 # only on chr1 and chr2; chr1 *200 # from 1-200 i.e. start to 200.; chr1 4000* # from 4000 to the end of chr1.; chr1 4000 # only position 4000; chr1 4M # only position 4 million. M=10^6, k/K=10^3 ; chr1 10000-99 # from 10000 to 10099... ; # perhaps is best not to accept this as it might silence user input errors.; # but what about instead?; chr1 100[00-99]; chr1 10000+100 # 100 bps starting at 10000 so 10000-10099; chr1 4k # only poistion 4000.; chr20 1M+32K # from position 1 million extending to the following 32Kbps.; chr20 1M1+32K # from position 1 million and 1 instead. (avoiding all those 0s). chr1 *:200 # consecutive 200bp intervals for the entire chromosome; chr1 *:200(100) # 200bp intervals with 100 gaps; chr1 *:200/20 # 200bp intervals with an overlap of 20bp.; chr1 *:20/200 # 200bp starting every 20 positions (so 180bp overlap); chr1 *:200~20 # 200bp intervals truncating down to 20bp if necessary. ; chr1 { # we can combine interval specs in blocks if they apply to the same contig(s).; 1M-2M:150(20) # from 1 to 2Mbp 150 intervals with 20bp gap; 20M-25M # a big interval from 20 to 25M.; 40012451-40023451 # another standalone interval ; } . ```; ## Interval exclusion; We could specify the exclused interval in the same file:; ```; chr20 *:200 exclude *10000 11000000+10000 32510000* # 200bp intervals except telomere and centromere regions. chr20 { # another way using blocks.; *:200; } excl {; *10000 ; 11000000+10000 ; 32510000*; }. ```. ## Arbitrary interval list. Some other tools cannot specify intervals if these are very specific... for example in exome analysis targets do not fall at regular intervals and are tailor to the capture used. In this case explicit listing is not avoidable. However there are ways to gain. For one thing the language above allows to pack intervals on the same contig on the block so savi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5702:2005,down,down,2005,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5702,1,['down'],['down']
Availability,200130Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4200630Z location: class ReferenceConfidenceVariantContextMerger; 2022-08-16T00:09:07.4211864Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:7: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4214985Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T00:09:07.4215495Z @VisibleForTesting; 2022-08-16T00:09:07.4216081Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4251408Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4265184Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4267067Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4271200Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4272874Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4278681Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4292326Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4293163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4296749Z src/main/java/org/broadinstitu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:15385,error,error,15385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,2011 -5 ; Lines 151426 150912 -514 ; Branches 16623 16131 -492 ; ================================================; - Hits 131636 53105 -78531 ; - Misses 13728 92939 +79211 ; + Partials 6062 4868 -1194; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/6007?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/6007/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/6007/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/6007/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/6007/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/6007/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6007#issuecomment-502666660:1589,down,downsampling,1589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6007#issuecomment-502666660,1,['down'],['downsampling']
Availability,"2019-01-09 13:35:12 INFO Server:414 - Started @9981ms; 2019-01-09 13:35:12 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHan",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7157,AVAIL,AVAILABLE,7157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,"2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonf",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:36454,failure,failure,36454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['failure'],['failure']
Availability,"2021/05/27 19:36:04 Delocalizing output /cromwell\_root/memory\_retry\_rc -> gs://fc-51aefb1c-4e8e-4dcb-a59c-62e318ea351a/b4b25c64-84dc-4902-ae53-89bff2091e92/mendelian\_analysis/fd25ef2c-8ed6-4b2a-9df9-b7287511aee8/call-mendelian\_analysis/memory\_retry\_rc 2021/05/27 19:36:04 Delocalizing output /cromwell\_root/rc -> gs://fc-51aefb1c-4e8e-4dcb-a59c-62e318ea351a/b4b25c64-84dc-4902-ae53-89bff2091e92/mendelian\_analysis/fd25ef2c-8ed6-4b2a-9df9-b7287511aee8/call-mendelian\_analysis/rc 2021/05/27 19:36:05 Delocalizing output /cromwell\_root/stdout -> gs://fc-51aefb1c-4e8e-4dcb-a59c-62e318ea351a/b4b25c64-84dc-4902-ae53-89bff2091e92/mendelian\_analysis/fd25ef2c-8ed6-4b2a-9df9-b7287511aee8/call-mendelian\_analysis/stdout 2021/05/27 19:36:06 Delocalizing output /cromwell\_root/stderr -> gs://fc-51aefb1c-4e8e-4dcb-a59c-62e318ea351a/b4b25c64-84dc-4902-ae53-89bff2091e92/mendelian\_analysis/fd25ef2c-8ed6-4b2a-9df9-b7287511aee8/call-mendelian\_analysis/stderr 2021/05/27 19:36:08 Delocalizing output /cromwell\_root/1kgp.chrX.recalibrated.snp\_indel.pass.MVs.byFamily.table -> gs://fc-51aefb1c-4e8e-4dcb-a59c-62e318ea351a/b4b25c64-84dc-4902-ae53-89bff2091e92/mendelian\_analysis/fd25ef2c-8ed6-4b2a-9df9-b7287511aee8/call-mendelian\_analysis/1kgp.chrX.recalibrated.snp\_indel.pass.MVs.byFamily.table Required file output '/cromwell\_root/1kgp.chrX.recalibrated.snp\_indel.pass.MVs.byFamily.table' does not exist. I am running VariantEval to detect Mendelian violations in large joint genotyped VCF files, so I'm running it on a per-chromosome basis. This error only occurs for the chromosome X file, and it only occurs with this FASTA file (GRCh38 on chrX does not cause this issue). IndexFeatureFile is run just before this error, which has also led to successful runs in other chromosomes, so that's not the issue. Any insight on this issue would be appreciated.<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/161363'>Zendesk ticket #161363</a>)<br>gz#161363</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7304:8603,error,error,8603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7304,2,['error'],['error']
Availability,2022-08-16T00:09:07.4271200Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4272874Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4278681Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4292326Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4293163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4296749Z src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4303354Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4304128Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4304857Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4317403Z src/main/java/org/broadinstitute/hellbender/utils/runtime/ProcessControllerBase.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4330221Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ThresholdCalculator.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:16437,error,error,16437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"204e+01,0.0000e+00,4.5000e+02,8.5278e+01,1.3828e+02,4.5000e+02,1.3246e+02,4.5000e+02,4.5000e+02:0.00,2.00,5.00,2.00,4.00,5.00,34.77,36.77,36.77,37.77:1,0,18,17:1,0,22,13; ```; * ReblockGVCF (4.2.3.0) output; ```; chr14 60604048 . TCACACA T,<NON_REF> 135.20 . AS_QUALapprox=|140|0;AS_VarDP=1|34|0;DP=44;MQ=250.00;MQRankSum=1.636;QUALapprox=140;RAW_GT_COUNT=0,0,1;RAW_MQandDP=2750000,44;ReadPosRankSum=1.540;VarDP=35 GT:AD:AF:DP:F1R2:F2R1:GQ:ICNT:MB:PL:PRI:SB:SPL 1/1:1,34,0:0.944,0.028,0.000:36:1,20,1,0:0,14,0,0:88:0,29:1,0,22,13:140,88,0,935,101,948:0.00,2.00,5.00,2.00,4.00,5.00,34.77,36.77,36.77,37.77:1,0,18,17:255,0,220; ```. As you can see above, there are small issues related to ReblockGVCF output. First, as you do some kind of ""LeftAlignment"" normalization on the data, you are dropping one of the Alt Variants (in this case, variant ""TCACACA"") but, unfortunately, the FORMAT information is not following this change. The AF still has 3 values from the Dragen output when it was supposed to be 2 (This is the main reason for the GenomicsDBImport error shown here). AD drops one of the reads count, but DP don't follow it (dragen AD = 1,34,1,0 ; DP = 36 ---- reblock AD = 1,34,0 ; DP = 36 <-- it was supposed to be 35). Plus, I'm not sure why, but Reblock doesn't keep the GP format information from dragen. <br>-- Second; * dragen; ```; chrX 25031465 . G GTT,GTTT,<NON_REF> 73.68 PASS DP=9;MQ=241.99;FractionInformativeReads=0.667 GT:AD:AF:DP:F1R2:F2R1:GQ:PL:SPL:ICNT:GP:PRI:SB:MB 1:0,5,1,0:0.833,0.167,0.000:6:0,4,0,0:0,1,1,0:57:78,0,57,73:119,0:0,6:7.3684e+01,8.0247e-06,5.7494e+01,1.0405e+02:0.00,4.00,4.00,34.77:0,0,2,4:0,0,2,4; ```; * ReblockGVCF; ```; chrX 25031465 . G GTT,<NON_REF> 73.68 . AS_QUALapprox=|78|0;AS_VarDP=0|5|0;DP=9;MQ=241.99;QUALapprox=78;RAW_GT_COUNT=0,0,1;RAW_MQandDP=527032,9;VarDP=5 GT:AD:AF:DP:F1R2:F2R1:GQ:ICNT:MB:PL:PRI:SB:SPL 1:0,5,0:0.833,0.167,0.000:6:0,4,0,0:0,1,1,0:73:0,6:0,0,2,4:78,0,73:0.00,4.00,4.00,34.77:0,0,2,4:119,0; ```. Mostly the same happens in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7589:6908,error,error,6908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7589,1,['error'],['error']
Availability,"21.683 INFO Concordance - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 11:26:21.683 INFO Concordance - Deflater: IntelDeflater ; ; 11:26:21.684 INFO Concordance - Inflater: IntelInflater ; ; 11:26:21.684 INFO Concordance - GCS max retries/reopens: 20 ; ; 11:26:21.684 INFO Concordance - Requester pays: disabled ; ; 11:26:21.684 INFO Concordance - Initializing engine ; ; 11:26:22.217 INFO FeatureManager - Using codec VCFCodec to read file file:///scicore/home/cichon/GROUP/memory\_optimization/variants/filtered/NA12878.vcf.gz ; ; 11:26:22.497 INFO FeatureManager - Using codec VCFCodec to read file file:///scicore/home/cichon/GROUP/memory\_optimization/variants/filtered/sample1\_affect.filtered.vcf ; ; 11:26:22.663 INFO Concordance - Done initializing engine ; ; 11:26:22.672 INFO ProgressMeter - Starting traversal ; ; 11:26:22.672 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute ; ; 11:26:22.682 INFO Concordance - Shutting down engine ; ; \[November 11, 2021 11:26:22 AM CET\] org.broadinstitute.hellbender.tools.walkers.validation.Concordance done. Elapsed time: 0.02 minutes. ; ; Runtime.totalMemory()=559939584 ; ; java.lang.NullPointerException ; ; at htsjdk.variant.variantcontext.VariantContextComparator.compare(VariantContextComparator.java:87) ; ; at org.broadinstitute.hellbender.engine.AbstractConcordanceWalker$ConcordanceIterator.next(AbstractConcordanceWalker.java:192) ; ; at org.broadinstitute.hellbender.engine.AbstractConcordanceWalker$ConcordanceIterator.next(AbstractConcordanceWalker.java:174) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) ; ; at org.broadinstitute.hellbender.engine.AbstractConcordanceWalker.traverse(AbstractConcordanceWalker.java:132) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7562:4293,down,down,4293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7562,1,['down'],['down']
Availability,"210,177,182; chr13	32944609	.	T	A,*,TAAAA,<NON_REF>	0	.	BaseQRankSum=4.278;DP=787;ExcessHet=3.0103;MLEAC=0,1,0,0;MLEAF=0.00,0.500,0.00,0.00;MQRankSum=0.000;RAW_MQandDP=2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.gvcf -ERC GVCF && tail target.4.1.2.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.vcf && tail target.4.1.2.0.vcf; ```. #### Expected behavior; 1. expose the rule that the second variant (T>TAAAA) filtered (especially for version 4.0.9.0).; 2. give the right QUAL of the second variant; 3. then this type of variant can be retain in VCF as default operation or w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:6358,down,download,6358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,1,['down'],['download']
Availability,"22-01-18; OpenJDK Runtime Environment (build 17.0.2+8-86); OpenJDK 64-Bit Server VM (build 17.0.2+8-86, mixed mode, sharing); ```. Because it's a shared cluster, we aren't able to run Docker directly. But I attempted converting it in to a Singularity container and it didn't crash in the same way, but the job did end up failing. Logs are as follows -. For the ""bare metal"" known-crashing conditions (AMD-based machine), the final lines of the output are:; ```; 22:47:45.999 INFO ProgressMeter - Scaffold_1:21181812 551.0 125350 227.5; 22:47:56.192 INFO ProgressMeter - Scaffold_1:21203869 551.1 125450 227.6; 22:48:06.937 INFO ProgressMeter - Scaffold_1:21251889 551.3 125650 227.9; 22:48:18.177 INFO ProgressMeter - Scaffold_1:21271601 551.5 125750 228.0; 22:48:29.896 INFO ProgressMeter - Scaffold_1:21281660 551.7 125810 228.0; 22:48:40.223 INFO ProgressMeter - Scaffold_1:21284898 551.9 125830 228.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f889b5be310, pid=1422929, tid=1422930; #; # JRE version: OpenJDK Runtime Environment (17.0.2+8) (build 17.0.2+8-86); # Java VM: OpenJDK 64-Bit Server VM (17.0.2+8-86, mixed mode, sharing, tiered, compressed oops, compressed class ptrs, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0xcf310] __memset_avx2_unaligned_erms+0x60; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h %e"" (or dumping to /bigdata/operations/ejaco020/gatk/core.1422929); #; # An error report file with more information is saved as:; # /bigdata/operations/ejaco020/gatk/hs_err_pid1422929.log; #; # If you would like to submit a bug report, please visit:; # https://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. When running on singularity (AMD-based machine):; ```; 07:07:35.120 INFO Progress",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8988#issuecomment-2386154680:1080,error,error,1080,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8988#issuecomment-2386154680,1,['error'],['error']
Availability,22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:4752,reliab,reliable,4752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"22:45:33 INFO YarnScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool; 2019-06-03 22:45:33 INFO DAGScheduler:54 - Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 302.340057 s; 2019-06-03 22:45:35 INFO SparkHadoopWriter:54 - Job job_20190603224030_0014 committed.; 2019-06-03 22:45:35 INFO AbstractConnector:318 - Stopped Spark@6be766d1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-06-03 22:45:35 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4040; 2019-06-03 22:45:35 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-06-03 22:45:35 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-06-03 22:45:35 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-06-03 22:45:35 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-06-03 22:45:35 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-06-03 22:45:35 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-06-03 22:45:35 INFO MemoryStore:54 - MemoryStore cleared; 2019-06-03 22:45:35 INFO BlockManager:54 - BlockManager stopped; 2019-06-03 22:45:35 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-06-03 22:45:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-06-03 22:45:35 INFO SparkContext:54 - Successfully stopped SparkContext; 22:45:35.933 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 10:45:35 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 5.79 minutes.; Runtime.totalMemory()=4147118080; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-423d02dc-cbc1-4c83-907d-ca315ca231bc; 2019-06-03 22:45:35 INFO ShutdownHookMa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:8416,down,down,8416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,4,['down'],['down']
Availability,22:45:53.7882811Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7889039Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7926431Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7973092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7983013Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7993443Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7996577Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T22:45:53.7997033Z @VisibleForTesting; 2022-08-16T22:45:53.7997778Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.7998135Z location: class PileupElement; 2022-08-16T22:45:53.8006697Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8013274Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8014882Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8016302Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:5: error: package com.google.common.primitives does n,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:12009,error,error,12009,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"23:00:06 INFO YarnScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool; 2019-06-03 23:00:06 INFO DAGScheduler:54 - Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 375.304795 s; 2019-06-03 23:00:08 INFO SparkHadoopWriter:54 - Job job_20190603225351_0015 committed.; 2019-06-03 23:00:09 INFO AbstractConnector:318 - Stopped Spark@6be766d1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-06-03 23:00:09 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4040; 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-06-03 23:00:09 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-06-03 23:00:09 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-06-03 23:00:09 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-06-03 23:00:09 INFO MemoryStore:54 - MemoryStore cleared; 2019-06-03 23:00:09 INFO BlockManager:54 - BlockManager stopped; 2019-06-03 23:00:09 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-06-03 23:00:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-06-03 23:00:09 INFO SparkContext:54 - Successfully stopped SparkContext; 23:00:09.356 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 11:00:09 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 7.01 minutes.; Runtime.totalMemory()=4327997440; 2019-06-03 23:00:09 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-06-03 23:00:09 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-73067845-b641-4212-9c81-51e8d6aa9f31; 2019-06-03 23:00:09 INFO ShutdownHookMa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:15202,down,down,15202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,4,['down'],['down']
Availability,"25212Z location: class CountingVariantFilter; 2022-08-16T22:45:53.8032154Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8035089Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T22:45:53.8035234Z @VisibleForTesting; 2022-08-16T22:45:53.8035505Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8035658Z location: class ReadFilter; 2022-08-16T22:45:53.8087327Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8103864Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8113680Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8117654Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8118430Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8124030Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T22:45:53.8124383Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-08-16T22:45:53.8124657Z symbol: class BiMap; 2022-08-16T22:45:53.8124810Z location: class LoggingUtils; 2022-08-16T22:45:53.8125227Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:41: error: cannot find symbol; 2022-08-16T22:45:53.8125528Z private static BiMap<Log.LogLevel, java.util.logging.Level> javaUtilLevelNamespaceMap;; 2022-08-16T22:45:53.8125793Z symbol: class BiMap; 2",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:14620,error,error,14620,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"27, 2019 9:15:53 AM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2131755008; htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 3433: The VCF specification does not allow for whitespace in the INFO field; . Offending field value was ""AC=1;AF=9.671e-04;AN=1034;AS_BaseQRankSum=-1.550;AS_FS=8.334;AS_InbreedingCoeff=-0.3147;AS_MQ=31.69;AS_MQRankSum=-0.200;AS_QD=28.73;AS_ReadPosR; ankSum=nul;AS_SOR=2.235;BaseQRankSum=-1.381e+00;DP=40368;ExcessHet=160.0000;FS=8.334;InbreedingCoeff=-0.3147;MLEAC=7;MLEAF=6.770e-03;MQ=37.13;MQRankSum=0.126;QD=2.46;SOR=2.; 235 GT:AD:DP:GQ:PGT:PID:PL:PS 0/0:75,0:75:0:.:.:0,0,1525; `. However, from the error message I cannot see any whitespace in the INFO field. The /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR/ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.gz is the output of following command:. `gatk4.1.0.0 --java-options '-Xmx100g -Xmx100g' ApplyVQSR \; -R /dsgmnt/llfs2/masterdata/geno/hg38/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta \; -V ${SNPPath}/joint525_chr1_ExcessHet_filter.SNP.g.vcf.gz \; -V ${SNPPath}/joint525_chr2_ExcessHet_filter.SNP.g.vcf.gz \; ....; -V ${SNPPath}/joint525_chr22_ExcessHet_filter.SNP.g.vcf.gz \; -O /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR//ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.g; z \; --truth-sensitivity-filter-level 97 \; --tranches-file /dsgmnt/seq5_llfs/work/xhong/v4100/VQSR//ExcessHet_joint525_c1_22.snp.tranches \; --recal-file /dsgmnt/seq5_llfs/work/xho; ng/v4100/VQSR//ExcessHet_joint525_c1_22.snp.recal \; -mode SNP`. There is no error or warning in the standard error and standard output of this step. I have tried to apply VQSR SNP model to ${SNPPath}/joint525_chr1_ExcessHet_filter.SNP.g.vcf.gz. It works well. When I select BISNPs from the output, I could not repeat the error. . I would like to get suggestion on how to narrow down the problem. Any input is appreciated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6021:4672,error,error,4672,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6021,4,"['down', 'error']","['down', 'error']"
Availability,"2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.gvcf -ERC GVCF && tail target.4.1.2.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.vcf && tail target.4.1.2.0.vcf; ```. #### Expected behavior; 1. expose the rule that the second variant (T>TAAAA) filtered (especially for version 4.0.9.0).; 2. give the right QUAL of the second variant; 3. then this type of variant can be retain in VCF as default operation or with some addition parameters.; 4. can GATK have ability to detect the `real` variant such as TTT>AAAA. #### Actual behavior; ~~_Tell us what happens instead_~~; unknown",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:6551,down,download,6551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,3,['down'],['download']
Availability,28971Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431031Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431538Z [0K; 2022-08-16T00:09:07.4431680Z [0K; 2022-08-16T00:09:07.4431811Z [0K; 2022-08-16T00:09:07.4432994Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 49s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.4435974Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T00:09:07.4436105Z @VisibleForTesting; 2022-08-16T00:09:07.4436380Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4436641Z location: class CommandLineProgram; 2022-08-16T00:09:07.4436930Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:120: error: cannot find symbol; 2022-08-16T00:09:07.4437094Z @VisibleForTesting; 2022-08-16T00:09:07.4437369Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4437519Z location: class FeatureInput<T>; 2022-08-16T00:09:07.4437725Z where T is a type-variable:; 2022-08-16T00:09:07.4437925Z T extends Feature declared in class FeatureInput; 2022-08-16T00:09:07.4438276Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:251: error: cannot find symbol; 2022-08-16T00:09:07.4438417Z @VisibleForTesting; 2022-08-16T00:09:07.4438677Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4438873Z location: class PosteriorProbabilitiesUtils; 2022-08-16T00:09:07.443922,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:20290,error,error,20290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"2921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta is not a valid DFS filename.; 	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:213); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1436); 	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1433); 	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); 	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1448); 	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1436); 	at org.broadinstitute.hellbender.utils.spark.SparkUtils.pathExists(SparkUtils.java:100); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.setHadoopBAMConfigurationProperties(ReadsSparkSource.java:241); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:203); 	... 20 more; ERROR: (gcloud.dataproc.jobs.submit.spark) Job [da63aa3c-e3bc-4893-9f40-42921719a343] entered state [ERROR] while waiting for [DONE].; ```. to reproduce this error, . ```bash; cd /Users/shuang/GATK/gatk. CLUSTER_NAME=""svdev-caller""; MASTER_NODE=""hdfs://svdev-caller-m:8020""; PROJECT_DIR=""user/shuang/NA12878_PCR-_30X"". ./gatk-launch FindBreakpointEvidenceSpark \; -R ""$MASTER_NODE""/reference/Homo_sapiens_assembly38.fasta \; -I ""$MASTER_NODE""/data/smallCram.cram \; -O ""$MASTER_NODE""/""$PROJECT_DIR""/fastq \; --exclusionIntervals gs://sv-data-dsde-dev/reference/GRCh38.kill.intervals \; --kmersToIgnore gs://sv-data-dsde-dev/reference/Homo_sapiens_assembly38.dups \; --kmerIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/kmerIntervals \; --breakpointEvidenceDir ""$MASTER_NODE""/""$PROJECT_DIR""/evidence \; --breakpointIntervals ""$MASTER_NODE""/""$PROJECT_DIR""/intervals \; --qnameIntervalsMapped ""$MASTER_NODE""/""$PROJECT_DIR""/qnameIntervalsMapped \; --qnameIntervalsForAssembly ""$MASTER_NODE""/""$PROJECT_DIR""/qnameInt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:4099,ERROR,ERROR,4099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['ERROR'],['ERROR']
Availability,2:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:4962,reliab,reliable,4962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"2:18:50.379 INFO ProgressMeter - CM031199.1:15138950 1.5 2935000 1949928.6; 22:19:00.394 INFO ProgressMeter - CM031199.1:16835922 1.7 3304000 1975958.4; 22:19:10.397 INFO ProgressMeter - CM031199.1:18887424 1.8 3732000 2029566.1; 22:19:20.417 INFO ProgressMeter - CM031199.1:20313013 2.0 4041000 2014640.8; 22:19:30.446 INFO ProgressMeter - CM031199.1:22312939 2.2 4473000 2058491.9; 22:19:40.460 INFO ProgressMeter - CM031199.1:24063238 2.3 4842000 2069348.7; 22:19:52.201 INFO ProgressMeter - CM031199.1:25798492 2.5 5213000 2055964.2; 22:20:02.224 INFO ProgressMeter - CM031199.1:27826886 2.7 5646000 2089099.4; 22:20:12.237 INFO ProgressMeter - CM031199.1:29589960 2.9 6022000 2098635.6; Chromosome CM031199.1 position 29761047 (TileDB column 29761046) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. 22:20:13.114 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),84.82845143211256,Cpu time(s),73.66556314507389; [January 16, 2022 at 10:20:13 PM PST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 2.91 minutes.; Runtime.totalMemory()=683671552; java.lang.IllegalStateException: Genotype [T199970 ATATATAT/T GQ 49 DP 4 AD 0,2,0,0,0,2,0,0 {SB=0,0,2,2}] does not contain likelihoods necessary to calculate posteriors.; 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.log10NormalizedGenotypePosteriors(AlleleFrequencyCalculator.java:89); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.effectiveAlleleCounts(AlleleFrequencyCalculator.java:258); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.calculate(AlleleFrequencyCalculator.java:141); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1014180059:6739,down,down,6739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1014180059,1,['down'],['down']
Availability,"2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **maximum length** reference allele so that I can go back and set the `--reference_window_stop` argument appropriately in a second round so that I can left-align _all_ of my variants. . ### MD5 and looking into the files, we see input and output are different and in fact the tool did change allele representations:; ```; WMCF9-CB5:Mutect2 shlee$ gzcat zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz | grep -v '##' > zeta_headless.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487:7901,checkpoint,checkpoint,7901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487,1,['checkpoint'],['checkpoint']
Availability,3); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Caused by: org.gradle.process.internal.ExecException: Process 'Gradle Test Executor 1' finished with non-zero exit value 134; 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.DefaultExecHandle$ExecResultImpl.assertNormalExitValue(DefaultExecHandle.java:369); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcess.waitForStop(DefaultWorkerProcess.java:190); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.process.internal.worker.DefaultWorkerProcessBuilder$MemoryRequestingWorkerProcess.waitForStop(DefaultWorkerProcessBuilder.java:228); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.worker.ForkingTestClassProcessor.stop(ForkingTestClassProcessor.java:122); 11:54:40.436 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.endBatch(RestartEveryNTestClassProcessor.java:63); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.testing.processors.RestartEveryNTestClassProcessor.stop(RestartEveryNTestClassProcessor.java:57); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 11:54:40.437 [ERROR] [org.gradle.internal.buildevents.BuildExce,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:14252,ERROR,ERROR,14252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"3); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:26177,down,downloaded,26177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,4,"['down', 'error']","['downloaded', 'error']"
Availability,3.0.0 seems to be the most recent version available in maven. Hopefully it knows about java 11?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532379412:42,avail,available,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532379412,1,['avail'],['available']
Availability,"3.797 INFO CreateReadCountPanelOfNormals - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 19/02/18 12:33:53 INFO SparkContext: Running Spark version 2.2.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar) to method sun.security.krb5.Config.getInstance(); WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:33:54.187 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 12:33:54.263 INFO CreateReadCountPanelOfNormals - Shutting down engine; [February 18, 2019 at 12:33:54 PM CST] org.broadinstitute.hellbender.tools.copynumber.CreateReadCountPanelOfNormals done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2147483648; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at org.apache.spark.SparkConf.validateSettings(SparkConf.scala:546); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:373); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:178); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostPa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:2174,down,down,2174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,1,['down'],['down']
Availability,"30.861 INFO ProgressMeter - chr21:48065662 88.1 10112630 114731.5; 22:45:30.976 INFO HaplotypeCaller - 0 read(s) filtered by: MappingQualityReadFilter; 0 read(s) filtered by: MappingQualityAvailableReadFilter; 0 read(s) filtered by: MappedReadFilter; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter; 0 read(s) filtered by: NotDuplicateReadFilter; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter; 0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter; 0 read(s) filtered by: GoodCigarReadFilter; 0 read(s) filtered by: WellformedReadFilter; 0 total reads filtered; 22:45:30.976 INFO ProgressMeter - chr21:48129366 88.1 10112861 114731.7; 22:45:30.976 INFO ProgressMeter - Traversal complete. Processed 10112861 total regions in 88.1 minutes.; 22:45:31.288 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.864119336; 22:45:31.288 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 115.66789462000001; 22:45:31.288 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 90.73 sec; 22:45:31.289 INFO HaplotypeCaller - Shutting down engine; [August 31, 2020 10:45:31 PM CDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 88.19 minutes.; Runtime.totalMemory()=2630352896. And now the header looks like:; ```; @SQ SN:chr1 LN:249250621; @SQ SN:chr2 LN:243199373; @SQ SN:chr3 LN:198022430; @SQ SN:chr4 LN:191154276; @SQ SN:chr5 LN:180915260; @SQ SN:chr6 LN:171115067; @SQ SN:chr7 LN:159138663; @SQ SN:chr8 LN:146364022; @SQ SN:chr9 LN:141213431; @SQ SN:chr10 LN:135534747; @SQ SN:chr11 LN:135006516; @SQ SN:chr12 LN:133851895; @SQ SN:chr13 LN:115169878; @SQ SN:chr14 LN:107349540; @SQ SN:chr15 LN:102531392; @SQ SN:chr16 LN:90354753; @SQ SN:chr17 LN:81195210; @SQ SN:chr18 LN:78077248; @SQ SN:chr20 LN:63025520; @SQ SN:chr19 LN:59128983; @SQ SN:chr22 LN:51304566; @SQ SN:chr21 LN:48129895; ```. So I still think it is the header in BAM that is causing the error message.; Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684831011:1431,down,down,1431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684831011,2,"['down', 'error']","['down', 'error']"
Availability,"315.4; 11:16:47.479 INFO ProgressMeter - chr6_GL000251v2_alt:3288752 22.3 111608000 4999358.0; 11:16:57.479 INFO ProgressMeter - chr19_KI270915v1_alt:116858 22.5 112656000 5008907.2; 11:17:07.482 INFO ProgressMeter - chr6_GL000252v2_alt:3648002 22.7 113732000 5019540.7; 11:17:17.485 INFO ProgressMeter - chr19_GL000209v2_alt:107854 22.8 114378000 5011183.1; 11:17:27.485 INFO ProgressMeter - chr6_GL000254v2_alt:4706141 23.0 115453000 5021609.7; 11:17:37.489 INFO ProgressMeter - chr6_GL000256v2_alt:3229060 23.2 116516000 5031360.7; 11:17:47.495 INFO ProgressMeter - chrUn_KN707963v1_decoy:59481 23.3 117352000 5031225.8; 11:17:57.500 INFO ProgressMeter - HLA-A*02:53N:2725 23.5 117662000 5008712.4; 11:18:02.114 INFO PrintReads - No reads filtered by: WellformedReadFilter; 11:18:02.114 INFO ProgressMeter - unmapped 23.6 118064258 5009433.9; 11:18:02.114 INFO ProgressMeter - Traversal complete. Processed 118064258 total reads in 23.6 minutes.; 11:18:05.615 INFO PrintReads - Shutting down engine; [October 2, 2017 11:18:05 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 23.67 minutes.; Runtime.totalMemory()=11493965824; ```. And I can view the BAM with Samtools:; ```; samtools view /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam | less; SRR070790.20928984 99 chr1 10004 0 3S97M = 10036 116 AACCCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC <<<<<BFBBBBBFBBBBBBBBBBBFBBBBBFBBBBBBBBBBBBBBBBBBBBBBBBBBBBBFBBBBBBBBB7B<BBBB<F<B<<BBBB<<BFB<770<<<7 MC:Z:61M1D22M17S RG:Z:SRR070790 MQ:i:0 AS:i:97 XS:i:100; SRR070503.24638125 145 chr1 10008 0 100M chr6 8088710 0 AGCCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACC ''''''''''''BBB<<<<7<7<<BBBBFBBBFFBBBBBBFBFBBBFBBBBBFBFBBBFBFBBBF<BBBBFBBBBBFBBBBBFBBBBBFBBBBBB<<<<< RG:Z:SRR070503 MQ:i:60 AS:i:98 XS:i:98; SRR070790.26540140 65 chr1 10016 0 20M3D9M3D13M1I57M chr4 190122739 0 CCCTAACCCTAACCACAAC",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333567016:1587,down,down,1587,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333567016,1,['down'],['down']
Availability,"330180 59330708 target_189885_IL9R NaN; Y 59333828 59334429 target_189886_IL9R NaN; Y 59335302 59335904 target_189887_IL9R NaN; Y 59335905 59336289 target_189888_IL9R NaN; Y 59336290 59336776 target_189889_IL9R NaN; Y 59336840 59337486 target_189890_IL9R NaN; Y 59337698 59338400 target_189891_IL9R NaN; Y 59338503 59339109 target_189892_IL9R NaN; Y 59339943 59340528 target_189893_IL9R NaN; Y 59342236 59343330 target_189894_IL9R NaN. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242767764). @davidbenjamin could you please take a look? it sounds like it could be a problem with the reference missing these regions. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242774747). OK it turns out that the reference is hard masked and has ""N"" in that region. Nevertheless, we shouldn't get NaNs. In my opinion, the correct behavior is to drop targets on which GC percentage can not be defined + emit informative error messages. ---. @davidbenjamin commented on [Sun Sep 11 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-246177779). I will address this. ---. @mbabadi commented on [Tue Sep 27 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-250018497). @davidbenjamin also, CorrectGCBias produces NaNs when a sample has very low coverage. I think the correct behavior is this:. (1) when annotating targets, it is OK to produce NaNs on targets whose GC bias can not be determined. When correcting for GC bias, those targets must be removed altogether. (2) if the bias curve can not be determined (let's say because of low coverage), the tool should remove that sample from the collection and emit appropriate warning messages. If all samples are removed, the tool should produce a bad input error. ---. @mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/6",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2882:3996,error,error,3996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2882,1,['error'],['error']
Availability,34 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:4169,ERROR,ERROR,4169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,36 > 47638 expanding to 95278; 11:40:02.830 DEBUG Mutect2 - Processing assembly region at chrM:8830-9129 isActive: true numReads: 296990; 11:41:56.997 DEBUG ReadThreadingGraph - Recovered 7 of 8 dangling tails; 11:41:57.047 DEBUG ReadThreadingGraph - Recovered 2 of 24 dangling heads; 11:41:57.286 DEBUG IntToDoubleFunctionCache - cache miss 136737 > 53234 expanding to 136747; 11:41:57.301 DEBUG IntToDoubleFunctionCache - cache miss 136976 > 136747 expanding to 273496; 11:41:57.935 DEBUG Mutect2Engine - Active Region chrM:8830-9129; 11:41:57.937 DEBUG Mutect2Engine - Extended Act Region chrM:8730-9229; 11:41:57.939 DEBUG Mutect2Engine - Ref haplotype coords chrM:8730-9229; 11:41:57.940 DEBUG Mutect2Engine - Haplotype count 128; 11:41:57.941 DEBUG Mutect2Engine - Kmer sizes count 0; 11:41:57.942 DEBUG Mutect2Engine - Kmer sizes values []; 11:53:42.116 DEBUG Mutect2 - Processing assembly region at chrM:9130-9143 isActive: true numReads: 148251; 11:53:58.336 DEBUG ReadThreadingGraph - Recovered 4 of 9 dangling tails; 11:53:58.398 DEBUG ReadThreadingGraph - Recovered 0 of 20 dangling heads; 11:54:11.645 DEBUG ReadThreadingGraph - Recovered 20 of 23 dangling tails; 11:54:11.670 DEBUG ReadThreadingGraph - Recovered 0 of 60 dangling heads; 11:54:11.843 DEBUG Mutect2Engine - Active Region chrM:9130-9143; 11:54:11.852 DEBUG Mutect2Engine - Extended Act Region chrM:9030-9243; 11:54:11.861 DEBUG Mutect2Engine - Ref haplotype coords chrM:9030-9243; 11:54:11.870 DEBUG Mutect2Engine - Haplotype count 232; 11:54:11.879 DEBUG Mutect2Engine - Kmer sizes count 0; 11:54:11.889 DEBUG Mutect2Engine - Kmer sizes values []; 11:54:21.878 DEBUG IntToDoubleFunctionCache - cache miss 96632 > 95278 expanding to 190558; 11:54:22.252 DEBUG Mutect2 - Processing assembly region at chrM:9144-9301 isActive: false numReads: 273760; 11:54:28.421 DEBUG Mutect2 - Processing assembly region at chrM:9302-9584 isActive: true numReads: 250870; 11:55:47.246 DEBUG ReadThreadingGraph - Recovered 13 of 14 dangling,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:16272,Recover,Recovered,16272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"362); 	at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopDataset(PairRDDFunctions.scala:1084); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply$mcV$sp(PairRDDFunctions.scala:1003); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply(PairRDDFunctions.scala:994); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2.apply(PairRDDFunctions.scala:994); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopFile(PairRDDFunctions.scala:994); 	at org.apache.spark.api.java.JavaPairRDD.saveAsNewAPIHadoopFile(JavaPairRDD.scala:823); 	at org.disq_bio.disq.impl.formats.sam.AnySamSinkMultiple.save(AnySamSinkMultiple.java:96); 	at org.disq_bio.disq.HtsjdkReadsRddStorage.write(HtsjdkReadsRddStorage.java:206); 	at org.broadinstitute.hellbender.engine.sp...; ```. heres the command line; bamIn=gs://broad-gatk-test-jenkins-robust/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam; refIn=gs://broad-gatk-test-jenkins-robust/human_g1k_v37.fasta; bamOut=gs://broad-gatk-test-jenkins-write-robust/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam.md.bqsr; knownIn=gs://broad-gatk-test-jenkins-robust/dbsnp_138.b37.excluding_sites_after_129.vcf; vcfOut=gs://broad-gatk-test-jenkins-write-robust/CEUTrio.HiSeq.WEx.b37.NA12892.vcf; ./gatk ReadsPipelineSpark \; -I $bamIn \; -R $refIn \; --output-bam $bamOut \; -O $vcfOut \; --known-sites $knownIn \; --sharded-output true \; --emit-original-quals \; --duplicate-scoring-strategy SUM_OF_BASE_QUALITIES \; --num-reducers 0 \; -- \; --spark-runner GCS \; --cluster $CLUSTERNAME \; --driver-memory 8G \; --conf 'spark.yarn.executor.memoryOverhead=2000' \; --executor-memory 18g \; --executor-cores 6 \; --conf spark.yarn.executor.memoryOverhead=2000""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:12902,robust,robust,12902,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,5,['robust'],['robust']
Availability,"37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz; 14:58:11.090 INFO FeatureManager - Using codec VCFCodec to read file file://~/projects/test2/temp/vatiant_germline/sites.only.vcf.gz; 14:58:11.139 INFO VariantRecalibrator - Done initializing engine; 14:58:11.142 INFO TrainingSet - Found mills track: Known = false Training = true Truth = true Prior = Q12.0; 14:58:11.142 INFO TrainingSet - Found dbsnp track: Known = true Training = false Truth = false Prior = Q2.0; 14:58:11.142 INFO TrainingSet - Found axiomPoly track: Known = false Training = true Truth = false Prior = Q10.0; 14:58:11.167 INFO ProgressMeter - Starting traversal; 14:58:11.168 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:58:21.182 INFO ProgressMeter - 2:23974966 0.2 22000 131828.6; 14:58:31.703 INFO ProgressMeter - 3:171904490 0.3 46000 134404.7; 14:58:41.753 INFO ProgressMeter - 6:18264210 0.5 67000 131441.3; 14:58:42.144 INFO VariantRecalibrator - Shutting down engine; [November 12, 2020 2:58:42 PM CST] org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=29244260352; java.lang.IllegalStateException: The provided reference alleles do not appear to represent the same position, AC* vs. AA*; at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.determineReferenceAllele(GATKVariantContextUtils.java:209); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.isAlleleInList(GATKVariantContextUtils.java:164); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantDataManager.doAllelesMatch(VariantDataManager.java:424); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantDataManager.parseTrainingSets(VariantDataManager.java:399); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.addDatum(VariantRecalibrator.java:614); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.addVariantDatum(VariantRe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963:6303,down,down,6303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963,1,['down'],['down']
Availability,"37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz; 14:58:11.090 INFO FeatureManager - Using codec VCFCodec to read file file://~/projects/test2/temp/vatiant_germline/sites.only.vcf.gz; 14:58:11.139 INFO VariantRecalibrator - Done initializing engine; 14:58:11.142 INFO TrainingSet - Found mills track: Known = false Training = true Truth = true Prior = Q12.0; 14:58:11.142 INFO TrainingSet - Found dbsnp track: Known = true Training = false Truth = false Prior = Q2.0; 14:58:11.142 INFO TrainingSet - Found axiomPoly track: Known = false Training = true Truth = false Prior = Q10.0; 14:58:11.167 INFO ProgressMeter - Starting traversal; 14:58:11.168 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:58:21.182 INFO ProgressMeter - 2:23974966 0.2 22000 131828.6; 14:58:31.703 INFO ProgressMeter - 3:171904490 0.3 46000 134404.7; 14:58:41.753 INFO ProgressMeter - 6:18264210 0.5 67000 131441.3; 14:58:42.144 INFO VariantRecalibrator - Shutting down engine; [November 12, 2020 2:58:42 PM CST] org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=29244260352; java.lang.IllegalStateException: The provided reference alleles do not appear to represent the same position, AC* vs. AA*; at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.determineReferenceAllele(GATKVariantContextUtils.java:209); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.isAlleleInList(GATKVariantContextUtils.java:164); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantDataManager.doAllelesMatch(VariantDataManager.java:424); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantDataManager.parseTrainingSets(VariantDataManager.java:399); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.addDatum(VariantRecalibrator.java:614); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.addVariantDatum(VariantRe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532:4955,down,down,4955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532,1,['down'],['down']
Availability,"37: 3%|3 | 3/100 [00:00<00:26, 3.71it/s]; 15:10:06.307 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0016 +/- 0.0036: 4%|4 | 4/100 [00:01<00:25, 3.72it/s]; 15:10:06.575 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0018 +/- 0.0019: 5%|5 | 5/100 [00:01<00:25, 3.72it/s]; 15:10:06.844 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0013 +/- 0.0014: 6%|6 | 6/100 [00:01<00:25, 3.72it/s]; 15:10:07.113 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0014 +/- 0.0019: 7%|7 | 7/100 [00:01<00:24, 3.72it/s]; 15:10:07.381 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0011 +/- 0.0011: 8%|8 | 8/100 [00:02<00:24, 3.72it/s]; 15:10:07.649 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0008 +/- 0.0009: 10%|# | 10/100 [00:02<00:24, 3.72it/s]; 15:10:08.193 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0006: 11%|#1 | 11/100 [00:02<00:24, 3.70it/s]; 15:10:08.463 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0005 +/- 0.0007: 12%|#2 | 12/100 [00:03<00:23, 3.70it/s]; 15:10:08.732 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0007: 13%|#3 | 13/100 [00:03<00:23, 3.70it/s]; 15:10:09.001 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0004 +/- 0.0005: 13%|#3 | 13/100 [00:03<00:25, 3.45it/s]; 15:10:09.002 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1): 0%| | 0/1 [00:00<?, ?it/s]; 15:10:09.003 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1) ploidy update size: 0.200122: 100%|##########| 1/1 [00:00<00:00, 1605.78it/s]; 15:10:09.004 INFO gcnvkernel.tasks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:12303,error,error,12303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['error'],['error']
Availability,"38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:32037,failure,failure,32037,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['failure'],['failure']
Availability,"3:13:14.515 INFO PostprocessGermlineCNVCalls - Analyzing shard 43 / 45...; 03:13:14.652 INFO PostprocessGermlineCNVCalls - Analyzing shard 44 / 45...; 03:13:14.843 INFO PostprocessGermlineCNVCalls - Analyzing shard 45 / 45...; 03:13:15.144 INFO PostprocessGermlineCNVCalls - Generating segments...; 03:14:44.578 INFO PostprocessGermlineCNVCalls - Parsing Python output...; 03:14:44.593 INFO PostprocessGermlineCNVCalls - Writing segments VCF file to /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/output/R18002110LU01-XG3351_combined_segment_cohort.vcf...; 03:14:46.272 INFO PostprocessGermlineCNVCalls - Generating denoised copy ratios...; 03:14:47.231 INFO PostprocessGermlineCNVCalls - Writing denoised copy ratios to /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/output/R18002110LU01-XG3351_combined_ratio.txt...; 03:14:58.266 INFO PostprocessGermlineCNVCalls - PostprocessGermlineCNVCalls complete.; 03:14:58.268 INFO PostprocessGermlineCNVCalls - Shutting down engine; [April 15, 2024, 3:14:58AM CST] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 2.32 minutes.; Runtime.totalMemory()=1207959552; Using GATK jar /data/xiangxd/project/software/callers/gatk_4.4/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /data/xiangxd/project/software/callers/gatk_4.4/gatk-package-4.4.0.0-local.jar PostprocessGermlineCNVCalls --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_1-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_2-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_3-model --model-shard-path /data/xiangxd/project/test/PD_WES_50/cnv_calling/GATK_gCNV/infos/cohort_all/cohort_4-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:7615,down,down,7615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,1,['down'],['down']
Availability,"4 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-05-19 19:09:41 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-05-19 19:09:41 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-05-19 19:09:41 INFO MemoryStore:54 - MemoryStore cleared; 2019-05-19 19:09:41 INFO BlockManager:54 - BlockManager stopped; 2019-05-19 19:09:41 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-05-19 19:09:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-05-19 19:09:41 INFO SparkContext:54 - Successfully stopped SparkContext; 19:09:41.578 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 19, 2019 7:09:41 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 44.89 minutes.; Runtime.totalMemory()=21646802944; htsjdk.samtools.util.RuntimeIOException: Error opening file: file:///restricted/projectnb/casa/wgs.hg38/pipelines/sv/gatk.sv/temp/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.contig-sam-file.sam; at htsjdk.samtools.SAMFileWriterFactory.makeSAMWriter(SAMFileWriterFactory.java:356); at htsjdk.samtools.SAMFileWriterFactory.makeSAMOrBAMWriter(SAMFileWriterFactory.java:437); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVFileUtils.writeSAMFile(SVFileUtils.java:29); at org.broadinstitute.hellbender.tools.spark.sv.evidence.AlignedAssemblyOrExcuse.writeAssemblySAMFile(AlignedAssemblyOrExcuse.java:336); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.gatherEvidenceAndWriteContigSamFile(FindBreakpointEvidenceSpark.java:199); at org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark.runTool(StructuralVariationDiscoveryPipelineSpark.java:164); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); at org.broadinstitute.hellbender.eng",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590:4783,Error,Error,4783,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590,1,['Error'],['Error']
Availability,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:9901,down,down,9901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,6,['down'],['down']
Availability,"4 HelpFormatter - Copyright (c) 2010-2016 The Broad Institute ; INFO 10:47:54,224 HelpFormatter - For support and documentation go to https://software.broadinstitute.org/gatk ; INFO 10:47:54,225 HelpFormatter - [Tue Sep 08 10:47:54 WEST 2020] Executing on Mac OS X 10.15.6 x86_64 ; INFO 10:47:54,225 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17 ; INFO 10:47:54,229 HelpFormatter - Program Args: -T IndelRealigner -R /Users/mac/Desktop/NGS-/TriTrypDB-47_LmajorLV39c5_Genome.fasta -I /Users/mac/Desktop/NGS-/marked_duplicates42-pe.bam -targetIntervals /Users/mac/Desktop/NGS-/42-pe-realigner.intervals -o /Users/mac/Desktop/NGS-/42-pe-idelsrealigner.bam ; INFO 10:47:54,492 HelpFormatter - Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ----------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:1783,ERROR,ERROR,1783,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['ERROR'],['ERROR']
Availability,"4 INFO BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 00:11:11.814 INFO BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 00:11:11.814 INFO BaseRecalibrator - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 00:11:11.814 INFO BaseRecalibrator - Deflater: JdkDeflater ; ; 00:11:11.815 INFO BaseRecalibrator - Inflater: JdkInflater ; ; 00:11:11.815 INFO BaseRecalibrator - GCS max retries/reopens: 20 ; ; 00:11:11.815 INFO BaseRecalibrator - Requester pays: disabled ; ; 00:11:11.815 INFO BaseRecalibrator - Initializing engine ; ; 00:11:12.005 WARN IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:11:12.009 WARN IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:11:12.127 WARN IntelInflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater ; ; 00:11:12.134 INFO BaseRecalibrator - Shutting down engine ; ; \[August 21, 2022 at 12:11:12 AM CST\] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.01 minutes. ; ; Runtime.totalMemory()=285212672 ; ; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec ; ;   at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:535) ; ;   at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:482) ; ;   at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:397) ; ;   at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:373) ; ;   at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:319) ; ;   at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:291) ; ;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8005:11942,down,down,11942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8005,1,['down'],['down']
Availability,"4 MLEAF.tdb; -rwx------ 1 hcaoad boip 80M Apr 20 13:34 MLEAF_var.tdb; -rwx------ 1 hcaoad boip 236M Apr 20 13:34 MQRankSum.tdb; -rwx------ 1 hcaoad boip 204M Apr 20 13:34 PGT.tdb; -rwx------ 1 hcaoad boip 6.8M Apr 20 13:34 PGT_var.tdb; -rwx------ 1 hcaoad boip 208M Apr 20 13:34 PID.tdb; -rwx------ 1 hcaoad boip 15M Apr 20 13:34 PID_var.tdb; -rwx------ 1 hcaoad boip 315M Apr 20 13:34 PL.tdb; -rwx------ 1 hcaoad boip 14G Apr 20 13:34 PL_var.tdb; -rwx------ 1 hcaoad boip 173M Apr 20 13:34 PS.tdb; -rwx------ 1 hcaoad boip 496M Apr 20 13:34 QUAL.tdb; -rwx------ 1 hcaoad boip 412M Apr 20 13:34 RAW_MQandDP.tdb; -rwx------ 1 hcaoad boip 358M Apr 20 13:34 ReadPosRankSum.tdb; -rwx------ 1 hcaoad boip 254M Apr 20 13:34 REF.tdb; -rwx------ 1 hcaoad boip 1.5G Apr 20 13:34 REF_var.tdb; -rwx------ 1 hcaoad boip 278M Apr 20 13:34 Samples.tdb; -rwx------ 1 hcaoad boip 256M Apr 20 13:34 Samples_var.tdb; -rwx------ 1 hcaoad boip 510M Apr 20 13:34 SB.tdb; </pre>; Log file for chr1, no error reported:; <pre>Using GATK jar /home/hcaoad/miniconda2/share/gatk4-4.2.0.0-0/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx80G -Xms80G -jar /home/hcaoad/miniconda2/share/gatk4-4.2.0.0-0/gatk-package-4.2.0.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /scratch/PI/boip/Han/WGS/HK_WGS_5X/GenomicsDB//chr1 -L 1 --sample-name-map input/sample.map -R /scratch/PI/boip/Reference/Human_genome/GRCh37/hs37d5.fa --batch-size 400 --reader-threads 5; 14:48:08.923 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/hcaoad/miniconda2/share/gatk4-4.2.0.0-0/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 16, 2021 2:48:09 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:48:09.08",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7218:4170,error,error,4170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7218,1,['error'],['error']
Availability,4 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:2427,ERROR,ERROR,2427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"4 [addAssemblyQNames -> getKmerIntervals] mapPartitionsToPair, then reduceByKey, then mapPartitions; * Job 5 [getAssemblyQNames] mapPartitions twice and a collect; * Job 6 [generateFastqs] mapPartitions and combineByKey, then write FASTQ to files. A few observations:; * Jobs 0,1,3 are simple map jobs - very quick 1-2 mins each.; * Job 2 is a simple MR, with a tiny shuffle to sum by key (<1MB of shuffle data); * Job 4 takes a bit longer longer (3min), and shuffles ~3GB. This is a lot faster than when I ran it before with less memory, when it took 9 min. Is it creating a lot of garbage? If you wanted to speed things up you might look at what this is doing on a local machine and see if there are any opportunities to improve CPU efficiency.; * Job 5 takes ~8 mins, and has no shuffle. CPU intensive processing again?; * Job 6 take a little over 3 mins, shuffling ~3GB. Overall, it looks like its performing pretty well. There is very little data being shuffled relative to the size of the input (~6GB to 133GB input), so its not worth looking into optimizing the data structures there. The input data is being read multiple times, so it _might_ be worth seeing if it can be cached by Spark to avoid reading from disk over and over again. This is only worth it if you have sufficient memory available across the cluster to hold the input (which will be bigger than the on-disk size) _plus_ enough memory for the processing, which as we saw is quite memory hungry anyway. There might be some CPU efficiencies to pursue, especially if some code paths are creating a lot of objects that need garbage collecting (as Jobs 4 and 5 seem to be). Jobs 4 and 5 seem to have some skew (judging from the task time distribution in the UI). You might investigate this by logging the amount of data that each task processes (or rather than logging, generating another output that is some description of the task data - or use a Spark accumulator), and then seeing if there's some way to make it more uniform.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884:2696,avail,available,2696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884,2,['avail'],['available']
Availability,4.1 has the improved reporting on system errors. Not sure if it fixes this issue. Would it be possible to include new logs by running 4.1 if you encounter the issue again?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-460418712:41,error,errors,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-460418712,1,['error'],['errors']
Availability,4.4.0.0 compile: git lfs error transferring ; Failed to fetch some objects from 'file:///startdir/gatk',MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:25,error,error,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,1,['error'],['error']
Availability,4068.tsv /tmp/tintest/sample-3734484951576950052743.tsv /tmp/tintest/sample-3745007638909244994571.tsv /tmp/tintest/sample-3758817480300622528681.tsv /tmp/tintest/sample-3765561422653477541111.tsv /tmp/tintest/sample-377681127346074691924.tsv /tmp/tintest/sample-3788006936711929575536.tsv /tmp/tintest/sample-3794598448303416401276.tsv /tmp/tintest/sample-380910670101098136635.tsv /tmp/tintest/sample-3815864583095389374312.tsv /tmp/tintest/sample-3821063008346821202582.tsv /tmp/tintest/sample-3836550848258521825191.tsv /tmp/tintest/sample-3842488752532231097400.tsv /tmp/tintest/sample-3855124216409092357090.tsv /tmp/tintest/sample-3866989755460133829309.tsv ; Stdout: 10:58:52.820 INFO cohort_denoising_calling - Loading 387 read counts file(s)...; 11:01:01.618 INFO gcnvkernel.io.io_metadata - Loading germline contig ploidy and global read depth metadata...; 11:02:11.422 INFO gcnvkernel.tasks.task_cohort_denoising_calling - Instantiating the denoising model (warm-up)...; 11:04:53.672 ERROR theano.gof.cmodule - [Errno 12] Cannot allocate memory. Stderr: Problem occurred during compilation with the command line below:; /usr/bin/g++ -shared -g -O3 -fno-math-errno -Wno-unused-label -Wno-unused-variable -Wno-write-strings -fopenmp -march=knl -mmmx -mno-3dnow -msse -msse2 -msse3 -mssse3 -mno-sse4a -mcx16 -msahf -mmovbe -maes -mno-sha -mpclmul -mpopcnt -mabm -mno-lwp -mfma -mno-fma4 -mno-xop -mbmi -mbmi2 -mno-tbm -mavx -mavx2 -msse4.2 -msse4.1 -mlzcnt -mrtm -mhle -mrdrnd -mf16c -mfsgsbase -mrdseed -mprfchw -madx -mfxsr -mxsave -mxsaveopt -mavx512f -mno-avx512er -mavx512cd -mno-avx512pf -mno-prefetchwt1 -mclflushopt -mxsavec -mxsaves -mavx512dq -mavx512bw -mno-avx512vl -mno-avx512ifma -mno-avx512vbmi -mclwb -mno-mwaitx -mno-clzero -mpku --param l1-cache-size=32 --param l1-cache-line-size=64 --param l2-cache-size=22528 -mtune=generic -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m64 -fPIC -I/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/numpy/core/include -I/h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053:61691,ERROR,ERROR,61691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053,1,['ERROR'],['ERROR']
Availability,"41294Z location: class CountingVariantFilter; 2022-08-16T00:09:07.4054361Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4060164Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T00:09:07.4060614Z @VisibleForTesting; 2022-08-16T00:09:07.4061233Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4061591Z location: class ReadFilter; 2022-08-16T00:09:07.4083439Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4092135Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4107682Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4116317Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4117746Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4124264Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T00:09:07.4124816Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-08-16T00:09:07.4125855Z symbol: class BiMap; 2022-08-16T00:09:07.4126189Z location: class LoggingUtils; 2022-08-16T00:09:07.4126674Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:41: error: cannot find symbol; 2022-08-16T00:09:07.4127264Z private static BiMap<Log.LogLevel, java.util.logging.Level> javaUtilLevelNamespaceMap;; 2022-08-16T00:09:07.4127999Z symbol: class BiMap; 2",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:12582,error,error,12582,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/simple_uniprot_Dec012014.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 15:41:54.747 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xrefseq_v75_37.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:18885,error,errors,18885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['error'],['errors']
Availability,433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildEx,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:2033,ERROR,ERROR,2033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:2839,ERROR,ERROR,2839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"44139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	... 15 more; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.""; }; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:3667,error,errors,3667,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['error'],['errors']
Availability,"46 INFO CNNVariantWriteTensors - Picard Version: 3.0.0; 02:02:31.346 INFO CNNVariantWriteTensors - Built for Spark Version: 3.3.1; 02:02:31.346 INFO CNNVariantWriteTensors - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 02:02:31.346 INFO CNNVariantWriteTensors - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 02:02:31.346 INFO CNNVariantWriteTensors - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 02:02:31.347 INFO CNNVariantWriteTensors - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 02:02:31.347 INFO CNNVariantWriteTensors - Deflater: IntelDeflater; 02:02:31.347 INFO CNNVariantWriteTensors - Inflater: IntelInflater; 02:02:31.347 INFO CNNVariantWriteTensors - GCS max retries/reopens: 20; 02:02:31.347 INFO CNNVariantWriteTensors - Requester pays: disabled; 02:02:31.347 WARN CNNVariantWriteTensors - . !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CNNVariantWriteTensors is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 02:02:31.347 INFO CNNVariantWriteTensors - Initializing engine; 02:02:33.899 INFO CNNVariantWriteTensors - Done initializing engine; 02:02:33.899 INFO CNNVariantWriteTensors - Args are:[--reference_fasta, /data2/example/1/hg19.fa, --input_vcf, /data2/example/NA12877.vcf.gz, --bam_file, , --train_vcf, /data2/example/hg19.hybrid.vcf.gz, --bed_file, /data2/example/hg19.hybrid.bed, --tensor_name, reference, --annotation_set, best_practices, --samples, 1000000, --downsample_snps, 0.05, --downsample_indels, 0.5, --data_dir, /data2/example/results, --channels_last, --mode, write_reference_and_annotation_tensors]; 02:38:41.806 INFO CNNVariantWriteTensors - Shutting down engine; [August 30, 2023 at 2:38:41 AM GMT] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNVariantWriteTensors done. Elapsed time: 36.18 minutes.; Runtime.totalMemory()=285212672; Tool returned:; true. ####issue:; /data2/example/results is empty, and no file was generated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8506:3342,down,down,3342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8506,1,['down'],['down']
Availability,"463); - formatting on sample QC README; - formatting change #2 to sample QC README; - address VS-152, remove extra headers from extract (#7466); - Update GvsExtractCallset.example.inputs.json (#7469); - Add ability to copy interval list files to gs directory [VS-191] (#7467); - add an expiration date to the temp tables (#7455); - fix the check for duplicates in import genomes (#7470); - added job ID to alt_allele population call output [VS-194] (#7473); - added steps and deliverables to GVS README [VS-181] (#7452); - Ah check the is loaded field in feature extract (#7475); - changes to put pet data directly into data table (#7478); - added override for ExtractTasks' preemptible value (#7477); - bcftools to the rescue (#7456); - execute_with_retry() refactor and error handling improvements [VS-159] (#7480); - Small updates to GvsExtractCallset from beta callset, new workflow for re-scattered shards (#7493); - add flag in prepare to print out sql instead of executing (#7501); - Workflow to re-scatter and then merge ""problematic"" intervals from ExtractCallset [VS-209] (#7495); - changed README to reflect comments from Lee [VS-210] (#7502); - Export the VAT into GCS (#7472); - addresses VS-219 (#7508); - small fix to MergeVCFs (#7517); - small fixes to GVS pipeline (#7522); - make sure ExtractTask is run on all interval files; - Revert ""make sure ExtractTask is run on all interval files""; - make sure ExtractTask is run on all interval files (#7527); - Remove Sites only step from the VAT creation WDL (#7510); - fix bad argument processing for bool (#7529); - Support for TDR DRS URIs in Import (#7528); - Match format of filename output in GvsRescatterCallsetInterval (#7539); - Reference block storage and query support (#7498); - update docs (#7540); - Kc fix rr load bug (#7550); - Update .dockstore.yml (#7553); - Ah add reblocking wdl (#7544); - Scatter over all interval files, not just scatter count (#7551); - fixed docker (#7558); - take advantage of fixed version of Spl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:19018,error,error,19018,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['error'],['error']
Availability,"46:05.153 INFO CNNScoreVariants - Inflater: IntelInflater; 10:46:05.153 INFO CNNScoreVariants - GCS max retries/reopens: 20; 10:46:05.153 INFO CNNScoreVariants - Requester pays: disabled; 10:46:05.153 INFO CNNScoreVariants - Initializing engine; 10:46:05.598 INFO FeatureManager - Using codec VCFCodec to read file file:///lustre/scratch/scratch/regmova/tmp/TEST_DATA/TR017_GERMLINE_VARIANTS/TR017.GL.vcf.gz; 10:46:05.638 INFO CNNScoreVariants - Done initializing engine; 10:46:05.639 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/lustre/home/regmova/tools/gatk/build/libs/gatk-package-4.2.0.0-19-ge60cdf8-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_utils.so; 10:46:35.436 INFO CNNScoreVariants - Using key:CNN_1D for CNN architecture:/tmp/1d_cnn_mix_train_full_bn.8208762367402959162.json and weights:/tmp/1d_cnn_mix_train_full_bn.2787226329292768726.hd5; 10:46:35.438 INFO CNNScoreVariants - Done scoring variants with CNN.; 10:46:35.438 INFO CNNScoreVariants - Shutting down engine; [12 May 2021 10:46:35 BST] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.51 minutes.; Runtime.totalMemory()=2132279296; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: A nack was received from the Python process (most likely caused by a raised exception caused by): nkm received. ```; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/regmova/miniconda3/envs/gatk/lib/python3.6/site-packages/vqsr_cnn/vqsr_cnn/models.py"", line 22, in start_session_get_args_and_model; K.clear_session(). AttributeError: module 'keras.backend' has no attribute 'clear_session'; 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.waitForAck(StreamingPythonScriptExecutor.java:222); 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.sendSynchronousCommand(StreamingPythonScriptExecutor.java:183); at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNSco",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250:3551,down,down,3551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250,1,['down'],['down']
Availability,"49: 2%|2 | 2/100 [00:00<00:26, 3.69it/s]; 15:10:06.039 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0023 +/- 0.0037: 3%|3 | 3/100 [00:00<00:26, 3.71it/s]; 15:10:06.307 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0016 +/- 0.0036: 4%|4 | 4/100 [00:01<00:25, 3.72it/s]; 15:10:06.575 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0018 +/- 0.0019: 5%|5 | 5/100 [00:01<00:25, 3.72it/s]; 15:10:06.844 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0013 +/- 0.0014: 6%|6 | 6/100 [00:01<00:25, 3.72it/s]; 15:10:07.113 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0014 +/- 0.0019: 7%|7 | 7/100 [00:01<00:24, 3.72it/s]; 15:10:07.381 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0011 +/- 0.0011: 8%|8 | 8/100 [00:02<00:24, 3.72it/s]; 15:10:07.649 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0008 +/- 0.0009: 10%|# | 10/100 [00:02<00:24, 3.72it/s]; 15:10:08.193 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0006: 11%|#1 | 11/100 [00:02<00:24, 3.70it/s]; 15:10:08.463 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0005 +/- 0.0007: 12%|#2 | 12/100 [00:03<00:23, 3.70it/s]; 15:10:08.732 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0007: 13%|#3 | 13/100 [00:03<00:23, 3.70it/s]; 15:10:09.001 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0004 +/- 0.0005: 13%|#3 | 13/100 [00:03<00:25, 3.45it/s]; 15:10:09.002 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1): 0%| | 0/1 [00:00<?, ?it/s]; 15:10:09.003 INFO gcnvkernel.tasks.inference_t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:12154,error,error,12154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['error'],['error']
Availability,4:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:4348,ERROR,ERROR,4348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"4\_transcriptExon, Gencode\_34\_transcriptPos, Gencode\_34\_cDnaChange, Gencode\_34\_codonChange, Gencode\_34\_proteinChange, Gencode\_34\_gcContent, Gencode\_34\_referenceContext, Gencode\_34\_otherTranscripts, ACMGLMMLof\_LOF\_Mechanism, ACMGLMMLof\_Mode\_of\_Inheritance, ACMGLMMLof\_Notes, ACMG\_recommendation\_Disease\_Name, ClinVar\_VCF\_AF\_ESP, ClinVar\_VCF\_AF\_EXAC, ClinVar\_VCF\_AF\_TGP, ClinVar\_VCF\_ALLELEID, ClinVar\_VCF\_CLNDISDB, ClinVar\_VCF\_CLNDISDBINCL, ClinVar\_VCF\_CLNDN, ClinVar\_VCF\_CLNDNINCL, ClinVar\_VCF\_CLNHGVS, ClinVar\_VCF\_CLNREVSTAT, ClinVar\_VCF\_CLNSIG, ClinVar\_VCF\_CLNSIGCONF, ClinVar\_VCF\_CLNSIGINCL, ClinVar\_VCF\_CLNVC, ClinVar\_VCF\_CLNVCSO, ClinVar\_VCF\_CLNVI, ClinVar\_VCF\_DBVARID, ClinVar\_VCF\_GENEINFO, ClinVar\_VCF\_MC, ClinVar\_VCF\_ORIGIN, ClinVar\_VCF\_RS, ClinVar\_VCF\_SSR, ClinVar\_VCF\_ID, ClinVar\_VCF\_FILTER, LMMKnown\_LMM\_FLAGGED, LMMKnown\_ID, LMMKnown\_FILTER ; ; 02:00:35.778 ERROR FuncotationMap - Values: , , , , , , , , , , , , , , , , , , , , , , , , , , , , false, , ; ; 02:00:35.793 INFO FilterFuncotations - Shutting down engine ; ; \[April 25, 2022 at 2:00:35 AM EDT\] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 0.03 minutes. ; ; Runtime.totalMemory()=319815680 ; ; org.broadinstitute.hellbender.exceptions.GATKException$ShouldNeverReachHereException: Cannot parse the funcotation attribute. Num values: 31  Num keys: 53 ; ;   at org.broadinstitute.hellbender.tools.funcotator.FuncotationMap.createAsAllTableFuncotationsFromVcf(FuncotationMap.java:224) ; ;   at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.lambda$createAlleleToFuncotationMapFromFuncotationVcfAttribute$5(FuncotatorUtils.java:2256) ; ;   at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:178) ; ;   at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ;   at java.base/java.util.stream.IntPipeline$1$1.accept(I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7865:6525,ERROR,ERROR,6525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7865,1,['ERROR'],['ERROR']
Availability,5 <0> (+2)` | :arrow_up: |; | [...nder/tools/funcotator/FuncotatorTestConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JUZXN0Q29uc3RhbnRzLmphdmE=) | `98.361% <100%> (+0.027%)` | `1 <0> ()` | :arrow_down: |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5860#issuecomment-480044442:2542,down,downsampling,2542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5860#issuecomment-480044442,1,['down'],['downsampling']
Availability,"5); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2000); 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:7962,down,down,7962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['down'],['down']
Availability,"5); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:79); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; #### Steps to reproduce; `gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz`. The cram is HG0096.final.cram found here:. https://www.internationalgenome.org/data-portal/data-collection/30x-grch38. #### Expected behavior; When I run an earlier version v4.1.7.0, it runs without an error.... ```; gatk HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar HaplotypeCaller -L chr22 -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -I cram/HG00096.final.cram -O test.g.vcf.gz; 14:40:45.497 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 10, 2021 2:40:45 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076:5279,error,error,5279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076,1,['error'],['error']
Availability,"5-g27b5190-SNAPSHOT; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4666,ERROR,ERROR,4666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['ERROR'],['ERROR']
Availability,"5.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Tue Jun 16 23:25:05 CDT 2020] Executing as xxxx on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; [Tue Jun 16 23:25:05 CDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=605028352; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to create BasicFeatureReader using feature file , for input source: file:///tmp/test%20a/data/calling/a.vcf.gz; at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:124); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:81); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:148); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:98); at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:174); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664:2350,avail,available,2350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664,1,['avail'],['available']
Availability,"5.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Deflater: IntelDeflater; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Inflater: IntelInflater; 13:15:05.204 INFO FuncotatorDataSourceDownloader - GCS max retries/reopens: 20; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Requester pays: disabled; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Initializing engine; 13:15:05.205 INFO FuncotatorDataSourceDownloader - Done initializing engine; 13:15:05.205 INFO FuncotatorDataSourceDownloader - Germline data sources selected.; 13:15:05.207 INFO FuncotatorDataSourceDownloader - Collecting expected checksum...; 13:19:33.264 INFO FuncotatorDataSourceDownloader - Shutting down engine; [November 18, 2023 1:19:33 PM CST] org.broadinstitute.hellbender.tools.funcotator.FuncotatorDataSourceDownloader done. Elapsed time: 4.48 minutes.; Runtime.totalMemory()=1967128576; code: 0; message: All 3 retries failed. Waited a total of 14000 ms between attempts; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: All 3 retries failed. Waited a total of 14000 ms between attempts; 	at com.google.cloud.storage.contrib.nio.CloudStorageRetryHandler.handleRetryForStorageException(CloudStorageRetryHandler.java:135); 	at com.google.cloud.storage.contrib.nio.CloudStorageRetryHandler.handleStorageException(CloudStorageRetryHandler.java:115); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:253); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:110); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageRead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:2673,down,down,2673,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['down'],['down']
Availability,5.741 DEBUG IntToDoubleFunctionCache - cache miss 26873 > 26616 expanding to 53234; 11:36:56.119 DEBUG Mutect2Engine - Active Region chrM:6354-6629; 11:36:56.119 DEBUG Mutect2Engine - Extended Act Region chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Ref haplotype coords chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Haplotype count 128; 11:36:56.119 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:56.120 DEBUG Mutect2Engine - Kmer sizes values []; 11:39:06.762 DEBUG Mutect2 - Processing assembly region at chrM:6630-6929 isActive: false numReads: 30053; 11:39:07.547 DEBUG Mutect2 - Processing assembly region at chrM:6930-7229 isActive: false numReads: 0; 11:39:07.574 DEBUG Mutect2 - Processing assembly region at chrM:7230-7493 isActive: false numReads: 359; 11:39:07.584 DEBUG Mutect2 - Processing assembly region at chrM:7494-7771 isActive: true numReads: 718; 11:39:07.668 DEBUG ReadThreadingGraph - Recovered 32 of 33 dangling tails; 11:39:07.713 DEBUG ReadThreadingGraph - Recovered 31 of 50 dangling heads; 11:39:07.996 DEBUG Mutect2Engine - Active Region chrM:7494-7771; 11:39:07.998 DEBUG Mutect2Engine - Extended Act Region chrM:7394-7871; 11:39:07.999 DEBUG Mutect2Engine - Ref haplotype coords chrM:7394-7871; 11:39:08.000 DEBUG Mutect2Engine - Haplotype count 128; 11:39:08.001 DEBUG Mutect2Engine - Kmer sizes count 0; 11:39:08.002 DEBUG Mutect2Engine - Kmer sizes values []; 11:39:12.623 DEBUG Mutect2 - Processing assembly region at chrM:7772-8071 isActive: false numReads: 359; 11:39:12.636 INFO ProgressMeter - chrM:7772 3.5 30 8.5; 11:39:12.638 DEBUG Mutect2 - Processing assembly region at chrM:8072-8371 isActive: false numReads: 0; 11:39:27.522 DEBUG IntToDoubleFunctionCache - cache miss 9173 > 5354 expanding to 10710; 11:39:31.241 DEBUG Mutect2 - Processing assembly region at chrM:8372-8671 isActive: false numReads: 0; 11:39:43.892 DEBUG Mutect2 - Processing assembly region at chrM:8672-8829 isActive: false numReads: 148658; 11:39:47.277 DEBUG IntToDoubleFu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:14242,Recover,Recovered,14242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"503 (Service Unavailable) errors are transient and should be retried. Saw this today running GenomicsDBImport. `htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: 503 Service Unavailable; Service Unavailable, for input source: gs://fc-4c1c7765-2de2-4214-ac41-dc10bbcbb55b/1e300bb3-6990-4342-8959-118826efb3dd/PairedEndSingleSampleWorkflow/d0aac891-4d32-43b9-8adb-edb6b5204af9/call-GatherVCFs/S76-1-2.g.vcf.gz; 	at htsjdk.tribble.TabixFeatureReader.readHeader(TabixFeatureReader.java:102); 	at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:86); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:106); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getReaderFromVCFUri(GenomicsDBImport.java:443); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getFeatureReaders(GenomicsDBImport.java:425); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:349); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:747); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:174); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:193); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadinstitute.hellbender.Main.main(Main.java:220); Caused by: com.google.cloud.storage.StorageException: 503 Service Unavailable; Service Unavailable; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:186); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:332); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:186); 	at com.google.cloud.storage.Storage",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2749:26,error,errors,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2749,2,['error'],"['error', 'errors']"
Availability,"51Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002731707Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 2019-10-29T18:18:04.002745164Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 2019-10-29T18:18:04.002777218Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 2019-10-29T18:18:04.002785268Z 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 2019-10-29T18:18:04.002855927Z 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 2019-10-29T18:18:04.002867030Z 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```; I am using ExAC lifted to hg38 as a germline resource in mutect2 with only a tumor sample, and getting the above error in filtermutectcalls. I recently updated to v4.1.3.0 to have the latest changes to mutect2. I was not having this issue with v4.0.5.1. Here is extracted information from the VCF which caused the issue. . ```; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=6;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=16;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,34;MFRL=0,272;MMQ=60,30;MPOS=25;MQ=30.00;POPAF=4.13;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,32;MFRL=0,272;MMQ=60,30;MPOS=15;MQ=30.00;POPAF=4.23;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:5279,error,error,5279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['error'],['error']
Availability,"51Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002731707Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 2019-10-29T18:18:04.002745164Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 2019-10-29T18:18:04.002777218Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 2019-10-29T18:18:04.002785268Z 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 2019-10-29T18:18:04.002855927Z 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 2019-10-29T18:18:04.002867030Z 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```; I am using ExAC lifted to hg38 as a germline resource in mutect2 with only a tumor sample, and getting the above error in filtermutectcalls. I recently updated to v4.1.3.0 to have the latest changes to mutect2. I was not having this issue with v4.0.5.1. Here is extracted information from the VCF which caused the issue. . ```; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=6;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=16;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,34;MFRL=0,272;MMQ=60,30;MPOS=25;MQ=30.00;POPAF=4.13;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,32;MFRL=0,272;MMQ=60,30;MPOS=15;MQ=30.00;POPAF=4.23;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; `",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:5279,error,error,5279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['error'],['error']
Availability,"53.7776218Z symbol: class RangeMap; 2022-08-16T22:45:53.7776715Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7777389Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7778220Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7779110Z symbol: class Range; 2022-08-16T22:45:53.7779574Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7780209Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T22:45:53.7780965Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T22:45:53.7781896Z symbol: class Range; 2022-08-16T22:45:53.7782232Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7785096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7789228Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7798240Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7810436Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7857595Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/SeqGraph.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.7861943Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseGraph.java:3: error: package com.google.common.collect does not exist; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:9371,error,error,9371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"54,138,143,148,154,159,166,172,180,188,197,208,220,234,251,274,306,359,854,143,148,154,159,166,172,180,188,197,208,220,234,251,274,306,359,854,148,154,159,166,172,180,188,197,208,220,234,251,274,306,359,854,154,159,166,172,180,188,197,208,220,234,251,274,306,359,854,159,166,172,180,188,197,208,220,234,251,274,306,359,854,166,173,180,188,197,208,220,234,251,274,306,359,854,173,180,188,197,208,220,234,251,274,306,359,854,180,188,197,208,220,234,251,274,306,359,854,188,197,208,220,234,251,274,306,359,854,197,208,220,234,251,274,306,359,854,208,220,234,251,274,306,359,854,220,234,251,274,306,359,854,234,252,274,306,359,854,252,274,306,359,854,274,306,359,854,306,359,854,360,854,854:9,9,0,0. for samples --variant $path_calls/H1_1.spark.g.vcf.gz and --variant $path_calls/H1_2.spark.g.vcf.gz tis variant is unpresent. the whole analysis is against Arabidopsis thaliana reference ftp://ftp.ensemblgenomes.org/pub/plants/release-47/fasta/arabidopsis_thaliana/dna/. i think that could be a same error within next call too; 1	560578	.	A	AAAAG,<NON_REF>	768.01	.	BaseQRankSum=0.297;DP=22;MLEAC=50,0;MLEAF=0.500,0.00;MQRankSum=0.000;RAW_MQandDP=79200,22;ReadPosRankSum=-0.232	GT:AD:DP:GQ:PL:SB	0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1:5,14,0:19:0:516,232,190,166,149,135,125,115,108,101,95,89,84,79,75,71,67,64,61,58,55,52,50,47,45,43,41,39,37,35,33,32,30,28,27,26,24,23,22,20,19,18,17,16,15,14,13,12,11,10,10,9,8,7,7,6,5,5,4,4,3,3,2,2,2,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,2,2,3,4,4,5,6,7,9,11,12,15,17,21,25,30,39,53,233,516,232,190,166,149,136,125,116,108,101,95,89,84,80,75,71,68,64,61,58,55,53,50,48,45,43,41,39,37,35,34,32,30,29,27,26,24,23,22,21,20,18,17,16,15,14,13,12,12,11,10,9,9,8,7,7,6,5,5,4,4,3,3,3,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,2,2,3,3,4,4,5,6,7,8,10,11,13,15,18,21,26,31,39,54,234,517,232,191,166,149,136,125,116,108,101,95,89,84,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-677396205:38299,error,error,38299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-677396205,1,['error'],['error']
Availability,54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Transformers$4.transform(Transformers.java:169); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:2633,ERROR,ERROR,2633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['ERROR'],['ERROR']
Availability,"55 INFO server.Server: Started @25495ms; 18/01/09 18:30:55 INFO server.AbstractConnector: Started ServerConnector@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@418f0534{/jobs,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@134a8ead{/jobs/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54247647{/jobs/job,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5463f035{/jobs/job/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44fd7ba4{/stages,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baac4a7{/storage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:7814,AVAIL,AVAILABLE,7814,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"55.067 INFO Funcotator - Picard Version: 2.17.2; 22:56:55.067 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 22:56:55.067 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:56:55.068 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:56:55.068 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:56:55.068 INFO Funcotator - Deflater: IntelDeflater; 22:56:55.068 INFO Funcotator - Inflater: IntelInflater; 22:56:55.068 INFO Funcotator - GCS max retries/reopens: 20; 22:56:55.068 INFO Funcotator - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 22:56:55.068 INFO Funcotator - Initializing engine; 22:56:56.227 INFO FeatureManager - Using codec VCFCodec to read file file:///omics/chatchawit/sm/out/sample21.vcf; 22:56:56.402 INFO Funcotator - Done initializing engine; 22:56:56.425 INFO Funcotator - Shutting down engine; [April 27, 2018 10:56:56 PM ICT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2276982784; java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.closeTool(Funcotator.java:330); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:897); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275). Next, I tried only ""gencode"" in the data-source folder. Using GATK jar /omics/chatchawit/gatk/gatk-package-4.0.0.0-local",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157:2791,down,down,2791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157,1,['down'],['down']
Availability,"559423		8560126; chr3	64547471	64549936; chr3	90414457	90415989; ````. I tried the following, running `ModelSegments` using fairly sensitive parameters (`--number-of-changepoints-penalty-factor 0.1 --maximum-number-of-segments-per-chromosome 10000 --window-size 16 --window-size 32 --maximum-number-of-smoothing-iterations 0` in copy-ratio-only mode:. 1) CollectFragmentCounts. This only recovered event 2.; 2) CollectReadCounts - same as CollectFragmentCounts, but removing the properly-paired and first-of-pair filters and adding a count for each read to the bin containing its start. This recovered all 3 events.; 3) CollectFragmentOverlaps - same filters as CollectFragmentCounts, but adding counts to all bins overlapping each fragment. Note that we need to implement a filter on maximum fragment length, otherwise we get some strange artifacts from (incorrectly mapped?) extremely long fragments; I arbitrarily chose a cutoff of 10000bp. This recovered events 1 and 2. Event 3 seemed to be the most difficult to recover. Plotting the copy ratios surrounding this event (which spans ~15 100bp bins) yields some insights:. CollectFragmentCounts:; ![image](https://user-images.githubusercontent.com/11076296/37244188-317a7f1e-2453-11e8-937d-f7239354316e.png). CollectReadCounts:; ![image](https://user-images.githubusercontent.com/11076296/37244228-ad24908c-2453-11e8-91dd-a978578e77f4.png). CollectFragmentOverlaps:; ![image](https://user-images.githubusercontent.com/11076296/37244230-b25b9cee-2453-11e8-8646-f9c95365b355.png). The increased statistical noise in the CollectFragmentCounts result (due to the lower overall count because of the pairing of reads) probably causes us to miss this event. Also, although CollectFragmentOverlaps initially looks pretty good, I think the bin-to-bin correlations that are evident here negatively affect segmentation. This is not an extremely rigorous evaluation, but it suggests that we should consider switching over to a CollectReadCounts-like strategy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4519:2364,recover,recover,2364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519,1,['recover'],['recover']
Availability,"57:17.333 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates17353441228865531235.csv'; 12:57:17.414 INFO AnalyzeCovariates - Generating plots file '/home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf'; 12:57:17.829 INFO AnalyzeCovariates - Shutting down engine; [December 17, 2020 at 12:57:17 PM TRT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=633339904; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10272183847736955081';source('/tmp/BQSR.16251220439562120273.R'); /tmp/AnalyzeCovariates17353441228865531235.csv /home/detagen/Desktop/pipeline/playground/BACKUP/FMF-248_Backup/before.recal.FMF-248.table /home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Stdout: ; Stderr: Error in library(gplots) : there is no package called gplots; Calls: source -> withVisible -> eval -> eval -> library; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:130); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.doWork(AnalyzeCovariates.java:341); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(Command",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006:4112,Error,Error,4112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006,1,['Error'],['Error']
Availability,"5:53.390 INFO ProgressMeter - Starting traversal; 09:15:53.390 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:15:53.479 INFO SelectVariants - Shutting down engine; [June 27, 2019 9:15:53 AM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2131755008; htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 3433: The VCF specification does not allow for whitespace in the INFO field; . Offending field value was ""AC=1;AF=9.671e-04;AN=1034;AS_BaseQRankSum=-1.550;AS_FS=8.334;AS_InbreedingCoeff=-0.3147;AS_MQ=31.69;AS_MQRankSum=-0.200;AS_QD=28.73;AS_ReadPosR; ankSum=nul;AS_SOR=2.235;BaseQRankSum=-1.381e+00;DP=40368;ExcessHet=160.0000;FS=8.334;InbreedingCoeff=-0.3147;MLEAC=7;MLEAF=6.770e-03;MQ=37.13;MQRankSum=0.126;QD=2.46;SOR=2.; 235 GT:AD:DP:GQ:PGT:PID:PL:PS 0/0:75,0:75:0:.:.:0,0,1525; `. However, from the error message I cannot see any whitespace in the INFO field. The /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR/ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.gz is the output of following command:. `gatk4.1.0.0 --java-options '-Xmx100g -Xmx100g' ApplyVQSR \; -R /dsgmnt/llfs2/masterdata/geno/hg38/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta \; -V ${SNPPath}/joint525_chr1_ExcessHet_filter.SNP.g.vcf.gz \; -V ${SNPPath}/joint525_chr2_ExcessHet_filter.SNP.g.vcf.gz \; ....; -V ${SNPPath}/joint525_chr22_ExcessHet_filter.SNP.g.vcf.gz \; -O /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR//ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.g; z \; --truth-sensitivity-filter-level 97 \; --tranches-file /dsgmnt/seq5_llfs/work/xhong/v4100/VQSR//ExcessHet_joint525_c1_22.snp.tranches \; --recal-file /dsgmnt/seq5_llfs/work/xho; ng/v4100/VQSR//ExcessHet_joint525_c1_22.snp.recal \; -mode SNP`. There is no error or warning in the standard error and standard output of this step. I have tried to apply VQSR SNP model to ${SNPPath}/joint525_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6021:3784,error,error,3784,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6021,1,['error'],['error']
Availability,"5:53.8124383Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-08-16T22:45:53.8124657Z symbol: class BiMap; 2022-08-16T22:45:53.8124810Z location: class LoggingUtils; 2022-08-16T22:45:53.8125227Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:41: error: cannot find symbol; 2022-08-16T22:45:53.8125528Z private static BiMap<Log.LogLevel, java.util.logging.Level> javaUtilLevelNamespaceMap;; 2022-08-16T22:45:53.8125793Z symbol: class BiMap; 2022-08-16T22:45:53.8126059Z location: class LoggingUtils; 2022-08-16T22:45:53.8134767Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:13: error: package com.google.common.base does not exist; 2022-08-16T22:45:53.8135486Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:14: error: package com.google.common.io does not exist; 2022-08-16T22:45:53.8163449Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8167163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:245: error: cannot find symbol; 2022-08-16T22:45:53.8167305Z @VisibleForTesting; 2022-08-16T22:45:53.8167581Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8167809Z location: class ReferenceConfidenceVariantContextMerger; 2022-08-16T22:45:53.8173821Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:7: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8175307Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T22:45:53.8175437Z @VisibleForTesting; 2022-08-16T22:45:53.8175712Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8180874Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does no",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:16133,error,error,16133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,5:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.resolveLargeResourceStubFiles(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:116); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$resolveLargeResourceStubFiles$0.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.ensureBuildPrerequisites(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:140); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17$ensureBuildPrerequisites.callCurrent(Unknown Source); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at build_2s1dokgyqm2mnf3n5hcv2kf17.run(/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle:143); 22:05:55.985 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:90); 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	... 58 more; 22:05:55.986 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] BUILD FAILED; 22:05:55.986 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] ; 22:05:55.987 [LIFECYCLE] [org.gradle.internal.buildevents.BuildResultLogger] Total time: 29.153 secs; ```. ```; root# su - portage; portage$ cd /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/; portage$ git lfs pull --include src/main/resources/large; No default remote. Errors logged to /scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects/logs/20180420T,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:14137,ERROR,ERROR,14137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,5Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2861934Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3012792Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3151812Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3156616Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3263061Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3605617Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3694118Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3740413Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3746092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3759011Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3760984Z src/main/java/o,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:3121,error,error,3121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"5g -Xms85g"" GenomicsDBImport \\ ; ; \-R ${dir\_refdata}/b37\_human\_g1k\_v37\_decoy.fasta \\ ; ; \--sample-name-map ${dir\_CombineGVCFs}/S2\_cohort.sample\_map \\ ; ; \--genomicsdb-workspace-path ${dir\_CombineGVCFs}/temporary/tmp4 \\ ; ; \--TMP\_DIR ${dir\_CombineGVCFs}/temporary \\ ; ; \--intervals ${dir\_CombineGVCFs}/intervals/bed3\_tmp.intervals \\ ; ; \--reader-threads 5 \\ ; ; \--batch-size 50. **\[output\]**:. folders and files in; ====================. \--genomicsdb-workspace-path ${dir\_CombineGVCFs}/temporary/tmp4; ================================================================. callset.json ; ; genomicsdb\_array ; ; \_\_tiledb\_workspace.tdb ; ; vcfheader.vcf ; ; vidmap.json. **\[Tool\]: GenotypeGVCFs**. export TILEDB\_DISABLE\_FILE\_LOCKING=1. time ${dir\_tool\_gatk}/gatk --java-options ""-Xmx4g"" GenotypeGVCFs \\ ; ; \-R ${dir\_refdata}/b37\_human\_g1k\_v37\_decoy.fasta \\ ; ; \-V gendb://${dir\_GenomicsDBImport}/tmp4 \\ ; ; \-O ${dir\_GenotypeVCFs}/tmp4.vcf.gz. c) Entire error log:. Using GATK jar /home/projects/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false ; ; \-Dsamjdk.use\_async\_io\_write\_samtools=true ; ; \-Dsamjdk.use\_async\_io\_write\_tribble=false ; ; \-Dsamjdk.compression\_level=2 ; ; \-Xmx4g -jar /home/projects/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar ; ; GenotypeGVCFs -R /home/reference\_hg19/b37\_human\_g1k\_v37\_decoy.fasta ; ; \-V gendb:///home/WES-VCFQC/S2\_GenomicsDBImport/temporary/tmp4 ; ; \-O /home/WES-VCFQC/S2\_GenomicsDBImport/VCF/tmp4.vcf.gz ; ; 12:52:15.187 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/projects/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; 12:52:16.266 INFO GenotypeGVCFs - ------------------------------------------------------------ ; ; 12:52:16.267 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.0.3.0 ; ; 12:52:16.267 INFO GenotypeGVCFs - For",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7442:1856,error,error,1856,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7442,1,['error'],['error']
Availability,"6 4314000 1212183.7; 15:38:44.573 INFO ProgressMeter - unmapped 3.7 5276000 1415236.1; 15:38:44.689 WARN IntelInflater - Zero Bytes Written : 0; 15:38:44.691 INFO SplitNCigarReads - 0 read(s) filtered by: AllowAllReadsReadFilter . 15:38:45.179 INFO OverhangFixingManager - Overhang Fixing Manager saved 434 reads in the first pass; 15:38:45.182 INFO SplitNCigarReads - Starting traversal pass 2; 15:38:54.809 INFO ProgressMeter - 1:67424901 3.9 5368000 1376916.3; 15:39:05.144 INFO ProgressMeter - 1:153935839 4.1 5421000 1331662.9; 15:39:15.368 INFO ProgressMeter - 1:210675831 4.2 5438000 1282169.2; 15:39:25.463 INFO ProgressMeter - 10:119579965 4.4 5479000 1242549.2; 15:39:35.700 INFO ProgressMeter - 11:118752077 4.6 5530000 1207397.2; 15:39:46.028 INFO ProgressMeter - 12:58875536 4.8 5592000 1176709.9; 15:39:56.079 INFO ProgressMeter - 13:37022394 4.9 5628000 1143956.7; 15:40:06.117 INFO ProgressMeter - 16:14727212 5.1 5728000 1125992.7; 15:40:16.383 INFO SplitNCigarReads - Shutting down engine; [March 2, 2023 3:40:16 PM EST] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 5.27 minutes.; Runtime.totalMemory()=3432513536; java.lang.ClassCastException: htsjdk.samtools.BAMRecord cannot be cast to java.lang.Comparable; 	at java.util.Arrays$NaturalOrder.compare(Arrays.java:102); 	at java.util.TimSort.countRunAndMakeAscending(TimSort.java:355); 	at java.util.TimSort.sort(TimSort.java:234); 	at java.util.ArraysParallelSortHelpers$FJObject$Sorter.compute(ArraysParallelSortHelpers.java:145); 	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401); 	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734); 	at java.util.Arrays.parallelSort(Arrays.java:1180); 	at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:247); 	at htsjdk.samtools.util.SortingCol",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452525485:5539,down,down,5539,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452525485,1,['down'],['down']
Availability,"6 more**. 00:59 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 1.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 1, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:55:54 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 0.1 in stage 2.0 (TID 6, xx.xx.xx.16, executor 3, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:55:55 INFO TaskSetManager: Lost task 0.1 in stage 2.0 (TID 6) on xx.xx.xx.16, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 2]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:55 INFO TaskSetManager: Starting task 0.2 in stage 2.0 (TID 7, xx.xx.xx.23, executor 5, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:55:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.23:42535 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:55:55 INFO TaskSetManager: Lost task 0.2 in stage 2.0 (TID 7) on xx.xx.xx.23, executor 5: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 3]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:55 INFO TaskSetManager: Starti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:27909,Error,Error,27909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Error'],['Error']
Availability,"616546): instance a816c00e-015f-0a1b-f1bd-00002ce33928 ; on database directory /tmp/spark-98953d35-8594-4907-b4a5-0870f1d17b3e/metastore with class loader sun.misc.Launcher$AppClassLoader@5c647e05 ; Loaded from file:/opt/cloudera/parcels/CDH-5.12.1-1.cdh5.12.1.p0.3/jars/derby-10.11.1.1.jar; java.vendor=Oracle Corporation; java.runtime.version=1.8.0_91-b14; user.dir=/opt/Software/gatk; os.name=Linux; os.arch=amd64; os.version=3.10.0-514.el7.x86_64; derby.system.home=null; Database Class Loader started - derby.database.classpath=''; 17/10/11 14:25:33 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.1.0-cdh5.12.1; 17/10/11 14:25:33 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException; SQL context available as sqlContext. **./gradlew bundle**; **[root@com1 gatk]# ./gradlew bundle; when I executed the command ./gradlew bundle it appeared the error in the last did this matter**. .......; [loading ZipFileIndexFileObject[/root/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.6.5/d50be1723a09be903887099ff2014ea9020333/jackson-databind-2.6.5.jar(com/fasterxml/jackson/databind/annotation/JsonSerialize$Inclusion.class)]]; [loading ZipFileIndexFileObject[/root/.gradle/caches/modules-2/files-2.1/org.apache.logging.log4j/log4j-core/2.5/7ed845de1dfe070d43511fab1784e6c4118398/log4j-core-2.5.jar(org/apache/logging/log4j/core/config/plugins/PluginVisitorStrategy.class)]]; [done in 5759 ms]; 1 error; :gatkTabComplete FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkTabComplete'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/opt/Software/gatk/build/tmp/gatkTabComplete/jadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAI",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240:2848,error,error,2848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240,1,['error'],['error']
Availability,"625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-NISTSampleHeadToHead/BenchmarkComparison/4ffa2353-b1bc-4960-a5a4-96291208a7eb/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-NISTSampleHeadToHead/BenchmarkComparison/4ffa2353-b1bc-4960-a5a4-96291208a7eb/call-BenchmarkVCFControlSample/Benchmark/8cf95ec9-48a7-4e20-a8fe-816dc3e652ae/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""100.56416111111112"",; ""NIST evalHCsystemhours"": ""0.19999166666666665"",; ""NIST evalHCwallclockhours"": ""74.00048055555555"",; ""NIST evalHCwallclockmax"": ""4.007605555555555"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-NISTSampleHeadToHead/BenchmarkComparison/4ffa2353-b1bc-4960-a5a4-96291208a7eb/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-NISTSampleHeadToHead/BenchmarkComparison/4ffa2353-b1bc-4960-a5a4-96291208a7eb/call-BenchmarkVCFTestSample/Benchmark/6b79227b-3ca8-4f5b-96b6-60d57760cc5b/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-CreateHTMLReport/cacheCopy/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1533946590:22061,error,errors,22061,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1533946590,1,['error'],['errors']
Availability,"625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-NISTSampleHeadToHead/BenchmarkComparison/d1a60d2b-8100-459a-9b05-72a22afccb4a/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-NISTSampleHeadToHead/BenchmarkComparison/d1a60d2b-8100-459a-9b05-72a22afccb4a/call-BenchmarkVCFControlSample/Benchmark/9f6d4e85-981d-4607-8ff6-97495034807f/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""96.65376666666666"",; ""NIST evalHCsystemhours"": ""0.17881944444444442"",; ""NIST evalHCwallclockhours"": ""68.38394444444445"",; ""NIST evalHCwallclockmax"": ""3.8226138888888888"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-NISTSampleHeadToHead/BenchmarkComparison/d1a60d2b-8100-459a-9b05-72a22afccb4a/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-NISTSampleHeadToHead/BenchmarkComparison/d1a60d2b-8100-459a-9b05-72a22afccb4a/call-BenchmarkVCFTestSample/Benchmark/e62b142c-c39c-4c1f-9a08-c41a96647879/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-CreateHTMLReport/cacheCopy/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672:21401,error,errors,21401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672,1,['error'],['errors']
Availability,64dd8791c5149d5bed330c4?src=pr&el=desc) will **increase** coverage by `<.001%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5074 +/- ##; ===============================================; + Coverage 86.928% 86.928% +<.001% ; + Complexity 30319 30318 -1 ; ===============================================; Files 1849 1849 ; Lines 140737 140738 +1 ; Branches 15476 15475 -1 ; ===============================================; + Hits 122340 122341 +1 ; Misses 12789 12789 ; Partials 5608 5608; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5074?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `100% <100%> ()` | `18 <3> (-3)` | :arrow_down: |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `77.049% <100%> ()` | `10 <2> ()` | :arrow_down: |; | [...llbender/utils/downsampling/MutectDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvTXV0ZWN0RG93bnNhbXBsZXIuamF2YQ==) | `68.182% <100%> ()` | `17 <0> ()` | :arrow_down: |; | [...dinstitute/hellbender/utils/MathUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYXRoVXRpbHNVbml0VGVzdC5qYXZh) | `92.44% <100%> (+0.071%)` | `145 <2> (+2)` | :arrow_up: |; | [...lbender/utils/locusiterator/SamplePartitioner.java](https://codecov.io/gh/broadinstitute/gatk/pull/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-434027785:1233,down,downsampling,1233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-434027785,1,['down'],['downsampling']
Availability,66366Z [0K; 2022-08-16T22:45:53.8466494Z [0K; 2022-08-16T22:45:53.8482815Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8483576Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8485557Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8486273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8489006Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T22:45:53.8489149Z @VisibleForTesting; 2022-08-16T22:45:53.8489418Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8489587Z location: class CommandLineProgram; 2022-08-16T22:45:53.8514933Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/DefaultGATKVariantAnnotationArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8515375Z [done in 2341 ms]; 2022-08-16T22:45:53.8515491Z 1 error; 2022-08-16T22:45:53.8515610Z 101 warnings; 2022-08-16T22:45:53.8515748Z expected [99] but found [1]; 2022-08-16T22:45:53.8515934Z at org.testng.Assert.fail(Assert.java:97); 2022-08-16T22:45:53.8516162Z at org.testng.Assert.assertEqualsImpl(Assert.java:136); 2022-08-16T22:45:53.8516413Z at org.testng.Assert.assertEquals(Assert.java:118); 2022-08-16T22:45:53.8516617Z at org.testng.Assert.assertEquals(Assert.java:839); 2022-08-16T22:45:53.8517212Z at org.broadinstitute.hellbender.utils.help.DocumentationGenerationIntegrationTest.documentationSmokeTest2(DocumentationGenerationIntegrationTest.java:131); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:22974,error,error,22974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,2,['error'],['error']
Availability,"67); 	at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.handlePosition(FastaAlternateReferenceMaker.java:176); 	at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.apply(FastaAlternateReferenceMaker.java:141); 	at org.broadinstitute.hellbender.engine.ReferenceWalker.traverse(ReferenceWalker.java:55); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. By narrowing down on where this happens I find it happens here:. ```; chrom	16798	.	TAGC	*	41.94	.	AC=1;AF=1.00;AN=1;BaseQRankSum=-5.240e-01;DP=29;FS=3.663;MQ=36.43;MQRankSum=-1.282e+00;QD=1.40;ReadPosRankSum=0.00;SOR=0.446	GT:AD:DP:GQ:PL	1:0,6:29:99:810,0. chrom	16799	.	A	*	0	LowQual	AC=1;AF=1.00;AN=1;DP=29;FS=3.663;QD=0.00;SOR=0.446	GT:AD:DP:GQ:PL	1:0,6:29:99:810,0. chrom	16800	.	G	*	3727.44	.	AC=1;AF=1.00;AN=1;BaseQRankSum=0.00;DP=29;FS=2.256;MQ=42.17;MQRankSum=1.88;QD=21.42;ReadPosRankSum=-6.100e-02;SOR=0.920	GT:AD:DP:GQ:PL	1:0,6:29:99:810,0. chrom	16801	.	C	*	0	LowQual	AC=1;AF=1.00;AN=1;DP=29;FS=3.663;QD=0.00;SOR=0.446	GT:AD:DP:GQ:PL	1:0,6:29:99:810,0. chrom	16802	.	A	*	0	LowQual	AC=1;AF=1.00;AN=1;DP=29;FS=4.509;QD=0.00;SOR=0.378	GT:AD:DP:GQ:PL	1:0,6:29:99:810,0. chrom	16804	.	CAGA	.	379.83	.	AN=1;BaseQRankSum=0.00;DP=48;FS=0.000;MQ=42.50;MQRankSum=-6.740e-01;QD=29.22;ReadPosRankSum=0.524;SOR=0.836	GT:AD:DP:PL	0:48:48:0; ```. The problem is at position 16800. I have gotten this error again in similar positions w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7433:1918,down,down,1918,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7433,1,['down'],['down']
Availability,"6913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:1896,Error,Error,1896,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,5,"['Error', 'error']","['Error', 'error']"
Availability,6:40.765 DEBUG Mutect2 - Processing assembly region at chrM:5144-5443 isActive: false numReads: 0; 11:36:40.771 INFO ProgressMeter - chrM:5144 1.0 20 20.4; 11:36:40.774 DEBUG Mutect2 - Processing assembly region at chrM:5444-5743 isActive: false numReads: 0; 11:36:41.211 DEBUG IntToDoubleFunctionCache - cache miss 11898 > 5320 expanding to 11908; 11:36:41.213 DEBUG IntToDoubleFunctionCache - cache miss 17632 > 11908 expanding to 23818; 11:36:41.254 DEBUG IntToDoubleFunctionCache - cache miss 29537 > 23818 expanding to 47638; 11:36:42.578 DEBUG Mutect2 - Processing assembly region at chrM:5744-6043 isActive: false numReads: 0; 11:36:47.533 DEBUG Mutect2 - Processing assembly region at chrM:6044-6343 isActive: false numReads: 30078; 11:36:47.979 DEBUG Mutect2 - Processing assembly region at chrM:6344-6353 isActive: false numReads: 30081; 11:36:48.322 DEBUG Mutect2 - Processing assembly region at chrM:6354-6629 isActive: true numReads: 60135; 11:36:55.630 DEBUG ReadThreadingGraph - Recovered 8 of 11 dangling tails; 11:36:55.645 DEBUG ReadThreadingGraph - Recovered 7 of 16 dangling heads; 11:36:55.737 DEBUG IntToDoubleFunctionCache - cache miss 26606 > 4800 expanding to 26616; 11:36:55.741 DEBUG IntToDoubleFunctionCache - cache miss 26873 > 26616 expanding to 53234; 11:36:56.119 DEBUG Mutect2Engine - Active Region chrM:6354-6629; 11:36:56.119 DEBUG Mutect2Engine - Extended Act Region chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Ref haplotype coords chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Haplotype count 128; 11:36:56.119 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:56.120 DEBUG Mutect2Engine - Kmer sizes values []; 11:39:06.762 DEBUG Mutect2 - Processing assembly region at chrM:6630-6929 isActive: false numReads: 30053; 11:39:07.547 DEBUG Mutect2 - Processing assembly region at chrM:6930-7229 isActive: false numReads: 0; 11:39:07.574 DEBUG Mutect2 - Processing assembly region at chrM:7230-7493 isActive: false numReads: 359; 11:39:07.584 DEBUG Mutect2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:13043,Recover,Recovered,13043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"6; 22:48:06.937 INFO ProgressMeter - Scaffold_1:21251889 551.3 125650 227.9; 22:48:18.177 INFO ProgressMeter - Scaffold_1:21271601 551.5 125750 228.0; 22:48:29.896 INFO ProgressMeter - Scaffold_1:21281660 551.7 125810 228.0; 22:48:40.223 INFO ProgressMeter - Scaffold_1:21284898 551.9 125830 228.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f889b5be310, pid=1422929, tid=1422930; #; # JRE version: OpenJDK Runtime Environment (17.0.2+8) (build 17.0.2+8-86); # Java VM: OpenJDK 64-Bit Server VM (17.0.2+8-86, mixed mode, sharing, tiered, compressed oops, compressed class ptrs, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0xcf310] __memset_avx2_unaligned_erms+0x60; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h %e"" (or dumping to /bigdata/operations/ejaco020/gatk/core.1422929); #; # An error report file with more information is saved as:; # /bigdata/operations/ejaco020/gatk/hs_err_pid1422929.log; #; # If you would like to submit a bug report, please visit:; # https://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. When running on singularity (AMD-based machine):; ```; 07:07:35.120 INFO ProgressMeter - Scaffold_1:21181812 627.1 125350 199.9; 07:07:45.271 INFO ProgressMeter - Scaffold_1:21193618 627.2 125400 199.9; 07:07:56.027 INFO ProgressMeter - Scaffold_1:21249981 627.4 125640 200.3; 07:08:07.701 INFO ProgressMeter - Scaffold_1:21267889 627.6 125730 200.3; 07:08:19.031 INFO ProgressMeter - Scaffold_1:21279883 627.8 125800 200.4; 07:08:32.466 INFO ProgressMeter - Scaffold_1:21283419 628.0 125820 200.3; Using GATK jar /gatk/gatk-package-4.6.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8988#issuecomment-2386154680:1723,error,error,1723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8988#issuecomment-2386154680,1,['error'],['error']
Availability,"6b-7565-103a-a738-f8f3fc8675d2/Job2.work/WGS_1852_consolidated.gdb/callset.json; 23 Feb 2022 15:33:59,339 DEBUG: 	15:33:59.330 INFO GenomicsDBImport - Incrementally importing to workspace - /home/exacloud/gscratch/prime-seq/workDir/0950f56b-7565-103a-a738-f8f3fc8675d2/Job2.work/WGS_1852_consolidated.gdb; 23 Feb 2022 16:28:45,048 DEBUG: 	16:28:45.047 INFO GenomicsDBImport - Done importing batch 1/5; 23 Feb 2022 17:29:49,240 DEBUG: 	17:29:49.226 INFO GenomicsDBImport - Done importing batch 2/5; 23 Feb 2022 18:26:19,107 DEBUG: 	18:26:19.105 INFO GenomicsDBImport - Done importing batch 3/5; 23 Feb 2022 19:20:18,500 DEBUG: 	19:20:18.478 INFO GenomicsDBImport - Done importing batch 4/5; 24 Feb 2022 16:51:19,017 DEBUG: 	[TileDB::utils] Error: (gzip_handle_error) Cannot decompress with GZIP: inflateInit error: Z_MEM_ERROR; 24 Feb 2022 16:51:19,048 DEBUG: 	[TileDB::Codec] Error: Could not decompress with GZIP.; 24 Feb 2022 16:51:19,056 DEBUG: 	[TileDB::ReadState] Error: Cannot decompress tile for /home/exacloud/gscratch/prime-seq/workDir/0950f56b-7565-103a-a738-f8f3fc8675d2/Job2.work/WGS_1852_consolidated.gdb/2$1$196197964/__e7217c9e-767d-4295-b75a-9162c22c6996139785909643008_1613563029631/END.tdb.; 24 Feb 2022 16:51:51,388 DEBUG: 	16:51:51.388 erro NativeGenomicsDB - pid=225263 tid=225739 VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,405 DEBUG: 	TileDB error message : ; 24 Feb 2022 16:51:51,412 DEBUG: 	terminate called after throwing an instance of 'VariantStorageManagerException'; 24 Feb 2022 16:51:51,419 DEBUG: 	 what(): VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,427 DEBUG: 	TileDB error message : ; 24 Feb 2022 16:52:27,478 WARN : 	process exited with non-zero value: 134; ```. Does that give anything to suggest troubleshooting steps?. The full command is:; ```; /home/exacloud/gscratch/prime-seq/java/java8/bin/java \; 	Xmx497g -X",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022:1587,Error,Error,1587,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022,1,['Error'],['Error']
Availability,"7 9:14:13 AM CST] Executing as yaron@dn1 on Linux 4.4.0-31-generic amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.alpha.2-281-g752d020-SNAPSHOT; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:14:13.567 INFO PrintReadsSpark - Deflater: IntelDeflater; 09:14:13.567 INFO PrintReadsSpark - Inflater: IntelInflater; 09:14:13.567 INFO PrintReadsSpark - Initializing engine; 09:14:13.567 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:3109,ERROR,ERROR,3109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['ERROR'],['ERROR']
Availability,"7.554 INFO GenomicsDBImport - Callset Map JSON file will be written to CDL-164-04P-1_0_249250621_genomicsdb/callset.json; 10:24:57.554 INFO GenomicsDBImport - Complete VCF Header will be written to CDL-164-04P-1_0_249250621_genomicsdb/vcfheader.vcf; 10:24:57.554 INFO GenomicsDBImport - Importing to array - CDL-164-04P-1_0_249250621_genomicsdb/genomicsdb_array; 10:24:57.554 INFO ProgressMeter - Starting traversal; 10:24:57.554 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 10:24:57.971 INFO GenomicsDBImport - Importing batch 1 with 1 samples; Buffer resized from 22726bytes to 32529; Buffer resized from 32529bytes to 32693; Buffer resized from 32693bytes to 32738; Buffer resized from 32738bytes to 32741; Buffer resized from 32741bytes to 32756; Buffer resized from 32756bytes to 32768; Buffer resized from 32768bytes to 32769; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f7288295359, pid=68672, tid=0x00007f72dc187700; #; # JRE version: OpenJDK Runtime Environment (8.0_171-b10) (build 1.8.0_171-b10); # Java VM: OpenJDK 64-Bit Server VM (25.171-b10 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libtiledbgenomicsdb8064358042335455262.so+0x155359] BufferVariantCell::set_cell(void const*)+0x99; #; # Core dump written. Default location: /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/core or core.68672; #; # An error report file with more information is saved as:; # /mnt/isilon/cbmi/variome/rathik/mendelian_rnaseq/gatk_output/CDL-164-04P/hs_err_pid68672.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. ```. And here is the `hs_err_pid68672.log` file: ; [hs_err_pid68672.log](https://github.com/broadinstitute/gatk/files/2219689/hs_err_pid68672.log)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045:11348,error,error,11348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045,1,['error'],['error']
Availability,"7/100 [00:01<00:24, 3.72it/s]; 15:10:07.381 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0011 +/- 0.0011: 8%|8 | 8/100 [00:02<00:24, 3.72it/s]; 15:10:07.649 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0008 +/- 0.0009: 10%|# | 10/100 [00:02<00:24, 3.72it/s]; 15:10:08.193 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0006: 11%|#1 | 11/100 [00:02<00:24, 3.70it/s]; 15:10:08.463 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0005 +/- 0.0007: 12%|#2 | 12/100 [00:03<00:23, 3.70it/s]; 15:10:08.732 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0007: 13%|#3 | 13/100 [00:03<00:23, 3.70it/s]; 15:10:09.001 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0004 +/- 0.0005: 13%|#3 | 13/100 [00:03<00:25, 3.45it/s]; 15:10:09.002 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1): 0%| | 0/1 [00:00<?, ?it/s]; 15:10:09.003 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1) ploidy update size: 0.200122: 100%|##########| 1/1 [00:00<00:00, 1605.78it/s]; 15:10:09.004 INFO gcnvkernel.tasks.inference_task_base - (denoising) starting...: 0%| | 0/1000 [00:00<?, ?it/s]; 15:10:09.105 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 2) ELBO: -419.253 +/- 160.674, SNR: 8.0, T: 1.79: 4%|3 | 37/1000 [00:00<00:02, 365.67it/s]; 15:10:09.207 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 2) ELBO: -412.997 +/- 158.620, SNR: 7.8, T: 1.79: 7%|7 | 74/1000 [00:00<00:02, 363.49it/s]; 15:10:09.312 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 2) ELBO: -407.614 +/- 156.431, SNR: 7.6, T: 1.78: 11%|#1 | 111/1000 [00:00<00:02, 359.40it/s]; 15:10:09.415 INFO gcnvkerne",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:12910,error,error,12910,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['error'],['error']
Availability,70 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultBuildConfigurer.configure(DefaultBuildConfigurer.java:38); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradleLauncher.java:151); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Factories$1.create(Factories.java:22); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLaunc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:4487,ERROR,ERROR,4487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"709 INFO ProgressMeter - 1:16264047 3.3 56380 17024.5; 09:52:36.145 INFO ProgressMeter - 1:16891523 3.5 58590 16809.0; 09:52:50.980 INFO ProgressMeter - 1:16893022 3.7 58600 15698.3; 09:53:01.463 INFO ProgressMeter - 1:17740440 3.9 61570 15756.5; 09:53:12.294 INFO ProgressMeter - 1:19379390 4.1 67150 16425.7; 09:53:22.294 INFO ProgressMeter - 1:20576686 4.3 71380 16776.4; 09:53:32.681 INFO ProgressMeter - 1:21106727 4.4 73230 16538.3; 09:53:44.258 INFO ProgressMeter - 1:21270052 4.6 73820 15975.4; 09:53:54.757 INFO ProgressMeter - 1:21754504 4.8 75500 15742.8; 09:54:04.928 INFO ProgressMeter - 1:23419224 5.0 81370 16387.6; 09:54:15.956 INFO ProgressMeter - 1:23812728 5.1 82750 16070.6; 09:54:31.008 INFO ProgressMeter - 1:24023237 5.4 83470 15457.4; 09:54:33.610 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 58.921665822; 09:54:33.611 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 72.92 sec; 09:54:33.612 INFO Mutect2 - Shutting down engine; [March 7, 2019 9:54:33 AM EST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 5.51 minutes.; Runtime.totalMemory()=193003520; java.lang.IllegalArgumentException: readMaxLength must be > 0 but got 0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:152); 	at org.broadinstitute.hellbender.utils.pairhmm.N2MemoryPairHMM.initialize(N2MemoryPairHMM.java:28); 	at org.broadinstitute.hellbender.utils.pairhmm.LoglessPairHMM.initialize(LoglessPairHMM.java:7); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:177); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.initializePairHMM(PairHMMLikelihoodCalculationEngine.java:242); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844:4464,down,down,4464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844,1,['down'],['down']
Availability,"709859-185537688(G* -> <DEL>): Variant overlaps transcript but is not completely contained ; within it. Funcotator cannot currently handle this case. Transcript: ENST00000378191.5 Variant: [VC Unknown @ chr1:4709859-185537688 Q. of type=SYMBOLIC alleles=[G*, <DEL>] attr={CIEND=[0, 4], CIPOS=[0, 4], END=185537688, HOML; EN=4, HOMSEQ=TCCT, SOMATIC=true, SOMATICSCORE=141, SVLEN=-180827829, SVTYPE=DEL} GT=PR:SR 68,0:94,0 38,23:94,24 filters=; 17:07:32.003 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000378191.5 for problem variant: chr1:4709859-185537688(G* -> <DEL>); 17:07:32.009 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/0; 17:07:32.136 INFO Funcotator - Shutting down engine; [14 January 2021 17:07:32 GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.77 minutes.; Runtime.totalMemory()=1426182144; java.lang.ArrayIndexOutOfBoundsException: 0; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getNonOverlappingAltAlleleBaseString(FuncotatorUtils.java:294); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getGenomeChangeString(GencodeFuncotationFactory.java:2346); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationBuilderWithTrivialFieldsPopulated(GencodeFuncotationFactory.java:2214); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createDefaultFuncotationsOnProblemVariant(GencodeFuncotationFactory.java:923); [...]; ```. I've seen that FuncotateSegments works for segment files with CNVs, but I was wondering if there is (or there are plans to add) ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7040:1365,down,down,1365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7040,1,['down'],['down']
Availability,"72a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_lof/hg38/acmg_lof.tsv; 14:24:35.311 INFO Funcotator - Shutting down engine; [October 29, 2020 2:24:35 PM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2055733248; code: 400; message: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:244); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:241); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:736); 	at java.nio.file.Files.exists(Files.java:2385); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.assertPathFilePropertiesField(DataSourceUtil",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926:7646,error,error,7646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926,1,['error'],['error']
Availability,78 INFO ProgressMeter - Starting traversal; 01:25:02.078 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); 01:25:43.661 INFO GenomicsDBImport - Starting batch input file preload; 01:26:19.244 INFO GenomicsDBImport - Finished batch preload; 01:26:19.244 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 01:30:20.226 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.226 INFO GenomicsDBImport - Done importing batch 1/1; 01:30:20.227 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.227 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 5.3 minutes.; 01:30:20.227 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed!; 01:30:20.227 INFO GenomicsDBImport - Shutting down engine; [10 December 2021 01:30:20 UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 7.76 minutes.; Runtime.totalMemory()=16078340096; ```. #### Steps to reproduce. Not sure if it reproducible with any particular imput... it seems that one has to simulate the IO errors for example by using a nearly full storage for the output or create some read-only conflicting file s. #### Expected behavior. No low-level error messages as the ones above... and that the output can be use for genotype-gvcfs without issue . #### Actual behavior. Error messages coming from the jni dependency. The tool finishes succesfully in apperance but the output file is missing some content render it unusable for VCF calling.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:5192,down,down,5192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,4,"['Error', 'down', 'error']","['Error', 'down', 'error', 'errors']"
Availability,"781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContex",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7944,AVAIL,AVAILABLE,7944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,"781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-07 11:33:30 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-07 11:33:30 INFO Client:54 - Setting up co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:10042,AVAIL,AVAILABLE,10042,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContex",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8204,AVAIL,AVAILABLE,8204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"7:18:41.657 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:18:48.155 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:18:54.358 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:19:01.067 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:19:08.337 INFO GenomicsDBImport - Importing batch 1 with 80 samples; 17:19:09.814 INFO ProgressMeter - chr1:227419 95.0 1 0.0; 17:19:09.814 INFO GenomicsDBImport - Done importing batch 1/1; 17:19:09.815 INFO ProgressMeter - chr1:227419 95.0 1 0.0; 17:19:09.815 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 95.0 minutes.; 17:19:09.815 INFO GenomicsDBImport - Import completed!; 17:19:09.816 INFO GenomicsDBImport - Shutting down engine; [January 16, 2021 5:19:09 PM IST] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 95.12 minutes.; Runtime.totalMemory()=13188464640. And when I tried to create panel of normal using `CreateSomaticPanelOfNormals` and I am getting an error that `It isn't a regular file`: Here is the stack trace:. 17:19:12.932 INFO CreateSomaticPanelOfNormals - ------------------------------------------------------------; 17:19:12.933 INFO CreateSomaticPanelOfNormals - The Genome Analysis Toolkit (GATK) v4.1.9.0; 17:19:12.933 INFO CreateSomaticPanelOfNormals - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:19:12.933 INFO CreateSomaticPanelOfNormals - Executing as akansha@sbilab on Linux v4.4.0-169-generic amd64; 17:19:12.933 INFO CreateSomaticPanelOfNormals - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~16.04-b01; 17:19:12.933 INFO CreateSomaticPanelOfNormals - Start Date/Time: January 16, 2021 5:19:12 PM IST; 17:19:12.934 INFO CreateSomaticPanelOfNormals - ------------------------------------------------------------; 17:19:12.934 INFO CreateSomaticPanelOfNormals - ------------------------------------------------------------; 17:19:12.934 INFO CreateSomatic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-761558811:13420,error,error,13420,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-761558811,1,['error'],['error']
Availability,"7:24:16.220 INFO ProgressMeter - NC_016854.1:138000 6.0 138000 23062.5; 07:24:29.116 INFO ProgressMeter - NC_016854.1:175000 6.2 175000 28231.8; 07:43:58.742 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),29.644886145999088,Cpu time(s),29.480321756000397; Using GATK jar /opt/conda/envs/789546e2/share/gatk4-4.0.1.1-0/gatk-package-4.0.1.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /opt/conda/envs/789546e2/share/gatk4-4.0.1.1-0/gatk-package-4.0.1.1-local.jar GenotypeGVCFs -ploidy 1 -R references/359488/genome_fasta.fasta --annotate-with-num-discovered-alleles true --annotations-to-exclude InbreedingCoeff -V gendb://typing/gatk_gvcfs/full_genome/359488/bwa/genomics_db -O typing/gatk_gvcfs/full_genome/359488/bwa/all_samples.vcf; ```; In between the last ProgressMeter and the Shutting down of the engine, I see the java process still running with top. Do you know what could be causing the problem ? Could it be related to -ERC BP_RESOLUTION ? I used to use -ERC GVCF before but I would rather keep the information of the coverage for post filtering, and I am not sure how to use --GVCFGQBands to match my criteria for coverage filtering. Thanks a lot for your help !. Edit: sorry with the latest version of gatk I get a new message error :; ```; 08:22:54.446 INFO ProgressMeter - NC_016854.1:20000 0.2 20000 87450.8; 08:23:04.942 INFO ProgressMeter - NC_016854.1:58000 0.4 58000 143694.8; 08:25:25.155 INFO ProgressMeter - NC_016854.1:82000 2.7 82000 29921.4; 08:25:35.161 INFO ProgressMeter - NC_016854.1:100000 2.9 100000 34396.6; 08:28:02.395 INFO ProgressMeter - NC_016854.1:102000 5.4 102000 19025.7; 08:28:13.248 INFO ProgressMeter - NC_016854.1:140000 5.5 140000 25261.3; 08:28:24.027 INFO ProgressMeter - NC_016854.1:175000 5.7 175000 30585.2; 08:46:13.574 INFO GenotypeGVCFs - S",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4467:1690,down,down,1690,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467,1,['down'],['down']
Availability,"7:30.677 INFO GenomicsDBImport - Vid Map JSON file will be written to genomicsdb/vidmap.json; 04:37:30.677 INFO GenomicsDBImport - Callset Map JSON file will be written to genomicsdb/callset.json; 04:37:30.677 INFO GenomicsDBImport - Complete VCF Header will be written to genomicsdb/vcfheader.vcf; 04:37:30.678 INFO GenomicsDBImport - Importing to array - genomicsdb/genomicsdb_array; 04:37:30.680 INFO ProgressMeter - Starting traversal; 04:37:30.680 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 04:37:33.253 INFO GenomicsDBImport - Starting batch input file preload; 04:37:35.079 INFO GenomicsDBImport - Finished batch preload; 04:37:35.079 INFO GenomicsDBImport - Importing batch 1 with 50 samples; 04:37:37.079 INFO GenomicsDBImport - Starting batch input file preload; 04:37:38.712 INFO GenomicsDBImport - Finished batch preload; 04:37:38.712 INFO GenomicsDBImport - Importing batch 1 with 50 samples; 04:37:39.162 INFO GenomicsDBImport - Shutting down engine; [October 8, 2018 4:37:39 AM UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.17 minutes.; Runtime.totalMemory()=4116185088; java.util.concurrent.CompletionException: org.broadinstitute.hellbender.exceptions.GATKException: Cannot call query with different interval, expected:1:29867-31003 queried with: 1:68590-70510; at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273); at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280); at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1592); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Cannot call query with different interval, expected:1:29867-31003 queried with: 1:68590-70510;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5300:3966,down,down,3966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5300,1,['down'],['down']
Availability,"7;ExcessHet=3.0103;MLEAC=0,1,0;MLEAF=0.00,0.500,0.00;MQRankSum=0.000;RAW_MQandDP=2869200,797;ReadPosRankSum=0.386	GT:AD:DP:GQ:PL:SB	0/2:413,2,357,0:772:99:14840,11462,50871,0,41338,45112,14111,52486,44158,56658:203,210,177,182; chr13	32944609	.	T	A,*,TAAAA,<NON_REF>	0	.	BaseQRankSum=4.278;DP=787;ExcessHet=3.0103;MLEAC=0,1,0,0;MLEAF=0.00,0.500,0.00,0.00;MQRankSum=0.000;RAW_MQandDP=2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.gvcf -ERC GVCF && tail target.4.1.2.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.vcf && tail target.4.1.2.0.vcf; ```. #### Expected behavior; 1. ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:6143,down,download,6143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,1,['down'],['download']
Availability,7_PDS/MCF7_PDS.bam --ALIGNMENT_STATUS=Aligned --PF_STATUS PF --HEADER_ONLY true ; Using GATK jar /resources/tools/gatk-4.0.4.0/gatk-package-4.0.4.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /resources/; tools/gatk-4.0.4.0/gatk-package-4.0.4.0-local.jar ViewSam -I /data/MCF7_PDS.bam --ALIGNMENT_STATUS=Aligned --PF_STATUS PF --HEADER_ONLY; true; 08:51:42.543 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/resources/tools/gatk-4.0.4.0/gatk-package-4.0.4.0-local.jar!/com/intel/gkl/native/libgkl_compr; ession.so; [Mon May 07 08:51:42 CEST 2018] ViewSam --INPUT /data/MCF7_PDS.bam --ALIGNMENT_STATUS Aligned --PF_STATUS PF --HEADER_ONLY true --REC; ORDS_ONLY false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH; _CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Mon May 07 08:51:42 CEST 2018] Executing as [...] on Linux 4.4.0-87-generic amd64; OpenJDK 64-Bit Server VM 1.8.0_151-8u151-b12-0ubuntu0.16.04.2-b12; Deflater; : Intel; Inflater: Intel; Provider GCS is available; **Picard version: Version:4.0.4.0**; ```; And if I use `--version true`:; ```; $ gatk ViewSam -I /data/MCF7_PDS.bam --ALIGNMENT_STATUS=Aligned --PF_STATUS PF --HEADER_ONLY true --version true; Using GATK jar /resources/tools/gatk-4.0.4.0/gatk-package-4.0.4.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /resources/tools/gatk-4.0.4.0/gatk-package-4.0.4.0-local.jar ViewSam -I /data/MCF7_PDS.bam --ALIGNMENT_STATUS=Aligned --PF_STATUS PF --HEADER_ONLY true --version true; Version:4.0.4.0; Tool returned:; 1; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4733#issuecomment-386976106:1412,avail,available,1412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4733#issuecomment-386976106,1,['avail'],['available']
Availability,"7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:1574,Error,Error,1574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,1,['Error'],['Error']
Availability,"8); 18/04/24 17:42:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:42:11 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:42:11 INFO BlockManager: BlockManager stopped; 18/04/24 17:42:11 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:42:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:42:11 INFO SparkContext: Successfully stopped SparkContext; 17:42:11.053 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:42:11 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 2.87 minutes.; Runtime.totalMemory()=866648064; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 8, xx.xx.xx.xx, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:39299,Error,Error,39299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Error'],['Error']
Availability,"8); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:100); ... 24 more; 05:12:04.045 INFO HaplotypeCallerSpark - Shutting down engine; [May 18, 2017 5:12:04 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 131.63 minutes.; Runtime.totalMemory()=16201547776; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 1.0 failed 1 times, most recent failure: Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayI; ndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGSchedul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:6422,failure,failure,6422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['failure'],['failure']
Availability,8-16T00:09:07.2856913Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2860245Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2861934Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3012792Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3151812Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3156616Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3263061Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3605617Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3694118Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/InfoFieldAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3740413Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/VariantAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3746092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/GenotypeAnnotation.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3759011Z src/main/java/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:2938,error,error,2938,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"8-16T00:09:07.4061591Z location: class ReadFilter; 2022-08-16T00:09:07.4083439Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4092135Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4107682Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4116317Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4117746Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4124264Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T00:09:07.4124816Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-08-16T00:09:07.4125855Z symbol: class BiMap; 2022-08-16T00:09:07.4126189Z location: class LoggingUtils; 2022-08-16T00:09:07.4126674Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:41: error: cannot find symbol; 2022-08-16T00:09:07.4127264Z private static BiMap<Log.LogLevel, java.util.logging.Level> javaUtilLevelNamespaceMap;; 2022-08-16T00:09:07.4127999Z symbol: class BiMap; 2022-08-16T00:09:07.4128334Z location: class LoggingUtils; 2022-08-16T00:09:07.4137968Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:13: error: package com.google.common.base does not exist; 2022-08-16T00:09:07.4139500Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:14: error: package com.google.common.io does not exist; 2022-08-16T00:09:07.4190745Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantCont",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:13058,error,error,13058,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,8-16T22:45:53.6653787Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6657039Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6658760Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6739776Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6889124Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6895571Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6965286Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6965863Z * Returns the STR period at a given position.??; 2022-08-16T22:45:53.6972650Z src/main/java/org/broadinstitute/hellbender/utils/dragstr/DragstrReferenceAnalyzer.java:87: error: unmappable character for encoding ASCII; 2022-08-16T22:45:53.6973221Z * Returns the STR period at a given position.??; 2022-08-16T22:45:53.6981573Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7254348Z src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7492903Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annot,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:4591,error,error,4591,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"8-16T22:45:53.8035658Z location: class ReadFilter; 2022-08-16T22:45:53.8087327Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8103864Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8113680Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8117654Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8118430Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8124030Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T22:45:53.8124383Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-08-16T22:45:53.8124657Z symbol: class BiMap; 2022-08-16T22:45:53.8124810Z location: class LoggingUtils; 2022-08-16T22:45:53.8125227Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:41: error: cannot find symbol; 2022-08-16T22:45:53.8125528Z private static BiMap<Log.LogLevel, java.util.logging.Level> javaUtilLevelNamespaceMap;; 2022-08-16T22:45:53.8125793Z symbol: class BiMap; 2022-08-16T22:45:53.8126059Z location: class LoggingUtils; 2022-08-16T22:45:53.8134767Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:13: error: package com.google.common.base does not exist; 2022-08-16T22:45:53.8135486Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:14: error: package com.google.common.io does not exist; 2022-08-16T22:45:53.8163449Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantCont",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:15096,error,error,15096,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:5888,ERROR,ERROR,5888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912,3,"['ERROR', 'down']","['ERROR', 'down']"
Availability,"80k is what I had easy access to and what I'm the most invested in; benchmarking right now. Master does fine with the same params. It's slow,; but no failures. We decided to split into 1000 shards (Eric is convinced; that there's a substantial startup cost per shard so we do better in total; cpu-hours on fewer shards) and each of those takes about 24 hours. On Thu, May 10, 2018, 11:09 AM Louis Bergelson <notifications@github.com>; wrote:. > @ldgauthier <https://github.com/ldgauthier> You're running 80k? Does that; > run using the current master version of GATK? I assumed you were rerunning; > a 20k shard with the same settings we had used for the 20k.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388082988>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdLdlQoWlC8kjRvJJermDYEjltVUFks5txFgigaJpZM4TOtSm>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388183296:150,failure,failures,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388183296,1,['failure'],['failures']
Availability,"81 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-09 13:35:14 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-09 13:35:14 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-09 13:35:14 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-09 13:35:14 INFO Client:54 - Setting up co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9782,AVAIL,AVAILABLE,9782,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,"81 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Start",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8204,AVAIL,AVAILABLE,8204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,"81 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandle",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8604,AVAIL,AVAILABLE,8604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,84 isActive: false numReads: 0; 12:05:51.476 DEBUG Mutect2 - Processing assembly region at chrM:10785-11084 isActive: false numReads: 0; 12:05:51.489 DEBUG Mutect2 - Processing assembly region at chrM:11085-11384 isActive: false numReads: 0; 12:05:51.501 DEBUG Mutect2 - Processing assembly region at chrM:11385-11684 isActive: false numReads: 0; 12:05:51.513 DEBUG Mutect2 - Processing assembly region at chrM:11685-11984 isActive: false numReads: 0; 12:05:51.526 DEBUG Mutect2 - Processing assembly region at chrM:11985-12284 isActive: false numReads: 0; 12:06:02.022 DEBUG Mutect2 - Processing assembly region at chrM:12285-12584 isActive: false numReads: 0; 12:06:03.941 DEBUG Mutect2 - Processing assembly region at chrM:12585-12729 isActive: false numReads: 44205; 12:06:04.330 DEBUG Mutect2 - Processing assembly region at chrM:12730-13020 isActive: true numReads: 88386; 12:06:10.995 DEBUG ReadThreadingGraph - Recovered 11 of 15 dangling tails; 12:06:11.087 DEBUG ReadThreadingGraph - Recovered 7 of 36 dangling heads; 12:06:11.465 DEBUG Mutect2Engine - Active Region chrM:12730-13020; 12:06:11.470 DEBUG Mutect2Engine - Extended Act Region chrM:12630-13120; 12:06:11.474 DEBUG Mutect2Engine - Ref haplotype coords chrM:12630-13120; 12:06:11.478 DEBUG Mutect2Engine - Haplotype count 128; 12:06:11.481 DEBUG Mutect2Engine - Kmer sizes count 0; 12:06:11.485 DEBUG Mutect2Engine - Kmer sizes values []; 12:08:48.420 DEBUG Mutect2 - Processing assembly region at chrM:13021-13320 isActive: false numReads: 44155; 12:08:49.628 INFO ProgressMeter - chrM:13021 33.1 50 1.5; 12:09:01.241 DEBUG Mutect2 - Processing assembly region at chrM:13321-13620 isActive: false numReads: 55070; 12:09:01.757 DEBUG Mutect2 - Processing assembly region at chrM:13621-13636 isActive: false numReads: 55240; 12:09:02.341 DEBUG Mutect2 - Processing assembly region at chrM:13637-13936 isActive: true numReads: 110273; 12:09:09.957 DEBUG ReadThreadingGraph - Recovered 24 of 26 dangling tails; 12:09:10.041 DEBUG Re,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:19178,Recover,Recovered,19178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"864+29181309; 21/04/13 07:32:24 INFO FileOutputCommitter: Saved output of task 'attempt_20210413073224_0026_r_000001_0' to file:/dev/shm/chr4_GL000008v2_random.g.vcf.gz.parts; 21/04/13 07:32:24 INFO SparkHadoopMapRedUtil: attempt_20210413073224_0026_r_000001_0: Committed; 21/04/13 07:32:24 INFO Executor: Finished task 1.0 in stage 5.0 (TID 106). 762 bytes result sent to driver; 21/04/13 07:32:24 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 106) in 136 ms on localhost (executor driver) (1/3); 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 2; 21/04/13 07:32:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 21/04/13 07:32:24 ERROR Utils: Aborting task; java.lang.IllegalArgumentException: Sequence [VC HC @ chr4_GL000008v2_random:7168-7691 Q. of type=SYMBOLIC alleles=[T*, <NON_REF>] attr={END=7691} GT=[[NA12878 T*/T* GQ 0 DP 0 PL 0,0,0 {MIN_DP=0}]] filters= added out of order currentReferenceIndex: 25, referenceIndex:37; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(Indexing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:2474,failure,failures,2474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,5,"['ERROR', 'failure']","['ERROR', 'failures']"
Availability,"89); - Pinned typing_extensions python package to 4.1.1 to fix conda environment. (#7802); - WeightedSplitInterval fixes [VS-384] [VS-332] (#7795); - Replace Travis with GithubActions (#7754); - Docker build only lfs pulls main/src/resources/large (#7727); - Clean up gatk jars -- looks like we are not passing them properly in the extract (#7788); - Fix typo that broke git lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were trying to grep a binary file (#7837); - Cleanup scripts/variantstore [VS-414] (#7834); - Merge VAT TSV files into single bgzipped file [VS-304] (#7848); - Handle fully and partially loaded samples [VS-262] [VS-258] (#7843); - Ingest Error Handling Fixes [VS-261] (#7841); - First cut at a python notebook to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868); - VET Ingest Validation / Allow Ingest of non-VQSR'ed data (#7870); - Fix AoU workflow bugs (#7874); - Curate input arrays to skip already ingested sample data [VS-246] (#7862); - KM upload GVS product sheet (#7883); - Default extract scatter width [VS-415] (#7878); - Volatile tasks review [VS-447] (#7880); - Update Quickstart Integration for X/Y scaling changes ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:24019,Reliab,Reliability,24019,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,"['Error', 'Reliab']","['Error', 'Reliability']"
Availability,"895); 	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:878); 	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550); 	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:143); 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758); 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750); 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397); 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315); 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1237); 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226); 	at com.luz.push.PushApplication.main(PushApplication.java:10). java.io.IOException: The Application Default Credentials are not available. They are available if running in Google Compute Engine. Otherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.; 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:131); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); 	at com.luz.push.utils.GcmUtils.init(GcmUtils.java:31); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.springframework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:28694,avail,available,28694,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['avail'],['available']
Availability,"8:30:55 INFO util.log: Logging initialized @25356ms; 18/01/09 18:30:55 INFO server.Server: jetty-9.3.z-SNAPSHOT; 18/01/09 18:30:55 INFO server.Server: Started @25495ms; 18/01/09 18:30:55 INFO server.AbstractConnector: Started ServerConnector@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@418f0534{/jobs,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@134a8ead{/jobs/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54247647{/jobs/job,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5463f035{/jobs/job/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44fd7ba4{/stages,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef4cbe1{/stages/pool/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2baac4a7{/storage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:7683,AVAIL,AVAILABLE,7683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,8Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2726493Z src/main/java/org/broadinstitute/hellbender/engine/FeatureContext.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2743559Z src/main/java/org/broadinstitute/hellbender/utils/io/BlockCompressedIntervalStream.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2775681Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2833952Z src/main/java/org/broadinstitute/hellbender/engine/FeatureManager.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2841948Z src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/IntervalArgumentCollection.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2856913Z src/main/java/org/broadinstitute/hellbender/engine/ProgressMeter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2860245Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.2861934Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3012792Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3151812Z src/main/java/org/broadinstitute/hellbender/utils/logging/OneShotLogger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3156616Z src/main/java/org/broadinstitute/hellbender/tools/walkers/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:1876,error,error,1876,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"9 18:30:55 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/01/09 18:30:55 INFO storage.DiskBlockManager: Created local directory at /tmp/sun/blockmgr-b03058dc-763a-449c-bd05-18f3304c01ea; 18/01/09 18:30:55 INFO memory.MemoryStore: MemoryStore started with capacity 2004.6 MB; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering OutputCommitCoordinator; 18/01/09 18:30:55 INFO util.log: Logging initialized @25356ms; 18/01/09 18:30:55 INFO server.Server: jetty-9.3.z-SNAPSHOT; 18/01/09 18:30:55 INFO server.Server: Started @25495ms; 18/01/09 18:30:55 INFO server.AbstractConnector: Started ServerConnector@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@418f0534{/jobs,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@134a8ead{/jobs/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54247647{/jobs/job,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5463f035{/jobs/job/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44fd7ba4{/stages,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69d103f0{/stages/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74fb5b59{/stages/stage,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@26fadd98{/stages/stage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3db6dd52{/stages/pool,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.Se",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:7296,AVAIL,AVAILABLE,7296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,"9 Jul 2022 14:35:24,720 DEBUG: 		at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$null$1(VariantLocusWalker.java:161); 09 Jul 2022 14:35:24,726 DEBUG: 		at java.util.Iterator.forEachRemaining(Iterator.java:116); 09 Jul 2022 14:35:24,731 DEBUG: 		at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 09 Jul 2022 14:35:24,738 DEBUG: 		at java.util.stream.ReferencePipeline$Head.forEachOrdered(ReferencePipeline.java:590); 09 Jul 2022 14:35:24,743 DEBUG: 		at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$2(VariantLocusWalker.java:151); 09 Jul 2022 14:35:24,749 DEBUG: 		at java.util.Iterator.forEachRemaining(Iterator.java:116); 09 Jul 2022 14:35:24,755 DEBUG: 		at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 09 Jul 2022 14:35:24,761 DEBUG: 		at java.util.stream.ReferencePipeline$Head.forEachOrdered(ReferencePipeline.java:590); 09 Jul 2022 14:35:24,767 DEBUG: 		at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:148); 09 Jul 2022 14:35:24,773 DEBUG: 		at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 09 Jul 2022 14:35:24,780 DEBUG: 		at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 09 Jul 2022 14:35:24,786 DEBUG: 		at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 09 Jul 2022 14:35:24,792 DEBUG: 		at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 09 Jul 2022 14:35:24,798 DEBUG: 		at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 09 Jul 2022 14:35:24,804 DEBUG: 		at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 09 Jul 2022 14:35:24,813 DEBUG: 		at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. I thought this was fixed in the prior version. Is this a new error or a regression?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7933:4330,error,error,4330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7933,1,['error'],['error']
Availability,"9); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:242); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:93); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:56); at org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. 21/04/13 07:32:25 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Cancelling stage 5; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage cancelled; 21/04/13 07:32:25 INFO DAGScheduler: ResultStage 5 (runJob at SparkHadoopWriter.scala:78) failed in 0.353 s due to Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 105, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:10803,ERROR,ERROR,10803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['ERROR'],['ERROR']
Availability,"9.8 114664000 5778139.5; 06:46:23.072 INFO ProgressMeter - NC_038255.2:25849821 20.0 115712000 5782366.7; 06:46:33.076 INFO ProgressMeter - NC_038255.2:26067132 20.2 116682000 5782658.4; 06:46:43.076 INFO ProgressMeter - NC_038255.2:26257373 20.3 117691000 5784881.3; 06:46:53.083 INFO ProgressMeter - NC_038255.2:26457381 20.5 118693000 5786693.9; 06:47:03.088 INFO ProgressMeter - NC_038255.2:26643575 20.7 119720000 5789695.5; 06:47:13.106 INFO ProgressMeter - NC_038255.2:26850339 20.8 120726000 5791581.5; 06:47:23.111 INFO ProgressMeter - NC_038255.2:27050560 21.0 121742000 5793973.2; 06:47:33.116 INFO ProgressMeter - NC_038255.2:27256247 21.2 122736000 5795288.5; 06:47:42.432 INFO CombineGVCFs - Shutting down engine; [March 13, 2024 at 6:47:42 AM GMT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 21.46 minutes.; Runtime.totalMemory()=920649728; htsjdk.samtools.util.RuntimeIOException: java.io.IOException: Transport endpoint is not connected; at htsjdk.tribble.readers.TabixIteratorLineReader.readLine(TabixIteratorLineReader.java:48); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.readNextRecord(TabixFeatureReader.java:170); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:205); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:149); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextFeature(FeatureIntervalIterator.java:98); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextNovelFeature(FeatureIntervalIterator.java:74); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.next(FeatureIntervalIterator.java:62); at org.broadinstitute.hellbender.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8735:21979,down,down,21979,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8735,1,['down'],['down']
Availability,"9238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:31739,down,down,31739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['down'],['down']
Availability,"92GB RAM. MarkDuplicatesSpark usually hangs and never finish (even after few days) with log as below:. ```; 11:26:29.511 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.511 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:29.512 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:29.512 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:30.738 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:30.738 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.830 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.830 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:45.831 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:45.831 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 11:26:55.475 INFO FileOutputCommitter - File Output Committer Algorithm version is 1; 11:26:55.475 INFO FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, igno",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8555:1329,failure,failures,1329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8555,1,['failure'],['failures']
Availability,"931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Serve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766:1502,Error,Error,1502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766,1,['Error'],['Error']
Availability,"933:HG2MVDSX5:1:1101:1045:5306 A00257:933:HG2MVDSX5:1:1101:1045:5306; A00257:933:HG2MVDSX5:1:1101:1045:5306 A00257:933:HG2MVDSX5:1:1101:1045:6277; A00257:933:HG2MVDSX5:1:1101:1045:6277 A00257:933:HG2MVDSX5:1:1101:1045:7717; A00257:933:HG2MVDSX5:1:1101:1045:6277 A00257:933:HG2MVDSX5:1:1101:1045:8375; A00257:933:HG2MVDSX5:1:1101:1045:7717 A00257:933:HG2MVDSX5:1:1101:1045:8531; A00257:933:HG2MVDSX5:1:1101:1045:7717 A00257:933:HG2MVDSX5:1:1101:1045:9283; A00257:933:HG2MVDSX5:1:1101:1045:8531 A00257:933:HG2MVDSX5:1:1101:1045:10316; A00257:933:HG2MVDSX5:1:1101:1045:8531 A00257:933:HG2MVDSX5:1:1101:1045:11130; A00257:933:HG2MVDSX5:1:1101:1045:11130 A00257:933:HG2MVDSX5:1:1101:1045:11882; A00257:933:HG2MVDSX5:1:1101:1045:11130 A00257:933:HG2MVDSX5:1:1101:1045:12007; A00257:933:HG2MVDSX5:1:1101:1045:12007 A00257:933:HG2MVDSX5:1:1101:1045:12665; A00257:933:HG2MVDSX5:1:1101:1045:12007 A00257:933:HG2MVDSX5:1:1101:1045:12727; A00257:933:HG2MVDSX5:1:1101:1045:12665 A00257:933:HG2MVDSX5:1:1101:1045:13260; A00257:933:HG2MVDSX5:1:1101:1045:12665 A00257:933:HG2MVDSX5:1:1101:1045:13322; ```. The error above makes sense since the lexicographic difference between `A00257:933:HG2MVDSX5:1:1101:1045:11130` and `A00257:933:HG2MVDSX5:1:1101:1045:8531` is `-7`, the result of `ord(""1"") - ord(""8"")`. #### Expected behavior; The `traverse` function above should keep advancing through the uBAM. Assuming the BAMs to be queryname sorted, the `traverse` function could check the lengths of the names when the `diff` is not zero in https://github.com/broadinstitute/gatk/blob/2b0a558fdb9fdf654e796d5d69a092e26345583b/src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/TransferReadTags.java#L121, advancing the `unmappedSamIterator` if the name of the `currentTargetRead` is larger than the name of `currentUnmappedRead`. . #### Actual behavior; An `java.lang.IllegalStateException: A read found in the aligned bam is not found in the unmapped bam.` exception is raised when in fact the read might exist",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8147:7960,error,error,7960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8147,1,['error'],['error']
Availability,97 DEBUG ReadThreadingGraph - Recovered 7 of 8 dangling tails; 11:41:57.047 DEBUG ReadThreadingGraph - Recovered 2 of 24 dangling heads; 11:41:57.286 DEBUG IntToDoubleFunctionCache - cache miss 136737 > 53234 expanding to 136747; 11:41:57.301 DEBUG IntToDoubleFunctionCache - cache miss 136976 > 136747 expanding to 273496; 11:41:57.935 DEBUG Mutect2Engine - Active Region chrM:8830-9129; 11:41:57.937 DEBUG Mutect2Engine - Extended Act Region chrM:8730-9229; 11:41:57.939 DEBUG Mutect2Engine - Ref haplotype coords chrM:8730-9229; 11:41:57.940 DEBUG Mutect2Engine - Haplotype count 128; 11:41:57.941 DEBUG Mutect2Engine - Kmer sizes count 0; 11:41:57.942 DEBUG Mutect2Engine - Kmer sizes values []; 11:53:42.116 DEBUG Mutect2 - Processing assembly region at chrM:9130-9143 isActive: true numReads: 148251; 11:53:58.336 DEBUG ReadThreadingGraph - Recovered 4 of 9 dangling tails; 11:53:58.398 DEBUG ReadThreadingGraph - Recovered 0 of 20 dangling heads; 11:54:11.645 DEBUG ReadThreadingGraph - Recovered 20 of 23 dangling tails; 11:54:11.670 DEBUG ReadThreadingGraph - Recovered 0 of 60 dangling heads; 11:54:11.843 DEBUG Mutect2Engine - Active Region chrM:9130-9143; 11:54:11.852 DEBUG Mutect2Engine - Extended Act Region chrM:9030-9243; 11:54:11.861 DEBUG Mutect2Engine - Ref haplotype coords chrM:9030-9243; 11:54:11.870 DEBUG Mutect2Engine - Haplotype count 232; 11:54:11.879 DEBUG Mutect2Engine - Kmer sizes count 0; 11:54:11.889 DEBUG Mutect2Engine - Kmer sizes values []; 11:54:21.878 DEBUG IntToDoubleFunctionCache - cache miss 96632 > 95278 expanding to 190558; 11:54:22.252 DEBUG Mutect2 - Processing assembly region at chrM:9144-9301 isActive: false numReads: 273760; 11:54:28.421 DEBUG Mutect2 - Processing assembly region at chrM:9302-9584 isActive: true numReads: 250870; 11:55:47.246 DEBUG ReadThreadingGraph - Recovered 13 of 14 dangling tails; 11:55:47.346 DEBUG ReadThreadingGraph - Recovered 6 of 47 dangling heads; 11:55:47.787 DEBUG Mutect2Engine - Active Region chrM:9302-9584; 1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:16419,Recover,Recovered,16419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"97968 347968 contig; >; > chr1 535988 585988 contig; >; > chr1 2702781 2746290 scaffold; >; >; For what it's worth, your description of your approach sounds like a; sensible one to me.; I am concerned about the size of the data and how we'd access it. I've; chosen the tracts I have because they are small enough to jam into; resources. On Tue, May 1, 2018 at 8:06 AM samuelklee <notifications@github.com> wrote:. > @TedBrookings <https://github.com/TedBrookings> which formats are you; > using, in particular?; >; > In the CNV package, I've taken pains to unify how tabular data are; > represented in Java, depending on whether each record is Locatable or; > whether the collection of records can be associated with a sample name or; > sequence dictionary. This allows us to represent records that extend; > Locatable with multidimensional numerical or non-numerical annotations; > along with some metadata (sample name and sequence dictionary) with a; > minimum of boilerplate. There are also base methods for producing interval; > trees, etc.; >; > However, this unification effort was a quick push I made before release,; > so some polishing or redesigning may be warranted. We may also want to add; > more forms of metadata, etc. if other teams would require more features.; > Another downside is that this code lacks the indexing, NIO support, etc.; > that some of the other standardized/Tribble formats enjoy. For CNV data,; > this isn't a huge issue, but I think it would be nice to unify how we; > represent such data GATK-wide. As I said above, I don't think VCF is the; > correct answer, but certainly it could fit into whatever framework we come; > up with.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGKhCDUca-ZFaXWUoM6bn-LrGlgzx8jDks5tuE_QgaJpZM4TtIPq>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551:2201,down,downside,2201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551,1,['down'],['downside']
Availability,98); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:43954,Error,Error,43954,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Error'],['Error']
Availability,98); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:44700,Error,Error,44700,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Error'],['Error']
Availability,"9:07.4124816Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-08-16T00:09:07.4125855Z symbol: class BiMap; 2022-08-16T00:09:07.4126189Z location: class LoggingUtils; 2022-08-16T00:09:07.4126674Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:41: error: cannot find symbol; 2022-08-16T00:09:07.4127264Z private static BiMap<Log.LogLevel, java.util.logging.Level> javaUtilLevelNamespaceMap;; 2022-08-16T00:09:07.4127999Z symbol: class BiMap; 2022-08-16T00:09:07.4128334Z location: class LoggingUtils; 2022-08-16T00:09:07.4137968Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:13: error: package com.google.common.base does not exist; 2022-08-16T00:09:07.4139500Z src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java:14: error: package com.google.common.io does not exist; 2022-08-16T00:09:07.4190745Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4198885Z src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java:242: error: cannot find symbol; 2022-08-16T00:09:07.4199424Z @VisibleForTesting; 2022-08-16T00:09:07.4200130Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4200630Z location: class ReferenceConfidenceVariantContextMerger; 2022-08-16T00:09:07.4211864Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:7: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4214985Z src/main/java/org/broadinstitute/hellbender/utils/SVInterval.java:41: error: cannot find symbol; 2022-08-16T00:09:07.4215495Z @VisibleForTesting; 2022-08-16T00:09:07.4216081Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4251408Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtils.java:3: error: package com.google.common.annotations does no",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:14095,error,error,14095,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,"9:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:14:13.567 INFO PrintReadsSpark - Deflater: IntelDeflater; 09:14:13.567 INFO PrintReadsSpark - Inflater: IntelInflater; 09:14:13.567 INFO PrintReadsSpark - Initializing engine; 09:14:13.567 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting down engine; [June 8, 2017 9:14:26 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=494927872; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /user/yaron/output.bam because writ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:3409,ERROR,ERROR,3409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['ERROR'],['ERROR']
Availability,"9] malloc+0x169`: . ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000014cfb1d504f9, pid=1182729, tid=1195264; #; # JRE version: OpenJDK Runtime Environment (17.0.3) (build 17.0.3-internal+0-adhoc..src); # Java VM: OpenJDK 64-Bit Server VM (17.0.3-internal+0-adhoc..src, mixed mode, sharing, tiered, compressed oops, compressed class ptrs, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0xaf4f9] malloc+0x169; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h"" (or dumping to /gpfs/gpfs_de6000/home/dalegre/projects/1000-Genomes/jointcalling-test/goast_workflows/JointCalling/test_samples-1000.1.3/core.1182729); #; # If you would like to submit a bug report, please visit:; # https://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; [dalegre@login4601 fdone]$ head -n 20 hs_err_pid1182729.log; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000014cfb1d504f9, pid=1182729, tid=1195264; #; # JRE version: OpenJDK Runtime Environment (17.0.3) (build 17.0.3-internal+0-adhoc..src); # Java VM: OpenJDK 64-Bit Server VM (17.0.3-internal+0-adhoc..src, mixed mode, sharing, tiered, compressed oops, compressed class ptrs, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0xaf4f9] malloc+0x169; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h"" (or dumping to /gpfs/gpfs_de6000/home/dalegre/projects/1000-Genomes/jointcalling-test/goast_workflows/JointCalling/test_samples-1000.1.3/core.1182729); #; # If you would like to submit a bug report, please visit:; # https://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8683#issuecomment-1936285520:1215,error,error,1215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8683#issuecomment-1936285520,1,['error'],['error']
Availability,": ...working... done. Downloading and Extracting Packages. keras-preprocessing- | 36 KB | ########## | 100%; astor-0.8.0 | 46 KB | ########## | 100%; setuptools-36.4.0 | 563 KB | ########## | 100%; termcolor-1.1.0 | 8 KB | ########## | 100%; protobuf-3.11.2 | 635 KB | ########## | 100%; keras-applications-1 | 33 KB | ########## | 100%; readline-6.2 | 606 KB | ########## | 100%; libgfortran-ng-7.3.0 | 1006 KB | ########## | 100%; numpy-1.13.3 | 3.1 MB | ########## | 100%; ```. numpy-1.13.3 is corectly installed . but then . ```; Collecting numpy (from biopython==1.70->-r /root/gatk-4.1.4.0/condaenv.g1uyq0ce.requirements.txt (line 1)); Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB); ```. that does . ```; Found existing installation: numpy 1.13.3; Uninstalling numpy-1.13.3:; Successfully uninstalled numpy-1.13.3; ```. this causes ```gatk DetermineGermlineContigPloidy ```; to exit with an error related to numpy.testing.decorators which is deprecated since numpy 1.15.0 see https://docs.scipy.org/doc/numpy-1.15.0/release.html. ```; Deprecations. Aliases of builtin pickle functions are deprecated, in favor of their unaliased pickle.<func> names:; numpy.loads; numpy.core.numeric.load; numpy.core.numeric.loads; numpy.ma.loads, numpy.ma.dumps; numpy.ma.load, numpy.ma.dump - these functions already failed on python 3 when called with a string.; Multidimensional indexing with anything but a tuple is deprecated. This means that the index list in ind = [slice(None), 0]; arr[ind] should be changed to a tuple, e.g., ind = [slice(None), 0]; arr[tuple(ind)] or arr[(slice(None), 0)]. That change is necessary to avoid ambiguity in expressions such as arr[[[0, 1], [0, 1]]], currently interpreted as arr[array([0, 1]), array([0, 1])], that will be interpreted as arr[array([[0, 1], [0, 1]])] in the future.; Imports from the following sub-modules are deprecated, they",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396:1552,error,error,1552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396,1,['error'],['error']
Availability,": 4%|4 | 4/100 [00:01<00:25, 3.72it/s]; 15:10:06.575 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0018 +/- 0.0019: 5%|5 | 5/100 [00:01<00:25, 3.72it/s]; 15:10:06.844 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0013 +/- 0.0014: 6%|6 | 6/100 [00:01<00:25, 3.72it/s]; 15:10:07.113 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0014 +/- 0.0019: 7%|7 | 7/100 [00:01<00:24, 3.72it/s]; 15:10:07.381 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0011 +/- 0.0011: 8%|8 | 8/100 [00:02<00:24, 3.72it/s]; 15:10:07.649 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0007 +/- 0.0011: 9%|9 | 9/100 [00:02<00:24, 3.73it/s]; 15:10:07.919 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0008 +/- 0.0009: 10%|# | 10/100 [00:02<00:24, 3.72it/s]; 15:10:08.193 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0006: 11%|#1 | 11/100 [00:02<00:24, 3.70it/s]; 15:10:08.463 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0005 +/- 0.0007: 12%|#2 | 12/100 [00:03<00:23, 3.70it/s]; 15:10:08.732 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0006 +/- 0.0007: 13%|#3 | 13/100 [00:03<00:23, 3.70it/s]; 15:10:09.001 INFO gcnvkernel.tasks.inference_task_base - (sampling epoch 1) relative error: 0.0004 +/- 0.0005: 13%|#3 | 13/100 [00:03<00:25, 3.45it/s]; 15:10:09.002 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1): 0%| | 0/1 [00:00<?, ?it/s]; 15:10:09.003 INFO gcnvkernel.tasks.inference_task_base - (ploidy calling epoch 1) ploidy update size: 0.200122: 100%|##########| 1/1 [00:00<00:00, 1605.78it/s]; 15:10:09.004 INFO gcnvkernel.tasks.inference_task_base - (denoising) starting...: 0%| | 0/1000 [00:00<?, ?it/s]; 15:10:09.105 INFO gcnvkernel.tasks.inference_task_base - (denoising epoc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:12454,error,error,12454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['error'],['error']
Availability,": 746:29958; partition 3257: 746:30311; partition 3258: 746:31786; partition 3259: 746:32742; partition 3260: 814:418; partition 3261: 935:388; partition 3262: 1262:412; partition 3263: 1828:953; partition 3264: 2219:1063; partition 3265: 2581:633; partition 3266: 2710:693; partition 3267: 2741:759; partition 3268: 2771:593; partition 3269: 2771:1340; partition 3270: 2815:1030; partition 3271: 2833:1911; partition 3272: 2147483647:-1; partition 3273: 2147483647:-1; partition 3274: 2147483647:-1; partition 3275: 2147483647:-1; partition 3276: 2147483647:-1; partition 3277: 2147483647:-1; partition 3278: 2147483647:-1; partition 3279: 2147483647:-1; partition 3280: 2147483647:-1; partition 3281: 2147483647:-1; partition 3282: 2147483647:-1; partition 3283: 2147483647:-1; partition 3284: 2147483647:-1; partition 3285: 2147483647:-1; partition 3286: 2147483647:-1; partition 3287: 2147483647:-1; partition 3288: 2147483647:-1; 14:53:31.635 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [October 19, 2017 2:53:31 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 1.59 minutes.; Runtime.totalMemory()=15018229760; org.broadinstitute.hellbender.exceptions.GATKException: Partition boundaries are not coordinate sorted.; 	at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.readExternalEvidence(FindBreakpointEvidenceSpark.java:312); 	at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.getMappedQNamesSet(FindBreakpointEvidenceSpark.java:208); 	at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.gatherEvidenceAndWriteContigSamFile(FindBreakpointEvidenceSpark.java:111); 	at org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark.runTool(StructuralVariationDiscoveryPipelineSpark.java:79); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3717#issuecomment-337936683:93098,down,down,93098,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3717#issuecomment-337936683,1,['down'],['down']
Availability,": MemoryStore started with capacity 366.3 MB; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering OutputCommitCoordinator; 17/10/13 18:11:34 INFO util.log: Logging initialized @3816ms; 17/10/13 18:11:34 INFO server.Server: jetty-9.3.z-SNAPSHOT; 17/10/13 18:11:34 INFO server.Server: Started @3902ms; 17/10/13 18:11:34 INFO server.AbstractConnector: Started ServerConnector@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:34 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@710ae6a7{/jobs,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7b211077{/jobs/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62b0bf85{/jobs/job,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f07d414{/jobs/job/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40faff12{/stages,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@223967ea{/stages/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5d7f1e59{/stages/stage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68e47e7{/stages/stage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16ac4d3d{/stages/pool,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@719c1faf{/stages/pool/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f172892{/storage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:6146,AVAIL,AVAILABLE,6146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,": Started o.s.j.s.ServletContextHandler@6bce4140{/storage/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5882b202{/storage/rdd,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b506ed0{/storage/rdd/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f3e805{/environment,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10618775{/environment/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20a3e10c{/executors,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e2a6991{/executors/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f96dd64{/executors/threadDump,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@409732fb{/executors/threadDump/json,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e99e2cb{/static,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478967eb{/,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f2b39a{/api,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18c880ea{/jobs/job/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:55 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6afbe6a1{/stages/stage/kill,null,AVAILABLE,@Spark}; 18/01/09 18:30:56 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.4:4040; 18/01/09 18:30:56 INFO spark.SparkContext: Added JAR file:/opt/NfsDir/BioDir/GATK4/gatk/build",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:9545,AVAIL,AVAILABLE,9545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['AVAIL'],['AVAILABLE']
Availability,: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3952011Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3953755Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3960718Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3962332Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3968675Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3978229Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3984771Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3993495Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4002426Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4005459Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T00:09:07.4005923Z @VisibleForTesting; 2022-08-16T00:09:07.4006520Z symbol: class VisibleForTesting; 2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:9275,error,error,9275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7871768Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7873510Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/AbstractReadThreadingGraph.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7881195Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7882811Z src/main/java/org/broadinstitute/hellbender/utils/pairhmm/PairHMM.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7889039Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/PairHMMLikelihoodCalculationEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7926431Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7973092Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/Kmer.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7983013Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7993443Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7996577Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T22:45:53.7997033Z @VisibleForTesting; 2022-08-16T22:45:53.7997778Z symbol: class VisibleForTesting; 2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:11313,error,error,11313,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270723v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270724v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270725v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270726v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:5172,reliab,reliable,5172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,":06:29.368 INFO ProgressMeter - Lama-PacBio.Chr08:1676524 1.6 4676000 2883156.9; 17:06:39.369 INFO ProgressMeter - Lama-PacBio.Chr17:545310 1.8 9925000 5549291.3; 17:06:49.558 INFO ProgressMeter - Lama-PacBio.Chr20:3003652 2.0 14424000 7365509.5; 17:06:59.558 INFO ProgressMeter - Lama-PacBio.Chr26:426929 2.1 19191000 9031058.8; 17:07:09.558 INFO ProgressMeter - Lama-PacBio.Chr30:1051399 2.3 24396000 10645527.3; 17:07:19.559 INFO ProgressMeter - Lama-PacBio.Chr34:95733 2.5 29543000 12017410.1; 17:07:23.141 INFO DepthOfCoverage - 1031666 read(s) filtered by: WellformedReadFilter ; 0 read(s) filtered by: NotDuplicateReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 1031666 total reads filtered; 17:07:23.142 INFO ProgressMeter - Lama-PacBio.Chr34:1982733 2.5 31430935 12482169.5; 17:07:23.142 INFO ProgressMeter - Traversal complete. Processed 31430935 total loci in 2.5 minutes.; 17:07:23.142 INFO DepthOfCoverage - Shutting down engine; [June 29, 2021 5:07:23 PM GMT] org.broadinstitute.hellbender.tools.walkers.coverage.DepthOfCoverage done. Elapsed time: 2.54 minutes.; Runtime.totalMemory()=244318208; java.lang.ArrayIndexOutOfBoundsException: 0; 	at org.broadinstitute.hellbender.tools.walkers.coverage.CoverageOutputWriter.printIntervalTable(CoverageOutputWriter.java:616); 		at org.broadinstitute.hellbender.tools.walkers.coverage.CoverageOutputWriter.writeOutputIntervalStatistics(CoverageOutputWriter.java:364); 	at org.broadinstitute.hellbender.tools.walkers.coverage.DepthOfCoverage.onTraversalSuccess(DepthOfCoverage.java:397); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1062); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7332:4279,down,down,4279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7332,1,['down'],['down']
Availability,":08.558 INFO Mutect2 - GCS max retries/reopens: 20; 13:24:08.558 INFO Mutect2 - Requester pays: disabled; 13:24:08.558 INFO Mutect2 - Initializing engine; 13:24:09.048 INFO FeatureManager - Using codec VCFCodec to read file file://ref/1000g_pon.hg38.vcf.gz; 13:24:09.207 INFO FeatureManager - Using codec VCFCodec to read file file://ref/af-only-gnomad.hg38.vcf.gz; 13:24:09.374 INFO Mutect2 - Done initializing engine; 13:24:09.435 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 13:24:09.438 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 13:24:09.472 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 13:24:09.472 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 13:24:09.473 INFO IntelPairHmm - Available threads: 24; 13:24:09.473 INFO IntelPairHmm - Requested threads: 4; 13:24:09.473 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 13:24:09.501 INFO ProgressMeter - Starting traversal; 13:24:09.502 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 13:24:19.721 INFO ProgressMeter - chr1:634040 0.2 2460 14443.7; 13:24:29.736 INFO ProgressMeter - chr1:1564703 0.3 7220 21409.5; .; .; .; 15:28:55.286 INFO ProgressMeter - chrM:12891 124.8 11474080 91967.0; 15:29:08.985 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 10.162159898; 15:29:08.986 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 1047.646162184; 15:29:08.986 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 1077.35 sec; 15:29:08.986 INFO Mutect2 - Shutting down engine; [September 25, 2020 3:29:08 PM BST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 125.01 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6851:3601,Avail,Available,3601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851,1,['Avail'],['Available']
Availability,":13.567 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 09:14:13.567 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:14:13.567 INFO PrintReadsSpark - Deflater: IntelDeflater; 09:14:13.567 INFO PrintReadsSpark - Inflater: IntelInflater; 09:14:13.567 INFO PrintReadsSpark - Initializing engine; 09:14:13.567 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@6d21714c] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@6ee12bac].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 09:14:26.202 INFO PrintReadsSpark - Shutting down engine; [June 8, 2017 9:14:26 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=494",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066:3230,ERROR,ERROR,3230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066,1,['ERROR'],['ERROR']
Availability,":16.216 INFO TransferReadTags - Deflater: IntelDeflater; 13:08:16.216 INFO TransferReadTags - Inflater: IntelInflater; 13:08:16.216 INFO TransferReadTags - GCS max retries/reopens: 20; 13:08:16.216 INFO TransferReadTags - Requester pays: disabled; 13:08:16.216 WARN TransferReadTags -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: TransferReadTags is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:08:16.217 INFO TransferReadTags - Initializing engine; 13:08:16.658 INFO TransferReadTags - Done initializing engine; 13:08:16.710 WARN ReadUtils - Skipping index file creation for: /data/reddylab/Alex/tmp/TEST_BAM.with_umis.bam. Index file creation requires reads in coordinate sorted order.; 13:08:16.739 INFO ProgressMeter - Starting traversal; 13:08:16.739 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 13:08:16.741 INFO TransferReadTags - Shutting down engine; [January 5, 2023 1:08:16 PM EST] org.broadinstitute.hellbender.tools.walkers.qc.TransferReadTags done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2612002816; java.lang.IllegalStateException: A read found in the aligned bam is not found in the unmapped bam. This tool assumes reads in both input files are query-name sorted lexicographically (i.e. by Picard SortSam but not by samtools sort): aligned read = A00257:933:HG2MVDSX5:1:1101:1045:11130, unmapped read = A00257:933:HG2MVDSX5:1:1101:1045:8531; at org.broadinstitute.hellbender.tools.walkers.qc.TransferReadTags.traverse(TransferReadTags.java:142); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8147:4877,down,down,4877,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8147,1,['down'],['down']
Availability,":16:21.553 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63 ; ; 17:16:21.554 INFO GenomicsDBImport - Vid Map JSON file will be written to /home/akansha/vivekruhela/pon\_db/vidmap.json ; ; 17:16:21.554 INFO GenomicsDBImport - Callset Map JSON file will be written to /home/akansha/vivekruhela/pon\_db/callset.json ; ; 17:16:21.554 INFO GenomicsDBImport - Complete VCF Header will be written to /home/akansha/vivekruhela/pon\_db/vcfheader.vcf ; ; 17:16:21.554 INFO GenomicsDBImport - Importing to workspace - /home/akansha/vivekruhela/pon\_db ; ; 17:16:21.554 WARN GenomicsDBImport - GenomicsDBImport cannot use multiple VCF reader threads for initialization when the number of intervals is greater than 1. Falling back to serial VCF reader initialization. ; ; 17:16:21.554 INFO ProgressMeter - Starting traversal ; ; 17:16:21.554 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute ; ; 17:16:21.590 INFO GenomicsDBImport - Shutting down engine ; ; \[January 12, 2021 5:16:21 PM IST\] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.09 minutes. ; ; Runtime.totalMemory()=2761949184 ; ; java.lang.IndexOutOfBoundsException: Index: 0 ; ; at java.util.Collections$EmptyList.get(Collections.java:4456) ; ; at org.genomicsdb.model.GenomicsDBImportConfiguration$ImportConfiguration.getColumnPartitions(GenomicsDBImportConfiguration.java:2083) ; ; at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:203) ; ; at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:745) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMai",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7037:5582,down,down,5582,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037,1,['down'],['down']
Availability,":17.382 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Thu Mar 07 16:08:17 UTC 2019] ValidateSamFile --INPUT CQ-NEQAS-2018.ILLUMINA.library.000000000-BCFDC.1.1.sorted.bam --MODE SUMMARY --MAX_OUTPUT 100 --IGNORE_WARNINGS false --VALIDATE_INDEX true --INDEX_VALIDATION_STRINGENCY EXHAUSTIVE --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --SKIP_MATE_VALIDATION false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrows",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:1679,avail,available,1679,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['avail'],['available']
Availability,:186); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:102); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:157); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error reading null at position 0; 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.openStream(SeekableGCSStream.java:126); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.seek(SeekableGCSStream.java:103); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.<init>(SeekableGCSStream.java:59); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAMFile(BAMIO.java:67); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAM(BAMIO.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:178); 	... 20 more; Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; Bad Request; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-264909676:3018,Error,Error,3018,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-264909676,1,['Error'],['Error']
Availability,:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error reading null at position 0; 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.openStream(SeekableGCSStream.java:126); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.seek(SeekableGCSStream.java:103); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.<init>(SeekableGCSStream.java:59); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAMFile(BAMIO.java:67); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAM(BAMIO.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:178); 	... 20 more; Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized; Anonymous users does not have storage.objects.get access to object mw-pathseq-test/hs37d5cs.reads.sorted.bam.; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929:9045,Error,Error,9045,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929,1,['Error'],['Error']
Availability,":189445 131.2 141330000 1077550.0; 02:12:47.714 INFO ProgressMeter - 33:3337674 131.3 141488000 1077385.4; 02:12:57.758 INFO ProgressMeter - 33:4894812 131.5 141812000 1078478.0; 02:13:07.778 INFO ProgressMeter - 33:5541459 131.7 141930000 1078006.1; 02:13:17.801 INFO ProgressMeter - 33:6552319 131.8 142090000 1077853.8; 02:13:29.312 INFO ProgressMeter - 33:6897003 132.0 142231000 1077355.5; 02:13:39.368 INFO ProgressMeter - 33:7093963 132.2 142374000 1077071.3; 02:13:49.368 INFO ProgressMeter - 33:7125494 132.4 142594000 1077377.2; 02:13:59.416 INFO ProgressMeter - 33:7127107 132.5 142752000 1077208.0; 02:14:09.424 INFO ProgressMeter - 33:7726380 132.7 142902000 1076984.3; 02:14:11.026 INFO SplitNCigarReads - 0 read(s) filtered by: AllowAllReadsReadFilter. 02:14:11.026 INFO ProgressMeter - 33:7774932 132.7 142924170 1076934.7; 02:14:11.026 INFO ProgressMeter - Traversal complete. Processed 142924170 total reads in 132.7 minutes.; 02:14:55.471 INFO SplitNCigarReads - Shutting down engine; [February 21, 2021 at 2:14:55 AM PST] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 133.47 minutes.; Runtime.totalMemory()=1283457024; htsjdk.samtools.SAMException: Exception when processing alignment for BAM index DRR029822.14231344 1/2 94b aligned to 1:68375-68468.; at htsjdk.samtools.BAMFileWriter.writeAlignment(BAMFileWriter.java:141); at htsjdk.samtools.SAMFileWriterImpl.close(SAMFileWriterImpl.java:212); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyClose(AsyncSAMFileWriter.java:38); at htsjdk.samtools.util.AbstractAsyncWriter.close(AbstractAsyncWriter.java:89); at org.broadinstitute.hellbender.utils.read.SAMFileGATKReadWriter.close(SAMFileGATKReadWriter.java:26); at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.closeTool(SplitNCigarReads.java:193); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1053); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7091:58691,down,down,58691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7091,1,['down'],['down']
Availability,":25:11 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 71.1 KB, free 331.9 KB); 16/11/16 23:25:11 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 26.0 KB, free 357.9 KB); 16/11/16 23:25:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:40833 (size: 26.0 KB, free: 1247.2 MB); 16/11/16 23:25:11 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 16/11/16 23:25:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:273); 16/11/16 23:25:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks; 16/11/16 23:25:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 1951 bytes); 16/11/16 23:25:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 1); 16/11/16 23:25:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks; 16/11/16 23:25:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms; 16/11/16 23:25:11 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 1); java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrRead",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:11794,ERROR,ERROR,11794,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['ERROR'],['ERROR']
Availability,":308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846); at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111); at java.lang.Thread.run(Thread.java:744); ```. And then warnings about lost tasks:. ```; 16/02/16 11:45:59 WARN TaskSetManager: Lost task 42.1 in stage 0.0 (TID 364, dataflow03.broadinstitute.org): java.io.IOException: Connection from /69.173.65.227:56014 closed; ```. Then errors like this:. ```; 16/02/16 11:47:37 ERROR ErrorMonitor: AssociationError [akka.tcp://sparkDriver@69.173.65.227:47043] -> [akka.tcp://sparkExecutor@dataflow05.broadinstitute.org:36695]: Error [Association failed with [akka.tcp://sparkExecutor@dataflow05.broadinstitute.org:36695]] [; ```. akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dataflow05.broadinstitute.org:36695]; Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dataflow05.broadinstitute.org/69.173.65.230:36695; ]; akka.event.Logging$Error$NoCause$. ```; 16/02/16 11:47:39 ERROR YarnScheduler: Lost executor 37 on dataflow02.broadinstitute.org: remote Rpc client disassociated; ```. This seems to be causing tasks to be re-queued and executed, which hurts performance. The command line I'm using is:. ```; gatk-launch FindBadGenomicKmersSpark --reference hdfs:///user/cwhelan/reference/Homo_sapiens_assembly19.2bit --output bad_kmers_v5_cl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491:5461,error,errors,5461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491,1,['error'],['errors']
Availability,":33:06.617 INFO FastaAlternateReferenceMaker - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:33:06.618 INFO FastaAlternateReferenceMaker - Deflater: IntelDeflater; 15:33:06.618 INFO FastaAlternateReferenceMaker - Inflater: IntelInflater; 15:33:06.618 INFO FastaAlternateReferenceMaker - GCS max retries/reopens: 20; 15:33:06.619 INFO FastaAlternateReferenceMaker - Requester pays: disabled; 15:33:06.619 INFO FastaAlternateReferenceMaker - Initializing engine; 15:33:06.870 INFO FeatureManager - Using codec VCFCodec to read file file:///mnt/research/Hausbeck_group/Lukasko/BotrytisDNASeq/CCR7/ConservedGenes/VCFs/AI7.vcf; 15:33:06.936 INFO IntervalArgumentCollection - Processing 4444 bp from intervals; 15:33:06.939 INFO FastaAlternateReferenceMaker - Done initializing engine; 15:33:06.949 INFO ProgressMeter - Starting traversal; 15:33:06.949 INFO ProgressMeter - Current Locus Elapsed Minutes Bases Processed Bases/Minute; 15:33:07.194 INFO FastaAlternateReferenceMaker - Shutting down engine; [July 18, 2023 at 3:33:07 PM EDT] org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2076049408; java.lang.IllegalArgumentException: Illegal base [ ] seen in the allele; at htsjdk.variant.variantcontext.Allele.create(Allele.java:251); at htsjdk.variant.variantcontext.Allele.create(Allele.java:402); at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.lambda$handlePosition$0(FastaAlternateReferenceMaker.java:176); at java.base/java.util.Optional.orElseGet(Optional.java:369); at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.handlePosition(FastaAlternateReferenceMaker.java:176); at org.broadinstitute.hellbender.tools.walkers.fasta.FastaAlternateReferenceMaker.apply(FastaAlternateReferenceMaker.java:141); at org.broadinstitute.hellbender.engine.ReferenceWalker.traverse(ReferenceWalker.java:55); at org.broadinstitute.hellbender.engine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8427:4633,down,down,4633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8427,1,['down'],['down']
Availability,":34 INFO server.Server: Started @3902ms; 17/10/13 18:11:34 INFO server.AbstractConnector: Started ServerConnector@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:34 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@710ae6a7{/jobs,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7b211077{/jobs/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62b0bf85{/jobs/job,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f07d414{/jobs/job/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40faff12{/stages,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@223967ea{/stages/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5d7f1e59{/stages/stage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@68e47e7{/stages/stage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16ac4d3d{/stages/pool,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@719c1faf{/stages/pool/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f172892{/storage,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@45f9d394{/storage/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3a588b5f{/storage/rdd,null,AVAILABLE,@Spark}; 17/10/13 18:11:34 INFO handler.ContextHandler: Started o.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:6403,AVAIL,AVAILABLE,6403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['AVAIL'],['AVAILABLE']
Availability,":39:44 INFO org.spark_project.jetty.server.Server: Started @3988ms; 17/11/27 20:39:44 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@7fbe38a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/27 20:39:44 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/27 20:39:45 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at droazen-test-cluster-m/10.240.0.10:8032; 17/11/27 20:39:47 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1511814592376_0002; 17/11/27 20:39:52 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@7fbe38a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 20:39:52.363 INFO CountReadsSpark - Shutting down engine; [November 27, 2017 8:39:52 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=630718464; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:340); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:74); 	at com.google.cloud.RetryHelper.runWithRetries(Ret",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:5681,Error,Error,5681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['Error'],['Error']
Availability,:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3993495Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4002426Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4005459Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T00:09:07.4005923Z @VisibleForTesting; 2022-08-16T00:09:07.4006520Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4006876Z location: class PileupElement; 2022-08-16T00:09:07.4015304Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4023160Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4025208Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4026746Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4037886Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:200: error: cannot find symbol; 2022-08-16T00:09:07.4038351Z @VisibleForTesting; 2022-08-16T00:09:07.4038957Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4039323Z location: class CountingReadFilter; 2022-08-16T00:09:07.4039849Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T00:09:07.4040311Z @VisibleForTesting; 2022-08-16T00:09:07.4040921Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4041294Z location: class CountingVariantFilter; ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:10627,error,error,10627,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7983013Z src/main/java/org/broadinstitute/hellbender/utils/pileup/ReadPileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7993443Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7996577Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupElement.java:315: error: cannot find symbol; 2022-08-16T22:45:53.7997033Z @VisibleForTesting; 2022-08-16T22:45:53.7997778Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.7998135Z location: class PileupElement; 2022-08-16T22:45:53.8006697Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/LeftAlignAndTrimVariants.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8013274Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8014882Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8016302Z src/main/java/org/broadinstitute/hellbender/utils/Utils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8023734Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingReadFilter.java:200: error: cannot find symbol; 2022-08-16T22:45:53.8023874Z @VisibleForTesting; 2022-08-16T22:45:53.8024147Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8024320Z location: class CountingReadFilter; 2022-08-16T22:45:53.8024635Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T22:45:53.8024772Z @VisibleForTesting; 2022-08-16T22:45:53.8025036Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8025212Z location: class CountingVariantFilter; ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:12665,error,error,12665,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,":43:34.915 INFO PostprocessGermlineCNVCalls - Writing intervals VCF file to /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19/vcfs/sample.vcf...; 12:43:34.916 INFO PostprocessGermlineCNVCalls - Analyzing shard 1 / 3...; 12:43:37.965 INFO PostprocessGermlineCNVCalls - Analyzing shard 2 / 3...; 12:43:40.679 INFO PostprocessGermlineCNVCalls - Analyzing shard 3 / 3...; 12:43:43.248 INFO PostprocessGermlineCNVCalls - Generating segments VCF file...; 12:44:50.045 INFO PostprocessGermlineCNVCalls - Writing segments VCF file to /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19/vcfs/sample.segments.vcf...; 12:44:50.129 INFO PostprocessGermlineCNVCalls - Generating denoised copy ratios...; 12:44:50.928 INFO PostprocessGermlineCNVCalls - Writing denoised copy ratios to /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19/vcfs/sample.copy_ratios.tsv...; 12:44:51.493 INFO PostprocessGermlineCNVCalls - PostprocessGermlineCNVCalls complete.; 12:44:51.493 INFO PostprocessGermlineCNVCalls - Shutting down engine; [October 29, 2020 12:44:51 PM MSK] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 1.40 minutes.; Runtime.totalMemory()=4294443008; Using GATK jar /home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar PostprocessGermlineCNVCalls --model-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0001_of_10/cohort-model/ --model-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0002_of_10/cohort-model/ --model-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0003_of_10/cohort-model/ --calls-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0001_of_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924:4996,down,down,4996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924,1,['down'],['down']
Availability,":44:1:689:1:1; chr22	19895477	CNV_chr22_19895477_19901476	N	<DUP>	2.39	.	END=19901476	GT:CN:NP:QA:QS:QSE:QSS	./.:3:6:1:2:1:0; chr22	19901477	CNV_chr22_19901477_19946476	N	<DEL>	114.12	.	END=19946476	GT:CN:NP:QA:QS:QSE:QSS	1/1:0:45:0:114:1:1; chr22	19946477	CNV_chr22_19946477_19971476	N	<DUP>	4.69	.	END=19971476	GT:CN:NP:QA:QS:QSE:QSS	./.:3:25:0:5:2:0; chr22	19971477	CNV_chr22_19971477_20003000	N	<DEL>	96.55	.	END=20003000	GT:CN:NP:QA:QS:QSE:QSS	1/1:0:32:0:97:2:2. ```. #### Actual behavior. - `gatkgermlinecnvcaller_genotyped-intervals-COHORT_0.woTimestamp.vcf` (`##contig` cut from header and only first 5 chr22 CNVs present). ```; ##fileformat=VCFv4.2; ##FORMAT=<ID=CN,Number=1,Type=Integer,Description=""Copy number maximum a posteriori value"">; ##FORMAT=<ID=CNLP,Number=.,Type=Integer,Description=""Copy number log posterior (in Phred-scale) rounded down"">; ##FORMAT=<ID=CNQ,Number=1,Type=Integer,Description=""Genotype call quality as the difference between the best and second best phred-scaled log posterior scores"">; ##FORMAT=<ID=GT,Number=1,Type=Integer,Description=""Genotype"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""End coordinate of the variant"">; ##contig=<ID=chr1,length=248956422,assembly=GRCh38.d1.vd1>; ...; ##contig=<ID=HPV-mSD2,length=7300,assembly=GRCh38.d1.vd1>; ##source=PostprocessGermlineCNVCalls; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	E07002_normal; chr1	10000	CNV_chr1_10000_10999	N	<DEL>,<DUP>	.	.	END=10999	GT:CN:CNLP:CNQ	0:2:30,32,0,33,33,33:30; chr1	11000	CNV_chr1_11000_11999	N	<DEL>,<DUP>	.	.	END=11999	GT:CN:CNLP:CNQ	0:2:30,32,0,33,33,33:30; chr1	12000	CNV_chr1_12000_12999	N	<DEL>,<DUP>	.	.	END=12999	GT:CN:CNLP:CNQ	0:2:30,32,0,33,33,33:30; chr1	13000	CNV_chr1_13000_13999	N	<DEL>,<DUP>	.	.	END=13999	GT:CN:CNLP:CNQ	0:2:30,32,0,33,33,33:30; chr1	14000	CNV_chr1_14000_14999	N	<DEL>,<DUP>	.	.	END=14999	GT:CN:CNLP:CNQ	0:2:29,32,0,33,33,33:29; chr1	15000	CNV_chr1_15000_15999	N	<DEL>,<DUP>	.	.	END=15999	GT:CN:CNLP:CNQ	0:2:29,32,0,33,33,33:29; chr1	1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8628:19661,down,down,19661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8628,1,['down'],['down']
Availability,":49.226 INFO GenomicsDBImport - Done importing batch 2/5; 23 Feb 2022 18:26:19,107 DEBUG: 	18:26:19.105 INFO GenomicsDBImport - Done importing batch 3/5; 23 Feb 2022 19:20:18,500 DEBUG: 	19:20:18.478 INFO GenomicsDBImport - Done importing batch 4/5; 24 Feb 2022 16:51:19,017 DEBUG: 	[TileDB::utils] Error: (gzip_handle_error) Cannot decompress with GZIP: inflateInit error: Z_MEM_ERROR; 24 Feb 2022 16:51:19,048 DEBUG: 	[TileDB::Codec] Error: Could not decompress with GZIP.; 24 Feb 2022 16:51:19,056 DEBUG: 	[TileDB::ReadState] Error: Cannot decompress tile for /home/exacloud/gscratch/prime-seq/workDir/0950f56b-7565-103a-a738-f8f3fc8675d2/Job2.work/WGS_1852_consolidated.gdb/2$1$196197964/__e7217c9e-767d-4295-b75a-9162c22c6996139785909643008_1613563029631/END.tdb.; 24 Feb 2022 16:51:51,388 DEBUG: 	16:51:51.388 erro NativeGenomicsDB - pid=225263 tid=225739 VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,405 DEBUG: 	TileDB error message : ; 24 Feb 2022 16:51:51,412 DEBUG: 	terminate called after throwing an instance of 'VariantStorageManagerException'; 24 Feb 2022 16:51:51,419 DEBUG: 	 what(): VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,427 DEBUG: 	TileDB error message : ; 24 Feb 2022 16:52:27,478 WARN : 	process exited with non-zero value: 134; ```. Does that give anything to suggest troubleshooting steps?. The full command is:; ```; /home/exacloud/gscratch/prime-seq/java/java8/bin/java \; 	Xmx497g -Xms497g -Xss2m \; 	-jar /home/exacloud/gscratch/prime-seq/bin/GenomeAnalysisTK4.jar \; 	GenomicsDBImport \; 	-V 25780.g.vcf.gz \; 	-V <total of 92 gVCFs> \; 	--genomicsdb-update-workspace-path WGS_1852_consolidated.gdb \; 	--batch-size 10 \; 	--reader-threads 12 \; 	--consolidate \; 	--genomicsdb-shared-posixfs-optimizations \; 	--bypass-feature-reader \; 	-R 128_Mmul_10.fasta; ```. this is GATK v4.2.5.0. Thanks i advance for any ideas.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022:1963,Error,Error,1963,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022,4,"['Error', 'error']","['Error', 'error']"
Availability,:53.8267814Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8268598Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8269986Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8270563Z [0K; 2022-08-16T22:45:53.8270698Z [0K; 2022-08-16T22:45:53.8270832Z [0K; 2022-08-16T22:45:53.8272441Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 31s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/transformers/DRAGENMappingQualityReadTransformer.java:3: error: package com.google.common.annotations does not exist[0K; 2022-08-16T22:45:53.8283859Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8284709Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8288203Z src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8294852Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8295684Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8296401Z src/main/java/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:18491,error,error,18491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,":54 - Removed TaskSet 13.0, whose tasks have all completed, from pool; 2019-05-19 19:09:41 INFO DAGScheduler:54 - ResultStage 13 (foreach at BwaMemIndexCache.java:84) finished in 2.117 s; 2019-05-19 19:09:41 INFO DAGScheduler:54 - Job 9 finished: foreach at BwaMemIndexCache.java:84, took 2.128154 s; 2019-05-19 19:09:41 INFO AbstractConnector:318 - Stopped Spark@42576db9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-05-19 19:09:41 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4040; 2019-05-19 19:09:41 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-05-19 19:09:41 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-05-19 19:09:41 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-05-19 19:09:41 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-05-19 19:09:41 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-05-19 19:09:41 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-05-19 19:09:41 INFO MemoryStore:54 - MemoryStore cleared; 2019-05-19 19:09:41 INFO BlockManager:54 - BlockManager stopped; 2019-05-19 19:09:41 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-05-19 19:09:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-05-19 19:09:41 INFO SparkContext:54 - Successfully stopped SparkContext; 19:09:41.578 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 19, 2019 7:09:41 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 44.89 minutes.; Runtime.totalMemory()=21646802944; htsjdk.samtools.util.RuntimeIOException: Error opening file: file:///restricted/projectnb/casa/wgs.hg38/pipelines/sv/gatk.sv/temp/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.contig-sam-file.sam; at htsjdk.samtools.SAMFileWr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590:3624,down,down,3624,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590,4,['down'],['down']
Availability,:54.462 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:55.715 DEBUG Mutect2 - Processing assembly region at chrM:13945-14244 isActive: false numReads: 54745; 12:13:56.962 DEBUG Mutect2 - Processing assembly region at chrM:14245-14544 isActive: false numReads: 0; 12:13:56.973 DEBUG Mutect2 - Processing assembly region at chrM:14545-14844 isActive: false numReads: 0; 12:13:56.984 DEBUG Mutect2 - Processing assembly region at chrM:14845-15144 isActive: false numReads: 0; 12:13:56.995 DEBUG Mutect2 - Processing assembly region at chrM:15145-15444 isActive: false numReads: 0; 12:13:57.009 DEBUG Mutect2 - Processing assembly region at chrM:15445-15744 isActive: false numReads: 0; 12:13:57.027 INFO ProgressMeter - chrM:15445 38.3 60 1.6; 12:13:57.035 DEBUG Mutect2 - Processing assembly region at chrM:15745-15960 isActive: false numReads: 14; 12:13:57.047 DEBUG Mutect2 - Processing assembly region at chrM:15961-16230 isActive: true numReads: 30; 12:13:57.055 DEBUG ReadThreadingGraph - Recovered 1 of 1 dangling tails; 12:13:57.063 DEBUG ReadThreadingGraph - Recovered 0 of 1 dangling heads; 12:13:57.096 DEBUG ReadThreadingGraph - Recovered 3 of 3 dangling tails; 12:13:57.106 DEBUG ReadThreadingGraph - Recovered 3 of 5 dangling heads; 12:13:57.464 DEBUG Mutect2Engine - Active Region chrM:15961-16230; 12:13:57.469 DEBUG Mutect2Engine - Extended Act Region chrM:15861-16299; 12:13:57.472 DEBUG Mutect2Engine - Ref haplotype coords chrM:15861-16299; 12:13:57.476 DEBUG Mutect2Engine - Haplotype count 111; 12:13:57.479 DEBUG Mutect2Engine - Kmer sizes count 0; 12:13:57.482 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:58.821 DEBUG Mutect2 - Processing assembly region at chrM:16231-16299 isActive: false numReads: 15; 12:13:58.938 INFO Mutect2 - 0 read(s) filtered by: MappingQualityReadFilter ; 0 read(s) filtered by: MappingQualityNotZeroReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; 0 read(s) filtered by: PassesVen,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:22201,Recover,Recovered,22201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,":55910600 0.9 186370 213817.0; 13:40:55.466 INFO HaplotypeCaller - 0 read(s) filtered by: MappingQualityReadFilter; 0 read(s) filtered by: MappingQualityAvailableReadFilter; 0 read(s) filtered by: MappedReadFilter; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter; 0 read(s) filtered by: NotDuplicateReadFilter; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter; 0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter; 0 read(s) filtered by: GoodCigarReadFilter; 0 read(s) filtered by: WellformedReadFilter; 0 total reads filtered out of 18 reads processed; 13:40:55.466 INFO ProgressMeter - chr19:61430410 1.0 204773 210541.8; 13:40:55.467 INFO ProgressMeter - Traversal complete. Processed 204773 total regions in 1.0 minutes.; 13:40:55.707 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.096771218; 13:40:55.708 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.04 sec; 13:40:55.709 INFO HaplotypeCaller - Shutting down engine; [October 26, 2023 at 1:40:55 PM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.99 minutes.; Runtime.totalMemory()=2617245696; ```. ```; ##source=HaplotypeCaller; ##bcftools_viewVersion=1.16+htslib-1.16; ##bcftools_viewCommand=view -c1 output.g.vcf; Date=Thu Oct 26 13:40:56 2023; ##bcftools_annotateVersion=1.16+htslib-1.16; ##bcftools_annotateCommand=annotate -x INFO,FORMAT/SB,FORMAT/PL; Date=Thu Oct 26 13:40:56 2023; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT CGAAGAGGTAGGTGCGAG-1; chr19 55910646 . AC A,<NON_REF> 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9,0:15:99:0|1:55910646_AC_A:55910646; chr19 55910648 . AAATCCCCC A,<NON_REF> 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9,0:15:99:0|1:55910646_AC_A:55910646; chr19 55910653 . CCCCAT *,C,<NON_REF> 227.84 . . GT:AD:DP:GQ:PGT:PID:PS 2|1:0,9,6,0:15:99:1|0:55910646_AC_A:55910646; chr19 55910675 . T C,<NON_REF> 30.64 . . GT:AD:DP:GQ 0/1:13,2,0:15:38; ```. ```; Using GATK jar /omics/group",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195:15606,down,down,15606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195,1,['down'],['down']
Availability,":56:44.709 INFO HaplotypeCaller - GCS max retries/reopens: 20; 03:56:44.709 INFO HaplotypeCaller - Requester pays: disabled; 03:56:44.709 INFO HaplotypeCaller - Initializing engine; 03:56:45.204 INFO FeatureManager - Using codec BEDCodec to read file file:///data/b37.chr13.bed; 03:56:45.276 INFO IntervalArgumentCollection - Processing 595907 bp from intervals; 03:56:45.305 INFO HaplotypeCaller - Done initializing engine; 03:56:45.324 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 03:56:45.349 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.2.2.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:56:45.351 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.2.2.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:56:45.373 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 03:56:45.375 INFO IntelPairHmm - Available threads: 8; 03:56:45.375 INFO IntelPairHmm - Requested threads: 4; 03:56:45.375 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 03:56:45.415 INFO ProgressMeter - Starting traversal; 03:56:45.416 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 03:56:46.180 WARN VariantAnnotatorEngine - Jumbo genotype annotations requested but fragment likelihoods or haplotype likelihoods were not given.; 03:56:46.210 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position 13:32911888 and possibly subsequent; at least 10 samples must have called genotypes; 03:56:46.621 INFO HaplotypeCaller - 1 read(s) filtered by: MappingQualityReadFilter ; 0 read(s) filtered by: MappingQualityAvailableReadFilter ; 0 read(s) filtered by: MappedReadFilter ; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter ; 57 read(s) filtered by: NotDuplicateReadFilter ; 0 read(s) filtered by: PassesVendorQualityCheckReadFilte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8149:5331,Avail,Available,5331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8149,1,['Avail'],['Available']
Availability,":58:33.933 INFO HaplotypeCaller - GCS max retries/reopens: 20; 03:58:33.933 INFO HaplotypeCaller - Requester pays: disabled; 03:58:33.934 INFO HaplotypeCaller - Initializing engine; 03:58:34.384 INFO FeatureManager - Using codec BEDCodec to read file file:///data/b37.chr13.bed; 03:58:34.461 INFO IntervalArgumentCollection - Processing 595907 bp from intervals; 03:58:34.491 INFO HaplotypeCaller - Done initializing engine; 03:58:34.509 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 03:58:34.532 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:58:34.536 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:58:34.580 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 03:58:34.582 INFO IntelPairHmm - Available threads: 8; 03:58:34.582 INFO IntelPairHmm - Requested threads: 4; 03:58:34.582 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 03:58:34.623 INFO ProgressMeter - Starting traversal; 03:58:34.623 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 03:58:35.812 INFO HaplotypeCaller - 58 read(s) filtered by: ((((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter) AND WellformedReadFilter); 58 read(s) filtered by: (((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter); 58 read(s) filt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8149:11643,Avail,Available,11643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8149,1,['Avail'],['Available']
Availability,":781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8865,AVAIL,AVAILABLE,8865,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['AVAIL'],['AVAILABLE']
Availability,":781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9126,AVAIL,AVAILABLE,9126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,":; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Build file '/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle' line: 102; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * What went wrong:; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] A problem occurred evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at or",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:1824,ERROR,ERROR,1824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,":; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workbench:; external: true; ```; - Hadoop:; ```; version: '3'; services:; namenode:; image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - namenode:/hadoop/dfs/name; environment:; - CLUSTER_NAME=test; env_file:; - ./hadoop.env; deploy:; mode: replicated; replicas: 1; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50070; ports:; - 8334:50070; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/output/:/output/; - /data/ngs/:/ngs/; datanode:; image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - datanode:/hadoop/dfs/data; environment:; SERVICE_PRECONDITION: ""namenode:50070""; # depends_on:; # - namenode; env_file:; - ./hadoop.env; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50075. volumes:; datanode:; namenode:. networks:; workbench:; external: true; ```; the datanodes and namenode and spark master and workers are all working.; My hardware resources are:; 16 core and 1Tb memory ssd and 56Gb ram for 3 machines. I have this problem when I launch the version(GATK) v4.0.4.0 but not with this version v4.0.2.0-4-gb59d863-SNAPSHOT:. >java.lang.IllegalStateException: Duplicate key -1; 	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.uti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:3121,failure,failure,3121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['failure'],['failure']
Availability,:thumbsup: ready to merge once the test passes (probably a transient Travis error),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5471#issuecomment-443544817:76,error,error,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5471#issuecomment-443544817,1,['error'],['error']
Availability,"; - Spark. ```; version: '3'; services:; spark-master:; image: atahualpa/spark-master:GATK4.0.4; networks:; - workbench; deploy:; replicas: 1; mode: replicated; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8080; env_file:; - ./hadoop.env; ports:; - 8333:8080; - 4040:4040; - 6066:6066; - 7077:7077; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/fastq/:/fastq/; - /data0/NGS-SparkGATK/NGS-SparkGATK/:/NGS-SparkGATK/; - /data/ngs/:/ngs/; - /data0/output/:/output/; spark-worker:; image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8; networks:; - workbench; environment:; - SPARK_MASTER=spark://spark-master:7077; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 8081. env_file:; - ./hadoop.env; volumes:; - reference-image:/reference_image. reference:; image: vzzarr/reference:hg19_img; networks:; - workbench; deploy:; mode: global; restart_policy:; condition: on-failure; tty: true #keeps the container alive; volumes:; - reference-image:/reference_image. volumes:; reference-image:. networks:; workbench:; external: true; ```; - Hadoop:; ```; version: '3'; services:; namenode:; image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - namenode:/hadoop/dfs/name; environment:; - CLUSTER_NAME=test; env_file:; - ./hadoop.env; deploy:; mode: replicated; replicas: 1; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50070; ports:; - 8334:50070; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/output/:/output/; - /data/ngs/:/ngs/; datanode:; image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - datanode:/hadoop/dfs/data; environment:; SERVICE_PRECONDITION: ""namenode:50070""; # depends_on:; # - namenode; env_file:; - ./hadoop.env; deploy:; mode: global; restart_policy:; condition: on-failure; labels",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:2152,failure,failure,2152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,2,"['alive', 'failure']","['alive', 'failure']"
Availability,"; --spark-verbosity DEBUG \; -- --spark-runner SPARK --spark-master yarn-cluster \; # --conf 'spark.submit.deployMode=cluster'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; -rw-r--r-- 3 hadoop supergroup 113008112 2020-07-29 15:54 hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; ```; When I specify input as: `hdfs://cromwellhadooptest/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, (i.e. without the port) I get the same error. **Stack trace for this**:; ```; ***********************************************************************; A USER ERROR has occurred: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MissingReference: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.checkFastaPath(CachingIndexedFastaSequenceFile.java:173); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:143); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSeque",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730:2321,error,error,2321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730,1,['error'],['error']
Availability,; 11:35:48.094 DEBUG ReadThreadingGraph - Recovered 17 of 20 dangling tails; 11:35:48.198 DEBUG ReadThreadingGraph - Recovered 16 of 50 dangling heads; 11:35:48.511 DEBUG IntToDoubleFunctionCache - cache miss 2389 > 10 expanding to 2399; 11:35:48.874 DEBUG Mutect2Engine - Active Region chrM:2544-2841; 11:35:48.874 DEBUG Mutect2Engine - Extended Act Region chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Ref haplotype coords chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Haplotype count 128; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:08.907 INFO ProgressMeter - chrM:2544 0.4 10 22.3; 11:36:08.954 DEBUG Mutect2 - Processing assembly region at chrM:2842-2920 isActive: false numReads: 4726; 11:36:09.094 DEBUG Mutect2 - Processing assembly region at chrM:2921-3202 isActive: true numReads: 4600; 11:36:09.663 DEBUG ReadThreadingGraph - Recovered 1 of 2 dangling tails; 11:36:09.671 DEBUG ReadThreadingGraph - Recovered 4 of 7 dangling heads; 11:36:09.750 DEBUG Mutect2Engine - Active Region chrM:2921-3202; 11:36:09.750 DEBUG Mutect2Engine - Extended Act Region chrM:2821-3302; 11:36:09.750 DEBUG Mutect2Engine - Ref haplotype coords chrM:2821-3302; 11:36:09.751 DEBUG Mutect2Engine - Haplotype count 32; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:14.909 DEBUG Mutect2 - Processing assembly region at chrM:3203-3502 isActive: false numReads: 2398; 11:36:15.137 DEBUG Mutect2 - Processing assembly region at chrM:3503-3702 isActive: false numReads: 2587; 11:36:15.184 DEBUG Mutect2 - Processing assembly region at chrM:3703-3943 isActive: true numReads: 5164; 11:36:15.511 DEBUG ReadThreadingGraph - Recovered 3 of 5 dangling tails; 11:36:15.517 DEBUG ReadThreadingGraph - Recovered 1 of 5 dangling heads; 11:36:15.911 DEBUG ReadThreadingGraph - Recovered 34 of 41 dangling tails; 11:36:15.932 DEBUG ReadThreadingGraph - Recovered 13 of 31 d,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:10145,Recover,Recovered,10145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,; 12:05:51.465 DEBUG Mutect2 - Processing assembly region at chrM:10485-10784 isActive: false numReads: 0; 12:05:51.476 DEBUG Mutect2 - Processing assembly region at chrM:10785-11084 isActive: false numReads: 0; 12:05:51.489 DEBUG Mutect2 - Processing assembly region at chrM:11085-11384 isActive: false numReads: 0; 12:05:51.501 DEBUG Mutect2 - Processing assembly region at chrM:11385-11684 isActive: false numReads: 0; 12:05:51.513 DEBUG Mutect2 - Processing assembly region at chrM:11685-11984 isActive: false numReads: 0; 12:05:51.526 DEBUG Mutect2 - Processing assembly region at chrM:11985-12284 isActive: false numReads: 0; 12:06:02.022 DEBUG Mutect2 - Processing assembly region at chrM:12285-12584 isActive: false numReads: 0; 12:06:03.941 DEBUG Mutect2 - Processing assembly region at chrM:12585-12729 isActive: false numReads: 44205; 12:06:04.330 DEBUG Mutect2 - Processing assembly region at chrM:12730-13020 isActive: true numReads: 88386; 12:06:10.995 DEBUG ReadThreadingGraph - Recovered 11 of 15 dangling tails; 12:06:11.087 DEBUG ReadThreadingGraph - Recovered 7 of 36 dangling heads; 12:06:11.465 DEBUG Mutect2Engine - Active Region chrM:12730-13020; 12:06:11.470 DEBUG Mutect2Engine - Extended Act Region chrM:12630-13120; 12:06:11.474 DEBUG Mutect2Engine - Ref haplotype coords chrM:12630-13120; 12:06:11.478 DEBUG Mutect2Engine - Haplotype count 128; 12:06:11.481 DEBUG Mutect2Engine - Kmer sizes count 0; 12:06:11.485 DEBUG Mutect2Engine - Kmer sizes values []; 12:08:48.420 DEBUG Mutect2 - Processing assembly region at chrM:13021-13320 isActive: false numReads: 44155; 12:08:49.628 INFO ProgressMeter - chrM:13021 33.1 50 1.5; 12:09:01.241 DEBUG Mutect2 - Processing assembly region at chrM:13321-13620 isActive: false numReads: 55070; 12:09:01.757 DEBUG Mutect2 - Processing assembly region at chrM:13621-13636 isActive: false numReads: 55240; 12:09:02.341 DEBUG Mutect2 - Processing assembly region at chrM:13637-13936 isActive: true numReads: 110273; 12:09:09.957 DEBUG Rea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:19103,Recover,Recovered,19103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Recover'],['Recovered']
Availability,"; 13:16:10.652 INFO gcnvkernel.tasks.inference_task_base -; Stderr: Traceback (most recent call last):; File ""/tmp/die9s/cohort_determine_ploidy_and_depth.861556744637254264.py"", line 106, in <module>; gcnvkernel.io_ploidy.PloidyModelWriter(ploidy_config, ploidy_workspace,; AttributeError: module 'gcnvkernel.io.io_ploidy' has no attribute 'PloidyModelWriter'. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:365); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:263); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. I also know that I should post errors in the GATK forum, but when I do this I get the following error message :; ``` { ""Code"": 403, ""Exception"": ""You need the Garden.Community.Manage permission to do that."", ""Class"": ""Gdn_UserException"" }```. Thanks in advance; Stefan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4679:2185,error,errors,2185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4679,2,['error'],"['error', 'errors']"
Availability,"; 13:56:52.187 INFO GenotypeGVCFs - Picard Version: 2.22.8; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:3304,down,down,3304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,1,['down'],['down']
Availability,"; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@5",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4966,ERROR,ERROR,4966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['ERROR'],['ERROR']
Availability,"; 18/04/23 20:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/23 20:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/23 20:42:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/23 20:42:03 INFO MemoryStore: MemoryStore cleared; 18/04/23 20:42:03 INFO BlockManager: BlockManager stopped; 18/04/23 20:42:03 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/23 20:42:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/23 20:42:03 INFO SparkContext: Successfully stopped SparkContext; 20:42:03.045 INFO PathSeqPipelineSpark - Shutting down engine; [April 23, 2018 8:42:03 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=793247744; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:17652,failure,failure,17652,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['failure'],['failure']
Availability,"; 18/04/24 17:56:39 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:56:39 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:56:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:56:39 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:56:39 INFO BlockManager: BlockManager stopped; 18/04/24 17:56:39 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:56:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:56:39 INFO SparkContext: Successfully stopped SparkContext; 17:56:39.758 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:56:39 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=821559296; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:38384,failure,failure,38384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['failure'],['failure']
Availability,"; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHan",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7417,AVAIL,AVAILABLE,7417,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['AVAIL'],['AVAILABLE']
Availability,"; 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 2019-10-29T18:18:04.002745164Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 2019-10-29T18:18:04.002777218Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 2019-10-29T18:18:04.002785268Z 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 2019-10-29T18:18:04.002855927Z 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 2019-10-29T18:18:04.002867030Z 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```; I am using ExAC lifted to hg38 as a germline resource in mutect2 with only a tumor sample, and getting the above error in filtermutectcalls. I recently updated to v4.1.3.0 to have the latest changes to mutect2. I was not having this issue with v4.0.5.1. Here is extracted information from the VCF which caused the issue. . ```; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=6;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=16;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,34;MFRL=0,272;MMQ=60,30;MPOS=25;MQ=30.00;POPAF=4.13;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,32;MFRL=0,272;MMQ=60,30;MPOS=15;MQ=30.00;POPAF=4.23;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; ```. Additionally, I tried to re-run this sample without the germline resource and encountered the same error. . _Originally posted by @MikeWLloyd in https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:6331,error,error,6331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['error'],['error']
Availability,; 2022-08-16T00:09:07.4267067Z src/main/java/org/broadinstitute/hellbender/utils/read/AlignmentUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4271200Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4272874Z src/main/java/org/broadinstitute/hellbender/utils/downsampling/AlleleBiasedDownsamplingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4278681Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4292326Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4293163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4296749Z src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4303354Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4304128Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4304857Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4317403Z src/main/java/org/broadinstitute/hellbender/utils/runtime/ProcessControllerBase.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4330221Z src/main/j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:16271,error,error,16271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,; 2022-08-16T00:09:07.4278681Z src/main/java/org/broadinstitute/hellbender/utils/Nucleotide.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4292326Z src/main/java/org/broadinstitute/hellbender/utils/read/CigarUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4293163Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4296749Z src/main/java/org/broadinstitute/hellbender/tools/walkers/qc/Pileup.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4303354Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4304128Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4304857Z src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4317403Z src/main/java/org/broadinstitute/hellbender/utils/runtime/ProcessControllerBase.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4330221Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/filtering/ThresholdCalculator.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4331864Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/clustering/SomaticClusteringModel.java:4: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4360539Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/QualByDepth.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:16813,error,error,16813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270706v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270707v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270708v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:1615,reliab,reliable,1615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270707v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270708v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:1824,reliab,reliable,1824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270708v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:2033,reliab,reliable,2033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.381 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270709v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:2242,reliab,reliable,2242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270710v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:2451,reliab,reliable,2451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270711v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:2660,reliab,reliable,2660,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270712v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:2869,reliab,reliable,2869,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270713v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:3078,reliab,reliable,3078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr1_KI270714v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:3287,reliab,reliable,3287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270715v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:3496,reliab,reliable,3496,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr2_KI270716v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:3705,reliab,reliable,3705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr3_GL000221v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_rando,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:3914,reliab,reliable,3914,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr4_GL000008v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_rand,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:4123,reliab,reliable,4123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr5_GL000208v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270717v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270718v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270719v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.382 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr9_KI270720v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr11_KI270721v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000009v2_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000225v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_KI270722v1_random). Germline contig ploidy determination may not be reliable for decoy/non-standard contigs.; 22:01:54.383 WARNING gcnvkernel.structs.metadata - Sample HG01565 has an unrecognized contig (chr14_GL000194v1_ran,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4840:4332,reliab,reliable,4332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4840,1,['reliab'],['reliable']
Availability,"; 22:05:55.943 [DEBUG] [org.gradle.configuration.project.BuildScriptProcessor] Timing: Running the build script took 12.879 secs; 22:05:55.952 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.954 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] FAILURE: Build failed with an exception.; 22:05:55.955 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Where:; 22:05:55.956 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] Build file '/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/build.gradle' line: 102; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.964 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * What went wrong:; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] A problem occurred evaluating root project 'gatk'.; 22:05:55.966 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK.; 22:05:55.967 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] ; 22:05:55.968 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] * Exception is:; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.GradleScriptException: A problem occurred evaluating root project 'gatk'.; 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:1329,ERROR,ERROR,1329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['ERROR'],['ERROR']
Availability,"; ERROR: Record 18321, Read name U",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:1969,ERROR,ERROR,1969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,12,['ERROR'],['ERROR']
Availability,"; ERROR: Record 966501, Read name UMI-AGA-ATG-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966509, Read name UMI-AGT-GGT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966514, Read name UMI-ATC-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966517, Read name UMI-GAT-TGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966538, Read name UMI-ATA-GGG-23, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966699, Read name UMI-CCG-TGA-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966722, Read name UMI-AGG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966742, Read name UMI-CCG-TCA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966752, Read name UMI-GAA-GAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966784, Read name UMI-CCT-TAT-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966875, Read name UMI-AGG-GGG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966887, Read name UMI-AGG-CCG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966916, Read name UMI-GCT-TCG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:9448,ERROR,ERROR,9448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability,"; ERROR: Record 966542, Read name UMI-GTG-TAG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966699, Read name UMI-CCG-TGA-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966722, Read name UMI-AGG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966742, Read name UMI-CCG-TCA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966752, Read name UMI-GAA-GAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966784, Read name UMI-CCT-TAT-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966875, Read name UMI-AGG-GGG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966887, Read name UMI-AGG-CCG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966916, Read name UMI-GCT-TCG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966939, Read name UMI-CAA-TGT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966989, Read name UMI-GAA-TCA-7, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966991, Read name UMI-TAG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 967245, Read name UMI-AAG-ATT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 975151, Read name UMI-ACT-CCC-4, Zero-length read without FZ, CS or CQ tag; ERROR: Reco",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:9899,ERROR,ERROR,9899,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability,"; ERROR: Record 966591, Read name UMI-CCG-TAT-6, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966596, Read name UMI-GTT-GTT-3-D2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966613, Read name UMI-ACC-GAC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966616, Read name UMI-ACG-TGG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966618, Read name UMI-ACT-GGG-11, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966620, Read name UMI-ACT-GGG-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966627, Read name UMI-GGC-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966674, Read name UMI-CCT-GTC-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966699, Read name UMI-CCG-TGA-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966722, Read name UMI-AGG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966742, Read name UMI-CCG-TCA-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966752, Read name UMI-GAA-GAT-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966784, Read name UMI-CCT-TAT-12, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966875, Read name UMI-AGG-GGG-10, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966887, Read name UMI-AGG-CCG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966916, Read name UMI-GCT-TCG-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966939, Read name UMI-CAA-TGT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966989, Read name UMI-GAA-TCA-7, Zero-length read without FZ, CS or CQ tag; ERROR: Record 966991, Read name UMI-TAG-TGT-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 967245, Read name UMI-AAG-ATT-8, Zero-length read without FZ, CS or CQ tag; ERROR: Record 975151, Read name UMI-ACT-CCC-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 1064783, Read name UMI-GGA-GGT-6, Zero-length read without FZ, CS or CQ tag; Maximum ou",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:9989,ERROR,ERROR,9989,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['ERROR'],['ERROR']
Availability,"; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_20050601_V5.2, LmjF08_01_20050601_V5.2, LmjF09_01_20050601_V5.2, LmjF06_01_20050601_V5.2, LmjF12_01_20050601_V5.2, L",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:3489,ERROR,ERROR,3489,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,2,['ERROR'],['ERROR']
Availability,"; Note that although the error log below says exome, this is a genome sample. I tried raising the ulimit to the same number this other user tried, but I still can get through BaseRecalibratorSpark. I've been trying for awhile to push this data through MarkDuplicatesSpark and finally gave up and switched back to the Picard MarkDuplicates. But even though I got through Picard MarkDuplicates I'm having problems with BaseRecalibratorSpark. I'm running in local mode with 250gb of memory and 128 cores available. . Is there something else for Spark that I can modify to prevent so many tasks getting created in stage 0.0? I'm running on a shared computing system, so it's quite possible that I can't change the ulimit number of open files. I am able to set ulimit -s unlimited, but I might not be able to set ulimit -n beyond a particular threshold on this system. I'll continue to explore the ulimit setting but I'd like to know if there's something else I could try instead. The relevant portion of the error logs are below... 20/01/05 17:43:23 INFO TaskSetManager: Starting task 4991.0 in stage 0.0 (TID 49; 91, localhost, executor driver, partition 4991, PROCESS_LOCAL, 4959 bytes); 20/01/05 17:43:23 INFO Executor: Running task 4991.0 in stage 0.0 (TID 4991); 20/01/05 17:43:23 INFO TaskSetManager: Finished task 4843.0 in stage 0.0 (TID 48; 43) in 74817 ms on localhost (executor driver) (4864/5114); 20/01/05 17:43:23 ERROR Executor: Exception in task 4876.0 in stage 0.0 (TID 487; 6); org.broadinstitute.hellbender.exceptions.UserException$NoSuitableCodecs: Cannot ; read file:///scratch/tmp/spark-ecd63991-68be-4879-b481-68e6789a2004/userFiles-b7; 2d4821-5e36-4d36-aa79-aa6263768669/dbsnp_138.hg19.vcf because no suitable codecs; found; at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(F; eatureManager.java:468); at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFea; tureInput(FeatureDataSource.java:324); at org.broadinstitute.hellbender.engine.Fea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855:1096,error,error,1096,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855,1,['error'],['error']
Availability,"; [September 3, 2024 at 9:55:50 AM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=1241513984; java.lang.RuntimeException: Invalid deflate block found.; at com.intel.gkl.compression.IntelInflater.inflateNative(Native Method); at com.intel.gkl.compression.IntelInflater.inflate(IntelInflater.java:176); at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:145); at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:561); at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:543); at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:479); at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:469); at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:207); at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:342); at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:268); at htsjdk.tribble.readers.PositionalBufferedStream.fill(PositionalBufferedStream.java:132); at htsjdk.tribble.readers.PositionalBufferedStream.read(PositionalBufferedStream.java:84); at java.base/sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:270); at java.base/sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:313); at java.base/sun.nio.cs.StreamDecoder.read(StreamDecoder.java:188); at java.base/java.io.InputStreamReader.read(InputStreamReader.java:177); at htsjdk.tribble.readers.LongLineBufferedReader.fill(LongLineBufferedReader.java:140); at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:300); at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:356); at htsjdk.tribble.readers.SynchronousLineR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8969:4280,avail,available,4280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8969,1,['avail'],['available']
Availability,"; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:595); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Using GATK jar /home/parashar/anaconda3/share/gatk4-4.1.4.0-0/gatk-package-4.1.4.0-local.jar. I used the following command; `gatk Mutect2 -R /archive/GRCh38_GATK/Homo_sapiens_assembly38.fasta -I /scratch/pixel_dis/BCC199N_S12_dedup.bam --max-mnp-distance 0 -O /scratch/pixel_dis/BCC199N_S12_dedup_normal.vcf.gz 2> /scratch/pixel_dis/BCC199N_S12_dedup_normal.stderr; `. to create PONs. But ending up with the same error. I also updated GATK. However, with `--independent-mates` option, it works fine. Why not make that as a default option?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643:2777,error,error,2777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643,1,['error'],['error']
Availability,"; at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 16/01/21 14:55:33 INFO ShutdownHookManager: Shutdown hook called; ```. Attached is a small BAM file that I used to reproduce the error (If memory serves, I've seen this issue on other BAM files as well):. [NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip](https://github.com/broadinstitute/gatk/files/101575/NA12878.chrom20.100kb.ILLUMINA.bwa.CEU.exome.20121211.bam.zip). (This issue may be related to one posted here: https://github.com/broadinstitute/gatk/issues/1417.). Here is some information on what I installed:. ```; echo ""Installing Java""; sudo add-apt-repository -y ppa:webupd8team/java; sudo apt-get -qq update; echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections; echo debconf shared/accepted-oracle-license-v1-1 seen true | sudo debconf-set-selections; sudo apt-get -qq install -y oracle-java8-installer. java -version. echo ""Installing Gradle""; sudo add-apt-repository -y ppa:cwchien/gradle; sudo apt-get -qq update > /dev/null; sudo apt-get -qq install -y gradle. echo ""Downloading binaries for Spark""; wget http://d3kbcqa49mib13.cloudfront.net/spark-1.5.1-bin-hadoop2.6.tgz; tar -xzf spark-1.5.1-bin-hadoop2.6.tgz; export SPARK_HOME=spark-1.5.1-bin-hadoop2.6. echo ""Set up Spark for standalone mode processing""; $SPARK_HOME/sbin/start-master.sh -h localhost; $SPARK_HOME/sbin/start-slave.sh spark://localhost:7077. echo ""Downloading source for GATK4""; wget https://github.com/broadinstitute/gatk/archive/4.alpha.tar.gz; tar -xvzf 4.alpha.tar.gz; export GATK_DIR=gatk-4.alpha. echo ""Building GATK4""; cd $GATK_DIR; gradle installAll; cd .. ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1444:3876,echo,echo,3876,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1444,10,"['Down', 'echo']","['Downloading', 'echo']"
Availability,";; 2022-08-16T00:09:07.3892257Z symbol: class RangeMap; 2022-08-16T00:09:07.3892601Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3893126Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3893670Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3894352Z symbol: class Range; 2022-08-16T00:09:07.3894678Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3897711Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3902203Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3902980Z symbol: class RangeMap; 2022-08-16T00:09:07.3903340Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3903864Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3904505Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3905250Z symbol: class Range; 2022-08-16T00:09:07.3905751Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3906273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T00:09:07.3906908Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T00:09:07.3907793Z symbol: class Range; 2022-08-16T00:09:07.3908125Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3910592Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3914013Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not ex",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:6560,error,error,6560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['error'],['error']
Availability,";; 2022-08-16T22:45:53.7739852Z symbol: class RangeMap; 2022-08-16T22:45:53.7740332Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7740892Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7741707Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7743523Z symbol: class Range; 2022-08-16T22:45:53.7743866Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7747579Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7748444Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7776218Z symbol: class RangeMap; 2022-08-16T22:45:53.7776715Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7777389Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7778220Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7779110Z symbol: class Range; 2022-08-16T22:45:53.7779574Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7780209Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T22:45:53.7780965Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T22:45:53.7781896Z symbol: class Range; 2022-08-16T22:45:53.7782232Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7785096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7789228Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not ex",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:8598,error,error,8598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['error'],['error']
Availability,<0%> (-5%)` | |; | [...ynumber/models/AlleleFractionGlobalParameters.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvbkdsb2JhbFBhcmFtZXRlcnMuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-10%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...rs/vqsr/VariantRecalibratorArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVmFyaWFudFJlY2FsaWJyYXRvckFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [.../read/markduplicates/sparkrecords/Passthrough.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9QYXNzdGhyb3VnaC5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5617#issuecomment-458642276:2501,down,downsampling,2501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5617#issuecomment-458642276,1,['down'],['downsampling']
Availability,=) | `0% <0%> (-100%)` | `0 <0> (-21)` | |; | [...llbender/utils/downsampling/MutectDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvTXV0ZWN0RG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-68.182%)` | `0 <0> (-17)` | |; | [...ownsampling/ReadsDownsamplingIteratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVhZHNEb3duc2FtcGxpbmdJdGVyYXRvclVuaXRUZXN0LmphdmE=) | `1.639% <0%> (-64.361%)` | `1 <0> (-7)` | |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `1.449% <0%> (-75.6%)` | `1 <0> (-9)` | |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0 <0> (-21)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ark/AssemblyRegionReadShardArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQXNzZW1ibHlSZWdpb25SZWFkU2hhcmRBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...nder/tools/copynumber/utils/TagGermlineEvents.java](https://codecov.io/gh/broadinstitute/gatk,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758:2488,down,downsampling,2488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758,1,['down'],['downsampling']
Availability,=2 -jar /Users/cnorman/projects/gatk/build/libs/gatk-package-4.1.7.0-41-g79586b8-SNAPSHOT-local.jar MergeVcfs -I data/calling/my.vcf.gz -I data/calling/b.vcf.gz -O out.vcf.gz; 16:00:13.443 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/cnorman/projects/gatk/build/libs/gatk-package-4.1.7.0-41-g79586b8-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Mon Jun 22 16:00:13 EDT 2020] MergeVcfs --INPUT data/calling/my.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT out.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Mon Jun 22 16:00:13 EDT 2020] Executing as cnorman@WMCEA-78B on Mac OS X 10.13.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0-41-g79586b8-SNAPSHOT; [Mon Jun 22 16:00:13 EDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=373293056; Tool returned:; 0; ```; The only way I can reproduce it is to delete one of the files so it *really* doesn't exist at the specified location:; ```; (base) /tmp/test a /Users/cnorman/projects/gatk/gatk MergeVcfs -I data/calling/my.vcf.gz -I data/calling/b.vcf.gz -O out.vcf.gz; Using GATK jar /Users/cnorman/projects/gatk/build/libs/gatk-package-4.1.7.0-41-g79586b8-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /Users/cnorman/projects/gatk/build/libs/gatk-package-4.1.7.0-41-g79586b8-SNAPSHOT-local.jar MergeVcfs -I data/calling/my.vcf.gz -I data/calling/b.vcf.gz -O out.vcf.gz; 16:03:19.691 INFO NativeLibraryLoader - Loading libgkl_compression.dylib fr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647743321:1610,avail,available,1610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647743321,1,['avail'],['available']
Availability,"=2 -jar /Users/cnorman/projects/gatk/build/libs/gatk-package-4.1.7.0-41-g79586b8-SNAPSHOT-local.jar MergeVcfs -I data/calling/my.vcf.gz -I data/calling/b.vcf.gz -O out.vcf.gz; 16:03:19.691 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/cnorman/projects/gatk/build/libs/gatk-package-4.1.7.0-41-g79586b8-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Mon Jun 22 16:03:19 EDT 2020] MergeVcfs --INPUT data/calling/my.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT out.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Mon Jun 22 16:03:19 EDT 2020] Executing as cnorman@WMCEA-78B on Mac OS X 10.13.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0-41-g79586b8-SNAPSHOT; [Mon Jun 22 16:03:19 EDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=372244480; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.samtools.SAMException: Cannot read non-existent file: file:///private/tmp/test%20a/data/calling/my.vcf.gz; 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:498); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:485); 	at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:177); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); 	at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647743321:3359,avail,available,3359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647743321,1,['avail'],['available']
Availability,"=4191682560; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:554); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:543); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:512); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:326); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:4485,avail,available,4485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472,1,['avail'],['available']
Availability,=; Files 2014 2014 ; Lines 151333 151333 ; Branches 16612 16612 ; ================================================; - Hits 119638 66503 -53135 ; - Misses 25900 79634 +53734 ; + Partials 5795 5196 -599; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5999?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5999/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5999/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5999/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5999/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5999/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5999#issuecomment-501449432:1575,down,downsampling,1575,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5999#issuecomment-501449432,1,['down'],['downsampling']
Availability,==) | `100% <100%> ()` | `25 <3> (+4)` | :arrow_up: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `93.333% <100%> (+0.741%)` | `19 <3> (+3)` | :arrow_up: |; | [...er/tools/examples/ExampleAssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlQXNzZW1ibHlSZWdpb25XYWxrZXIuamF2YQ==) | `83.784% <100%> (+1.431%)` | `19 <3> (+3)` | :arrow_up: |; | [...titute/hellbender/engine/AssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXNzZW1ibHlSZWdpb25XYWxrZXIuamF2YQ==) | `85.135% <85.714%> (+1.312%)` | `15 <0> ()` | :arrow_down: |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `96% <88.889%> (-1.674%)` | `23 <7> (+3)` | |; | [...institute/hellbender/tools/exome/TargetWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9UYXJnZXRXcml0ZXIuamF2YQ==) | `89.744% <0%> (-3.805%)` | `9% <0%> (+2%)` | |; | [.../broadinstitute/hellbender/engine/LocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTG9jdXNXYWxrZXIuamF2YQ==) | `77.083% <0%> (-2.227%)` | `33% <0%> (+13%)` | |; | [...lbender/utils/read/SAMRecordToGATKReadAdapter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314173877:2491,down,downsampling,2491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314173877,1,['down'],['downsampling']
Availability,==; Files 1928 1928 ; Lines 145320 145320 ; Branches 16089 16089 ; ===============================================; - Hits 126498 61049 -65449 ; - Misses 12961 79174 +66213 ; + Partials 5861 5097 -764; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5589?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5589/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5589/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5589/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5589/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5589/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5589#issuecomment-455598752:1571,down,downsampling,1571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5589#issuecomment-455598752,1,['down'],['downsampling']
Availability,==========; Files 1928 1934 +6 ; Lines 145340 145727 +387 ; Branches 16089 16104 +15 ; ===============================================; - Hits 126513 10129 -116384 ; - Misses 12966 134867 +121901 ; + Partials 5861 731 -5130; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5594?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...der/tools/HaplotypeCallerSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.439% <> (-65.854%)` | `2 <0> (-14)` | |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-100%)` | `0 <0> (-21)` | |; | [...llbender/utils/downsampling/MutectDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvTXV0ZWN0RG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-68.182%)` | `0 <0> (-17)` | |; | [...ownsampling/ReadsDownsamplingIteratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVhZHNEb3duc2FtcGxpbmdJdGVyYXRvclVuaXRUZXN0LmphdmE=) | `1.639% <0%> (-64.361%)` | `1 <0> (-7)` | |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `1.449% <0%> (-75.6%)` | `1 <0> (-9)` | |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758:1565,down,downsampling,1565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758,1,['down'],['downsampling']
Availability,===========; + Coverage 86.928% 86.928% +<.001% ; + Complexity 30319 30318 -1 ; ===============================================; Files 1849 1849 ; Lines 140737 140738 +1 ; Branches 15476 15475 -1 ; ===============================================; + Hits 122340 122341 +1 ; Misses 12789 12789 ; Partials 5608 5608; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5074?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `100% <100%> ()` | `18 <3> (-3)` | :arrow_down: |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `77.049% <100%> ()` | `10 <2> ()` | :arrow_down: |; | [...llbender/utils/downsampling/MutectDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvTXV0ZWN0RG93bnNhbXBsZXIuamF2YQ==) | `68.182% <100%> ()` | `17 <0> ()` | :arrow_down: |; | [...dinstitute/hellbender/utils/MathUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYXRoVXRpbHNVbml0VGVzdC5qYXZh) | `92.44% <100%> (+0.071%)` | `145 <2> (+2)` | :arrow_up: |; | [...lbender/utils/locusiterator/SamplePartitioner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5074/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9sb2N1c2l0ZXJhdG9yL1NhbXBsZVBhcnRpdGlvbmVyLmphdmE=) | `94.286% <100%> ()` | `11 <0> ()` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-434027785:1565,down,downsampling,1565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-434027785,1,['down'],['downsampling']
Availability,=====================================; Files 1909 1914 +5 ; Lines 144202 144264 +62 ; Branches 15954 15956 +2 ; ===============================================; + Hits 125433 125492 +59 ; - Misses 12999 13003 +4 ; + Partials 5770 5769 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5311?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ellbender/utils/iterators/PushPullTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5311/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pdGVyYXRvcnMvUHVzaFB1bGxUcmFuc2Zvcm1lci5qYXZh) | `0% <0%> ()` | `0 <0> (?)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5311/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> ()` | `0 <0> (?)` | |; | [...ute/hellbender/utils/downsampling/Downsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5311/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRG93bnNhbXBsZXIuamF2YQ==) | `100% <100%> ()` | `6 <1> ()` | :arrow_down: |; | [...hellbender/utils/iterators/PushToPullIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5311/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pdGVyYXRvcnMvUHVzaFRvUHVsbEl0ZXJhdG9yLmphdmE=) | `100% <100%> ()` | `17 <17> (?)` | |; | [.../utils/downsampling/ReadsDownsamplingIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5311/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVhZHNEb3duc2FtcGxpbmdJdGVyYXRvci5qYXZh) | `100% <100%> ()` | `1 <1> (-16)` | :arrow_down: |; | [...e/hellbender/utils/variant/writers/GVCFWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5311/diff?src=pr&el=tr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5311#issuecomment-430318188:1546,down,downsampling,1546,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5311#issuecomment-430318188,2,"['Down', 'down']","['Downsampler', 'downsampling']"
Availability,=========================================; Files 1908 1908 ; Lines 144007 144037 +30 ; Branches 15927 15930 +3 ; ==============================================; + Hits 125300 125324 +24 ; - Misses 12950 12955 +5 ; - Partials 5757 5758 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5448?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ava/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9VdGlscy5qYXZh) | `81.573% <100%> (+0.041%)` | `159 <1> (+1)` | :arrow_up: |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `100% <100%> ()` | `23 <6> (+2)` | :arrow_up: |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `81.818% <100%> (+4.769%)` | `12 <2> (+2)` | :arrow_up: |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `95.745% <80%> (-4.255%)` | `25 <6> (+4)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5448/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...itute/hellbender/utils/report/GATKReportTable.java](https://codecov.io/gh/broadinst,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5448#issuecomment-442185802:1521,down,downsampling,1521,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5448#issuecomment-442185802,1,['down'],['downsampling']
Availability,=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...der/tools/walkers/mutect/M2ArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3988/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NMkFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `100% <100%> ()` | `1 <0> ()` | :arrow_down: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/3988/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `92.593% <100%> (+0.285%)` | `17 <1> (+1)` | :arrow_up: |; | [...titute/hellbender/engine/AssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/3988/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXNzZW1ibHlSZWdpb25XYWxrZXIuamF2YQ==) | `82.857% <50%> (+0.165%)` | `26 <1> (+1)` | :arrow_up: |; | [...llbender/utils/downsampling/MutectDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/3988/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvTXV0ZWN0RG93bnNhbXBsZXIuamF2YQ==) | `60.606% <60.606%> ()` | `14 <14> (?)` | |; | [...itute/hellbender/tools/funcotator/Funcotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3988/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0aW9uLmphdmE=) | `33.333% <0%> (-16.667%)` | `3% <0%> (-1%)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3988/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `91.064% <0%> (-0.426%)` | `66% <0%> (-1%)` | |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3988/diff?src=pr&el=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3988#issuecomment-352767525:1854,down,downsampling,1854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3988#issuecomment-352767525,1,['down'],['downsampling']
Availability,> (-32%)` | |; | [.../utils/reference/FastaReferenceWriterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWZlcmVuY2UvRmFzdGFSZWZlcmVuY2VXcml0ZXJVbml0VGVzdC5qYXZh) | `62.443% <0%> (-22.696%)` | `33% <0%> (-37%)` | |; | [...ellbender/tools/walkers/vqsr/CNNScoreVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50cy5qYXZh) | `58.387% <0%> (-22.057%)` | `33% <0%> (-12%)` | |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `78.534% <0%> (-21.466%)` | `8% <0%> (-5%)` | |; | [...ownsampling/ReadsDownsamplingIteratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVhZHNEb3duc2FtcGxpbmdJdGVyYXRvclVuaXRUZXN0LmphdmE=) | `51.724% <0%> (-20.407%)` | `7% <0%> (-4%)` | |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `86.301% <0%> (-13.699%)` | `33% <0%> (+6%)` | |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `77.273% <0%> (-10.356%)` | `13% <0%> ()` | |; | ... and [18 more](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5645#issuecomment-460657077:3494,down,downsampling,3494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5645#issuecomment-460657077,2,['down'],['downsampling']
Availability,"> . @lbergelson Yes the error was from a previous version as I didn't have the new error recorded. I ran it again and here is the code and error. Just for clarity, I simplified the code paste here, removed long paths and stuff but some of those are shown in the error. Thanks!. `java -jar /home/apps/software/picard/2.27.5-Java-1.8.0_201/picard.jar CollectInsertSizeMetrics \; I=HG03125.final.cram \; O=insertSize_metrics.txt \; H=insertSize_hist.pdf \; R=GRCh38_full_analysis_set_plus_decoy_hla.fa \; M=0.5`. `[Thu Feb 02 13:05:04 CST 2023] picard.analysis.CollectInsertSizeMetrics HISTOGRAM_FILE=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_hist.pdf MINIMUM_PCT=0.5 INPUT=./crams/AFR/HG03125.final.cram OUTPUT=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_metrics.txt REFERENCE_SEQUENCE=/home/groups/h3abionet/RefGraph/data/genomes/human/GRCh38/GRCh38_full_analysis_set_plus_decoy_hla.fa DEVIATIONS=10.0 METRIC_ACCUMULATION_LEVEL=[ALL_READS] INCLUDE_DUPLICATES=false ASSUME_SORTED=true STOP_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [Thu Feb 02 13:05:04 CST 2023] Executing as valizad2@compute-5-1 on Linux 4.18.0-348.23.1.el8_5.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_201-b09; Picard version: 2.9.0-1-gf5b9f50-SNAPSHOT; INFO	2023-02-02 13:05:15	SinglePassSamProgram	Processed 1,000,000 records. Elapsed time: 00:00:11s. Time for last 1,000,000: 6s. Last read position: chr1:3,185,445; INFO	2023-02-02 13:05:20	SinglePassSamProgram	Processed 2,000,000 records. Elapsed time: 00:00:16s. Time for last 1,000,000: 5s. Last read position: chr1:6,814,058; INFO	2023-02-02 13:05:25	SinglePassSamProgram	Processed 3,000,000 records. Elapsed time: 00:00:21s. Time for last 1,000,000: 4s. Last read position: chr1:10,463,599; INFO	2023-02-02 13:05:30	SinglePassSamProgram	Processed 4,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417:24,error,error,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417,8,['error'],['error']
Availability,"> ; > ; > @shengzha In your case it looks like ApplyBQSR is failing because ALL of your input reads are being filtered out before BQSR ever sees them, due to having mapping quality 0:; > ; > `23:40:38.767 INFO BaseRecalibrator - 62393454 read(s) filtered by: MappingQualityNotZeroReadFilter`; > ...; > `23:40:38.822 INFO BaseRecalibrator - BaseRecalibrator was able to recalibrate 0 reads`. Hi, I also encounted the trable. And it looks like ApplyBQSR is failing is truelly caused by 0 reads after filtered in BQSR processing. I solved my problem in BQSR to generate recal_table.; So maybe my experience is helpful to you or others. ; **Q**: ""on the ApplyBQSR step with an error stating ""The covariates table is missing ReadGroup xxx in RecalTable0""; **A**: check up reads remained in BQSR, such as filtering by regions: --intervals xxx.bed and no reads in target regions.and other filtering situations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6242#issuecomment-659246329:673,error,error,673,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6242#issuecomment-659246329,1,['error'],['error']
Availability,"> > I've manually kicked off our integration tests on this branch. If that passes (it should take a couple of hours), I'll give this a thumb.; > ; > SG! I also pushed this to Agora and will test it out using our genomic extraction workflow. our error is resolved with this PR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447390883:245,error,error,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447390883,1,['error'],['error']
Availability,"> @Ben-Habermeyer We had a few PRs in late 2021 that may have fixed this. If it's still occurring in the latest GATK version I would like to take a look at it. ok @davidbenjamin I got a chance to test with latest release `4.3.0.0` and the issue seems to be mostly resolved when running `--alleles` on our test samples. Additionally, `FilterMutectCalls` works on low DP variants. . For control samples, using the `--alleles` option results in an error due to the value of the stats `callable`. . Combination of this call:; ```; chr18 77560878 . AA TT . . AS_SB_TABLE=0,0|0,0;DP=1;ECNT=2;MBQ=0,90;MFRL=0,100;MMQ=60,60;MPOS=29;POPAF=7.30;TLOD=4.20 GT:AD:AF:DP:F1R2:F2R1:FAD:PGT:PID:PS:SB 0|1:0,1:0.667:1:0,1:0,0:0,1:0|1:77560878_AA_TT:77560878:0,0,0,1; ```; and the stats file containing:; ```; callable 1.0; ```; results in FilterMutectCalls exception; ```; java.lang.IllegalArgumentException: logValues must be non-infinite and non-NAN; at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeFromLogToLinearSpace(NaturalLogUtils.java:27); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:140); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSomaticVariant(SomaticClusteringModel.java:146); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.performEMIteration(SomaticClusteringModel.java:345); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:330); at org.broadinstitute.hellbe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7276#issuecomment-1293969047:445,error,error,445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7276#issuecomment-1293969047,2,['error'],['error']
Availability,> @Bowen1992 Could you please try running with the latest GATK release (`4.2.6.1`) and reporting whether the issue persists?. Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -Djava.io.tmpdir=./tmp -jar /public/home/gaoshibin/software/GATK/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R /public/home/gaoshibin/B73_REF/Zea_mays.AGPv4.dna.toplevel.fa -V gendb://./CHR7_gvcf_database -G StandardAnnotation --genomicsdb-shared-posixfs-optimizations true -O new_ALL_MATERIALS_chr7.g.vcf.gz; 17:49:50.404 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 17:49:50.653 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/public/home/gaoshibin/software/GATK/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 17:49:51.271 INFO GenotypeGVCFs - ------------------------------------------------------------; 17:49:51.273 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.6.1; 17:49:51.273 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:49:51.273 INFO GenotypeGVCFs - Executing as gaoshibin@comput6 on Linux v3.10.0-693.el7.x86_64 amd64; 17:49:51.274 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_211-b12; 17:49:51.274 INFO GenotypeGVCFs - Start Date/Time: 2022522 054950; 17:49:51.274 INFO GenotypeGVCFs - ------------------------------------------------------------; 17:49:51.275 INFO GenotypeGVCFs - ------------------------------------------------------------; 17:49:51.276 INFO GenotypeGVCFs - HTSJDK Version: 2.24.1; 17:49:51.276 INFO GenotypeGVCFs - Picard Version: 2.27.1; 17:49:51.276 INFO GenotypeGVCFs - Built for Spark Version: 2.4.5; 17:49:51.277 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:49:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135302097:680,Redundant,Redundant,680,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135302097,1,['Redundant'],['Redundant']
Availability,"> @Echopei could you explain why you think this value of AF is wrong?. pos:46731791 this value of AF should be 0.34,but createSomaticPanelOfNormals return 2.462e-05.; I think 46731782 deletion overrides 46731791,so createSomaticPanelOfNormals return 2.462e-05. but it's wrong.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7215#issuecomment-833168055:3,Echo,Echopei,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7215#issuecomment-833168055,1,['Echo'],['Echopei']
Availability,"> @Siadjeu Don't worry about the ""Failed to detect"" message. It indicates some internal state in one of the google libraries but not an error we need to worry about. Generally you shouldn't worry about INFO messages if everything else is going fine and they don't say something particular about what you're doing. A WARNING or ERROR message would indicate a problem. This should maybe be downgraded to be a DEBUG level message or something but it's in a third library and convincing them to change it might be a hassle. Although there are results, but the size of the results is wrong, the results are too small.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-1598239834:136,error,error,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-1598239834,3,"['ERROR', 'down', 'error']","['ERROR', 'downgraded', 'error']"
Availability,"> @TearsWillFall To help us diagnose this issue, could you please try running the same `CNNScoreVariants` command in our official 4.2 docker image in dockerhub (https://hub.docker.com/r/broadinstitute/gatk/), and report whether you get the same error?. Just to confirm and clarify. The same command works fine on a 4.2.0 docker image built on Singularity. ; However, it doesn't seem to work, when I either:. A) Download the zip/tar and build the conda environment as per Requirements section instructions using `conda env create -f gatkcondaenv.yml `; B) Clone the master repo build gatk and use `./gradlew localDevCondaEnv` to build the conda env. In both cases, I seem to get the error above mentioned.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-849516520:245,error,error,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-849516520,3,"['Down', 'error']","['Download', 'error']"
Availability,"> @colinhercus I was able to re-run your command successfully on the latest master branch (not in a release yet). I believe PR #6240 fixed the issue. @Rohit-Satyam @danielecook there's a good chance the errors you encountered are also fixed. If not, please let me know. In reference to your reply, I wish to inform you the problem still stands. > java.lang.IllegalArgumentException: Cannot construct fragment from more than two reads; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725); at org.broadinstitute.hellbender.utils.read.Fragment.create(Fragment.java:36); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1376); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:595); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLinePro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643:203,error,errors,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643,1,['error'],['errors']
Availability,"> @oldmikeyang Do you get the same result if the inputs and outputs to `MarkDuplicatesSpark` are on the local filesystem rather than HDFS?; > ; > @jamesemery Can you comment?. I just try the MarkDuplicatesSpark from local file system without the HDFS.; the application will failure. It said can't find the file, but the file is on the local file system. ```; ls -la /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; -rw-rw-r--. 1 test test 4668988887 Oct 4 11:27 /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; ```. Here is SPARK information. ```; A USER ERROR has occurred: Failed to read bam header from; /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.sec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:274,failure,failure,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,2,"['ERROR', 'failure']","['ERROR', 'failure']"
Availability,> @slw287r I found the error and have fixed it in a branch. I will test it on a few genomes and then submit a PR. That's cool! thanks,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6724#issuecomment-690803941:23,error,error,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6724#issuecomment-690803941,1,['error'],['error']
Availability,"> @wqrao Hi - you must use the v1.7 Funcotator data sources to get those annotations. These datasources can only be used with GATK 4.1.9.0 or newer. Hi,I have tried this code "" java -jar ./gatk-4.1.9.0/gatk Funcotator --variant filter_snp.vcf --reference Homo_sapiens_assembly38.fasta --ref-version hg38 --data-sources-path funcotator_dataSources.v1.7.20200521s --out v17_anno.snp.maf --output-file-format MAF"" again,but few seconds later ,this error(""Error: Invalid or corrupt jarfile ./gatk-4.1.9.0/gatk"") appeared. How to solve it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-747913339:445,error,error,445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-747913339,2,"['Error', 'error']","['Error', 'error']"
Availability,"> A fix for another often-reported issue where Mutect2 could emit MNPs despite --max-mnp-distance being 0, causing downstream errors in GenomicsDB about MNPs not being supported. Is this fix is only dedicated to the Mutect2 module and not extended for the HaplotypeCaller/HaplotypeCallerSpark/CombineGVCFs functions?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-671790528:115,down,downstream,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-671790528,2,"['down', 'error']","['downstream', 'errors']"
Availability,"> But again - this isn't being merged to EchoCallset, just run off of this branch?. Yes that's right, this is the branch I ran the full / rev1 filter extract with. I don't think this should be merged to EchoCallset (not that being on EchoCallset is any guarantee that code will make it back to ah_var_store, but still).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8868#issuecomment-2166488412:41,Echo,EchoCallset,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8868#issuecomment-2166488412,3,['Echo'],['EchoCallset']
Availability,"> Do I need to run this Python package in the GATK4.0.4.0 Docker? I am getting a similar error with DetermineGermlineContigPloidy while running within the Docker on a Linux Compute Engine VM.; > ; > ```; > ...; > 19:06:35.948 INFO DetermineGermlineContigPloidy - Aggregating read-count file /gatk/snail/gcnv_180517/coverage_1k/A19625.hc.soohee1k.hdf5 (24 / 24); > 19:06:54.675 INFO DetermineGermlineContigPloidy - Shutting down engine; > [May 18, 2018 7:06:54 PM UTC] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 1.83 minutes.; > Runtime.totalMemory()=2822242304; > org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; > python exited with 1; > Command Line: python /tmp/root/cohort_determine_ploidy_and_depth.8539868448285133842.py --sample_coverage_metadata=/tmp/root/samples-by-coverage-per-contig3023244219495833390.tsv --output_calls_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.000000e-02 --adamax_beta1=9.000000e-01 --adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_epochs=20 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/root/intervals3258684972117897378.tsv --contig_ploidy_prior_table=/gatk/snail/gcnv/grch38_germline_CN_priors.tsv --output_model_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-434527279:89,error,error,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-434527279,2,"['down', 'error']","['down', 'error']"
Availability,"> First, if a datasource config has a space in it, throw an error and tell the user to remove the space. Yes, but trim trailing and leading spaces first. Do this when initializing the datasource. So if a config file specifies a leading or trailing whitespace, it is discarded. > Second - remove spaces from funcotation field names when outputting the funcotations (could still happen with XSVs with spaces in column headers). Actually, since we know the output field names before we do any work, I would recommend doing something similar as above (i.e. Remove trailing or leading spaces and throw error if any other spaces are found).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5937#issuecomment-507304973:60,error,error,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5937#issuecomment-507304973,2,['error'],['error']
Availability,"> GATK depends on gradle 3.1.: download shaw256. It currently works with gradle-4.6, no need to go back to 3.1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444210781:31,down,download,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444210781,1,['down'],['download']
Availability,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/311:628,FAILURE,FAILURE,628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311,2,"['FAILURE', 'failure']","['FAILURE', 'failure']"
Availability,"> Have you tested this on a quickstart?. I have not, I'd certainly be interested in some pairing / mobbing to do that. Also this requires the [Cromwell shell escape fixes](https://github.com/broadinstitute/cromwell/pull/6989/files) to be available in production. I hope to merge that soon but I'm not sure these days how long after merge to Cromwell develop before code goes to production.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8170#issuecomment-1402746956:238,avail,available,238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8170#issuecomment-1402746956,1,['avail'],['available']
Availability,"> Hey @ccartermices. Looking at that error message it appears that the genotype given alleles has tried to insert a '*' allele into an assembled haplotype. (""TTTTGAC*TTCGC"" in the error message). I suspect this is because the code is missing a check to filter symbolic alleles out of GGA inputs. Can you check your input `db_raw_call_bbe_6largest.vcf` for `\*` alleles? It should be possible to filter those out of your input file. Thanksif i want to make a filter on it, should i use which tool? VQSR?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553776381:37,error,error,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553776381,2,['error'],['error']
Availability,"> How can I install GATK4 successful?. If you just want to install (as opposed to build), you can download a [release .zip or .tar](https://github.com/broadinstitute/gatk/releases) directly. If you want to build, then as @magicDGS suggested, you need to have git-lfs installed. If you already have that, I would try manually running the command `git lfs pull --include src/main/resources/large` from the root of the repo clone and see if you get a more detailed failure message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4669#issuecomment-382363528:98,down,download,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4669#issuecomment-382363528,2,"['down', 'failure']","['download', 'failure']"
Availability,"> I agree with you that this is a real problem. I don't understand the logic, why HALF of PCR_ERROR_QUAL? if that's really 20, then it's way too low!!. The intent of this code is that downstream code will not do anything special to avoid over-counting ; overlapping mates, so that assigning half of the PCR qual effectively gives the full PCR qual for the fragment. Of course, this assumption is wrong in the case of M2. > I also object to the second part (when the bases disagree.) imagine that one base is A@Q2 and the other is T@Q60...why would you put both bases to Q0 in that case?. Good point. > We should take some time to figure out the model that allows for PCR error and then derive the posterior posteriors from that... Are you suggesting something like there are binary indicators for PCR error, read 1 sequencing error, read 2 sequencing error, with priors given by the PCR and base qualities, and we want the posteriors of these indicators given that the bases agree / disagree?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4958#issuecomment-400799135:184,down,downstream,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4958#issuecomment-400799135,5,"['down', 'error']","['downstream', 'error']"
Availability,> I also encounter this error when most samples have been imported. I ran importing in batches '--batch-size 50 --consolidate '. The error occured at the last batch. Can I reuse some of the imported data files or have to rerun the whole importing again?. ...; 13:13:26.069 INFO GenomicsDBImport - Done importing batch 21/22; 13:13:26.069 INFO GenomicsDBImport - Starting batch input file preload; 13:13:27.440 INFO GenomicsDBImport - Finished batch preload; 13:13:27.440 INFO GenomicsDBImport - Importing batch 22 with 22 samples; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : Error while consolidating TileDB array chrY$1$57227415; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6519#issuecomment-641091886:24,error,error,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6519#issuecomment-641091886,7,"['Error', 'error']","['Error', 'error']"
Availability,"> I am also interested in; > ; > 1. Rescue rare variants.; > 2. For variants that are not called in a sample, get the REF/ALT counts for them for downstream analysis.; > ; > and I didn't notice this issue and [opened my own](https://github.com/broadinstitute/gatk/issues/7847). However, isn't it Best Practice to use HaplotypeCaller for germline variants?; > ; > ![image](https://user-images.githubusercontent.com/631218/169218653-9be2caa1-5c29-4c56-8fa6-8d10e52b3e29.png). Hi Dario- . I am trying to do variant calling (both somatic and germline) on targeted sequencing data of single tumor cells, and therefore my concerns for HaplotypeCaller are:; - the diploid assumption does not hold.; - VQSR is not feasible given the targeted sequencing data. That's why I turned to Mutect2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7825#issuecomment-1148062132:146,down,downstream,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7825#issuecomment-1148062132,1,['down'],['downstream']
Availability,"> I guess my objection boils down to the fact that by outputting . Instead of PASS you're throwing away information. I agree that we need to address that. What if an allele whose failing filters were all passed to the site got a concise tag like `site` to indicate that it has no additional filters, is not a passing allele, and that allele-specific filters were applied?. Besides the aesthetics of the word ""PASS"" being associated in any way with something failing, I'm worried about users shooting themselves in the foot with pipelines that only check the allele filters. You could imagine cases where failing to check the site filters wouldn't be so egregious as to be obvious.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-590029834:29,down,down,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-590029834,1,['down'],['down']
Availability,"> I have no objection to these changes, especially since this is just bringing us back to where we were in genomicsDB in the last release. We should spawn a ticket to track reintroducing these improvements and perhaps we should also add a macos test to our travis array so we can catch this kind of issue in the future? I think there is a macOS VM availible on travis that we could rerun some of the integration tests on. Yes, travis has macOS VM. It is very slow, so would recommend only sanity checks on it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6204#issuecomment-539574124:348,avail,availible,348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6204#issuecomment-539574124,1,['avail'],['availible']
Availability,"> If one thinks about a genomicsDB workspace more like a database than single file, are there defrag/shrink-like tasks that need to be performed on the workspace for efficiency?. Did you use the `--consolidate` option with GenomicsDBImport? This option consolidates fragments to help with query performance later. Usually not needed for very small batch sizes.; Also, available from 4.1.7.0 is a `--genomicsdb-shared-posixfs-optimizations` option. Can you try GenotypeGVCFs with this knob turned on if your workspace is on NFS/Lustre and let us know?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-669344356:368,avail,available,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-669344356,1,['avail'],['available']
Availability,"> In this case, allele-specific annotations are outputted to GVCFs files by 'HaplotypeCaller -ERC GVCF -G AS_StandardAnnotation' command.; > ; > Although some warning message of 'HaplotypeCaller -ERC GVCF -G AS_StandardAnnotation' command.; > ; > ```; > WARN:StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; > ```; > ; > This warning message does not happen in all of my cases, but the FORMAT/AD error happen in all of my cases. hello , i met the warning message:; `DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null`; `WARN:StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null`. could you help me ? i just am a fresh . So i don't know what should i do next step and why it reported some warning messages. ; Thank you very much !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4691#issuecomment-727523636:458,error,error,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4691#issuecomment-727523636,1,['error'],['error']
Availability,"> Is it possible to add an integration test to this? Since the change did not fail any test, it seems that the integrationtest is missing. Unit test fixed to include checking of variant type (which it did not include before - hence the non-failure). Test data adjusted accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1806779412:240,failure,failure,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1806779412,1,['failure'],['failure']
Availability,"> Is the 1bp alignment really zero length somehow -- is that the issue?. Yes! In a different sense.; The explanation below is a bit mind-numbing, so please bear with me:. --------. So, to illustrate further, this is the alignment that prompted this PR: [ribbon plot](http://www.genomeribbon.com/?perma=Vg2BPO7Yay). Turning off the filter step in `AssemblyContigAlignmentsConfigPicker` by setting `ALIGNMENT_LOW_READ_UNIQUENESS_THRESHOLD = 0;` (hence the comment _""The aim is to make the downstream logic agnostic to upstream filtering detail""_), the middle alignment--actually only 2 alignment but we do gap-split--is uniquely covering only 1 base. It would generate the following without this PR; ```; chr21	42283722	CPX_chr21:42283722-42284027	C	<CPX>	.	.	ALIGN_LENGTHS=733;ALT_ARRANGEMENT;CTG_NAMES=asm029245:tig00000;END=42284027;HQ_MAPPINGS=1;MAPPING_QUALITIES=60;MAX_ALIGN_LENGTH=733;SEGMENTS=chr21:42283722-42283784,chr21:42283784-42284027;SEQ_ALT_HAPLOTYPE=CAC;SVLEN=-303;SVTYPE=CPX;TOTAL_MAPPINGS=1; ```; with this PR, it would generate:; ```; chr21	42283722	CPX_chr21:42283722-42284027	C	<CPX>	.	.	ALIGN_LENGTHS=733;ALT_ARRANGEMENT=UINS-1;CTG_NAMES=asm029245:tig00000;END=42284027;HQ_MAPPINGS=1;MAPPING_QUALITIES=60;MAX_ALIGN_LENGTH=733;SEGMENTS=chr21:42283722-42284027;SEQ_ALT_HAPLOTYPE=CAC;SVLEN=-303;SVTYPE=CPX;TOTAL_MAPPINGS=1; ```; The differences are in annotations `ALT_ARRANGEMENT` and `SEGMENTS`:; * without the PR, the code hyper-segments the region into 2 segments, with no `ALT_ARRANGEMENT`. This is technically wrong.; * with the PR, the two segmentations are ""merged"" into one, and the `ALT_ARRANGEMENT` annotation correctly says there's one ""unmapped"" base (technically not unmapped, but it would bring in more noise because a single base could map to 1/4 of the genome). And yes, the hyper-segmentation problem is still there for cases where de-overlapped alignments are 2bp long (or very short, 3bp, 5bp, etc.), but in that case the `ALT_ARRANGEMENT` won't be empty. And the",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-406061907:487,down,downstream,487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-406061907,1,['down'],['downstream']
Availability,"> It contains the information for all chromosomes and is not always in the right order. (ID=chr1, ID=chr2 ... in the right order; ID=chr1_KI270706v1_random et al. are not in the right order.). Just to confirm that chr7-10 show up in the right order in vcfheader.vcf, then? `GenomicsDBImport` doesn't store anything else that could impact chromosome/contig order AFAIK (order in the `vidmap.json` doesn't matter). Can you share what your `GenotypeGVCF`/`CreateSomaticPanelOfNormals` commandline is and specifically the stacktrace/error?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1659297039:529,error,error,529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1659297039,1,['error'],['error']
Availability,> It's OK using gatk-4.1.3. @lbergelson I am getting the same error as @wangshun1121 mentions above. I'm using version 4.1.4.0. I am assuming this version has the bug fix too like v4.1.3 that works for @wangshun1121 ?. Thanks.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-582695736:62,error,error,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-582695736,1,['error'],['error']
Availability,"> Jupollet, This is a known issue and should be resolved by the most recent release gatk4-4.1.4.1. This was released last week, so you may need to just update. If that doesnt work, you may need to disable supplementary reads. Thanks, Mark; > [](#); > On Mon, Dec 2, 2019 at 10:52 AM jupollet ***@***.***> wrote: I verify with sacct SLURM command and the job have no problem with RAM memory, he run through the end but no produce .stat file and output only .vcf and .vcf.idx  You are receiving this because you were assigned. Reply to this email directly, view it on GitHub <#6271?email_source=notifications&email_token=ACRX2DIR7ZYRDCNPZNOLET3QWU4L3A5CNFSM4JPWZLUKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEFUEKKA#issuecomment-560481576>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/ACRX2DJECNGRYUGBY62LLN3QWU4L3ANCNFSM4JPWZLUA> . Dear @fleharty. I have 4.2.2. version of GATK, however the problem is exactly like that, I get vcf and its index file without stats: . ***********************************************************************. A USER ERROR has occurred: Mutect stats table somatic_449_WT_vs_6KO_Pd.vcf.gz.stats not found. When Mutect2 outputs a file calls.vcf it also creates a calls.vcf.stats file. Perhaps this file was not moved along with the vcf, or perhaps it was not delocalized from a virtual machine while running in the cloud.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-979278929:1088,ERROR,ERROR,1088,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-979278929,1,['ERROR'],['ERROR']
Availability,"> Overall the refactoring looks good and makes sense but I'm not seeing how this fixes the problem of eating exceptions we saw during a recent run. Can you explain what was happening before, and how the new code addresses it?. Sure! This code (besides refactoring so that it was only in one place) aims to fix two issues:; 1. if query results in an error, it gets run three more times and then, because of `while len(retry_delay) > 0`, it doesnt run again and the `raise err` line never gets executed, so no error is ever raised; 2. if the query fails for a reason that has no chance of being fixed by a retry (eg. 404), it will still run three more times. I probably missed some errors that should be ""retry-able"" (maybe `Aborted `? `BadGateway`? `Cancelled `? [full list here](https://googleapis.dev/python/google-api-core/latest/exceptions.html)), but I still think it makes sense to not treat all errors the same.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7480#issuecomment-930239576:350,error,error,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7480#issuecomment-930239576,4,['error'],"['error', 'errors']"
Availability,"> The constructors (some of them anyway) use the args during constructor execution. That's a theoretical problem but in this case they dont. Anyway, I restored my earlier code to special-case CommandLineException and throw that. . You may have seen this, but there was a failure in AlleleFrequencyQCTest, which I addressed here: https://github.com/broadinstitute/gatk/pull/6973/commits/8a9f5db6eccbc82600f8ec46e7656bcf92bedf5b. The general change is to stop stashing two variables locally within AlleleFrequency, which allows AlleleFrequencyQC to set their values later.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827880315:271,failure,failure,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827880315,1,['failure'],['failure']
Availability,"> The error comes from two annotations: InbreedingCoeff and ExcessHet. One solution is to add ""-AX ExcessHet -AX InbreedingCoeff"". It doesnt exactly solve the problem, but it avoids hitting the problem code. Awesome! It is useful. Thank you very much!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7938#issuecomment-1238890115:6,error,error,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7938#issuecomment-1238890115,1,['error'],['error']
Availability,"> The four test failures in `ExtractCohortToPgenTest` appear to be real:; > ; > ```; > 2024-03-12T20:53:02.3169070Z Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.gvs.extract.ExtractCohortToPgenTest > testFinalVQSRLitePgenfromRangesAvro [31mFAILED[39m[0K; > 2024-03-12T20:53:02.3171276Z java.lang.AssertionError: expected [-1] but found [13570][0K; > 2024-03-12T20:53:02.3172934Z at org.testng.Assert.fail(Assert.java:97); > 2024-03-12T20:53:02.3173927Z at org.testng.Assert.assertEqualsImpl(Assert.java:136); > 2024-03-12T20:53:02.3174922Z at org.testng.Assert.assertEquals(Assert.java:118); > 2024-03-12T20:53:02.3175853Z at org.testng.Assert.assertEquals(Assert.java:729); > 2024-03-12T20:53:02.3176775Z at org.testng.Assert.assertEquals(Assert.java:739); > 2024-03-12T20:53:02.3178703Z at org.broadinstitute.hellbender.tools.gvs.extract.ExtractCohortToPgenTest.testFinalVQSRLitePgenfromRangesAvro(ExtractCohortToPgenTest.java:78); > ```. That's weird, because it looks like it's succeeding in the other test tasks where it's running. The place it's failing is an extremely simple equality assertion of two compressed files, though. I wonder if there's something about operating system differences that can change the compression slightly. I'll see if I can find a better way to do that check",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2000109415:16,failure,failures,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2000109415,2,['failure'],['failures']
Availability,"> The new changes to the base image Dockerfile look good to me, @kevinpalis ! Can you tell us how many layers we have total after these changes? Is there any value in pursuing a full squash, or do you think that with this patch most users' issues will be resolved?. @droazen , the total layers is now down to **16** (from 44). I honestly don't see the value of doing a full squash, mainly because if we are hosting this in a premium ACR, the limit is 10,000 readOps per minute. So with 16 layers, you get around 625 pulls per minute. Also, this will be able to still take advantage of parallel pulls (default is 3, but at most 16 threads in this case, I believe) as opposed to one big layer which will not download in parallel. There's the potential of that being a lot slower and subsequent jobs falling into the same ""minute"" because others are not done, making it easier to hit that 10k readOps limit. Lastly, people using GATK outside data pipelines will not be able to take advantage of layer caching too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8808#issuecomment-2102891281:301,down,down,301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8808#issuecomment-2102891281,2,['down'],"['down', 'download']"
Availability,"> The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. I wonder if this has to do with the base qualities simReads generates. Can you post some reads from both sets?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6705#issuecomment-658842808:145,error,error,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705#issuecomment-658842808,1,['error'],['error']
Availability,"> This gives a compilation error. On line 1973, you have disjointPairCounts.bumpCount(reportType);; > ; > It should be disjointPairCounts.bumpCount(ignoredMate);. That was silly on my part - fixed. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8557#issuecomment-1822835932:27,error,error,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8557#issuecomment-1822835932,1,['error'],['error']
Availability,"> Two questions:; > ; > `getMaxClusterableStartingPositionWithParams` in `CanonicalSVLinkage` uses the `window` to determine the max clusterable position. Will setting the value to 10MB make everything look clusterable to this method, potentially bogging down the algorithm for large callsets?. `getMaxClusterableStartingPositionWithParams` should be smart enough to use enough both the window and reciprocal overlap to calculate the max position, taking the min of the two if both are required. Effectively we're just disabling the window requirement so the RO will always be used I think. > Is there a reason to keep the keep the old code around if this is the intended way to disable the proximity check (setting the window very large)? Seems like an opportunity to simplify if you don't want to support that special case anymore. I was thinking of doing that, but we're probably also going to start doing some experimenting with new clustering strategies in the near future so I wanted to keep it in just in case. I'll add a comment noting that the AND vs OR functionality is not used anymore.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8962#issuecomment-2343727259:255,down,down,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8962#issuecomment-2343727259,2,['down'],['down']
Availability,"> did we figure out why the number goes down sometimes?!??!. We think it has to do with someone creating a jar on a branch (with many commits ahead of `ah_var_store`) and someone who creates a jar on `ah_var_store` (or on a branch that not very ahead of `ah_var_store`) where the merged branch commits have been squashed. Not confirmed, but it makes a kind of sense.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8376#issuecomment-1604311206:40,down,down,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8376#issuecomment-1604311206,1,['down'],['down']
Availability,">--af_of_alleles_not_in_resource: is this allele frequency used only in certain contexts, e.g. with matched normal analyses, or towards tumor sample variant alleles, etc.? I need to add to the doc details how this argument factors into calculations. This is the population AF assigned to a variant not found in the germline resource and is inversely proportional to the number of samples used to create that resource. For example, gnomAD contains about 16,000 wgs samples, or 32,000 homologs per locus. Thus the AF of an allele not found in gnomAD is probably 1/32,000 or less. This is useful because it lets us use absence from the germline resource as evidence that an allele is *not* a germline variant. >I need a sentence or two describing the new algorithmic improvement on the new Mutect2 integration over uncertainty. Since allele depths (ADs) are subject to statistical error -- i.e. the exact number of reads for an allele is a random variable -- alleles' allele fractions are not known. Previously, M2 estimated allele fractions ffrom the ADs and proceeded with the likelihoods calculation. Now M2 uses nifty math to account for the uncertainty in the allele fraction when calculating likelihoods. In statistical language (which *will* be familiar to a decent-sized minority of users) we marginalize over allele fractions instead of using a maximum likelihood estimate. >The WDLs do not include use of a contamination.table and so I did not include it in the commands. Is this something we want to nudge users to use, i.e. should I put in a sentence in the documentation section about the new tool CalculateContamination?. `CalculateContamination` is invoked inside the `Filter` task in mutect2.wdl. We want users to use the new tool. You might mention that in the interest of speed you can pass it `-L 1` to use only variants on chromosome 1, which gives a very good estimate in a couple of minutes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306107618:878,error,error,878,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306107618,1,['error'],['error']
Availability,>Let's do off by default for all modes. Error if MNPs and GVCF mode. @ldgauthier Done and done. @LeeTL1220 I need for your sign-off as well.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-388163049:40,Error,Error,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-388163049,1,['Error'],['Error']
Availability,?src=pr&el=desc) will **decrease** coverage by `80.096%`.; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #5594 +/- ##; ===============================================; - Coverage 87.046% 6.951% -80.096% ; + Complexity 31524 2797 -28727 ; ===============================================; Files 1928 1934 +6 ; Lines 145340 145727 +387 ; Branches 16089 16104 +15 ; ===============================================; - Hits 126513 10129 -116384 ; - Misses 12966 134867 +121901 ; + Partials 5861 731 -5130; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5594?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...der/tools/HaplotypeCallerSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.439% <> (-65.854%)` | `2 <0> (-14)` | |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-100%)` | `0 <0> (-21)` | |; | [...llbender/utils/downsampling/MutectDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvTXV0ZWN0RG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-68.182%)` | `0 <0> (-17)` | |; | [...ownsampling/ReadsDownsamplingIteratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVhZHNEb3duc2FtcGxpbmdJdGVyYXRvclVuaXRUZXN0LmphdmE=) | `1.639% <0%> (-64.361%)` | `1 <0> (-7)` | |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758:1264,down,downsampling,1264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758,1,['down'],['downsampling']
Availability,"@AJDCiarla . Hello. So, to preface my answers it's also important to note that I am having these issues on Firefox. Now that I tried it in Chromium the Sign in link works. `When did you start having trouble signing into your GATK account?`; The issue is actually not with my account. I cannot even get to the Sign-in screen that you show.; `What is the username/email address associated with your GATK Forum account?`; As I mentioned before, the issue is not account specific. In fact I don't really remember if I still have one. My plan was to try my email and if it was already in the system to recover it.; `Could you please walk me through more of what you are seeing/doing when trying to log into your existing GATK account?`; When I open the [forum page](https://gatk.broadinstitute.org/hc/en-us/community/topics) and click New Post button or if I just click the ""Sign in"" button in the top panel. ![image](https://user-images.githubusercontent.com/22867431/204882347-257314af-1421-4e74-87e2-dffe760480d1.png). I don't get redirected to the Sign in page, but to the main page of GATK; ; ![image](https://user-images.githubusercontent.com/22867431/204882697-43bd0d15-0dd8-479b-af69-78951bb7d56c.png). The URL that I see in the browser does have some extra info:. https://gatk.broadinstitute.org/hc/en-us/signin?return_to=https%3A%2F%2Fgatk.broadinstitute.org%2Fhc%2Fen-us%2Fcommunity%2Fposts%2Fnew . But it still doesn't change where I end up.; The same is happening eevn if I run Firefox with `--safe-mode` to see if it's due to any of my extensions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8115#issuecomment-1332595323:597,recover,recover,597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8115#issuecomment-1332595323,1,['recover'],['recover']
Availability,@AJDCiarla It would also be useful to know whether the error occurs when the user runs `GenotypeGVCFs` without the `--force-output-intervals` argument.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7938#issuecomment-1188238905:55,error,error,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7938#issuecomment-1188238905,1,['error'],['error']
Availability,@AJDCiarla The user should try re-running `GenotypeGVCFs` with `--max-genotype-count` set to a value greater than 1024. This should prevent the PLs from getting dropped and avoid the downstream error. The user may also need to increase `--max-alternate-alleles` as well.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7938#issuecomment-1187744382:183,down,downstream,183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7938#issuecomment-1187744382,2,"['down', 'error']","['downstream', 'error']"
Availability,"@Akazhiel It looks like the problem is with your gnomad vcf. Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: /media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz (Device or resource busy), for input source: /media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz. Can you verify that `/media/AGROS/hg19/af-only-gnomad.raw.sites.vcf.gz` is not actually busy?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7059#issuecomment-775388546:154,error,error,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7059#issuecomment-775388546,1,['error'],['error']
Availability,"@AlijahArcher We will need to clarify exactly what you intend by skipping the assembly. Here are some possibilities, with my initial thoughts:. * ""skip assembly"" = ""trust the alignments completely and use them directly for variant calling"": if your aligner is good this is reasonable though not ideal. If this is what you want you might as well use samtools for variant calling.; * ""skip assembly"" = ""every unique pattern of variants seen in your reads defines a haplotype"": the problem is that every sequencing error generates a new haplotype, so you need some way to cull bad haplotypes. Also, reads might only cover part of a haplotype so you need a way to sew them together.; * ""skip assembly"" = ""find all variants in your read alignments and let every combination thereof define a haplotype"": if I recall correctly this is FreeBayes. I would call this a quick-and-dirty assembly rather than skipping assembly entirely.; * ""skip assembly"" = ""avoid haplotypes altogether and genotype variants directly"": as you are aware, this is not possible within HC and M2. Hopefully that focuses the conversation somewhat on the two main questions: how do you generate haplotypes, and how do you refine the set of haplotypes to a few good candidates? What did you have in mind?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7064#issuecomment-770995444:512,error,error,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7064#issuecomment-770995444,1,['error'],['error']
Availability,"@Aqoolare Hello. There are a a few things going on here. The `unrecognized runtime attribute keys` warning is coming from cromwell. It's telling you that the cromwell **local** backend doesn't understand those keys, which is true. That means it's just ignoring them. I think the actual problem is different though. You're running the spark tool in spark local mode, which in this case isn't configured to use the correct amount of cores or memory. I think the intent of this wdl script was that it would be run in a container on a cluster and the container would restrict the cores and memory options. In any case, it's not configured correctly for what you need. I would skip running cromwell and just invoke gatk directly since this wdl only executes a single job. Since this is going to run spark in local mode you need to specify the number of cores using the `--spark-master` argument, and set the memory using the `--java-options ""-Xmx""` arguments. For example:. ```; gatk ReadsPipelineSpark ; --java-options ""-Xmx16G"" ; --spark-master 'local[8]'; --I yourbam.; ... etc; ```. The above command is specifying to use 8 (that's what the local[**8**] means) cores for spark and give it 16G of memory. Your job was accidentally using 200 cores so it doesn't surprise me that it would run into memory issues. Using spark with more than 16ish cores in a single process is going to bog down a lot. I think 8 is a good starting place to try. If you want to go wider you should really look into running a proper cluster (or using dataproc), but there's pretty heavy diminishing returns. Try 8 or 16 and tune the memory from there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7796#issuecomment-1108913771:1384,down,down,1384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7796#issuecomment-1108913771,1,['down'],['down']
Availability,"@AxVE Thanks for this PR. We really appreciate your interest and work on resolving this issue! It might take a little bit for me to get to reviewing it properly, we're currently preparing for our release and we're a bit swamped with various issues. I'm worried about changing the `userClassPathFirst` property. We added that a long time ago because it fixed some issues we were running into at the time. It's completely possible that we no longer have the same issue and it's a harmful remnant from a previous time, but I'm afraid that changing it might have unanticipated consequences in our own spark environment. Unfortunately we don't have good automated tests that would necessarily identify any issue. @cwhelan Would you be able to test your pipeline with - ""spark.driver.userClassPathFirst"" : ""false"" and see if you run into any issues? . I'm also a bit confused about why the change to the arguments is necessary. Clearly in your environment it is, but it goes against my understanding of how we set the arguments to spark submit, so I want to properly understand why the existing --deploy-mode arguments aren't working for you before adding an additional hardcoded argument to the launch script. (As I'm sure you've seen, the launch script is a pretty crufty and brittle piece of code that was really meant to be replaced with a more robust solution by now, so any additional complexity in would be great to avoid...)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-351430567:1343,robust,robust,1343,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-351430567,1,['robust'],['robust']
Availability,"@Bowen1992 **I got the same error, do you have a solution now?**. Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx76800m -jar /home/zwc1988/miniconda3/envs/gatk/share/gatk4-4.2.6.1-0/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R data/ref/CL200105941_L02.fa -V gendb://results/genotype/genodb/group2 -O results/genotype/vcfs/group2.vcf.gz --tmp-dir ./tmp; 18:24:10.205 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zwc1988/miniconda3/envs/gatk/share/gatk4-4.2.6.1-0/gatk-package-4.2.6.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 18:24:10.451 INFO GenotypeGVCFs - ------------------------------------------------------------; 18:24:10.452 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.6.1; 18:24:10.452 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:24:10.452 INFO GenotypeGVCFs - Executing as zwc1988@fat01 on Linux v3.10.0-957.el7.x86_64 amd64; 18:24:10.453 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_312-b07; 18:24:10.453 INFO GenotypeGVCFs - Start Date/Time: June 19, 2022 6:24:10 PM CST; 18:24:10.453 INFO GenotypeGVCFs - ------------------------------------------------------------; 18:24:10.453 INFO GenotypeGVCFs - ------------------------------------------------------------; 18:24:10.454 INFO GenotypeGVCFs - HTSJDK Version: 2.24.1; 18:24:10.454 INFO GenotypeGVCFs - Picard Version: 2.27.1; 18:24:10.454 INFO GenotypeGVCFs - Built for Spark Version: 2.4.5; 18:24:10.454 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:24:10.455 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:24:10.455 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:24:10.455 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:24:10.455 INFO Genotype",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1159695894:28,error,error,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1159695894,1,['error'],['error']
Availability,"@Cashalow The GC error indicates that you are running out of memory. How much physical memory does your machine have, and how much are you allocating with `-Xmx`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4467#issuecomment-369320265:17,error,error,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467#issuecomment-369320265,1,['error'],['error']
Availability,@DCarbonez Thanks for reporting. A team from intel has recently started looking into some GKL issues. I've forwarded your stack trace to them. Is this a reproducible error? Can you provide any additional information about your system that might help debug?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-631471705:166,error,error,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-631471705,1,['error'],['error']
Availability,"@DanielAmsel That is really strange -- I can't replicate this with the GATK 4.4 image. What happens if you `docker run -it broadinstitute/gatk:4.4.0.0`, and then type `/usr/bin/env python` on the command line? Do you get an error, or does Python come up?. ```; Python 3.6.10 | packaged by conda-forge | (default, Apr 24 2020, 16:44:11) ; [GCC 7.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>>; ```. What about if you try running `./gatk PrintReads --version` Does that work?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8402#issuecomment-1692243089:224,error,error,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8402#issuecomment-1692243089,1,['error'],['error']
Availability,"@DanielAmsel The genomic regions Funcotator uses are based on the [Genocde](https://www.gencodegenes.org/) GTF files. Sometime before Gencode v34 (the version used in the Funcotator v1.7 pre-bundled datasources) Gencode stopped natively creating gene annotations for HG19. The solution for them was to liftover their annotations from HG38. When the version 1.7 datasources release was created, we updated the Gencode datasources to use the latest and greatest at the time, and the only resource available was the lifted over files (full gencode releases live [here](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_34/)). I believe what you're seeing is a result of this liftover.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8403#issuecomment-1650020964:495,avail,available,495,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8403#issuecomment-1650020964,1,['avail'],['available']
Availability,"@DanishIntizar Hello! Thank you for this pr. This is great to see an official plugin from amazon available. I appreciate that you took the time to make it an optional include. I think if we're going to include it we might as well just add it as one of our normal dependencies though. Assuming there aren't any dependency conflicts it **should** (always a risky statement) be independent from everything else. . Thanks also for identifying the different issues you mentioned. It's expected that it won't work with most picard tools as you discovered, but we're actively in the process of updating more of them too support Paths instead of Files so that will slowly improve. The second issue is more worrisome. We regularly use an equivalent provider with google to read reference files through the exact same code, so I suspect there is either some sort of mismatched assumptions in the way they are handling things. Maybe something strange with the Path.resolve methods or the like. (Or in in the much worse potential case a bug in their look ahead caching.). I'd like to look into that before we'd merge this. Ideally we would have tests for this. Are there any public AWS paths we could read from without any secret authentication?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8672#issuecomment-1930094721:97,avail,available,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8672#issuecomment-1930094721,1,['avail'],['available']
Availability,"@DarioS Are you running contamination checks on this sample first? Did that not fail your QC?. It's difficult for us to provide a failure QC metric like this because there are so many different cancer types, each with their own behaviors. The fact that variants are all near their limit of detection is not necessarily a failure of M2 or even your sample. Instead it sounds like maybe you need a tool that would take a VCF as input and produce summary statistics on the VCF that you could then decide on QC metrics for. Does that sound like it would solve your problem?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6674#issuecomment-648951268:130,failure,failure,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6674#issuecomment-648951268,2,['failure'],['failure']
Availability,"@DarioS How much memory are you providing to Java via the `-Xmx` option, and how much physical memory do you have available? You can see how to pass the `-Xmx` option in to GATK here: https://github.com/broadinstitute/gatk?tab=readme-ov-file#jvmoptions",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8654#issuecomment-1889935644:114,avail,available,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8654#issuecomment-1889935644,1,['avail'],['available']
Availability,"@DuyDN This is a known issue in BQSR -- see https://github.com/broadinstitute/gatk/issues/6242. Sorry for the inconvenience! We hope to be able to develop a fix within the next several months. The fact that you ran into this error indicates that there may not actually be any usable reads in that particular read group -- they were likely all filtered out by one of the BQSR filters, which filter out malformed, low mapping quality, unmapped, and secondary alignments. You could likely avoid the error by filtering out that read group using the `ReadGroupBlackListReadFilter` in GATK while running ApplyBQSR (`--read-filter ReadGroupBlackListReadFilter`)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7549#issuecomment-963494490:225,error,error,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7549#issuecomment-963494490,4,['error'],['error']
Availability,@Echopei could you explain why you think this value of AF is wrong?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7215#issuecomment-832377292:1,Echo,Echopei,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7215#issuecomment-832377292,1,['Echo'],['Echopei']
Availability,"@EdwardDixon Isn't this a dupe of https://github.com/broadinstitute/gatk/pull/5142? Have you addressed our original concerns from that PR's discussion thread, some of which I've reproduced below?. ```; droazen commented on Aug 30; @EdwardDixon We have a fair number of GATK users who are stuck with older hardware (including; university clusters that they have no power to upgrade), and we can't just cut these users off by ; imposing such a minimum hardware requirement. The best we can do is to use AVX when it's ; available, and fall back to slower codepaths when it's not. Also, actual crashes in native code impose a significant support burden on our comms team, as they; are often hard to diagnose and deal with. Things like SIGSEGV or SIGILL are a nightmare for our ; support staff. At a minimum we'd need a graceful failure with an easy-to-understand error message; when AVX is not present rather than a crash, before we could make this the default in GATK. ldgauthier commented on Aug 30; Aside from the users with old hardware, very few of the GCS zones guarantee processors that ; support AVX, which would lead to sporadic failures except in central-1f, for example.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428265950:517,avail,available,517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428265950,4,"['avail', 'error', 'failure']","['available', 'error', 'failure', 'failures']"
Availability,"@EdwardDixon Looks like you've had a git accident in this branch and rebased a bunch of other people's commits from master. Can you repair this branch? It should only contain your own commits, not rebased copies of other people's commits.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437403121:132,repair,repair,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437403121,1,['repair'],['repair']
Availability,"@EdwardDixon Sure, here's my suggested repair process:. 1. If you haven't already, add an ""upstream"" remote to your git clone via `git remote add upstream git@github.com:broadinstitute/gatk.git` (or `https://github.com/broadinstitute/gatk.git` if you don't have ssh authentication set up with github). 2. `git fetch upstream`. 3. Copy the files you actually intended to change in this PR into a temp directory somewhere. 4. Create a new temporary branch off of `upstream/master`: `git checkout -b avxcheck_repaired upstream/master`. 5. Copy the files you saved in step 3 back into their original locations in the working tree. 6. `git commit -a`. 7. Examine the diff against upstream/master via `git diff upstream/master HEAD`. Verify that the diff is what you expect. 8. Run `git rev-parse HEAD` and save the commit ID it outputs. 9. Switch back to the broken version of the branch: `git checkout avxcheck`. 10. Run `git reset --hard commit_id_from_step_8`. This will force the branch to point to the repaired commit we created in step 6. 11. Run `git push -f origin avxcheck:avxcheck` to force-push the repaired version of the branch into your fork. Then check that it looks ok on github. For avoiding this sort of thing in the future, here's a few tips:. * Never run `git merge` or `git pull`. Always update your branch with changes from the latest gatk master branch via the command: `git fetch upstream && git rebase -i upstream/master`, followed by `git push -f` to push the rebased branch into your fork. * If you've never run `git rebase` before, read a tutorial on it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437415495:39,repair,repair,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437415495,3,['repair'],"['repair', 'repaired']"
Availability,"@EdwardDixon Thanks for trying this - it would be great if we were able to have a single conda env, but a couple of questions:. - We'd need to understand the affect of this change on our build times. It looks like the travis builds are failing because the dependency downloads are resulting in so many progress messages that we're exceeding the allowable log length, probably because the download is either large or slow. I'm not sure if thats transient or not.; - We try to carefully control the size of our (already sizable) docker image. We'll need to understand how this impacts that.; - @lucidtronix Any thoughts on moving from tensorflow 1.4 to 1.9 ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-416943910:267,down,downloads,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-416943910,2,['down'],"['download', 'downloads']"
Availability,"@EdwardDixon We have a fair number of GATK users who are stuck with older hardware (including university clusters that they have no power to upgrade), and we can't just cut these users off by imposing such a minimum hardware requirement. The best we can do is to use AVX when it's available, and fall back to slower codepaths when it's not. Also, actual crashes in native code impose a significant support burden on our comms team, as they are often hard to diagnose and deal with. Things like `SIGSEGV` or `SIGILL` are a nightmare for our support staff. At a minimum we'd need a graceful failure with an easy-to-understand error message when AVX is not present rather than a crash, before we could make this the default in GATK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417383038:281,avail,available,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417383038,3,"['avail', 'error', 'failure']","['available', 'error', 'failure']"
Availability,"@EdwardDixon What is the behavior if AVX is not available? Does it crash/refuse to run, or is there a graceful automatic fallback to non-vectorized code? Without such a fallback in place, I'm not sure we could switch to it exclusively.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-416991160:48,avail,available,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-416991160,1,['avail'],['available']
Availability,"@Emmalynchen I wouldn't worry about the `log4j:WARN` messages discussed in this thread---they're just harmless annoyances that pop up because we haven't gotten around to making sure the HDF5Library dependency uses the same logger as the rest of the GATK. Looking at your initial post (before you edited it), it looks like DenoiseReadCounts is failing because the panel of normals contains different intervals than those in the read-count collection you are trying to denoise:. ```; 22:50:58.635 INFO SVDDenoisingUtils - Validating sample intervals against original intervals used to build panel of normals...; 22:50:59.487 INFO DenoiseReadCounts - Shutting down engine; [May 7, 2019 10:50:59 PM UTC] org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=894959616; java.lang.IllegalArgumentException: Sample intervals must be identical to the original intervals used to build the panel of normals.; ```. You might try asking for more pointers over in the GATK Forums (https://gatkforums.broadinstitute.org/gatk), if you need them. Good luck!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-491473550:657,down,down,657,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-491473550,1,['down'],['down']
Availability,"@EvanTheB Thanks for moving over to the gatk tracker, I think it make more sense to start here and you'll get more eyes on it. We can always push it back down to htsjdk if we determine that's definitely where the problem is. . I downloaded that vcf, I noticed that the actual download link for it is ; ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/1000G_omni2.5.b37.vcf **.gz** . In zipped form it's a gzip file, but not a bgzip file which is what's required for tribble indexing to work. If you downloaded and unzipped it to just plain old vcf it should be fine though. . I haven't been able to reproduce the issue yet. It looks like to me like line 104 is the first non-header line of the vcf, and I do see that string it's reporting on line 242. Is it possible there's a mix up between files?; ```; 882033 rs2272756 G A . PASS CR=99.79803;GentrainScore=0.7203;HW=4.306476E-6; ```. It sounds a lot like some sort of indexing bug. I don't think it should be #4224 because you're using a vcf instead of a vcf.gz. Hopefully there isn't a different index bug lurking out there... One weird thing I did notice, is that if I regenerate the .idx file, I get a different file from what comes with the vcf from the ftp site. Indexes aren't necessarily unique to a file, but I wonder if the one on the website is corrupted in some way. Could you try running `gatk IndexFeatureFile -F 1000G_omni2.5.b37.vcf` and then re-running your command with the newly generated index. I'm hoping that will fix it. If not we'll have to dig in more.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4761#issuecomment-388416287:154,down,down,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4761#issuecomment-388416287,4,['down'],"['down', 'download', 'downloaded']"
Availability,"@Fazulur I've managed to reproduce this issue. It's a bug in Disq which will require a Disq release and a GATK release before it's available. In the meantime, you can work around the problem by adding; `--create-output-bam-index false` to the command line, then creating the .bai file manually (e.g. with samtools). Hope that helps.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5919#issuecomment-492282468:131,avail,available,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5919#issuecomment-492282468,1,['avail'],['available']
Availability,"@GATKSupportTeam Can you ask the user to provide an example `FUNCOTATION` attribute from their VCF? This error indicates that one or more of the FUNCOTATION attributes are malformed, so it would help to be able to inspect one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7865#issuecomment-1135061463:105,error,error,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7865#issuecomment-1135061463,1,['error'],['error']
Availability,"@GuoYu-Peng I am able to extract the `.tar.gz` (https://github.com/broadinstitute/gatk/archive/4.1.8.1.tar.gz) fine on my end. Make sure you got a complete download -- the file size should be 69,129,515 bytes. Please note that the `.tar.gz` contains only the GATK source code. For a runnable GATK installation you should download the zip file instead (https://github.com/broadinstitute/gatk/releases/download/4.1.8.1/gatk-4.1.8.1.zip)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6719#issuecomment-662529283:156,down,download,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6719#issuecomment-662529283,3,['down'],['download']
Availability,"@Horneth Thank you. . It's very strange. I would expect to see a difference. I wonder if something is wrong with the wiring of those arguments. What version of gatk are you running? (you can find out by using --version`); ; I'm not sure what to make of the memory usage. I'm not sure that `free` will tell you anything useful about java memory, since java usually expands to fill all available memory and then garbage collects as needed. A better estimate of memory use might be to set the `XX:-PrintGCDetails` jvm option and look at what's retained after garbage collection. Or if you're logging into the vms, something like jstat or a proper profiler can tell a lot more about the memory usage.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2640#issuecomment-298707289:384,avail,available,384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2640#issuecomment-298707289,1,['avail'],['available']
Availability,"@Ismaelfermir The message about ""Flush-to-zero"" is normal, and not an error. The problem is likely that your BAM doesn't have read groups in its header, or if it does, those read groups may lack sample names.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-486384034:70,error,error,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-486384034,1,['error'],['error']
Availability,@JavisPeng I think it is having trouble connecting to google cloud to get the gnomAD data. As an alternative you can download the gnomAD data directly to your machine and run against a local copy.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5903#issuecomment-486390665:117,down,download,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5903#issuecomment-486390665,1,['down'],['download']
Availability,"@JavisPeng I wanted to check in. Did you have a chance to download gnomAD locally and run from that? If not, I think that will fix the issue you're seeing. If so, are you all set now?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5903#issuecomment-507296889:58,down,download,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5903#issuecomment-507296889,1,['down'],['download']
Availability,"@KevinCLydon Loos good to me. If you think we should have a different warning in the case where we get an error while checking permissions then I support that, but I'm not sure what we'd tell people exactly. Good to either implement that or merge .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8951#issuecomment-2422957920:106,error,error,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8951#issuecomment-2422957920,1,['error'],['error']
Availability,@LN908 Did you manage to figure out how to resole this error?. Thank you!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7258#issuecomment-1917430655:55,error,error,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7258#issuecomment-1917430655,1,['error'],['error']
Availability,"@LeeTL1220 . This seems to be running into a cromwell / WDL error:. ```; java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); ```. Isn't cromwell supposed to handle `gs://` URLs for localizing files? Do you have any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556:60,error,error,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556,3,"['Failure', 'error']","['Failures', 'error']"
Availability,"@LeeTL1220 @droazen This is ready for review. It modestly improves all of our validations except Dream challenge 4, which I suspect is because the synthetic data doesn't respect mate pairing. To account for that I added an advanced option to turn off mate-awareness. @kachulis Thanks for catching the error in finding fragments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-490599827:301,error,error,301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-490599827,1,['error'],['error']
Availability,"@LeeTL1220 @katevoss @ruchim I started exposing all optional task-level parameters in the somatic workflows so that they could be specified via json when the workflows are used as subworkflows. E.g., `CNVSomaticPanelWorkflow.PreprocessIntervals.bin_length` is an optional task-level parameter that can be specified properly via json when `CNVSomaticPanelWorkflow` is the top-level workflow, but not when `CNVSomaticPanelWorkflow` is used as a subworkflow. This is because `MetaWorkflow.CNVSomaticPanelWorkflow.PreprocessIntervals.bin_length` cannot be set, correct?. However, things quickly became very messy. For example, alongside parameters like `bin_length` which are unique to the PreprocessIntervals task, we also have a lot of optional runtime parameters that are named generic things like `mem` which are not. So to expose these, we'd have to have workflow-level parameters with names like `preprocess_intervals_mem`, etc. It seems like this is exactly the problem the expected functionality would solve, if only it worked past the subworkflow level and the namespace is propagated as one would expect. Requiring that these be exposed also partially obviates the reason for having optional task-level arguments in the first place---what's the point of having them be optional if I have to add lines of code to expose all of them at the workflow level?. So again, I'm strongly against exposing all inputs for a particular workflow on the off-chance that that workflow might be used as a subworkflow. This adds a lot of unnecessary boilerplate that quickly gets very messy. I think that this problem should instead be solved by dynamically bubbling up all inputs, optional or required, at all levels. Anyway, I'm not going to try to tackle this before release, which I think was OK with @LeeTL1220. However, after release, I'd be happy to sit down and discuss how we want to do this sort of thing going forward.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3980#issuecomment-355830670:1849,down,down,1849,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3980#issuecomment-355830670,1,['down'],['down']
Availability,"@LeeTL1220 A few minor remaining comments. Do what you will. How much of a performance impact does the change have? You said it slows it down, is it significant? It might be faster if you make it a long instead of an atomic long which should be safe it it's single threaded and you don't use parallel streams anywhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316490330:137,down,down,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316490330,1,['down'],['down']
Availability,@LeeTL1220 Added in a specific integration test for the `FILTER` field. Also rebased on master to fix the unrelated R test failures.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341:123,failure,failures,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341,1,['failure'],['failures']
Availability,"@LeeTL1220 It sounds like you're suggesting two things. . First, if a datasource config has a space in it, throw an error and tell the user to remove the space. . Second - remove spaces from funcotation field names when outputting the funcotations (could still happen with XSVs with spaces in column headers). Is this correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5937#issuecomment-507298072:116,error,error,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5937#issuecomment-507298072,1,['error'],['error']
Availability,"@LeeTL1220 Latest commit includes the rollback. I will create a separate branch for you that is rebased on sl_preprocess. Looking at it again, I initially described the change to you incorrectly. I thought it was ""similar CR || similar AF -> merge"" to ""similar CR && similar AF -> merge"", but that's not actually the case; it's instead ""similar according to credible interval 1 || similar according to credible interval 2 -> merge"" to ""similar according to credible interval 1 && similar according to credible interval 2 -> merge"". Probably the `&&` behavior is way too conservative, so I think rolling back to the `||` behavior would be fine for release. Let's double check with the validation just to be sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989:38,rollback,rollback,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989,1,['rollback'],['rollback']
Availability,"@LeeTL1220 This consists of a lot of trivial changes where the commit message is self-explanatory, most of which (eg indentation) yield big diffs. Basically it comes down to:; * M2 wdls have better formatting; * autoval works in the cloud; * gatk launch script and docker jar are used properly in all M2 wdls, including the unsupported ones.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4132:166,down,down,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4132,1,['down'],['down']
Availability,"@LeeTL1220 commented on [Mon Feb 01 2016](https://github.com/broadinstitute/gatk-protected/issues/343). In `CreatePanelOfNormals` make anonymize a flag that defaults to `false`. (i.e. `--anonymize`) In other words, by default, we do _not_ produce an anonymized PoN. We could also use a separate tool that takes a pre-existing PoN and anonymizes it. . To anonymize a PoN:; - [ ] Determine which fields are private. At the very least: `fnt_control_matrix`, `log_normals`, and `log_normals_pinv`. _There may be others -- please investigate as part of this issue_; - [ ] Have `CreatePanelOfNormals` delete the fields as the last step.; - [ ] Make sure that `HDF5PoN` produces reasonable error messages if one of these fields is accessed in an anonymized PoN.; - [ ] Create CLI that can take existing PoN and delete the fields. ---. @LeeTL1220 commented on [Mon Feb 01 2016](https://github.com/broadinstitute/gatk-protected/issues/343#issuecomment-178022285). This is necessary since we may want to share PoNs and the PoN files cannot have any private data. ---. @LeeTL1220 commented on [Wed Mar 02 2016](https://github.com/broadinstitute/gatk-protected/issues/343#issuecomment-191420153). Moving this to later milestone, unless it becomes more urgent.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2835:683,error,error,683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2835,1,['error'],['error']
Availability,"@LeeTL1220 commented on [Tue Mar 14 2017](https://github.com/broadinstitute/gatk-protected/issues/937). By grabbing the gatk-protected docker image (or whichever is being used for M2), this task commits to a ~2GB download. However, the task does basic bash commands, which could easily be performed using one of the ``ubuntu:14.04`` images or maybe even one smaller.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2952:213,down,download,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2952,1,['down'],['download']
Availability,"@LeeTL1220 mentioned having difficulty running gCNV on REBC WGS normals. As far as I can tell, other than runs failing due to quota or FC issues, there were some runs that failed because the WDL version and the Docker version were not in sync. Specifically, these runs failed because the WDL was more recent than the Docker, causing the ScatterIntervals task (which was running an out-of-date IntervalListTools in the latter) to ""fail silently"". The behavior upon failure, for reasons due to the somewhat awkward format of the IntervalListTools output, is to output just a single shard by simply copying the original intervals list; this is handled in bash. This single-shard run then failed due to OOM in the gCNV step. Just to be clear, everything typically works fine when the versions are in sync. But you could imagine that even then IntervalListTools could fail for other reasons, in which case we'd probably fail misleadingly at the gCNV step again. So let's modify the WDL so we fail at the appropriate place. Apologies to @asmirnov239, who I think pointed this weirdness out in the original PR review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5744:464,failure,failure,464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5744,1,['failure'],['failure']
Availability,"@LindoNkambule For your dataset, do you expect an extremely large number of novel variants (on the order of 2 billion+)? How many total variants are in your dataset?. @ldgauthier Have you ever encountered an error like this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7859#issuecomment-1135064165:208,error,error,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7859#issuecomment-1135064165,1,['error'],['error']
Availability,"@MartonKN I've labeled the update of the caller as a ""reach"", so I'm not expecting that it gets done before release. However, I expect that the tutorial data should be updated well before release. The tutorial data runs quickly (~1 hr for coverage collection, which is mostly limited by the slowest samples or cloud preemptions, and then ~minutes once collection has been call cached), so we should have plenty of time. Whether or not the actual tutorial itself will be ready depends on whether @sooheelee has available bandwidth and if it is a high priority for comms.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353730988:510,avail,available,510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353730988,1,['avail'],['available']
Availability,"@MattMcL4475 We've merged a PR that reduces the number of layers in our docker image from 44 down to 16: https://github.com/broadinstitute/gatk/pull/8808. See comments on that PR for reasons why this approach might be preferable to a full squash. If there are still too many layers for your use case, please feel free to reopen this ticket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-2103231924:93,down,down,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-2103231924,1,['down'],['down']
Availability,"@MengZhang2019 I have not seen this kind of error before, but the first thing I would do is to set java heap limit using `--java-options ""-Xmx280g""`. . Also, what kind of samples are these? PathSeq generally runs better when there are <10M microbial reads in the sample, and large microbe-rich samples can cause issues. Downsampling the bam and omitting `--filter-metrics` can be helpful in this case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6293#issuecomment-624718013:44,error,error,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6293#issuecomment-624718013,2,"['Down', 'error']","['Downsampling', 'error']"
Availability,"@MigleSur Looks like you created an issue using just the template. I'll close this out assuming it was created in error. If you do have an issue, feel free to re-open and edit to include the details. thx.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4898#issuecomment-397597920:114,error,error,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4898#issuecomment-397597920,1,['error'],['error']
Availability,"@MikeWLloyd GATK uses code in htsjdk that, for better or worse, attempts to ""repair"" bad headers when it sees them, and I suspect thats what is happening here. I'm not sure what version the old and new headers are in your case, but it looks to me like the VCF spec going back to at least v4.1 does explicitly state that GQ is integer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8629#issuecomment-1861463671:77,repair,repair,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8629#issuecomment-1861463671,1,['repair'],['repair']
Availability,"@MikeWLloyd It seems like you are running `Mutect2` in parallel, which is totally fine, and then running `FilterMutectCalls` in parallel as well, which is not how the tool works. You need to run `MergeMutectStats` on the `.vcf.stats` files and run `MergeVcfs` on the scattered `.vcf`s, and then run `FilterMutectCalls` with the merged files as inputs. This is implemented in the mutect2 WDL: https://github.com/broadinstitute/gatk/blob/master/scripts/mutect2_wdl/mutect2.wdl and the featured workspace in Terra: https://app.terra.bio/#workspaces/help-gatk/Somatic-SNVs-Indels-GATK4. The error seems to occur because the `.stats` file for the failing interval shows no callable depth. That is, every locus in the interval had a depth less than 10. Once you merge your files I would hope that somewhere in the genome there is a site with greater depth. (If not, you can adjust the threshold with the `--callable-depth` argument)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-548016293:587,error,error,587,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-548016293,1,['error'],['error']
Availability,"@MikeWLloyd No need to look - I know exactly where and why its happening. Unfortunately, I don't know of any way to stop it short of implementing a more principled header versioning scheme (which we've done, but it's not merged yet). And honestly, although I understand it causes you downstream issues, in this case, I think the repair is doing the right thing anyway, since its making the header spec-compliant where it previously wasn't.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8629#issuecomment-1861539568:284,down,downstream,284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8629#issuecomment-1861539568,2,"['down', 'repair']","['downstream', 'repair']"
Availability,"@MikeWLloyd Sorry you had to track that down. Although I sympathize, I doubt we would undertake to update the documentation for that, since its complicated to explain (there are other ramifications since many types of lines can be repaired), and I would guess that it affects about 50 GATK tools. We do have a plan and implementation for a better versioning strategy for VCFv4.3+.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8629#issuecomment-1861596930:40,down,down,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8629#issuecomment-1861596930,2,"['down', 'repair']","['down', 'repaired']"
Availability,@MinS1 @MengZhang2019 Would it be possible for one of you to attach a full log file? Also are you sure there is sufficient disk available? I have a feeling this may relate to temp or memory swap storage.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6293#issuecomment-625922070:128,avail,available,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6293#issuecomment-625922070,1,['avail'],['available']
Availability,"@NTNguyen13 Yes, I just merged the PR that fixes it - https://github.com/broadinstitute/gatk/pull/6613 so it will be available in the next release. Thank you again for bringing this up.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6573#issuecomment-634766708:117,avail,available,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6573#issuecomment-634766708,1,['avail'],['available']
Availability,@NeginValizadegan For some reason you appear to be running very old Picard versions. This most recent error message you posted is coming from an even older version of Picard (`2.9.0-1-gf5b9f50-SNAPSHOT`) than the first one you posted (which you said was `2.10.1`). I would suggest upgrading to [2.27.5](https://github.com/broadinstitute/picard/releases).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274:102,error,error,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274,1,['error'],['error']
Availability,"@NeginValizadegan Thanks for looking into it, and sorry you're still seeing the issue. . Is that error message from the 2.10.1 version? It doesn't line up with the code in 2.27.1 so either you're posting your original error, or you're not getting the version of picard you expect. Would it be possible to include the entire program log, and the command line to run it here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739:97,error,error,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739,2,['error'],['error']
Availability,"@Ning-310 The error you're getting here (""Did not inflate expected amount"") implies that your input file is likely corrupt. Can you try running the tool `PrintBGZFBlockInformation` to validate the compressed blocks in your `.vcf.gz`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7114#issuecomment-793015796:14,error,error,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7114#issuecomment-793015796,1,['error'],['error']
Availability,@RWilton There is not particular code I can point to that specifically should fall over. We filter out low MQ reads in large part because they are very likely to cause false positives corresponding to sequence from other regions on the genome and the current behavior for adjusting genotyper confidences based on mapping quality (which is accomplished by lowering the Base Qualities based on the MQ prior to the HMM step) doesn't work well enough especially at sites where there are many low MQ reads piled-up. It should be noted that based on how many sequencers work low MQ reads appear piled up in the thousands at a some commonly repeated sites in the genome and can easily drown out all of the other evidence unless you are careful. Keep an eye out for #6634 as it will include the argument you are asking about as well as providing an explicit model in the genotyper for mapping quality as a source of errors which will likely better handle high coverage + low MQ sites explicitly.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6854#issuecomment-701629283:908,error,errors,908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6854#issuecomment-701629283,1,['error'],['errors']
Availability,"@SHuang-Broad I see. So the conversion to SAM and back when we write the file actually changes the results (or at least their annotations). It makes me a little nervous that in one version of the pipeline the records go through `BwaMemAlignmentUtils.applyAlignment` and in the other they don't, since that method has some complex logic. Right now we have two possible paths:. `AlignedAssemblyOrExcuse -> SAMRecord -> writeToFile -> GATKRead -> AlignmentRegion`. or . `AlignedAssemblyOrExcuse -> AlignmentRegion`. What if we always converted to `SAMRecord`? It's a little more expensive but it would cut down on alternate code paths and conversion code, and IMO would make the code a lot simpler to read if I didn't have to think about which code path I was in. I'm also worried that the different conversions could lead to bugs that will be hard to debug since you have to know the code path that generated them. @tedsharpe what do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294168022:603,down,down,603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294168022,2,['down'],['down']
Availability,"@SHuang-Broad Thanks, that's good to know that it actually fixes the problem you're having... I think we need to investigate this error a bit more though before we can merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-511987146:130,error,error,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-511987146,1,['error'],['error']
Availability,"@SHuang-Broad can you create two new issues, for 1) the error you saw on one of the runs about the missing bwa index file -- maybe we could verify that it's there on all the nodes or do retries and 2) the variability in the number of kmers found and variants discovered? You can assign the latter one to @tedsharpe .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294157463:56,error,error,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294157463,1,['error'],['error']
Availability,"@SHuang-Broad hard to say. It's a small change once I get to it, but then it needs to go through review and wait for a release. To give a very rough estimate I'd say perhaps a month, with wide error bars.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-493513447:193,error,error,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-493513447,1,['error'],['error']
Availability,"@SHuang-Broad reports having problems running spark tests when his machine is connected to the broad vpn. Errors seem to occur with any tests that start a spark context. They all seem to be caused by `java.net.BindException`. ```; 23:59:49.200 ERROR NettyTransport:65 - failed to bind to /10.1.2.144:0, shutting down Netty transport; 23:59:49.200 WARN Utils:71 - Service 'sparkDriver' could not bind on port 0. Attempting port 1.; 23:59:49.200 ERROR Remoting:65 - Remoting system has been terminated abrubtly. Attempting to shut down transports; 23:59:49.206 ERROR NettyTransport:65 - failed to bind to /10.1.2.144:0, shutting down Netty transport; 23:59:49.206 ERROR SparkContext:96 - Error initializing SparkContext.; java.net.BindException: Failed to bind to: /10.1.2.144:0: Service 'sparkDriver' failed after 16 retries!; at org.jboss.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272); at akka.remote.transport.netty.NettyTransport$$anonfun$listen$1.apply(NettyTransport.scala:393); at akka.remote.transport.netty.NettyTransport$$anonfun$listen$1.apply(NettyTransport.scala:389); at scala.util.Success$$anonfun$map$1.apply(Try.scala:206); at scala.util.Try$.apply(Try.scala:161); at scala.util.Success.map(Try.scala:206); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1534:106,Error,Errors,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1534,9,"['ERROR', 'Error', 'down']","['ERROR', 'Error', 'Errors', 'down']"
Availability,@SebastianHollizeck Are you able to share the unfiltered VCF and .vcf.stats file from Mutect2 that caused this error?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-595345149:111,error,error,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-595345149,1,['error'],['error']
Availability,"@ShirelyI can you elaborate a bit on the exact issue here? You're trying to run GenotypeGVCFs on some input genomicsdb workspace, and it doesn't work at all with the above error? Or does the error only happen with certain workspaces (chr23)? Can you also list the files/folders in (one of) the workspaces that doesn't work?. Can you also share the contig description from the fasta, maybe by grepping something like; ```; grep ""^>"" genome.fasta; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-1648684414:172,error,error,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-1648684414,2,['error'],['error']
Availability,"@Siadjeu Could you try running the latest 4.1.9.0 release and reporting whether you get the same error? We updated a number of our dependencies for that release, including the Google cloud NIO library that the error is coming from.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707916225:97,error,error,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707916225,2,['error'],['error']
Availability,"@Siadjeu Don't worry about the ""Failed to detect"" message. It indicates some internal state in one of the google libraries but not an error we need to worry about. Generally you shouldn't worry about INFO messages if everything else is going fine and they don't say something particular about what you're doing. A WARNING or ERROR message would indicate a problem. This should maybe be downgraded to be a DEBUG level message or something but it's in a third library and convincing them to change it might be a hassle.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708443156:134,error,error,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708443156,3,"['ERROR', 'down', 'error']","['ERROR', 'downgraded', 'error']"
Availability,@SnehalA have you seen this error before? @KMannth?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6649#issuecomment-754933140:28,error,error,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649#issuecomment-754933140,1,['error'],['error']
Availability,"@Stikus Yes, this is expected, and is mentioned in the release notes for 4.1.8.0:. * More flexible matching of dbSNP variants during variant annotation (#6626); * Add all dbsnp id's which match a particular variant to the variant's id, instead of just the first one found in the dbsnp vcf.; * Be less brittle to variant normalization issues, and match differing variant representations of the same underlying variant. This is implemented by splitting and trimming multiallelics before checking for a match, which I suspect are the predominant cause of these types of matching failures. For more details see the original pull request here: https://github.com/broadinstitute/gatk/pull/6626",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6690#issuecomment-653119026:576,failure,failures,576,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6690#issuecomment-653119026,1,['failure'],['failures']
Availability,"@SusieX Sorry for the delay, we're just trying to finalize some potentially disruptive changes before we merge. I'll open an issue so I can ping you there once this PR has been both merged and released. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-430237566:140,ping,ping,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-430237566,1,['ping'],['ping']
Availability,"@TearsWillFall To help us diagnose this issue, could you please try running the same `CNNScoreVariants` command in our official 4.2 docker image in dockerhub (https://hub.docker.com/r/broadinstitute/gatk/), and report whether you get the same error?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-847248626:243,error,error,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-847248626,1,['error'],['error']
Availability,"@TedBrookings which formats are you using, in particular? If there is a format out there that nicely fits our needs, we should adopt it. In the CNV package, I've taken pains to unify how tabular data are represented in Java, depending on whether each record is Locatable or whether the collection of records can be associated with a sample name or sequence dictionary. This allows us to represent records that extend Locatable with *multidimensional numerical or non-numerical annotations* along with some metadata (sample name and sequence dictionary) with a minimum of boilerplate. There are also base methods for producing interval trees, etc. This pretty much satisfies all of the CNV team's needs (and is, in my opinion, a necessary improvement over the horrowshow of read/write utility methods for each file format that we had previously...). However, this unification effort was a quick push I made before release, so some polishing or redesigning may be warranted. We may also want to add more forms of metadata, etc. if other teams would require more features. Another downside is that this code lacks the indexing, NIO support, etc. that some of the other standardized/Tribble formats enjoy. For CNV data, this isn't a huge issue, but I think it would be nice to unify how we represent such data GATK-wide. As I said above, I don't think VCF is the correct answer, but certainly it could fit into whatever framework we adopt or come up with.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468:1078,down,downside,1078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468,1,['down'],['downside']
Availability,"@TianJin297 I'm sorry you're hitting this issue. I haven't seen this error myself so I'm not sure exactly what's going on. We test with spark 2.0.2 and hadoop 2.7.3. (We're currently using google dataproc for most of our work, using [image version 1.1](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions)) I would suspect that newer versions would also work, but I can definitely tell you that gatk has issues with any spark before 2.0.2. . We'll need to see if we can reproduce locally, it's possible that it's a bug unrelated to the spark version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306836459:69,error,error,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306836459,1,['error'],['error']
Availability,"@TianJin297 commented on [Fri May 26 2017](https://github.com/broadinstitute/gatk-protected/issues/1107). When I was running HaplotypeCallorSpark with one of my samples, I got an error as ""Duplicate key"". . The command I used is ""/gatk-protected HaplotypeCallerSpark -I XX_BQSRappliedspark.bam -O XX_525.gvcf -R /curr/data/humann_g1k_v37.2bit --emitRefConfidence BP_RESOLUTION --TMP_DIR tmp"". And it runs on Amazon instance m4.2xlarge. 00:10:41.089 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:41.089 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:41.089 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:45.460 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:45.460 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:11:09.609 WARN TaskMemoryManager:381 - leak 166.6 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@60a3c432; 00:11:09.611 ERROR Executor:91 - Exception in task 15.0 in stage 1.0 (TID 519); java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:179,error,error,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['error'],['error']
Availability,"@TianJin297 commented on [Fri May 26 2017](https://github.com/broadinstitute/gatk-protected/issues/1108). The command is gatk-protected HaplotypeCallerSpark -I XX_BQSRappliedspark.bam -O XX_spark.vcf -R /curr/data/humann_g1k_v37.2bit --emitRefConfidence GVCF --TMP_DIR tmp. And it is run on an Amazon m4.2xlarge instance. The error messages are like below.; 04:39:06.415 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 05:09:00.269 ERROR Executor:91 - Exception in task 8.0 in stage 1.0 (TID 345); java.lang.ArrayIndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 05:09:00.455 WARN TaskSetManager:66 - Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayIndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:326,error,error,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"@Tintest Sorry for the slow reply. I'm not sure exactly what the issue is. I've never seen this exact error before. . I have two guesses, one is that there's something really weird going on in spark that's causing that null pointer exception which is killing the heartbeat. I'm not sure how to debug that without your access to your input data . The other theory which I think is more likely, is that you're running out of memory and it's causing weird errors to occur. How much memory is available to your job? You can set the java -Xmx value with `--java-options ""-Xmx120g""` as a GATK option. I would check that you're not running out of memory on your machine, or giving the job too little. I think for BaseRecalibratorSpark you want at least 2-4g per core, but haven't tested it in a long time so I might be wrong about that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134:102,error,error,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134,4,"['avail', 'error', 'heartbeat']","['available', 'error', 'errors', 'heartbeat']"
Availability,"@Twojarshub Hi! Have you solved the problem? As I mentioned in my post, just adding ""--use-jdk-inflater true --use-jdk-deflater true"" in the step of GenotypeGVCFs could not solve the problem [https://github.com/broadinstitute/gatk/issues/7582](url) . In my case, I restarted from one step ahead (BQSR) with those options and could finish the pipelines without an error. Please try!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1005376853:363,error,error,363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1005376853,1,['error'],['error']
Availability,"@Unip0rn Thank you for the pr. I'm not sure I understand what you're trying to do here though. currently when I run `./gatk --list` it prints the list of gatk tools. ex:; ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the --",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:204,Avail,Available,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030,1,['Avail'],['Available']
Availability,"@V-Z The error you encountered is a regression in `new-qual` that was introduced in `4.0.5.0`. You can track this issue here: https://github.com/broadinstitute/gatk/issues/4975. For the purposes of this ticket, you might want to do a test with GATK 4.0.4.0 and `new-qual`, and see if that works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401931618:9,error,error,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401931618,1,['error'],['error']
Availability,"@V-Z Would you mind sharing your GVCF, or just the offending chunk, with me so I can debug? I'm pretty sure it's a finite precision error and have a simple fix in mind but I would like to confirm on real data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402199745:132,error,error,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402199745,2,['error'],['error']
Availability,"@Vzzarr Don't worry, these things are complicated and take time to learn! You can use whatever you want, I just know more gradle than maven so it's easier for me to help with that. . I'm having trouble reproducing the error you're having. Is your project on github? Or at a minimum could you paste your pom file here? . In the meantime, could you try cloning https://github.com/lbergelson/gatk-downstream-test and seeing if `mvn compile` completes successfully?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339761069:218,error,error,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339761069,4,"['down', 'error']","['downstream-test', 'error']"
Availability,@Zepeng-Mu Could create a forum post ([here](https://gatk.broadinstitute.org/hc/en-us/community/topics)) explaining what you tried and the specific error you saw?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6292#issuecomment-682200502:148,error,error,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6292#issuecomment-682200502,1,['error'],['error']
Availability,"@Zepeng-Mu You say the original mapping contained contigs not in your reference but you filtered it with samtools to remove those contigs? I wonder if somehow some mappings to other contigs remain. I opened a PR ( #6781 ) to improve the error message. If you wanted to debug it further and ( have the time and inclination) you could build that commit and rerun with it to get the new error message. Alternatives to proceed would be to use the original reference you mapped it with, or run HaplotypeCaller with an intervals file that only contains the contigs that match the hg19 reference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684130877:237,error,error,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684130877,2,['error'],['error']
Availability,"@adamjorr The test failures are in `BaseRecalibratorIntegrationTest.testBQSR` and `BaseRecalibratorSparkIntegrationTest.testBQSRSpark`. These are old, brittle tests that fail if there is not an exact match with the expected output. You can put a breakpoint in your IDE where the failure occurs and copy the actual result file to the expected file, but first you should spot-check the difference, which should be minor.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6389#issuecomment-580358184:19,failure,failures,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6389#issuecomment-580358184,2,['failure'],"['failure', 'failures']"
Availability,@ahaessly Could you please take a look at this? I'd appreciate it if you would also look at the expected output and make sure those intervals make sense since I don't think that aspect of the code was previously tested and I want to be sure there are no off by one style errors.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8070:271,error,errors,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8070,1,['error'],['errors']
Availability,@ahaessly It looks like you are still running on a somewhat old snapshot of the DRAGEN code. It might be worth updating to master and re-running since we fixed some other errors related to this tool since 4.2 that you might want anyway.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804141441:171,error,errors,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804141441,1,['error'],['errors']
Availability,"@ahaessly This error message indicates a corrupt .crai index file - you should see the same message if you try to read the file with any other GATK tool. Regenerating the index should fix it. Also, let me know if you happen to know what software/version created the index.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804045945:15,error,error,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804045945,1,['error'],['error']
Availability,"@ahaessly and I have figured out what's triggering this error, and are working on a patch. It should be part of the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-698437515:56,error,error,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-698437515,1,['error'],['error']
Availability,"@ahaessly not yet, I'll reach out to the user and let you know when it is available",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-689731165:74,avail,available,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-689731165,1,['avail'],['available']
Availability,"@akiezun @lbergelson Changed the Spark context configuration from ""local[*]"" to ""local[N]"", where N is specified by a environmental variable. Ran gradle test with ""--tests _SparkIntegration_"". Out of 203 tests, one failed: "" testBulkFragmentsNoDuplicates"", the rest passed. Here is the snippet of code change. Any suggestions?. ```; private static JavaSparkContext createTestSparkContext(Map<String, String> overridingProperties) {; determineSparkMaster();; final SparkConf sparkConf = setupSparkConf(""TestContext"", DEFAULT_SPARK_MASTER, DEFAULT_TEST_PROPERTIES, overridingProperties);; return new JavaSparkContext(sparkConf);; }. /**; * Determine the number of cores Spark master should use. Only used in Spark Test; * Read the specification from the environmental variable GATK_TEST_SPARK_CORES; * If the value is a valid positive integer, use it; * If the value is bogus (strings, etc), or the env. var. is not set, use all available cores, as in ""local[*]""; */. private static void determineSparkMaster() {; int foo = 0;; try {; foo = Integer.parseInt( System.getenv(""GATK_TEST_SPARK_CORES"") );; } catch ( NumberFormatException e ) {}; String numSparkCores;; if ( foo > 0 ) {; numSparkCores = String.format(""[%d]"", foo);; } else {; numSparkCores = ""[*]"";; }; DEFAULT_SPARK_MASTER = ""local"" + numSparkCores;; }. ```. Error messages:. ```; java.lang.NullPointerException at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:77); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1768:927,avail,available,927,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1768,1,['avail'],['available']
Availability,"@akiezun Instead of adding these overloads would we see the same speedup if we cached the result of isUnmapped and isPaired in the adapter? That would have the downside of complicating the adapter but it might avoid adding these strange methods to the interface. . If caching seems like a bad alternative, I think maybe these methods should have names that make it clear that they're some sort of performance hack and you should generally prefer the standard ones. 'getContigUnsafe` for instance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235101307:160,down,downside,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235101307,1,['down'],['downside']
Availability,"@akiezun The goal is to use a genome mask, like for example Heng's low complexity sequence mask, which has many small intervals from the reference to be masked out. To that end I've tried using both the -XL exclude regions arg and -L with a 'complement' version of the mask. I was running on custom 10X tools in one of my branches but the problem exists with simpler tools like PrintReadsSpark. . For example running like this on a bam subset of 1MB of the reference is fine:. ```; time /humgen/gsa-scr1/cwhelan/GATK/gatk/gatk-launch PrintReadsSpark --input test_in.bam -O test_out.bam -- --sparkRunner LOCAL; real 0m49.678s; user 5m10.396s; sys 0m14.556s; ```. But add the complemented mask:. ```; $ time /humgen/gsa-scr1/cwhelan/GATK/gatk/gatk-launch PrintReadsSpark --input test_in.bam -O test_out.bam -L /humgen/gsa-hpprojects/dev/cwhelan/gatk-sv/hs37d5LCRs.complement.bed -- -- sparkRunner LOCAL; ```. And it's still running 35+ minutes later. Similar results observed using the original mask and XL argument:. ```; $ time /humgen/gsa-scr1/cwhelan/GATK/gatk/gatk-launch PrintReadsSpark --input test_in.bam -O test_out.bam -XL /humgen/gsa-hpprojects/dev/cwhelan/gatk-sv/hs37d5LCRs.bed -- --sparkRunner LOCAL; ```. Let me know if I can provide more details.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1532#issuecomment-209056610:37,mask,mask,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1532#issuecomment-209056610,6,['mask'],"['mask', 'masked']"
Availability,"@akiezun commented on [Wed Oct 28 2015](https://github.com/broadinstitute/gatk-protected/issues/169). all parts that are a) mature enough b) shared between germline and somatic CNVs should be moved to the public gatk repo. . OK to do past alpha. ---. @akiezun commented on [Wed Nov 04 2015](https://github.com/broadinstitute/gatk-protected/issues/169#issuecomment-153783985). @LeeTL1220 @vruano can you list here the name of the subcomponents that would be pushed down to gatk public?; A lot of code would qualify I think: Targets, Segments, etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2827:464,down,down,464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2827,1,['down'],['down']
Availability,@alanhoyle Can you tell us whether the 400 Bad Request error is repeatable -- did you see it more than once? Oftentimes when accessing cloud data we encounter transient errors like this that go away on their own.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-724225557:55,error,error,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-724225557,2,['error'],"['error', 'errors']"
Availability,@aliveben2k Are you still encountering this error?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7008#issuecomment-754178433:44,error,error,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7008#issuecomment-754178433,1,['error'],['error']
Availability,"@alrafaykhan Did you clone (this) repository with git, and if so, is the root of that clone the location from which you're running ./gradlew ? I'm not sure how that happened, but it seems like you have build.gradle, but not the rest of the repo. You also can download a [zip file with GATK already built](https://github.com/broadinstitute/gatk/releases) if you just want to run it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369654074:259,down,download,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369654074,1,['down'],['download']
Availability,@alrafaykhan I'm guessing that you downloaded the source code zip instead of actually cloning our git repository. You need to clone the repository to build GATK.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369675396:35,down,downloaded,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369675396,1,['down'],['downloaded']
Availability,@andrew-niaid Would changing the setting to only make it read/writeable by the owner of the gatk process be sufficient for you? I'm afraid changing the behavior to error on a non-writable tmpdir would cause people's pipelines to start failing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371644801:164,error,error,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371644801,1,['error'],['error']
Availability,@andrewrech I'm not certain. Let's let @davidbenjamin or @takutosato weigh in before we get too far down this rabbit hole . I'm not super knowledgeable about the details of mutect and don't want to give any bad information.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-525364547:100,down,down,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6102#issuecomment-525364547,1,['down'],['down']
Availability,"@apete Thanks for the PR! That's really helpful to update and any svd improvements are definitely something we want. . It's failing to build though, because it can't locate `ojalgo-extensions-1.0.0`. I get the following error:; ```; Build file '/Users/louisb/Workspace/gatk/build.gradle' line: 511. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Could not resolve all dependencies for configuration ':runtime'.; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; Required by:; project :; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://repo1.maven.org/maven2/org/ojalgo/ojalgo-commons-math3/1.0.0/ojalgo-commons-math3-1.0.0.pom; > Could not find org.ojalgo:ojalgo-extensions:1.0.0.; Searched in the following locations:; https://repo1.maven.org/maven2/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://repo1.maven.org/maven2/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; https://jcenter.bintray.com/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://jcenter.bintray.com/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; file:/Users/louisb/.m2/repository/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; file:/Users/louisb/.m2/repository/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://jcenter.bintray.com/org/ojalgo/ojalgo-commons-math3/1.0.0/ojalgo-commons-math3-1.0.0.pom; > Could not find org.ojalgo:ojalgo-extensions:1.0.0.; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-351825206:220,error,error,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-351825206,1,['error'],['error']
Availability,"@ashwini06 . This bam appears to be malformed and it fails Picard ValidateSamFile. I think you'll need to examine the earlier stages of your pipeline that produce your bam to ensure you get a correctly formed bam. I'm going to close this ticket now since this doesn't appear to be an issue with Mutect2. (base) wm462-624:Downloads fleharty$ java -jar $PICARD ValidateSamFile I=concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam ; INFO	2020-07-14 11:25:52	ValidateSamFile	. ********** NOTE: Picard's command line syntax is changing.; **********; ********** For more information, please see:; ********** https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition); **********; ********** The command line looks like this in the new syntax:; **********; ********** ValidateSamFile -I concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam; **********. 11:25:52.673 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/fleharty/resources/picard.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Jul 14 11:25:52 EDT 2020] ValidateSamFile INPUT=concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam MODE=VERBOSE MAX_OUTPUT=100 IGNORE_WARNINGS=false VALIDATE_INDEX=true INDEX_VALIDATION_STRINGENCY=EXHAUSTIVE IS_BISULFITE_SEQUENCED=false MAX_OPEN_TEMP_FILES=8000 SKIP_MATE_VALIDATION=false VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Jul 14 11:25:52 EDT 2020] Executing as fleharty@wm462-624 on Mac OS X 10.15.5 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_191-b12; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.20.4-SNAPSHOT; WARNING	2020-07-14 11:25:52	ValidateSamFile	NM validation cannot be performed without the reference. All other validations will still occur.; ERROR: Record 18321, Read name U",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:321,Down,Downloads,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['Down'],['Downloads']
Availability,"@asmirnov239 I'm getting the same error on Terra when bam files and their indices are not in the same location. I'm running https://github.com/broadinstitute/gatk/blob/4.1.7.0/scripts/mutect2_wdl/mutect2_pon.wdl. The workflow input for bam index seems to be just a placeholder, if you follow the variables along the wdl it's never actually used.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487#issuecomment-1697767879:34,error,error,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487#issuecomment-1697767879,1,['error'],['error']
Availability,"@asmirnov239 has investigated clustering on Picard metrics, which he found to be informative. However, we've decided to go with clustering on coverage on a subset of bins, since this will be more readily available than the Picard metrics.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4170#issuecomment-459355056:204,avail,available,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4170#issuecomment-459355056,1,['avail'],['available']
Availability,"@audrysgp It looks like your `samtools view` command removes reads from chr2 but leaves the record for chr2 in the bam header. Then, when you run using the chr1 reference fasta, the GATK sees the discrepancy in sequence dictionaries and errors. There is no need to use `samtools view` before running GATK tools. Just run on the original bams and use the `-L` argument to specify an interval, in this case `-L 1`. Also, I notice that the Mutect2 command you're using is incorrect in several ways. The tutorial on the GATK forum: https://gatk.broadinstitute.org/hc/en-us/articles/360047232772--Notebook-Intro-to-using-Mutect2-for-somatic-data shows how to run Mutect2 optimally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6768#issuecomment-685866421:237,error,errors,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768#issuecomment-685866421,1,['error'],['errors']
Availability,"@avalind I got an e-mail saying that you ran picard and had no errors, but I don't see that comment here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-661244119:63,error,errors,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-661244119,1,['error'],['errors']
Availability,"@avalind This appears to be a different error from the one you were previously encountering.; The current error indicates that there is something wrong with your bam. It appears that there is a mismatch to the size of your insert quality sizes and read size. Is there a way that you can share your bam?. Also, are you sure that you intend to have insertion and deletion qualities, this is something we haven't been using for a few years now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658207661:40,error,error,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658207661,2,['error'],['error']
Availability,"@bbimber @mlathara Here is a pretty good article for optimizing the GenomicsDBImport [https://gatk.broadinstitute.org/hc/en-us/articles/360056138571-GDBI-usage-and-performance-guidelines] There is some advice about handling many small contigs that may be useful. . To troubleshoot the GenomicsDBImport high memory issue my script have, I reran the script on chr1 to narrow down the source of the high memory issue. These are running on reblocked gvcfs. . 1. Without --bypass-feature-reader and -consolidate; 2. With --bypass-feature-reader; 3. With --consolidate without --bypass-feature-reader (This ended up on a node with 384gb.) The other ran on 256GB nodes. . Test 2 ran the fastest with the lowest memory requirements (Wall clock 76 hours); Test 1 ran slower and required more memory 40-50% of 256GB (Wall Clock 94 hours); Test 3 ran initially faster with less memory than test 1 but by batch 65 it was using 75% of 384 GB. This job has not finished and appears stuck on importing batch 65. So the consolidate option appears to have a memory leak or using just requiring too much memory. The -consolidate option was the culprit. So rerunning chr1-3 with just the --bypass-feature-reader option (test2) ran fine without lots of memory being used. Below is the time output from chr1. The output shows the Maximum resident set size (kbytes): **2630440**. Using GATK jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar defined in environment variable GATK_LOCAL_JAR; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx200g -Xms16g -jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reade",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687:373,down,down,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687,2,['down'],['down']
Availability,@bbimber Can you try running `GenotypeGVCFs` without the `--force-output-intervals` argument and report whether the same error occurs?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7933#issuecomment-1188242520:121,error,error,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7933#issuecomment-1188242520,1,['error'],['error']
Availability,"@bbimber Could you please try running the following command on your GATK jar:. ```; jar tvf GenomeAnalysisTK4.jar; echo $?; ```. Then see whether the `jar` command reports any error, and whether the `echo` command shows an exit status of 0 for the command. Also try running this:. ```; jar tvf GenomeAnalysisTK4.jar | grep -i FileTruncatedException; ```. You should get output like:. ```; 765 Wed Mar 17 12:09:12 EDT 2021 htsjdk/samtools/FileTruncatedException.class; ```. Lastly, can you paste your complete Java classpath here?. We just checked the official release jar on github ourselves for corruption, and it seems fine, so we're not sure what's causing this issue on your end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042017121:115,echo,echo,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042017121,3,"['echo', 'error']","['echo', 'error']"
Availability,"@bbimber I believe we resolve it from jcenter. There were some issues around it because we removed jcenter resolution from our build at one point when it was slated to shut down. Testing didn't see any issue because it was being silently mirrored through our artifactory instance and we didn't realize that. Jcenter changed their plans from shutting down to going into indefinite read only mode, so we re-added it. . I think if you're seeing problems it's either because:; 1. You are building on a version of gatk which removed jcenter; 2. Your custom build doesn't resolve from jcenter; 3. We have a new issue I don't know about yet. . Can you rule out 1 and 2 before we start debugging 3? . In your build.gradle you should should see ` jcenter()` in your `repositories {}` block. It's very possible that we're relying on an outdated version and maybe we should update to a new one which isn't on the ill fated Jcenter only. @TedBrookings any thoughts about that? I think this is your dependency.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7839#issuecomment-1122757145:173,down,down,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7839#issuecomment-1122757145,2,['down'],['down']
Availability,"@bbimber I have to do a bit more digging here, but one thing I noted was that the reference you provide has some soft-masked regions. If I convert that reference to all upper case, the REF base is actually populated correctly. I still have to dig into why that is the case, but wanted to let you about this potential workaround in case you want to use it. I'll update this with more as I find it...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7089#issuecomment-783553524:118,mask,masked,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7089#issuecomment-783553524,1,['mask'],['masked']
Availability,"@bbimber I'm making way through this, and will focus on the diffs from GATK3, especially the tool itself. There are a few things that I mentioned above that will absolutely need to be done though; the VariantEval tool javadoc needs to be updated to reflect GATK4 syntax (i.e. references to GenomeAnalysisTK.jar need to be updated, etc. - see other tools for examples), and the tool command line arguments need to be changed to reflect GATK4 conventions (i.e. `selectName` -> `select-name`). Ideally those would be done before I go any further. Also, it would be much easier if we could start this review process/comments with just two commits - the initial GATK3 source code commit, and one commit with all the changes. Can you squash down all of your commits (except the initial one) into a single commit ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433415826:735,down,down,735,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433415826,1,['down'],['down']
Availability,@bbimber I'm pinging the funcotator owner who needs to approve this - not sure when he'll respond though. @jonn-smith Thoughts on this ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1353322736:13,ping,pinging,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1353322736,1,['ping'],['pinging']
Availability,"@bbimber Just so you're aware, I expect this PR to be merged in the next couple of weeks - we're mostly just waiting on a couple of downstream dependencies. If you're still using Barclay docgen, there were some pretty significant [changes to the doclets](https://github.com/broadinstitute/barclay/pull/188) - not sure if that will affect your code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1430413869:132,down,downstream,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1430413869,1,['down'],['downstream']
Availability,@bbimber No problem. We fully intended to have snapshot builds available. It's a bug/oversight that they're not.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8138#issuecomment-1371230636:63,avail,available,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8138#issuecomment-1371230636,1,['avail'],['available']
Availability,"@bbimber Thanks for rebasing (and point taken on the May 11 squash - we do sometimes ask for that to be done, we just generally try not to). I'm not sure what events lead to the 2 ""spurious"" commits, but they, as well as the extra ""correct bad merge"" commit, should be deleted. If we just squash them, the author attribution will be reflected incorrectly. It should be fairly easy to do (if you're accustomed to the command line, do: `git rebase -i HEAD~9`"", your editor will come up, just delete the 3 lines with those commits in your editor, and save). Feel free to also add the other (hasUserSuppliedIntervals) commit, since it should be part of this PR. I also wouldn't be opposed to you just squashing everything down to one commit at that point - up to you. Then I'll do what is hopefully the final pass to make sure we covered everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405699452:718,down,down,718,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405699452,1,['down'],['down']
Availability,"@bbimber The -Xmx option controls only the maximum size of the *Java* heap. It does not limit the size of the C heap used by the GenomicsDB library. This is why we always advise leaving extra memory available for C when using GenomicsDB by selecting an -Xmx value that is comfortably under the amount of physical memory available. Even though your GenotypeGVCFs command is not importing into a GenomicsDB, it is reading out of a GenomicsDB and performing an on-the-fly merge, which will cause the native library to use nontrivial amounts of memory. Having said that, ~80 GB for the native heap does seem like a lot. Do you have lots of highly multi-allelic records in your callset? @nalinigans @mlathara Thoughts on this one?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7542#issuecomment-963504342:199,avail,available,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7542#issuecomment-963504342,2,['avail'],['available']
Availability,@bbimber The underlying error (`ZipException: invalid LOC header (bad signature)`) suggests that there might be an issue with the JAR file being corrupt. Can you try re-downloading the GATK from github and seeing if the problem persists? It would also be helpful if you could post the MD5 of the JAR file you're running (generated via the command `md5sum <jar_file>`),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1040862548:24,error,error,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1040862548,2,"['down', 'error']","['downloading', 'error']"
Availability,"@bbimber There is a defrag operation that you can perform on the DB. My understanding is that it's only necessary if you have >100ish input batches. . When you say similar size combine gVcfs do you mean similar size of the input data, or similar size of the stored database compared to the merged gvcf? If you mean the later then that's expected because a genomicsdb will have much more data than an equivalent gvcf. I assume you mean the former though. I believe it is also expected that running from a genomicsdb should be slower than from a combined gvcf (up to a certain size of gvcf) because the combination operation is done at at read-time so it slows down the genotyping operation. The thing to look at is the sum of GenomicsDBImport + GenotypeGvcfs vs CombineGVCFS + GenotypeGvcfs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-669343616:659,down,down,659,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-669343616,1,['down'],['down']
Availability,@bbimber There's some [github service outage](https://status.github.com) right now and it's preventing travis from running. I'm not sure how to work around it. Hopefully it will be resolved soon.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431916861:38,outage,outage,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431916861,1,['outage'],['outage']
Availability,"@bbimber These changes look pretty good now except for a couple of things from the last round that didn't get done. I added new comments for those. Please make those changes, and also squash this PR down to single a commit, and rebase on current master. Thx.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-388127863:199,down,down,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-388127863,1,['down'],['down']
Availability,"@bbimber This looks like a good change, but I don't think it'll solve the problem. The `XsvLocatableTableCodec` works differently than other codecs. It was essentially created for Funcotator datasources, and it expects to be given a `.config` file rather than the XSV file itself. For example, if you wanted to index the Oreganno data source file, you'd need to first create a funcotator configuration file adjacent to it, and then use `IndexFeatureFile` to index the config file rather than the tsv. This is not a good design (my fault), but it's how the tool operates as of right now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591483042:531,fault,fault,531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591483042,1,['fault'],['fault']
Availability,@bbimber VariantEvalIntegrationTest line 502 needs to change from `CommandLineException.BadArgumentValue.class` to `CommandLineException.class` to reflect the change in the catch block we made earlier. That will fix the remaining failure.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827932254:230,failure,failure,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827932254,1,['failure'],['failure']
Availability,"@bbimber We believe that this should be fixed by https://github.com/broadinstitute/gatk/pull/7670, which will go out in the next GATK release. If you're able to test with that patch and give feedback on whether it resolves the error for you, that would be helpful!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1048160591:227,error,error,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1048160591,2,['error'],['error']
Availability,"@bbimber everything looks good! One Travis job was failing with a transient error, so I restarted it. Since all the other jobs passed I'm pretty sure this will be ready to merge in an hour or two.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582444997:76,error,error,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582444997,1,['error'],['error']
Availability,"@bbimber mostly true and I don't want to discourage you cleaning up incomplete/duplicate fragments. But I don't think that is the root cause of your import failure. Duplicate/incomplete fragments should not cause errors during import (or at least, not till the consolidation phase after all the batches have been imported). . When you do an import (incremental or otherwise) and specify `--consolidate`, all of the batches get must get imported and only then does consolidation happen. Since you said this failure happens during batch 3 of 4 of the import, this means consolidation hasn't started yet. Regarding list of folders within each contig folder -- no there is no sample to fragment mapping. Theoretically, a sample can exist in multiple fragments (though this is not possible here, due to the way GenomicsDB is used within GATK). The __coords.tdb files have some low level information that helps map between samples and fragments, but these are all in binary formats and are not human readable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722594093:156,failure,failure,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722594093,3,"['error', 'failure']","['errors', 'failure']"
Availability,"@bbimber question for you - what is the primary motivation for wanting to merge the scattered workspaces back into a single workspace here? I'm assuming the scatter is because you have a large enough dataset that you need multiple nodes to run the import in parallel. (side note: we're planning on enabling reading vcfs through native htslib in GenomicsDBImport which should drive down memory usage for cases that are able to take advantage of that route. This might make it more feasible to use `--max-intervals-to-import-in-parallel` for multiple threads on a single node ). If the large dataset is the primary reason, wouldn't you want the benefits of distributed processing on the query side as well? You mentioned in the previous thread that you saw the fact that a single workspace is a valid GenomicsDB workspace as a benefit...and that's certainly true - but if performance is the driving factor then it might be worth it to keep the workspace separate. @droazen Could you elaborate on what you envision we should do here? This approach should work as long as the same command line is used for each import with a different/unique interval list each time. Are you asking for a test case to be run just for sanity? Or add test cases to GATK? Or add a tool to do this...?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-635081015:381,down,down,381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-635081015,1,['down'],['down']
Availability,"@bbimber, I have placed another version of consolidate_genomicsdb_array [here](https://github.com/GenomicsDB/GenomicsDB/releases/download/v1.4.3/consolidate_genomicsdb_array). This allows for batch-wise consolidation with the `--batch-size` or `-b` option. The tool also does better reuse of the consolidation buffers between reads, so might work a little better. Be aware that the total time to consolidate increases with the batch option and the final batches require almost as much memory as consolidating all the fragments at once. Please try consolidating any one GenomicsDB array to see how it functions as we are still working at making this scalable in a better way. This is just a draft version and if you can share some of the resulting logs, that will be very helpful. Please do let me know the total size of all the `__book_keeping.tdb.gz` files in your fragments. Just a back-of-envelope calculation, you probably need about 40 times that total size of memory to successfully consolidate.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1081029205:129,down,download,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1081029205,1,['down'],['download']
Availability,"@bbimber, just a back of envelope calculation for the number of files in a GenomicsDB workspace would be; `(num_samples/batch_size)*(num_genomic_fields*2)*num_contigs*num_iterations` for the number of files you end up with. For your case, assuming 20 genomic info fields, it would approximately be `(1117/50)*(20*2)*2473*3=6.5M` files which seems to be in the ballpark of what you are seeing. If you invoke GenomicsDBImport with the `consolidate` option, that would bring down the number of files by a factor of `(num_samples/batch_size)*num_iterations`, which in your case will be `(1117/50)*3=66`. @droazen, GenomicsDB does have C/C++ based tools that do only consolidation, maybe we should offer a `gatk GenomicsDBImport --consolidate-only ...` option for existing workspaces. @mlathara, any other suggestions?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6895#issuecomment-710446103:472,down,down,472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6895#issuecomment-710446103,1,['down'],['down']
Availability,"@bbimber, sorry that the import with consolidate did not complete. If you are amenable to using a native tool, please download the tool from [here](https://github.com/GenomicsDB/GenomicsDB/releases/download/v1.4.3/consolidate_genomicsdb_array) for consolidation. This executable will consolidate a given array in a GenomicsDB workspace, it has been instrumented to output memory stats to help tune the segment size. Note that the executable is for Centos 7, if you find any unresolved shared library dependencies during usage, please let me know and I will work on getting another one to you. For usage from a bash shell:; ```; ~/GenomicsDB: ./consolidate_genomicsdb_array; Usage: consolidate_genomicsdb_array [options]; where options include:; 	 --help, -h Print a usage message summarizing options available and exit; 	 --workspace=<GenomicsDB workspace URI>, -w <GenomicsDB workspace URI>; 		 Specify path to GenomicsDB workspace; 	 --array-name=<Array Name>, -a <Array Name>; 		 Specify name of array that requires consolidation; 	 --segment-size=<Segment Size>, -z <Segment Size>; 		 Optional, default is 10M. Specify a buffer size for consolidation; 	 --shared-posixfs-optimizations, -p; 		 Optional, default is false. If specified, the array folder is not locked for read/write and file handles are kept open until a final close for write; 	 --version Print version and exit; ```. ```; ~/GenomicsDB.: ./consolidate_genomicsdb_array -w /Users/xxx/WGS.gdb/ -a ""1\$1\$249250621"" -z 1048576 -p; 21:09:47.100 info consolidate_genomicsdb_array - pid=30881 tid=30881 Starting consolidation of 1$1$249250621 in ws; Using buffer_size=1048576 for consolidation; 21:9:47 Memory stats(pages) beginning consolidation size=45821 resident=18998 share=1824 text=3530 lib=0 data=16810 dt=0; 21:9:47 Memory stats(pages) after alloc for attribute=END size=45821 resident=19009 share=1835 text=3530 lib=0 data=16810 dt=0; 21:9:48 Memory stats(pages) after alloc for attribute=REF size=46788 resident=19743 share=18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1057680354:118,down,download,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1057680354,3,"['avail', 'down']","['available', 'download']"
Availability,"@bbimber, this is another manifestation of running out of memory - `Error: (gzip_handle_error) Cannot decompress with GZIP: inflateInit error: Z_MEM_ERROR`. We have been looking into these types of issues with heap profilers. Will share a libgenomicsdb.so to try out with gatk when we have something.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050491425:68,Error,Error,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050491425,2,"['Error', 'error']","['Error', 'error']"
Availability,"@bbimber, we are investigating some scalable solutions for you. Meanwhile, can you provide the following information?; 1. What is the total and free amount of memory available to say consolidate_genomicsdb_array on your individual nodes?; 2. Sizes of all files under any one fragment say in 9$1$134124166?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1062349294:166,avail,available,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1062349294,1,['avail'],['available']
Availability,"@bbimber, your approach should mostly work, this is exactly what I am going to allow with the standalone tool, a new arg for `batch-wise consolidation`. The tool is also better optimized with memory allocations and you can specify the batch size to the tool for batch-wise consolidation which should clamp down the memory use. Still testing out the tool, hopefully I can get some version to you over the weekend or on Monday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1073040553:306,down,down,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1073040553,1,['down'],['down']
Availability,"@bensprung So I thought this would be a trivial change. It turns out that encoding the Genotype as something like `1/1` is done way down in the depths of the VCF encoder and isn't exposed in an accessible way. It's going to need a (hopefully simple) change to the underlying htsjdk library to expose that machinery. It shouldn't be hard, it just means it will take a bit longer to get to than I expected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8160#issuecomment-1397695685:132,down,down,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8160#issuecomment-1397695685,2,['down'],['down']
Availability,"@bhandsaker Thanks for chiming in with your thoughts/concerns. Under this proposal, the various classes in htsjdk that read and return `SAMRecords` (eg., `SAMReader` & co.) would continue to put the header inside of the records, so we would not be imposing an additional burden on direct clients of htsjdk to check for null headers any more than they do currently. The only difference is that if downstream consumers of `SAMRecords` (like hellbender) choose to strip the header from the records, there would be an explicit contract governing the behavior of headerless `SAMRecords` (as opposed to the status quo, in which the header may be null but behavior is totally undocumented and in some cases inconsistent -- eg., the reference name and index in a headerless `SAMRecord` can get out-of-sync in some cases). . In addition to documenting/clarifying the behavior of headerless `SAMRecords` and fixing any consistency-related bugs we find when operating without a header, we would also make an effort to document when a class in htsjdk that consumes `SAMRecords` requires that a header be present in the records (such as the various writer classes). Does this sound reasonable? It's actually a much more conservative proposal than it may have initially sounded :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142020109:396,down,downstream,396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142020109,1,['down'],['downstream']
Availability,@bhanugandham Have people been having trouble installing java 8 recently? I just found out that you now need to log into an oracle account to download it which is gross and off putting.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6024#issuecomment-507804068:142,down,download,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6024#issuecomment-507804068,1,['down'],['download']
Availability,"@bhanugandham This message itself is harmless and won't affect results directly, but it can mask warning/error messages coming from Jexl (such as missing variable names!). I wouldn't expect a user to see it when running from a normal installation, and I'm not sure why it seems to be intermittent. I'll need to do some debugging.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4637#issuecomment-439434139:92,mask,mask,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4637#issuecomment-439434139,2,"['error', 'mask']","['error', 'mask']"
Availability,@bhanugandham What error do you get when running the tool without a reference? It looks to me like the tool does not actually use the reference at all.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7023#issuecomment-754872904:19,error,error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7023#issuecomment-754872904,1,['error'],['error']
Availability,@biosinodx Are you able to share a small chunk of the bam that exhibits the error for debugging?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6490#issuecomment-600436626:76,error,error,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6490#issuecomment-600436626,1,['error'],['error']
Availability,"@bklein345 It looks like you're encountering 2 distinct bugs. . 1. There seems to be a nasty off by 1 error which needs to be fixed in the code.; @davidbenjamin This method has at least 1 bug (and I think 2). https://github.com/broadinstitute/gatk/blob/9bca5119e996886ee85ef6c890eba79ec5d6cfb1/src/main/java/org/broadinstitute/hellbender/tools/walkers/realignmentfilter/RealignmentEngine.java#L135-L137; 1. It needs to convert from [0,1) coordinates to [1,1].; 2. There is no guarantee that the reference index corresponds to the contig with the same number, and I think in practice it probably won't ever, since the reference indexes start at 0 but contig naming starts at 1. There may also be confusion between the realignment reference and the reference from the original file but I haven't looked closely enough. . 2. It looks like you're also hitting a non-deterministic error in the accelerated smith waterman which should be able to be worked around by specifying `--smith-waterman JAVA` .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6344#issuecomment-575728474:102,error,error,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6344#issuecomment-575728474,2,['error'],['error']
Availability,"@bshifaw found this bug in the M2 wdl where it requests eg 3500 GB of RAM instead of 3500 MB, causing disastrous ""no machines available"" errors. @LeeTL1220 any way to get this into a release?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4321:126,avail,available,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4321,2,"['avail', 'error']","['available', 'errors']"
Availability,"@bw2 I agree, this is an unhelpful error. We should fix it but it probably has to be done in htsjdk. (or picard since this is a picard tool we import). I'm not 100% sure what the issue is, it seems like were somehow resolving an invalid bin in the index. I would expect that that might happen using a very long chromosome, but 193,00,00 shouldn't be too large. Are you using non-human data or something with an extremely long variant?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7838#issuecomment-1122776500:35,error,error,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7838#issuecomment-1122776500,1,['error'],['error']
Availability,"@byoo @MikeWLloyd I reproduced your errors and fixed them, at least on my laptop, in PR #5563. Thank you for your help, and please don't hesitate to speak up if the bug remains for you once this PR goes in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451711763:36,error,errors,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451711763,1,['error'],['errors']
Availability,"@byoo Could you take the unfiltered vcf: `/gpfs/data/software/cromwell/log/cromwell-executions/Mutect2/0c2281d2-9d90-4ee3-88bb-f0bb015cdb7c/call-Filter/attempt-4/inputs/-356078842/Ameloblastoma_FFPE_P5-unfiltered.vcf.gz`, and restrict it to a small interval (at big as one chromosome and small as just the problematic site) surrounding the variant that causes the error? If the stderr isn't enough to identify the site approximately, you could run `gatk FilterMutectCalls -V unfiltered.vcf -O tmp.vcf` locally without any of the optional inputs and I believe tmp.vcf would be produced with every site up to but not including the problematic one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-450606674:364,error,error,364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-450606674,1,['error'],['error']
Availability,"@caijingtao1993 Thank you for your question. The ""java.io.Exception: No Space Left On Device"" implies that your task likely failed because you ran out of hard drive space on the device you used for running MarkDuplicates. If you are running on a cloud instance I would suggest increasing the available disk space or rerunning on another machine that has sufficient space. You might also try rerunning on a file input that is ReadNameSorted rather than CoordinateSorted since MarkDuplicates has to do an extra disk-backed sort for the entire input file if it has coordinate sorted inputs which could explain why you witnessed this error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6787#issuecomment-691149449:292,avail,available,292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6787#issuecomment-691149449,2,"['avail', 'error']","['available', 'error']"
Availability,"@carbocation @droazen just to speed along the question and answer process, the index files that triggered this error were produced using samtools v1.3.1, and was run back in 2019. So the issue here is with compatibility between the current htsjdk cram implementation and older versions of htslib. The current GP pipeline uses a much newer version of samtools, which appears to be more compatible with htsjdk, and so shouldn't produce data that runs into this issue (@cmnbroad's explanation of the different allowances htsjdk makes is relevant here). Personally, I think the spec is (probably intentionally) quite lenient about this behavior, even more than htsjdk. The relevant line is, I believe, ""Slices containing solely unmapped unplaced data (reference ID -1) still require values for all columns, although the alignment start and span will be ignored. It is recommended that they are both set to zero."" towards the bottom of page 22 in https://samtools.github.io/hts-specs/CRAMv3.pdf. It's always a fun time when a spec uses the word ""recommended"" :). I'd guess this is a situation where earlier specs were too vague, and so too many different behaviors appeared in the wild, and now the spec can't be solidified without pushing a bunch of tools suddenly off-spec. Though a cram expert could probably give more detail on exactly the thinking around that wording.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099661674:111,error,error,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099661674,1,['error'],['error']
Availability,@carbocation Could you clarify which version of which specific tool produced the index files that are triggering the error? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099610730:117,error,error,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099610730,1,['error'],['error']
Availability,"@carbocation This error indicates a malformed/corrupt .crai index file - I would suggest re-creating the index when this happens (also, it would be helpful to know what software created the index). If it persists after the index is recreated, then it would be helpful to point us to the actual cram/crai.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1088702231:18,error,error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1088702231,1,['error'],['error']
Availability,@chadisaad Could you make your file test-unfiltered.vcf available?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6058#issuecomment-519134296:56,avail,available,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6058#issuecomment-519134296,1,['avail'],['available']
Availability,"@chadisaad The remaining error involves samples with no callable sites, which means not only that they are control samples but that M2 saw no sites with coverage of 10 or more reads. Also, if it is a control sample with no variants, why run FilterMutectCalls on it?. If this error shows up for a case sample, feel free to open an issue in this repo.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6058#issuecomment-583471640:25,error,error,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6058#issuecomment-583471640,2,['error'],['error']
Availability,@chadisaad What GATK version did you use? I was not able to reproduce your error with GATK releases from August 2019 and December 2019.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6058#issuecomment-572180647:75,error,error,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6058#issuecomment-572180647,1,['error'],['error']
Availability,"@chandrans I'm not sure if this is related or not, but I would love to get a test case from them. That's an unhelpful error message at the very least.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2116#issuecomment-410702793:118,error,error,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2116#issuecomment-410702793,1,['error'],['error']
Availability,"@chandrans commented on [Mon May 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1382). ## Feature request. A user has reported ASEReadCounter counts homozygous sites as having potential ASE. This should not be the case, as only heterozygous sites should be counted. The user should input a VCF sites file with only heterozygous sites, but sometimes that doesn't happen, so there should be an error message when he or she does not. ; ### Tool(s) involved. ASEReadCounter; ### Description. There needs to be an error message telling the user he/she needs to subset the sites VCF to only heterozygous sites. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1382#issuecomment-260490723). May want to move this to GATK4, waiting for @meganshand to opine. . ---. @meganshand commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1382#issuecomment-260648100). Yeah, let's move it to GATK4 and incorporate porting it in the first place.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2265:408,error,error,408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2265,2,['error'],['error']
Availability,"@chandrans commented on [Tue Feb 20 2018](https://github.com/broadinstitute/gsaweb/issues/89). ## Feature request. ### Tool(s) involved; CollectRnaSeqMetrics. ### Description; In Picard standalone version 2.16.0, --IGNORE_SEQUENCE is not required, but in GATK4 version, it is required and fails with an error if not provided. This should be an optional argument. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/46016#Comment_46016",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4427:303,error,error,303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4427,1,['error'],['error']
Availability,"@chapmanb I forgot to say that with the fix I can run your test command successfully. Without the fix I was getting the same error that you got. If you want to try out the fix you will have to build Hadoop-BAM, see https://github.com/broadinstitute/gatk/wiki/Build-GATK-with-a-locally-built-htsjdk-or-Hadoop-BAM. When building GATK, do something like:. ```bash; ./gradlew clean installDist sparkJar -DhadoopBam.version=...; ```. For the record, here is the command I ran:; ```bash; ./gatk-launch HaplotypeCallerSpark -I hdfs:///user/$USER/debug-ref-name/gatkspark_refname.bam -R hdfs:///user/$USER/debug-ref-name/Homo_sapiens_assembly38.2bit -O hdfs:///user/$USER/debug-ref-name/out/NA24631-chr15_68578892_84670250-block.vcf.gz -pairHMM AVX_LOGLESS_CACHING -L regions.bed \; -- \; --sparkRunner SPARK --sparkMaster yarn-client --sparkSubmitCommand spark2-submit \; --driver-memory 4G \; --num-executors 30 \; --executor-cores 1 \; --executor-memory 4G \; --conf spark.dynamicAllocation.enabled=false; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659#issuecomment-341184164:125,error,error,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659#issuecomment-341184164,1,['error'],['error']
Availability,@chapmanb This is being handled by https://github.com/broadinstitute/gatk/pull/2783. Does this meet the needs for your use case? Thank you for including us in bioconda! We're excited to be more easily available to people.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2778#issuecomment-305583210:201,avail,available,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2778#issuecomment-305583210,1,['avail'],['available']
Availability,"@chapmanb We were able to reproduce a failure with your command line. This looks like an issue related to JNI and garbage collection that is exposed by setting `-Xmx46965m` and `-XX:+UseSerialGC`, but it needs further debugging. To confirm, can you please try running without specifying these javaOptions? Something like this:; ```; ./gatk-launch --javaOptions '-Djava.io.tmpdir=$TEMP_DIR' \; ApplyBQSRSpark \; --sparkMaster local[16] \; --input $BAM_IN \; --output $BAM_OUT \; --bqsr_recal_file $BQSR_RECAL \; -- \; --conf spark.local.dir=$SPARK_LOCAL_DIR; ```. FYI, we see better performance from Spark when using an SSD for spark.local.dir. The `--conf ` option above shows how to set the spark.local.dir.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-332370070:38,failure,failure,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-332370070,1,['failure'],['failure']
Availability,"@chapmanb, @sbamin, thank you for reporting the error. I fixed the bug by padding the reference bases with N's when we reach the end of the chromosome, with the variant base in the middle . But in retrospect, I'm pretty sure @davidbenjamin would rather slide the center and get real bases (i.e. variant need not be in the center). So I'll write that version tomorrow. PR is #5151",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5130#issuecomment-417475637:48,error,error,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5130#issuecomment-417475637,1,['error'],['error']
Availability,"@chochangwoo1023 We recommend recreating the GenomicsDB from scratch in this case, since it may have been corrupted when your server shut down.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7324#issuecomment-865247084:138,down,down,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7324#issuecomment-865247084,1,['down'],['down']
Availability,"@cjllanwarne, how do I opt-in per parameter? I am trying to run the v4.0.11.0 gCNV WDL using Cromwell v36 and even after changing `File` type to `String` type for the relevant BAM/BAI inputs, I am getting a file-type not recognized error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-437037011:232,error,error,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-437037011,1,['error'],['error']
Availability,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:359,down,downstream,359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['down'],['downstream']
Availability,"@cmnbroad - I can add more tests if there is available data for it, so it will be nice if you can figure out if the data can be made public. Now, the coverage for the tool is 74-75%, because there is no test for known indels; but the test outputs were generated with GATK3 (I can't remember, as I told you before, with which version). Should I close this PR and open a new one with the documentation and arguments with the current style of GATK4, and the tests that are now? I can also add the tests from the tutorial that @sooheelee has gave me, but they are kind of big (probably they should be added with lfs). Just let me know the approach that we should take here...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520:45,avail,available,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520,1,['avail'],['available']
Availability,"@cmnbroad - any advance on this? It looks like soon the uber-jar will include a lot of large files ( #4530 and https://github.com/broadinstitute/gatk/pull/4245) that are not directly related with the engine, and thus jar files for downstream projects will be huge. I would like to have a way to select a maven artifact with the core engine (maybe including Spark) - although it will be nice also to get some classes in the tools package, but I can propose the change to the ""core"" package if required. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3900#issuecomment-375646992:231,down,downstream,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900#issuecomment-375646992,1,['down'],['downstream']
Availability,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:64,down,downstream,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828,1,['down'],['downstream']
Availability,@cmnbroad . I checked with @asmirnov239 and he said that this can be fixed by providing GenotypeGVCFs with the same interval list as GenomicsDBImport(so just add -L Qrob_Chr02 to GenotypeGVCFs CLI). . The error msg however is a little confusing. Can we make the error msg more descriptive?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480546121:205,error,error,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480546121,2,['error'],['error']
Availability,"@cmnbroad : first - would it be possible to kick off travis tests? i refactored this and dont seem to be able to do that. Second, yes, I was trying to reorder and condense the commits but clearly didnt work. I think the problem was trying to put your GATK3 commit first (which would seem to make sense). in any case, I just recreated this, putting a pristine GATK3 first, following a consolidated set of my commits with 1) the limited core changes, 2) the meat of the VariantEval port, and 3) A separate commit with a port of GATK3 VariantEvalIntegrationTest which is useful for validation but should not be merged. To your points:. 1) I substantially cut down the incoming large files, mostly by limiting the intervals of new large VCFs. 2) On the plugin: this was discussed above, and I initially also pointed out this should ultimately go into Barclay. You are actually the one who proposed staging it in GATK. I am not entirely sure I understand the reticence on plugins; however, my goal is to get VariantEval ported by touching as little of it as possible. This is already sucking up a ton of time. I flipped VariantEvalUtils to gather a list of classes from the appropriate package instead of a full-on plugin. That should satisfy that concern?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431913735:656,down,down,656,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431913735,2,['down'],['down']
Availability,"@cmnbroad : thanks for the reply. yes, obviously tests would need to be added/updated. there's no question it needs robust testing. . my main concern is that VariantEval is a fairly sprawling tool with all sorts of add-ons. The majority of the untouched code taken verbatim from GATK3 isnt going to pass muster based on the bar of our last PR without a lot of petty revision (and maybe some useful updates). There are certainly some code improvements one could make across VariantEval, but I'm just not that keen on combing through the whole thing if it can be avoided. . how about this: while tests need to be updated (as discussed above, they work on the GATK3 data, which isnt checked in), the code in this PR is functional. Would you be willing to review a couple classes, maybe VariantEval itself and a few ancillary classes to see what scope of work we're talking about?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-413642544:116,robust,robust,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-413642544,1,['robust'],['robust']
Availability,@cmnbroad @SHuang-Broad . The cluster uses Kerberos for authentication. This style of pathname works for reading the cram file which is on the hdfs file system. . Using the hadoop shell works fine.... ; hadoop fs -ls hdfs:///project/casa/gcad/adsp.cc; Found 2 items; drwxrwxr-x - zhucc casa 0 2018-04-27 14:59 hdfs:///project/casa/gcad/adsp.cc/cram; drwxrwxr-x - farrell casa 0 2018-05-08 15:21 hdfs:///project/casa/gcad/adsp.cc/sv. When I change this to a local file a similar error occurs. The program runs for 40 plus minutes and then gets the following error. . ```; 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 92.0 in stage 13.0 (TID 68093) in 1108 ms on scc-q01.scc.bu.edu (executor 24) (101/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 101.0 in stage 13.0 (TID 68102) in 1061 ms on scc-q01.scc.bu.edu (executor 6) (102/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 34.0 in stage 13.0 (TID 68035) in 1653 ms on scc-q01.scc.bu.edu (executor 24) (103/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 44.0 in stage 13.0 (TID 68045) in 1553 ms on scc-q07.scc.bu.edu (executor 7) (104/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 63.0 in stage 13.0 (TID 68064) in 1362 ms on scc-q01.scc.bu.edu (executor 24) (105/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 102.0 in stage 13.0 (TID 68103) in 1057 ms on scc-q07.scc.bu.edu (executor 7) (106/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 39.0 in stage 13.0 (TID 68040) in 1604 ms on scc-q06.scc.bu.edu (executor 23) (107/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 5.0 in stage 13.0 (TID 68006) in 2015 ms on scc-q01.scc.bu.edu (executor 24) (108/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 10.0 in stage 13.0 (TID 68011) in 1928 ms on scc-q06.scc.bu.edu (executor 23) (109/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 15.0 in stage 13.0 (TID 68016) in 1865 ms,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590:478,error,error,478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590,4,['error'],['error']
Availability,"@cmnbroad @droazen Didn't realize that I accidentally omitted the `fullName` when specifying the sequence-dictionary argument for PlotModeledSegments:. @Argument(; doc = PlottingUtils.SEQUENCE_DICTIONARY_DOC_STRING,; shortName = StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME; ); private File inputSequenceDictionaryFile;. This works when called in WDL tests using the fullName `--sequenceDictionary` (which is why it slipped by me--I would've thought this should fail):. java -Xmx${command_mem}m -jar $GATK_JAR PlotModeledSegments \; --denoised-copy-ratios ${denoised_copy_ratios} \; --allelic-counts ${het_allelic_counts} \; --segments ${modeled_segments} \; --sequence-dictionary ${ref_fasta_dict} \; --minimum-contig-length ${default=""1000000"" minimum_contig_length} \; --output ${output_dir_} \; --output-prefix ${entity_id}. However, the argument names appear in the documentation as:. --inputSequenceDictionaryFile,-sequence-dictionary:File. And if the argument is not specified, this gives the error message:. A USER ERROR has occurred: Argument inputSequenceDictionaryFile was missing: Argument 'inputSequenceDictionaryFile' is required. Is this intended behavior? If so, please close, but it seems a little unexpected to me.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4049:1008,error,error,1008,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4049,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,@cmnbroad @samuelklee Seems like there's at least one test failure on this branch: . ```; PythonEnvironmentIntegrationTest. testGATKPythonEnvironmentPackagePresent; java.lang.AssertionError: The installed version of r-backports does not match the 1.1.10 version that was requested. Check the build log to see the actual version that was resolved by conda.; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6955#issuecomment-726961872:59,failure,failure,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6955#issuecomment-726961872,1,['failure'],['failure']
Availability,@cmnbroad @tedsharpe Do you guys have only 4 GB of physical memory on the machines where you saw the failures?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288436924:101,failure,failures,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288436924,1,['failure'],['failures']
Availability,"@cmnbroad Apologies that I didn't specify that I did run `./gradlew createPythonPackageArchive` first. You can see from the error that it's looking for the archive in `gatk/scripts/build/` (which doesn't exist) instead of `gatk/build`. It seems to be searching for `./build/gatkPythonPackageArchive.zip` relative to the scripts sub-directory rather than the root (also didn't mention I ran conda from the gatk root dir). Running conda v4.5.2, python v3.6.4. I run everything from a conda env created with: `conda create -n py36 python=3.6 anaconda`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4741#issuecomment-387166077:124,error,error,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4741#issuecomment-387166077,1,['error'],['error']
Availability,@cmnbroad Did another round and squashed down to one commit.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3851#issuecomment-362397954:41,down,down,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3851#issuecomment-362397954,1,['down'],['down']
Availability,"@cmnbroad Hope you had a good break. As you might have seen above, I refactored out VariantEvalEngine, which I think will address some of the problems, like passing the walker around, which you didnt like in the PR. . I might not have as good an eye over tests as you, but I believe the failures mostly relate to the change to set 'source' on the VCs. As you probably know, that means it's passed into the resulting VCF, and will change test expectations in some cases. You said someone at GATK was looking into that, but I would be happy to take a stab if your team has ideas on how to address this. If I'm missing test failures beyond that I can take a look.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-754015497:287,failure,failures,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-754015497,2,['failure'],['failures']
Availability,@cmnbroad I am grateful. I have been trying to huint down the source of this error without success for the last week. I created the ticket for you. Good luck.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1217247258:53,down,down,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1217247258,2,"['down', 'error']","['down', 'error']"
Availability,"@cmnbroad I did a pass with a little cleanup. I think this is ready for review, but has a couple things I left the might help review:. 1) As noted above, the primary purpose here is to migrate to MultiVariantWalkerGroupedOnStart, and remove the redundant re-querying of comp alleles. This seems to work, but has the effect of altering behavior in some cases, described more above. In VariantEvalUtils.java I left some debugging code that illustrates the behavior difference that will occur. . 2) It is a fair question as to whether changing the behavior of what is or isnt considered an overlap is appropriate. For now I'm making changes as though it is, since it's sort of a fringe case and this is a beta tool, but it should be discussed. 3) There are ~6 tests with altered expectations, due to that change in detecting overlaps. I just checked in their updated expectations, since it helps illustrate how the iteration change would impact results",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-732478578:245,redundant,redundant,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-732478578,1,['redundant'],['redundant']
Availability,"@cmnbroad I started down this road. i wanted to make sure i follow your reasoning on some of this. I think you propose to change the tool arguments such that each input VCF is tagged by name (like -V:eval vcf1.vcf.gz -V:comp vcf2.vcf.gz), instead of different argument names. This is paired with a change to set the 'source' on each VariantContext to match the name of the source feature context. Unless I'm missing something, this basically makes everything identified by strings, with no direct FeatureInput <-> VariantContext reference, right? . Presumably, MultiVariantWalkerGroupedOnStart could implement something like:. protected Map<FeatureInput<VariantContext>, List<VariantContext>> groupVariantsByFeatureInput(List<VariantContext> variants) {; Map<String, FeatureInput<VariantContext>> sourceMap = new HashMap<>();; getDrivingVariantsFeatureInputs().forEach(x -> sourceMap.put(x.getName(), x));; ; Map<FeatureInput<VariantContext>, List<VariantContext>> ret = new HashMap<>();; variants.forEach(vc -> {; FeatureInput<VariantContext> fi = sourceMap.get(vc.getSource());; if (fi == null) {; //possibly throw? ; }; ; List<VariantContext> l = ret.getOrDefault(fi, new ArrayList<>());; l.add(vc);; ret.put(fi, l);; }); ; ; return ret;; }",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5439#issuecomment-730532600:20,down,down,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5439#issuecomment-730532600,1,['down'],['down']
Availability,"@cmnbroad I think the defaulting to vcf if the file extension is ambiguous is probably better behavior for gatk than crashing. We can read a vcf with no extension, so it seems symmetrical at least. What's the downside of including it, is it just the fairly minor added complexity?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2046#issuecomment-243161489:209,down,downside,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2046#issuecomment-243161489,1,['down'],['downside']
Availability,"@cmnbroad I think this proposal is good provided that the error message people get clearly explains what they need to do to resolve things when this happens (eg., explains which dependencies have changed and how to mark the changes as ""ok"")",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-300897729:58,error,error,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-300897729,2,['error'],['error']
Availability,@cmnbroad I think we should change this behavior and return codes should only be error conditions.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6056#issuecomment-524554102:81,error,error,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6056#issuecomment-524554102,1,['error'],['error']
Availability,"@cmnbroad I understand that I could have retained a bunch of single-use text files, but it seemed like the more permutations one adds, the less it makes sense to have a separate, very redundant, static text file to check each scenario. There's a ton of VariantContext-related tests that parse the output VCF to test some feature as opposed to checking in a bunch of VCF text files.... While I'll grant the 4th test case I added (where we pass chr 2) isnt especially compelling over just testing chr 1, one could argue more breadth is a good thing here. if you want clarity, pulling that VariantEval report parsing code into a method called extractUniqueContigsFromEvalReport(), or simply adding a comment line, supports this goal. Anyway, I'm checking in slightly clarified version of this now, simply to get tests running. If you respond to the above, maybe we go with that. In the interest of time, I'll stage and check in the version which restores the text files and goes that route.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7238#issuecomment-831459741:184,redundant,redundant,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7238#issuecomment-831459741,2,['redundant'],['redundant']
Availability,"@cmnbroad I was going to actually fix the test data, but when I made the test data valid I started getting test failures. @droazen seemed like he preferred the quick and dirty solution, but maybe I communicated the state poorly to him.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351249:112,failure,failures,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351249,1,['failure'],['failures']
Availability,"@cmnbroad I've implemented a compromise approach in `ReservoirDownsampler.consumeFinalizedItems()` that I think satisfies both of our concerns:. * If `consumeFinalizedItems()` is called after end of input has been signaled, it always clears state (including the end of input flag itself), regardless of whether there are any finalized items; * If `consumeFinalizedItems()` is called before end of input has been signaled, it returns an empty List and does not clear state, since in that case the downsampling process is still ongoing and we want to preserve pending items. I've also added tests to verify this new behavior. Let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171:496,down,downsampling,496,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171,2,['down'],['downsampling']
Availability,"@cmnbroad It's not clear that I will at this point, but the SV Spark tool takes multiple passes, and what I'm goofing around with right now will be a part of that (or son of that).; I just thought it might be helpful to have this alternative available. It's not worth spending a lot of time on.; What's nice is that the engine puts you in charge, for once. You get to make any number of traversals if, as, and when you need them. It relieved me of the necessity to stuff my object with a bunch of transient state. And the ReadDataSource can be managed by a try with resources, so that looks a lot more bullet-proof than the current design, too. (For example, the TwoPassReadWalker leaks the first ReadDataSource when it reinitializes for the second pass.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5985#issuecomment-499230776:242,avail,available,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5985#issuecomment-499230776,2,['avail'],['available']
Availability,"@cmnbroad No problem, this isn't particularly time-sensitive. Ping me once it's ready for review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7402#issuecomment-952237587:62,Ping,Ping,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7402#issuecomment-952237587,1,['Ping'],['Ping']
Availability,"@cmnbroad OK, I tracked down two issues:. - The CpG and repeat status are dictates by the sequence spanning where ReferenceContext thinks it starts. This value is difference in the MultiVariantWalker version than before (basically the version on master can be expanded). I need to think about this. I half-fixed this, which restores the indel -related tests back to their original values (i.e. we no longer change behavior).; ; - I think in some cases the MultiVariantWalker will miss overlapping comp variants upstream of the eval.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747566966:24,down,down,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747566966,1,['down'],['down']
Availability,"@cmnbroad OK, thanks for the reply. I will plan to port to DISCVRseq, making some minor changes but leaving a lot as-is. I'll rename it MergeVcfsAndGenotypes but include mention of GATK3 and CombineVariants in my description of it. Also, I will likely strip down the features, as we dont need the full spectrum of options is says it supports.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7038#issuecomment-775491669:258,down,down,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7038#issuecomment-775491669,1,['down'],['down']
Availability,"@cmnbroad OK, thanks. I appreciate your help and time on this. It's sometimes difficult to evaluate what's going on with the review with relatively little information available out here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-799740212:167,avail,available,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-799740212,1,['avail'],['available']
Availability,@cmnbroad PyPI sound like a reasonable solution with the caveat that we need to make sure the github repo and PyPI are in sync at all times. Perhaps a less error-prone solution for git cloning users is putting together an official setup script @lbergelson and encouraging the users to install GATK via the setup script. The setup script could offer the benefits of `gradlew` while taking care of setting up the conda env and installing GATK python modules at the same time. We must also discourage the users from downloading JARs and make git clone + setup and the docker as the only two official methods of installing and using GATK.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-352171869:156,error,error-prone,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-352171869,2,"['down', 'error']","['downloading', 'error-prone']"
Availability,"@cmnbroad Thank you for pointing out those build failures and even digging down to the apparent cause! I investigated and the issue wasn't inability to decompress gzip files (or at least wasn't only that), but XReadLines trims the lines by default and my code doesn't. The ""expected"" files have an extra tab at the end of some lines (the CHROM line for example) that this was picking up. What I've done is updated XReadLines so it can take Paths as input, so we get good matching behavior without having to duplicate code. While I was at it I also exposed XReadLines' ability to strip out comments, so assertEqualTextFiles didn't need to re-implement it anymore. Assuming Travis passes, this should be ready to review. I have the feeling we're getting close!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456919065:49,failure,failures,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456919065,2,"['down', 'failure']","['down', 'failures']"
Availability,"@cmnbroad Thanks for pointing to the conda environment file. I tried to install load it but the first error it gave me was ; ```; NoPackagesFoundError: Package missing in current linux-64 channels:; - intel-openmp 2018.0.0*; ```; so I installed this package by hand with conda install -c anaconda intel-openmp and afterwards tried to install the gatkcondaenv.yml again with conda env create -n gatk -f gatkcondaenv.yml . Unfortunately I run into the next error which says:. ```; root@k-hg-srv1:/BioinfSoftware# conda env create -n gatk -f gatkcondaenv.yml; Using Anaconda API: https://api.anaconda.org; Solving environment: done. Downloading and Extracting Packages; mkl-service 1.1.2: ################################################################################################################################################################################################################## | 100%; libgcc-ng 7.2.0: #################################################################################################################################################################################################################### | 100%; mkl 2018.0.1: ####################################################################################################################################################################################################################### | 100%; intel-openmp 2018.0.0: ############################################################################################################################################################################################################## | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:102,error,error,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460,3,"['Down', 'error']","['Downloading', 'error']"
Availability,"@cmnbroad Thanks for the reply. I will look through that code to see if I turn up where this is happening. Is there a way to override/skip this repair? I understand as the header is coming from SVABA the VCF header is out of spec for GATK. It is one of the reasons I am using the tool to fix the dictionary of the VCF. It would be helpful to avoid the repair of other header fields in such cases. In the meantime, I will add a step to re-repair that particular header line so that downstream python scripts don't throw errors for the type mismatch. If there is no current way to avoid the header repair, and because it is a spec issue within GATK, I can close the issue after your reply.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8629#issuecomment-1861509061:144,repair,repair,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8629#issuecomment-1861509061,6,"['down', 'error', 'repair']","['downstream', 'errors', 'repair']"
Availability,@cmnbroad That works for me. Looks like you have already tracked down the source.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6615#issuecomment-634052214:65,down,down,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6615#issuecomment-634052214,1,['down'],['down']
Availability,"@cmnbroad The results look good to me. Ideally though, shouldn't we be downloading and baking these images into our bundle instead of fetching them at page load? It seems bad to rely on an external webservice for documentation to render.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6606#issuecomment-631708551:71,down,downloading,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6606#issuecomment-631708551,1,['down'],['downloading']
Availability,"@cmnbroad This branch is failing, I don't know why (don't understand the failures). I just rebased it on latest master, which passes everything afaict.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502481:73,failure,failures,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502481,1,['failure'],['failures']
Availability,"@cmnbroad This clears about 50mb of memory, probably not enough to make a difference but it might help reduce error rates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6085#issuecomment-521280086:110,error,error,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6085#issuecomment-521280086,2,['error'],['error']
Availability,@cmnbroad This looks good but I was thinking it would be good to try to fix the problem in the build script so it treats things as utf-8 always instead of being platform specific. Are you able to reproduce the error locally?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5936#issuecomment-492704734:210,error,error,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5936#issuecomment-492704734,1,['error'],['error']
Availability,@cmnbroad This should hopefully fix the failures...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322318791:40,failure,failures,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322318791,1,['failure'],['failures']
Availability,"@cmnbroad We seem to have a bit of a bug where you can disable a read filter that doesn't exist and get a warning instead of an error:. @droazen This is why that command line was ""working"" in the wdl. `--disableReadFilter asdfasdf` -> `Disabled filter (asdfasdf) is not enabled by this tool`. I opened #2397 to track it, which is slightly different than the existing #2358. This allowed a bug to be undetected for a while in gatk-protected broadinstitute/gatk-protected#893",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278172785:128,error,error,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278172785,1,['error'],['error']
Availability,"@cmnbroad We're seeing some weird Python failures in this branch (https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32072.5/tests/test/index.html and https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32072.5/tests/test/index.html). Example error:. ```; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: A nack was received from the Python process (most likely caused by a raised exception caused by): nkm received. : Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/vqsr_cnn/vqsr_cnn/models.py"", line 26, in start_session_get_args_and_model; return args_and_model_from_semantics(semantics_json, weights_hd5, tensor_type); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/vqsr_cnn/vqsr_cnn/models.py"", line 33, in args_and_model_from_semantics; model = set_args_and_get_model_from_semantics(args, semantics_json, weights_hd5); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/vqsr_cnn/vqsr_cnn/models.py"", line 90, in set_args_and_get_model_from_semantics; model = load_model(weights_hd5, custom_objects=get_metric_dict(args.labels)); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/keras/engine/saving.py"", line 419, in load_model; model = _deserialize_model(f, custom_objects, compile); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/keras/engine/saving.py"", line 224, in _deserialize_model; model_config = json.loads(model_config.decode('utf-8')); AttributeError: 'str' object has no attribute 'decode'. 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.waitForAck(StreamingPythonScriptExecutor.java:222); 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.sendSynchronousCommand(StreamingPythonScriptExecutor.java:183); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.initializePythonArgsAndModel(CNNScoreVariants.java:557); 	a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6718#issuecomment-724836660:41,failure,failures,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6718#issuecomment-724836660,2,"['error', 'failure']","['error', 'failures']"
Availability,"@cmnbroad Yeah, it looks like libgcc-ng is not available for osx64 at all. There is libgcc, but even that is only at 4.8.5 for osx64 (and at 7.2.0 for linux32/64). @mbabadi Do you know what the difference is between libgcc-ng and libgcc? (Even if libgcc is an acceptable subsititute, I'm not sure how to peg the different version numbers across linux and osx, and I'm not sure if there are differences between them.). Are we going to require use of the Docker?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355652809:47,avail,available,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355652809,1,['avail'],['available']
Availability,"@cmnbroad Yeah, the M2 failures went away in the most recent build, only to be replaced with the `XHMMSegmentCallerBaseIntegrationTest` transient failure :) . Since @mbabadi has a PR that fixes `XHMMSegmentCallerBaseIntegrationTest`, we can merge this into master, rebase that PR on top of it and merge, and then we should have passing tests again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311409797:23,failure,failures,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311409797,2,['failure'],"['failure', 'failures']"
Availability,@cmnbroad You're still seeing errors after rebasing? Bleh,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246150:30,error,errors,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246150,1,['error'],['errors']
Availability,"@cmnbroad and @davidbenjamin . A user found this error when trying to set the `--normal-p-value-threshold' argument in FilterMutectCalls tool. In the tool documentation, looks like this argument is declared as static and final which is why we see this error. Would you please look into this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5978#issuecomment-498386968:49,error,error,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5978#issuecomment-498386968,2,['error'],['error']
Availability,@cmnbroad as discussed during gatk office hrs I created a github issue ticket for this error. Let me know if there is any other information you need from the user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485581517:87,error,error,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485581517,1,['error'],['error']
Availability,"@cmnbroad could you point me to the relevant tests so I can figure out the various resource files that I assume the tests use in their commands? I want to make sure I get you everything you need, as I may make you a new small reference, given the small data I have available right now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371499166:265,avail,available,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371499166,1,['avail'],['available']
Availability,"@cmnbroad has volunteered to implement `PythonScriptExecutor` (should be quick), plus an example tool. Then he'll turn things over to @samuelklee and the CNV team to implement a prototype ML tool, after which we'll do the evaluation outlined above and decide whether this is the right path to go down.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3501#issuecomment-324724782:296,down,down,296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501#issuecomment-324724782,1,['down'],['down']
Availability,"@cmnbroad hi chris - sorry to ping you directly here, but does GATK have someone watching PRs? we're hoping to extend funcotator and this PR has some very minor changes from private->protected to enable that. is this something GATK would consider?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1352245629:30,ping,ping,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1352245629,1,['ping'],['ping']
Availability,@cmnbroad my exact error is `AttributeError: module 'tensorflow' has no attribute 'reset_default_graph'\`; I attached my full output from CNNScoreVariants. I started with a fresh gatk install and created my conda env as such: ; `~/miniconda3/bin/conda env create --file gatkcondaenv.yml --prefix=/N/soft/rhel7/gatk/4.2.2.0/`. In my **activated** environment:; `~/miniconda3/bin/conda list tensorflow`; Stdout:. tensorflow 1.15.0 mkl_py36h4920b83_0 ; tensorflow-base 1.15.0 mkl_py36he1670d9_0 ; tensorflow-estimator 1.15.1 pyh2649769_0 . It seems like I have the right version of tensorflow. Do you have any suggestions for getting this script to run?. [cnnscorevariants_output.txt](https://github.com/broadinstitute/gatk/files/7375962/cnnscorevariants_output.txt); d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-947022287:19,error,error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-947022287,1,['error'],['error']
Availability,"@cmnbroad on a related note -- it might be worthwhile to setup the Docker to include a dynamic BLAS library and pass it to theano. I will test how it affects the performance. NumPy is usually either linked against MKL or OpenBLAS. If theano has no dynamic BLAS lib available to link the compiled graph against, it will fall back to NumPy for linalg ops. It is not too bad since the only cost is the c++/python communication overhead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350264808:265,avail,available,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350264808,1,['avail'],['available']
Availability,@cmnbroad please review (assuming there aren't any test failures that I missed in my local testing),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321078016:56,failure,failures,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321078016,1,['failure'],['failures']
Availability,@cmnbroad reports that he's seeing out-of-memory errors when running the test suite locally. He says it could be a recently-introduced regression -- we should narrow it down to a single commit.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2484:49,error,errors,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2484,2,"['down', 'error']","['down', 'errors']"
Availability,"@cmnbroad says a 400MB reference is too large and the largest file they have is 250MB. So I need to pare down the reference and data further. This will involve making artificial contigs that are basically just snippets of the original GRCh38 contigs. The data will still represent real data. Let me know what you think @cmnbroad @magicDGS, before I spend more time towards this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373176079:105,down,down,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373176079,1,['down'],['down']
Availability,@cmnbroad small update: i tried creating the conda environment from a fresh miniconda install and got the same error I included in my above post.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-947160800:111,error,error,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-947160800,1,['error'],['error']
Availability,"@cmnbroad sorry to pester but i'm hoping to keep momentum here. were there any issues with the PR except for improving the test (which is done)? Only one test failed, with a test compile error related to GencodeGtfCodecUnitTest (https://travis-ci.com/github/broadinstitute/gatk/jobs/501273207). Given all else passed this seems like a test artifact?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7219#issuecomment-827593892:187,error,error,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7219#issuecomment-827593892,1,['error'],['error']
Availability,"@cmnbroad thanks for the additional info. Some more detail from my side in case others stumble upon the same problem... * My input file comes from gnomad (`gs://gnomad-public/release/2.0.2/vcf/genomes/gnomad.genomes.r2.0.2.sites.chr18.vcf.bgz`). I editied it only to turn chromosome ""18"" into ""chr18"". * bcftools handles the duplicate INFO correctly and it fixes it! In case someone find it useful this is the command I used to retain only the AF tag and discard missing values:. ```; bcftools annotate -O z -i 'INFO/AF > 0' -x ^INFO/AF gnomad.r2.0.2.biallelic.hg38.chr18.vcf.gz > gnomad.r2.0.2.simple.hg38.chr18.vcf.gz; ```. * Unrelated to this particular issue, `gatk GetPileupSummaries` (next command in my workflow) doesn't like tags with missing values, I get a NumberFormatException error (I think, I don't have the logs). Hence the option `INFO/AF > 0` in bcftools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704:789,error,error,789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704,2,['error'],['error']
Availability,"@cmnbroad  to adding an advanced command line option for it. . @magicDGS Our goal is to make it unnecessary for normal users to ever need to see a stacktrace. We're definitely not at the point yet where every UserException produces either a) the complete information necessary to debug, or even b) the correct information. We're trying to fix all those cases, but there's a lot of possible failure modes between cloud access, spark, filesystem plugins, etc, so it's going to be an issue for a while. . I don't think it will hurt the user experience to have an extra commandline argument for it. Printing the stacktrace when debug is on isn't a bad idea, but I think it's better to have finer grained control over it. . The other issue is that it's easier to explain to an unsophisticated user how to set an extra commmand line argument rather than trying to get them to set the environment variable which well be helpful for our support team when they're trying to debug someone's problem. (especially since setting the environment variables may be different on a spark cluster than on a local run).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285390394:391,failure,failure,391,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285390394,2,['failure'],['failure']
Availability,"@cmnbroad, [a researcher has pointed out](https://gatkforums.broadinstitute.org/gatk/discussion/1319/collected-faqs-about-interval-lists#latest) that although GATK accepts both types of intervals lists (Picard-style & BED), Picard tools called through the GATK errors with a BED intervals list. Is it possible to amend this behavior so any intervals list GATK accepts, Picard-called-through-GATK also accepts? If not, please let us know (myself and @rcmajovski) so that we can update documentation. . Given BED is the more widely-used intervals format, it would be great if we enabled its use consistently in our tools. The downside is the lack of reference match checking. However, it seems the decision has already been made with GATK's acceptance of BED intervals. Let me know your thoughts.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5472:261,error,errors,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5472,2,"['down', 'error']","['downside', 'errors']"
Availability,"@cmnbroad, passing MIN_DP to the attributesToIgnore list still checks it! It's ignored only when I remove it inside assertAttributesEquals() method. Is this expected?. Also, I get similar double vs integer checks fail for END and DP. In case of SB, the comparator fails as two arrays toString() methods differ (I guess):. java.lang.AssertionError: Attribute SB expected [0,0,13,14] but found [0, 0, 13, 14]; Expected: 0,0,13,14; Actual: [0, 0, 13, 14]. Haven't reached to the ""longer than expected"" error you mentioned.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-295403243:499,error,error,499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-295403243,1,['error'],['error']
Availability,"@colinhercus I was able to re-run your command successfully on the latest master branch (not in a release yet). I believe PR #6240 fixed the issue. @Rohit-Satyam @danielecook there's a good chance the errors you encountered are also fixed. If not, please let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-556889456:201,error,errors,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-556889456,1,['error'],['errors']
Availability,"@cristinaluengoagullo Hi Cristina. I just tried running your files, and I did not get any error. I used version 4.0.2.0 and ran the command in your command.txt file",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-373122582:90,error,error,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-373122582,1,['error'],['error']
Availability,"@cwhelan , after our offline discussion about how to make the insertion annotation easier for downstream analysis, I went back and did a check on how insertion annotation are extracted, and here's a summary:. Keys: NARL&mdash;NovelAdjacencyReferenceLocations, CA&mdash;ChimericAlignment, BC&mdash;BreakpointComplications. * NARL contains {mate breakpoint locations, orientation change between the breakpoints, complications around the breakpoint}, where the complication is mainly used for two purposes: 1) adjusting the exact locations of the breakpoints, and 2) useful for downstream annotations for the associated VCF records.; * NARL is constructed from an input CA, which in turn has two ways of being constructed: 1) deliberate construction with two neighboring alignments on the contig, 2) construction from an input contig whose alignments are scanned through in a semi pair-wise fashion. The second way is the master version currently in use in out pipeline, and is planned to be phased out eventually. Note that the second way extracts neighboring alignments that it considers good quality and send the information to the first version for actual construction. ; * The ctor for CA that takes two neighboring alignments also takes in a string representation of mapping locations of suspected insertions. In master version, this information is extracted from the alignments that are considered not strong enough, e.g. lower MQ, shorter alignment length, but the actual inserted sequence is not extracted in CA, but rather in BC.; * The BC field in NARL, holding inserted sequence, micro-homology and other information (e.g. for duplication), does not contain where the inserted sequence, if any, is mapped, and the inserted sequence is extracted from the distance on the contig between two neighboring alignments stored in the input CA.; * The variant, after its NARL locations are pinned down, is annotated by information stored in both CA and BC, where the information for BC is critical for",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810:94,down,downstream,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810,2,['down'],['downstream']
Availability,"@cwhelan . Thanks for adding the docs!. However, I still have concerns about three classes: `StrandedInterval`, `EvidenceTargetLink` and `BreakpointEvidence`. They seem to be tightly coupled, through an un-documented concept called ""distal target"" (not sure if people with more experience would immediately understand what it is, but it took me some time to grasp). . * My understanding is that a target in the ""distal target"" is really an interval that is spanned and/or suggested by a piece of evidence. The ""distal"" part is for representing mate of discordant read pairs, and non primary locations of split reads. Hence the first mention to distal target, in base class `BreakpointEvidence`'s methods `hasDistalTargets()` and `getDistalTargets()`, should document it. * By studying the possible arrangements of innies, outties, lefies and righties, the `strand` information stored in `StrandedInterval` could be understood, where upstream/downstream of possible event breakpoint location has 1-1 correspondence with the ""target""'s strand. (BTW, the doc currently for the class refers to a method called ""getStrand()"" in BreakpointEvidence, which I couldn't find). But using the word ""strand"" is confusing I think, and some example in the documentation/example in `StrandedInterval` is needed.; * `StrandedInterval` at its current state, is almost synonymous to ""distal target region"". I am not advocating that this to be done in this PR, but the BreakpointEvidence is so central to the logic (except the kmer acrobatics) that we should document it better.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333680006:942,down,downstream,942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333680006,1,['down'],['downstream']
Availability,"@cwhelan @tedsharpe please review. The pipeline tools are:; 1. PathSeqFilterSpark : quality/low-complexity/host read filtering; 2. PathSeqPathogenAlignSpark : bwa-mem aligner; 3. PathSeqClassifyReadsSpark : quantifies pathogen abundance. These are supported by utilities:; 4. PathSeqKmerSpark - creates kmer library (either a Hopscotch set or Bloom filter) used by Filter tool; 5. PathSeqBuildReferenceTaxonomy - creates a file containing taxonomic information for a given reference, required by ClassifyReads. tools.spark.pathseq package:; Contains all the tools. Static helper functions were put into PS<ToolName>Utils classes, eg PSFilterUtils contains functions used by PathSeqFilterSpark. PSUtils contains mostly functions that are used by more than one tool. There are a number of other ""PS"" classes for doing Bwa, taxonomy bookkeeping, and read classification. Also has the kmer and host alignment read filters. tools.spark.sv package:; Added base masking to SVKmerShort class. tools.spark.utils package:; Hopscotch set and Bloom filter for long primitives. Each type has a ""Large"" class for sets exceeding the maximum JVM array size (~2B).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2646:955,mask,masking,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2646,1,['mask'],['masking']
Availability,@cwhelan I've addressed the comments in the separate commits. The commit messages decribes what was done in each push.. Please take another look. Thanks!. The tests are failing because of travis. They run successfully when manually rebooted but the status here don't get updated...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-292063168:232,reboot,rebooted,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-292063168,1,['reboot'],['rebooted']
Availability,@cwhelan mentioned at @jamesemery's presentation last week that there are more efficient options available for getting data into HDFS. It's worth exploring these.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2014:97,avail,available,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2014,1,['avail'],['available']
Availability,"@cwhelan thank you, this is a good explanation. You are right in saying that `--min-base-quality-score` doesn't do what I am looking for. The explanation in the tool is:; ```; --min-base-quality-score,-mbq:Byte; Minimum base quality required to consider a base for calling Default value: 10. ; ```; Notice that it says `for calling` and in the documentation (https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.3.0/org_broadinstitute_hellbender_tools_walkers_mutect_Mutect2.php) it says:; ```; --min-base-quality-score / -mbq; Minimum base quality required to consider a base for calling; Bases with a quality below this threshold will not be used for calling.; ```; Nowhere it is mentioned that such bases would not be used for aligning the reads, which is a very different concept. I hope at least this lengthy discussion will spur an improvement of the documentation. In my application I would very much like to see the FORMAT/AD counting only the number of fragments where the evidence for a given SNP is above a certain threshold. Given my understanding of `--min-base-quality-score` I assume that there is no way to do that with GATK then. I think a better explanation of the `--min-base-quality-score` is warranted though. In general, if someone is trying to monitor cancer and they have a high coverage BAM for germline data from which they built a highly reliable VCF with genotypes and low coverage BAM from cell-free DNA, how should they use the VCF from high coverage to drive the molecule counting of the low coverage BAM?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-528886020:1380,reliab,reliable,1380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6045#issuecomment-528886020,1,['reliab'],['reliable']
Availability,@cxfustc I'm curious what the overlap of `PASS` variants after `FilterMutectCalls` is. Usually when the downsampler is invoked the region has very high coverage from mapping errors and almost everything is a false positive. Were you using default parameters?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382756006:104,down,downsampler,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382756006,2,"['down', 'error']","['downsampler', 'errors']"
Availability,@danagibbon thanks for this pointer. What versions of gatk have you seen this error on?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8683#issuecomment-1936415765:78,error,error,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8683#issuecomment-1936415765,1,['error'],['error']
Availability,@dannykwells Fix is in `master`. The error only occured in GCP backend. #4048 is the PR,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4017#issuecomment-355870266:37,error,error,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4017#issuecomment-355870266,1,['error'],['error']
Availability,"@dantefff Thank you for making this fix. It seems like the recommended solution based on https://blogs.apache.org/logging/entry/log4j-2-11-released. . The downside is that it seems to nearly double the size of the packaged jars. I'm going to try to look into why that is exactly and see if there's a work around. The annoying thing is that we're not really aiming to actually produce a multi-version jar, we just want to incorporate the files that are version specific for the version we need. So I suspect there's probably a way to do this without including many additional versions of each file in the final jar. It might be a bit more involved. . It looks like travis started finally, but I also pushed a copy to lb_test_multijar to force it to build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7339#issuecomment-876666468:155,down,downside,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7339#issuecomment-876666468,1,['down'],['downside']
Availability,"@dantefff Ugh... our tests don't catch this because it's a problem in the shading process where we package everything in our jar. Our tests don't use he shaded jar because it takes a long time to build and we've never seen an error like this before. Similarly, when I run my own tests locally I usually don't build the shaded jar for speed reasons and haven't noticed this error. I guess we need to run a test on the actual final artifact to catch this sort of problem. Thanks for finding a solution.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7338#issuecomment-876584599:226,error,error,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7338#issuecomment-876584599,2,['error'],['error']
Availability,"@danxmoran This is the bug you're seeing too. I haven't gotten a chance to try any of the suggestions above yet, but I'm hoping to start this afternoon. Also, just for completeness I saw a new error message today that I think Dan saw too (this time from PrintReads):. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -Xms2g -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar PrintReads -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-GatherBamFiles/CHMI_CHMI3_WGS2.bam --interval_padding 500 -L /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/1scattered.interval_list -O local.sharded.bam; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.l7eTB5; [July 21, 2017 6:20:54 PM UTC] PrintReads --output local.sharded.bam --intervals /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/1scattered.interval_list --interval_padding 500 --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-GatherBamFiles/CHMI_CHMI3_WGS2.bam --interval_set_rule UNION --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:193,error,error,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564,1,['error'],['error']
Availability,@david-wb Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368:28,avail,available,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368,1,['avail'],['available']
Availability,"@davidbenjamin . - Downsampling is definitely a concern for us, but as you have suggested, I have utilized this parameter to not limit ourselves to 50 reads per alignment start. After running a range of values, I landed on 500 as not being too much of a burden computationally, but still allowing us to fully digest alignments at each start site in a given region. For us, I have estimated a value of 500 would cover us to a depth of about 2000 or so, since we expect to see a bias at the projected amplicon start site.; - The read filters you list don't have a huge effect on the majority of our regions. Generally, I would not expect to see more than a 5% loss based on the mapping quality filter. The read size filter should never be triggered, as we input only reads larger than 30 bases to M2. We perform duplicate removal, as we are working with UMIs, so this also should not be an issue. ; - I wouldn't expect the realignment stage to cause the type of effect I see, and as you say, it really just corrects the data anyways. **Example:**; The following was called:; ```; 1	12919623	.	C	T	.	.	DP=741;ECNT=4;POP_AF=1.000e-03;P_GERMLINE=-2.169e-04;TLOD=743.86; 	GT:AD:AF:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:PGT:PID:SA_MAP_AF:SA_POST_PROB	0/1:520,210:0.291:0,0:520,210:36:153,132:57:47:0; |1:12919623_C_T:0.232,0.283,0.288:0.835,2.995e-04,0.165; ```; Also called in a different variant caller:; ```; 1	12919623	.	CC	TG	6989.54	.	AB=0.308968;ABP=423.639;AC=1;AF=0.5;AN=2;AO=410;CIGAR=2X;DP=1327;DPB=1327;DPRA=0;EPP=55.973;EPPR=139.678;GTI=0;LEN=2;MEANALT=8;MQM=50.4732;MQMR=56.3933;NS=1;NUMALT=1;ODDS=1609.4;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=13156;QR=30163;RO=900;RPL=282;RPP=128.617;RPPR=256.291;RPR=128;RUN=1;SAF=177;SAP=19.6194;SAR=233;SRF=377;SRP=54.4404;SRR=523;TYPE=mnp;technology.ILLUMINA=1	GT:DP:AD:RO:QR:AO:QA:GL	0/1:1327:900,410:900:30163:410:13156:-725.008,0,-2308.15; ```; Yes, M2 also calls the neighboring C>G substitution, these are just being represented differently between the ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3808#issuecomment-344740595:19,Down,Downsampling,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3808#issuecomment-344740595,1,['Down'],['Downsampling']
Availability,"@davidbenjamin @droazen unfortunately the new PON does not make up for the precision loss introduced in v4.1.9.0.; In v4.4.0.0 we get just 2 fewer FP SNVs in our performance evaluation, compared to the old PON.; Benchmarking results in WES tumor-normal mode, HCC1395 benchmark, and:. - v4.1.8.1 (last release with high SNV precision), v4.1.9.0 (first release affected by precision drop), v4.4.0.0 (current release); - oldPON: 1000g_pon.hg38.vcf.gz, newPON: mutect2-hg38-pon.vcf.gz; ![FD_TN_4181_FD_TN_4181_oldPON_FD_TN_4181_newPON_FD_TN_4190_FD_TN_4190_oldPON_FD_TN_4190_newPON_FD_TN_4400_FD_TN_4400_oldPON_FD_TN_4400_newPON](https://user-images.githubusercontent.com/15612230/236126940-9fc26627-260a-43c2-b409-69fbcec6ad47.png). Any chance to get this issue fixed? With Mutect3 not being available and v4.1.8.1 being affected by the log4j vulnerability, it is quite regrettable to be stuck with inferior precision. Extended methods, code, and data to reproduce the issue are here: ; [https://github.com/ddrichel/Mutect2_calling_performance_bug](https://github.com/ddrichel/Mutect2_calling_performance_bug)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1534177043:789,avail,available,789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1534177043,1,['avail'],['available']
Availability,"@davidbenjamin @jonn-smith I have pushed the latest version of the code. Most of the changes since this was last shown are adding checks to about every level of the code for infinite loops (several places in the dangling end recovery code, and several places the new BestHaplotypeFinder). Additionally tests have been updated to capture these cases as well as several of the changes to functionality (no longer forcing reference start kmer to have a junction tree, limiting the cases where we actually attempt to follow an unsupported reference path when constructing a haplotype, reintroducing reference path weight to the calculation, etc...).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6034#issuecomment-520991019:225,recover,recovery,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6034#issuecomment-520991019,1,['recover'],['recovery']
Availability,@davidbenjamin @jonn-smith The test failure is a false alarm. Please review as if the tests were passing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4941#issuecomment-402846895:36,failure,failure,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4941#issuecomment-402846895,1,['failure'],['failure']
Availability,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:299,down,downsampling,299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233,8,['down'],['downsampling']
Availability,@davidbenjamin Can you comment on this? Is this argument actually redundant?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7731#issuecomment-1074250007:66,redundant,redundant,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7731#issuecomment-1074250007,1,['redundant'],['redundant']
Availability,"@davidbenjamin Discovered that importing hellbender as a dependency fails now that we have add spark dependencies. This is easily fixed by including the following (or it's non-gradle equivalent) in your build file, but it shouldn't be necessary. ```; maven {; url ""https://repository.cloudera.com/artifactory/cloudera-repos/"" // spark-dataflow; }; ```. We should update our artifact so that it includes the necessary information to download the spark dependencies.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/779:432,down,download,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/779,1,['down'],['download']
Availability,@davidbenjamin Feel free to merge once test failures are resolved.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4132#issuecomment-357115303:44,failure,failures,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4132#issuecomment-357115303,1,['failure'],['failures']
Availability,"@davidbenjamin Funcotator is not quite ready to outright replace Oncotator, but there is a test WDL for it in the M2/unsupported folder. . It can run off the same docker image, but you need to download the data sources (or provide your own - the default downloadable tar.gz is about 300MB and extracts to about 3GB). There is a short set of instructions in the tool doc for how to run it (I'm still working on the tutorial for the forum). . One current limitation is that it only consumes and produces VCF files, which may be an issue for some users. . I should add that while I have done _some_ testing with GRCh38, I have not extensively tested with that reference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952:193,down,download,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952,2,['down'],"['download', 'downloadable']"
Availability,"@davidbenjamin Hello, we started using this feature more seriously and have a question. the output from GenotypeGVCFs with --force-output-sites seems to include sites with <NON_REF> as the ALT allele. Is this expected? I am guessing that these sites used to be filtered (no passing evidence of variation), and the point of this feature is the include sites based on whitelist?. The problem is that some downstream tools dont know what to do with this. There is probably some subtlety here, but I would think either a given sample has callable variation, it is REF, or it is no-call? Is <NON_REF> in the output by design?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-575922370:403,down,downstream,403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-575922370,1,['down'],['downstream']
Availability,@davidbenjamin How do you feel about merging this quick fix as-is while we're waiting for the next-gen error corrector to be merged?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6366#issuecomment-576774379:103,error,error,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6366#issuecomment-576774379,1,['error'],['error']
Availability,"@davidbenjamin I also found there are two `preemptible_attempts = preemptible_attempts` lines in line 181 and 187. Having these lines wouldn't cause an error, but I just wanted to let you know.; https://github.com/broadinstitute/gatk/blob/b5720472fe025270e410379885cd58fed7b20b77/scripts/mutect2_wdl/mutect2.wdl#L181-L187",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4596#issuecomment-379875734:152,error,error,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4596#issuecomment-379875734,1,['error'],['error']
Availability,"@davidbenjamin I do have a public bam! This is just chrM for NA12878: `/humgen/gsa-hpprojects/dev/mshand/SpecOps/Mitochondria/NA12878/NA12878_chrMOnly.bam`. The coverage should be quite high, so if it's too big I can downsample it if you want. . And my mitochondria only reference would probably also be useful: `/humgen/gsa-hpprojects/dev/mshand/SpecOps/Mitochondria/MitochondriaOnlyFastas/Homo_sapiens_assembly38.mt_only.fasta` (the fai and dict are there too).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5038#issuecomment-406595660:217,down,downsample,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5038#issuecomment-406595660,1,['down'],['downsample']
Availability,@davidbenjamin I resolved the issue after passing on proper docker string value into runtime block of WDL script. There is no error now. . In case of any requirement I will communicate you. Thank you so much.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5906#issuecomment-583809875:126,error,error,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5906#issuecomment-583809875,1,['error'],['error']
Availability,"@davidbenjamin I think one essential test you haven't done is to run master with more aggressive downsampling settings using the existing `--maxReadsPerAlignmentStart` argument, and compare that against your branch. This would help us determine whether or not the existing downsampling functionality really is inadequate to control peak memory use and runtime. The current default in `Mutect2` for `--maxReadsPerAlignmentStart` is 50, which is almost certainly much higher than it needs to be. That's 50 * 300 = 15,000 reads per assembly region, with on the order of ~2 regions in memory at any time = 30,000 reads. I propose that we try a run with the current vanilla master and `--maxReadsPerAlignmentStart 3`, and compare that to an identical run on your branch with your new downsampling options.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341838476:97,down,downsampling,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341838476,3,['down'],['downsampling']
Availability,"@davidbenjamin I think that is a bit of a cop out. I would have been happy to use a provided resource but there was none to be found for hg38. I had to do a liftover for the gnomAD data and that introduced subtle changes to the VCF that invoked this bug in <20% of my samples after hours of processing without any sensible error message to lead me onto what was the cause of the problem. I have wasted many days on debugging this issue and creating a bug report and I was considering switching to GATK3 or some other variant caller because of it. I think someone else reported a very similar issue on the forum and went back to using GATK3. . Maybe Mutect2 should, by default, run a filter on the pop resource VCF to get rid of unnecessary or erroneous lines. When users get more familiar with the algorithm, they could disable this filtering to save time and provide a pre-filtered VCF (--germline-resource or --germline-filtered-resource).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5391#issuecomment-435840613:323,error,error,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5391#issuecomment-435840613,1,['error'],['error']
Availability,"@davidbenjamin I tried and this time its a different error. ; ```; 14:55:53.232 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/shollizeck/clustering.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 09, 2020 2:55:53 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:55:53.432 INFO FilterMutectCalls - ------------------------------------------------------------; 14:55:53.433 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.4.1-6-g6bb31a7-SNAPSHOT; 14:55:53.433 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:55:53.433 INFO FilterMutectCalls - Executing as shollizeck@stpr-res-compute02.unix.petermac.org.au on Linux v3.10.0-1062.4.3.el7.x86_64 amd64; 14:55:53.433 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_232-b09; 14:55:53.434 INFO FilterMutectCalls - Start Date/Time: 9 January 2020 2:55:53 PM; 14:55:53.434 INFO FilterMutectCalls - ------------------------------------------------------------; 14:55:53.434 INFO FilterMutectCalls - ------------------------------------------------------------; 14:55:53.434 INFO FilterMutectCalls - HTSJDK Version: 2.21.0; 14:55:53.435 INFO FilterMutectCalls - Picard Version: 2.21.2; 14:55:53.435 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:55:53.435 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:55:53.435 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:55:53.435 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:55:53.435 INFO FilterMutectCalls - Deflater: IntelDeflater; 14:55:53.435 INFO FilterMutectCalls - Inflater: IntelInflater; 14:55:53.435 INFO FilterMutectCalls - GCS max retries/reopens: 20; 14:55:53.435 INFO FilterMutectCalls - Requester pays: disabled; 14:55:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-572799341:53,error,error,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-572799341,2,['error'],['error']
Availability,"@davidbenjamin I'm willing to concede number 3, and for number 2 I grudgingly agree. A dot in the FILTER field means filters haven't been applied, so by extension a dot in the ASFILTER field would mean that filters haven't been applied to that allele, which isn't true. But in the autosomal pipeline, a variant that fails a site filter before VQSR wouldn't be seen or filtered by VQSR, which I suppose does mean that filters have not been applied. I guess my objection boils down to the fact that by outputting . instead of PASS you're throwing away information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-588431161:475,down,down,475,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-588431161,1,['down'],['down']
Availability,"@davidbenjamin I've significantly refactored the production code, see the last commit. Most of this refactoring was to done make the code for the accounting of different modes (SNP/INDEL/both x BGMM/python x non/allele-specific) more minimal and straightforward. I've also combined the score/apply steps using the TwoPassVariantWalker. There's still lots of documentation, cleanup, and hardening/validation to be done, but most of the key methods and design choices have been documented, so I think it could be worth a quick review at this stage. Again, no need to nitpick code-style details, etc. (unless you really want to!) In the meantime, I'm going to do some more testing/tieout to make sure the refactor didn't break anything. This covers ~1800 LOC, which is roughly 50% of the equivalent VQSR code. Even modulo the remaining work just mentioned, which may add a few hundred LOC, I think this is a decent improvement---additional functionality, stability, etc. notwithstanding!. There's stubs for adding the truth-sensitivity conversion you proposed---should be pretty straightforward. I think it should also still be pretty easy for future pushes to add features like extraction/downsampling of unlabeled data, etc., but please do keep an eye out for design choices that may ultimately be constraining.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1044836946:1187,down,downsampling,1187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1044836946,1,['down'],['downsampling']
Availability,"@davidbenjamin Intellij pointed out this if statement to me as suspicious and I think it is. There are two arms of the second if statement that are guarded by `includeNonVariants`. However the second one can never be hit because if `includeNonVariants` you will already have chosen the first clause. Seems suspicious...; ```; if (regenotypedVC == null || (!GATKVariantContextUtils.isProperlyPolymorphic(regenotypedVC) && !includeNonVariants)) {; return null;; }; if (GATKVariantContextUtils.isProperlyPolymorphic(regenotypedVC) || includeNonVariants) {; // Note that reversetrimAlleles must be performed after the annotations are finalized because the reducible annotation data maps; // were generated and keyed on the un reverseTrimmed alleles from the starting VariantContexts. Thus reversing the order will make; // it difficult to recover the data mapping due to the keyed alleles no longer being present in the variant context.; final VariantContext withGenotypingAnnotations = addGenotypingAnnotations(originalVC.getAttributes(), regenotypedVC);; final VariantContext withAnnotations = annotationEngine.finalizeAnnotations(withGenotypingAnnotations, originalVC);; final int[] relevantIndices = regenotypedVC.getAlleles().stream().mapToInt(a -> originalVC.getAlleles().indexOf(a)).toArray();; final VariantContext trimmed = GATKVariantContextUtils.reverseTrimAlleles(withAnnotations);; final GenotypesContext updatedGTs = subsetAlleleSpecificFormatFields(outputHeader, trimmed.getGenotypes(), relevantIndices);; result = new VariantContextBuilder(trimmed).genotypes(updatedGTs).make();; } else if (includeNonVariants) {; result = originalVC;; } else {; return null;; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6109:835,recover,recover,835,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6109,1,['recover'],['recover']
Availability,"@davidbenjamin Mutect2 is failing with this error: `Cannot construct fragment from more than two reads`. As discussed, looks like this is an edge case we have not accounted for. If the secondary alignment is on the same assembly region as the primary, we see this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-546094922:44,error,error,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-546094922,1,['error'],['error']
Availability,"@davidbenjamin OK, i see them now. these were not failing for me locally, so i'm going to need to look more. I am fairly certain these didnt occur prior to my last commit (the errors about allele sorting are odd). nonetheless your point about callRegion() might also be right.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582249580:176,error,errors,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582249580,1,['error'],['errors']
Availability,@davidbenjamin Pinging on this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6908#issuecomment-726991481:15,Ping,Pinging,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6908#issuecomment-726991481,1,['Ping'],['Pinging']
Availability,@davidbenjamin Pinging you on this one -- any thoughts on how we could resolve this?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-576778405:15,Ping,Pinging,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-576778405,1,['Ping'],['Pinging']
Availability,"@davidbenjamin Since the error doesn't occur with GATK 4.1.4.1, it's possible that this is a side effect of the changes to `LeftAlignIndels` that went into GATK 4.1.5.0 in https://github.com/broadinstitute/gatk/pull/6427. @gbrandt6 Could you or the user test whether the error occurs in GATK 4.1.5.0? If it does, that would definitely implicate https://github.com/broadinstitute/gatk/pull/6427 as the source of the regression.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6765#issuecomment-680237910:25,error,error,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765#issuecomment-680237910,2,['error'],['error']
Availability,"@davidbenjamin Sorry I've been out and just got around to looking at this. Given that this test appears to run just fine in the Java 11 job (which is not run on our docker), I suspect the failure may have something to do with the jar file we use to test on the docker (which is not the same jar we use on the non-docker tests). . I pulled your branch and all of the generation tasks (gatk doc, wdl gen, javadoc) seem to work fine, so given how much time it looks like this has taken up, I think it would make sense to either disable this test (on the docker only - see below - since we want it to still run in the other CI integration test job), or else remove the variantcalling package from the test package list (if thats the one thats causing the failure ?). And then create a ticket for me with whatever data you have, which I'll follow up on. If you restore everything to its natural state, you should be able to add this to the `DocumentationGenerationIntegrationTest.documentationSmokeTest` method and then it will be skipped only when running on the docker:. ```; final DocumentationGenerationIntegrationTest dt = new DocumentationGenerationIntegrationTest();; if (dt.isGATKDockerContainer()) {; throw new SkipException(""See gatk issue #..."");; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1216668361:188,failure,failure,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1216668361,2,['failure'],['failure']
Availability,@davidbenjamin Testing failure is transient. Please review...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5062#issuecomment-408470885:23,failure,failure,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5062#issuecomment-408470885,1,['failure'],['failure']
Availability,"@davidbenjamin Thanks for the test! Unfortunately none of the spike-in bams I have are public, but I will ask Sarah Calvo if she knows of any samples that would work as a spike-in and are public. Maybe we can track one down.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5057#issuecomment-408863715:219,down,down,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5057#issuecomment-408863715,1,['down'],['down']
Availability,"@davidbenjamin Thanks for the update. It may be awhile before I try it.; I'll let you know if I have further problems. On Thu, 21 Nov 2019 at 11:03, David Benjamin <notifications@github.com>; wrote:. > @colinhercus <https://github.com/colinhercus> I was able to re-run your; > command successfully on the latest master branch (not in a release yet). I; > believe PR #6240 <https://github.com/broadinstitute/gatk/pull/6240> fixed; > the issue. @Rohit-Satyam <https://github.com/Rohit-Satyam> @danielecook; > <https://github.com/danielecook> there's a good chance the errors you; > encountered are also fixed. If not, please let me know.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6230?email_source=notifications&email_token=AALRZ6RAXJXJ645XMCTODTLQUX3AVA5CNFSM4JE2YEB2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEEYXK4A#issuecomment-556889456>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AALRZ6X6YCPNOCZLOTEFOP3QUX3AVANCNFSM4JE2YEBQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-556994346:566,error,errors,566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-556994346,1,['error'],['errors']
Availability,"@davidbenjamin Thanks for the workaround in the 4.1.9.0 release!. I tested the updated `CreateSomaticPanelOfNormals` with `genomicsDBs` computed in 4.1.7.0 as above and it seems that the workaround recovers a lot of multiallelic variants that were already missing in 4.1.7.0. Using the record and variant counts in 4.1.7.0 as 100% reference, I'm getting 57% more records (all multiallelic) or 142% more variants. No sites from 4.1.7.0 are missing in 4.1.9.0. As a side note, all of the new records have `FRACTION=1` and most (90%) have `BETA=1,1;FRACTION=1`. Among shared records, all multiallelic sites also have `FRACTION=1` and almost always different beta parameter estimates compared to 4.1.7.0. As expected, biallelic sites are unchanged. As far as I understand, these annotations are irrelevant in deciding whether a site should be output or not, so this is not a concern.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-707740253:198,recover,recovers,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-707740253,1,['recover'],['recovers']
Availability,"@davidbenjamin The error is not specific to GenomicsDB. @V-Z got the same error with a VCF as input (see https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928), so that should make it slightly easier to replicate.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4975#issuecomment-402184817:19,error,error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4975#issuecomment-402184817,2,['error'],['error']
Availability,"@davidbenjamin This branch seems to have a lot of unrelated refactoring bundled in with the substantive fix for `Mutect2`, and some of this refactoring seems problematic to me (eg., deletion of some downsampler API methods that will be needed when `ReadWalker` downsampling is ported). . Since mixing refactoring into the same PR as behavioral changes is asking for trouble as a general rule, could I ask you to strip out everything except the substantive change to `PositionalDownsampler` from this PR? Happy to do a quick review once this is done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787:199,down,downsampler,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787,2,['down'],"['downsampler', 'downsampling']"
Availability,@davidbenjamin Was familiarizing myself with `KBestHaplotypeFinder` and decided to take a crack at this issue. . I have no idea how much of a performance hit this will end up being at extreme sites. At worst it involves adding more paths into the priority queues than existed before which could slow down the whole search algorithm. . Fixes #5907,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5952:300,down,down,300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5952,1,['down'],['down']
Availability,"@davidbenjamin We could easily add in `ReadWalker` downsampling, yes -- it would be simple to add alignment-start-based downsampling like GATK3 ReadWalkers had (and the GATK4 HaplotypeCaller currently has) using a `ReadsDownsamplingIterator` + a `PositionalDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5075#issuecomment-443864289:51,down,downsampling,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5075#issuecomment-443864289,4,['down'],['downsampling']
Availability,@davidbenjamin We should chat about this in person -- have some questions for you. Some of the functionality you removed from the downsampler interface is needed by code that is not yet ported.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314200383:130,down,downsampler,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314200383,1,['down'],['downsampler']
Availability,"@davidbenjamin commented on [Fri Sep 09 2016](https://github.com/broadinstitute/gatk-protected/issues/700). Currently, `Mutect2` hard filters a candidate somatic variant if any event occurs at the same locus in the panel of normal samples. The idea is to avoid false positive calls at inherently noisy sites. This approach is reasonable but perhaps we can improve it. Some thoughts:; - Asymptotically, as the size of the PoN goes to infinity eventually every site will have some event and we will filter out every variant. Obviously this is an unrealistic limit, but a model should always perform better with more data.; - It might be good to use the PoN to learn a probabilistic model of error at each site, similar to the tool EBCall which has been noted to perform quite well on indels.; - regardless of our model, we should consider alternatives to hard filtering, such as perhaps using the PoN to penalize a somatic quality score.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2891:689,error,error,689,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2891,1,['error'],['error']
Availability,"@davidbenjamin commented on [Sun May 28 2017](https://github.com/broadinstitute/gatk-protected/issues/1114). HaplotypeCaller and Mutect by default assemble reads with kmer sizes of 10 and 25. 10 seems extremely small given the low error rates of Illumina sequencing. It's worth investigating how the Mutect validations are affected by increasing these values. ---. @ldgauthier commented on [Tue May 30 2017](https://github.com/broadinstitute/gatk-protected/issues/1114#issuecomment-305032024). Investigate away, but keep in mind bigger kmers introduce more ""dangling tails"", which may end up dropping evidence at the ends of reads. If you end up diving into the assembly graphs, I'm happy to consult. It's a deep, dark rabbit hole, but I've been there before and I know the way. ;)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3024:231,error,error,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3024,1,['error'],['error']
Availability,"@davidbenjamin commented on [Thu Apr 20 2017](https://github.com/broadinstitute/gatk-protected/issues/994). The simplest idea is to take kmers (k = 5, 7, 10?) centered at variant positions and fit a distribution (beta distribution?) of artifact allele fractions for each kmer. . Back of the envelope: with k = 10 we have 4^10 ~ 1 million different kmers, so each kmer appears ~ 3000 times per genome or about 1 million times in our panel of normals. This is easily enough to fit the distribution of artifact fractions very precisely. In addition to beta distributions, we may wish to fit different distributions for artifact allele fractions, such as a mixture of no artifacts (other than base errors as expected from the base quals) and a beta.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2973:694,error,errors,694,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2973,1,['error'],['errors']
Availability,"@davidbenjamin commented on [Tue May 23 2017](https://github.com/broadinstitute/gatk-protected/issues/1094). In active region determination for Mutect, and I believe also HaplotypeCaller, we count soft clips as a potential sign of a variant. This is because the aligner might soft clip the last few bases of a read that follow a deletion rather than call the deletion. For example, if the reference and read are:. TTCCAGAGTGTGTCAC (reference); TTC____________GTCAC (read). the alignment might choose to soft clip the GTCAC rather than call a deletion on the CAGAGTGT. In somatic calling it is expensive to call too many active regions, so perhaps we should only count eg the soft-clipped bases GTCAC as evidence of variation if that kmer appears downstream in the reference. @fleharty is this understanding of soft-clips being possible deletions (but not insertions or SNVs) correct?. ---. @fleharty commented on [Wed May 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1094#issuecomment-303733706). @davidbenjamin . I certainly agree with you that soft-clips can be due to deletions. It's not at all clear to me that they wouldn't happen with an insertion. Consider:. ---ATGAACAGATATAACAGAT (reference); ---ATGAA(AGGTAA)CAGATATAACAGAT (read). I don't see why a soft clip might not show up on this read after ATGAA.; I'm not really sure I understand why some things are soft-clipped to be honest. I've seen plenty of things that were soft-clipped, but appear to match the reference perfectly (maybe I'm remembering this incorrectly). I suspect that soft-clips are hardly ever correctly associated with SNVs though. ---. @davidbenjamin commented on [Wed May 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1094#issuecomment-303771734). @fleharty Thanks for the input!. ---. @ldgauthier commented on [Thu May 25 2017](https://github.com/broadinstitute/gatk-protected/issues/1094#issuecomment-303996178). You'll also likely see a difference in behavior for exomes vs gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3014:746,down,downstream,746,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3014,1,['down'],['downstream']
Availability,"@davidbenjamin commented on [Wed May 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1098). The telltale sign of a substitution error occurring on a single strand of DNA is that supporting evidence is all on forward strand read 1 and reverse strand read 2, or vice versa. This lends itself to a graphical model, the hyperparameters of which can be learned from the data. Further down the road, we might use a neural network to learn the context-specific risk of such artifacts and attach it to the Bayesian model for forward/reverse and read 1/read 2. This would be our first experience with a deep generative model.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3016:145,error,error,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3016,2,"['down', 'error']","['down', 'error']"
Availability,"@davidbenjamin comparing [better error bars for samples with small contamination](https://github.com/broadinstitute/gatk/pull/7003) version to master 4.2.0.0. - running on large set of probably considered as a small panel with high read depth.; percent of observations with all compared variables equal 88%, values unequal 12%. We can conclude that over all the Zero contamination remains Zero contamination but with non zero stdError (accepted after the binary searched). . **only 0.5%** of samples which were reported zero on version 4.2.0.0 are now reported as non zero contamination when the stdError was not accepted and the min maf iteration continued. ### Need to distinguish between **true zero contamination** ie was not found after running all maf iterations over all strategies (HOMO ALT,REF,UNSCRUPULOUS_HOM_REF) to a zero contamination after accepting stdError of Zero contamination of a single strategy. it is about **15%** of samples which will be reported non zero if continuing the maf iterations . @itaibeno to test on larger panel and report here. @davidbenjamin - could you consider running all maf iterations and report contamination per strategy,minMaf and loci if exists?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-856187340:33,error,error,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-856187340,1,['error'],['error']
Availability,@davidbenjamin here is a link to a minimal bam with the error: https://nextcloud-bird.univ-nantes.fr/index.php/s/CkFc66MsjCNLywr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6490#issuecomment-605617217:56,error,error,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6490#issuecomment-605617217,1,['error'],['error']
Availability,"@davidbenjamin looks like i have to wait for the test to pass because travis is having problems. What was happening is that the list of alleles didn't necessarily overlap with the VC being evaluated here (the `AssemblyBasedCallerUtils.getAllelesConsistentWithGivenAlleles(givenAlleles, vc)` was among other things responsible for filtering out alleles that don't overlap the site at all. This was responsible for the users issue because there were alleles from adjacent --alleles file variants 20 bases downstream that caused that condition to fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7740#issuecomment-1081925541:503,down,downstream,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7740#issuecomment-1081925541,1,['down'],['downstream']
Availability,"@davidbenjamin looks that it works for CombineVariants now (not on the full set of data). However, I am getting a lot of random errors for HaplotypeCallerSpark (4.1.8.1):. > 20/09/15 21:46:45 ERROR Executor: Exception in task 14.0 in stage 5.0 (TID 464); > java.util.ConcurrentModificationException; > 	at java.util.ArrayList.sort(ArrayList.java:1456). after rerunning with the same parameters for some runs problems disappeared, for some doesn't, and I must rerun them once again. There was no this kind of issue when I was using 4.1.3.0 HaplotypeCallerSpark O_o. I am confused O_o for what version tools works and for what doesn't. [H1_1.2.gatk.spark.HaplotypeCaller.gvcf.log](https://github.com/broadinstitute/gatk/files/5229907/H1_1.2.gatk.spark.HaplotypeCaller.gvcf.log); [H1_2.5.gatk.spark.HaplotypeCaller.gvcf.log](https://github.com/broadinstitute/gatk/files/5229908/H1_2.5.gatk.spark.HaplotypeCaller.gvcf.log). in contrast to the working processes; [H1_2.3.gatk.spark.HaplotypeCaller.gvcf.log](https://github.com/broadinstitute/gatk/files/5229912/H1_2.3.gatk.spark.HaplotypeCaller.gvcf.log). exactly same HPC infrastructure O_o. ________________; I think I have stuck once again somewhere in #5680 and #6730",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-693185541:128,error,errors,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-693185541,2,"['ERROR', 'error']","['ERROR', 'errors']"
Availability,"@davidbenjamin ready for re-review. I'm going to do a little performance benchmarking in the meantime. It takes ~40min to call the whole contig for my 4000X bams, which isn't terrible, but it isn't great. Anecdotally it seems like the AF thresholding slowed things down, but I'll collect some numbers.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-449458286:265,down,down,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-449458286,1,['down'],['down']
Availability,"@davidbenjamin there is one test that failed. is this possible an intermittent /timeout problem? i dont have permission to restart them, but i dont see an actual test failure in it: https://travis-ci.com/broadinstitute/gatk/jobs/283688682",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582418410:167,failure,failure,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582418410,1,['failure'],['failure']
Availability,"@davidbenjamin what I was talking about earlier. It comes with the very nice side effect of pasting this to the command line output: ; ![Screenshot 2024-09-23 at 3 44 08PM](https://github.com/user-attachments/assets/cbe824d1-755a-41d2-9647-31a14ae8a402); It also generally makes it much easier to track down ""what does mito mode change exactly again?""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8986:304,down,down,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8986,1,['down'],['down']
Availability,"@davidbenjamin, @fleharty agree with the implementation of PR #7003. ; I'm running that version comparing to samples previously reported 0 contamination and 0 std error.; will update here. One concern on the math Eq37 - Eq.42 calculate std (chi).; the math not taking into account the sample size (n) i.e number of homs.; note that we are starting with GetPileupSummaries output ~5k loci , ; filterSitesByCoverage keep ~300 loci ; filter segments + MAF keep variable number of loci depend on panel size etc. this number can vary and the question should the implementation will take it into account? i.e. reject the sample if n<NUM_LOCI (5,10,50???). **Thinking on the end user observing the Pair( contamination,stdError) and his interpretation on that...** . Probably adding the number of homs sites + strategy to final output as well as listing the pileups for the homsites will let the end user better understand the sample contamination output or even to find contaminant of a batch. **suggesting the following update to output file:**; sample	contamination	error; TUMOR	0.019245855721094312	0.0036809520099731763. sample, **strategy, n_loci,** contamination, error; TUMOR,HOM_ALT,M. list of homosites used; **contig	position	ref_count	alt_count	other_alt_count	allele_frequency**; PileupSummary1; PileupSummary2; ...; PileupSummaryM",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-833821730:163,error,error,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-833821730,3,['error'],['error']
Availability,"@davidbenjamin, @lbergelson reminded me about this bug. Unlikely, but any chance the sign error in the digamma implementation (which kicks in for x >= 49) affects M2 or anything else that uses the Dirichlet class? Looks like there are also a few calls in VQSR. I'm still primarily interested in any possible performance/runtime improvements that could be gained by updating to a more recent package, perhaps one more actively developed than Apache Commons Math (e.g. Apache Commons Numbers). Seems to be some complications regarding release policies across those projects that preclude them from being updated frequently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6133#issuecomment-547988573:90,error,error,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6133#issuecomment-547988573,1,['error'],['error']
Availability,"@davidbernick thanks!. I noticed that the existing jobs are now failing with a GCS error (see https://gatk-jenkins.broadinstitute.org/job/gatk-perf-test-spark-markeddupe/436/console):. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```. There has been a change to the GCS library (https://github.com/broadinstitute/gatk/commit/b47838c9a5fa172ed6669ed4872b04d91c962a85), but when I ran a GCS pipeline manually on my machine it worked fine, even with this change. Any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325:83,error,error,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325,2,"['Error', 'error']","['Error', 'error']"
Availability,"@dpmccabe commented on [Mon Apr 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1008). (Very low-priority enhancement request). Allow GetBayesianHetCoverage's matched tumor-normal mode to run on multiple tumor samples matched to a single normal. The normal coverage pulldown and likelihood calculations really only need to be calculated and written to a file once. Alternatively, allow the user to specify a `normalHets` file instead of a BAM if one has already been generated. Thanks!. ---. @samuelklee commented on [Thu Apr 27 2017](https://github.com/broadinstitute/gatk-protected/issues/1008#issuecomment-297704915). We're slowly rebuilding the entire somatic pipeline. One change on the allelic side will be to simply collect allelic counts at all specified sites, rather than performing genotyping on all sites in matched normals and then collecting the corresponding tumor counts at het sites. . The CLI tool to do this (CollectAllelicCounts) is already merged, if you'd like to start using it. You'd only have to run this once on each BAM. The ultimate idea is that resulting allelic count files, along with the corresponding coverage files, could then be passed to a SomaticCNVCaller tool, along with the necessary annotations denoting whether they are tumor or normal. For now, you could probably insert a simple script that performs the genotyping step if you still want to use the rest of the old pipeline but avoid pulling down the normal multiple times.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2977:1453,down,down,1453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2977,1,['down'],['down']
Availability,"@droazen , @jamesemery - I think I addressed your comments, back to you now. ; Looking at this deeper, I think we will anyway remove the ""removeUncertainFlows"" options that triggered all this; It resulted in a need to fix a bug we had in a basecalling, but it had been long resolved. . In any case, I think that the check is more robust now, and it was a good fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1560516851:330,robust,robust,330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1560516851,1,['robust'],['robust']
Availability,"@droazen , I got a genomicsdb.jar from @kgururaj and just tried out the GenomicsDB cloud tests. The call stack that I got from my test run in nalini_new_genomicsdb_jar branch mentions that we do need the **fs.gs.project.id** hadoop configuration set. The google service json I use for our internal testing has this key, but the Hellbender service json does not. . Any ideas on how to get this key for the tests? Would this value be HELLBENDER_TEST_PROJECT? How is it being made available to the spark cloud tests for example? I do see it being configured in src/main/java/org/broadinstitute/hellbender/engine/spark/SparkContextFactory.java. ```; hdfsBuilderConnect(forceNewInstance=1, nn=gs://hellbender-test-logs, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:; java.io.IOException: Must supply a value for configuration setting: **fs.gs.project.id**; 	at com.google.cloud.hadoop.util.ConfigurationUtil.getMandatoryConfig(ConfigurationUtil.java:39); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createOptionsBuilderFromConfig(GoogleHadoopFileSystemBase.java:2185); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1832); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1013); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:976); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-427509641:478,avail,available,478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-427509641,2,"['avail', 'error']","['available', 'error']"
Availability,"@droazen , I was able to reproduce your result. I tried to isolate what made it work or not. I tried with two kinds of inputs:; - on the hellbender bucket, or; - on my own bucket. I tried with two choices for `GOOGLE_APPLICATION_CREDENTIALS`:; - default credentials, or; - my own. I tried with two different clusters:; - one created in the Broad project, or; - one created in my own project. With every one of those eight combinations, I got the same result: the dreaded ""Error code 404 trying to get security access token from Compute Engine metadata for the default service account."". ```; ./gatk-launch CountReadsSpark -I gs://hellbender/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -- --sparkRunner GCS --cluster jp-test-cluster --executor-cores 2 --num-executors 2; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-352147413:472,Error,Error,472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-352147413,2,['Error'],['Error']
Availability,"@droazen - That won't be solved by the current #3447, because there is no way of fine-tune the codecs: I require to being able to add/remove concrete classes, and exclude codecs from a concrete package. An example is a custom codec implementation for some feature, to provide extra-validation for the downstream toolkit. This would be even more useful if HTSJDK is moving to an interface-based library...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-337622596:301,down,downstream,301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-337622596,1,['down'],['downstream']
Availability,"@droazen - any idea about the time to get into this? It has been 2 years since the original proposal (https://github.com/broadinstitute/gatk/pull/1528) and almost a month for this to be reviewed. I understand that the bandwidth for community-driven development is lower than the one for broad needs - but I need to get non-intrusive functionality like this in an easier way to be shared between downstream projects. I'll probably opt to create a new project for this kind of gatk extensions: general-purpose walkers, common utility for gatk abstractions (e.g., `GATKRead`), etc. In that case, I am open to backport anything that might be useful for your team (and for the rest of the community), but I cannot block my own development due to long-standing PRs. Let me know what do you think about this. I will keep contributing to GATK and proposing new code to be included, but I guess that having a repository with this code available for the community in a versioned and delivered way might be useful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-388326562:395,down,downstream,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-388326562,2,"['avail', 'down']","['available', 'downstream']"
Availability,@droazen - friendly ping here!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-415308713:20,ping,ping,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-415308713,1,['ping'],['ping']
Availability,"@droazen - sorry for the compilation error, it was just an early optimization. Can you have a look to it? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-384300799:37,error,error,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-384300799,1,['error'],['error']
Availability,@droazen - that failure is related to the question I sent Louis and James - I'll forward you the same email,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-386378020:16,failure,failure,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-386378020,1,['failure'],['failure']
Availability,@droazen : Thanks a lot for prioritizing and attending to this. The security posture has greatly improved from where we started. Community greatly benefits from your effort. I have migrated to using the 4.5 release after some regression testing. Below is a list of critical and high findings with 4.5 release. There are links to snyk version update recommendations. I know sometimes its not easy just to upgrade the library version as we could end up with run time errors. I am adding this here so that its handy when ever you look at this further. Thanks again. . packageName | version | severity | language | module_id; -- | -- | -- | -- | --; com.google.protobuf:protobuf-java | 3.7.1 | high | java | [SNYK-JAVA-COMGOOGLEPROTOBUF-2331703 ](https://security.snyk.io/vuln/SNYK-JAVA-COMGOOGLEPROTOBUF-2331703 ); com.google.protobuf:protobuf-java | 3.7.1 | high | java | [SNYK-JAVA-COMGOOGLEPROTOBUF-3167772](https://security.snyk.io/vuln/SNYK-JAVA-COMGOOGLEPROTOBUF-3167772); io.netty:netty-codec-http2 | 4.1.96.Final | high | java | [SNYK-JAVA-IONETTY-5953332](https://security.snyk.io/vuln/SNYK-JAVA-IONETTY-5953332); log4j:log4j | 1.2.17 | high | java | [SNYK-JAVA-LOG4J-2342645](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-2342645); log4j:log4j | 1.2.17 | high | java | [SNYK-JAVA-LOG4J-2342646](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-2342646); log4j:log4j | 1.2.17 | high | java | [SNYK-JAVA-LOG4J-2342647](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-2342647); log4j:log4j | 1.2.17 | critical | java | [SNYK-JAVA-LOG4J-572732](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-572732); net.minidev:json-smart | 1.3.2 | high | java | [SNYK-JAVA-NETMINIDEV-3369748](https://security.snyk.io/vuln/SNYK-JAVA-NETMINIDEV-3369748); org.apache.zookeeper:zookeeper | 3.6.3 | high | java | [SNYK-JAVA-ORGAPACHEZOOKEEPER-5961102](https://security.snyk.io/vuln/SNYK-JAVA-ORGAPACHEZOOKEEPER-5961102); org.codehaus.jettison:jettison | 1.1 | high | java | [SNYK-JAVA-ORGCODEHAUSJETTISON-3168085](https://,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1890593067:465,error,errors,465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1890593067,1,['error'],['errors']
Availability,"@droazen ; * A field is imported into TileDB/GenomicsDB from the input VCF/gVCF files irrespective of whether the combine operation exists or doesn't exist.; * During the query phase, when GenomicsDBFeatureReader is executed, if the combine operation isn't specified (either in the source or in the vid JSON) for an INFO field, it will not be available in the combined VariantContext objects (warning message showed up front).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293997495:343,avail,available,343,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293997495,1,['avail'],['available']
Availability,"@droazen @cmnbroad sorry to bug you on this, but it looks like the last round of test failures were largely related to the free dockerhub account exceeding the max pulls. is there a chance you'd be able to restart the tests and/or review? thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7219#issuecomment-824992510:86,failure,failures,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7219#issuecomment-824992510,1,['failure'],['failures']
Availability,"@droazen @cwhelan Yes, it appears to be fixed. (Don't have a failing test that I can run on the old behavior, but a quick test of the latest code in master appears to have repaired the flaw.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2037#issuecomment-358093905:172,repair,repaired,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2037#issuecomment-358093905,1,['repair'],['repaired']
Availability,"@droazen @jonn-smith I am rerunning failed travis checks, since the error was something about picard piping, which is quite unrelated to this branch, so I am betting a transient error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5941#issuecomment-495230485:68,error,error,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5941#issuecomment-495230485,2,['error'],['error']
Availability,"@droazen @lbergelson ; I spoke with @jamesemery about this, and he suggested I make a ticket and ping you two. I'm trying to use the GATK docker as a starting point, but I run into this problem with GPG signatures. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447#issuecomment-908629838:97,ping,ping,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447#issuecomment-908629838,3,"['avail', 'error', 'ping']","['available', 'error', 'ping']"
Availability,"@droazen @lbergelson Have just updated this branch with fixes to the mismatches from the old codepath. I have just run it over a 5gb exome bam with it set to error if it ever mismatches the results in the old codepath and it completed successfully. As far as I can tell this is correct now and could use a more close review... . @ldgauthier The last commit on this branch handles an edge-case where the old codepath will prematurely report that a read with a long deletion in its middle may end up being marked as uninformative because read.getLength() will mismatch from the length of the bases realigned, thus resulting in reads with deletions in the beginning being less informative about deletions at their end. I don't know what you think should be done about this issue as it makes the code in this branch more complicated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-460420772:158,error,error,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-460420772,1,['error'],['error']
Availability,"@droazen @ldgauthier I'm assuming the travis failure is not caused by this? looking at some of the travis logs its complaining about ""Timeout waiting for network availability"" and the previous travis CI in master failed too...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-519716794:45,failure,failure,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-519716794,2,"['avail', 'failure']","['availability', 'failure']"
Availability,"@droazen @magicDGS There's a test failure because the ADAM project relies on deprecated code in HTSJDK that was removed in 2.7.0. We'll either need to disable the ADAM functionality or get a patched version of ADAM. I have a [patch for ADAM](https://github.com/bigdatagenomics/adam/pull/1235), but I don't think they release very often. We could host a patched artifact until then.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-257909408:34,failure,failure,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-257909408,1,['failure'],['failure']
Availability,"@droazen @sooheelee Anything involving adaptors is not my forte but here goes my best shot. The basic idea of `getAdaptorBoundary` is to find the end of the insert, that is, where the original fragment ends and the adaptor begins. Since the 5' ends of the paired reads define the bounds of a fragment, its approach is to look for the start of the forward strand mate if our read is on the reverse strand, or the end of a reverse strand mate if our read is on the forward strand. This protects us from the possibility of a read longer than its insert. So far, so good, I think. One possible source of error is that these boundaries are determined by the *alignment* starts of the paired reads. This might clip too much if a read has a soft-clipped end and it turns out that these soft-clipped bases were e.g. a real insertion. Then the soft-clipped bases would be considered part of the adaptor. However, this can't do the more harmful thing of failing to clip an adaptor as far as I can tell. So it looks to me like the only issue is the edge case of falsely soft-clipped bases in very short inserts, in which case we hard clip the soft clips and in theory could lose some sensitivity. . That said, @sooheelee may have something else in mind, and @yfarjoun will have a better-informed opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963:600,error,error,600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963,1,['error'],['error']
Availability,"@droazen Applied your steps, I hope correctly - the pull request looks clean now. Your steps were a huge help. . The travis build looks like failing now, for reasons not obviously connected with our commit:. `Error: (converted from warning) unable to access index for repository http://cran.mtu.edu/src/contrib; Execution halted; The command ""if [[ $TEST_DOCKER != true ]]; then sudo mkdir -p /usr/local/lib/R/; sudo mkdir -p site-library; sudo ln -sFv ~/site-library /usr/local/lib/R/site-library; sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9; sudo add-apt-repository ""deb http://cran.rstudio.com/bin/linux/ubuntu trusty/""; sudo apt-get update; sudo apt-get install -y --force-yes r-base-dev=3.1.3-1trusty; sudo apt-get install -y --force-yes r-base-core=3.1.3-1trusty; sudo Rscript scripts/docker/gatkbase/install_R_packages.R; fi;"" failed and exited with 1 during .`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437922888:209,Error,Error,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437922888,1,['Error'],['Error']
Availability,"@droazen As it turns out they interact poorly. If i try to run a picard tool with the argument `--tmp-dir` you get a failure for the argument being unrecognized where as if I run a GATK tool with `--TMP_DIR` it also fails. The system property ""-Djava.io.tmpdir=<>"" appears to work correctly for both GATK and Picard tools however.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6811#issuecomment-691246876:117,failure,failure,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6811#issuecomment-691246876,1,['failure'],['failure']
Availability,"@droazen Can you re-assign to someone not me? This would also imply changes to the travis tests, to make sure that it is using the correct user. Probably other downstream effects that I have not determined.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-333545888:160,down,downstream,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-333545888,1,['down'],['downstream']
Availability,@droazen Confirmed. There was no error when re-running on the user's data with the latest release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6516#issuecomment-689047718:33,error,error,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6516#issuecomment-689047718,1,['error'],['error']
Availability,"@droazen Ditto for gatk-fermi-lite: there's a new PR that adds some error handling. However, that artifact is hooked up to Travis, which fails. So I'll probably need some help from @lbergelson to get that sorted out -- gradle is missing an assemble verb. Can you review the PR or assign a reviewer, please?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313532473:68,error,error,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313532473,1,['error'],['error']
Availability,@droazen Fixed the error,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420295205:19,error,error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420295205,1,['error'],['error']
Availability,"@droazen I agree that running master with default settings is not a fair comparison. Therefore, I set `-maxReadsPerAlignmentStart` to be equal and much lower than the default in both branches. I have tried a few values, but none lower than 10. I expect that using master downsampling to 3 reads per alignment start will handle most of the runtime issue at some small cost to sensitivity and precision, but let me run it and see what happens.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341939411:271,down,downsampling,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341939411,1,['down'],['downsampling']
Availability,"@droazen I assume that this fixes the BigQuery error you were seeing. I think this may fail on a cluster due to not using a shaded version of google-cloud-java, but I'll give it a go.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-490555179:47,error,error,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-490555179,1,['error'],['error']
Availability,@droazen I fixed the tests (it was an errant find and replace error). I have spot checked the changes and it looks like nothing obviously off-target in there. I need another approval in order to finally merge this branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-602812944:62,error,error,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-602812944,1,['error'],['error']
Availability,"@droazen I followed your instructions, but same error, I'm sorry. @lbergelson ; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.3 LTS; Release:	16.04; Codename:	xenial. Anyway I remember that I faced this issue some months ago and I resolved it adding to .basrc this line; `export JAVA_OPTS=-Dfile.encoding=UTF8`, but now for some reason I don't know why when I use `./gradlew bundle` is not used this java encoding and so doesn't work (but if you have the possibility to modify that name, you should resolve definitely the issue).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367410334:48,error,error,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367410334,1,['error'],['error']
Availability,"@droazen I had put in https://github.com/broadinstitute/gatk/issues/3899 over a week ago and just now assigned you to decide if we want to consider instituting a symlink/environmental variable `gatk` that is callable from anywhere in the Docker. . As someone with a newbie perspective, it is easier for me to grasp `gatk` represents the script to which I must provide the path to (e.g. ~/Downloads/gatk/gatk) than to understand that `./gatk` must be run in a particular folder.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3911#issuecomment-350787427:388,Down,Downloads,388,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3911#issuecomment-350787427,1,['Down'],['Downloads']
Availability,"@droazen I have a PR for gatk-bwa-mem that adds a footer to the image file so that we can test integrity. I also added code to test every (I think) call that returns an error indication, and pass this info up the chain. Could you review the PR or delegate, please?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079:169,error,error,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079,1,['error'],['error']
Availability,@droazen I have pushed the cache removal step down to a more testable point in the code and added the assertion to the existing testing infrastructure. Can you take a quick look at this branch so it can go in at some point?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930:46,down,down,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930,1,['down'],['down']
Availability,"@droazen I implemented the pr skipping on push builds if there's a pr branch. It seems to work. It has to spin up a vm to do the check, but that takes about a minute instead of many, and it avoids running tests and downloading lfs. The good things is that if it fails for some reason it should just continue on with the build, so flakiness in the github api or network connectivitiy will just result in some extra builds completing rather than extra failures. . <img width=""1054"" alt=""screen shot 2018-09-05 at 11 19 14 am"" src=""https://user-images.githubusercontent.com/4700332/45103843-c5b5ae00-b0fe-11e8-9934-0025af9836ee.png"">. I think I should add a github token though so we don't get api throttling. Should I just add one from my own account?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5156#issuecomment-418773830:215,down,downloading,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5156#issuecomment-418773830,2,"['down', 'failure']","['downloading', 'failures']"
Availability,@droazen I just looked and it seems that the only other big one I added was `--disable-artificial-haplotype-recovery` and that one is very esoteric indeed and doesn't need to be exposed I don't think.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6737#issuecomment-668197410:108,recover,recovery,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6737#issuecomment-668197410,1,['recover'],['recovery']
Availability,@droazen I profiled a lot and did some unit test experiments and basically there's no difference. Depending on average depths one or the other can be faster by up to 15 seconds per billion sites. I really just wanted to cull the list of open issues and had nothing against the old downsampler code. How about we close this PR *and* close Adam's GATK issue?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-433994089:281,down,downsampler,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-433994089,1,['down'],['downsampler']
Availability,"@droazen I ran #4314 and it did not solve the problem. When I reverted the ADAM patch from the #4314 branch I got the normal performance. @fnothaft I wish I knew. @lbergelson said he saw more logs being produced. Another (untested) theory is that the Kryo registrations changed somehow. GATK only uses the 2bit code from ADAM, so it is surprising that it is having such an effect. I'm not sure how to track down the problem at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366294101:407,down,down,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366294101,1,['down'],['down']
Availability,"@droazen I rebased against master on 11/1, and ran on several tumor-normal pairs with and without interval lists. The total CPU time remains about 30-40% better in the rebased downsampling branch than in the latest master branch. Also, wall clock time turns out to be a stronger argument in favor of these additions: scattering wgs bams 50 ways, the wall clock time tends to be 3-5x greater in master.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341741374:176,down,downsampling,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341741374,1,['down'],['downsampling']
Availability,@droazen I responded to your comments. I've additionally some changes to the readme to include information about the test environment variables. Let me know if there are horrible spelling errors that I somehow missed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278802390:188,error,errors,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278802390,1,['error'],['errors']
Availability,"@droazen I think I see how #4801 could introduce a rounding error that creates an extremely small positive log10 probability, which triggers the error. The old code was ; ```; log10PNoVariant += log10GenotypePosteriors[HOM_REF_GENOTYPE_INDEX]; ```. and the new code to handle spanning deletion is; ```; log10PNoVariant += MathUtils.log10SumLog10(nonVariantLog10Posteriors); ```; where `nonVariantLog10Posteriors` includes but the hom ref posterior *and* the posteriors of ref / span del het genotypes. So instead of A, where A is the log 10 hom ref posterior, we have log10(10^A + 10^B), where B is the ref/span del het log10 posterior. This latter quantity should never be positive, but the `log10SumLog10` method it relies on doesn't know that and has finite precision. Given that the problematic number is truly miniscule, `2.559797571100845E-21`, my money is on that explanation. I think a reasonable solution is just to replace it by zero, because we know that's where it comes from. That is, the code should become; ```; log10PNoVariant += Math.min(MathUtils.log10SumLog10(nonVariantLog10Posteriors), 0);; ```. If there is a way for me to debug without having to learn to use GenomicsDB I would like to confirm this myself. Otherwise, @sooheelee can I give you a jar to try out on the tutorial data where you spotted the problem earlier?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4975#issuecomment-402175972:60,error,error,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4975#issuecomment-402175972,4,['error'],['error']
Availability,@droazen I think the failure is transient,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4977#issuecomment-401860633:21,failure,failure,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4977#issuecomment-401860633,1,['failure'],['failure']
Availability,"@droazen I think this can be closed since @djb17 indicated that he was able to import without error after merging intervals. @djb17 if you absolutely need your analysis to reflect only the intervals your specify in your bed file, then you can either pre-process the gvcf files (VariantFiltration or bcftools or the like) to only leave those intervals in there before importing using `GenomicsDBImport` or maybe specify the intervals argument to whatever tool will be reading from the genomicsdb workspace (for instance, `GenotypeGVCFs` has a `-L` argument)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950#issuecomment-732402671:94,error,error,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950#issuecomment-732402671,1,['error'],['error']
Availability,"@droazen I'll put together my version and you can have a look. I'm making it always attempt a retry on retriable exceptions, so we don't have to worry about errors that would result in a reopen in `CloudStorageReadChannel`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315472400:157,error,errors,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315472400,1,['error'],['errors']
Availability,"@droazen I'm getting a similar error. The 'import tensorflow as tf', followed by the modified definition for start_session_get_args_and_model, didn't work for me. Any suggestions? Is there an updated models.py? . I installed gatk 4.2.2 from the zip file and built the python environment with miniconda",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-939408146:31,error,error,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-939408146,1,['error'],['error']
Availability,"@droazen I've finally been able to move ahead on this and have a question on what to expect for plugins that define arguments. I have two plugins that each share an argument. I created an ArgumentCollection class to define that argument, and then added this @ArgumentCollection to each plugin. Something like:. ```. public class GenotypeConcordanceBySite extends PedigreeAnnotation implements InfoFieldAnnotation { ; @ArgumentCollection; public GenotypeConcordanceArgumentCollection args = new GenotypeConcordanceArgumentCollection();. . .etc......; }. Gpublic class GenotypeConcordance extends PedigreeAnnotation implements InfoFieldAnnotation {; @ArgumentCollection; public GenotypeConcordanceArgumentCollection args = new GenotypeConcordanceArgumentCollection();. . etc......; }. public class GenotypeConcordanceArgumentCollection {; @Argument(doc=""Reference genotypes VCF"", fullName = ""reference-genotypes-vcf"", shortName = ""rg"", optional = true); public FeatureInput<VariantContext> referenceVcf = null;; }. ```. When I run VariantAnnotator with both plugins, I get an error from within Barclay about arguments with duplicate names. . Ideally these plugins would not be aware of each other (since they can be used independently). Is there a way to define arguments that might be declared in different plugins, but are somehow resolved as identical and therefore allowed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-794444380:1082,error,error,1082,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-794444380,1,['error'],['error']
Availability,"@droazen It's not a hard fix but it's bad that we don't have any way of detecting it... The way we set system properties is very gross and error prone. We set them in 2 place in build.gradle AND in gatk-launch, and we have to be careful to duplicate the changes in build.gradle in gatk-protected (which I don't think we ever end up doing...)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2316#issuecomment-267121107:139,error,error,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2316#issuecomment-267121107,1,['error'],['error']
Availability,@droazen It's possible. @guandailu Are you able to share a minimal set of inputs that reproduces the error?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7092#issuecomment-785936927:101,error,error,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7092#issuecomment-785936927,1,['error'],['error']
Availability,"@droazen Not sure why we're getting a build failure here, can you or @lbergelson please take a look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2789#issuecomment-309636298:44,failure,failure,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2789#issuecomment-309636298,1,['failure'],['failure']
Availability,"@droazen OK, so that involved jumping through a bunch of hurdles. i ended up using your docker image to check out and build the project (based on the 4.2.5.0 tag). copied that JAR out, and re-tried on our cluster. I grabbed the JAR in the build -> ""bundled resources"" folder, named: gatk-package-4.2.5.0-SNAPSHOT-local.jar. I think this is the shadow JAR, but nothing was explicitly named that. From here, I restarted my jobs, but unfortunately I'm actually getting different ClassNotFoundException errors: . ```; 15 Feb 2022 15:46:19,117 DEBUG: 	Exception in thread ""main"" java.lang.NoClassDefFoundError: htsjdk/samtools/FileTruncatedException; 15 Feb 2022 15:46:19,123 DEBUG: 		at htsjdk.samtools.util.BlockCompressedOutputStream.close(BlockCompressedOutputStream.java:355); 15 Feb 2022 15:46:19,128 DEBUG: 		at htsjdk.samtools.util.BlockCompressedOutputStream.close(BlockCompressedOutputStream.java:333); 15 Feb 2022 15:46:19,150 DEBUG: 		at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.close(IndexingVariantContextWriter.java:172); 15 Feb 2022 15:46:19,160 DEBUG: 		at htsjdk.variant.variantcontext.writer.VCFWriter.close(VCFWriter.java:233); 15 Feb 2022 15:46:19,169 DEBUG: 		at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.closeTool(GenotypeGVCFs.java:297); 15 Feb 2022 15:46:19,180 DEBUG: 		at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1091); 15 Feb 2022 15:46:19,185 DEBUG: 		at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 15 Feb 2022 15:46:19,190 DEBUG: 		at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 15 Feb 2022 15:46:19,212 DEBUG: 		at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 15 Feb 2022 15:46:19,217 DEBUG: 		at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 15 Feb 2022 15:46:19,223 DEBUG: 		at org.broadinstitute.hellben",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1040915714:499,error,errors,499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1040915714,1,['error'],['errors']
Availability,"@droazen People continue to encounter errors trying to use shuffle, see https://github.com/broadinstitute/dsde-docs/issues/2318. I repeat my recommendation to remove it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2231#issuecomment-316795693:38,error,errors,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2231#issuecomment-316795693,1,['error'],['errors']
Availability,"@droazen Setting master to 3 reads per alignment start and this branch to 30 reads per alignment start with a stride of 10 (i.e. equal downsampling on average) and scattering four wgs bams 50 ways each, CPU time is almost identical but wall clock time is anywhere from 20% to 100% slower in master. Also, sensitivity in master goes down by 0.5% but is unchanged in this branch. I think this makes a good case for the alignment start stride and biasing downsampling to higher mapping quality, but those are not urgent. As we discussed in person, I *don't* like my maxReadsToIgnore region argument, which provides most of the benefit, and I want to explore a read start filter as an alternative. I think that will take less than a week to prototype.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-342946075:135,down,downsampling,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-342946075,3,['down'],"['down', 'downsampling']"
Availability,"@droazen Thanks for the reply!; Certainly. `umask `returns `0022`. As such I reckon that is not the issue. Stacktrace in the bottom. The folder permission of the datastore folder is as follows:; `drwx--S---+ 26 vidprijatelj group 4096 Mar 14 15:29 Vid_database`. When changing to 766, the error disappears. ```; Tue Mar 14 15:37:57 CET 2023; Using GATK jar /appl/tools/versions/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Djava.io.tmpdir=zzz_tmpdir -Xmx128G -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /appl/tools/versions/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar GenotypeGVCFs --reference /data/Scratch/References/ucsc.hg38.fa --variant gendb://Vid_database --output Step05_MultiSampleCalling/Vid.vcf.gz --intervals /data/Scratch/References/hg38_exome_v2.0.2_merged_probes_sorted_validated.annotated.bed --genomicsdb-shared-posixfs-optimizations True --merge-input-intervals; 15:37:59.895 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/appl/tools/versions/gatk-4.3.0.0/gatk-package-4.3.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:38:00.018 INFO GenotypeGVCFs - ------------------------------------------------------------; 15:38:00.018 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.3.0.0; 15:38:00.018 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:38:00.018 INFO GenotypeGVCFs - Executing as user@server; 15:38:00.018 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_362-b08; 15:38:00.019 INFO GenotypeGVCFs - Start Date/Time: March 14, 2023 3:37:59 PM CET; 15:38:00.019 INFO GenotypeGVCFs - ------------------------------------------------------------; 15:38:00.019 INFO GenotypeGVCFs - ------------------------------------------------------------; 15:38:00.019 INFO GenotypeGVCFs - HTSJDK V",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1468228918:289,error,error,289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1468228918,1,['error'],['error']
Availability,"@droazen The Travis build failed so I reran it a couple times and it seems to have passed fine on the most recent run. I'm not sure if that should still be taken as an indication of an issue, though. The first failure was on the Java 11 job, which I just assumed was the same issue other builds are running into. Second time, it was a failure on one of the Java 8 jobs and it seemed to be a docker issue, which I didn't think made sense for the type of changes in this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7021#issuecomment-756196675:210,failure,failure,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7021#issuecomment-756196675,2,['failure'],['failure']
Availability,"@droazen The issue here is that `ReadWalker` doesn't have downsampling, right? It seems like it would be straightforward to downsample the streamed reads in its `traverse` method. Thoughts / am I missing something?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5075#issuecomment-443586548:58,down,downsampling,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5075#issuecomment-443586548,2,['down'],"['downsample', 'downsampling']"
Availability,"@droazen The thought was that we would fail at the point we try to load bases which is usually very close to the start. It moves the error back a bit which isn't great, but would allow for crams with embedded references.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6665#issuecomment-645474983:133,error,error,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6665#issuecomment-645474983,1,['error'],['error']
Availability,@droazen The user provided test data(problematic BAM file and its md5sum): https://drive.google.com/drive/folders/1a6q_c7xNlsFqG1B3TdrdVL51_QB5e7RD; The command they used:; `gatk SplitNCigarReads -R hg38_primary_refseq.fa -I SOD1P_A272C_rep2.Dedup.bam -O SOD1P_A272C_rep2.Split.bam`. Additional info: The original raw data is publicly available in the SRA: SRR5273292,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6776#issuecomment-689025052:335,avail,available,335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776#issuecomment-689025052,1,['avail'],['available']
Availability,@droazen This improves the error message we talked about in the meeting.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6779#issuecomment-683955730:27,error,error,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6779#issuecomment-683955730,1,['error'],['error']
Availability,"@droazen We have a couple of merged PRs, #5873 and #5853, between which the error should not be thrown in the next minor release. However, this does not change the fact that **users should never, ever, run the Mutect2 pipeline with an unmatched tumor-normal pair.** When there is no matched normal, one should run it in tumor-only mode with a panel of normals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083056:76,error,error,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083056,1,['error'],['error']
Availability,"@droazen Yes, the user has confirmed there are contigs in their eval VCF that are not in the truth VCF. This bug report is to improve the error message for this case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7562#issuecomment-969320338:138,error,error,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7562#issuecomment-969320338,1,['error'],['error']
Availability,@droazen `-R /mnt/d/data/gatk_bundle/hg38//Homo_sapiens_assembly38.fasta.gz` in the error from the first user. There could be some issue related to the gzipped index but that doesn't look like an unusual reference to me.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-572231730:84,error,error,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-572231730,1,['error'],['error']
Availability,@droazen are you sure thats not transient ? The first (connection timeout) failures that happened don't appear in previous builds that succeeded.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311408683:75,failure,failures,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311408683,1,['failure'],['failures']
Availability,"@droazen correct. ; Generally, one issue is that this slows down the docker image creation in a somewhat substantial way. Around 10 minutes currently. Half of this is unzipping the bundled jar, and another piece is some redundant gradle downloading that can be alleviated with cache shenanigans.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4955#issuecomment-400797666:60,down,down,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4955#issuecomment-400797666,3,"['down', 'redundant']","['down', 'downloading', 'redundant']"
Availability,@droazen gentle ping: this code has been awaiting review for two weeks.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2565#issuecomment-294569533:16,ping,ping,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2565#issuecomment-294569533,1,['ping'],['ping']
Availability,"@droazen here are the error messages with gatk4.1.8.1 and gatk4.1.4.1:. 15:01:44.424 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cm/shared/unil/software/8.3/GATK/4.1.4.1-GCCcore-8.3.0-Java-8/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 09, 2020 3:01:45 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine. 14:28:22.786 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cm/shared/unil/software/8.3/GATK/4.1.8.1-GCCcore-8.3.0-Java-8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 09, 2020 2:28:23 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707085229:22,error,error,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707085229,1,['error'],['error']
Availability,"@droazen ideally, the executor must be able to fire up one (or more) python kernels and keep it (them) alive as long as the user decides to keep it (or the GATK session terminates). Here's an example why this is desirable: the compilation of a complicated theano computational graph can take a significant portion of the total computation time. The compiled graph is a function of data dimensions, which in my use case, varies from loci to loci. My current solution to this is to pre-compile and cache a number of theano computational graphs with different sizes, pad the data to fit it to the closest matching computational graph, and re-use the same compiled graph(s) as required. To this end, one needs to keep the python kernel w/ the compiled graphs alive.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3501#issuecomment-325040324:103,alive,alive,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501#issuecomment-325040324,2,['alive'],['alive']
Availability,@droazen is there a new release available?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8296#issuecomment-1653781265:32,avail,available,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8296#issuecomment-1653781265,1,['avail'],['available']
Availability,@droazen oh it was my own fault David :),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2813#issuecomment-306320827:26,fault,fault,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2813#issuecomment-306320827,1,['fault'],['fault']
Availability,@droazen ping,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4841#issuecomment-403081626:9,ping,ping,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4841#issuecomment-403081626,1,['ping'],['ping']
Availability,@droazen production informed me that recalibration has passed (and that now they have a different downstream problem...as predicted!),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-641575854:98,down,downstream,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-641575854,1,['down'],['downstream']
Availability,@droazen still giving error:. com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132:22,error,error,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132,2,"['Error', 'error']","['Error', 'error']"
Availability,"@droazen sure. This PR updates both `BucketUtils.getPathOnGcs` and `IOUtils.getPath` (the latter indirectly) to create a Google Cloud Storage filesystem with a default reopen set to 3. Anyone opening the given `Path` (or even a `Path` derived from it, e.g. via `subpath`) will have the retries enabled. `addPrefetcher` wraps an existing `Path`, so it inherits the underlying `Path`'s retry behavior. Classes within htsjdk that create a `Path` from a String, without using our utility code, would indeed not set retries and errors on those files would not get the benefit of our extra retry. The exception to that is the Spark code path with `NioBam`: this goes via `ReadsIterable`, which also sets the retries. My understanding is that the normal way to open BAMs for tools always creates the `Path` object when parsing the command line, as in e.g. `ReadInputArgumentCollection::GetReadIndexPaths()`. That code path that calls `IOUtils.getPath` (and thus sets the retries). I would expect that the added support for VCF follows the same style, though it looks like it doesn't. If there's a code path that I missed where you think we need retries then please let me know so I can add it!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-289585791:523,error,errors,523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-289585791,1,['error'],['errors']
Availability,"@droazen thanks for that, though I did update them by hand already! My remaining failures are in `CombineGVCFsIntegrationTest` and `GenotypeGVCFsIntegrationTest`, so I am close!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-431078115:81,failure,failures,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-431078115,1,['failure'],['failures']
Availability,"@droazen there might be some new test failures (which I will address if/when they arise), but this is ready for re-review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7670#issuecomment-1041936461:38,failure,failures,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7670#issuecomment-1041936461,1,['failure'],['failures']
Availability,"@droazen this behavior hasn't changed in the most recent GenomicsDB release. . Short recap: this happens because bcf codec doesn't support the 64 bit values that GenomicsDB is returning. Running with `--genomicsdb-use-vcf-codec` will resolve it. From our discussions in the office hours, I thought we had decided to change the behavior in htsjdk so that it doesn't try to decode the type if it doesn't recognize it. (maybe I should have filed https://github.com/broadinstitute/gatk/issues/6548 in htsjdk instead? I thought I was told to do in GATK, but its been long enough that I can't remember). Another possibility is to make `--genomicsdb-use-vcf-codec` the default - though I recall you had some potential performance concerns about that. Lastly, we could change GenomicsDB to throw out a warning if a 64 bit value is needed and we're using bcf codec. Of course, this would still require the user to (re)run with `--genomicsdb-use-vcf-codec` to avoid hitting the NPE (or whatever other failure would be hit if the NPE was changed to something a bit more meaningful).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6667#issuecomment-646167430:991,failure,failure,991,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6667#issuecomment-646167430,1,['failure'],['failure']
Availability,@droazen weekly ping. Please take a look?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2565#issuecomment-297162369:16,ping,ping,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2565#issuecomment-297162369,1,['ping'],['ping']
Availability,"@droazen yes, let's discuss. There's no need to remove those methods as far as Mutect is concerned. As long as we implement the new functionality in *some* downsampler class, we have what we need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314319556:156,down,downsampler,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314319556,1,['down'],['downsampler']
Availability,"@droazen, @lbergelson I have the following argument to the tool:. ```java; @Argument(fullName = ""read-tags"", doc = ""read tag names to recover""); public List<String> readTags = DEFAULT_READ_TAGS;; ```. On the command line I want to say. ```; java -jar gatk.jar ; ...; --read-tags RX; ```. and want readTags to be a singleton list. But in my test it's not parsing the arguments correctly---what am I doing wrong here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1081090913:134,recover,recover,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1081090913,1,['recover'],['recover']
Availability,"@droazen, I have pushed a debugging test. It just prints out all the keys and not private and not id values in the service json pointed by GOOGLE_APPLICATION_CREDENTIALS env. Would it be possible to accept this into the nalinigans_genomicsdb_uri_support branch, so I can browse through the stdout for that test on Travis? By the way, the failures in the build seem to be unrelated to my change. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5017#issuecomment-423026481:338,failure,failures,338,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5017#issuecomment-423026481,1,['failure'],['failures']
Availability,"@droazen, I will address this in #2041. As you suggested this when I implemented `LocusWalker`, I would like to have some idea about why `DownsamplingMethod` is used as a parameter in the constructor. I think that this is misleading, because independently of the method for downsampling the one that is used by `SamplePartitioner` is a `ReservoirDownsampler` (if downsampling is performed), so API users could think that they are performing a different downsampling in LIBS that the actual one. I will keep the constructor in the PR, but I would like some feedback for this either here or in #2041.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1879#issuecomment-235530006:274,down,downsampling,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1879#issuecomment-235530006,3,['down'],['downsampling']
Availability,"@droazen, I'm running a job using a JAR based on #7962 and it progressed beyond the previous failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7938#issuecomment-1195740340:93,failure,failures,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7938#issuecomment-1195740340,1,['failure'],['failures']
Availability,"@droazen, how do you interpret these results? I see one failure is a timeout, the other I'm not sure about but neither look really related to this code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-458336902:56,failure,failure,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-458336902,1,['failure'],['failure']
Availability,"@droazen, looks like the changes from PR https://github.com/broadinstitute/gatk/pull/5540 caused the failure with testGenomicsDBImportFileInputs_newMQ. Reverting the changes from that pull request got things working again. I will look at this issue tomorrow, meanwhile any suggestions @ldgauthier?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-453889312:101,failure,failure,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-453889312,1,['failure'],['failure']
Availability,"@droazen, we were able to go past the MIN_DP and ExcessHet problem. GenomicsDB calls the appropriate combine operation for this field from the given samples and the error went away. However, we have run into another problem: assertVariantContextsAreEqual() method compares two lists of Alleles and if these lists are not ordered in the same way, the check fails. The order in which alleles are read from GenomicsDB does not always match that generated by your tool. For example, for position 17966384, the alleles are CAA, CA, C, <NON_REF> and GenomicsDB feature reader shows them as CAA, C, CA, <NON_REF>. Our ""vcfdiff"" tool in GenomicsDB passes the test and all data looks good. So, either we check the variant contexts using our diff tool or you fix the assertion method.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293699648:165,error,error,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293699648,1,['error'],['error']
Availability,@duanshumeng It seems like the error is pretty self explanatory. You ran out of space on your hard drive. I'm closing this because I'm not sure what the question is. Make some room and try again? If you think there's a bug feel free to re-open and clarify.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6772#issuecomment-682116189:31,error,error,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6772#issuecomment-682116189,1,['error'],['error']
Availability,"@dwuab which issue/error are you specifically referring to? As indicated in the last message before you posted, the previous user was able to use GenomicsDBImport and GenotypeGVCFs after following our suggestions to break up large chromosomes into smaller intervals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-900456302:19,error,error,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-900456302,1,['error'],['error']
Availability,"@eddiebroad commented on [Thu Dec 01 2016](https://github.com/broadinstitute/gatk-protected/issues/806). An issue encountered with gatk-protected ""SparkGenomeReadCounts"" tool is a non-helpful ""null"" error message. A non-helpful error ""null"" message was printed by gatk-protected with the command-line below; during the course of trying to use it on/in FireCloud:. ```; + java -Xmx48g -jar fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar SparkGenomeReadCounts --outputFile this.entity_id.coverage.tsv --reference fc-e2421839-93d5-4ed5-8861-593f00364e54/Homo_sapiens_assembly19.fasta --input firecloud-tcga-open-access/tutorial/bams/C835.HCC1143_BL.4.bam --binsize 5000; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; .....; ......; ......; proceeding with flushing remote transports.; ***********************************************************************. null. ***********************************************************************; ```. To try to make a more helpful error message appear I added a ""catch"" block after a call to runTool in instanceMainPostParseArgs in file CommandLineProgram.java and got a more helpful message about a missing dictionary file: . try {; return runTool();; } ; catch(Exception e) {; e.getStackTrace();; }. java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:204); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:152); Caused by: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:199,error,error,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,2,['error'],['error']
Availability,"@efr3m This syntax seems to work fine for me using both single and double quotes (and bash), so I don't see any evidence of a bug. Have you tried running the same command directly ? Do you see the same error ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6241#issuecomment-548777913:202,error,error,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6241#issuecomment-548777913,1,['error'],['error']
Availability,@eitanbanks please review (by testing out the repair tool),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3868#issuecomment-346449167:46,repair,repair,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3868#issuecomment-346449167,1,['repair'],['repair']
Availability,"@elbakrifz The error is telling you that the sequence dictionary for your bam file does not match the sequence dictionary for your reference -- are you using the right reference? . Also, you are running GATK 3, which we no longer officially support. This repository is for GATK 4 issues only.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798#issuecomment-692227557:15,error,error,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798#issuecomment-692227557,1,['error'],['error']
Availability,"@eriqande thanks for sharing your data, but I'll need your reference fasta as well to be able to reproduce your error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023334394:112,error,error,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023334394,1,['error'],['error']
Availability,"@eriqande your data looks good with the update in https://github.com/broadinstitute/gatk/pull/7655 Hopefully we can get a point release out next week, but if you're in a rush you can roll your own jar from that branch. There are two args now (both to be used in the GenotypeGVCFs command). I would suggest setting the `--max-alternate-alleles-for-gdb` to a value 3-4 more than the `--max-alternate-alleles` value that's used by GenotypeGVCFs if you want to be sensitive about retaining variants, keeping in mind that sites with more than `--max-alternate-alleles-for-gdb` will ultimately be dropped. For a human cohort, I would typically expect sites with more than 6 alleles to be (indel) PCR stutter errors, but use your own judgement based on your organism's mutation rate and population diversity.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1024381530:702,error,errors,702,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1024381530,1,['error'],['errors']
Availability,@erniebrau I don't think we can exclude log4j 1.x. A lot of our dependencies use it. This branch is failing with various ClassNotFound errors. ex: https://storage.googleapis.com/hellbender/test/build_reports/11489.3/tests/test/classes/org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSourceUnitTest.html#testReadFromFileAndHDFS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279:135,error,errors,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279,1,['error'],['errors']
Availability,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:104,error,error,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152,3,['error'],['error']
Availability,"@fi1d18 It looks to me like the error message is correct. The input file you specified (`--INPUT NG-27280_CLTSS_LTS_001A_lib506241_7636_2_MarkedDup.bam`) is in fact not in the folder from which you're running, which you can see from the results of the `ls` command you provided:. ```; (gatk) root@34684eaa046e:/gatk/data/Continuum/WES/vcf# ls; GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz; ```. You can see that `NG-27280_CLTSS_LTS_001A_lib506241_7636_2_MarkedDup.bam` is not included in the `ls` output. If the input file is in another location, you'll need to specify it using either an absolute or relative pathname. If the problem persists after that, feel free to reopen this ticket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8462#issuecomment-1677320234:32,error,error,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8462#issuecomment-1677320234,1,['error'],['error']
Availability,"@fleharty : You can download the bam file using the shared link. . https://ki.box.com/s/b9fe0854eccclz85vvkktd2qfqquyq71. > Also, are you sure that you intend to have insertion and deletion qualities, this is something we haven't been using for a few years now.; In my workflow, these bam files were generated using sentieon bwa-mem with the default options. Are there any suggestions on how to run mutect2 successfully on this bam file?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658243918:20,down,download,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658243918,1,['down'],['download']
Availability,"@fleharty @avalind ; Sorry, something happened with my previous message.; But what I wrote previously was that I couldn't reproduce the same error message using Picard ValidateSamFile. I tried validating my bam file and I don't see any errors. Even the samtools flagstat option works fine on my bam file.; Please find the attached screenshots,. <img width=""704"" alt=""picard"" src=""https://user-images.githubusercontent.com/6302819/88064375-8023f200-cb6b-11ea-960e-bab93f79ff22.png"">. <img width=""289"" alt=""flagstst"" src=""https://user-images.githubusercontent.com/6302819/88064447-9631b280-cb6b-11ea-86ee-6c49f9111507.png"">. Do you still think my bam file is malformatted?. PS: @fleharty used Picard version (2.20.4-SNAPSHOT), whereas I used v.2.23.2; for running Picard ValidateSamFile.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-661884614:141,error,error,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-661884614,2,['error'],"['error', 'errors']"
Availability,@fleharty I have a branch that ought to fix this. Do you have data that reproduce the error?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6727#issuecomment-730905397:86,error,error,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6727#issuecomment-730905397,1,['error'],['error']
Availability,"@fleharty It's line 810 in that class (https://github.com/samtools/htsjdk/blob/f15bc9d2c0297a1bde6b89aa95cf2dc45dfc567f/src/main/java/htsjdk/variant/vcf/AbstractVCFCodec.java#L810). We need to switch from calling `decodeInts()` to calling a method that tolerates and preserves missing values. A decision will need to be made about whether, for AD specifically, missing values should be replaced with 0 (which @ldgauthier said she'd be ok with), or passed through to the caller as '.' or null. If we choose to propagate the missing values back to the caller, we may need to do downstream work in GATK/Picard to modify tools to handle them, and also modify the HTSJDK accessor for the AD field to return list of `Integer` instead of array of `int`. If we replace the missing values with 0, we likely wouldn't have to patch any downstream code at all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-682016997:253,toler,tolerates,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-682016997,3,"['down', 'toler']","['downstream', 'tolerates']"
Availability,"@fnothaft Thanks for this pr. I fixed the problem that was causing compilation to fail, but now we're getting real errors. ex:; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1419.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1419.0 (TID 3897, localhost): java.lang.IllegalArgumentException: requirement failed: Failed when trying to create region 21 10006438 10006545 on null strand.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356012620:115,error,errors,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356012620,3,"['error', 'failure']","['errors', 'failure']"
Availability,"@fpbarthel I did use 4.1.0.0 to test this as well as 4.0.9.0. I think that it must have been fixed, but I am glad that you were able to find a workaround. Let us know if this error occurs again though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5683#issuecomment-888363150:175,error,error,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5683#issuecomment-888363150,1,['error'],['error']
Availability,"@frank-y-liu I ran using the scripts in https://github.com/broadinstitute/gatk/tree/tw_spark_eval/q4_spark_eval, so no extra ENV variables. What happens if you try to run a small job using a GATK Spark JAR built from master? Do you get the same error?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299503397:245,error,error,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299503397,1,['error'],['error']
Availability,"@frank-y-liu Something has gone slightly wrong in this branch git-wise -- it looks like you've duplicated some commits from master, and the merge commits in your history imply that your git workflow needs some tweaking. In general, you want to always `rebase` rather than `merge` or `pull` (and avoid mixing the two, which can cause problems), since `rebase` produces a much cleaner history. Since you're working in a fork, you should create an ""upstream"" remote if you haven't already:. `git remote add upstream https://github.com/broadinstitute/gatk.git`. Then when you're working in a branch to which you've made one or more commits, and you want to update your branch with the latest changes from our master, do this:. `git fetch upstream`; `git rebase -i upstream/master`. This will bring up a screen allowing you to ""squash"" (combine) your work into a single commit that is suitable for merging into our master branch. If you do this with the current version of your branch, and select ""squash"" for all but the top commit, I believe you'll succeed in repairing your git history. . Note that after each `rebase`, when you want to push your changes to github you'll need to do a `git push -f` instead of a simple `git push`, since `rebase` changes your commit history. Try it out and let me know how it goes!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1776#issuecomment-215474210:1057,repair,repairing,1057,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1776#issuecomment-215474210,1,['repair'],['repairing']
Availability,"@frank-y-liu Yes, I think it's not only fragile, but the direct cause of the error you're seeing. @davidbenjamin has agreed to attempt a refactor of the class when he has some free time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422444261:77,error,error,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422444261,1,['error'],['error']
Availability,"@freeseek This is a regrettable but temporary regression done for the sake of making Mutect2 much more principled ultimately. Let me try to explain with a timeline. * ~6 months ago: Mutect2 throws away one read whenever mates overlap. This reduces sensitivity unnecessarily, especially for indels, and messes up several annotations, although it does make the ADs come out right.; * ~3 months ago: we no longer throw out reads, and instead modify base and indel quals of overlapping mates to account for the possibility of PCR error. This improves sensitivity and strand, orientation, and position annotations, but it *is* a genuine regression in AD.; * [in 2nd round of code review, probably merged in a week]: Mutect2's `ReadLikelihoods` matrix forces mates to support the same haplotype and the entire likelihood framework is rewritten to allow pairs (or indeed, arbitrary groups of reads) as the atomic unit of data.; * [next step, 1 - 2 months?]: rewrite the annotations engine to accept read likelihoods for some annotations and pair likelihoods for others (such as AD).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-524138917:526,error,error,526,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-524138917,1,['error'],['error']
Availability,"@gaze-abyss Can you check your `.table` input files to see whether they have a header that looks like this:. ```; #<METADATA>SAMPLE=sample; contig position ref_count alt_count other_alt_count allele_frequency; ```. The error message indicates that the tool is not finding the ""contig"" column for some reason, and a malformed header line is one possiblity.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7707#issuecomment-1061039784:219,error,error,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7707#issuecomment-1061039784,1,['error'],['error']
Availability,@gbggrant Could I have a path for the bam and a minimal command line to reproduce the error?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625615496:86,error,error,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625615496,1,['error'],['error']
Availability,"@gbrandt6 While you're at it, would you mind asking the user to try running with GATK 4.1.6.0, and reporting back as to whether the same error occurs? The annotation changes for the MT pipeline were released in version 4.1.7.0, so this would help narrow things down a bit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-697887353:137,error,error,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-697887353,2,"['down', 'error']","['down', 'error']"
Availability,"@gevro Could you try running with the latest GATK master branch, and report whether the error still occurs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781707223:88,error,error,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781707223,1,['error'],['error']
Availability,"@gevro There is a docker image snapshot of the latest master available in the [broadinstitute/gatk-nightly](https://hub.docker.com/r/broadinstitute/gatk-nightly) repository on dockerhub. The latest snapshot is `broadinstitute/gatk-nightly:2021-02-18-4.1.9.0-68-gae06fb734-NIGHTLY-SNAPSHOT`. Even though you found a workaround, it would be helpful for us to know whether this issue is resolved by the newer GKL version included in master. I agree that the tool should allow the Java SmithWaterman implementation to be selected via an argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782236482:61,avail,available,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782236482,1,['avail'],['available']
Availability,@gmagoon I agree that it does look a lot like an off-by-one error. The genotype validator is complaining about seeing a reference allele that just happens to be the same as the previous VC. . @cwhelan can you take a look when you get a chance?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336#issuecomment-431855929:60,error,error,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336#issuecomment-431855929,1,['error'],['error']
Availability,"@gmagoon You're right to raise the issue. The tricky thing about it is that overlapping mates' bases *are* independent evidence as far as sequencing error is concerned, but are not independent as far as PCR error is concerned, so there are reasons to use fragments as the fundamental unit, but also reasons to use reads. This is why a quick fix is probably not going to be satisfactory. A few of us are thinking about something principled. Suggestions are welcome, of course!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-443552901:149,error,error,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-443552901,2,['error'],['error']
Availability,@gokalpcelik The same error occurs when working with HaplotypeCaller results.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7147#issuecomment-1755411995:22,error,error,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7147#issuecomment-1755411995,1,['error'],['error']
Availability,"@gokalpcelik This isn't an insane request, but it's probably not going to happen very quickly. . I don't think it's a trivial change to just exclude log4j, we'd need a compatible replacement or you'd end up with crashes in weird places when a transitive dependency tries to log with it. We can (and might) do it, but it's not super high priority at the moment. I think there's internal interest in changing out the logger but at the moment our strategy is to patch to the newest version as they become available. . That said, if you find a way to build a log4j free version without weird issues please let us know :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7626#issuecomment-1005810220:502,avail,available,502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7626#issuecomment-1005810220,1,['avail'],['available']
Availability,"@gspowley Can you take a look? This problem started happening with https://github.com/broadinstitute/gatk/commit/dfa9cf1a420490285b7be7917082222a07e2b042. I can pretty reliably move back to the previous commit and it goes away. It always surfaces in the VariantSparkSinkUnitTests, but it seems to be the result of a cumulative effect since AFAICT it only happens when running the full test suite via ""./gradlew clean test"". I tried changing the default values of useJdkInflater and useJdkDeflater to true, and I still get the same problem. Interestingly, disabling all of the tests in IntelInflaterDeflaterIntegrationTest seems to reliably fix it (even with useJdkInflater/Deflater set to false), so I'd start there. If thats the culprit, it might explain why we don't see this in travis since we run the unit tests and integration tests separately there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288098956:168,reliab,reliably,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288098956,2,['reliab'],['reliably']
Availability,"@gspowley I have neglected this for a while, to say the least. Here is a command line using publicly available data with paths on the Broad servers. Everyone at the Broad has read access to these files, FWIW. What should I do with the data?. ```bash; wgs_intervals=/seq/references/Homo_sapiens_assembly19/v1/variant_calling/wgs_calling_regions.v1.interval_list; hg19=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta; tumor_bam=/dsde/working/davidben/dream/synthetic/original_bams_symlinks/tumor_4.bam; tumor_sample=synthetic.challenge.set4.tumour; normal_bam=/dsde/working/davidben/dream/synthetic/original_bams_symlinks/normal_4.bam; normal_sample=synthetic.challenge.set4.normal; java -jar $gatk Mutect2 \; -R $hg19 \; -L $wgs_intervals \; -I $tumor_bam -tumor $tumor_sample \; -I $normal_bam -normal $normal_sample \; -O output.vcf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2562#issuecomment-307436212:101,avail,available,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2562#issuecomment-307436212,1,['avail'],['available']
Availability,"@gspowley That seems to do it (I also needed to use the GKL snapshot library, otherwise I see the malloc bug more frequently), but I was able to run the whole test suite on both of my laptops as long as I have both fixes. We are propagating that DEBUG log level setting to kryo, which was printing out [tons](https://github.com/EsotericSoftware/kryo/blob/f3700c49cad803f8e1782c07737197e425b1b229/src/com/esotericsoftware/kryo/Kryo.java#L675) of DEBUG output, eventually resulting in the OOM error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-290990465:491,error,error,491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-290990465,1,['error'],['error']
Availability,@gspowley can you review and/or delegate to Eric and Lucy?. I confirmed the speedup on MarkDuplicatesSpark - from 9:23 down to 8:54 seconds,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1874:119,down,down,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1874,1,['down'],['down']
Availability,"@guandailu This error implies that something happened to the output file during the run -- was it moved during the run, or was the containing directory renamed? Can you replicate this error if you run again with the latest release (4.2.0.0).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7091#issuecomment-783624632:16,error,error,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7091#issuecomment-783624632,2,['error'],['error']
Availability,"@gudeqing I think you are referrring to the calls to `GetPileupSummaries`, where we have both `-L` and `-V` arguments with the same variable. This is actually not redundant, though I admit it is clumsy. This is a consequence of `GetPileupSummaries` being written as a GATK `LocusWalker`, which is necessary for optimal performance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7731#issuecomment-1154211085:163,redundant,redundant,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7731#issuecomment-1154211085,1,['redundant'],['redundant']
Availability,"@gudeqing Thanks for reporting. `GatherBamFiles` is a bit of a tricky tool and it's easy to do the wrong thing with it accidentally. It's possible that there's an error in either how it was run or the input files but you definitely also could have discovered a bug. Samtools indexing it correctly would be point towards a bug, but I'd like you to check a few things first to be sure. . GatherBamFiles is dumb and just concatenates bam files so it's very picky about inputs. If the bam files in the input are not disjoint or they are specified out of order than `GatherBamFiles` will produce an invalid output which might manifest in indexing errors. It's also possible that the header specified didn't include all the contigs present in the collection of bams which could have a similar error result. Could you run ValidateSamFile on the result and report back what it says? If the file is out of order in some way or the header doesn't match it should report that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6379#issuecomment-575680528:163,error,error,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6379#issuecomment-575680528,3,['error'],"['error', 'errors']"
Availability,@gudeqing We encountered what might be the same error while developing the Mutect2 pipeline. Our solution was to sort the gathered bam file before indexing. For example:. ```; gatk GatherBamFiles -I bam1.bam -I bam2.bam -O unsorted.bam -R ref.fasta; gatk SortSam -I unsorted.bam -O sorted.bam \; --SORT_ORDER coordinate -VALIDATION_STRINGENCY LENIENT; gatk BuildBamIndex -I sorted.bam -VALIDATION_STRINGENCY LENIENT; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6379#issuecomment-577964985:48,error,error,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6379#issuecomment-577964985,1,['error'],['error']
Availability,"@gudeqing if you're getting a similar error, go ahead and post on the [GATK forum](https://gatk.broadinstitute.org/hc/en-us/community/topics) so we can help you there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963#issuecomment-1208507227:38,error,error,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963#issuecomment-1208507227,1,['error'],['error']
Availability,@guoyuh Please try the most recent GATK release. If the error persists we will debug.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6248#issuecomment-572161269:56,error,error,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6248#issuecomment-572161269,1,['error'],['error']
Availability,"@haileypfox This PR has test failures in `FuncotatorIntegrationTest` -- you can inspect these failures in the logs linked in the most recent comment from ""gatk-bot"" above. These will have to be resolved before we can merge this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-881612419:29,failure,failures,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-881612419,2,['failure'],['failures']
Availability,@haileypfox You have a failing test in `FuncotatorIntegrationTest` -- see the test logs in the `gatk-bot` comment above:. https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34997.12/tests/test/index.html; https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34997.2/tests/test/index.html. Can you fix this test failure before I re-review?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-882812134:353,failure,failure,353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-882812134,1,['failure'],['failure']
Availability,"@heliac2000 Thanks for the trace. I suspect that once the timeout initially occurs, the GATK process terminates, but the Python process is still trying to write back to it and gets the ""broken pipe"" return code. We already have plan to make the IPC/timeout more robust. In the meantime it would be interesting to see the last 50-100 lines of the journal file if it contains contains anything other than the repeated `Sending: [vqsr_cnn.score_and_write_batch(args, model, tempFile, fifoFile, 2, 2, '')` lines (which are expected).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4696#issuecomment-384300005:262,robust,robust,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4696#issuecomment-384300005,1,['robust'],['robust']
Availability,@heuermh Thanks for the info! I updated from adam-core_2.10 -> adam-core_2.11 but I didn't realize we needed to change to adam-core2_2.11. I'll open a new patch. Our tests for adam interop are pretty thin so we must have just not hit whatever errors are lurking out there yet.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-261066471:243,error,errors,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-261066471,1,['error'],['errors']
Availability,"@heuermh Thanks for your input, we'll look into those options. I think the use case most of us are imagining is for narrow tables with ~1M-1B records or fewer (sometimes far fewer). For the CNV pipeline, Tribble support is a much higher priority than Hadoop integration, efficient compression, etc., and it's very unlikely we'll need to do out-of-core computations that won't be enabled by Tribble. However, that might not be true of more general use cases, so it's certainly worth investigating more robust formats. @SHuang-Broad For all current CNV use cases, we use separate columns for each annotation. Not sure how much VCF code actually needs to be shared if all we care about is extracting parsing and Tribble indexing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481408414:501,robust,robust,501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481408414,1,['robust'],['robust']
Availability,"@hliang , the suggestion by @mwalker174 might be your solution. ; Note that those log4j errors are known and is on our radar to be fixed(it won't prevent real work being done in my experience, just annoying).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362505:88,error,errors,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362505,1,['error'],['errors']
Availability,"@hliang I see that many of the tasks are failing and it looks like one of the executors crashed. To find the cause, you can check the error logs of these tasks through the web UI. I suspect increasing executor memory will fix the problem. Heartbeat timeouts usually occur when an executor JVM runs out of memory or requests more memory than the node will allow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313197140:134,error,error,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313197140,2,"['Heartbeat', 'error']","['Heartbeat', 'error']"
Availability,@hliu2016 and @DeadlyDoll . Can you please share a problematic subset of the bam so we can recreate this error on our end. Also please post the version of GATK you are using.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-582151637:105,error,error,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-582151637,1,['error'],['error']
Availability,@hurrialice I'm having trouble reproducing this error. What commands are you using for `Mutect2` and `FilterMutectCalls`?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6170#issuecomment-535166745:48,error,error,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6170#issuecomment-535166745,1,['error'],['error']
Availability,@iAMSe What's the error? `Shutting down engine` is a normal message that shows up in normal runs. Is it producing output that seems correct?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8204#issuecomment-1432199784:18,error,error,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8204#issuecomment-1432199784,2,"['down', 'error']","['down', 'error']"
Availability,"@igordot Could you provide your command line? Also, could you check whether the error persists when you use a panel of normals, or nothing at all, instead of the unmatched normal?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478076231:80,error,error,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478076231,1,['error'],['error']
Availability,"@igordot I have not yet succeeded in reproducing the error with the few hg38 samples I have tested (2) and nothing obvious showed up in various `grep` regexes of our hg38 gnomAD (1). I am starting to think that we actually have solved all the hg38 issues and this is unrelated to my initial guess. If you can share your unfiltered vcf input it would be very helpful, but if that's not possible could you post the contents of your `contamination-table` input? I have a hunch that the small size of the panel is causing `CalculateContamination` to give an unreliable result. For targeted panels we recommend running Mutect2 without CalculateContamination. If you're running from Terra/Firecloud or from the wdl, this means leaving the optional `variants_for_contamination` input empty.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478444912:53,error,error,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478444912,1,['error'],['error']
Availability,"@igordot Thanks very much for following up on this. Just to clarify, are you saying that the 1/NaN contamination occurs when you run `GetPileupSummaries` on both the tumor and a non-matched normal and then run `CalculateContamination` using both of these outputs? If so, that will definitely cause problems. Running `CalculateContamination` on just the tumor output from `GetPileupSummaries` should work much better. We went to great lengths to make `CalculateContamination` work in tumor-only mode, although I would still be wary if your target territory is less than a few megabases. Also, I would not recommend using a non-matched normal *anywhere* in `Mutect2`. Unless your panel has unique technical artifacts that don't resemble those in an exome I would recommend you run tumor-only mode but use use of the publicly-available panels of normals in the GATK bucket. A worse alternative but in my opinion still better than a non-matched normal would be to run Mutect2 in tumor-only mode *separately* on the tumor samples and the unmatched normal, then use the unmatched normal vcf as a blacklist for the tumor calls with `SelectVariants`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-479345686:823,avail,available,823,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-479345686,1,['avail'],['available']
Availability,"@ilyasoifer Looks like this user got tricked by some of the flow based annotations that don't work on their data. I would like to cut down on the risk that this happens for users. If we had more foresight I would advocate renaming all of the flow specific annotations to something like ""flowbased_#####"". How destructive would this be for your pipelines? . We have some appropriate checks in GATK for the flow-ness of the bam that give warnings more broadly about flow-based mode but we don't currently have any safeguards in the annotations. Thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8788#issuecomment-2073082102:134,down,down,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8788#issuecomment-2073082102,1,['down'],['down']
Availability,@itaibeno @droazen PR #7003 greatly improves the error bars estimate when the contamination is small or zero. I think that it addresses all the concerns mentioned above. It just needs a review. . .,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-832357420:49,error,error,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-832357420,1,['error'],['error']
Availability,"@jamesemery @bhanugandham Since the initial error was in the codepath that's reading from the reference fasta, I think we need a copy of the reference being used (+ accompanying indices) to see if we can reproduce this error on our end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-572229866:44,error,error,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-572229866,2,['error'],['error']
Availability,"@jamesemery Back to you, at long last. I adopted your suggestion of a proper search that doesn't revisit already-seen vertices and came up with a better way of seeding the ""good"" subgraph that is safe from your STR concern. As far as code is concerned it's a total rewrite  you can pretend the first PR commit doesn't exist. The new criterion for seeding the search is chains with good log odds on both ends and which are incident on a vertex with multiple good out-edges or multiple good in-edges. The rationale is that the adjacency of two bad edges may have good log odds (Suppose a bad edge comes in and two bad edges come out. One is a new error on top of the original error and one is the continuation of the original error) but two have two outgoing edges with good log odds requires an actual real variant. On our M2 validations this essentially no effect on sensitivity and a mild reduction in false positives. I will leave it to you (or to me when I don't have to work like a vampire) to investigate how well it interacts with junction trees. As a first step I wrote a basic unit test for the basic pathology of the old method.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6520#issuecomment-624265441:646,error,error,646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6520#issuecomment-624265441,3,['error'],['error']
Availability,"@jamesemery Can we instrument the `HaplotypeCaller` to dump additional info to its log that would help us narrow this down? Such as the number of reads in each region, etc.?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6105#issuecomment-528986200:118,down,down,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6105#issuecomment-528986200,1,['down'],['down']
Availability,"@jamesemery Could you review this? I think you may appreciate it. It took several tries, but I was finally able to write a stripped-down version of the code that actually slightly outperforms the old version. What I realized after a lot of profiling the old code and various failed rewrites was that cache-friendliness is the critical thing here. It turns out that this can be achieved without too many buffers, without precomputing the log frequencies, and without storing 2D and 3D arrays as flattened 1D arrays.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351:132,down,down,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351,1,['down'],['down']
Availability,"@jamesemery Here is the bug fix. It's working on a lot of bams. It all comes down to keeping anything ref-consuming in an alt haplotype's cigar, even leading/trailing deletions. My mistake earlier was to treat haplotype cigars like read cigars.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6544:77,down,down,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6544,1,['down'],['down']
Availability,"@jamesemery Hey James. Is it possible to add an error message stating that the user needs to set --TMP_DIR to a bigger disk? Another user posted ""It would be nice some warning about low disk space instead of crashing after running for so many hours.""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4487#issuecomment-398159225:48,error,error,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4487#issuecomment-398159225,1,['error'],['error']
Availability,"@jamesemery How ""future-proof"" is this PR? That is, how likely is it that future releases of Gencode will break the parser again? Has the parser been relaxed to the point where it will tolerate the addition of new fields, etc.?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8351#issuecomment-1581265687:185,toler,tolerate,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8351#issuecomment-1581265687,1,['toler'],['tolerate']
Availability,@jamesemery I reverted the two breaking changes in 2 separate commits so we should see a pair of comments coming down the line.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550469073:113,down,down,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550469073,1,['down'],['down']
Availability,@jamesemery I was unable to test out this fix due to repeatedly encountering a (seemingly) unrelated git lfs error:. ```; Git LFS: (0 of 104 files) 0 B / 1.28 GB ; batch request: Host key verification failed.: exit status 255; batch request: Host key verification failed.: exit status 255; error: failed to fetch some objects from 'https://github.com/broadinstitute/gatk.git/info/lfs'; ```. I'll attempt to test this branch again in January prior to the next GATK release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6883#issuecomment-733954722:109,error,error,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6883#issuecomment-733954722,2,['error'],['error']
Availability,@jamesemery Looks like there is a test failure in this PR now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4674#issuecomment-388402050:39,failure,failure,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4674#issuecomment-388402050,1,['failure'],['failure']
Availability,@jamesemery Pinging you on this one -- do you want to get this in for the 4.1 release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5469#issuecomment-454945628:12,Ping,Pinging,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5469#issuecomment-454945628,1,['Ping'],['Pinging']
Availability,@jamesemery Some test failures here https://storage.googleapis.com/hellbender-test-logs/build_reports/master_16064.3/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217:22,failure,failures,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217,1,['failure'],['failures']
Availability,@jamesemery Still some test failures https://storage.googleapis.com/hellbender-test-logs/build_reports/master_19811.2/tests/test/classes/org.broadinstitute.hellbender.tools.spark.validation.CompareDuplicatesSparkIntegrationTest.html#testOutputFile,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4894#issuecomment-397343622:28,failure,failures,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4894#issuecomment-397343622,1,['failure'],['failures']
Availability,"@jamesemery The fun begins. No change in output yet, but a non-trivial change in implementation. Instead of making preliminary event groups according to overlap, then merging them according to mutually excluded events, this PR does it all in one step while automatically handling transitivity by treating as a matter of finding connected components of a graph whose vertices are events and whose edges are reasons (overlap and mutex) for events to be in the same event group. All the failures are from WDL tests. I assume those are not related.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8366:484,failure,failures,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8366,1,['failure'],['failures']
Availability,@jamesemery There appear to be some lingering test failures here after the rebase (mismatches between actual and expected VCF files).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601852368:51,failure,failures,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601852368,1,['failure'],['failures']
Availability,@jamesemery This is failing with a compiler error:. ```; error: package org.testng.annotations does not exist; import org.testng.annotations.Test; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841:44,error,error,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841,2,['error'],['error']
Availability,@jamesemery This needs to be rebased I think and it has some compilation error I think.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-457744794:73,error,error,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-457744794,1,['error'],['error']
Availability,@jamesemery We have test failures again https://storage.googleapis.com/hellbender-test-logs/build_reports/master_19079.2/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4750#issuecomment-388422469:25,failure,failures,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4750#issuecomment-388422469,1,['failure'],['failures']
Availability,"@jamesemery While you're in the `HaplotypeCallerEngine` doing optimizations, you should profile peak memory usage as well and see if we can get it down to < 3 GB. This would reduce costs by allowing us to use cheaper instances on the cloud.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2591#issuecomment-460407699:147,down,down,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2591#issuecomment-460407699,1,['down'],['down']
Availability,@jamesemery Would you mind taking a look at this bit of code maintenance?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5745#issuecomment-473953843:61,mainten,maintenance,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5745#issuecomment-473953843,1,['mainten'],['maintenance']
Availability,"@jamesemery You are right. I tried combineGVCFs first and it produced the java.lang.ArrayIndexOutOfBoundsException. I then tried the GenotypeGVCFs from GenomicsDBImport and got the same error again. I think I have since found out I did not index two of the g.vcf files and added those. When I tried it again, combineGVCFs works but GenotypeGVCFs on GenomicsDBImport still fail with the java.lang.ArrayIndexOutOfBoundsException error. GenotypeGVCFs worked on all other chromosomes, just not on chr7 in this case. I will generate a snippet for #6357",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-572158949:186,error,error,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-572158949,2,['error'],['error']
Availability,@jamesemery You have a compiler error on the latest version of this branch:. ```; :compileJava/home/travis/build/broadinstitute/gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:428: error: ';' expected; final int priorsListSize = priorList.size(); ^; 1 error; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461928409:32,error,error,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461928409,3,['error'],['error']
Availability,"@jamesemery and @droazen thank you for reviewing. @jamesemery I have enabled `GenomicsDBImportIntegrationTest.testGenomicsDBAlleleSpecificAnnotations()` and this test is passing. Is anything else required?. @droazen I incremented the GenomicsDB release that incorporates a fix for resizing LUTs when dealing with spanning deletions - this was a single line change in GenomicsDB that should fall under the umbrella of enabling allele-specific annotation support [3707](https://github.com/broadinstitute/gatk/issues/3707). This updated jar has been uploaded, but isn't available on Maven yet (it should be within the next hour). I agree that additional tests should be added for the bugs that this PR addresses. I'll plan on adding tests for the two high priority fixes ([4160](https://github.com/broadinstitute/gatk/issues/4160) and [3736](https://github.com/broadinstitute/gatk/issues/3736)) this afternoon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092:567,avail,available,567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092,1,['avail'],['available']
Availability,@jamesemery are these test failures expected/known? They seem unrelated to this PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8347#issuecomment-1609714705:27,failure,failures,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8347#issuecomment-1609714705,1,['failure'],['failures']
Availability,"@jamesemery sorry to bug on this topic, but I'm hoping to make a push early this year to fully migrate my lab off GATK3 . I looked more closely at the specific annotations we need to migrate. I decided that I will implement our walker, 'DiscvrVariantAnnotator', which is basically a light wrapper around VariantAnnotation. This will make it easier to spike in custom annotations. In that walker, I will override makeVariantAnnotations(). I will make a new marker interface for EngineAwareAnnotation, and test that on all the Annotation classes, and use this to inject FeatureManager. So no core GATK changes needed. I did find one thing I'd like to propose. You probably know PedigreeAnnotation is special-cased in GATK. Annotations that use it have automatic argument validation and have the SampleDB injected. Currently, PedigreeAnnotation is a subclass of InfoFieldAnnotation, so isnt available to GenotypeAnnotations. There doesnt appear to be a solid reason why. I tried to fix that and my best idea is the proposal here: #7041 . The core idea is to convert InfoFieldAnnotation and GenotypeAnnotation to interfaces. This is generally a trivial switch in existing code. With that, it becomes possible for classes that currently extend PedigreeAnnotation (which I switched to no longer extend InfoFieldAnnotation) to simply PedigreeAnnotation and implement InfoFieldAnnotation. This makes it possible for future classes to extend PedigreeAnnotation and implement GenotypeAnnotation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063:888,avail,available,888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063,2,['avail'],['available']
Availability,"@jamesemery the use of padding is a little confusing. One use of padding is for providing extra reference bases around the reads. This is the case in `ReadWalkerSpark`, for example. When the whole reference is available via the Spark files mechanism (which is what this PR is about) then there is no need for padding (and in the case of `ReadWalkerSpark`, no need for sharding at all). Therefore it makes sense to remove the use of padding in these cases. Another use of padding was for providing more reads around an area of interest in assembly region/haplotype caller tools. This is no longer the case though, since the refactoring that @droazen did in `HaplotypeCaller` in #4031. However, `HaplotypeCallerSpark` has not been updated to reflect the changes from that refactoring, so it's probably best not to change the padding in that class. I've reverted the change there for this reason. The locus walkers never had any need for padding, except for padding reference bases in `LocusWalkerSpark`, mentioned above. I've added a comment in the code to clarify this. Hopefully that makes more sense now. Please let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426274932:210,avail,available,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426274932,1,['avail'],['available']
Availability,"@jamesemery, thanks for kicking off tests. the compile failure is probably due to a bad merge. I pushed a fix - would you be able to restart tests?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8871#issuecomment-2189263528:55,failure,failure,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8871#issuecomment-2189263528,1,['failure'],['failure']
Availability,@jason-weirather I see the error in the config file - this is definitely a bug in the data source release. There will need to be another data sources release to fix this and another data sources bug. I expect that this will be released by end of week. I will run through some additional tests on hg38 data to see if I can duplicate the null pointer exception.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798:27,error,error,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798,1,['error'],['error']
Availability,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:108,error,error,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016,3,"['down', 'error']","['down', 'error', 'errors']"
Availability,"@jason-weirather OK, I found the problem. It was _another_ issue with the data sources. I've fixed it in my local copy - we'll have to release another version tomorrow. I have also made a few logging upgrades so you'll get more information about errors. I'm opening the PR for this now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375469404:246,error,errors,246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375469404,1,['error'],['errors']
Availability,"@jason-weirather There is a new set of data sources available in the data sources area (v1.1). I still haven't tested very thoroughly, but it should have all required files for hg38. I'm planning to test this further later this week / early next week.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375059321:52,avail,available,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375059321,1,['avail'],['available']
Availability,@jaspez Thank you for your bug-report here. As it turns out it was an error in documentation to include the gene_statistics file in the labeled outputs since the original gatk3 tool never produced the `_gene_statistics` style files in the first place and that behavior was replicated in the gatk4 version of the tool. I can add that functionality into gatk4 but given the changes to how overlapping genes are handled in gatk4 compared to gatk3 it seems like it should be a less useful file output. How useful is the the question (what # of genes in this list have at least x coverage?) Either way I will make a PR to add this functionality and we can decide if its worthwhile there.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6714#issuecomment-754907032:70,error,error,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6714#issuecomment-754907032,1,['error'],['error']
Availability,@jberghout If you post your actual output we might be able to track down your variant of the problem (the error message in the original post looks to me somewhat like a corrupt gradle cache: error reading /vsc-hard-mounts/leuven-user/304/vsc30484/.gradle/caches/modules-2/files-2.1/org.spire-math/spire_2.11/0.11.0/998b1c1d841baf4fc5d1b119ea55f165f6684ef5/spire_2.11-0.11.0.jar; error in opening zip file). Is it the `gatkTabComplete` task that is failing for you as well ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345:68,down,down,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345,4,"['down', 'error']","['down', 'error']"
Availability,"@jean-philippe-martin @Horneth informs me that if he runs with cloud buffering turned off completely, all of these errors go away. However, it takes twice as long to complete, as might be expected :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300817391:115,error,errors,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300817391,1,['error'],['errors']
Availability,"@jean-philippe-martin Agree that we probably shouldn't refactor `IntegrationTest` as part of this PR, but it looks like some other tests are failing now. The PR build failures are [here](https://travis-ci.com/broadinstitute/gatk/builds/97887212). There are some CRAN mirror problems that are affecting all builds at the moment, but there are also some failures that are fallout from the `IntegrationTest` changes. See [this](https://travis-ci.com/broadinstitute/gatk/jobs/171535202). The previous (`XReadLines`) code was gzip aware, but the new code is not, which is causing the test failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456645889:167,failure,failures,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456645889,3,['failure'],['failures']
Availability,@jean-philippe-martin Any thoughts on how this one is possible? I'm assuming it was some sort of network error because it's transient.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2686#issuecomment-300265178:105,error,error,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2686#issuecomment-300265178,1,['error'],['error']
Availability,"@jean-philippe-martin Can you comment on this error with your thoughts? Despite now doing a channel reopen on `UnknownHostException` in our fork of the NIO library, all reopens are failing, which implies that this error can't be recovered from via a simple retry. Could there be something wrong in our authentication setup?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412906931:46,error,error,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412906931,6,"['error', 'recover']","['error', 'recovered']"
Availability,"@jean-philippe-martin Can you comment on this one? It looks like `google-cloud-java` recently bumped their `google-auth-library-credentials` and `google-auth-library-oauth2-http` dependencies to `0.8.0` -- was there some change that would require us to modify our authentication-related code in GATK, and/or the permissions setup in our Google Cloud project, that could explain the error:. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001:382,error,error,382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001,2,"['Error', 'error']","['Error', 'error']"
Availability,"@jean-philippe-martin Do you know what google service is responsible for this? It sounds like a bug that should be fixed on google's end if it's misreporting errors. It's also strange that it just started happening, possibly just recently introduced.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735#issuecomment-339027561:158,error,errors,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735#issuecomment-339027561,1,['error'],['errors']
Availability,"@jean-philippe-martin Given that we've finally resolved our intermittent GCS failures at scale, do you think it's still valuable to keep this around, or should this PR be closed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-330331684:77,failure,failures,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-330331684,1,['failure'],['failures']
Availability,"@jean-philippe-martin I can see the shaded Jar in the following repository:. https://oss.sonatype.org/#nexus-search;quick~gcloud-java-nio. You can download it from the following link for the 0.2.7 version:. https://oss.sonatype.org/service/local/repositories/snapshots/content/com/google/cloud/gcloud-java-nio/0.2.7-SNAPSHOT/gcloud-java-nio-0.2.7-20160722.195539-2-shaded.jar. And in Maven Central is provided as a link for all the versions here under **shaded.jar**:. http://search.maven.org/#search%7Cgav%7C1%7Cg%3A%22com.google.cloud%22%20AND%20a%3A%22gcloud-java-nio%22. The direct link for the 2.6 version:. https://repo1.maven.org/maven2/com/google/cloud/gcloud-java-nio/0.2.6/gcloud-java-nio-0.2.6-shaded.jar. The Maven directory for `gcloud-java-nio` - containing all the versions - is at the following link:. https://repo1.maven.org/maven2/com/google/cloud/gcloud-java-nio/. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2044#issuecomment-235088767:147,down,download,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2044#issuecomment-235088767,1,['down'],['download']
Availability,"@jean-philippe-martin I get the following error when trying to use the shaded google-cloud-java snapshot jar:. ```; /Users/droazen/.m2/repository/com/google/cloud/google-cloud-nio/0.20.2-alpha-SNAPSHOT/google-cloud-nio-0.20.2-alpha-SNAPSHOT-shaded.jar(com/google/cloud/storage/contrib/nio/CloudStorageFileSystemProvider.class): ; warning: Cannot find annotation method 'value()' in type 'AutoService': ; class file for com.google.auto.service.AutoService not found; ```. Checking the jar, `AutoService` is indeed not present, but is an annotation on `CloudStorageFileSystemProvider`. Any thoughts on what could be causing this? Shading error?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314260186:42,error,error,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314260186,2,['error'],['error']
Availability,"@jean-philippe-martin I had assumed that there were already CRAM tests in ReadUtilsUnitTest for the old createSAMWriter method, but there aren't (there are integration tests that exercise the cram code path through PrintReadsIntegrationTest.) In general you have to just know which reference goes with which cram. The canonical file we use is print_reads.cram/print_reads.fasta (in the tools test folder). You should probably copy them into the ReadUtils test folder to use it in those tests. If you do,you'll have to also copy print_reads.fasta.fai, or you'll get misleading CRAM errors. Also note that you won't be able to use iterator comparison when comparing an Iterator<CRAMRecord> with Iterator<BAMRecord>.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332212832:581,error,errors,581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332212832,1,['error'],['errors']
Availability,"@jean-philippe-martin In our initial tests with the latest gatk, we're still getting errors like this at a rate of ~2%:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; java.lang.IllegalArgumentException: A project ID is required for this service but could not be determined from the builder or the environment. Please set a project ID using the builder.; com.google.cloud.storage.StorageException: 503 Service Unavailable; com.google.cloud.storage.StorageException: 503 Service Unavailable; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; com.google.cloud.storage.StorageException: 503 Service Unavailable; com.google.cloud.storage.StorageException: 503 Service Unavailable; com.google.cloud.storage.StorageException: 503 Service Unavailable; com.google.cloud.storage.StorageException: 503 Service Unavailable; com.google.cloud.storage.StorageException: 503 Service Unavailable; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Remote host closed connection during handshake, for input source:; ```. Now, I know that you put in an explicit retry for 503's, so I'm wondering what could be going on. I've asked the person running the tests to check that they're using an up-to-date GATK jar, but I'm wondering if we're setting all the right retry options on the GATK side. Eg., your PR https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2083 says ""but only when OptionMaxChannelReopens is set"" -- are we setting this properly? Any other thoughts on things we could try?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-306944607:85,error,errors,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-306944607,2,['error'],"['error', 'errors']"
Availability,"@jean-philippe-martin Is this good to go, or are you still seeing failures with this version?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-279769506:66,failure,failures,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-279769506,1,['failure'],['failures']
Availability,"@jean-philippe-martin Mind prioritizing this one? We are building a custom snapshot of `google-cloud-java` with `maxChannelReopens` hardcoded to the value we want, which should resolve https://github.com/broadinstitute/gatk/issues/2685 for now, but it would be great to have a permanent solution in master. Requiring GATK to construct Path objects a certain way and pass them down into libraries like htsjdk is just too brittle, as those libraries often need to create Path objects on-the-fly and we lose our settings. Ideally we'd just be able to call a static method (or similar) at GATK startup to force all instances of `CloudStorageReadChannel` to use our desired settings.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3120#issuecomment-309128063:376,down,down,376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3120#issuecomment-309128063,1,['down'],['down']
Availability,"@jean-philippe-martin Sorry, I originally typed ""you can't compare `Iterator<CRAMRecord>` with `Iterator<SAMRecord>`"" , but I didn't quote it, so it displays as ""you can't compare Iterator with Iterator"". Anyway, it looks like you're not doing that. Thanks for adding the CRAM tests. Rather than adding separate data providers and methods for them though, can you just change the existing providers and methods to have an output extension and a reference (null is OK), and then thread those through the test code. I made a branch of your branch with a commit [here](https://github.com/broadinstitute/gatk/commit/5e52fca813e57065713852d12f80a7599fcbc3ce) to make sure that would work - it eliminates a lot of redundant code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332381114:708,redundant,redundant,708,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332381114,1,['redundant'],['redundant']
Availability,"@jean-philippe-martin Thanks for adding the additional test, but by ""integration test"", I meant something that exercises an actual tool (which is why I mentioned SelectVariants) with a non-default provider, not another unit test that uses GCS. I suggested SelectVariants since I thought it would be easy:. > all the previous comments have been addressed with the exception of adding a SelectVariants integration test. It should be pretty easy to clone an existing case and change it use a non-default nio provider. I think this last test is redundant with the one you already added. My apologies if that was confusing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455668135:541,redundant,redundant,541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455668135,1,['redundant'],['redundant']
Availability,"@jean-philippe-martin There was another error in one build job in the travis matrix, but it looks transient, and unrelated. I restarted that build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3526#issuecomment-346370425:40,error,error,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3526#issuecomment-346370425,1,['error'],['error']
Availability,@jean-philippe-martin They moved our artifactory so there was probably a downtime where it was inaccessible. I've restarted. There's supposed to be a redirect in place from the old link so it should work.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2879#issuecomment-306267919:73,downtime,downtime,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2879#issuecomment-306267919,1,['downtime'],['downtime']
Availability,@jean-philippe-martin Thoughts on why we sometimes manage to exhaust all 20 retries with these SSL errors?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308542739:99,error,errors,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308542739,1,['error'],['errors']
Availability,@jean-philippe-martin We're seeing the same errors here as in yours pr. So it's something in the htsjdk update...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330357192:44,error,errors,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330357192,1,['error'],['errors']
Availability,@jean-philippe-martin Where are you seeing that test failure? I'm seeing the travis failures as . ```; htsjdk.samtools.SAMException: Exception when processing alignment for BAM index i 1/2 76b aligned read.; 	at htsjdk.samtools.BAMFileWriter.writeAlignment(BAMFileWriter.java:142); 	at htsjdk.samtools.SAMFileWriterImpl.addAlignment(SAMFileWriterImpl.java:201); 	at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:36); 	at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); 	at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:124); 	at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.samtools.SAMException: Exception creating BAM index for record i 1/2 76b aligned read.; 	at htsjdk.samtools.BAMIndexer.processAlignment(BAMIndexer.java:119); 	at htsjdk.samtools.BAMFileWriter.writeAlignment(BAMFileWriter.java:139); 	... 5 more; Caused by: htsjdk.samtools.SAMException: IOException in BinaryBAMIndexWriter reference 0; 	at htsjdk.samtools.BinaryBAMIndexWriter.writeReference(BinaryBAMIndexWriter.java:151); 	at htsjdk.samtools.BAMIndexer.advanceToReference(BAMIndexer.java:138); 	at htsjdk.samtools.BAMIndexer.processAlignment(BAMIndexer.java:115); 	... 6 more; Caused by: java.nio.channels.ClosedByInterruptException; 	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202); 	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:216); 	at java.nio.channels.Channels.writeFullyImpl(Channels.java:78); 	at java.nio.channels.Channels.writeFully(Channels.java:101); 	at java.nio.channels.Channels.access$000(Channels.java:61); 	at java.nio.channels.Channels$1.write(Channels.java:174); 	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82); 	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140); 	at htsjdk.samtools.BinaryBAMIndexWriter.writeReference(BinaryBAMIndexWriter.java:149); 	... 8 more; ```. One of the ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-329967977:53,failure,failure,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-329967977,2,['failure'],"['failure', 'failures']"
Availability,"@jean-philippe-martin Yeah, I was being a bit over-aggressive with the retries to maximize my chances of fixing the failures. We could make the retries conditional, and I did extract `CloudStorageRetryHandler.isRetryable()` and `CloudStorageRetryHandler.isReopenable()` methods, but are we 100% sure that in `CloudStorageFileSystemProvider` we wouldn't want to retry any of the errors that in `CloudStorageReadChannel` result in a reopen? That wasn't clear to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315471923:116,failure,failures,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315471923,4,"['error', 'failure']","['errors', 'failures']"
Availability,"@jean-philippe-martin Yeah, I'm seeing that. I suspect it's because we aren't passing the environment variables correctly to the docker tests so it's exploding with an unhelpful error during test initialization.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740:178,error,error,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740,1,['error'],['error']
Availability,"@jean-philippe-martin has added support for requester pays to gcloud. ; See https://github.com/GoogleCloudPlatform/google-cloud-java/pull/3406 . I've set up a new fork of the project at https://github.com/broadinstitute/google-cloud-java. I have a branch https://github.com/broadinstitute/google-cloud-java/tree/lb_update_pom_to_publish_to_orgbroad which I believe should make the changes necessary to run on dataproc and avoid https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2453. However, if you rollback the dependencies the project no longer compiles. You can compile the nio-subproject, but the parent project can no longer build against the old dependencies. That makes me very nervous because it seems likely that we will encounter runtime errors if we substitute them. . JP created a small test case to reproduce the error and it seems like the dataproc team is looking at it. Hopefully they can resolve the issue and we can switch to the base library instead of needing to publish an additional sketchy version of it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-404322757:514,rollback,rollback,514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-404322757,3,"['error', 'rollback']","['error', 'errors', 'rollback']"
Availability,@jean-philippe-martin pinging you on this one,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2441#issuecomment-285753432:22,ping,pinging,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2441#issuecomment-285753432,1,['ping'],['pinging']
Availability,"@jean-philippe-martin, when you have a chance could you please take a look at the stack trace above and give your thoughts? Our NIO library dependency was not upgraded between 4.0.11.0 and 4.0.12.0 (it was last upgraded in 4.0.9.0), so it's not clear what it is about 4.0.12.0 that is leading to this higher failure rate. . We've already tried a custom build of 4.0.12.0 that included the version of htsjdk from 4.0.11.0, but that didn't help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085:308,failure,failure,308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085,2,['failure'],['failure']
Availability,"@jhl667 The ref/alt coverage in an M2 vcf may differ from that of IGV for the following reasons:. * Downsampling. This one ought to occur only at extremely high depths. By default M2 downsamples to 50 reads per alignment start, so if reads are 100 bp long downsampling only kicks in at coverage of 5000 and above. Usually such large coverage indicates a poorly-mappable region, but in targeted sequencing that legitimately has such high coverage you should adjust the `-maxReadsPerAlignmentStart` argument.; * Read filters. M2 removes reads with mapping quality less than 20, which are overwhelmingly likely to be mapping errors, reads that are less than 30 bases, reads marked as duplicates etc. This filtering is done by the GATK engine before traversing the BAM and the M2 code never sees them. It would not be possible to output these in M2, but they are bad reads, anyway.; * Reassembly / realignment. Like HaplotypeCaller, M2 builds a local assembly graph and realigns reads to candidate haplotypes. This can change the allele that a read is assigned to, particularly in the case of indels near STRs or near the end of reads. However, this doesn't *lose* the original information -- it corrects it. Do you know which, if any, of these causes you had in mind? Could you provide an example?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3808#issuecomment-342923670:100,Down,Downsampling,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3808#issuecomment-342923670,4,"['Down', 'down', 'error']","['Downsampling', 'downsamples', 'downsampling', 'errors']"
Availability,"@jingydz The error message; `Feature inputs must be unique: /data/users/zhanglei/species/Medicago/result/SRR340103.HC.g.vcf.gz` says exactly what the problem is, which is that you have a duplicate input:. /data/users/zhanglei/species/Medicago/result/SRR340102.HC.g.vcf.gz --variant /data/users/zhanglei/species/Medicago/result/**SRR340103.HC.g.vcf.gz** --variant /data/users/zhanglei/species/Medicago/result/**SRR340103.HC.g.vcf.gz** --variant /data/users/zhanglei/species/Medicago/result/SRR340104.HC.g.vcf.gz --variant",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-493674150:13,error,error,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-493674150,1,['error'],['error']
Availability,"@jjfarrell . After talking with @cmnbroad this afternoon, we'd like to ask you to perform an experiment to limit the scope where hunt down the issue. Is it possible for you to run `PrintReadsSpark` on the same cluster? That is, something similar to . ```bash; gatk --java-options ""-Djava.io.tmpdir=tmp"" \; PrintReadsSpark \; -R $REF \; -I $CRAM_DIR/$SAMPLE.cram \; -O hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.cram \; -- \; --spark-runner SPARK \; --spark-master yarn \; --deploy-mode client \; --executor-memory 85G \; --driver-memory 30g \; --num-executors 40 \; --executor-cores 4 \; --conf spark.yarn.submit.waitAppCompletion=false \; --name ""$SAMPLE"" \; --conf spark.yarn.executor.memoryOverhead=5000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-495357208:134,down,down,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-495357208,2,"['down', 'heartbeat']","['down', 'heartbeatInterval']"
Availability,"@jjfarrell @cmnbroad I tracked the problem down to htsjdk, see https://github.com/samtools/htsjdk/pull/1255. What seems to be happening is that `SeekableStream#available()` is returning a negative value due to int overflow, which `ReadableByteChannelImpl` is relying on to fill its byte buffer (from `AbstractIndexedFastaSequenceFile#getSubsequenceAt`). When it gets a negative value it returns early, without filling the buffer. The end result is that the reference is not read correctly, hence the MD5 mismatch errors. The reason we haven't seen this before is that we've only tested on CRAMs with FASTA files that are less than 2GB (ones that don't cover the whole genome, or ones that are gzipped). When the file is less than 2GB there's no int overflow, so we don't see the error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624:43,down,down,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624,4,"['avail', 'down', 'error']","['available', 'down', 'error', 'errors']"
Availability,"@jjfarrell In addition to the switch to disq, GATK 4.0.12.0 also included an updated htsjdk that had CRAM changes. It would be helpful to know if CountReads (non-spark) from that same GATK version works on this file, since that would help narrow down whether its disq-related. Is it possible to run that and let us know the results ? Thx.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450884370:246,down,down,246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450884370,1,['down'],['down']
Availability,@jjfarrell Thanks for the update. This error message indicates an invalid index file - older versions of GATK/HTSJDK didn't report these. Reindexing is the correct remedy.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076#issuecomment-779851653:39,error,error,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076#issuecomment-779851653,1,['error'],['error']
Availability,"@jjfarrell That error message usually indicates that the reference supplied isn't the same (exact) same one that was used to create the cram. Can you try using `samtools view` on the same file/ref pair, and see if that works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449485244:16,error,error,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449485244,1,['error'],['error']
Availability,"@jkobject Actually, we just noticed that your error is triggered by the file `gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/5c2db926-3b1c-479c-9ed3-a99ce518de91/omics_mutect2/60955825-7723-4bc9-8202-bdd9975bb5c0/call-mutect2/Mutect2/7d737efc-c8be-4a6d-8803-4f786129521a/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list`, not the bam. Could you attempt the `gsutil` test on that file instead, and let us know what happens? Eg.,. ```; gsutil -u broad-firecloud-ccle cp gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/5c2db926-3b1c-479c-9ed3-a99ce518de91/omics_mutect2/60955825-7723-4bc9-8202-bdd9975bb5c0/call-mutect2/Mutect2/7d737efc-c8be-4a6d-8803-4f786129521a/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list .; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064482965:46,error,error,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064482965,1,['error'],['error']
Availability,"@jkobject After further testing we think the issue might be more specific: the error seems to occur only when checking for the existence of non-existent files in non-requester-pays buckets when a requester-pays project is specified. In your case, it is checking for the existence of an index for your `interval_list` file and failing, since `interval_list` files don't have indices. As another experiment, it would be helpful to know whether your `Mutect2` command succeeds if you specify a specific interval string like ""1:1000000-2000000"" (doesn't matter which interval) for the `-L` argument instead of the `interval_list` file (but keeping all other inputs the same).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1065230706:79,error,error,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1065230706,1,['error'],['error']
Availability,"@jkobject After further testing we think the issue might be more specific: the error seems to occur only when checking for the existence of non-existent files in non-requester-pays buckets when a requester-pays project is specified. In your case, it is checking for the existence of an index for your interval_list file and failing, since interval_list files don't have indices. As another experiment, it would be helpful to know whether your Mutect2 command succeeds if you specify a specific interval string like ""1:1000000-2000000"" (doesn't matter which interval) for the -L argument instead of the interval_list file (but keeping all other inputs the same).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1065238192:79,error,error,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1065238192,1,['error'],['error']
Availability,@jkobject Do you see the error without `--genotype-germline-sites` and `--genotype-pon-sites`?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1154394128:25,error,error,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1154394128,1,['error'],['error']
Availability,"@jkobject Here's an update for you on this issue, as promised: we've tested the patch in https://github.com/broadinstitute/gatk/pull/7730 extensively on both our local machines and on a clean Google Cloud VM, and found it to work perfectly with all kinds of requester pays inputs to GATK (fastas, bams, vcfs, interval_lists, etc.). We now believe that the test failures in the PR are artifacts of some configuration issue in our Travis CI test environment, and that the PR does actually fix requester pays support in GATK. We are considering merging and releasing the branch as-is, and dealing with the issues in our test suite post-release. It would make us more confident doing this if you could test the branch out as well on your end and confirm whether it works for you. You can do this using the following commands:. ```; git clone https://github.com/broadinstitute/gatk.git gatk; cd gatk; git fetch; git checkout -b lb_refix_requester_pays origin/lb_refix_requester_pays; ./gradlew clean installDist; ./gatk <a GATK command that failed for you previously>; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1079421576:361,failure,failures,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1079421576,1,['failure'],['failures']
Availability,"@jkobject Sorry, I missed when you initially tagged me here. It's strange that you had to go to 32 gb, do those shards include some extremely complicated sites or anomalously high depth? I'm not an M2 expert so it seems like a good question for David. The initial error you're seeing looks like an issue in the wdl where cromwell is trying to create a link to cromwell_root/*normal-pileups.table but for some reason there is no file with that name. In the wdl I'm looking at it says thats an expected case and shouldn't cause an error. ; https://github.com/broadinstitute/gatk/blob/7f96bf6677040851c6da3cb96d97f957f1df05bc/scripts/mutect2_wdl/mutect2.wdl#L545-L548. I wonder if there is a cromwell issue that made empty globs cause a crash.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-939057580:264,error,error,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-939057580,2,['error'],['error']
Availability,"@jkobject Thanks for testing that for us! After looking into this issue a bit more, it seems that there might be a problem in the latest Google libraries with handling the case of a non-requester-pays input when a requester-pays project is provided. In our tests, running a similar `Mutect2` command line to yours with _all_ inputs in requester pays buckets succeeds, but when we run with a mix of requester-pays and non-requester-pays inputs, or all non-requester-pays inputs, and do specify a requester pays project, we're able to replicate your error. We are looking in a debugger now to pin down the cause. Can you tell us whether running `Mutect2` with a mix of requester-pays and non-requester-pays inputs and `--gcs-project-for-requester-pays` specified succeeded for you previously? If so, with which version(s) of GATK?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064548850:548,error,error,548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064548850,2,"['down', 'error']","['down', 'error']"
Availability,"@jkobject That appears to be a different error: ""User project specified in the request is invalid"" instead of ""Bucket is a requester pays bucket but no user project provided"", which was the error this patch fixed. Can you confirm that the `broad-firecloud-ccle` project exists and is authorized under your service account? . @lbergelson Can you comment further on this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064417440:41,error,error,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064417440,2,['error'],['error']
Availability,"@jkobject We are currently testing the new `google-cloud-nio` release in https://github.com/broadinstitute/gatk/pull/7730. In that branch, we added tests for all possible combinations of requester-pays and non-requester-pays inputs, but not all of the tests are passing yet. We're still looking into the reasons for the failures -- it could be a flaw in the way the tests are set up, or it could be that the failures are real. We should have an update by end of the week.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1077813713:320,failure,failures,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1077813713,2,['failure'],['failures']
Availability,@jkobject thanks for the PR! This seems to only affect a subset of the issues you mentioned above - specifically #6345. Did this patch fix the error you're seeing in your data that you posted in #6651?. It's a good bandaid for this error case. There are some other places where a fix like this will need to be added as well. Are you able to update those areas and make some tests for this case?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1182113899:143,error,error,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1182113899,2,['error'],['error']
Availability,"@jmstover Thank you for your recommendation. I added the following line in the beginning of test.pbs. ```; source activate gatk; ```. However, running the following command still threw the same error. ; ```; singularity exec gatk.simg ./test.pbs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-433550679:194,error,error,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-433550679,1,['error'],['error']
Availability,@jmthibault79 This fails with a compiler error: . ```; :compileTestJava/home/travis/build/broadinstitute/gatk/src/test/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSinkUnitTest.java:240: error: cannot find symbol; return inferFromUncompressedData(IOUtil.isGZIPInputStream(bis) ? new GZIPInputStream(bis) : bis);; ^; symbol: method isGZIPInputStream(BufferedInputStream); location: class IOUtil; 1 error; FAILED; ```. I think you perhaps need to update the htsjdk dependency to a release that includes this change?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265:41,error,error,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265,3,['error'],['error']
Availability,"@jonn-smith - sorry for the late response, I was checking if I could find an error on my side. Currently I receive this result for an IDH2 R172 mutation. Interestingly, the dbSNP id is leading to the right variant.; ```; IDH2	3418	__UNKNOWN__	hg19	15	90631838	90631838	+	Intron	SNP	C	C	T	121913503		__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	NA	NA	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	g.chr15:90631838C>T	ENST00000559482.5_2	-			c.e6+104G>A			IDH2_ENST00000330062.8_3_Missense_Mutation_p.G323S|IDH2_ENST00000540499.2_2_Missense_Mutation_p.G323R			P48735	IDHP_HUMAN	isocitrate dehydrogenase (NADP(+)) 2, mitochondrial	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	2-oxoglutarate metabolic process (GO:0006103)|carbohydrate metabolic process (GO:0005975)|cellular metabolic process (GO:0044237)|glyoxylate cycle (GO:0006097)|isocitrate metabolic process (GO:0006102)|small molecule metabolic process (GO:0044281)|tricarboxylic acid cycle (GO:0006099)	extracellular vesicular exosome (GO:0070062)|mitochondrial inner membrane (GO:0005743)|mitochondrial matrix (GO:0005759)|mitochondrion (GO:0005739)	isocitrate dehydrogenase (NADP+) activity (GO:0004450)|magnesium ion binding (GO:0000287)|NAD binding (GO:0051287)			NS(223)|adrenal_gland(294)|autonomic_ganglia(349)|biliary_tract(876)|bone(893)|breast(1151)|central_nervous_system(11211)|cervix(20)|endometrium(22)|eye(81)|genital_tract(1)|haematopoietic_and_lymphoid_tissue(26199)|kidney(260)|large_intestine(1302)|liver(111)|lung(320)|meninges(57)|oesophagus(176)|ovary(533)|pancreas(585)|perineum(1)|peritoneum(60)|pleura(11)|prostate(172)|salivary_gland(105)|skin(644)|small_intestine(26)|soft_tissue(479)|stomach(547)|testis(11)|thymus(26)|thyroid(239)|upper_aerodigestive_tract(127)|urinary_tract(32)|vulva(66)	47210	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__		ATGGGCGTGCCTGCCAATGGT	0.5635910224438903	__",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064:77,error,error,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064,1,['error'],['error']
Availability,"@jonn-smith @LeeTL1220 @droazen Thanks for sharing the information above, and I looked at it. It seems to me that once we have a chain file for one reference and another reference, the remaining steps are straightforward. I also noticed the following Picard utility [Picard LiftoverVcf]( https://broadinstitute.github.io/picard/command-line-overview.html#LiftoverVcf ) that can Lift over a VCF file from one reference to another. ; Therefore, creating the chain file between a pair of references (and limiting ourselves to cases where both references are from the same species, mouse/human) is the key. To that end, according to the following post [List of chain file creators](https://www.biostars.org/p/65558/) most of the chain file creation tools are available as a web interface. However, the UCSC one seems to be more popular, and fortunately, they have the utilities as open source and to some degree explain their steps in the [LiverOver_Howto](http://genomewiki.ucsc.edu/index.php/LiftOver_Howto) link you sent. With this approach, they first BLAT the pairwise contigs in the reference files and then use the utility DoSameSpeciesLiftOver.pl. . Based on this, it appears to me I should think about the following steps:; a) First, try out their code (UCSC) and make sure it works to produce chain files for two references successfully.; b) Design/propose a solution putting the logic in DoSameSpeciesLiftOver.pl into GATK, which also might need a BLAT run . Let me know what you think of this or have any suggestions about how I should proceed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6837#issuecomment-804188470:755,avail,available,755,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6837#issuecomment-804188470,1,['avail'],['available']
Availability,@jonn-smith Can you make sure that the test failure is nothing to block merging?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4063#issuecomment-355789698:44,failure,failure,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4063#issuecomment-355789698,1,['failure'],['failure']
Availability,"@jonn-smith Could you comment on this one? The tool output clearly states that we don't support this version of Gencode, and that errors may occur:. ```; GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 38): ##description: evidence-based annotation of the human genome (GRCh38), version 38 (Ensembl 104), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; ```. Do we claim to support 38 anywhere? (eg., in documentation, etc.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7385#issuecomment-891227342:130,error,errors,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7385#issuecomment-891227342,4,['error'],['errors']
Availability,@jonn-smith I have downloaded the gnomADit becomes normal if i don't untar gnomAD,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5903#issuecomment-510810697:19,down,downloaded,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5903#issuecomment-510810697,1,['down'],['downloaded']
Availability,"@jonn-smith I have sucessfully built GATK by these commands. git clone https://github.com/broadinstitute/gatk; gradlew bundle. I've got this zip file in folder ""build"".; gatk-4.0.4.0-34-g2cc7abd-SNAPSHOT.zip. So I unzipped and used this to replace GATK-4.0.4.0 that I downloaded from https://github.com/broadinstitute/gatk/releases/download/4.0.4.0/gatk-4.0.4.0.zip. I still found errors. 21:09:33.811 INFO ProgressMeter - Starting traversal; 21:09:33.811 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 21:09:46.267 INFO ProgressMeter - chr1:24929636 0.2 3000 14453.2; 21:09:59.072 INFO ProgressMeter - chr1:64681324 0.4 6000 14251.2; 21:10:09.456 INFO ProgressMeter - chr1:156245393 0.6 9000 15149.8; 21:10:21.510 INFO ProgressMeter - chr1:206965947 0.8 12000 15094.7; 21:10:26.132 INFO Funcotator - Shutting down engine; [May 23, 2018 9:10:26 PM ICT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 1.36 minutes.; Runtime.totalMemory()=11500781568; java.lang.IllegalArgumentException: Genomic positions must be > 0.; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:722). What should I do? Can you send me one that is ready-to-use? Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391371859:268,down,downloaded,268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391371859,4,"['down', 'error']","['down', 'download', 'downloaded', 'errors']"
Availability,@jonn-smith Looks like the travis failures are transient...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5046#issuecomment-407144823:34,failure,failures,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5046#issuecomment-407144823,1,['failure'],['failures']
Availability,@jonn-smith Looks like there are 3 failures in `CustomMafFuncotationCreatorUnitTest` on the latest run,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7422#issuecomment-901407571:35,failure,failures,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7422#issuecomment-901407571,1,['failure'],['failures']
Availability,@jonn-smith Make sure to check that travis errors are transient.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5321#issuecomment-432869433:43,error,errors,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5321#issuecomment-432869433,1,['error'],['errors']
Availability,"@jonn-smith Something is weird here, it looks like the the stubs are committed now by accident. That's what I see if I check it out locally. They're still valid git-lfs stubs, so running a `git-lfs checkout` will pull them down and then git will think that they've all been modified since they're not being tracked correctly by git-lfs... In the past to move things out of git-lfs I've had to do it in 2 commits. ; 1. remove the file from git, ; 2. re-commit it to a new location that isnt tracked by git-lfs. `git lfs migrate export` might help, but I've never used it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5381#issuecomment-434782675:223,down,down,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5381#issuecomment-434782675,1,['down'],['down']
Availability,@jonn-smith The original BAM (containing short reads) will run normally. The filtered BAM (containing only long reads) will crash. @lbergelson Is there a way to keep the file in `--conf spark.local.dir=./tmp`? Perhaps I can extract a minimal bam file that reliably reproduces this problem from it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949#issuecomment-2287584742:256,reliab,reliably,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949#issuecomment-2287584742,1,['reliab'],['reliably']
Availability,@jonn-smith There are a bunch of test failures on this branch in travis -- could you fix these before we review? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3410#issuecomment-320329698:38,failure,failures,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3410#issuecomment-320329698,1,['failure'],['failures']
Availability,@jonn-smith You have a bunch of failures in `DataSourceUtilsUnitTest` -- can you fix before I review?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6807#issuecomment-691238608:32,failure,failures,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6807#issuecomment-691238608,1,['failure'],['failures']
Availability,@jonn-smith is this in a release or would we have to download/compile to test?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-951261199:53,down,download,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-951261199,1,['down'],['download']
Availability,@jonn-smith tested a workaround using JEXL expressions to filter out spanning deletions but it was not working. This seems like a bug because spanning deletions can cause downstream issues.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7341#issuecomment-876574736:171,down,downstream,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7341#issuecomment-876574736,1,['down'],['downstream']
Availability,"@jonn-smith this is tested on my end. would you mind testing on yours and reviewing the pull request?. Also I am trying to run it using the jar file but when I use it I get an error:; ```; Error: A JNI error has occurred, please check your installation and try again; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/broadinstitute/barclay/argparser/CommandLineException; ```; let me know if you have any inputs on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1185730223:176,error,error,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1185730223,3,"['Error', 'error']","['Error', 'error']"
Availability,"@joshwilding4444 Were you able to get our test suite running, or are you still running into this? We've never seen this error before and are not sure of the cause. Are you running with Java 8, or a later version of Java?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748#issuecomment-696286788:120,error,error,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748#issuecomment-696286788,1,['error'],['error']
Availability,"@jrvanalstine I'd strongly suggest that you upgrade. As discussed in the linked issue above, the underlying segmentation algorithm is completely different from that used in the beta workflows. Major changes were made to file formats and the overall structure of the pipeline as well. That said, it may still be the case that heavily downsampled input still gives strange results---if you are just downsampling to create test BAMs, I'd suggest that you increase the bin size to maintain a reasonable number of counts in each bin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944#issuecomment-474513366:333,down,downsampled,333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944#issuecomment-474513366,2,['down'],"['downsampled', 'downsampling']"
Availability,"@kachulis In the past, htsjdk had bugs that resulted in bad index files. Those checks are an attempt to try to detect and reject such files, since they can result in subtle downstream problems. The 1 and -1 allowances are a compromise for common cases that are out-of-spec, but legitimate. So it's a compromise between being too defensive and too aggressive. A value like -2147483647 winds up getting rejected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1095568749:173,down,downstream,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1095568749,1,['down'],['downstream']
Availability,"@kachulis It is, although Travis says there's a build error and the data of the run isn't available anymore. @droazen Is there a way to rerun Travis?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7193#issuecomment-1428504147:54,error,error,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7193#issuecomment-1428504147,2,"['avail', 'error']","['available', 'error']"
Availability,@kachulis May I ask where is the resulting chain file for lifting over from Hg38 to B37? It seems to me that only the chain file for lifting over from B37 to Hg38 is available in the repo. Thanks.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5579#issuecomment-671080367:166,avail,available,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5579#issuecomment-671080367,1,['avail'],['available']
Availability,"@kcibul Can you try re-running with a build of https://github.com/broadinstitute/gatk/pull/2417, and paste the (hopefully) more detailed error message here?. Can you also try with a few different files in different buckets, and see whether you get the same error in every case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281521368:137,error,error,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281521368,2,['error'],['error']
Availability,"@kcibul That NPE suggests that GenomicsDBImporter is failing to find a reader for a particular sample name. One possible cause of this is disagreement between the samples in your `--sampleNameMap` file and the sample names in the VCF headers. Due to a bug that I noticed just now (https://github.com/broadinstitute/gatk/issues/2714), the `GenomicsDBImporter` class in GenomicsDB unnecessarily uses the actual VCF headers to construct a list of sample names internally, which it then uses to query a map of `sample -> reader` that was (in your case) populated using the contents of the `--sampleNameMap` file. I've asked Intel to fix that bug in GenomicsDB (ie., use the sample names passed in to it instead of going back to the VCF headers), but it will probably take them 1-2 days, since a new GenomicsDB release will be required. In the meantime @kcibul, I suggest you try running without the `--sampleNameMap` argument and see if the problem goes away. It will likely be a bit slower, since it will download all VCF headers up-front, but it seems to me to greatly decrease the opportunity for this particular NPE to occur. While you're at it, it would also be good to check the contents of your `--sampleNameMap` file against the sample name in each VCF header.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301452121:1002,down,download,1002,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301452121,1,['down'],['download']
Availability,"@kcibul encountered the following transient error when running GenomicsDBImport with vcfs in GCS. ```; [May 9, 2017 1:35:47 PM UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 2.44 minutes.; Runtime.totalMemory()=2436366336; htsjdk.samtools.FileTruncatedException: Premature end of file: /temp/10C102545.5783b88e-6d16-4da7-be0e-590811cd6d2f.g.vcf.gz; at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:513); at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:451); at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:441); at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:234); at htsjdk.tribble.readers.TabixReader.readLine(TabixReader.java:199); at htsjdk.tribble.readers.TabixReader$IteratorImpl.next(TabixReader.java:416); at htsjdk.tribble.readers.TabixIteratorLineReader.readLine(TabixIteratorLineReader.java:45); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.readNextRecord(TabixFeatureReader.java:178); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:216); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:156); at com.intel.genomicsdb.GenomicsDBImporterStreamWrapper.next(GenomicsDBImporterStreamWrapper.java:100); at com.intel.genomicsdb.GenomicsDBImporter.importBatch(GenomicsDBImporter.java:1313); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:361); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:740); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2686:44,error,error,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2686,2,"['avail', 'error']","['available', 'error']"
Availability,"@kcibul reports getting the following error while running `GenotypeGVCFs`:. ```; New error coming out of GenotypeGVCFs when running 1000 shards:. [11:20] ; ***********************************************************************. A USER ERROR has occurred: Bad input: Cannot calculate Root Mean Square Mapping Quality if there are 0 or less reads.; Number of reads recorded as :0; In VariantContext: [VC UG_call @ chr1:143249103 Q38.86 of type=SNP alleles=[C*, T] attr={DP=14, ExcessHet=3.0102999210357666, MLEAC=[2], MLEAF=[0.25], RAW_MQ=0.0} GT=[[09C81377 C*/C* GQ 6 DP 5 PL 0,6,90 {MIN_DP=4}],[09C83237 C*/C* GQ 3 DP 6 PL 0,3,45 {MIN_DP=6}],[09C97255 ./. DP 0 PL 0,0,0 {MIN_DP=0}],[09C98651 ./. DP 0 PL 0,0,0 {MIN_DP=0}],[09C99383 T/T GQ 3 PL 45,3,0 {PGT=0|1, PID=143249097_C_T, SB=[0, 0, 0, 0]}],[09C99677 ./. DP 0 PL 0,0,0 {MIN_DP=0}],[10C100868 C*/C* GQ 3 DP 7 PL 0,3,45 {MIN_DP=4}],[10C101312 ./. DP 0 PL 0,0,0 {MIN_DP=0}],[10C102545 ./. DP 1 PL 0,0,0 {MIN_DP=0}],[10C102782 ./. DP 0 PL 0,0,0 {MIN_DP=0}]]. [11:21] ; ```. I think this might be a bug, or at least a case of over-aggressive error checking. We have an extra check in our version of `RMSMappingQuality` that is not present in the GATK3 version:. ```; if (numOfReads <= 0){; throw new UserException.BadInput(""Cannot calculate Root Mean Square Mapping Quality if there are 0 or less reads."" +; ""\nNumber of reads recorded as :"" +numOfReads +; ""\nIn VariantContext: ""+ vc.toStringDecodeGenotypes());; }; ```. We should match the GATK3 behavior in this case, unless we can **prove** (and not merely infer) that GATK3 also explodes. @lbergelson Since you are git blamed here, can you give your thoughts on this?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2658:38,error,error,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2658,4,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"@kcibul reports the following issue while trying to use `SelectVariants` to read a VCF from GCS using the latest master:. ```; I was trying this out today, and ran into some problems. I built GATK4 from the latest master and ran:. VCF=gs://fc-4c1c7765-2de2-4214-ac41-dc10bbcbb55b/e11051c9-27ce-4ff1-ba70-de73bf11f312/PairedEndSingleSampleWorkflow/326f24b8-9158-4120-8df3-7fc4b928589c/call-GatherVCFs/S1-1.g.vcf.gz; ; ./gatk-launch SelectVariants -V $VCF -L 1:1000-2000 -O foo.vcf; and I get an error about token being expired (see below). However, I can run. gsutil cat $VCF | zcat | head; without a problem, so I don't think my gcloud credentials are the problem. com.google.cloud.storage.StorageException: 400 Bad Request; {; ""error"" : ""invalid_grant"",; ""error_description"" : ""Token has been expired or revoked.""; }; 	at com.google.cloud.storage.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:202); 	at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:348); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:186); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:183); 	at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:183); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:531); 	at java.nio.file.Files.exists(Files.java:2385); 	at org.broadinstitute.hellbender.utils.io.IOUtils.assertFileIsReadable(IOUtils.java:567); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:248); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:209); 	at org.broadinstitute.hellbender.engine.VariantWalker.initializeDrivingVariants(VariantWalker.java:54); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerB",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2415:494,error,error,494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2415,2,['error'],['error']
Availability,@kdatta @kgururaj Any update on when the modified version of this PR will be available? We're eager to test it out!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-279769739:77,avail,available,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-279769739,1,['avail'],['available']
Availability,"@kdatta @kgururaj We have some questions about this pull request. It looks like maybe you forgot some commits, (and included some extra ones that you didn't intend to). . 1. The tests are a direct copy and paste of `PrintReadsIntegrationTests` and couldn't possibly run. Did you forget to push the commit with the actual test code? We really need some tests especially because it's not totally obvious how to use this tool and what needs to be in the jsons. . 2. The tool currently takes a partition index and a json with stream ids. The way we had envisioned this working was that it would take a `-V` argument with a list of vcfs and `-L` argument specifying what chunk of the genome to load. Can you explain why it is designed this way and if it is possible to change to use the more idiomatic input style? . 3. Can you let us know when 0.4.0 is available on maven? . We have additional review comments, but it seems premature to get into those details until the above are answered.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277310677:849,avail,available,849,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277310677,1,['avail'],['available']
Availability,@kdatta It shouldn't cause any problems for you. It was a local configuration issue. If your already set up to download the lfs files these should just work.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288540859:111,down,download,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288540859,1,['down'],['download']
Availability,"@kdatta Pasting the relevant portion of the travis log here for reference. The test suite appears to be dying with error code 134 (process received `SIGABRT`), perhaps due to the following error: `[E::bcf_hdr_add_sample] Duplicated sample name 'HG00096'`. ```; :test[M::bwa_idx_load_from_disk] read 0 ALT contigs; [M::mem_pestat] skip orientation FF as there are not enough pairs; [M::mem_pestat] analyzing insert size distribution for orientation FR...; [M::mem_pestat] (25, 50, 75) percentile: (387, 415, 430); [M::mem_pestat] low and high boundaries for computing mean and std.dev: (301, 516); [M::mem_pestat] mean and std.dev: (407.54, 32.35); [M::mem_pestat] low and high boundaries for proper pairs: (258, 559); [M::mem_pestat] skip orientation RF as there are not enough pairs; [M::mem_pestat] skip orientation RR as there are not enough pairs; [M::mem_pestat] skip orientation FF as there are not enough pairs; [M::mem_pestat] analyzing insert size distribution for orientation FR...; [M::mem_pestat] (25, 50, 75) percentile: (387, 415, 430); [M::mem_pestat] low and high boundaries for computing mean and std.dev: (301, 516); [M::mem_pestat] mean and std.dev: (407.54, 32.35); [M::mem_pestat] low and high boundaries for proper pairs: (258, 559); [M::mem_pestat] skip orientation RF as there are not enough pairs; [M::mem_pestat] skip orientation RR as there are not enough pairs; [M::mem_pestat] skip orientation FF as there are not enough pairs; [M::mem_pestat] analyzing insert size distribution for orientation FR...; [M::mem_pestat] (25, 50, 75) percentile: (470, 502, 533); [M::mem_pestat] low and high boundaries for computing mean and std.dev: (344, 659); [M::mem_pestat] mean and std.dev: (501.23, 49.14); [M::mem_pestat] low and high boundaries for proper pairs: (281, 722); [M::mem_pestat] skip orientation RF as there are not enough pairs; [M::mem_pestat] skip orientation RR as there are not enough pairs; Created workspace /tmp/travis/genomicsdb-tests-1057177121940476778/worksp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2634#issuecomment-298740693:115,error,error,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2634#issuecomment-298740693,2,['error'],['error']
Availability,"@kdatta The maven artifact is up on maven-central, but Gradle gives an error since it appears to have an incorrect POM file:. > inconsistent module metadata found. Descriptor: com.intel:genomicsdb:${genomicsdb.version} Errors: bad version: expected='0.5.0-proto-3.0.0-beta-1' found='${genomicsdb.version}'. And if you look at the pom file on maven central, it looks like this:. <groupId>com.intel</groupId>; <artifactId>genomicsdb</artifactId>; <!-- Build version passed from parent Makefile -->; <version>${genomicsdb.version}</version>; ; Looks like the version didn't get propagated from your make file. Can you guys publish one with the real version embedded in the POM ? Thx.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293973655:71,error,error,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293973655,2,"['Error', 'error']","['Errors', 'error']"
Availability,@kdmurray91 Thanks for reporting this. This is caused by a dumb oversight in the code. I made a branch to fix it here: https://github.com/broadinstitute/gatk/pull/6435. I suspect you may have a different underlying error that was being hidden by this bug. Please update if you have additional issues.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6434#issuecomment-581511893:215,error,error,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6434#issuecomment-581511893,1,['error'],['error']
Availability,"@kelepiradam @sooheelee @droazen I have diagnosed the problem in the original issue at the top of this page. When we increase interval padding we introduce additional downstream reference sequence that is homologous to kmers with the variants that get dropped. Thus the kmers with the variant never actually get threaded into the graph because we only start threading at unique kmers. When you change the code to start threading from the beginning of the read, you get the variants back. There is no way to fix this on the command line, although there is a ticket (#4942) to consider doing something about this as @vruano has proposed. At the very least we should add an argument to allow threading to start at non-unique kmers. After some investigation we might want to make it the default behavior. @ldgauthier would you support creating a command-line argument to start threading from the beginning of each sequence?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-446691512:167,down,downstream,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-446691512,1,['down'],['downstream']
Availability,"@kew24 Thanks for the bug report! Would you be satisfied if we just changed the text of the error message to read ""The last overlapping interval is ....""?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329723947:92,error,error,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329723947,1,['error'],['error']
Availability,"@kguraj Thanks for the response(s). The test in the PR was super useful as a temporary test, but as you mentioned it runs pretty slowly, and as it stands the test passes on current master anyway. It seems to require on the order of 9000-1000 intervals instead rather than 1000 to actually hit stack overflow. Since that would be a very slow running test, I'm inclined to back it out. Also, the user who originally reported the issue was using 11k intervals, and it seems that the stack overflow fix is unlikely to help in that case. Is there any guidance for users on what is a reasonable number of intervals per process ? It sounds like the intention was that it be used with pretty small intervals. Should we issue a warning message in GenomicsDBImport at some threshold number of intervals ?. Are you planning to produce a jar with the error messages suppressed for this PR?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407867902:839,error,error,839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407867902,2,['error'],['error']
Availability,"@kgururaj . So I found out that there are other fields that are also throwing a similar error with `vcf-validator`:. Below you will find this: `INFO tag [an_adj_exac_oth=16,16] expected different number of values (1)`. ```; # from the vcf-validator; INFO field at 4:2044128 .. INFO tag [af_exac_all=0] expected different number of values (expected 3, found 1),INFO tag [af_adj_exac_fin=0] expected different number of values (expected 3, found 1),INFO tag [an_adj_exac_oth=16,16] expected different number of values (1),INFO tag [an_adj_exac_nfe=202,202] expected different number of values (1),INFO tag [an_adj_exac_afr=20,20] expected different number of values (1),INFO tag [af_adj_exac_amr=0] expected different number of values (expected 3, found 1),INFO tag [an_exac_all=1246,1246] expected different number of values (1),INFO tag [an_adj_exac_amr=10,10] expected different number of values (1),INFO tag [af_adj_exac_oth=0] expected different number of values (expected 3, found 1),INFO tag [an_adj_exac_eas=30,30] expected different number of values (1),INFO tag [an_adj_exac_fin=2,2] expected different number of values (1),INFO tag [an_adj_exac_sas=966,966] expected different number of values (1),INFO tag [af_adj_exac_sas=0] expected different number of values (expected 3, found 1),INFO tag [af_adj_exac_afr=0] expected different number of values (expected 3, found 1),INFO tag [af_adj_exac_nfe=0] expected different number of values (expected 3, found 1),INFO tag [max_aaf_all=1] expected different number of values (expected 3, found 1),INFO tag [af_adj_exac_eas=0] expected different number of values (expected 3, found 1); ```. In this case, `an_adj_exac_oth` has > 1 values and only 1 is allowed:. ```; grep ; ##INFO=<ID=an_adj_exac_oth,Number=1,Type=Integer,Description=""Other Chromosome Count (from /mnt/isilon/cbmi/variome/bin/bcbio-nextgen/bcbio/gemini_data/ExAC.r0.3.sites.vep.tidy.vcf.gz)"">. # the corresponding variant in the vcf ; 4	2044128	.	C	T,CGCT,<NON_REF>	3476.7	.	DP=97",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407497476:88,error,error,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407497476,1,['error'],['error']
Availability,"@kgururaj @francesperry There's a [thread on the GATK forum](https://gatkforums.broadinstitute.org/gatk/discussion/comment/48287) where people are reporting a number of issues running GenomicsDB. There are a few different issues but they all seem to be edge cases with the file system. . 1. Report of the following error when trying to read from a GenomicsDB that is marked as read only. Is there a reason that the workspace must be writeable in order to read it? Can we avoid that requirement?; ```; terminate called after throwing an instance of 'VariantQueryProcessorException'; 2018-01-10T12:15:04.154547266Z what(): VariantQueryProcessorException : Could not open array genomicsdb_array at workspace: /keep/d22f668d4f44631d98bc650d582975ca+1399/chr22_db; ```. 2. `Could not open array genomicsdb_array at workspace` when working with a small disk. Changing to a larger disk fixed the problem. Possibly we need a better error message for the case where we are out of disk space?. 3. Reports of similar errors using a Lustre filesystem with file locking disabled. Can GenomicsDB run without file locking? If not, can we emit a clear error message when we hit that problem?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4753:315,error,error,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4753,4,['error'],"['error', 'errors']"
Availability,@kgururaj @kdatta Could you guys give us your thoughts on this error?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2632#issuecomment-297812752:63,error,error,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2632#issuecomment-297812752,1,['error'],['error']
Availability,@kgururaj @nalinigans Just pinging you to make sure you notice @ldgauthier 's comment above where she reproduces this with just 2 intervals.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5300#issuecomment-438827882:27,ping,pinging,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5300#issuecomment-438827882,1,['ping'],['pinging']
Availability,"@kgururaj As I start to think about upgrading exome joint calling to use GenomicsDBImport the 100 interval threshold seems like it might be problematic. I've been working with WGS data, so I don't have much intuition for benchmarking with missing data. Is there any performance downside to running over larger intervals that include missing data? For example, if we want to scatter the exome 50 ways, each subset of the exome interval list will have ~4000 intervals, but the GVCFs won't have data outside those intervals. Does it make sense to pass to GenomicsDBImport a single interval encompassing all of those?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5066#issuecomment-409956462:278,down,downside,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5066#issuecomment-409956462,2,['down'],['downside']
Availability,@kgururaj Can you take a look and see if we can issue a more informative error message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5064#issuecomment-408492983:73,error,error,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5064#issuecomment-408492983,1,['error'],['error']
Availability,"@kgururaj Do those first messages originate [here](https://github.com/Intel-HLS/TileDB/blob/33ad0355db215cb528162a74c16b706a059b0346/core/src/storage_manager/storage_manager.cc#L1168) ? I'm not sure what GenomicsDB code path leads there, but it looks like TileDB considers them to be an error that results in a short-circuit return. I'd be concerned that masking them would hide some underlying error. Are there any tests that verify that data round-trips though GDB when an interval list large enough to trigger these messages is encountered ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407394879:287,error,error,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407394879,3,"['error', 'mask']","['error', 'masking']"
Availability,"@kgururaj I don't think so. While we see a lot fewer transient errors with the latest version, recent issue #3481 reports a similar truncation symptom.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2686#issuecomment-324733817:63,error,errors,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2686#issuecomment-324733817,1,['error'],['errors']
