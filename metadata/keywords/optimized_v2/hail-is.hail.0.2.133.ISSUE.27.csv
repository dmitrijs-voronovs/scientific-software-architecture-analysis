quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Usability,"@daniel-goldstein When you get a chance, I'd appreciate your high level opinion on this addition before I start thoroughly testing everything. Goal is to have something before the ATGU Welcome Workshop September 5th. I know the import locations are an issue in `initialize.py`. I mainly want feedback on whether the code passes the high level smell test and whether I've over designed this with too many checks and prompts or am forgetting something that would be nice to check for.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1648236180:292,feedback,feedback,292,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1648236180,2,['feedback'],['feedback']
Usability,"@daniel-goldstein sorry for the slow review turnaround! the code looks good to me, and i'll try it out tomorrow morning to make sure i don't have any additional feedback. thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13632#issuecomment-1781834758:161,feedback,feedback,161,https://hail.is,https://github.com/hail-is/hail/pull/13632#issuecomment-1781834758,2,['feedback'],['feedback']
Usability,"@daniel-goldstein, I'm vaguely worried given that the tests didn't fail on your PR the other day. Let's get a simple test that filters and/or sparsifies a block and then exports.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5500:110,simpl,simple,110,https://hail.is,https://github.com/hail-is/hail/issues/5500,1,['simpl'],['simple']
Usability,"@danking . The redirect was caused by lack of X-Forwarded-Host + X-Forwarded-Proto; * https://github.com/expressjs/express/blob/b8e50568af9c73ef1ade434e92c60d389868361d/lib/request.js#L429; * remoteAddress is the url from the last hop, not any forwarded address. > I'll revisit why ghost issues redirects with the new changes this afternoon.; Ghost doesn't read this header. They use X-Forwarded* headers, via Express: https://expressjs.com/en/guide/behind-proxies.html ; * Expresses finds ips using proxy-addr package (the getter is req.ips): https://github.com/expressjs/express/blob/3ed5090ca91f6a387e66370d57ead94d886275e1/lib/request.js#L349; * The test: https://github.com/expressjs/express/blob/3ed5090ca91f6a387e66370d57ead94d886275e1/test/req.ip.js; * proxy-addr does not support x-real-ip: https://github.com/jshttp/proxy-addr/issues/15. Ghost apparently uses X-Forwarded-For to rate limit malicious addresses:. * ""6. Include the X-Forwarded-For header, populated with the remote IP of the original request.; Without this, we aren't able to detect spam traffic patterns and your site risks being rate limited or incorrectly restricted.""; * https://ghost.org/faq/can-i-run-ghost-from-a-subdirectory/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8107#issuecomment-587687066:444,guid,guide,444,https://hail.is,https://github.com/hail-is/hail/pull/8107#issuecomment-587687066,2,['guid'],['guide']
Usability,"@danking @cseed should be ready for testing soon. pruned portions we're not using atm, wrote docker files, tested. if you want to run both packages on your local machine, you could use the top-level docker file (or each package's). To start a local instance of the web app, simply run:; `npm install && npm bootstrap`. To get a hot-reloading version of the web app (links to your browser, refreshes all changes): `cd packages/public && npm run dev`. To start the gateway: `cd packages/hail-api-gateway && nodemon index.js`. Dev mode routing is slow. To see a production, minified build: `cd packages/public && npm run build && npm run prod-test`.; * Build is a kind of compilation process. Dev dependencies are pruned, the app is split into static bundles, and minified. Some optimizations, like inlining of some React functions also occurs. This is independent of anything V8 does . This will also show a neat readout of all bundles:; ```; Browser assets sizes after gzip:. 2.79 kB .next/static/gZEz****/pages/_app.js; 2.42 kB .next/static/gZEz****/pages/_error.js; 502 B .next/static/gZEz****/pages/auth0callback.js; 349 B .next/static/gZEz****/pages/index.js; 745 B .next/static/gZEz****/pages/notebook.js; 856 B .next/static/gZEz****/pages/scorecard.js; 243 B .next/static/gZEz****/pages/tutorial.js; 99.4 kB .next/static/chunks/commons.294f****.js; 101 B .next/static/chunks/styles.9f25****.js; 450 B .next/static/css/commons.b770adbe.chunk.css; 5.74 kB .next/static/css/styles.4f393762.chunk.css; 6.93 kB .next/static/runtime/main-76ed****.js; 737 B .next/static/runtime/webpack-8917****.js; ```. Bundling cutoffs can be tweaked, but basically any common dependencies between pages are placed into one chunk. Chunks are loaded in parallel, and no chunks are needed to load the page; it's just HTML on initial render. At least some of the chunks could theoretically be served from a CDN (styles of course, some js). Each package expects a .env file, which organizes the environment variables used",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-454271935:274,simpl,simply,274,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-454271935,2,['simpl'],['simply']
Usability,@danking Can you do an initial pass and make sure there aren't any major issues with the Python code? I am most concerned with how I setup the disk manager and the disk creation / deletion code to avoid costly mistakes. I am aware of the FIXMEs. I haven't tested this at all yet. It would be great if I could have feedback on Wednesday so I can have this PR completely done on Friday.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11253:314,feedback,feedback,314,https://hail.is,https://github.com/hail-is/hail/pull/11253,1,['feedback'],['feedback']
Usability,"@danking I changed the homepage banner to ""Hail is hiring engineers!"" so it's clearer. I'll merge now but happy to keep iterating.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1948#issuecomment-311694515:78,clear,clearer,78,https://hail.is,https://github.com/hail-is/hail/pull/1948#issuecomment-311694515,2,['clear'],['clearer']
Usability,"@danking I have a mostly completed draft for SAIGE in QoB. Can you take a look? I'm mainly looking for enough feedback to get a green light to actually start testing this end to end, fill in the remaining not implemented components, add documentation, add verbosity and possibly a dry run feature, and support VEP annotations natively. There are a couple of core concepts:; 1. Phenotypes - Set of phenotypes to test. I support the ability to group phenotypes together. This is in anticipation of a new version of SAIGE that Wei is going to release soon.; 2. VariantChunks - The set of variant intervals of data to test per job. If it's SAIGE-GENE, then there's also the ""groups"" to actually test within that interval.; 3. io - There's a bunch of wrappers that handle input and output files so all of that logic combined with the checkpointing logic is abstracted away from what is actually going on.; 4. steps - These are the SAIGE modules to run. They are all dataclasses with configuration options; 5. saige - There's a class that can be instantiated in Python or I started writing the framework for a CLI. This has the code that builds the DAG end to end. All configuration happens with a yaml file that can overwrite default parameters for each step such as whether to checkpoint or where the results should be written to. For the CLI, I envision you can either give a config file and/or specify `--overrides step1_null_glmm.use_checkpoint=true`. For every Saige run, I write out the configuration used to a file in the output directory as well as information about the input data and variant chunks and the batch information.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13804:110,feedback,feedback,110,https://hail.is,https://github.com/hail-is/hail/pull/13804,1,['feedback'],['feedback']
Usability,"@danking I have a tab delimited file of pc-air pcs to try to run with the hail pc-relate (with header--SampleId, PC1, PC2,...PC10) . But I am not clear on the format of the scores_table.scores object needed to pass to pc-relate. Is it sorted by SampleId or indexed somehow? What are the steps in Hail to create that table from a tab delimited file? . `rel = hl.pc_relate(dataset.GT, 0.01,scores_expr=scores_table[dataset.col_key].scores, min_kinship=0.1)`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3490#issuecomment-390736100:146,clear,clear,146,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-390736100,2,['clear'],['clear']
Usability,"@danking I think this is set barring change to libsass compilation. If possible, I would like to keep the scss compilation in notebook.py, and create an issue to make a better solution as a step 2. I recognize what you want in broad terms, and am happy to do it, and at the same time the proposed alternative appears more complex, requires me to spend time on research (how to implement auto-reload, not having to retype `make scss` for every style change), and doesn't clearly add value compared to the remaining user-facing work.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5430#issuecomment-467256972:470,clear,clearly,470,https://hail.is,https://github.com/hail-is/hail/pull/5430#issuecomment-467256972,2,['clear'],['clearly']
Usability,@danking I'm keeping the changes requested state on until I get the full scope of changes that need to be made. Would be good to get your feedback first after my responses so I can do all changes in one pass.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13475#issuecomment-1739219812:138,feedback,feedback,138,https://hail.is,https://github.com/hail-is/hail/pull/13475#issuecomment-1739219812,2,['feedback'],['feedback']
Usability,"@danking I've made all of the changes except the one about the interface for `af_dist`. (I agree with the point you're making about it being confusing that both functions are seeded separately and need to be kept the same for the same dataset to be produced, but making it take a function might just add a lot of visual noise. Honestly, I'm really tempted to take all of the `seed` stuff out of `balding_nichols_model` and put a note in to the effect of ""for reproducible results, use `hl.set_global_seed()` just before creating a dataset."" How would you feel about that?). re: how seeding functions happens more generally---I don't think anything I've said in the docs is actually incorrect (I would consider array transformations a context, kind of like the axes of a table or matrix table, so the table should end up with `x = y = z` but different values for the elements in the array, and different values between rows), but I'll work on making the language clearer so that they actually say what I mean. w.r.t. `[z, z]` being two draws---I have sometimes waffled on this but in general I think I tend to disagree, in part because I have struggled to come up with a consistent definition of what that would mean. Happy to talk more about this, but I don't know if it's super relevant to balding nichols since all of the distributions are once-per-element draws.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4166#issuecomment-415848091:962,clear,clearer,962,https://hail.is,https://github.com/hail-is/hail/pull/4166#issuecomment-415848091,2,['clear'],['clearer']
Usability,"@danking IIUC the TeamCity build is now working with spark-2.1.0 but not spark-2.0.2; (even though running `./gradlew shadowJar archiveZip` on my laptop with spark-2.0.2 works fine.). From looking at the Maven repo; https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch-spark-20_2.11; and the elasticsearch-spark connector docs; https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html; there's no indication that some versions only support v2.1, though it does say; ```; elasticsearch-hadoop allows Elasticsearch to be used in Spark in two ways: through the dedicated support available since 2.1 or through the Map/Reduce bridge since 2.0. Spark 2.0 is supported in elasticsearch-hadoop since version 5.0; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2049#issuecomment-320274234:365,guid,guide,365,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320274234,2,['guid'],['guide']
Usability,"@danking So would be curious to get your thoughts. I was initially going to make this change such that instead of these activation tokens the batch worker authenticates with a cloud access token. I had a minor pause though because this means that other workers (even from other namespaces) could potentially impersonate each other, whereas they cannot in our current token system. Is that a concern to you? I suppose we are already pretty compromised if someone gets control of the batch worker's identity, considering the buckets that the batch worker has access to.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13071#issuecomment-1551928272:210,pause,pause,210,https://hail.is,https://github.com/hail-is/hail/pull/13071#issuecomment-1551928272,2,['pause'],['pause']
Usability,"@danking Tests are passing. What's the problem?. Strange, cloudtools is showing 2.0.0 available, but pip is installing 1.1.6. ```; + pip search cloudtools; cloudtools (2.0.0) - Collection of utilities for working on the Google Cloud Platform.; datawire-cloudtools (0.2.6) - Datawire Cloud Tools; cloudseed (0.0.1) - Cloudtools; + pip install -U cloudtools; Collecting cloudtools; Downloading https://files.pythonhosted.org/packages/47/f1/bec895151ea74b2117c66620840e9a86436b376927b557b080289b61f754/cloudtools-1.1.16-py3-none-any.whl; Installing collected packages: cloudtools; Successfully installed cloudtools-1.1.16; ```. Ah, cloudtools 1.2.0 and 2.0.0 were set up as python 2 packages, see https://pypi.org/simple/cloudtools/:. ```; cloudtools-1.1.16-py2-none-any.whl; cloudtools-1.1.16-py3-none-any.whl; cloudtools-1.2.0-py2-none-any.whl; cloudtools-2.0.0-py2-none-any.whl; ```. 1.1.16 is set up for both. @liameabbott I assume we're only supporting Python 3?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4240#issuecomment-419786154:711,simpl,simple,711,https://hail.is,https://github.com/hail-is/hail/pull/4240#issuecomment-419786154,2,['simpl'],['simple']
Usability,"@danking and I are giving feedback on this branch. Patrick, the test failure is due to you testing on files in scratch that are only local to your system. You should remove the test annotation @Test on scratch before pushing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1697#issuecomment-297083904:26,feedback,feedback,26,https://hail.is,https://github.com/hail-is/hail/pull/1697#issuecomment-297083904,2,['feedback'],['feedback']
Usability,"@danking danking There is a lot of things going on in this dataset that makes PCs challenging. This has 3 replicate related samples (mother and 2 children). It also contains EA, AA and Dominicans. So there is lots of recent admixture. Among the 5000 samples, there are 800 related samples. We ran eigenstrat with the 5000 samples + 2500 1000 genomes samples and those PCs look good. . So I am not sure it is the replicates that are the underlying cause. It may simply be the lack of the 1000 Genomes samples in the dataset for the PCs. I am will try adding the 1000 genomes samples to see if that fixes things. If that works, the docs would just need to recommend merging in the 1000 genomes data. I will get back to you on those results. That would be great to implement PC-Air in Hail to help streamline the processing of this type of dataset! I will be glad to test it out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3490#issuecomment-391760451:461,simpl,simply,461,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391760451,2,['simpl'],['simply']
Usability,@danking do you have an intuition for what the block size and capacity defaults should be for the cache?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3095#issuecomment-371984225:24,intuit,intuition,24,https://hail.is,https://github.com/hail-is/hail/pull/3095#issuecomment-371984225,2,['intuit'],['intuition']
Usability,"@danking img: https://github.com/genuinetools/img. ""Standalone, daemon-less, unprivileged Dockerfile and OCI compatible container image builder. img is more cache-efficient than Docker and can also execute multiple build stages concurrently, as it internally uses BuildKit's DAG solver. The commands/UX are the same as docker {build,tag,push,pull,login,logout,save} so all you have to do is replace docker with img in your scripts, command line, and/or life."". Oops, seems it doesn't quite work unprivileged yet, see: https://github.com/genuinetools/img#running-with-docker. Waiting on an upstream docker change, no movement in two months. Hrm.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5623#issuecomment-474189290:300,UX,UX,300,https://hail.is,https://github.com/hail-is/hail/pull/5623#issuecomment-474189290,2,['UX'],['UX']
Usability,@danking ready for another review. This PR has expanded because we needed to properly store/clear session-specific stuff in a bunch of places.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5872#issuecomment-484569009:92,clear,clear,92,https://hail.is,https://github.com/hail-is/hail/pull/5872#issuecomment-484569009,2,['clear'],['clear']
Usability,"@danking this should be good to go. Works. In future PR, should we place move gateway to last line of projects.txt? Not clear to me if CI is enforcing gateway-last in a different way",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5412#issuecomment-466476158:120,clear,clear,120,https://hail.is,https://github.com/hail-is/hail/pull/5412#issuecomment-466476158,2,['clear'],['clear']
Usability,"@danking, I started playing with your ASM experiment and wrote a library for lightweight bytecode generation. The primary abstractions are `FunctionBuilder` and `Code[T]`. The latter is an object that can generate bytecode to produce a value of type `T` on the top of the stack. I'm reasonably happy with the interface, see this example for factorial:. https://github.com/cseed/hail/commit/93d95982bccd16ffa531f67fa47163f3fc8cbdde#diff-e434fa9004c38142a8f6f64ffa73b48eR109. No ClassBuilder yet. Apart from that, all the major features are there. There are a bunch of missing operations (type conversions, for example) and I only have wrapper classes for `Int` and `Double`. Once we fill it out I think it will make an excellent stand-alone library. While I optimized conditional generation to be smart about converting between indicator values (0, 1) and branch targets, it still emits some unnecessary GOTOs for fall through and could be improved. There are two double comparison bytecodes (DCMPG and DCMPL) that treat NAN differently. I wasn't sure which one to use. We should probably emulate Java/Scala. I can't tell if ASM is generating short bytecodes for load from small local indices (e.g. ILOAD_2) or small constants (e.g., ICONST_3). It isn't clear if the pretty printer that comes with ASM makes a distinction. We probably need to dump to a file and run `javap`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/921:1253,clear,clear,1253,https://hail.is,https://github.com/hail-is/hail/pull/921,1,['clear'],['clear']
Usability,"@danking:. > Hey @shengqh !; > ; > Yeah, this is a bug in Kryo, a serialization library used by Spark, which cannot handle the size of data you're producing.; > ; > This is partly a deficiency in Hail: we assume that PLINK files are relatively small, in particular that the number of variants is small.; > ; > This issue was supposedly resolved in Spark 2.4.0+ and 3.0.0+ by [apache/spark@3e03303](https://github.com/apache/spark/commit/3e033035a3c0b7d46c2ae18d0d322d4af3808711) . You appear to be running Apache Spark version 3.3.2, so I'm surprised you encountered this. Can you confirm which version of the Kryo JAR you have in your environment?. I don't know the Kryo JAR. I tested on both docker images hailgenetics/hail:0.2.126-py3.11 and hailgenetics/hail:0.2.127-py3.11. > ; > Can you also share a bit of information about this PLINK file? `import_plink` could obviously be modified to support 30M+ variant PLINK files, but I'd like to understand better why such large PLINK files exist. Do you expect these files to continue to grow in size? Do other consumers of these PLINK files want one PLINK file per chromosome? Would it be possible to generate many PLINK files per chromosome such that all the PLINK files have roughly the same size in bytes?. We have a 35K cohort. The VCF format of chr1 is 2.4T. So we prefer to deliver plink bed format and hail matrix. And, the cohort will continue to grow in future. I will prefer to keep one file per chromosome. For large cohort, which format do you prefer? Hail matrix or Hail VDS?. > ; > Thanks for your feedback and help improving Hail!; > ; > Related issue: #5564 .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168#issuecomment-1904727993:1562,feedback,feedback,1562,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1904727993,2,['feedback'],['feedback']
Usability,"@illusional @lgruen Thanks for the feedback. I think the new changes address your comments, but let me know if you see something else.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11249#issuecomment-1020325698:35,feedback,feedback,35,https://hail.is,https://github.com/hail-is/hail/pull/11249#issuecomment-1020325698,2,['feedback'],['feedback']
Usability,"@jbloom22 opening this PR so we have something to work from. I think the dimensions where the ability to scale with Hail will be beneficial are:; * heritability estimation of many phenotypes at once; * partitioned LDSC with potentially thousands of covariates (Ran is currently exploring this space); * multiple tests of enrichment across different annotations (fitting the ""baseline"" partitioned model with ~50 covariates + 1 annotation of interest thousands of times -- Kate has been working in this area). In this first effort, I'm trying to implement the univariate, ""vanilla"" version of LD score regression -- no partitioning/annotations, just simple linear regression of chi-squared statistics on LD scores -- though I have tried to build for the first bullet point above, heritability estimation of many phenotypes at once.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5026:649,simpl,simple,649,https://hail.is,https://github.com/hail-is/hail/pull/5026,1,['simpl'],['simple']
Usability,"@jigold Did commit 23c9e2f fix the build or did the CI server break something? I guess either way, it's not clear why we had different results.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1012#issuecomment-257353710:108,clear,clear,108,https://hail.is,https://github.com/hail-is/hail/pull/1012#issuecomment-257353710,2,['clear'],['clear']
Usability,"@jigold Do I understand correctly that g2-standard-4 can only be created as a job private instance because there is no matching pool? If that's right, it looks like, unlike pool jobs, a JPIM job [will be correctly marked as error](https://github.com/hail-is/hail/blob/main/batch/batch/driver/instance_collection/job_private.py#L457-L467) if there are no available regions. Assuming all that is correct, do I also understand correctly that the only reason to block incoming jobs at the front-end is for a better user experience, not to protect the system from bad data? If yes, then I agree that need not be part of this PR because it merely improves user experience rather than being critical for correct functioning of the system. Are any of my assumptions or inferences wrong?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13430#issuecomment-1725778672:511,user experience,user experience,511,https://hail.is,https://github.com/hail-is/hail/pull/13430#issuecomment-1725778672,4,['user experience'],['user experience']
Usability,"@jigold I screwed up the stacked PRs so I'll need reapprovals. Sorry :(; ---; 1. Separating the `apk update` from the `apk add` means that; if the apk package repository metadata changes (say, the; URL of some repository changes) and we change our `apk add`; line (say we add a new package), then the `apk add` will; fail (e.g. because it has an out of date URL for the; repository that should contain the new package). The; `apk add --no-cache ...` invocation is essentially the same; as `apk update && apk add ... && rm -rf /path/to/repo/cache`.; When using docker, it is good practice remove unnecessary; files so that they do not get included in the ""image diff""; for that line of the Dockerfile. `apk add --no-cache ...`; succinctly performs exactly what we want. 2. Keeping each package on a separate line and sorting those; lines makes diffs easy-to-read with one line per new package. 3. Because `COPY` moves all the *contents* of a source folder into; the contents of the destination path (creating it if it does not; exist), it seems more clear to say `/batch/batch/`, indicating; that we are moving data into a folder.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4828:1049,clear,clear,1049,https://hail.is,https://github.com/hail-is/hail/pull/4828,1,['clear'],['clear']
Usability,"@jigold OK, so here's the summary of what I learned:. We don't have tabix files for GRCh38 and we only test on small positions. Many large positions without tabix files seems to cause a problem for VEP (and make it slow, unsurprisingly). Fix seems to be to download the *indexed* homo_sapiens cache https://ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/ and upload that to our QoB VEP bucket. I presume you copied from the data we use in Dataproc? If yes, we should update that to also have tabix files. Also, in Dataproc, we use highmem machines for VEP. We should change _service_vep to also use highmem machines. <details><summary>Listing the tabix files for GRCh38 and GRCh37</summary>. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch38-us-central1/homo_sapiens/95_GRCh38/\*/\*.tbi; CommandException: One or more URLs matched no objects.; ```. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/\*/\*.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/1/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/10/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/11/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/12/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/13/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/14/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/15/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/16/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/17/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/18/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/19/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/2/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145:44,learn,learned,44,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145,2,['learn'],['learned']
Usability,"@jigold Ok I changed this in a way that will hopefully be more clear. The rules are as follows:. 1. We only use `ci-intermediate` for anonymous images. Images are named auth, batch, etc. even when they are in tests or dev deploys.; 1. Every image draws from the main branch cache tag, named `<DOCKER_PREFIX>/<image_name>:cache`; 2. Every image has an additional cache tag that it draws from and pushes to. For deploys, that is the same as the main branch cache, for PRs, it is `cache-pr-<pr_number>`, for dev deploys it is `cache-<dev_username>`, and for deploys conducted by CIs in a non-default namespace, it is `cache-<namespace-CI-is-in>-deploy`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11999#issuecomment-1177641450:63,clear,clear,63,https://hail.is,https://github.com/hail-is/hail/pull/11999#issuecomment-1177641450,2,['clear'],['clear']
Usability,"@jigold addressed those changes. . Regarding the margin of the `div.wy-nav-content` element, I'm reducing the padding on the right rather than increasing the max-width, I think that should keep the left margin aligned. Though I think that it might not be a bad idea to reduce the left margin across all of the doc pages. I changed one of the treeview parameters as well, hopefully will help with selection issue you were experiencing. Though it is still a bit finicky in certain situations, usually when selecting/unselecting some combination of parent and child nodes (such as in gnomad.exomes). Selecting child nodes on selection of the parent isn't a basic option in the treeview class unfortunately, and I haven't figured out a way to do it that is completely to my satisfaction yet. The clear selections button seems to reset everything appropriately, at least.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1936#issuecomment-315459328:792,clear,clear,792,https://hail.is,https://github.com/hail-is/hail/pull/1936#issuecomment-315459328,2,['clear'],['clear']
Usability,"@jigold addressed your comments and, after seeing how simple it'd be to do, I came around to your point that I might as well make the same change in v1.1. Simplified the docs accordingly. We still may want to drop v1.1 at some point but Cotton agrees there is no urgency while it's not causing problems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2930#issuecomment-367113994:54,simpl,simple,54,https://hail.is,https://github.com/hail-is/hail/pull/2930#issuecomment-367113994,3,"['Simpl', 'simpl']","['Simplified', 'simple']"
Usability,@jigold identified `ibd_prune` as one of the slowest parts of the python doc test. This method is simply not effective. Users should use `pc_relate` or `ibd` in conjunction with `KeyTable.maximal_independent_set`. I didn't reimplement `ibd_prune` in terms of them simply to save time and because getting master builds going fast is important when we have limited build agents.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2274:98,simpl,simply,98,https://hail.is,https://github.com/hail-is/hail/pull/2274,2,['simpl'],['simply']
Usability,"@jigold test are fixed, properly clean up; I think the test should be improved to check that deletion properly cleans up expected resources (rather than simply doesn't throw an error, which will happen if deletion fails for any reason other than 404), but I think that could wait for a subsequent PR, because as written, the only way they will fail to do so is if the wrong name or namespace are supplied (else they will throw an error and the test will fail).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5618#issuecomment-478175367:153,simpl,simply,153,https://hail.is,https://github.com/hail-is/hail/pull/5618#issuecomment-478175367,2,['simpl'],['simply']
Usability,@jigold this should be simple. Last thing Dan wanted was that I fix the test,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11777#issuecomment-1170350346:23,simpl,simple,23,https://hail.is,https://github.com/hail-is/hail/pull/11777#issuecomment-1170350346,2,['simpl'],['simple']
Usability,"@jigold this should pass now. I also learned that Mypy checks each command line argument as an independent module. Instead of specifying individual files, we have to tell it to check `batch`. I also added `google_storage.py` in an ill-fated attempt to let batch use that. I think we can only type check modules that depend on one another by installing them first. We'll leave that for future work.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8968#issuecomment-662143859:37,learn,learned,37,https://hail.is,https://github.com/hail-is/hail/pull/8968#issuecomment-662143859,2,['learn'],['learned']
Usability,"@jigold you won the PR lottery, definitely ask me if you find something unclear (which may suggest ways to improve it). We can ask for feedback from @cseed or @tpoterba on the Spark question above.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2494#issuecomment-348243800:135,feedback,feedback,135,https://hail.is,https://github.com/hail-is/hail/pull/2494#issuecomment-348243800,2,['feedback'],['feedback']
Usability,"@jjfarrell Thanks for sharing that! This is really interesting information. I'm quite surprised, but the evidence is pointing to there being a PC that largely separates those 8 replicates from the entire remaining dataset (!!!). I'm personally quite surprised that 8 samples out of thousands could pull this off, but that definitely seems to be the issue, given that the PCs from PC-AiR avoid the issue. Thank you so much for hunting this down! It's very valuable information for us. ### Next Steps . So, clearly we need a solution for users that have substantial numbers of related individuals in their source dataset (especially if the pedigrees are unknown). For your _particular_ use case, I can add a blurb to the docs that recommends removing known replicates _before_ PCA and then projecting them using the loadings from PCA. A longer term solution is to simply implement PC-AiR in hail. I skimmed the implementation section of the paper earlier this week and it looks very straightforward. It seems to boil down to using the KING estimator to estimate relatedness, compute PCA on unrelated individuals, project related individuals into unrelated PC space. Finally, we can use pc_relate to improve on our original estimates of relatedness from KING. The timeline for the latter thing is kind of unclear and a bit further out given some other work I need to finish. I'll get the documentation improvement in this week. Is there anything else I can do that would have helped you avoid this issue? Is there anything else you need to resolve the issue now?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3490#issuecomment-391739992:505,clear,clearly,505,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391739992,4,"['clear', 'simpl']","['clearly', 'simply']"
Usability,"@jjfarrell Thanks for the information! This will be very helpful as I try to tease out what the issue is here. Also, I'm sorry my initial response was curt! I was a bit tired at the time and probably shouldn't have been responding to GitHub issues 😅. Hail's version of pc-relate does not identify an initial set of related and unrelated individuals. The R `pcrelate` implementation (the official / reference implementation by the authors of the paper) does this to identify a set of individuals on which to run the principal components analysis. It is not entirely clear to me why this is necessary, and we don't currently have a mechanism for doing so (since pc_relate _is_ our mechanism for determining related and unrelated individuals when there is population structure in the data set). If you have prior knowledge about related samples, you might try filtering to an known unrelated set and computing the scores from that set. I'm curious if that makes any difference in the results. Your invocations look very reasonable. I'll get in touch with the gnomAD team here at the broad to learn more about their experiences with pc_relate and see if I can better understand what's happening with the replicate samples. It's definitely possible there is an implementation error; however, I also want to rule out that the pc_relate model itself isn't breaking down here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3490#issuecomment-386639531:565,clear,clear,565,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-386639531,4,"['clear', 'learn']","['clear', 'learn']"
Usability,"@jmarshall @illusional Likewise, hopefully I captured the request clearly here but please provide more information if necessary!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14356#issuecomment-1964591127:66,clear,clearly,66,https://hail.is,https://github.com/hail-is/hail/issues/14356#issuecomment-1964591127,2,['clear'],['clearly']
Usability,@jmarshall thanks again for the feedback 0.2.128 should now be fixed: https://github.com/hail-is/hail/releases/tag/0.2.128 .,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14322#issuecomment-1967719780:32,feedback,feedback,32,https://hail.is,https://github.com/hail-is/hail/pull/14322#issuecomment-1967719780,2,['feedback'],['feedback']
Usability,"@jmarshall, thanks doing this - would you mind adding a simple unit test to lock down the behaviour?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14700#issuecomment-2397543555:56,simpl,simple,56,https://hail.is,https://github.com/hail-is/hail/pull/14700#issuecomment-2397543555,2,['simpl'],['simple']
Usability,@konradjk @bw2 Can you double check the test examples in `test_liftover_negative_strand` and give feedback on the interface?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4895:98,feedback,feedback,98,https://hail.is,https://github.com/hail-is/hail/pull/4895,1,['feedback'],['feedback']
Usability,"@konradjk I fixed the instructions. I remembered investigating this a month ago when a user asked how to do this and I didn't know off the top of my head what the semantics were. And I remembered the ""--"" thing that's used to pass arguments to gcloud and got them mixed up. So this is really not a big docs change now, but I think it's a little clearer?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7029#issuecomment-530395992:345,clear,clearer,345,https://hail.is,https://github.com/hail-is/hail/pull/7029#issuecomment-530395992,2,['clear'],['clearer']
Usability,"@konradjk asked for weighted OLS, which is just a transformation of `x` and `y` by `sqrt(w)`. Currently `sqrt` is done `1 + len(x)` per record rather than once because you can't bind inside an aggregate. If that's a bottleneck, I could rework the aggregator to pass the w through to scala and avoid taking sqrt altogether. But for now this simple change at the Python level seems reasonable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4146:340,simpl,simple,340,https://hail.is,https://github.com/hail-is/hail/pull/4146,1,['simpl'],['simple']
Usability,"@liameabbott I think you should go ahead and merge #3859. Once this is in, you can then use `locus_windows` to simplify, reduce memory req, and be more robust to catching out-of-order loci.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3873#issuecomment-401440022:111,simpl,simplify,111,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-401440022,2,['simpl'],['simplify']
Usability,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:22,clear,clear,22,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222,2,['clear'],['clear']
Usability,"@patrick-schultz I addressed your comments, would be happy to take more steps to make code clearer if you see some. Otherwise I'd like if you could check that you're now happy with how `oversamplingNum` is being used.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11050#issuecomment-992692981:91,clear,clearer,91,https://hail.is,https://github.com/hail-is/hail/pull/11050#issuecomment-992692981,2,['clear'],['clearer']
Usability,"@patrick-schultz I'm not sure if this makes sense or not, but I observed it while working on something else. It seems weird but acceptable to import an empty dictionary as any struct. Does this seem reasonable to you? How have we avoided this bug for so long?. I'm not familiar enough with this code to know how to simply reproduce the bug and add a corresponding test. Thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14202:315,simpl,simply,315,https://hail.is,https://github.com/hail-is/hail/pull/14202,1,['simpl'],['simply']
Usability,"@patrick-schultz I've assigned this to you because I wanted your feedback, but I'm happy to spin the wheel if you'd prefer. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4809:65,feedback,feedback,65,https://hail.is,https://github.com/hail-is/hail/pull/4809,1,['feedback'],['feedback']
Usability,"@patrick-schultz So, I made the change. It doesn't change the speed to get the keys (which was already at ~ SSD read speed). I'm not sure it's any clearer. Is there another way I could have done it?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3893#issuecomment-403986055:147,clear,clearer,147,https://hail.is,https://github.com/hail-is/hail/pull/3893#issuecomment-403986055,2,['clear'],['clearer']
Usability,@patrick-schultz sounds like an opportunity to learn how to do a deploy from Tim 😉,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6567#issuecomment-509642293:47,learn,learn,47,https://hail.is,https://github.com/hail-is/hail/issues/6567#issuecomment-509642293,2,['learn'],['learn']
Usability,"@patrick-schultz, you may have tuned out the long thread about all the issues with the first Python Chained Linear Regression and pruning, but this one is now clear of all of that and is purely a Python implementation of Scala's `LinearRegressionChained`: https://github.com/hail-is/hail/blob/main/hail/src/main/scala/is/hail/methods/LinearRegression.scala#L175",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9634#issuecomment-718124825:159,clear,clear,159,https://hail.is,https://github.com/hail-is/hail/pull/9634#issuecomment-718124825,2,['clear'],['clear']
Usability,"@rcownie I think this design is a reasonable compromise on interface, at least until linear algebra is in the compiler and we can ""cancel"" conversion from ndarray to BlockMatrix and back. The optimal `complexity_bound` will be hugely dependent on cluster setup. To aid user intuition, I made the unit in terms of a single dimension rather than dimension-cubed. I've found the divide-and-conquer eigh method (with memory proportional to elements) to be 2.5-3x faster than the RRR eigh method (with memory proportional to dimension) when run on laptop and GCP; it takes greater advantage of vectorized BLAS3 ops. Since we're CPU rather than RAM limited on a high-core GCP machine, I've set this up to use divide-and-conquer whenever it won't result in an overflow on `lwork` which is still an int32 in the Python stack (boo). @cseed please let me know if you have any high-level feedback",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3977#issuecomment-407268618:274,intuit,intuition,274,https://hail.is,https://github.com/hail-is/hail/pull/3977#issuecomment-407268618,4,"['feedback', 'intuit']","['feedback', 'intuition']"
Usability,"@tpoterba @cseed . If y'all can take a look at the docs, tests, and implementation, I want to merge this. I included a log of running on `profile.vcf.bgz` (which has 2500 samples) below, total time is about 3.5 minutes. I expect it to scale roughly like `O(nSamples^2)`. For Kyle's use case this performance is acceptable. Further performance, model, and usability improvements will be separate PRs. ```; dking@wmb16-359 # hail read -i profile.vds ibd -o foo; hail: info: running: read -i profile.vds; [Stage 0:==============> (1 + 3) / 4]SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; [Stage 1:============================================> (3 + 1) / 4]hail: info: running: ibd -o foo; [Stage 8:==================================================> (197 + 4) / 214]hail: info: timing:; read: 3.523s; ibd: 3m33.8s. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/738#issuecomment-250288185:355,usab,usability,355,https://hail.is,https://github.com/hail-is/hail/pull/738#issuecomment-250288185,2,['usab'],['usability']
Usability,@tpoterba @jigold committed some updates based on your feedback.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1936#issuecomment-314784714:55,feedback,feedback,55,https://hail.is,https://github.com/hail-is/hail/pull/1936#issuecomment-314784714,2,['feedback'],['feedback']
Usability,"@tpoterba I just did some back of the envelope calculations on this, and while I like the simplicity of it I don't think it scales in a tenable way. I'll let you know when I've fixed that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8071#issuecomment-584740001:90,simpl,simplicity,90,https://hail.is,https://github.com/hail-is/hail/pull/8071#issuecomment-584740001,2,['simpl'],['simplicity']
Usability,@tpoterba I'm assigning you since I've incorporated your feedback from when you reviewed these name changes before I separated them from the IR PR. I'll add a discuss post on breaking changes once this goes in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4032#issuecomment-408850197:57,feedback,feedback,57,https://hail.is,https://github.com/hail-is/hail/pull/4032#issuecomment-408850197,2,['feedback'],['feedback']
Usability,"@tpoterba Some changes to the load_dataset() function and documentation. @jbloom22 I reworded the ""Datasets"" documentation page. Is it clearer now, or is there anything else you would like to add?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4494:135,clear,clearer,135,https://hail.is,https://github.com/hail-is/hail/pull/4494,1,['clear'],['clearer']
Usability,"@tpoterba per your comments have largely left the PStruct varargs constructor in use in the PCanonicalStruct implementation. I think it would be simpler to just use the normal IndexedSeq constructor, and slightly more performant, and if you're interested in that could issue a separate PR. The only change in the implementation of PCanonicalStruct from the master version of PStruct is that I pass through requiredeness in all construction operations. Previously a few, like rename would not do this. Notably this only happened when they used the more complex varargs constructor, and seemed like a bug. The empty constructor was removed because it wasn't necessary.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7733:145,simpl,simpler,145,https://hail.is,https://github.com/hail-is/hail/pull/7733,1,['simpl'],['simpler']
Usability,"@tpoterba there is one minor implementation difference, wanted to check if you considered it too far afield: removed `PStringOptional` and `PStringRequired`. These are used in only 3 classes, and *Optional/Required classes are inconsistently used in the codebase anyways. By removing them we have fewer legacy constructors hanging off PArray.; * Furthermore, by adding the final class modifier to PCanonicalString, I'm not sure we can implement a case object in the same way (cannot extend PCanonicalString, which means places that expect a PType, like `StagedBlockLinkedListSuite.scala:159`, won't type check, if we simply make a PStringOptional with a constructor that calls `PCanonicalStruct()`)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7750:617,simpl,simply,617,https://hail.is,https://github.com/hail-is/hail/pull/7750,1,['simpl'],['simply']
Usability,@tpoterba why would these not go on the artifacts index page? It seems odd to couple the CI directly to the artifact structure of `hail-is/hail` when there's an equally simple alternative.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4667#issuecomment-433943049:169,simpl,simple,169,https://hail.is,https://github.com/hail-is/hail/pull/4667#issuecomment-433943049,2,['simpl'],['simple']
Usability,@tpoterba you were in here recently for performance so your eyes are appreciated. I simplified things a bit and localized almost all the parsing logic to `BgenRecord`. The contract for `advance` is that it is always called when `bfis` is pointing at the start of a record _or_ at or past the `end`. Advance will return the position to the start of a record or at or past the `end`. It returns true if there was a new record found. False otherwise. I avoided a couple allocating patterns. The rest of the diffs are copy pastes and some indentation changes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3783:84,simpl,simplified,84,https://hail.is,https://github.com/hail-is/hail/pull/3783,1,['simpl'],['simplified']
Usability,"A cluster monitoring terminal command also seems useful since you might forget to start your batch with the detailed information. I think a question for us is why this shouldn't be in the web UI? I think there's a clear benefit to having information directly in the CLI when you're using ipython or python or submit, but if you're starting a new terminal window to monitor a running job, why not start a browser window?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13063#issuecomment-1572346942:214,clear,clear,214,https://hail.is,https://github.com/hail-is/hail/issues/13063#issuecomment-1572346942,2,['clear'],['clear']
Usability,"A couple of notes:. - I moved the actual writing of the InsnNodes to the method's InsnList onto the MethodBuilder (MethodBuilder.close()) itself, per Dan's suggestion. This is a little weird because it gets called in fb.classAsBytes(), and so calling it earlier will basically add the instructions again, and we should never do this. I'm thinking of adding some logic to check that a method isn't ""closed"", or at least clearing out the instruction buffer afterwards.; - I want to implement `<init>` in terms of the method builder, but we don't have a way to deal with Unit return types well yet. Dan's made a crack at this as part of #2555, so I'm going to hold off on that until I can use that.; - We realized that the auto-adding of a return op at the end of the method was causing some extra bytecode to be added at the end of the method if you explicitly called Code._return() to return the last Code object in the method. We decided that keeping the return op in MethodBuilder and just not calling _return unless returning in the middle of a method was nicer, since Scala doesn't use return x either.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2569#issuecomment-351811149:419,clear,clearing,419,https://hail.is,https://github.com/hail-is/hail/pull/2569#issuecomment-351811149,2,['clear'],['clearing']
Usability,A few more rules for simplify,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3679:21,simpl,simplify,21,https://hail.is,https://github.com/hail-is/hail/pull/3679,2,['simpl'],['simplify']
Usability,"A little chaos testing revealed a database integrity issue. If jobs.state = Running, instance_id must be non-null. I incorrectly had `ON DELETE SET NULL`. Instead, make sure that the instance has been deactivated (which reschedules all jobs, setting state = Ready) before deleting the instance entry. Also, feedback on cancellation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7443:307,feedback,feedback,307,https://hail.is,https://github.com/hail-is/hail/pull/7443,1,['feedback'],['feedback']
Usability,"A lot of changes here. A summary:; - This subsumes notebook, so I deleted notebook and renamed notebook2 => notebook. Apologies, this makes the diff slightly harder to read.; - Added a simple messaging framework, stored in aiohttp session cookie, set message with `set_message`, handled by web_common by `base_context` by the default layout,; - Added notebook.hail.is/workshop-admin to manage and enable/disabled workshops. Workshops stored in the database.; - Workshop will be located at notebook.hail.is/workshop (I will move to workshop.hail.is as a later step); - Meta change: don't try to track dependencies on `make check` everywhere, it isn't really needed and it wasn't correct; - Rewrote code to monitor the spin up of notebooks: store notebook state in the database. I'm happy with how it turned out, it will be simpler and more reliable.; - I refactored the auth code to support the needs of workshops. I think it is also improved: simpler. Things left to do:; - ~~Port the load test code. And load test!~~; - The notebook link shouldn't be click-able if the notebook isn't ready. (Even better: If you click, launch the notebook when it is ready.); - ~~Didn't test the error case (when the notebook isn't actually available). This probably needs some work, and should get integrated into the message framework.~~; - The workshop header is a bit spare. Maybe add a slash (/) link. What would it link to?; - ~~Move notebook.hail.is/workshop to workshop.hail.is~~; - (low-prio) Finally, when the notebook state changes, we just refresh the page. Might be nice to just dynamically update HTML. Maybe react?; - (unrelated) The message framework should get used by the other services. @tpoterba I'm assigning this to you since you're point for the workshop. @akotlar knows this code if you want to re-assign. I gave you an account in my namespace, so you should be able to see/play with this at internal.hail.is/cseed/notebook. FYI @akotlar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112:185,simpl,simple,185,https://hail.is,https://github.com/hail-is/hail/pull/7112,3,['simpl'],"['simple', 'simpler']"
Usability,A much simpler fix for literals problem,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4173:7,simpl,simpler,7,https://hail.is,https://github.com/hail-is/hail/pull/4173,2,['simpl'],['simpler']
Usability,"A quick and dirty local test of different performances:; ```; 2017-09-22 18:05:57 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; [Stage 0:> (0 + 10) / 10]2017-09-22 18:05:58 Hail: INFO: Coerced sorted dataset; [Stage 374:==========================================> (3 + 1) / 4]. phi 27.4091310501. 2017-09-22 18:06:24 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:06:24 Hail: INFO: Coerced sorted dataset; [Stage 735:==========================================> (3 + 1) / 4]. phik2 34.3392460346. 2017-09-22 18:06:58 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:06:59 Hail: INFO: Coerced sorted dataset; [Stage 1192:==========================================> (3 + 1) / 4]. phik2k0 67.0002729893. 2017-09-22 18:08:05 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:08:06 Hail: INFO: Coerced sorted dataset; [Stage 1561:==========================================> (3 + 1) / 4]. all 102.006611109. ```. Time is in seconds. The most painful operation is clearly k0, but I bet most people will only want phi, maybe phi and k2.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2249#issuecomment-331572653:1230,clear,clearly,1230,https://hail.is,https://github.com/hail-is/hail/pull/2249#issuecomment-331572653,2,['clear'],['clearly']
Usability,"A simple but powerful extension requested by @alexb-3 and Christina to allow for synthetic genotypes with very general and realistic-looking PCA plots with [redacted]. Alex pointed out that BaldingNichols is special case of PritchardStephensDonnelly in a degenerate sense, just as one-hot encoded `Categorical(p_1,...,p_k)` is the distributional limit of `Dirichlet(a * p_1,..., a * p_k)` as `a` goes to 0. So the substantive changes took about 10 lines. It's turned on by the `mixture` parameter which defaults to False and is marked as experimental. `True` means treat `pop_dist` as the parameters of Dirichlet rather than Categorical. @alexb-3 , it'd be great if you and Christina could experiment with it and extend the documentation accordingly. Once we have that, I'll add tests and remove ""experimental"". The plots below are already quite convincing. ```; import hail as hl; import matplotlib.pyplot as plt. mt = hl.balding_nichols_model(3, 500, 50, pop_dist=[0.01, 0.02, 0.05], fst=[.2, .3, .5]); _, pcs, _ = hl.hwe_normalized_pca(mt, 3); plt.scatter(pcs.PC1.collect(), pcs.PC2.collect()); ```. ![ex0](https://user-images.githubusercontent.com/3201642/37743475-a470a372-2d40-11e8-894c-5ed0d74f3d14.png). ```; mt = hl.balding_nichols_model(3, 500, 50, pop_dist=[0.01, 0.02, 0.05], fst=[.2, .3, .5], mixture=True); ```. ![ex1](https://user-images.githubusercontent.com/3201642/37743104-decf0da8-2d3e-11e8-8d43-3e36f194fa8e.png). ```; mt = hl.balding_nichols_model(3, 500, 50, pop_dist=[0.1, 0.2, 0.5], fst=[.2, .3, .5], mixture=True); ```. ![ex2](https://user-images.githubusercontent.com/3201642/37743108-e2e4cfe0-2d3e-11e8-9860-724de2c6611c.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3206:2,simpl,simple,2,https://hail.is,https://github.com/hail-is/hail/pull/3206,1,['simpl'],['simple']
Usability,"A simple pipeline to generate fingerprinting data for gnomad v4 failed. . ```python3; import hail as hl; from gnomad_qc.v4.resources.basics import get_gnomad_v4_vds; hl.init(default_reference='GRCh38'); ​; ht = hl.import_table(; ""gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.haplotype_database.txt"",; comment=(""@""),; ); ht = ht.key_by(locus=hl.locus(ht['#CHROMOSOME'], hl.int(ht['POSITION'])), alleles=hl.array([ht.MAJOR_ALLELE, ht.MINOR_ALLELE])); vds = get_gnomad_v4_vds(split=True, remove_hard_filtered_samples=False); vds = hl.vds.filter_variants(vds, ht); mt = hl.vds.to_dense_mt(vds); mt = mt.checkpoint(""gs://gnomad/v4.0/sample_qc/exomes/gnomad.exomes.v4.0.fingerprinting_variants.mt"", overwrite=True); ```. We were able to get it to succeed, but filtering the variant data first on locus, splitting it, filtering it on variants. Then proceeding. There may be an ugly interaction with joins and explode but it needs more investigation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11717:2,simpl,simple,2,https://hail.is,https://github.com/hail-is/hail/issues/11717,1,['simpl'],['simple']
Usability,A simplistic port that still uses an EmitCode for the element IR to keep; BinarySearch mostly happy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9915:2,simpl,simplistic,2,https://hail.is,https://github.com/hail-is/hail/pull/9915,1,['simpl'],['simplistic']
Usability,"A user was getting an index out-of-bounds error on `cdf.values[idx]`. I can't reproduce it, but this should guarantee the index is in bounds, and is a simplification besides.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10624:151,simpl,simplification,151,https://hail.is,https://github.com/hail-is/hail/pull/10624,1,['simpl'],['simplification']
Usability,"A while back, TJ raised some concerns about the expressivity of hailtop.batch.; In this PR, I basically rebuilt hailtop.batch from scratch as a learning; exercise. Once I understood how it worked, I added two valuable features:. 1. `hb.remote` creates a ""remote"" resource which is never localized but still; creates dependency relationships. 2. `ResourceToStringPickler` which pickles resources appropriately even if; they are nested within other structures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11794:144,learn,learning,144,https://hail.is,https://github.com/hail-is/hail/pull/11794,1,['learn'],['learning']
Usability,"AFAIK, we don't test credential discovery. A little tricky because you want to modify the file system, which isn't kosher on a developer's laptop. Also not clear what to do about, e.g., the metadata server. You could mock it, but I've always felt pretty negative about the value of mocking. You might try adding some build.yaml steps that use docker to replicate some common environments?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11207#issuecomment-1007489641:156,clear,clear,156,https://hail.is,https://github.com/hail-is/hail/pull/11207#issuecomment-1007489641,2,['clear'],['clear']
Usability,"Ack, this isn't working as written in cluster mode on GCP due to different meaning of file names locally and through Hadoop. I'll think on it but would also appreciate feedback before I go further on this branch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3114#issuecomment-371968730:168,feedback,feedback,168,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-371968730,2,['feedback'],['feedback']
Usability,"Actually, a slightly longer answer:. The parent relationship is essentially a representation of the JVM stack. Each X corresponds to 1 JVM bytecode (except NewInstanceX which is fused). During emit, children are pushed on the stack left-to-right by necessity. Slightly more generally, there are two distinct questions here: what the implementation does, and what it guarantees. For what it guarantees, there are two options: fixed (like Java, which evaluates things left-to-right), and undefined (like C). In general, I think it is safest not to rely on the order of evaluation. I'm not aware of where we do. ; Our backend is simple enough and the mapping to the JVM concrete enough that I don't see any reason why we'd have reason to deviate from left-to-right. So I guess I fall somewhere in between (don't rely on it, but violate it).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8958#issuecomment-645533486:626,simpl,simple,626,https://hail.is,https://github.com/hail-is/hail/pull/8958#issuecomment-645533486,2,['simpl'],['simple']
Usability,"Actually, even simpler: . ```; def downsample_matrix_table(mt: hl.MatrixTable, n_divisions: int, p_threshold: float) -> hl.Table:; mt = mt.choose_cols(list(range(10))). x = mt.locus.global_position(); y = -hl.log10(mt.Pvalue). downsampled = mt.annotate_cols(; binned=hl.agg.downsample(; x,; y,; label=hl.str(mt.Pvalue),; n_divisions=n_divisions; ); ; ); downsampled = downsampled.cols(). return downsampled. mt = hl.balding_nichols_model(3, 100, 1000); pmt = mt.annotate_rows(Pvalue = hl.rand_unif(0, 1)); downed = downsample_matrix_table(pmt, 4, .05); downed.show(); ```. I'm now somewhat convinced that the downsample aggregator is accessing cleared memory",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8240#issuecomment-594754052:15,simpl,simpler,15,https://hail.is,https://github.com/hail-is/hail/issues/8240#issuecomment-594754052,4,"['clear', 'simpl']","['cleared', 'simpler']"
Usability,Add TableKeyBy simplification,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4471:15,simpl,simplification,15,https://hail.is,https://github.com/hail-is/hail/pull/4471,2,['simpl'],['simplification']
Usability,Add a few more simplification rules,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3550:15,simpl,simplification,15,https://hail.is,https://github.com/hail-is/hail/pull/3550,2,['simpl'],['simplification']
Usability,Add back progress bar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3143:9,progress bar,progress bar,9,https://hail.is,https://github.com/hail-is/hail/pull/3143,2,['progress bar'],['progress bar']
Usability,Add doctest instructions to the style-guide,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1394:38,guid,guide,38,https://hail.is,https://github.com/hail-is/hail/issues/1394,2,['guid'],['guide']
Usability,"Add information from https://discuss.hail.is/t/export-elasticsearch-function-documentation-for-updating-behavior/1899 to `export_elasticsearch` docs. This happens fairly often with preemptible Dataproc workers and has caused us some confusion in the past with the gnomAD browser. Without some understanding of how Hail works, it's not immediately clear why this happens.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9953:347,clear,clear,347,https://hail.is,https://github.com/hail-is/hail/pull/9953,1,['clear'],['clear']
Usability,Add new rules to Simplify,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3471:17,Simpl,Simplify,17,https://hail.is,https://github.com/hail-is/hail/pull/3471,1,['Simpl'],['Simplify']
Usability,Add rules to simplify statically missing IR nodes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3909:13,simpl,simplify,13,https://hail.is,https://github.com/hail-is/hail/pull/3909,2,['simpl'],['simplify']
Usability,Add simple- and twisted-tabulation hashes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2304:4,simpl,simple,4,https://hail.is,https://github.com/hail-is/hail/pull/2304,2,['simpl'],['simple']
Usability,Add simplest hash functions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2303:4,simpl,simplest,4,https://hail.is,https://github.com/hail-is/hail/pull/2303,2,['simpl'],['simplest']
Usability,Add simplification for mt.count_cols() with known col counts,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5068:4,simpl,simplification,4,https://hail.is,https://github.com/hail-is/hail/pull/5068,2,['simpl'],['simplification']
Usability,Add simplify rules to push filter into key_by and repartition,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5349:4,simpl,simplify,4,https://hail.is,https://github.com/hail-is/hail/pull/5349,2,['simpl'],['simplify']
Usability,Add some missing clears to aggregations,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3514:17,clear,clears,17,https://hail.is,https://github.com/hail-is/hail/pull/3514,2,['clear'],['clears']
Usability,Add two more simplify rules,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5804:13,simpl,simplify,13,https://hail.is,https://github.com/hail-is/hail/pull/5804,2,['simpl'],['simplify']
Usability,Added RegionValueAggregator.clear.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3523:28,clear,clear,28,https://hail.is,https://github.com/hail-is/hail/pull/3523,2,['clear'],['clear']
Usability,"Added in #115. We did not add AN, since this is simply `2 * nCalled`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/112#issuecomment-169052284:48,simpl,simply,48,https://hail.is,https://github.com/hail-is/hail/issues/112#issuecomment-169052284,2,['simpl'],['simply']
Usability,Added rules to simplify ArraySlice,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10755:15,simpl,simplify,15,https://hail.is,https://github.com/hail-is/hail/pull/10755,1,['simpl'],['simplify']
Usability,Added rules to simplify ArraySlice IR,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10759:15,simpl,simplify,15,https://hail.is,https://github.com/hail-is/hail/pull/10759,1,['simpl'],['simplify']
Usability,"Added set, get and clear commands.; join works against environment.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/959:19,clear,clear,19,https://hail.is,https://github.com/hail-is/hail/pull/959,1,['clear'],['clear']
Usability,"Added simple UI for billing projects, create, add and remove users. Hand-tested with dev deploy.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7713:6,simpl,simple,6,https://hail.is,https://github.com/hail-is/hail/pull/7713,1,['simpl'],['simple']
Usability,Added simple string escape.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/782:6,simpl,simple,6,https://hail.is,https://github.com/hail-is/hail/pull/782,2,['simpl'],['simple']
Usability,"Added support for a few more nodes, including {Insert, Select}Fields and Array{Range, Map, Filter} (deforested). I'm going to do ordering next. That should give us enough interesting stuff to play with when simple Table pipeline start working.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4663#issuecomment-433775154:207,simpl,simple,207,https://hail.is,https://github.com/hail-is/hail/pull/4663#issuecomment-433775154,2,['simpl'],['simple']
Usability,"Added the ""CHANGELOG"" note to contribution guidelines in #9752.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9749#issuecomment-736676863:43,guid,guidelines,43,https://hail.is,https://github.com/hail-is/hail/pull/9749#issuecomment-736676863,2,['guid'],['guidelines']
Usability,"Added:. - `textFilesLines` to go directly form array of file names to ContextRDD of strings. - `parallelize` with an `Option[Int]` (in addition to an overloaded version with an int parameter having a default value). - moved `run` to the top since it's super important. - eliminated two useless methods. - colocated `zipPartitions` with other zip-like methods. - added some `*AndContext*` methods that let the API user decide what context to give to the producer of values. The AndContext methods are useful for these two situations:. - One input value becomes multiple output values. We want to clear the input region separately from clearing the output region. - A zipPartitions / join where there are two inputs, we might want to use the same region for both inputs, but use a new region for the output. We might also want to use three distinct regions. All of these options are enabled by `czipPartitionsAndContext`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3389:595,clear,clear,595,https://hail.is,https://github.com/hail-is/hail/pull/3389,2,['clear'],"['clear', 'clearing']"
Usability,"Adding a new compiler pass (lowering MatrixIR to TableIR) exposed a problem in Simplify. The logic for preventing some simplifications from triggering if they would introduce non-determinism was broken, and fixing it required a pretty complete overhaul. Fortunately, I think it's now a lot simpler. Besides the rewrite of the high level Simplify architecture, I also:; * Changed `testRepartitioningSimplifyRules` to something that failed in the old version.; * Changed the `copy` signature on the IR hierarchy to be more precise (to avoid unnecessary coercions).; * Grouped the Simplify rules into IR, MatrixIR, and TableIR. After the reorganization, a couple of rule redundancies became evident.; * A couple of vals in PruneSuite required running the compiler. When I had a bug in Simplify, this was causing the test runner to fail before any tests were run, on class initialization of PruneSuite, which gives very little help in diagnosing the issue. I made them lazy vals to prevent this in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4564:79,Simpl,Simplify,79,https://hail.is,https://github.com/hail-is/hail/pull/4564,6,"['Simpl', 'simpl']","['Simplify', 'simpler', 'simplifications']"
Usability,"Adding a simple reproducible example. ```python; ht = hl.Table.from_pandas(pd.DataFrame({""variant"":['chr1:123:C:T']})); ht = ht.key_by(**hl.parse_variant(ht.variant)); pd_table = ht.to_pandas(); pd_table.to_pickle(os.path.join(bucket, 'test.pkl')); ```. The two examples below do not cause the same error. ; ```python; ht = hl.Table.from_pandas(pd.DataFrame({""foo"":['bar']})); ht = hl.Table.from_pandas(pd.DataFrame({""foo"":[1, 2, 3]})); ```. Hope this helps.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14004#issuecomment-1808416604:9,simpl,simple,9,https://hail.is,https://github.com/hail-is/hail/issues/14004#issuecomment-1808416604,2,['simpl'],['simple']
Usability,Adding how to guide for liftover,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5328:14,guid,guide,14,https://hail.is,https://github.com/hail-is/hail/pull/5328,2,['guid'],['guide']
Usability,"Adding zulip thread for posterity:. Patrick Schultz (he/him); [12:38 pm](https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/FastIndexedSeq/near/392155787); Ah, that's what I thought, originally FastSeq returned a Seq: https://github.com/hail-is/hail/commit/be415a850eb145c69a830e485d3192331799f14f#diff-75be823f33bdb7bc10ab85e3b954c91a4a7bd48176c2a39f2e3d2e7f7e30fab4. daniel king (he/him); [12:40 pm](https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/FastIndexedSeq/near/392156010); huh, I wonder when/why that changed. Patrick Schultz (he/him); [12:40 pm](https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/FastIndexedSeq/near/392156041); [toFastSeq](https://github.com/hail-is/hail/blob/995994c862b93406bc4b5fc37c7f022f7426cd52/hail/src/main/scala/is/hail/utils/richUtils/RichIterator.scala#L145) still does. If you make this change, you should get rid of toFastIndexedSeq too. [ 12:41 pm](https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/FastIndexedSeq/near/392156191); daniel king (he/him) [said](https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/FastIndexedSeq/near/392156010):. huh, I wonder when/why that changed. [a month later](https://github.com/hail-is/hail/commit/e2458973ad2bb9b065a56f480e986554b40eed79#diff-75be823f33bdb7bc10ab85e3b954c91a4a7bd48176c2a39f2e3d2e7f7e30fab4), not clear why",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13676#issuecomment-1728108189:1393,clear,clear,1393,https://hail.is,https://github.com/hail-is/hail/pull/13676#issuecomment-1728108189,2,['clear'],['clear']
Usability,"Addresses #1943 . [JVM Spec, Chapter 6](https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html) states, regarding, DCMPG and DCMPL:; > NaN is unordered, so any double comparison fails if either or both of its operands are NaN. With both dcmpg and dcmpl available, any double comparison may be compiled to push the same result onto the operand stack whether the comparison fails on non-NaN values or fails because it encountered a NaN. For more information, see [§3.5](https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-3.html#jvms-3.5). The `G` and `L` suffices refer to whether the presence of one or more `NaN`s should be indicated by returning ""greater than"" or ""less than"". Ergo, when we're checking `x > y` we use `DCMPL` so the NaN case produces `-1` with which the downstream comparison to `0` produces `false`. Confusingly, the simple intuition is, if you're checking **L**ess Than, you should use the **G** version. If you're checking **G**reater Than, you should use the **L** version.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1952:849,simpl,simple,849,https://hail.is,https://github.com/hail-is/hail/pull/1952,2,"['intuit', 'simpl']","['intuition', 'simple']"
Usability,"Adds stream expressions (undocumented), and forces the body of `map_partitions` to work at the stream level. This is needed for uid propagation for the new randomness design.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12331:25,undo,undocumented,25,https://hail.is,https://github.com/hail-is/hail/pull/12331,1,['undo'],['undocumented']
Usability,"Adds the ability to rerun/retry queries from the nearest `CollectDistributedArray` (`CDA`) IR site. Computes a ""Semantic Hash"" of the top-level IR, which is split and shared among the various constituent `CDA` calls in a query. The `CDA` procedure looks in an execution cache for the results of each partition for that call and uses/updates the cache with successful partition computations. . The nature of the staged- lower and execute model means we don't know how many `CDA` calls that will be generated ahead of time. Thus we treat the ""Semantic Hash"" in a similar way to an RNG state variable and generate a key from the Semantic Hash every time every time we encounter a `CDA`. Since an `ExecutionContext` is re-used for multiple queries in tests while a `SemanticHash` is coupled to one query, the two were kept separate. To minimise the amount of manual state handling, the code was transformed to use a ""State"" monad (abstracted as `MonadLower`). Since the `ExecuteContext` is used nearly everywhere the semantic hash is required, the `ExecuteContext` was absorbed into the `MonadLower` interface. `Lower` is a simple, concrete instance of `MonadLower`, and is used to adapt statements into `MonadLower` expressions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13194:1120,simpl,simple,1120,https://hail.is,https://github.com/hail-is/hail/pull/13194,1,['simpl'],['simple']
Usability,Adds the tutorial page (http://34.207.246.132/tutorial.html) and Learn More button bottom-right justified on home page. cc @mkveerapen includes some further content changes. minor updates to style (mostly width) found in the subsequent pr: #9007,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9005:65,Learn,Learn,65,https://hail.is,https://github.com/hail-is/hail/pull/9005,1,['Learn'],['Learn']
Usability,"After discussing with @ehigham, we decided to try a lighter-weight RFC process, where an RFC is simply a PR for a new dev doc. Discussion about the design can happen here, as well as on the dev doc itself (typos, clarity, etc.). When approved and merged, it will be a dev-doc marked as an unimplemented RFC. When implemented, the RFC mark will be replaced by a reference to the implementing commit.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14403:96,simpl,simply,96,https://hail.is,https://github.com/hail-is/hail/pull/14403,1,['simpl'],['simply']
Usability,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:301,learn,learn,301,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413,10,['learn'],['learn']
Usability,"After spending a few hours digging through log4j and trying a bunch of approaches, I wasn't able to fix our current approach of adding appenders to the consoleLog after log4j has already been configured. Instead, we set up log4j in initial configuration to have the appenders we want. Also moved logging config from HailContext to backend, where it should be. . Storing the StringSocketAppender on the static object is definitely a bit funky, but it's being allocated inside log4j and I don't see a simpler way to store it for retrieval later.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12783:499,simpl,simpler,499,https://hail.is,https://github.com/hail-is/hail/pull/12783,1,['simpl'],['simpler']
Usability,"After watching batch a bit, it is clear 5m is way too long.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7972:34,clear,clear,34,https://hail.is,https://github.com/hail-is/hail/pull/7972,1,['clear'],['clear']
Usability,"Agreed, this is good for useability. note it’s also a special case of simple linreg predicting y from x (we return the square r_sq. The sign is that of beta).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4479#issuecomment-425769239:70,simpl,simple,70,https://hail.is,https://github.com/hail-is/hail/issues/4479#issuecomment-425769239,2,['simpl'],['simple']
Usability,"Ah yes, this is what I meant by deploy. Patrick can learn how to do a release / pip deploy.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6567#issuecomment-509643864:52,learn,learn,52,https://hail.is,https://github.com/hail-is/hail/issues/6567#issuecomment-509643864,2,['learn'],['learn']
Usability,"Ah, I thought I said I was happy to fix the optimized version rather than revert. I do think it can be simplified, though, per my comments. Cotton also had the suggestion of writing this function unstaged using two utility functions:; ```scala; def findFirstNonZeroByte(addr: Long, n: Long): Long; def allPresent(addr: Long, n: Long): Long // uses findFirstNonZeroByte; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7646#issuecomment-561448054:103,simpl,simplified,103,https://hail.is,https://github.com/hail-is/hail/pull/7646#issuecomment-561448054,2,['simpl'],['simplified']
Usability,"Ah, got it. Pairwise is clearly no good. OK, one last question: what are the using for keys that they can compute the scores purely from the keys?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3425#issuecomment-385088990:24,clear,clearly,24,https://hail.is,https://github.com/hail-is/hail/pull/3425#issuecomment-385088990,2,['clear'],['clearly']
Usability,"Ah, you're totally right, this is unnecessary. I'm looking at a pipeline: split_multi, sampleqc. There wasn't a clear indication in the WebUI Spark wasn't recomputing this (it isn't shown as a green dot like persist), but after the job is complete, the shuffle is marked as ""skipped"" and wasn't recomputed. I don't know how long intermediate shuffle results are kept around or if/when they are flushed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1814#issuecomment-301566601:112,clear,clear,112,https://hail.is,https://github.com/hail-is/hail/pull/1814#issuecomment-301566601,2,['clear'],['clear']
Usability,Ah. One of them is the region.clear bug rear'ing its head in a new form. At least for that one I know roughly where to look.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3414#issuecomment-383178762:30,clear,clear,30,https://hail.is,https://github.com/hail-is/hail/pull/3414#issuecomment-383178762,2,['clear'],['clear']
Usability,"Ahh, hmm. Pylint agrees with me that this isn't Kosher:; ```; /hailtop/batch/backend.py:44:8: W0107: Unnecessary pass statement (unnecessary-pass); /hailtop/batch/backend.py:47:0: W0223: Method 'close' is abstract in class 'Backend' but is not overridden (abstract-method); ```. We've generally heeded pylint's advice even if it clashes with our intuition.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9191#issuecomment-667227984:346,intuit,intuition,346,https://hail.is,https://github.com/hail-is/hail/pull/9191#issuecomment-667227984,2,['intuit'],['intuition']
Usability,Akhil is trying to run `ld_prune` and it fails on a matrix table with these dimensions:. 55k samples; 1.9 million variants; r_2 = 0.1. A run with r_2 = 0.2 succeeded. I'm concerned that ld_prune pervasively forgets to clear its,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6883:218,clear,clear,218,https://hail.is,https://github.com/hail-is/hail/issues/6883,1,['clear'],['clear']
Usability,"All that messy state twiddling is because Scala's `Iterator` is the wrong model for most things we use it for, which is why I made `FlipbookIterator`. Using that, what you have would become; ```scala; private class BgenRecordStateMachine(; ctx: RVDContext,; p: BgenPartition,; settings: BgenSettings; ) extends StateMachine[RegionValue] {; private[this] val bfis = p.makeInputStream; private[this] val rv = RegionValue(ctx.region); private[this] val rvb = ctx.rvb; ; def isValid: Boolean = p.isValid; def value: RegionValue = rv; def advance() { p.advance(); findNextVariant() }; private def findNextVariant() {; // same as existing advance(), but without advancing p; }. findNextVariant() // make sure iterator is initialized in first valid state; }; ```; giving `BgenPartition` a `FlipbookIterator` style interface, with `isValid`, `value`, and `advance()` instead of `hasNext()` and `next()`. Then to create a new iterator `FlipbookIterator(new BgenRecordStateMachine(...))`. But honestly, what you had was clear enough, so if you benchmarked and the allocation isn't an issue, you should do whatever you find most readable. I've been conditioned to avoid `Option` in low-level code, but I don't have a good intuition for when it is or isn't actually a problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3893#issuecomment-404156507:1010,clear,clear,1010,https://hail.is,https://github.com/hail-is/hail/pull/3893#issuecomment-404156507,4,"['clear', 'intuit']","['clear', 'intuition']"
Usability,"Allocate a fixed stack, as it was the simplest thing I could do. 128 stack; slots should be more than enough for this implementation as it requires one; stack slot per level of the tree. There are many improvements that can be made here, but hopefully this should; unblock some amount of the method splitting work.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8847:38,simpl,simplest,38,https://hail.is,https://github.com/hail-is/hail/pull/8847,1,['simpl'],['simplest']
Usability,"Alright, I've addressed all of the above, you were right I was able to move things up to PContainer and simplify some of the code there. I didn't do the one decorator to test cxx and java in this PR because the cxx shape test ended up using some things I haven't implemented on jvm side yet so for now I just made a separate test. I'll add that in a separate PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6874#issuecomment-523600895:104,simpl,simplify,104,https://hail.is,https://github.com/hail-is/hail/pull/6874#issuecomment-523600895,2,['simpl'],['simplify']
Usability,"Alright, so. 1. If you `await`, call `exception`, or call `result` on a cancelled task, you receive a `CancelledError`. 2. A cancelled task is not necessarily done. The task could catch the `CancelledError` and do something, including raise a different exception (e.g. because a resource close failed). 3. Nested try-finally sucks. This PR adds `_cleanup_future` which:. 1. Cancels the future. 2. Waits for the future to receive its cancellation and then terminate. 3. Checks if the future is cleanly cancelled (in which case there is nothing more for us to do). 4. Retrieves any present exceptions from a not-cancelled (but done!) future. We then use this function, in combination with exit stacks, to simply and cleanly manage exceptions. I also added some missing retry_transient_errors invocations.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14347:703,simpl,simply,703,https://hail.is,https://github.com/hail-is/hail/pull/14347,1,['simpl'],['simply']
Usability,"Alright, think names are clear now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8867#issuecomment-634788030:25,clear,clear,25,https://hail.is,https://github.com/hail-is/hail/pull/8867#issuecomment-634788030,2,['clear'],['clear']
Usability,Also converted style guide to markdown.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/513:21,guid,guide,21,https://hail.is,https://github.com/hail-is/hail/pull/513,1,['guid'],['guide']
Usability,"Also included useful changes that made it possible to diagnose and fix this problem including:. - No longer dropping metrics for test namespaces. I checked the prometheus disk and we have plenty of space to add these additional metrics. Very useful for diagnosing test time latencies.; - Add prometheus scraping for envoy pods. Gives us many great metrics like number of 2xx, 3xx, 4xx and 5xx requests per upstream, rate limit enforcement, even time until the cert expires; - Made `Connection reset` a retry-once error. A connection reset can sometimes be indistinguishable from non-transient errors when the client is not able to inspect the response code before the reset clears the TCP buffer. We take multiple consecutive resets to mean an intentional action from the server indicating that the client is doing something wrong and retrying will not help. I have put off adding gzip compression to gateway in this PR. It was working fine with all of our services except for grafana, in which it was messing up the websocket connection for some reason. I'll dig into that separately.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12425:674,clear,clears,674,https://hail.is,https://github.com/hail-is/hail/pull/12425,1,['clear'],['clears']
Usability,Also remove undocumented fileDate header entry in exportvcf.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/512:12,undo,undocumented,12,https://hail.is,https://github.com/hail-is/hail/pull/512,1,['undo'],['undocumented']
Usability,"Also when there is a binding outside the tiebreaker used in the tiebreaker it fails in python. The error is very inscrutable, but it simply does not work.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12295#issuecomment-1431843216:133,simpl,simply,133,https://hail.is,https://github.com/hail-is/hail/pull/12295#issuecomment-1431843216,2,['simpl'],['simply']
Usability,"Also, interesting to note: . Home page (with menu bar, dark icon, not logged in): 1.5KB .gz . Logged in: 3.1KB. Bundle size: on order of 100KB. However, 30% of this is the auth0 client library; we can modify it to save space. I've commented on an issue with some light guidance on how to save 5.5KB of that. Effectively 70KB for React + React-Dom + Webpack tooling + all page js compares quite favorably with a jquery-only solution, while being faster than jQuery (https://github.com/jonmiles/react-performance-tests, https://medium.com/thothzocial-engineering/rendering-speed-performance-challenge-with-famous-front-end-framework-196c876a68af), far easier to manage, and with a much large ecosystem (and jquery-only solution would do nothing for universal rendering). The React side should drop this year substantially. They are also interested in writing a compiler to completely remove the vdom, compiling to optimized javascript or maybe web assembly. That may be something interesting to us as well.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-454608700:269,guid,guidance,269,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-454608700,2,['guid'],['guidance']
Usability,"Also, thanks for that detailed write up. That was incredibly clear and instructive.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561#issuecomment-615210085:61,clear,clear,61,https://hail.is,https://github.com/hail-is/hail/pull/8561#issuecomment-615210085,2,['clear'],['clear']
Usability,"Am I strange in that I want to name something what it is (ci, batch, etc.) rather than give everything codenames? The purpose of codenames is to hide and obscure, you know. I think this should be called tutorial. And when it becomes a notebook service, notebook. And when it becomes the Hail service, it should just be the main website. The landing page should be password protected. We should think about whether we want to collect additional information there (e.g. email), although for now I don't think we need to, as everyone who signed up for the next tutorial filled out a questionnaire. I'm getting proxy timeouts. We need an ready endpoint and something on the client side to poll and redirect. Actually, awesome if it doesn't poll but uses, say, websockets, and the server watches the pod for a notification for k8s (or does this and also polls, which seems to be our standard pattern). Should we have an auto-scaling non-preemptible pool and schedule these there? If we do that, to optimize startup time, we should have imagePullPolicy: Never and then pull the image on startup and push it on update. When do you reap jupyter pods? jupyterhub has a simple management console that lets you shut down notebooks. > figure out how to teach flask url_for to use a root other than /. I don't think you can do this dynamically using headers. Blueprints seem to be the answer in Flask: https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes/18969161#18969161. Is there a reason you didn't make it a subdomain? I thought we decided we preferred that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576#issuecomment-431037869:1160,simpl,simple,1160,https://hail.is,https://github.com/hail-is/hail/pull/4576#issuecomment-431037869,2,['simpl'],['simple']
Usability,And we should clearly document what we've implemented so there is no ambiguity.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/313#issuecomment-212074652:14,clear,clearly,14,https://hail.is,https://github.com/hail-is/hail/issues/313#issuecomment-212074652,2,['clear'],['clearly']
Usability,"Another (simpler) check that I think will produce a `ClassCastException` :. ``` scala; eval[Int]("""""" (if (true) 0 else 0.toLong).toInt """""" ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/748#issuecomment-245384057:9,simpl,simpler,9,https://hail.is,https://github.com/hail-is/hail/pull/748#issuecomment-245384057,2,['simpl'],['simpler']
Usability,"Another set of eyes on this would be great. My current thoughts on this:. I only looked at the failure in PCA. I was never able to reproduce. My next step to try to reproduce was to run PCA on Lindo's full dataset on dataproc (can't use batch because the error is in spark PCA). I did look carefully through the stack trace, trying to understand what could possibly be happening. The number 177860 from the error isn't either matrix dimension, which is 210234 by 8893. Everything in `org.apache.spark.mllib.linalg.EigenValueDecomposition$.symmetricEigs(EigenValueDecomposition.scala:106)` is independent of the number of rows, so only the number 8893 of cols should be relevent. I wrote a simple test to execute spark PCA with 8893 rows in scala, so I could step through with a debugger:; ```scala; var mt = rangeMatrix(10000, 8893); mt = MatrixMapEntries(mt, InsertFields(Ref(""g"", mt.typ.entryType), Seq(""a"" -> F64(1)))); val t = MatrixToTableApply(mt, PCA(""a"", 10, false)); val n = TableToValueApply(t, ForceCountTable()); assertEvalsTo(n, 8893L); ```; The array `v` in `symmetricEigs` has length 177860 = 8893*20, and I didn't find anything else with that size. The only line I could find that could generate an exception that looks like this is line 555 of `dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd`; ```scala; public void dsaupd(org.netlib.util.intW ido, String bmat, int n, String which, int nev, org.netlib.util.doubleW tol, double[] resid, int offsetresid, int ncv, double[] v, int offsetv, int ldv, int[] iparam, int offsetiparam, int[] ipntr, int offsetipntr, double[] workd, int offsetworkd, double[] workl, int offsetworkl, int lworkl, org.netlib.util.intW info) {; if (debug) System.err.println(""dsaupd"");; checkArgument(""DSAUPD"", 2, lsame(""I"", bmat) || lsame(""G"", bmat));; checkArgument(""DSAUPD"", 3, n >= 0);; checkArgument(""DSAUPD"", 4, lsame(""LA"", which) || lsame(""SA"", which) || lsame(""LM"", which) || lsame(""SM"", which) || lsame(""BE"", which));; checkArgument(""DSAUPD"", 5, 0 < ne",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313:689,simpl,simple,689,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313,2,['simpl'],['simple']
Usability,"Another very simple pipeline reported https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/zip.3A.20length.20mismatch . We can get access to these files via Sam B. ```python3; context_mis_freq_ht = hl.read_table(""gs://epi25/misc-data/gnomAD_v4/grch38_context_vep_annotated.v105.prefiltered.missense_freq_ensp.ht""); ensp2uniprot_ht = hl.import_table(""gs://epi-mis-3d/misc/ensp2uniprot_mart_export.ensp2uniprot.txt""). context_mis_freq_ht = context_mis_freq_ht.key_by(""ensp""); ensp2uniprot_ht = ensp2uniprot_ht.key_by(""ensp""). context_mis_freq_ht = context_mis_freq_ht.annotate(; uniprot = ensp2uniprot_ht[context_mis_freq_ht.ensp].uniprot); ```. notice that the error is removed if you instead use:; ```python3; context_mis_freq_ht = hl.read_table(""gs://epi25/misc-data/gnomAD_v4/grch38_context_vep_annotated.v105.prefiltered.missense_freq_ensp.ht""); ensp2uniprot_ht = hl.import_table(""gs://epi-mis-3d/misc/ensp2uniprot_mart_export.ensp2uniprot.txt""). context_mis_freq_ht = context_mis_freq_ht.key_by(""ensp""); ensp2uniprot_ht = ensp2uniprot_ht.key_by(""ensp""). context_mis_freq_ht = context_mis_freq_ht.join(ensp2uniprot_ht,'left'). ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13486#issuecomment-1883607858:13,simpl,simple,13,https://hail.is,https://github.com/hail-is/hail/issues/13486#issuecomment-1883607858,2,['simpl'],['simple']
Usability,Apologies for the delay in addressing the feedback. Had some urgent projects to attend to. Here are the changes you've suggested. Let me know if there's anything else I can do to help with this PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12065#issuecomment-1243163758:42,feedback,feedback,42,https://hail.is,https://github.com/hail-is/hail/pull/12065#issuecomment-1243163758,2,['feedback'],['feedback']
Usability,"Apologies for the size, this PR got a bit out of hand. Let me know if you want me to try to break it up. Changes:; - Use custom status for pods, stored in pod and job tables as json. See Pod.status and Container.status in worker.py for the format. Example at the end. Note, ""container_statuses"" items have a field ""container_status"", because container is used in two ways: as a substep of a pod/job, and as docker container. My last renaming proposal got shot down, but we clearly need to improve this in a later PR.; - Heavily reworked worker.py. I believe this fixes https://github.com/hail-is/hail/issues/7350. The main design idea is to having all state creation and cleanup in Pod.run and Container.run.; - worker: Just support pods/status and pods/log, not container level status or logs.; - Pod now writes final status, not containers. Individual containers write their logs.; - I time all the steps of the Pod container (creating, starting, running, uploading log, etc.) with a timing called ""runtime"" which is how long the docker container itself took to start/run. That's usually 4-6 seconds. However, if you log into a machine and run `docker run --rm ubuntu:18.04 echo hi` it takes 1-2 seconds. It would be good to find out where the extra 3-4 seconds are coming from (I feel like @jigold might have some insight into this. Comparing our container config to the docker command line's might be useful here.); - Stop using (value, err) style exception handling. I think we should be able to design this with very little explicit exception handling, mainly in critical blocks to maintain the program invariants.; - Pods can have error status in 1 of 3 ways: the pod itself failed (e.g. couldn't read k8s secrets), one of the pod containers error out (e.g. pull failed due to invalid image), and the docker container finished but the final container status had an ""Error"" field. Next step is to remove pods and merge the pod and job tables. ```; {; ""name"": ""batch-2-job-1"",; ""batch_id"": 2,; ""j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7354:473,clear,clearly,473,https://hail.is,https://github.com/hail-is/hail/pull/7354,1,['clear'],['clearly']
Usability,"Apparently, creating a zip file of all our dependencies and the Hail code takes ~30s. This change skips the shadow JAR for local development. We still need a shadow JAR to produce a shareable wheel file; however, when doing local development, we can simply tell Py4J (and the JVM) where to find our dependencies class files. Also notice that I made install-editable non-PHONY. It need not be PHONY as long as we can reliably determine if `hail/python` is the pip-installed version. To do so, we simply check if the `__init__.py` at the root of the pip package is newer than when we last installed. If its newer, then either:; 1. We edited `__init__.py`, or; 2. The pip location of Hail has changed since we last ran install-editable. I also deleted eggs because nobody uses eggs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13639:250,simpl,simply,250,https://hail.is,https://github.com/hail-is/hail/pull/13639,2,['simpl'],['simply']
Usability,"Are you working with another branch at the same time in dev? If not, I feel like `hailctl dev deploy -b jigold:region-job-queue-fast-ci -s test_batch,test_hailtop_batch -e deploy_batch` would be a faster feedback loop and not take up a spot in the PR queue",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12263#issuecomment-1267535507:204,feedback,feedback,204,https://hail.is,https://github.com/hail-is/hail/pull/12263#issuecomment-1267535507,2,['feedback'],['feedback']
Usability,"As I mentioned, I think this, plus KinshipMatrix and LDMatrix are getting lost in the domain-specific details. I suggest the following structure:; - an abstract Python `Matrix` class for numeric matrices. This should have (at least) three implementations: local, indexed-row and block. It should have read/write methods. It should support at least basic operations: *, +, -. They might not all be supported on all combination of implementations. There should be operations for converting between them. @danking is working on freeing us from Spark matrices and building on Breeze. You might coordinate here.; - a `Vector` class; - a `KeyedMatrix` which has row and column keys with schemas, or possibly a SymmetricKeyedMatrix to start if that is all we need (e.g. for Kinship and LD). This should again have read/write.; - then Eigen is just a KeyedMatrix with a Vector; - I'd nuke Kinship and LD, or if it is necessary to keep n{Samples, Variants}Used, it should be a simple wrapper class with the integer value and the underlying keyed matrix. Get the structure in place to start, don't worry so much about documentation. The user-facing part should be pretty thin/lightweight.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2160#issuecomment-326643889:968,simpl,simple,968,https://hail.is,https://github.com/hail-is/hail/pull/2160#issuecomment-326643889,2,['simpl'],['simple']
Usability,As I started to get attempt_ids working in the DB it seemed simpler to go with your approach. I implemented that instead.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8398#issuecomment-607436509:60,simpl,simpler,60,https://hail.is,https://github.com/hail-is/hail/pull/8398#issuecomment-607436509,2,['simpl'],['simpler']
Usability,"As part of our work with generating All of Us datasets, we needed to copy around a million gcs objects. Our `Copier` infrastructure 'should' be able to handle that, but it kept falling with robustness issues. What finally worked was using GCS's [rewrite](https://cloud.google.com/storage/docs/json_api/v1/objects/rewrite) api. This allowed us to copy data without reading it, allowing the copies to complete in a fraction of the time while also reducing bandwidth needs. There are two components to this:; 1. Research what specific APIs we can take advantage of; 2. Update our code to use them when we can, for the `Copier`, and the new sync tool (#14248). Here's the code I used for making the rewrite requests for merging a set of matrix tables together, the progress bar code was for visibility. ```python3; async def rewrite(; gfs: GoogleStorageAsyncFS,; src: str,; dst: str,; progress: Optional[rich.progress.Progress] = None,; file_tid: Optional[rich.progress.TaskID] = None,; requests_tid: Optional[rich.progress.TaskID] = None,; ):; assert (progress is None) == (file_tid is None) == (requests_tid is None); src_bkt, src_name = gfs.get_bucket_and_name(src); dst_bkt, dst_name = gfs.get_bucket_and_name(dst); if not src_name:; raise IsABucketError(src); if not dst_name:; raise IsABucketError(dst); client = gfs._storage_client; path = (; f'/b/{src_bkt}/o/{urllib.parse.quote(src_name, safe="""")}/rewriteTo'; f'/b/{dst_bkt}/o/{urllib.parse.quote(dst_name, safe="""")}'; ); kwargs = {'json': '', 'params': {}}; client._update_params_with_user_project(kwargs, src_bkt); response = await retry_transient_errors(client.post, path, **kwargs); if progress is not None:; progress.update(requests_tid, advance=1); while not response['done']:; kwargs['params']['rewriteToken'] = response['rewriteToken']; response = await retry_transient_errors(client.post, path, **kwargs); if progress is not None:; progress.update(requests_tid, advance=1); if progress is not None:; progress.update(file_tid, advance=1)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14601:761,progress bar,progress bar,761,https://hail.is,https://github.com/hail-is/hail/issues/14601,1,['progress bar'],['progress bar']
Usability,"Assigned Tim since he has looked at this a bit, open to feedback from whoever though. . Admittedly, there is still a good amount of white space on second page right hand side, and the bottom of the first page could be condensed to buy us more space, but I want to publish what's currently here and take a break from working on it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7940:56,feedback,feedback,56,https://hail.is,https://github.com/hail-is/hail/pull/7940,1,['feedback'],['feedback']
Usability,"Assigning @tpoterba since he (and cotton) have the most context to review this. A few preliminaries:. 1. I noticed the proxy headers were not quite right when you're testing this without SSL or on some non-standard port. `$host` does not include the port, `$http_host` does. `$scheme` returns `http` or `https` depending on how the user connected to gateway; 2. The admin privilege check was too restrictive, if `delete_worker_pod` is called by `/new` there's no need to check admin privs; 3. I realized that the timeout logic wasn't quite right because a misconfigured gateway (I was testing with a broken gateway config) will return 5xx codes, but that doesn't mean the server is alive. We probably should error here, but I'm hesitant to add new error modes so close to a tutorial. Ok, how does this work? Basically, if the gateway cannot connect to the notebook pod, we intercept the error and redirect the user to the ""create new notebook"" webpage. That webpage deletes whatever remains of the users previous notebook pod & service. Here are the pieces:. 1. `recursive_error_pages on;` the internet suggests that without this we cannot use `error_page` with an ""internal"" rule (the `@` rules are internal rules that users cannot directly access); 2. `proxy_connect_timeout` defaults to 60s which is a shit user experience if your pod dies. Honestly, I might set this to 100ms. This is all inside a datacenter.; 3. `proxy_intercept_errors` permits us to use `error_page` with 5xx errors from failing to connect to the proxy. ---. I tested this with a pile of hacks to deploy this into an anonymous namespace in `vdc`. I'm not ready to PR those changes, they need a clean up before others use them. Sometime next week I hope to get that in. Getting it requires some restructuring of `vdc/` and `gateway/` to be more modular.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4974:1310,user experience,user experience,1310,https://hail.is,https://github.com/hail-is/hail/pull/4974,1,['user experience'],['user experience']
Usability,"At some point, we should think about how to improve the discoverability and machine-verifiability of our APIs. Currently the tightest type of job log is rather complex. If the performance is OK, I think we should move towards classes that define the request and response types of each call. ---. The main difference is `hail-pip-install` having `retry`. If pip exits with a non-zero exit code, we'll just rerun the command exactly, at most four more times. This mitigates missing retry logic in `pip` itself. For example, [this job](https://ci.hail.is/batches/167314/jobs/27) failed because pip encountered a connection reset while downloading a file. Ideally, pip would simply retry the download. Since we don't control the pip source code, I use a retry that treats all of pip as a black box. There's definitely a failure mode: if you specify a package that doesn't exist, pip will error five times in a row and take ~30 seconds before the retry logic gives up. I'm OK with this because pip should basically never fail for legitimate reasons.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9906#issuecomment-775241278:671,simpl,simply,671,https://hail.is,https://github.com/hail-is/hail/pull/9906#issuecomment-775241278,2,['simpl'],['simply']
Usability,Auth gateway: simply adds project deps,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5362:14,simpl,simply,14,https://hail.is,https://github.com/hail-is/hail/pull/5362,2,['simpl'],['simply']
Usability,"Autodoc from type hints [broken intermediate, meant for feedback]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3156:56,feedback,feedback,56,https://hail.is,https://github.com/hail-is/hail/pull/3156,2,['feedback'],['feedback']
Usability,"BTW, this is an extremely awesome change. I didn't think it would be so simple!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11771#issuecomment-1100420864:72,simpl,simple,72,https://hail.is,https://github.com/hail-is/hail/pull/11771#issuecomment-1100420864,2,['simpl'],['simple']
Usability,"Bah, fixed. There was some weird grouping going on in the svgs that was causing the PNG conversion to do something weird, so I simplified all the svgs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9382#issuecomment-684992756:127,simpl,simplified,127,https://hail.is,https://github.com/hail-is/hail/pull/9382#issuecomment-684992756,2,['simpl'],['simplified']
Usability,"Banning versions completely is a little tricky because the user can specify a JAR url directly instead of a version. JARs don't currently have a simple way to report pip version to the worker, though we could cook something up. We could also just delete the old JARs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12941#issuecomment-1528389159:145,simpl,simple,145,https://hail.is,https://github.com/hail-is/hail/pull/12941#issuecomment-1528389159,2,['simpl'],['simple']
Usability,"Based on @bw2 suggestions to make it clear where the limits are and more interpretable storage plots:. <img width=""681"" alt=""Screen Shot 2023-01-24 at 12 36 16 PM"" src=""https://user-images.githubusercontent.com/1693348/214366577-bdbc49a0-478a-4f72-bf13-c6dfb54a82d4.png"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12617:37,clear,clear,37,https://hail.is,https://github.com/hail-is/hail/pull/12617,1,['clear'],['clear']
Usability,"Based on feedback from Maryam, this helps users use VEP correctly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8342:9,feedback,feedback,9,https://hail.is,https://github.com/hail-is/hail/pull/8342,1,['feedback'],['feedback']
Usability,"Basically this is what CalculateGenotypePosteriors of GATK does. ([link](https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_variantutils_CalculateGenotypePosteriors.php)) In common variant analysis, we need to improve GQ calculation based on a given panel, say, 1000 genomes panel. I see this module a common practice in variant QC for common variant analysis (GWAS/eQTL), so hope you can add this as a part of Hail. Thanks.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/332:109,guid,guide,109,https://hail.is,https://github.com/hail-is/hail/issues/332,1,['guid'],['guide']
Usability,"Batch currently only supports a single container with the name default. This change encodes this requirement in the create_job endpoint. A better solution is to change the API to not accept multiple containers or name parameters, but this is a simpler fix. resolves #4773",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5073:244,simpl,simpler,244,https://hail.is,https://github.com/hail-is/hail/pull/5073,1,['simpl'],['simpler']
Usability,"Batch page shows max 50 jobs paginated, with next page button. Search box supports search with a simple language of terms:; - k=v - match jobs with attribute key k and value v; - has:k - match jobs with attribute k, any value; - state - match jobs with the corresponding states. Search state terms are lower case (unlike actual job states, which I plan to change) and the recognized state terms are:. ```; state_query_values = {; 'pending': ['Pending'],; 'ready': ['Ready'],; 'running': ['Running'],; 'live': ['Ready', 'Running'],; 'cancelled': ['Cancelled'],; 'error': ['Error'],; 'failed': ['Failed'],; 'bad': ['Error', 'Failed'],; 'success': ['success'],; 'done': ['Cancelled', 'Error', 'Failed', 'Success']; }; ```; as you can see, some state search terms, like done, match multiple job states. ; - !term - match jobs that don't match term. To select specific names, you can do `name=foo`. Next steps:; - Make the corresponding changes to the API so you can iterate paginated through all jobs in a batch.; - Make batches page paginated, too.; - Help information about the search syntax.; - We'll probably want to order by fields other than just id.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7635:97,simpl,simple,97,https://hail.is,https://github.com/hail-is/hail/pull/7635,1,['simpl'],['simple']
Usability,Be clear we need a scratch folder not a scratch bucket.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5401:3,clear,clear,3,https://hail.is,https://github.com/hail-is/hail/pull/5401,1,['clear'],['clear']
Usability,"Because node selectors are ""recommended"": https://kubernetes.io/docs/concepts/configuration/assign-pod-node/ ""the recommended approaches all use label selectors to make the selection."" ""nodeSelector is the simplest recommended form of node selection constraint."". The taint/toleration documentation use no such language and their suggested use cases don't match ours: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/. I'm not sure what to read into this, if anything. I had a mark set in my mind against taints since I remember reading that some scheduler features (maybe eviction or downsizing?) were disabled with taints. I can't find this in the docs anymore, so it was probably fixed (or I'm not searching hard enough?), but the bad feeling remains. I see your argument, although missing the tag means either paying too much (running a preemptible pod on a non-preemptible node) which we should discovery by monitoring the non-preemptible node workload, or we get excessive downtime on preemptions which we should notice through uptime monitoring. I'm mostly just frustrated with the autoscheduler and trying to simplify things to get it to behave reasonably before I end up writing our own.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7636#issuecomment-560696683:206,simpl,simplest,206,https://hail.is,https://github.com/hail-is/hail/pull/7636#issuecomment-560696683,4,['simpl'],"['simplest', 'simplify']"
Usability,"Because that won't work at all, because the input file name expected by `gatk IndexFeatureFile` won't exist. But perhaps you meant to connect the unrelated filenames via something like. ```; …; bgzip -c {j.tsv_counts} > {j.counts['tsv.gz']}; …; ```. Reasons for not doing that would include:. 1. Filename extensions are significant to GATK, so I would not trust `SubCommand` to write the output file in the right format if the filename did not have the expected extension. (This could be ameliorated via `j.tsv_counts.set_extension`.). 2. Using bgzip with `-c … >` is not its natural mode of operation, so is more likely to encounter bugs than the more typical `bgzip filename` invocation. (For example, plain gzip burns the input filename into the compressed file's header, so the redirection version produces different results from the typical invocation for gzip; bgzip does not embed the filename but the change may have other effects. For example, bgzip's error checking (e.g. in disk full situations) may well be more complete in the typical invocation than when writing to standard output.). It is also less clear than the straightforward invocation, so using this would be a hack. 4. The resulting code is IMHO overall less clear than the original version in which the resource group models the relationship between all three filenames. If Hail Batch is a well-rounded orthogonal API, then that code ought to work too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13191#issuecomment-1599478181:1115,clear,clear,1115,https://hail.is,https://github.com/hail-is/hail/issues/13191#issuecomment-1599478181,4,['clear'],['clear']
Usability,"Before ndarrays, the two choices for children of `ValueToBlockMatrix` were array or float. This simplify rule hadn't been updated to reflect that ndarrays were now an option, so it was falling through to the float case when it saw an ndarray. . By fixing this, I've gotten `test_paired_elementwise_ops` to work on lowered backends.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10481:96,simpl,simplify,96,https://hail.is,https://github.com/hail-is/hail/pull/10481,1,['simpl'],['simplify']
Usability,"Before we can simplify the binding structure, we need to stop duplicating it all over the place. This PR rewrites `FreeVariables` so that it no longer needs special logic for particular nodes, hard coding binding structure (redundantly). To do this, it takes advantage of the new `Bindings`, which operates on a `GenericBindingEnv` interface. It adds a new implementation of this interface specifically for computing free variables, then simply does a generic traversal of the IR using this custom binging environment. While I find the new implementation far simpler and more obviously correct than the old, I do expect it to further simplify once I'm able to start modifying the core binding structure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14451:14,simpl,simplify,14,https://hail.is,https://github.com/hail-is/hail/pull/14451,4,['simpl'],"['simpler', 'simplify', 'simply']"
Usability,Benchmark:; ```; $ hail-bench compare /tmp/before.json /tmp/after.json; Name Ratio Time 1 Time 2; ---- ----- ------ ------; write_profile_mt 100.4% 31.130 31.249; ----------------------; Geometric mean: 100.4%; Simple mean: 100.4%; Median: 100.4%; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7934:211,Simpl,Simple,211,https://hail.is,https://github.com/hail-is/hail/pull/7934,1,['Simpl'],['Simple']
Usability,Benchmarks vs a hardcoded take-the-old-path branch:. ```; Geometric mean: 99.5%; Simple mean: 99.8%; Median: 99.5%; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7879:81,Simpl,Simple,81,https://hail.is,https://github.com/hail-is/hail/pull/7879,1,['Simpl'],['Simple']
Usability,"Better experiment below, you can see in the right hand side the computed values. Note: I don't see any visual difference between .25 and any value < 1 in safari (therefore I did not see clear evidence that safari affected line blending in a way that called for 1 / devicePixelRatio), so for the sake of not complicating this further, I want to keep .25 unless there is evidence this causes issues. Otherwise I think this issue is solved. All on low dpi device (1920*1080 tv):; ![Screenshot 2020-06-16 06 58 11](https://user-images.githubusercontent.com/5543229/84766569-095d6d00-af9f-11ea-8102-6d79eeed2aba.png); ![Screenshot 2020-06-16 06 58 28](https://user-images.githubusercontent.com/5543229/84766571-09f60380-af9f-11ea-9fe6-2fb9ae4bbe43.png); ![Screenshot 2020-06-16 06 58 45](https://user-images.githubusercontent.com/5543229/84766572-09f60380-af9f-11ea-9789-242bc3693598.png); ![Screenshot 2020-06-16 06 59 03](https://user-images.githubusercontent.com/5543229/84766573-09f60380-af9f-11ea-8a11-21c74cc0409d.png). All on high dpi display (pixel ratio 2):; <img width=""1920"" alt=""Screenshot 2020-06-16 07 04 28"" src=""https://user-images.githubusercontent.com/5543229/84766950-a5877400-af9f-11ea-8e4b-a691a1b5f5b7.png"">; <img width=""1920"" alt=""Screenshot 2020-06-16 07 01 51"" src=""https://user-images.githubusercontent.com/5543229/84766749-55101680-af9f-11ea-9a77-c7bacc79dd16.png"">; <img width=""1920"" alt=""Screenshot 2020-06-16 07 02 03"" src=""https://user-images.githubusercontent.com/5543229/84766751-55a8ad00-af9f-11ea-8e49-3c68f588fb0f.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8964#issuecomment-644692798:186,clear,clear,186,https://hail.is,https://github.com/hail-is/hail/pull/8964#issuecomment-644692798,2,['clear'],['clear']
Usability,"Broke AltAllele and Variant each into an interface with a concrete and a region-value implementation. Decided in favor of allocation per-variant (the array of alleles) for simplicity. Had to change a few field references to method calls because `foo(0)` doesn't work when `foo` is a fake-field, it must be `foo()(0)`. I kept `ArrayView` since it does one simple job well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2441:172,simpl,simplicity,172,https://hail.is,https://github.com/hail-is/hail/pull/2441,2,['simpl'],"['simple', 'simplicity']"
Usability,"Btw, I actually don't understand how one would use this function (not clear to me from the docs nor the test)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8865#issuecomment-641489296:70,clear,clear,70,https://hail.is,https://github.com/hail-is/hail/pull/8865#issuecomment-641489296,2,['clear'],['clear']
Usability,"Bumps [aiodocker](https://github.com/aio-libs/aiodocker) from 0.17.0 to 0.21.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiodocker/releases"">aiodocker's releases</a>.</em></p>; <blockquote>; <h2>aiodocker 0.18.0 release</h2>; <h2>Features</h2>; <ul>; <li>Improve the error text message if cannot connect to docker engine. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/411"">#411</a>)</li>; <li>Implement docker exec protocol. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/415"">#415</a>)</li>; <li>Implement container commit, pause and unpause functionality. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/418"">#418</a>)</li>; <li>Implement auto-versioning of the docker API by default. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/419"">#419</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiodocker/blob/master/CHANGES.rst"">aiodocker's changelog</a>.</em></p>; <blockquote>; <h1>0.21.0 (2021-07-23)</h1>; <h2>Bugfixes</h2>; <ul>; <li>Use ssl_context passsed to Docker constructor for creating underlying connection to docker engine. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/536"">#536</a>)</li>; <li>Fix an error when attach/exec when container stops before close connection to it. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/608"">#608</a>)</li>; </ul>; <h1>0.20.0 (2021-07-21)</h1>; <h2>Bugfixes</h2>; <ul>; <li>Accept auth parameter by <code>run()</code> method; it allows auto-pulling absent image from private storages. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/295"">#295</a>)</li>; <li>Fix passing of JSON params. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/543"">#543</a>)</li>; <li>Fix issue wit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11537:644,pause,pause,644,https://hail.is,https://github.com/hail-is/hail/pull/11537,1,['pause'],['pause']
Usability,"Bumps [boto3](https://github.com/boto/boto3) from 1.26.7 to 1.26.17.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.26.17</h1>; <ul>; <li>bugfix:dynamodb: Fixes duplicate serialization issue in DynamoDB BatchWriter</li>; <li>api-change:<code>backup</code>: [<code>botocore</code>] AWS Backup introduces support for legal hold and application stack backups. AWS Backup Audit Manager introduces support for cross-Region, cross-account reports.</li>; <li>api-change:<code>cloudwatch</code>: [<code>botocore</code>] Update cloudwatch client to latest version</li>; <li>api-change:<code>drs</code>: [<code>botocore</code>] Non breaking changes to existing APIs, and additional APIs added to support in-AWS failing back using AWS Elastic Disaster Recovery.</li>; <li>api-change:<code>ecs</code>: [<code>botocore</code>] This release adds support for ECS Service Connect, a new capability that simplifies writing and operating resilient distributed applications. This release updates the TaskDefinition, Cluster, Service mutation APIs with Service connect constructs and also adds a new ListServicesByNamespace API.</li>; <li>api-change:<code>efs</code>: [<code>botocore</code>] Update efs client to latest version</li>; <li>api-change:<code>iot-data</code>: [<code>botocore</code>] This release adds support for MQTT5 properties to AWS IoT HTTP Publish API.</li>; <li>api-change:<code>iot</code>: [<code>botocore</code>] Job scheduling enables the scheduled rollout of a Job with start and end times and a customizable end behavior when end time is reached. This is available for continuous and snapshot jobs. Added support for MQTT5 properties to AWS IoT TopicRule Republish Action.</li>; <li>api-change:<code>iotwireless</code>: [<code>botocore</code>] This release includes a new feature for customers to calculate the position of their devices by adding three new APIs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:1022,simpl,simplifies,1022,https://hail.is,https://github.com/hail-is/hail/pull/12507,1,['simpl'],['simplifies']
Usability,"Bumps [com.azure:azure-core-http-netty](https://github.com/Azure/azure-sdk-for-java) from 1.13.3 to 1.13.6.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/0e7e5a9589c61bb06193c8e887b6b631679f0902""><code>0e7e5a9</code></a> Skip coverage requirements for azure-core-test (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36254"">#36254</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/67df6924e911a1cb65a7f891a05e943dd66f274f""><code>67df692</code></a> Update broken links for test proxy documentation (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36250"">#36250</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/f2a67eb377d06f9478bc5e6c8bfc282cbcaa7508""><code>f2a67eb</code></a> [Form Recognizer] Address API view feedback (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36233"">#36233</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/e618ba1f0869480eff22a0682213bf7baa42a714""><code>e618ba1</code></a> Channel health check improvement for cancelled requests (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36225"">#36225</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/d464be7d9248d773b4aa793ad71c0eca77e8c450""><code>d464be7</code></a> Prepare Core Libraries for August 2023 Release (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36239"">#36239</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/530cc4378c650f7fe7c7a528dd119993961088a3""><code>530cc43</code></a> mgmt, upgrade network 2023-04 (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36242"">#36242</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/7e3b6a5634be16f65c02523c7d84f9b5b27f4e42""><code>7e3b6a5</code></a> Update TRC API azure core (<a href=""https://redirect.github.com/Azure/azure-sdk-for-jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13591:868,feedback,feedback,868,https://hail.is,https://github.com/hail-is/hail/pull/13591,1,['feedback'],['feedback']
Usability,"Bumps [com.google.cloud:google-cloud-storage](https://github.com/googleapis/java-storage) from 2.17.1 to 2.27.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/java-storage/releases"">com.google.cloud:google-cloud-storage's releases</a>.</em></p>; <blockquote>; <h2>v2.27.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.26.1...v2.27.0"">2.27.0</a> (2023-09-12)</h2>; <h3>Features</h3>; <ul>; <li>Add new JournalingBlobWriteSessionConfig usable with gRPC transport (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2194"">#2194</a>) (<a href=""https://github.com/googleapis/java-storage/commit/8880d94c3d1a737dd4492cf66a16ba5e08633a70"">8880d94</a>)</li>; <li>Follow-up CLI Improvements (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2184"">#2184</a>) (<a href=""https://github.com/googleapis/java-storage/commit/d9859768081ea6f872097851d3e318b5bad384d9"">d985976</a>)</li>; <li>Initial CLI for SSB integration and Workload 1 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2166"">#2166</a>) (<a href=""https://github.com/googleapis/java-storage/commit/a349735e7fe108e623a330afec0c8cd608ebeef9"">a349735</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>A resumable session without a Range header should be interpreted as 0 length (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2182"">#2182</a>) (<a href=""https://github.com/googleapis/java-storage/commit/53022011d83e6a8515a5ba008fc45fc2dae39cea"">5302201</a>)</li>; <li>Update User-Agent handling for resumable uploads (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2168"">#2168</a>) (<a href=""https://github.com/googleapis/java-storage/commit/665b714f421d3c13b557d0ff71460c328c010856"">665b714</a>)</li>; <li>Update version resolution logic to be more resilient (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2169"">#2169</a>) (<a href=""https://github.co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13624:520,usab,usable,520,https://hail.is,https://github.com/hail-is/hail/pull/13624,1,['usab'],['usable']
Usability,"Bumps [commons-codec](https://github.com/apache/commons-codec) from 1.11 to 1.15.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/apache/commons-codec/blob/rel/commons-codec-1.15/RELEASE-NOTES.txt"">commons-codec's changelog</a>.</em></p>; <blockquote>; <pre><code> Apache Commons Codec 1.15 RELEASE NOTES; September 1 2020; </code></pre>; <p>The Apache Commons Codec package contains simple encoder and decoders for; various formats such as Base64 and Hexadecimal. In addition to these; widely used encoders and decoders, the codec package also maintains a; collection of phonetic encoding utilities.</p>; <p>Feature and fix release.</p>; <p>Changes in this version include:</p>; <p>New features:; o CODEC-290: Base16Codec and Base16Input/OutputStream. Thanks to Adam Retter.; o CODEC-291: Hex encode/decode with existing arrays. Thanks to Adam Retter.</p>; <p>Fixed Bugs:; o CODEC-264: MurmurHash3: Ensure hash128 maintains the sign extension bug.; Thanks to Andy Seaborne.</p>; <p>Changes:; o CODEC-280: Base32/Base64/BCodec: Added strict decoding property to control; handling of trailing bits. Default lenient mode discards them; without error. Strict mode raise an exception.; o CODEC-289: Base32/Base64 Input/OutputStream: Added strict decoding property; to control handling of trailing bits. Default lenient mode; discards them without error. Strict mode raise an exception.; o Update tests from JUnit 4.12 to 4.13. Thanks to Gary Gregory.; o Update actions/checkout from v1 to v2.3.2 <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/50"">#50</a>, <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/56"">#56</a>.; Thanks to Dependabot.; o Update actions/setup-java from v1.4.0 to v1.4.1 <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/57"">#57</a>.; Thanks to Dependabot.</p>; <p>For complete information on Apache Commons Codec, including instructions on how; to submit bug ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12385:426,simpl,simple,426,https://hail.is,https://github.com/hail-is/hail/pull/12385,1,['simpl'],['simple']
Usability,"Bumps [elasticsearch-spark-20_2.12](https://github.com/elastic/elasticsearch-hadoop) from 7.17.1 to 8.4.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.4.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12358:493,guid,guide,493,https://hail.is,https://github.com/hail-is/hail/pull/12358,4,['guid'],['guide']
Usability,"Bumps [elasticsearch-spark-20_2.12](https://github.com/elastic/elasticsearch-hadoop) from 8.4.3 to 8.6.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.6.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:492,guid,guide,492,https://hail.is,https://github.com/hail-is/hail/pull/12601,4,['guid'],['guide']
Usability,"Bumps [elasticsearch-spark-20_2.12](https://github.com/elastic/elasticsearch-hadoop) from 8.4.3 to 8.6.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.6.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html</a></p>; <h2>Elasticsearch Hadoop 8.6.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:492,guid,guide,492,https://hail.is,https://github.com/hail-is/hail/pull/12623,4,['guid'],['guide']
Usability,"Bumps [elasticsearch-spark-30_2.12](https://github.com/elastic/elasticsearch-hadoop) from 8.0.0 to 8.4.3.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/elastic/elasticsearch-hadoop/releases"">elasticsearch-spark-30_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.4.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:492,guid,guide,492,https://hail.is,https://github.com/hail-is/hail/pull/12319,4,['guid'],['guide']
Usability,"Bumps [flask-cors](https://github.com/corydolphin/flask-cors) from 3.0.8 to 3.0.9.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/corydolphin/flask-cors/releases"">flask-cors's releases</a>.</em></p>; <blockquote>; <h2>Release 3.0.9</h2>; <h3>Security</h3>; <ul>; <li>Escape path before evaluating resource rules (thanks <a href=""https://github.com/praetorian-colby-morgan""><code>@​praetorian-colby-morgan</code></a>). Prior to this, flask-cors incorrectly; evaluated CORS resource matching before path expansion. E.g. &quot;/api/../foo.txt&quot; would incorrectly match resources for; &quot;/api/*&quot; whereas the path actually expands simply to &quot;/foo.txt&quot;</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/corydolphin/flask-cors/blob/master/CHANGELOG.md"">flask-cors's changelog</a>.</em></p>; <blockquote>; <h2>3.0.9</h2>; <h3>Security</h3>; <ul>; <li>Escape path before evaluating resource rules (thanks to Colby Morgan). Prior to this, flask-cors incorrectly; evaluated CORS resource matching before path expansion. E.g. &quot;/api/../foo.txt&quot; would incorrectly match resources for; &quot;/api/*&quot; whereas the path actually expands simply to &quot;/foo.txt&quot;</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/91babb941e07a1f45636bdcb75675f13ce1503a2""><code>91babb9</code></a> Update Api docs for credentialed requests (<a href=""https://github-redirect.dependabot.com/corydolphin/flask-cors/issues/221"">#221</a>)</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/522d98936f3995480fe3132b55415d74298d6790""><code>522d989</code></a> Release version 3.0.9 (<a href=""https://github-redirect.dependabot.com/corydolphin/flask-cors/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/67c4b2cc98ae87cf1fa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10464:685,simpl,simply,685,https://hail.is,https://github.com/hail-is/hail/pull/10464,1,['simpl'],['simply']
Usability,"Bumps [idna](https://github.com/kjd/idna) from 3.6 to 3.7.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/kjd/idna/releases"">idna's releases</a>.</em></p>; <blockquote>; <h2>v3.7</h2>; <h2>What's Changed</h2>; <ul>; <li>Fix issue where specially crafted inputs to encode() could take exceptionally long amount of time to process. [CVE-2024-3651]</li>; </ul>; <p>Thanks to Guido Vranken for reporting the issue.</p>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/kjd/idna/compare/v3.6...v3.7"">https://github.com/kjd/idna/compare/v3.6...v3.7</a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/kjd/idna/blob/master/HISTORY.rst"">idna's changelog</a>.</em></p>; <blockquote>; <p>3.7 (2024-04-11); ++++++++++++++++</p>; <ul>; <li>Fix issue where specially crafted inputs to encode() could; take exceptionally long amount of time to process. [CVE-2024-3651]</li>; </ul>; <p>Thanks to Guido Vranken for reporting the issue.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/kjd/idna/commit/1d365e17e10d72d0b7876316fc7b9ca0eebdd38d""><code>1d365e1</code></a> Release v3.7</li>; <li><a href=""https://github.com/kjd/idna/commit/c1b3154939907fab67c5754346afaebe165ce8e6""><code>c1b3154</code></a> Merge pull request <a href=""https://redirect.github.com/kjd/idna/issues/172"">#172</a> from kjd/optimize-contextj</li>; <li><a href=""https://github.com/kjd/idna/commit/0394ec76ff022813e770ba1fd89658790ea35623""><code>0394ec7</code></a> Merge branch 'master' into optimize-contextj</li>; <li><a href=""https://github.com/kjd/idna/commit/cd58a23173d2b0a40b95ee680baf3e59e8d33966""><code>cd58a23</code></a> Merge pull request <a href=""https://redirect.github.com/kjd/idna/issues/152"">#152</a> from elliotwutingfeng/dev</li>; <li><a href=""https://github.com/kjd/idna/commit/5beb28b9dd77912c0dd656d8b0fdba3eb80222e7""><code>5beb28",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14464:419,Guid,Guido,419,https://hail.is,https://github.com/hail-is/hail/pull/14464,7,['Guid'],['Guido']
Usability,"Bumps [junixsocket-core](https://github.com/kohlschutter/junixsocket) from 2.3.2 to 2.6.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/kohlschutter/junixsocket/releases"">junixsocket-core's releases</a>.</em></p>; <blockquote>; <h2>junixsocket 2.6.1</h2>; <ul>; <li>Add AFSocket.checkConnectionClosed to probe connection status</li>; <li>Fix connection status checks and error handling</li>; <li>Fix bind behavior on Windows, support re-bind with reuseAddress</li>; <li>Fix and improve unit tests/selftests, remove several false-positive errors found in the wild (Azure Cloudshell/Microsoft CBL-Mariner 2.0, Amazon EC2, OpenBSD, etc.)</li>; <li>Fix SimpleTestServer demo, actually counting now to 5, not 6.</li>; <li>Make builds reproducible, align timestamps with git commit</li>; </ul>; <p>NOTE: If you're seeing unexpected errors in selftest, please verify with the attached <code>junixsocket-selftest-2.6.1-hotpatch-jar-with-dependencies.jar</code>. There may be false-positive socket timeout issues on very slow machines (e.g., qemu s390).</p>; <h2>junixsocket 2.6.0</h2>; <ul>; <li>Add support for GraalVM native-image</li>; <li>Add support for native-image selftest</li>; <li>Add support for AF_VSOCK (on Linux, and some macOS VMs)</li>; <li>Reintroduce deprecated legacy constructors for AFUNIXSocketAddress that were removed in 2.5.0.</li>; <li>Parent POM has been renamed from junixsocket-parent to junixsocket</li>; </ul>; <h2>junixsocket 2.5.2</h2>; <ul>; <li>Fix address handling in the Abstract Namespace</li>; <li>Fix support for very large datagrams (&gt; 1MB)</li>; <li>Fix InetAddress-wrapping of long addresses</li>; <li>Update Xcode support script, crossclang</li>; <li>Bump postgresql version in demo code</li>; <li>Fix dependency for custom architecture artifact</li>; </ul>; <h2>junixsocket 2.5.1</h2>; <ul>; <li>Add support for IBM z/OS (experimental, binary not included)</li>; <li>Add support for building from source on arm64",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12483:698,Simpl,SimpleTestServer,698,https://hail.is,https://github.com/hail-is/hail/pull/12483,1,['Simpl'],['SimpleTestServer']
Usability,"Bumps [jupyterlab](https://github.com/jupyterlab/jupyterlab) from 4.0.9 to 4.0.12.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyterlab/jupyterlab/releases"">jupyterlab's releases</a>.</em></p>; <blockquote>; <h2>v4.0.12</h2>; <h2>4.0.12</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.11...69079ec413cbe6d173f0a667c15802b76423ece5"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Fix jupyterlab downgrade issue on extension installation <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15650"">#15650</a> (<a href=""https://github.com/Sarthug99""><code>@​Sarthug99</code></a>)</li>; <li>Fix search highlights removal on clearing input box <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15690"">#15690</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; <li>Add scroll margin to headings for better alignment <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15703"">#15703</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; <li>Fix shortcut UI failing on filtering when empty command is given <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15695"">#15695</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; <li>Fix connection loop issue with standalone foreign document in LSP <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15262"">#15262</a> (<a href=""https://github.com/trungleduc""><code>@​trungleduc</code></a>)</li>; <li>Fix outputarea package from not detecting updates <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15642"">#15642</a> (<a href=""https://github.com/MFA-X-AI""><code>@​MFA-X-AI</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15524"">#15524</a>: Fix visual tests <a href=""https://redirect.github.com/jupyter",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:717,clear,clearing,717,https://hail.is,https://github.com/hail-is/hail/pull/14218,1,['clear'],['clearing']
Usability,"Bundling working well now:. For instance, the addition of this file, which handles the auth0 callback/sets cookie, adds only *501B* despite importing Auth and react-easy-state :tada:. The entirety of Auth dependency, react-easy-state (just observable JS properties for easy event notification), js-cookie to simplify cookie management, all other imports that are used at least 2x, poly fills for IE11 compat (promises, object.assign) + React + React-Dom is 99KB, and served in parallel with the page, so initial render doesn't incur the cost. Not bad; we can get this down a bit by removing js-cookie (2KB). ```jsx; // TODO: Replace Loading component without Material UI; import { Component } from 'react';; import Router from 'next/router';; import { view } from 'react-easy-state';; import Auth from '../lib/Auth';. class Callback extends Component {; componentDidMount() {; Auth.handleAuthenticationAsync(err => {; // TODO: notify in modal if error; if (err) {; console.error('ERROR in callback!', err);; }. Router.push('/');; });; }. render() {; return !Auth.isAuthenticated() ? <div>Loading</div> : <div>Hello</div>;; }; }. export default view(Callback);; ```. <img width=""353"" alt=""screen shot 2018-12-19 at 5 06 59 pm"" src=""https://user-images.githubusercontent.com/5543229/50251076-ad695680-03b0-11e9-88f2-28d3ff7daa33.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-448761682:308,simpl,simplify,308,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-448761682,2,['simpl'],['simplify']
Usability,"Buy it, use it, break it, fix it; Trash it, change it, mail - upgrade it; Charge it, point it, zoom it, press it; Snap it, work it, quick - erase it; Write it, cut it, paste it, save it; Load it, check it, quick - rewrite it; Plug it, play it, burn it, rip it; Drag and drop it, zip - unzip it; Lock it, fill it, call it, find it; View it, code it, jam - unlock it; Surf it, scroll it, pause it, click it; Cross it, crack it, switch - update it; Name it, read it, tune it, print it; Scan it, send it, fax - rename it; Touch it, bring it, pay it, watch it; Turn it, leave it, start - format it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2036#issuecomment-318518817:386,pause,pause,386,https://hail.is,https://github.com/hail-is/hail/pull/2036#issuecomment-318518817,2,['pause'],['pause']
Usability,"CHANGELOG: Add `hl.pgenchisq` the cumulative distribution function of the generalized chi-squared distribution. The [Generalized Chi-Squared; Distribution](https://en.wikipedia.org/wiki/Generalized_chi-squared_distribution) arises from weighted sums of sums of squares of independent normally distributed variables and is used by `hl.skat` to generate p-values. The simplest formulation I know for it is this:. w : R^n; k : Z^n; lam : R^n; mu : R; sigma : R. x ~ N(mu, sigma^2); y_i ~ NonCentralChiSquared(k_i, lam_i). Z = x + w y^T; = x + sum_i{ w_i y_i }; Z ~ GeneralizedNonCentralChiSquared(w, k, lam, mu, sigma). The non-central chi-squared distribution arises from a sum of independent normally distributed variables with non-zero mean and unit variance. The non-centrality parameter, lambda, is defined as the sum of the squares of the means of each component normal random variable. Although the non-central chi-squared distribution has a closed form implementation (indeed, Hail implements this CDF: `hl.pchisqtail`), the generalized chi-squared distribution does not have a closed form. There are at least four distinct algorithms for evaluating the CDF. To my knowledge, the oldest one is by Robert Davies:. Davies, Robert. ""The distribution of a linear combination of chi-squared; random variables."" Applied Statistics 29 323-333. 1980. The [original publication](http://www.robertnz.net/pdf/lc_chisq.pdf) includes a Fortran implementation in the publication. Davies' [website](http://www.robertnz.net/QF.htm) also includes a C version. Hail includes a copy of the C version as `davies.cpp`. I suspect this code contains undefined behavior. Moreover, it is not supported on Apple M1 machines because we don't ship binaries for that platform. It seemed to me that the simplest solution is to port this algorithm to Scala. This PR is that port. I tested against the 39 test cases provided Davies with the source code. I also added some doctests based on the CDF plots from Wikipedia. The same",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12605:366,simpl,simplest,366,https://hail.is,https://github.com/hail-is/hail/pull/12605,1,['simpl'],['simplest']
Usability,"CHANGELOG: Fix #13979, affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"". This PR upgrades google-cloud-storage from 2.29.1 to 2.30.1. The google-cloud-storage java library has a bug present at least since 2.29.0 in which simply incorrect data was returned. https://github.com/googleapis/java-storage/issues/2301 . The issue seems related to their use of multiple intremediate ByteBuffers. As far as I can tell, this is what could happen:. 1. If there's no channel, open a new channel with the current position.; 2. Read *some* data from the input ByteChannel into an intermediate ByteBuffer.; 3. While attempting to read more data into a subsequent intermediate ByteBuffer, an retryable exception occurs.; 4. The exception bubbles to google-cloud-storage's error handling, which frees the channel and loops back to (1). The key bug is that the intermediate buffers have data but the `position` hasn't been updated. When we recreate the channel we will jump to the wrong position and re-read some data. Lucky for us, between Zstd and our assertions, this usually crashes the program instead of silently returning bad data. This is the third bug we have found in Google's cloud storage java library. The previous two:. 1. https://github.com/hail-is/hail/issues/13721; 2. https://github.com/hail-is/hail/issues/13937. Be forewarned: the next time we see bizarre networking or data corruption issues, check if updating google-cloud-storage fixes the problem.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14080:296,simpl,simply,296,https://hail.is,https://github.com/hail-is/hail/pull/14080,1,['simpl'],['simply']
Usability,"CHANGELOG: Fix `RuntimeError: This event loop is already running` error when running hail in a Jupyter Notebook. Man this is really complicated. OK, so, things I learned:. 1. [asyncio will not create a new event loop if `set_event_loop` has been called even if `set_event_loop(None)` has since been called.](https://github.com/python/cpython/blob/main/Lib/asyncio/events.py#L676); 2. [asyncio will not create a new event loop in a thread other than the main thread.](https://github.com/python/cpython/blob/main/Lib/asyncio/events.py#L677); 3. `aiohttp.ClientSession` stashes a copy of the event loop present when it starts. This can cause all manner of extremely confusing behavior if you later change the event loop or use that session from a different thread. The fix, in the end, wasn't that complicated. Anywhere Hail explicitly asks for an event loop (so that we can run async code), we apply nest asyncio if the event loop is already running. Otherwise we do nothing. Nest asyncio appears to [no longer require](https://github.com/erdewit/nest_asyncio/tree/master#usage) `apply` to be called before the event loop starts running. This PR *does not* address:; 1. Hail nesting async code in sync code in async code. I think we should avoid this, but the `hailtop.fs` and `hailtop.batch` APIs, among others, need async versions before we can do that.; 2. This `aiohttp.ClientSession` nonsense. We really should take pains to ensure we create one `ClientSession` per loop and we never mix loops.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13899:162,learn,learned,162,https://hail.is,https://github.com/hail-is/hail/pull/13899,1,['learn'],['learned']
Usability,"CHANGELOG: Fix memory leak in ExportBgen. If you look a dozen or so lines under the `boundary` I added, you'll see a :. ```; it.foreach { ptr =>; val (b, d) = bpw.emitVariant(ptr); out.write(b); dropped += d; }; ```. So that thing is stepping through the iterator without freeing. The `boundary` is to do a `clear` after each read from the `it`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9006:308,clear,clear,308,https://hail.is,https://github.com/hail-is/hail/pull/9006,1,['clear'],['clear']
Usability,"CHANGELOG: Fixes #13697, a long standing issue with QoB, in which a failing partition job or driver job is not failed in the Batch UI. I am not sure why we did not do this this way in the first place. If a JVMJob raises an exception, Batch will mark the job as failed. Ergo, we should raise an exception when a driver or a worker fails!. Here's an example: I used a simple pipeline that write to a bucket to which I have read-only access. You can see an example Batch (where every partition fails): https://batch.hail.is/batches/8046901. [1]. ```python3; import hail as hl; hl.utils.range_table(3, n_partitions=3).write('gs://neale-bge/foo.ht'); ```. NB: I removed the `log.error` in `handleForPython` because that log is never necessary. That function converts a stack of exceptions into a triplet of the short message, the full exception with stack trace, and a Hail error id (if present). That triplet is always passed along to someone else who logs the exception. (FWIW, the error id indicates a Python source location that is associated with the error. On the Python-side, we can look up that error id and provide a better stack trace.). [1] You'll notice the logs are missing. I noticed this as well, it's a new bug. I fixed it in https://github.com/hail-is/hail/pull/13729.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13715:366,simpl,simple,366,https://hail.is,https://github.com/hail-is/hail/pull/13715,1,['simpl'],['simple']
Usability,"CHANGELOG: In Query-on-Batch, simple pipelines with large numbers of partitions should be substantially faster. :facepalm:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12854:30,simpl,simple,30,https://hail.is,https://github.com/hail-is/hail/pull/12854,1,['simpl'],['simple']
Usability,"CHANGELOG: Introduce `hailctl fs sync` which robustly transfers one or more files between Amazon S3, Azure Blob Storage, and Google Cloud Storage. There are really two distinct conceptual changes remaining here. Given my waning time available, I am not going to split them into two pull requests. The changes are:. 1. `basename` always agrees with the [`basename` UNIX utility](https://en.wikipedia.org/wiki/Basename). In particular, the folder `/foo/bar/baz/`'s basename is *not* `''` it is `'baz'`. The only folders or objects whose basename is `''` are objects whose name literally ends in a slash, e.g. an *object* named `gs://foo/bar/baz/`. 2. `hailctl fs sync`, a robust copying tool with a user-friendly CLI. `hailctl fs sync` comprises two pieces: `plan.py` and `sync.py`. The latter, `sync.py` is simple: it delegates to our existing copy infrastructure. That copy infastructure has been lightly modified to support this use-case. The former, `plan.py`, is a concurrent file system `diff`. `plan.py` generates and `sync.py` consumes a ""plan folder"" containing these files:. 1. `matches` files whose names and sizes match. Two columns: source URL, destination URL. 2. `differs` files or folders whose names match but either differ in size or differ in type. Four columns: source URL, destination URL, source state, destination state. The states are either: `file`, `dif`, or a size. If either state is a size, both states are sizes. 3. `srconly` files only present in the source. One column: source URL. 4. `dstonly` files only present in the destination. One column: destination URL. 5. `plan` a proposed set of object-to-object copies. Two columns: source URL, destination URL. 6. `summary` a one-line file containing the total number of copies in plan and the total number of bytes which would be copied. As described in the CLI documentation, the intended use of these commands is:. ```; hailctl fs sync --make-plan plan1 --copy-to gs://gcs-bucket/a s3://s3-bucket/b; hailctl fs sync --use",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14248:697,user-friendly,user-friendly,697,https://hail.is,https://github.com/hail-is/hail/pull/14248,2,"['simpl', 'user-friendly']","['simple', 'user-friendly']"
Usability,"CHANGELOG: Reduce latency on simple pipelines by as much as 50% by reducing decoding time. Force count essentially tests decoding because it forces decoding but then just increments a counter by one. Analysis of profile results indicates that the array inplace decoder was perhaps 50% of time, but exactly what part of decoding was unclear. I attempted many different things. I eventually settled on loop unrolling as the primary benefit. After team meeting, I applied @patrick-schultz 's advice to use bit twiddling to further improve the speed. ---. I assessed the latency using `time python3` on this file:. ```python; import hail as hl; hl.init(master='local[1]'); hl._set_flags(write_ir_files='1'); hl.read_matrix_table('/Users/dking/projects/hail-data/foo.mt')._force_count_rows(); ```. `foo.mt` is a subset of the `variant_data` from a VDS with ~80k samples, ~300k variants, stored in ~1.6GiB. 1. This PR: 34s, 33s; 2. no twiddling: 43s, 43s https://github.com/hail-is/hail/compare/main...danking:hail:unroll-64; 3. no twiddling & 8 element blocks: 37s, 38s https://github.com/hail-is/hail/compare/main...danking:hail:unroll-8; 4. `main` (`481cfc201b [query] fix backoff code (#13713)`): 68s, 69s. In YourKit, I observe that (1) reads 50-70MB/s with one core whereas (4) reads 15-35MB/s. I also assessed the 10-core latency and JIT effects:. - (1) starts at ~12s, warms to ~6s (+- 0.5s). Peak bandwidth 490MB/s.; - (4) starts at ~17s and warms up to ~11s (+- 2s). Peak bandwidth ~250MB/s. I suspect, with this PR, the multi-core speed is fast enough to saturate any of our file stores (including my laptop, which I think taps out just around ~500MB/s). Big thanks to everyone who contributed, particularly @patrick-schultz, whose suggestion to use bit-twiddling, squeezeed another 10% off the 8 element blocks.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13776:29,simpl,simple,29,https://hail.is,https://github.com/hail-is/hail/pull/13776,1,['simpl'],['simple']
Usability,"CHANGELOG: Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set to an appropriate level. This issue manifests in a variety of inscrutable ways including RemoteDisconnectedError and socket closed. See issue #13960 for details. In Dataproc versions 1.5.74, 2.0.48, and 2.1.0, Dataproc introduced [""memory protection""](https://cloud.google.com/dataproc/docs/support/troubleshoot-oom-errors#memory_protection) which is a euphemism for a newly aggressive OOMKiller. When the OOMKiller kills the JVM driver process, there is no hs_err_pid...log file, no exceptional log statements, and no clean shutdown of any sockets. The process is simply SIGTERM'ed and then SIGKILL'ed. From Hail 0.2.83 through Hail 0.2.109 (released February 2023), Hail was pinned to Dataproc 2.0.44. From Hail 0.2.15 onwards, `hailctl dataproc`, by default, reserves 80% of the advertised memory of the driver node for the use of the Hail Query Driver JVM process. For example, Google advertises that an n1-highmem-8 has 52 GiB of RAM, so Hail sets the `spark:spark.driver.memory` property to 41g (we always round down). Before aggressive memory protection, this setting was sufficient to protect the driver from starving itself of memory. Unfortunately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14066:678,simpl,simply,678,https://hail.is,https://github.com/hail-is/hail/pull/14066,1,['simpl'],['simply']
Usability,CHANGELOG: `PythonJob`s now support intermediate file resources the same as `BashJob`s. I feel like `ofile` semantics should apply the same to bash and python jobs. I don't believe this is a breaking change since `j.ofile` didn't really mean anything usable until now for python jobs IIUC.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12726:251,usab,usable,251,https://hail.is,https://github.com/hail-is/hail/pull/12726,1,['usab'],['usable']
Usability,CHANGELOG: `hailtop.aiotools.copy` will always show a progress bar when `--verbose` is passed.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11776:54,progress bar,progress bar,54,https://hail.is,https://github.com/hail-is/hail/pull/11776,1,['progress bar'],['progress bar']
Usability,"CHANGELOG: `hl.export_vcf` is now substantially faster on simple pipelines. I fell into a bit of a rabbit hole. I started off using the balding nichols model as my test dataset. I improved random number generation a bit by making `rand_unif` into a method, but eventually bailed out to focus on other improvements. I also originally used `vcf.bgz` but bgzip is quite slow and it obscured the slow parts of what I could control, i.e. hail. I finally settled on this test case run against the Spark backend:; ```; import hail as hl; hl.init(master='local[1]'); hl._set_flags(write_ir_files='1'); mt = hl.utils.range_matrix_table(n_rows=1000_000, n_cols=4_000); mt = mt.key_cols_by(s = hl.str(mt.col_idx)); mt = mt.key_rows_by(locus = hl.locus(""1"", mt.row_idx + 1), alleles = ['G', 'T']); mt = mt.annotate_entries(GT = hl.call(mt.row_idx % 2, mt.col_idx % 2)); hl.export_vcf(mt, '/tmp/foo.vcf'); ```; It generates a 15GiB file. My initial tests, which used the balding nichols model, had write times of ~8MiB/s. With all my changes, I once saw 177 MIB/s but I think that may have been a fluke. I see pretty consistent ~110MiB/s in the profiler's estimate of bandwidth to the FileOutputStream. When measured by `time python3 test.py` this script writes at ~93MiB/s. Ideally we would hit 250MiB/s (1/8th of an n1-standard-8's network bandwidth), but, considering that we have to split that bandwidth with reading in most cases, ~91 MiB/s ain't so bad. On main, this pipeline writes at 32 MiB/s. The wins in decreasing order of importance were:; 1. Use buffered I/O. All of our exporters should now use buffered I/O because I changed it in the EmitMethodBuilder. I didn't change it in HadoopFS because (a) Hail's native I/O has buffering and (b) buffering and position tracking requires work.; 2. Avoid String allocation, String to UTF8 conversion, and Array[Byte] allocation in VCF writing. In particular, for the most common types of Calls, I just return the UTF8 byte array in a switch statement.; 3. Use",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12733:58,simpl,simple,58,https://hail.is,https://github.com/hail-is/hail/pull/12733,1,['simpl'],['simple']
Usability,CHANGELOG: `hl.nd.vstack` and `hl.nd.hstack` provide clear error messages when used with incompatible matrices or with no arguments.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12636:53,clear,clear,53,https://hail.is,https://github.com/hail-is/hail/pull/12636,1,['clear'],['clear']
Usability,"CHANGELOG: early implementation of regenie. I'd like to get this basic version in and iterate. It works on local. Has a few todos and fixmes; I've seen Cotton, others use these, and they'll be gone in fairly short order, saves a bit of time over making a formal issue, for something that is clearly wip. . This looks like a scary amount of lines, but almost all of the work is held in regenie-batch.py. Example files are included in contrib/regenie/regenie, which is a redacted copy of their repo, and which is sufficient, lighter-weight than the full. When you have a chance, I'd like to discuss increasing the max capacity of the SSD (striping partitions). I want this as a fallback mechanism, when not enough memory can be allocated (lowmem). It will likely perform terribly with persistent storage. I'm happy to contribute that.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9194:291,clear,clearly,291,https://hail.is,https://github.com/hail-is/hail/pull/9194,1,['clear'],['clearly']
Usability,"CHANGELOG: remove learn more, which should not have gone in until the learn more content was finalized.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8851:18,learn,learn,18,https://hail.is,https://github.com/hail-is/hail/pull/8851,2,['learn'],['learn']
Usability,"CHANGE_LOG: ; - Added ``Job.always_copy_output`` when using the ``ServiceBackend``. The default behavior is `False` which; is a breaking change from the previous behavior to always copy output files irregardless of the job's; completion state. Thoughts on introducing this ""breaking"" change? I think it's okay and we will announce the change on Zulip. I think the benefits of getting rid of this not so intuitive behavior where we copy files despite the main container's completion state outweighs possibly breaking someone's pipeline that relied on files being there when the copy step could have failed as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11884:403,intuit,intuitive,403,https://hail.is,https://github.com/hail-is/hail/pull/11884,1,['intuit'],['intuitive']
Usability,"Can you take another look now?. I added two new fields to the jobs table to help with indexing and order bys. This should make the queries simpler and allow us to revert back to the old scheduler that Cotton wrote that was optimitzed. The regions_bits_rep is just a 0/1 for each region. So [us-east1, us-central1] could be ""1100000"". I also realized that I could aggregate the ready cores per user and then order them after unioning each user. I think this will perform better. From small tests, the autoscaler query seemed much better, but I'll want to do one last load test once you're okay with this approach.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1274632733:139,simpl,simpler,139,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1274632733,2,['simpl'],['simpler']
Usability,"Changes:; - add cpu/memory field to workshops; - simplified workshop login logic a bit: workshops_session is just workshop name, token and guest user id, userdata for workshops is id and workshop, workshop auth decorator verifies workshop is valid to before creating userdata,; - make sure to check active everywhere,",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7157:49,simpl,simplified,49,https://hail.is,https://github.com/hail-is/hail/pull/7157,1,['simpl'],['simplified']
Usability,"Changes:; - batch2: send job_spec to worker instead of kubernetes pod spec; - batch2: create containers on worker from job_spec; - move job_spec_to_k8s_pod_spec to batch, only used there now; - simplified volume handling somewhat: Volume now means docker volume, cspec has list of volume mounts. As usual, will probably need a bit of testing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7332:194,simpl,simplified,194,https://hail.is,https://github.com/hail-is/hail/pull/7332,1,['simpl'],['simplified']
Usability,"Changes:; - create a custom job spec schema for what a job means to us; - hand-rolled validator; - use in bath_client, /jobs/create endpoints in batch, batch2; - slightly changed create_job interface around volumes, docker socket and secrets, update usage; - wrote route to convert this to a k8s pod spec, use when actually creating jobs. The secret has a namespace, but it is ignored by the servers. Eventually, batch should be able to pull secrets from wherever, but needs to enforce permissions on who can use what secrets. This was a long-standing issue that I think now has a clearer path. We can get rid of the mount docker socket option by making the worker support a build (rather than run) task. The validator should really go in the server code, but it needs to be shared between batch and batch2 for now. Plan is to push this through batch2 to remove the dependence on the k8s pod serialization. When that's done, the job to pod spec routine can go into batch (and go away when CI uses batch2). Will be interested to benchmark my validator vs. the previous cerberus + k8s validation/serialization.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7313:581,clear,clearer,581,https://hail.is,https://github.com/hail-is/hail/pull/7313,1,['clear'],['clearer']
Usability,"Changes:; - four containers: setup container, main container, cleanup container, keep alive container; - cleanup container waits for an HTTP message from batch before cleaning up; - keep alive container stays alive until batch sends it an HTTP message (this prevents terminated pod GC); - split `mark_complete` into three simpler methods; - extract several parts of former `mark_complete` into named helper methods; - `LogStore.results_filename` is gone, if the logs are present, the pod has already been run",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6746:322,simpl,simpler,322,https://hail.is,https://github.com/hail-is/hail/pull/6746,1,['simpl'],['simpler']
Usability,"Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3MThjYjgyZC1jNGU3LTRlNWEtODgzZi02NjQ0NjlmYzA4MGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjcxOGNiODJkLWM0ZTctNGU1YS04ODNmLTY2NDQ2OWZjMDgwYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""718cb82d-c4e7-4e5a-883f-664469fc080a"",""prPublicId"":""718cb82d-c4e7-4e5a-883f-664469fc080a"",""dependencies"":[{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JUPYTERSERVER-6099119""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[461],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Generation of Error Message Containing Sensitive Information](https://learn.snyk.io/lesson/error-message-with-sensitive-information/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14070:3607,Learn,Learn,3607,https://hail.is,https://github.com/hail-is/hail/pull/14070,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,Clean up and simplify subgenerator code.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/467:13,simpl,simplify,13,https://hail.is,https://github.com/hail-is/hail/pull/467,2,['simpl'],['simplify']
Usability,Clear region in groupVariantsBy.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2686:0,Clear,Clear,0,https://hail.is,https://github.com/hail-is/hail/pull/2686,1,['Clear'],['Clear']
Usability,Clearly document python dependencies,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2978:0,Clear,Clearly,0,https://hail.is,https://github.com/hail-is/hail/issues/2978,1,['Clear'],['Clearly']
Usability,"Closes out the first reorg work. There are a bunch of utility methods on PBinary, but these are non-trivial to remove. There are places where it isn't clear to me that we have a PBinary instance for instance. For example,. ```scala; srvb.addString(""hello""),; ```. Would need a PString (and the fundamentalType of that)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7755:151,clear,clear,151,https://hail.is,https://github.com/hail-is/hail/pull/7755,1,['clear'],['clear']
Usability,Closing for now while I incorporate the feedback and make a working prototype.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12697#issuecomment-1450841695:40,feedback,feedback,40,https://hail.is,https://github.com/hail-is/hail/pull/12697#issuecomment-1450841695,2,['feedback'],['feedback']
Usability,Closing this in light of what we've learned about keepalive,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11876#issuecomment-1170569730:36,learn,learned,36,https://hail.is,https://github.com/hail-is/hail/pull/11876#issuecomment-1170569730,2,['learn'],['learned']
Usability,Collapse adjacent MapGlobals nodes in Simplify,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5092:38,Simpl,Simplify,38,https://hail.is,https://github.com/hail-is/hail/pull/5092,1,['Simpl'],['Simplify']
Usability,Comments addressed. Still gotta work on the verbiage to clearly explain the present of P_0.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12637#issuecomment-1411233669:56,clear,clearly,56,https://hail.is,https://github.com/hail-is/hail/pull/12637#issuecomment-1411233669,2,['clear'],['clearly']
Usability,"Conceptually, if we're not just interested in missingness, then unboxedGT is useful only in route to nNonRefAlleles (and equal to it if we've split). E.g., the simplest way to extend regression to multi-allelic is to use nNonRefAlleles...though thinking about this further, it's upsettingly asymmetric in the case where the ref allele is the minor allele, so perhaps we should just force deliberate choice of splitting, esp if we're moving toward implementing that less painfully under the hood. Or do regression per alternate allele while maintaining multi-allelic form. (edited). We currently compute nNonRefAlleles from unboxedGT through GTPair, which allocates per genotype. For example, PCA currently requires splitting, but uses nNonRefAlleles. And IBD currently requires splitting but allocates per genotype via:; ```; def countRefs(gtIdx: Int): Int = {; val gt = Genotype.gtPair(gtIdx); indicator(gt.j == 0) + indicator(gt.k == 0); ```. So it may make sense to add `unboxedNNonRefAlleles` that avoids allocation, but doesn't require splitting for these.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1314#issuecomment-276082468:160,simpl,simplest,160,https://hail.is,https://github.com/hail-is/hail/issues/1314#issuecomment-276082468,2,['simpl'],['simplest']
Usability,"Context: https://hail.zulipchat.com/#narrow/stream/300487-Hail-Batch-Dev/topic/adding.20service.20account.20name.20to.20users.20list/near/349228510. It's useful for our automation to include this in the REST response get any get user call. I don't know how testing works, if needed, could you guide me how to add tests to cover this?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12889:293,guid,guide,293,https://hail.is,https://github.com/hail-is/hail/pull/12889,1,['guid'],['guide']
Usability,"ContextRDD registered a TaskCompletionListener with Spark to close its context no matter why the task ends. But if the region in the context points to RegionMemory that is shared (has refcount > 1), this won't actually free the memory. Plus, this doesn't free any regions not created by an RVDContext. This PR removes the TaskCompletionListener from ContextRDD, and instead adds a single one to each thread-local RegionPool. This clearly ensures all off-heap memory is freed at the end of the task.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8287:430,clear,clearly,430,https://hail.is,https://github.com/hail-is/hail/pull/8287,1,['clear'],['clearly']
Usability,"Convert three foreach calls to while loops. I see about a 15% reduction in variant aggregation time. I executed. ```; hail read profile225.vds \; annotatevariants expr -c 'va.foo = gs.map(g => 1).sum()' \; exportvariants -c 'va.foo' -o 'foo.tsv'; ```. Here are the comparisons between this PR, master, and some part-solutions that I tried. We always compare to this PR. In each case, the first row of numbers is the same row of timings for this PR. The second row of numbers is the timings for the alternative. Note that converting the outer loop and the last loop, but not the inner loop, seems to be slower than master. I suspect these measurements are fairly noisy, but perhaps there's something else going on in that case. Regardless, this PR is the clear winner and we know why: `while` loops are faster than `for` loops. vs master; ```; (/ (/ (+ 49.736 50.335 48.197 51.034 47.737) 5); (/ (+ 62.9 55.362 57.100 57.815 60.5) 5)). 0.84; ```. vs inner and last only; ```; (/ (/ (+ 49.736 50.335 48.197 51.034 47.737) 5); (/ (+ 52.982 63.1 57.481 56.480 51.814) 5)). 0.88; ```. vs outer and last only; ```; (/ (/ (+ 49.736 50.335 48.197 51.034 47.737) 5); (/ (+ 74.6 69.0 55.750 69.7 68.5) 5)). 0.73; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1223:754,clear,clear,754,https://hail.is,https://github.com/hail-is/hail/pull/1223,1,['clear'],['clear']
Usability,"Core infrastructure enclosed. Opening now to enable feedback as I continue to higher level interfaces, tests, and examples.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3397:52,feedback,feedback,52,https://hail.is,https://github.com/hail-is/hail/pull/3397,1,['feedback'],['feedback']
Usability,Cosmetic. Seemed simpler overall to not take an RV to mutate. No one used this in a smart way anyway.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7259:17,simpl,simpler,17,https://hail.is,https://github.com/hail-is/hail/pull/7259,1,['simpl'],['simpler']
Usability,Could we add a specific test for compatibilty on JDK 8 and move the default forward? We're on a crash course of incompatibility with the current python3.6 / ubuntu:18.04 / Java 8 restrictions. From Oracle's pages it feels like Java 8 will simply never die...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11046#issuecomment-965471326:239,simpl,simply,239,https://hail.is,https://github.com/hail-is/hail/pull/11046#issuecomment-965471326,2,['simpl'],['simply']
Usability,Could we just change the Python to generate `ArrayRef`? Not clear to me why we use `indexArray` instead.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10119#issuecomment-786807963:60,clear,clear,60,https://hail.is,https://github.com/hail-is/hail/pull/10119#issuecomment-786807963,2,['clear'],['clear']
Usability,"Create a filter alleles command. The interface should be modeled off the current filter commands (variant, sample, genotype). One wrinkle is that to update the variant annotations, which must be done by the user, they must have access to information about what alleles were filtered. Rough sketch of the interface:. ```; ... filteralleles; --keep; -c 'va.alleleQuality[aIndex] > 0.8'; -a 'va.info.AC = aIndices.map(i => va.info.AC[i]), va.info.AN = ...'; ```. where `va.alleleQuality` is a hypothetical annotation of type `Array[Double]`. It also has a `--remove` option. `-c` is the filter condition. It has type `Boolean` and `v`, `va`, and `aIndex` in scope, where `aIndex` is the index of the allele being evaluated. `-a` is an annotation expression which updates variant annotations analogous to the `-c` argument of `annotatevariants expr`. It has `v`, `va` and `aIndices`, where `v` is the _new_ variant (so `v.altAlleles.size` is the number of alleles being kept), `va` is the old variant annotations which are being updated, and `aIndices` is a map from the new to old allele indices. Only alternate alleles should be filtered, although all indices should be 0-based, counting the reference. If no alternate alleles remain, the variant should be filtered (no monomorphic variants). Step one should be to sketch the command docs so we can get feedback on the interface. We should work with @konradjk and Monkol to make examples that handle the ExACv2 use case.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/551:1351,feedback,feedback,1351,https://hail.is,https://github.com/hail-is/hail/issues/551,1,['feedback'],['feedback']
Usability,"Create a new class `VariantDatasetCombiner` that implements a simple state; machine for running a VariantDataset combiner pipeline from start to; finish. The `VariantDatasetCombiner` structure contains pretty much everything the; old `experimental.vcf_combiner.run_combiner` method took as arguments:; `temp_path`, `output_path`, list of gvcf paths, etc.. What is new is the; addition of a `save_path` and `vds_paths`. The `save_path` is used as; a filesystem or object storage location to save the state of the; combiner so that it may be resumed. The vds paths implement the long; awaited mixed hail and gvcf inputs, that was never completed for the VCF; combiner. End users should not call `VariantDatasetCombiner.__init__`; instead preferring the free function new_combiner. The; `VariantDatasetCombiner` API is fairly simple:. * @property finished; * save: serialize the current state to save_path; * step: does the next unit of work for the combiner (described in more detail below); * run: until `finished`, calls `save` then `step` followed by one last `save`. The public api is present in 2 free functions:. * new_combiner: public VariantDatasetCombiner constructor; * load_combiner. if `new_combiner` is not given a `save_path`, it will compute one based on; the SHA-256 of it's inputs. If the file at `save_path` is present, and; a valid `VariantDatasetCombiner`, it will load it and use it, unless the; `force` argument to `new_combiner` is True. This way, every combiner has; a `save_path`. ## The `step` algorithm. If there are any gvcf paths still uncombined, they are combined; `branch_factor` at a time, using `batch_size` parallel matrix table; writes to achive good parallelism. If there is only one merged vds, and; no vds arguments remaining to be combined it is written to; `output_path`. Otherwise the new vds paths are appended to the vds list; and the vds list is sorted by number of samples. The vds paths are always kept sorted by samples and new items are only; ever added ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10892:62,simpl,simple,62,https://hail.is,https://github.com/hail-is/hail/pull/10892,3,"['resume', 'simpl']","['resumed', 'simple']"
Usability,"Create an `EType`, `EStructOfArrays`, that encodes an `array<struct{...}>` into a transposed representation (hopefully) allowing for better data compression (either specialized per field, or simply better patterns for a general purpose algorithm to find) and decoding speed. At current, this is a prototype that only supports structs where all fields are `int32`. Each field of the struct of arrays is it's own `EContainer`, so we have fine grained control over the encoding of each field.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14391:191,simpl,simply,191,https://hail.is,https://github.com/hail-is/hail/pull/14391,1,['simpl'],['simply']
Usability,"Create custom Hail Dataproc images to speed up cluster creation time: https://cloud.google.com/dataproc/docs/guides/dataproc-images. Custom dataproc images expire every 30 days so image creation will need to scheduled regularly. There should be images for 0.1, 0.2 with and without VEP.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4038:109,guid,guides,109,https://hail.is,https://github.com/hail-is/hail/issues/4038,1,['guid'],['guides']
Usability,"Creates a responsive table whose dimensions are defined on the parent (allowing child elements to be set as a percentage of that table), by setting width of the parent based on viewport. If the table exceeds that width, it will scroll, such that the elements above the table are still fixed to the flex-end position. See https://github.com/hail-is/hail/pull/7777. Narrow view (very slightly wider, because 75% of 653 is > 75% of 600, and table is in fact 653px at minimum, even when you set 600px min width):; <img width=""774"" alt=""Screenshot 2019-12-27 15 38 52"" src=""https://user-images.githubusercontent.com/5543229/71533028-73d10280-28c4-11ea-99be-bea06bc67a10.png"">. Wide view:; <img width=""1920"" alt=""Screenshot 2019-12-27 15 38 58"" src=""https://user-images.githubusercontent.com/5543229/71533029-73d10280-28c4-11ea-98ef-7b8e3afe3ca3.png"">. Table that is too wide is scrollable (wider than 1024px):; <img width=""804"" alt=""Screenshot 2019-12-27 16 09 18"" src=""https://user-images.githubusercontent.com/5543229/71532988-4be19f00-28c4-11ea-915a-1e038f179d1f.png"">; after scrolling right:; <img width=""1453"" alt=""Screenshot 2019-12-27 16 09 12"" src=""https://user-images.githubusercontent.com/5543229/71532989-4be19f00-28c4-11ea-9fbd-0270c881d085.png"">. Tested manually in browser in Firefox and Chrome.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7786:10,responsiv,responsive,10,https://hail.is,https://github.com/hail-is/hail/pull/7786,1,['responsiv'],['responsive']
Usability,"Currently `TableRead.execute` always produces a `TableValueIntermediate`, even though almost all `TableReader`s are lowerable, so could produce a `TableStageIntermediate`. This pr refactors `TableReader` to allow producing a `TableStageIntermediate` in most cases, and to make it clearer which readers still need to be lowered (only `TableFromBlockMatrixNativeReader`, `MatrixVCFReader`, and `MatrixPLINKReader`). It also deletes some now dead code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13229:280,clear,clearer,280,https://hail.is,https://github.com/hail-is/hail/pull/13229,1,['clear'],['clearer']
Usability,"Currently if there are duplicated chr:pos:ref:alt in an annotation file, for example read by `annotatevariants table`, also the variants in the vds get duplicated. This is clearly not nice. So instead think on a better behaviour. But do not just issue an error, because otherwise is a pain.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/389:172,clear,clearly,172,https://hail.is,https://github.com/hail-is/hail/issues/389,1,['clear'],['clearly']
Usability,"Currently pruning dependencies, forking NextJS to remove poly fills for older browsers, and focusing on bundle size. Investigated using Inferno.js as a lighter alternative to React. Saves ~20-30KB bundle size, and is somewhat faster. However, main Inferno dev moved to React core team, and React is focusing on the optimizations present in Inferno for 2019 (DOM: move to native events where possible), as well as introducing optimizations not found in Inferno (compile time targets: initially inlining, future maybe web assembly binaries; move rendering work to separate thread / concurrent rendering). Furthermore, React ecosystem is orders of magnitude larger, so we can save a huge amount of dev time by avoiding Inferno (N modules * time to develop bespoke module avg), and have greater likelihood of LTS. Notably, I realized that most of my bundle size was coming from inefficient bundling of Material UI and due to Apollo's insanely large graphQL bundle. Removing these now. Lastly, React is actually very efficient. jQuery is ~31.1KB minified. React is 3KB, while React DOM is 33.8KB. In 2019 React DOM will shrink. In any case, given that React is both faster than jQuery, dramatically simplifies development, and introduces development structure, 4KB cost is imo worth it. Related issues:; https://github.com/zeit/next.js/issues/5923. Bundle (with header, authentication logic including jks-rsa verification of token, styles). Index.js is 336 B, _app is 2.89, and that is all that is needed for first page render. _app amortized over all other pages. Scorecard template w/fetch logic is 1.67KB. <img width=""341"" alt=""screen shot 2018-12-19 at 3 43 23 pm"" src=""https://user-images.githubusercontent.com/5543229/50247084-f3202200-03a4-11e9-8232-f1cd2a35958c.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-448652812:1194,simpl,simplifies,1194,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-448652812,2,['simpl'],['simplifies']
Usability,"Currently the binding structure is redundantly specified in two places: Binds.scala, and the parser. We need the binding structure in the parser to propagate the environment, so we can annotate `Ref` nodes (and a few other things) with their types. But we can't use Binds.scala because we don't yet have an IR. This PR removes environment maintenance from the parser by deferring type annotation to a separate pass (which is simple, because it can use the Binds.scala infrastructure). One consequence is that we can't assign types to nodes like `Ref` during parsing, which means we can't ask for the type of any node during parsing, and by extension we can't ask for types of children in IR node constructors. Instead, all typechecking logic is moved to the `TypeCheck` pass. Some benefits of this change:; * The parser is simpler, as it doesn't have to maintain a typing environment.; * Binds.scala is now the single source of truth on the binding structure of the IR.; * Instead of typechecking being split in an ad-hoc way between IR constructors and the `TypeCheck` pass, all typechecking and type error reporting logic is in one place.; * The parser parses a context-free grammar, no more and no less. If the input is gramatically correct, the parser succeeds.; * We can round trip IR with type errors through the text representation. For instance, if we log an IR that fails TypeCheck, we can copy the IR from the log, parse it, then debug. This change was motivated by my work in progress to convert the parser to use the SSA grammar, which this should greatly simplify. I chose to make the type annotation pass after parsing mutate the IR in place (with the unfortunate exception of `Apply`, which can change into an `ApplyIR` or `ApplySpecial`. Do these really need to be separate nodes?). The type of a `Ref` node was already mutable to allow this sort of deferred annotation, and I've had to make a few other things mutable as well. Alternatively we could rebuild the entire IR to include t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13990:425,simpl,simple,425,https://hail.is,https://github.com/hail-is/hail/pull/13990,2,['simpl'],"['simple', 'simpler']"
Usability,"Currently this is optimized to:. ```; (TableMapRows (idx) 1; (TableRange 5 5); (MakeStruct; (idx; (GetField idx; (Ref Struct{idx:Int32} row))); (x; (I32 5)))); ```. But clearly it should be an InsertFields, not a MakeStruct.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4001#issuecomment-408232868:169,clear,clearly,169,https://hail.is,https://github.com/hail-is/hail/issues/4001#issuecomment-408232868,2,['clear'],['clearly']
Usability,"Currently, garbage pods will sit around in the batch-pods and test namespaces forever. In anticipation of adding expensive resources (storage), batch needs to learn to clean up after itself. Batch creates garbage whenever it is killed without warning. This happens in two circumstances:; - when batch is killed by a deploy; - CI job is running a test batch instance and is killed because master or the feature branch changed. To mitigate this issue we delete all PVCs (storage, ergo monetarily expensive resources) from the batch-pods namespace before we deploy batch. These PVCs are no longer needed because the batch instance that owns them is about to be re-deployed. Since the test namespace (where CI jobs will spin up batch instances to test) might also contain PVCs, we delete the whole namespace. We can do this because the deploy job (the one running `make deploy` is in the `batch-pods` namespace, not the `test` namespace). Since we delete the whole namespace, we need to recreate anything that's expected to exist there. ---. This is a short term fix. The long term fix mitigates these two situations differently:; - persistence of batch jobs ensures that after a deploy, the new batch instance finds the orphaned resources and adopts them; - each test job will get a fresh namespace in which it creates whatever it needs to test, batch then ensures this namespace is destroyed when the job is finished (which, of course, requires persistence of batch jobs)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5488:159,learn,learn,159,https://hail.is,https://github.com/hail-is/hail/pull/5488,1,['learn'],['learn']
Usability,"Currently, if the type of the `default` argument to `dict.get` does not match the dictionary's value type, the error message contains the dictionary's type and the `default` argument's type. However, the `default` argument's type should be compared to the dictionary's **value** type. This can be particularly confusing when dealing with nested dictionaries. For example:; ```python; d = hl.dict({""foo"": {""foo"": 1}}); d.get(""somekey"", hl.dict({""bar"": {""bar"": 2}})); ```; results in:; ```; TypeError: 'get' expects parameter 'default' to have the same type as the dictionary ; value type, found 'dict<str, dict<str, int32>>' and 'dict<str, dict<str, int32>>'; ```. This change puts the value type instead of the dictionary type in the error message and slightly rewords the message to be clearer about which type is which.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7377:787,clear,clearer,787,https://hail.is,https://github.com/hail-is/hail/pull/7377,1,['clear'],['clearer']
Usability,"Currently, jobs in hail batch can only be run on n1 machines but with the rise of deep learning in bioinformatics, the ability to run jobs on g2 machines, as well as other GPU supported machines, is an important and exciting addition to hail batch. This PR highlights the steps needed to add new machine types into hail batch and could be used as a template for further development support. . The changes in this PR can broadly be divided into additions to the job crun container and insertion of g2 resources (CPU, RAM, L4 Accelerator) into the resources table for billing. This PR uses the NVIDIA Container Toolkit, which allows the creation of GPU accelerated containers. This toolkit is integrated with docker via the parameters —runtime=nvidia and the specification of GPUs is made through —gpus all. The toolkit is installed in the batch worker VM startup script and the corresponding docker parameters are configured if the machine type is g2, so there is no change to the docker configuration for n1 machines. For the toolkit to work there is a nvidia hook that needs to be injected into the crun config. These modifications are also done based on machine type. On the billing side, the existing pricing setup was expanded to include g2 machines. The g2 instance cores and RAM are inserted into the database, and the SKUs are hard coded. For future machine type incorporation or updates, [https://cloud.google.com/skus/?currency=USD&filter=](https://cloud.google.com/skus/?currency=USD&filter=) may serve as a useful resource to identify relevant SKU ids. A new resource type was also added for the accelerator, including preemptible and non-preemtible. Finally, g2 machines mount the worker data disk under the name nvme0n2 so the code is updated to reflect this. Future work may want to investigate a way to automatically detect what the proper disk name is or make the disk naming logic more robust.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13430:87,learn,learning,87,https://hail.is,https://github.com/hail-is/hail/pull/13430,1,['learn'],['learning']
Usability,"Currently, tasks to schedule new instances are put on the event loop inside the `Pool` and `JobPrivateInstanceManager` constructors. `Pool.create` and `JobPrivateInstanceManager.create` first instantiate an object of their respective type and then load existing instances from the database into the in-memory instance collection. This could potentially cause the create instances loop to trigger while we're drawing ""existing"" instances, which causes the assertion error in https://github.com/hail-is/hail-tasks/issues/24 when the create instances loop and load instances query race to add the instance to the in-memory data structure. This change moves the task creation from the constructor to the `create` method, so we don't start creating instances until all existing instances are accounted for. I think I would have liked to simply pass the constructor a list of instances, but we can't create an `Instance` without an `InstanceCollection`. Resolves hail-is/hail-tasks#24. I also threw in a bit of cleanup, i.e. removing some variable assignments that didn't seem very helpful and resolving a lint issue where we used `items` where we could just use `values`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11766:832,simpl,simply,832,https://hail.is,https://github.com/hail-is/hail/pull/11766,1,['simpl'],['simply']
Usability,"Currently, the `_csrf` cookie is made available to all subdomains of `.hail.is`. This means that if I first visit `batch.hail.is` I get a `_csrf` cookie set for `.hail.is`. That cookie is then reused if I visit `ci.hail.is`. Even more awkward, the same value of the cookie will get reused if I then visit `batch.azure.hail.is`. This isn't that big of a deal, these can all be considered part of the same application that the hail team delivers and secures, but it is very little work to set stricter bounds on where this cookie is sent. By removing the `domain` attribute and using `samesite='strict'`, the cookie's domain will be set by the browser to the domain of the request whose response included the `Set-Cookie` header, e.g. `batch.hail.is` or `internal.hail.is`. `Strict` mode then ensures that the cookie will only be sent to that exact domain, meaning that each application is guaranteed to receive the `_csrf` token that it itself delivered, and a `_csrf` token from CI cannot be used to take actions against Batch. This should not have an adverse impact on existing users' browser sessions. In `render_template` we preserve the value of an existing `_csrf` cookie so this change should do the following:; - Logged in user visits a page with an existing widely scoped (`.hail.is`) `_csrf` cookie; - The server returns a `Set-Cookie` header with a new `_csrf` cookie for strictly the `batch.hail.is` domain but with the same token value as the original `_csrf` cookie; - The user now has two cookies and the browser could send either one on a given request, but it does not matter because they have the same value; - If the user logs out and back in, their old widely scoped cookie will be cleared and they only get the strict cookie from now on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14180:1701,clear,cleared,1701,https://hail.is,https://github.com/hail-is/hail/pull/14180,1,['clear'],['cleared']
Usability,"Currently, the `mark_job_complete` SQL procedure deadlocks with itself, because the transaction takes a shared lock on the relevant row of the `batches` table, which it proceeds to try to upgrade to an exclusive lock later in the transaction when it calls `UPDATE batches …`. The lock upgrade is not an issue in itself, but it will cause a deadlock if we run multiple `mark_job_complete` transactions for the same batch at the same time, which we clearly would like to do. One way to avoid this deadlock is to never issue an UPDATE to the batches table during the `mark_job_complete` procedure. Currently, we conduct the following updates to the batch row:; - increment number of completed jobs; - mark the batch as complete if the number of completed jobs is equal to the total number of jobs; - increment the number of successful/failed/cancelled jobs depending on the completion type of the job. This deadlock is a symptom of the problem that the `batches` table holds both very static information (like the billing project) and very volatile information like the number of completed jobs. It's not an issue to have many transactions holding read-only locks on rows of the batches table so long as it contains mostly static data. Therefore, it seems appropriate to move the job counters out of the batch table and into a new small table that just contains these counters. This eliminates all but one of the UPDATEs to the batch table in the procedure. The one sticky issue is marking the batch as complete. This is a much more popular column and I was hesitant to move it around just yet. I ended up moving the completeness update into a second transaction, which I think is not too bad for now. I also think that it could merge nicely with the following transaction that does the callback. Resolving this deadlock uncovered yet another deadlock underneath, which I want to tackle next. This PR does NOT resolve the issue that all mark job complete transactions are serialized due to the way we inc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11352:447,clear,clearly,447,https://hail.is,https://github.com/hail-is/hail/pull/11352,1,['clear'],['clearly']
Usability,"Currently, the boolean versions aren't being used because there's no equivalent in the function registry. I removed the int and float versions because the Python interface didn't use them. Happy for feedback on what we want to expose. If we want to support booleans now, I'll add new Aggregators that work on annotations (not RV).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3535:199,feedback,feedback,199,https://hail.is,https://github.com/hail-is/hail/pull/3535,1,['feedback'],['feedback']
Usability,"Currently, the k8s namespace field is used both for routing internal requests inside kubernetes but also external requests over the internet. It also has special logic based on whether the namespace indicates a production or dev environment. For example, if `namespace == 'default'`, then we route external `batch` requests to `batch.<domain>/path`, but if `namespace == foo_dev`, we route external `batch` requests to `internal.<domain>/foo_dev/path`. This PR decouples the namespace field from routing. Aside from being overall more straightforward in my opinion, this is necessary for batch on azure terra where batch is served out of a subpath it does not control and is unrelated to whatever namespace it might reside in. The guiding principle for routing is then as follows: If the config has no subpath, use a subdomain, otherwise put everything under domain + subpath. For example:; - `{'domain': 'hail.is', 'subpath': null}` => `batch.hail.is`; - `{'domain': 'internal.hail.is', 'subpath': '/foo_dev'}` => `internal.hail.is/foo_dev/batch`. Since the CI pipeline runs on current production instances, there is a minor need to stay compatible with old deploy configs (or else hack up the CI build.yaml). It's quite a simple translation though, because if there is no subpath provided we can infer one based on the `default_namespace`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14056:731,guid,guiding,731,https://hail.is,https://github.com/hail-is/hail/pull/14056,2,"['guid', 'simpl']","['guiding', 'simple']"
Usability,"Currently, the memory client buffers the entire output in memory which is likely to cause OOMs. For reasons that are not entirely clear to me, sometimes these OOMs get muffled by our system and instead lead to non-termination. I vaguely remember this happening before with `using`. I suspect there is something somewhat subtle wrong with that method, but I am not certain. Anyway, there are four big changes here:; 1. Do not buffer the entire request body in memory when writing to memory.; 2. Because of (1) we have to pull retry behavior all the way up to the top-level where we know how to recreate the body.; 3. Because of (2) it is easier to provide a `write(url)(writerFunction)` style API, which I do here.; 4. Again, because of (2), and because I want to preserve the file-object-like interface, I added a somewhat funky anonymous class which uses a second thread to facilitate the movement of data written into the OutputStream returned by `create` into the OutputStream of the HTTP connection. Point (4) probably bears more explanation. The root issue is the bad Apache HTTP Client interface. Instead of `request` returning an OutputStream, it takes an ""entity"". An entity knows how to write itself into the OutputStream of an HTTP request. This works fine if the ""writer"" code is pased as a function (as in my new `write` method), but that does not work if the control flow looks like:. f = create(...); f.write(...); r.close(). We avoid this limited API by initiating the request in a second thread which will eventually block waiting to receive data from a PipedInputStream. That PipedInputStream produces the data written to a PipedOutputStream. The `create` call returns a positioned OutputStream which just writes data into the PipedOutputStream and handles cleaning up the thread when it is closed. In a multi-core system, network requests should proceed in parallel to the client code. In a single-core system, the written data will buffer until `close` is called which will definite",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12691:130,clear,clear,130,https://hail.is,https://github.com/hail-is/hail/pull/12691,1,['clear'],['clear']
Usability,"Currently, the memory client buffers the entire output in memory which is likely to cause OOMs. For reasons that are not entirely clear to me, sometimes these OOMs get muffled by our system and instead lead to non-termination. I vaguely remember this happening before with `using`. I suspect there is something somewhat subtle wrong with that method, but I am not certain. Anyway, there are two big changes here:; 1. Do not buffer the entire request body in memory when writing to memory.; 2. Because of (1) we have to pull retry behavior all the way up to the top-level where we know how to recreate the body.; 3. Because of (2) it is easier to provide a `write(url)(writerFunction)` style API, which I do here.; 4. Again, because of (2), and because I want to preserve the file-object-like interface, I added a somewhat funky anonymous class which uses a second thread to facilitate the movement of data written into the OutputStream returned by `create` into the OutputStream of the HTTP connection. Point (4) probably bears more explanation. The root issue is the bad Apache HTTP Client interface. Instead of `request` returning an OutputStream, it takes an ""entity"". An entity knows how to write itself into the OutputStream of an HTTP request. This works fine if the ""writer"" code is pased as a function (as in my new `write` method), but that does not work if the control flow looks like:. f = create(...); f.write(...); r.close(). We avoid this limited API by initiating the request in a second thread which will eventually block waiting to receive data from a PipedInputStream. That PipedInputStream produces the data written to a PipedOutputStream. The `create` call returns a positioned OutputStream which just writes data into the PipedOutputStream and handles cleaning up the thread when it is closed. In a multi-core system, network requests should proceed in parallel to the client code. In a single-core system, the written data will buffer until `close` is called which will definitel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12689:130,clear,clear,130,https://hail.is,https://github.com/hail-is/hail/pull/12689,2,['clear'],['clear']
Usability,"D`, possibly with some non-empty key. This is consistent with the rule that the `rvd` must always have a stronger/longer key than the `TableType`.; * **small tweaks** - Now I start working through the `TableIR` nodes, rewriting them to remove explicit uses of `UnpartitionedRVD`. The general plan is to sandwich the rvd logic between `toOrderedRVD` and `toOldStyleRVD`. The first takes an `UnpartitionedRVD` to an `OrderedRVD` with empty key (and leaves `OrderedRVD`s alone), and the second takes an `OrderedRVD` to an `UnpartitionedRVD` if its key was empty, and leaves it alone otherwise. Once they're all rewritten this way, I redefine `toOldStyleRVD` to always return `OrderedRVD`, and `UnpartitionedRVD` is no longer used.; * **remove `TableUnkey`** - With `UnpartitionedRVD` going away, `TableUnkey` is no longer necessary, it's equivalent to keying by an empty key.; * **small tweaks** - these next two rewrite more `TableIR` nodes; * **Merge master** - the big one; * **tweak MatrixColsTable** - 1) Optimize `coerce` by checking if the requested key is empty, avoiding a scan in that case. 2) Optimize `sortedColsValue` by checking if the column key is empty, avoiding the sort in that case. 3) Simplify `colsRVD`, removing the case on the type of the `RVD`, just calling `coerce` and letting the previous optimizations avoid unnecessary work.; * **`distinctByKey` fix** - While looking over `TableIR` implementations, I noticed a bug in `distinctByKey`: you need to be sure no key is split across multiple partitions. To be sure the empty key edge case still works, I added a test to check that `strictify` on an empty-key partitioner will always collapse everything to one partition.; * **Flipped switch** - redifines `toOldStyleRVD` to just return the `OrderedRVD` unchanged, and asserts that `TableValue.rvd` is always an `OrderedRVD`.; * **rest of the `TableIR` tweaks** - added a factory method `OrderedRVD.unkeyed` to replace `UnpartitionedRVD.apply`.; * the rest are simple tidying up",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4319:2029,Simpl,Simplify,2029,https://hail.is,https://github.com/hail-is/hail/pull/4319,2,"['Simpl', 'simpl']","['Simplify', 'simple']"
Usability,"Dan, should be resolved. Thanks for all of the feedback!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4994#issuecomment-449272584:47,feedback,feedback,47,https://hail.is,https://github.com/hail-is/hail/pull/4994#issuecomment-449272584,2,['feedback'],['feedback']
Usability,"Dear hail team,. I am trying to get familiar with hail by filtering and doing simple stuff I usually do on VCFs with softwares like bcftools.; I am working with Hail version 0.2.57-582b2e31b8bd; I splitted my VCF from multiallelic to biallelic with:; `data_tmp_bi = hl.split_multi_hts(data_tmp)`; Then I want to update the allele counts the same way as what I saw in your documentation:; `data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info))`; but I get this error:; ```; File ""<ipython-input-29-3595a23add68>"", line 1, in <module>; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)). TypeError: struct() got multiple values for keyword argument 'AC'; ```; The workaround I have been using is then to create a new info field called 'AC2', to then drop the 'AC' field and then recreate the 'AC' field with `annotate_rows` with to finally drop 'AC2'. Which is a long workaround:; ```; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC2=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC')); data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC2, **data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC2')); ```. On top of this, I filter by column some samples with `filter_cols`, so then, I want to update fields like allele count again, so I would still need to use the same workaround as above, otherwise I get the same error. Do you have an idea of what the problem might be? Or a better way of doing this than what I am using?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9685:78,simpl,simple,78,https://hail.is,https://github.com/hail-is/hail/issues/9685,1,['simpl'],['simple']
Usability,"Deleted the `gsutil cat` line, it wasn't doing anything because of that erroneous `/vep_data/Plugins.tar`. I don't think plugin needs to be included here, as it's in the docker image. . Deleted the `gsutil cp`, as the file it referenced did not exist. Grabbed the 1var.vcf from the already copied loftee_data. . It's not clear to me why we don't do the `1var.vcf` vep run stuff when using `GRCh38`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10370:321,clear,clear,321,https://hail.is,https://github.com/hail-is/hail/pull/10370,1,['clear'],['clear']
Usability,Depends on pull request #696. Merge that first to get a simpler diff.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/697:56,simpl,simpler,56,https://hail.is,https://github.com/hail-is/hail/pull/697,1,['simpl'],['simpler']
Usability,"Does not work (passes) with PL present in all rows, which surprised me since type should be virtual type should be taken as stated, I believe. Haven't investigated further (stats day) to see what the IR generated is. Also does not work if I edit the VCF file and insert a bogus PL of .,.,. for each sample. An upcast seems to be happening in the mt1 child, because PL is clearly missing in mt2:. <img width=""705"" alt=""Screenshot 2020-01-31 12 40 13"" src=""https://user-images.githubusercontent.com/5543229/73561429-f9e1eb00-4426-11ea-9bb8-0cec77398d92.png"">. code in updated, pushed test. edit, to show that mt1 does have expected entries (though this shouldn't matter unless array_elements_required doesn't loosen requiredeness over the imputed type):. MT1:; <img width=""170"" alt=""Screenshot 2020-01-31 12 47 00"" src=""https://user-images.githubusercontent.com/5543229/73561943-07e43b80-4428-11ea-847e-65f2f3771af8.png"">; MT2:; <img width=""208"" alt=""Screenshot 2020-01-31 12 47 05"" src=""https://user-images.githubusercontent.com/5543229/73561944-087cd200-4428-11ea-8968-6daf53291d83.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8008#issuecomment-580834992:371,clear,clearly,371,https://hail.is,https://github.com/hail-is/hail/pull/8008#issuecomment-580834992,2,['clear'],['clearly']
Usability,"Don't use typecheck decorators here, we need a clearer message.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2694:47,clear,clearer,47,https://hail.is,https://github.com/hail-is/hail/issues/2694,1,['clear'],['clearer']
Usability,"Done!. Thanks Tim!. On Wed, Feb 1, 2017 at 8:24 AM, Tim Poterba <notifications@github.com>; wrote:. > *@tpoterba* commented on this pull request.; >; > Need just one tiny change to the py/j connector. Looks great!; > ------------------------------; >; > In python/hail/dataset.py; > <https://github.com/hail-is/hail/pull/1324#pullrequestreview-19546823>:; >; > > @@ -2336,6 +2336,22 @@ def mendel_errors(self, output, fam):; > pargs = ['mendelerrors', '-o', output, '-f', fam]; > self.hc._run_command(self, pargs); >; > + def min_rep(self):; > + """"""; > + Gives minimal, left-aligned representation of alleles. Note that this can change the variant position.; > +; > + ** Examples **; > + 1) Simple trimming of a multi-allelic site, no change in variant position; > + `1:10000:TAA:TAA,AA` => `1:10000:TA:T,A`; > +; > + 2) Trimming of a bi-allelic site leading to a change in position; > + `1:10000:AATAA,AAGAA` => `1:10002:T:G`; > +; > + """"""; > + jvds = self._jvds.minrep(); >; > add in the try: / except: here, following the other methods in dataset.py.; >; > The default py4j errors look horrible, so calling our wrapper method helps; > a lot.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/1324#pullrequestreview-19546823>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ADVxgaQoXMxYMPE_V-RMRgYp5mvNSf-Pks5rYIePgaJpZM4LzbBv>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1324#issuecomment-276663883:691,Simpl,Simple,691,https://hail.is,https://github.com/hail-is/hail/pull/1324#issuecomment-276663883,1,['Simpl'],['Simple']
Usability,"Drat, it appears that pyspark doesn't work with Python 3.8. https://stackoverflow.com/a/58849063/342839. A simpler reproduction to demonstrate that this is a pyspark issues:. ```; snafu$ python -m pyspark.cloudpickle; Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 185, in _run_module_as_main; mod_name, mod_spec, code = _get_module_details(mod_name, _Error); File ""/usr/lib/python3.8/runpy.py"", line 111, in _get_module_details; __import__(pkg_name); File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/__init__.py"", line 51, in <module>; from pyspark.context import SparkContext; File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/context.py"", line 31, in <module>; from pyspark import accumulators; File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/accumulators.py"", line 97, in <module>; from pyspark.serializers import read_int, PickleSerializer; File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/serializers.py"", line 71, in <module>; from pyspark import cloudpickle; File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/cloudpickle.py"", line 145, in <module>; _cell_set_template_code = _make_cell_set_template_code(); File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/cloudpickle.py"", line 126, in _make_cell_set_template_code; return types.CodeType(; TypeError: an integer is required (got type bytes); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10197#issuecomment-800647452:107,simpl,simpler,107,https://hail.is,https://github.com/hail-is/hail/issues/10197#issuecomment-800647452,2,['simpl'],['simpler']
Usability,"Due to bytecode verification rules, an allocated but uninitalized object cannot be stored into a field, so the NEW and INVOKESPECIAL constructor call bytecodes cannot be split across methods. Therefore, I modified newInstance to fuse those operations together. I broke out control simplification and made it a stronger. Added method splitting. Currently, method splitting splits out basic blocks into their own, straight-line methods and all the control flow remains in the original method. All locals are spilled to fields which is terrible, but what we're doing now. I expect two changes in the future: recover the structured control flow (there are standard algorithms for this) so we can split out control flow, and use the dataflow analysis from InitializeLocals to only spill locals split across method boundaries. I will make a stacked PR on this that removes method wrapping from Emit and enables lir method splitting.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8958:281,simpl,simplification,281,https://hail.is,https://github.com/hail-is/hail/pull/8958,1,['simpl'],['simplification']
Usability,"EDIT from John for future readers: The issue here is that in general we only expect consumers to free memory after they're done processing a row. So when doing any sort of filtering operation, we want to make our own region that we clear after each row is filtered out, otherwise the garbage rows will continue to accumulate until we finally find a row to keep. `filterWithContext` demonstrates the correct way to do this, and so switching to use that method fixes the problem.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10182:232,clear,clear,232,https://hail.is,https://github.com/hail-is/hail/pull/10182,1,['clear'],['clear']
Usability,"Edit: Ready for a look, besides google sa key secret creation, because I'm not completely sure what the use case is, and whether it should be a namespaced secret. Since speaking with Cotton, I've moved to using our cloud mysql instance to track user resources, to ensure that a single user id results in a single resource. We can use auth0, but that would add complexity, and would really only make sense in the context of notebook (or whatever we end up managing users) I think: while auth0 allows you to add custom claims, I believe you need to first get the user's access token (via authentication), then call (server side, no user input needed) the /management api endpoint to check the existence of the claims, and update if they do not exist. So this requires user interaction. Would need to confirm this, if proven true, we will eventually be able to circumvent this by connecting our own database to their service ([they allow this](https://auth0.com/docs/connections/database/custom-db)). Still separately tracking mapping between user id and our resources feels relatively natural, and simpler. . Right now you could supply any identifier for the user_id, as long as its globally unique. I think using the auth0 id makes the most sense, since that is a guaranteed-unique id. I will need to provide you a way to get those ids if you want to use this outside of notebook2. edit: I opted not to separate user table from resources the user owns, because I expect one row per user, so not denormalized. Also, still needs some tests written (mysql related). cc @jigold, @cseed, @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5618:1096,simpl,simpler,1096,https://hail.is,https://github.com/hail-is/hail/pull/5618,1,['simpl'],['simpler']
Usability,"Eh, as you point out in the billing changes it's 0.02208 USD per core per hour, that's 2 USD per day. It's probably a bit more if we have a full SSD for a 4 core, but still, this is extremely far away from our biggest cost center. I vote for simplicity.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8850#issuecomment-635382758:242,simpl,simplicity,242,https://hail.is,https://github.com/hail-is/hail/pull/8850#issuecomment-635382758,2,['simpl'],['simplicity']
Usability,Eliminate `batch_utilization` in favor of `batch_total_cores`. Total cores can be used; in combination with free or user (aka used) cores to determine the cluster utilization. I also simplified the code for generating the metrics to make it easier to read.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12253:183,simpl,simplified,183,https://hail.is,https://github.com/hail-is/hail/pull/12253,1,['simpl'],['simplified']
Usability,"Emit was taking two MethodBuilder arguments, one directly and one embedded in an EmitRegion. This PR replaces the EmitRegion argument with a Value[Region]. It also makes a couple other simple refactorings that were personally helpful in understanding the structure of Emit.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8449:185,simpl,simple,185,https://hail.is,https://github.com/hail-is/hail/pull/8449,1,['simpl'],['simple']
Usability,"Enabling NDArray tests revealed a bug relative to the test suite: MakeNDArray doesn't actually consider row/column major. I added a simple fix for this, predicated on rowMajorIR being a literal, which seems like a reasonable choice.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9094:132,simpl,simple,132,https://hail.is,https://github.com/hail-is/hail/pull/9094,1,['simpl'],['simple']
Usability,"Environment:; - Spark 3.2.0; - Scala 2.12.15. Running: ; ```; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.2.0; ```; I get the error:; ```BUILD SUCCESSFUL in 2m 5s; 3 actionable tasks: 3 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; make: *** No rule to make target 'check-pip-lockfiles', needed by 'install-on-cluster'. Stop.; ```. Issue is fixed for me by renaming `install-on-cluster: $(WHEEL) check-pip-lockfiles` -> `install-on-cluster: $(WHEEL) check-pip-lockfile` on line 344 of hail/Makefile. Many thanks,; Barney",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12568:675,Clear,Clear,675,https://hail.is,https://github.com/hail-is/hail/issues/12568,1,['Clear'],['Clear']
Usability,Example error:. ```; Caused by: is.hail.relocated.org.json4s.MappingException: No usable value for value_parameter_names; No usable value for str; Did not find value which can be converted into java.lang.String; 	at is.hail.relocated.org.json4s.reflect.package$.fail(package.scala:53); 	at is.hail.relocated.org.json4s.Extraction$ClassInstanceBuilder.org$json4s$Extraction$ClassInstanceBuilder$$buildCtorArg(Extraction.scala:638); 	at is.hail.relocated.org.json4s.Extraction$ClassInstanceBuilder$$anonfun$3.applyOrElse(Extraction.scala:689); 	at is.hail.relocated.org.json4s.Extraction$ClassInstanceBuilder$$anonfun$3.applyOrElse(Extraction.scala:688); 	at scala.PartialFunction.$anonfun$runWith$1$adapted(PartialFunction.scala:145); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at scala.collection.TraversableLike.collect(TraversableLike.scala:407); 	at scala.collection.TraversableLike.collect$(TraversableLike.scala:405); 	at scala.collection.AbstractTraversable.collect(Traversable.scala:108); 	at is.hail.relocated.org.json4s.Extraction$ClassInstanceBuilder.instantiate(Extraction.scala:688); 	at is.hail.relocated.org.json4s.Extraction$ClassInstanceBuilder.result(Extraction.scala:767); 	at is.hail.relocated.org.json4s.Extraction$.$anonfun$extract$10(Extraction.scala:462); 	at is.hail.relocated.org.json4s.Extraction$.$anonfun$customOrElse$1(Extraction.scala:780); 	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127); 	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126); 	at scala.PartialFunction$$anon$1.applyOrElse(PartialFunction.scala:257); 	at is.hail.relocated.org.json4s.Extraction$.customOrElse(Extraction.scala:780); 	at is.hail.relocated.org.json4s.Extraction$.extract(Extraction.scala:454); 	at is.hail.relocated.org.json4s.Extraction$.org$json4s$Extraction$$extractDete,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14579#issuecomment-2163457890:82,usab,usable,82,https://hail.is,https://github.com/hail-is/hail/pull/14579#issuecomment-2163457890,4,['usab'],['usable']
Usability,"Excellent feedback, I've improved the makefile substantially. It should now be a seamless experience for AUS et al.!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11645#issuecomment-1076594568:10,feedback,feedback,10,https://hail.is,https://github.com/hail-is/hail/pull/11645#issuecomment-1076594568,2,['feedback'],['feedback']
Usability,Extend Simplify to remove more operations before TableCount,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3676:7,Simpl,Simplify,7,https://hail.is,https://github.com/hail-is/hail/issues/3676,1,['Simpl'],['Simplify']
Usability,"Extremely nice @lfrancioli, very elegantly done. Rebase and address the minor comments, and it should be good to go. A simple test would be nice, too, but I'll put that on our todo list if you don't get to it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1147#issuecomment-265653872:119,simpl,simple,119,https://hail.is,https://github.com/hail-is/hail/pull/1147#issuecomment-265653872,2,['simpl'],['simple']
Usability,"FT JOIN aggregated_batch_resources; -> ON batches.id = aggregated_batch_resources.batch_id; -> LEFT JOIN resources; -> ON aggregated_batch_resources.resource = resources.resource; -> STRAIGHT_JOIN billing_project_users ON batches.billing_project = billing_project_users.billing_project; -> WHERE (billing_project_users.`user` = 'test' AND billing_project_users.billing_project = batches.billing_project) AND NOT deleted AND (batches.id < 1114186) AND ; -> (batches.`user` = 'test'); -> GROUP BY batches.id; -> ORDER BY batches.id DESC; -> LIMIT 51;; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+---------+---------+-------------------------------------------+---------+----------+----------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+---------+---------+-------------------------------------------+---------+----------+----------------------------------+; | 1 | SIMPLE | batches | NULL | range | PRIMARY,batches_deleted,batches_token,batches_user_state,batches_time_completed,batches_billing_project_state | PRIMARY | 8 | NULL | 1348998 | 5.00 | Using where; Backward index scan |; | 1 | SIMPLE | batches_n_jobs_in_complete_states | NULL | eq_ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 1 | 100.00 | NULL |; | 1 | SIMPLE | batches_cancelled | NULL | eq_ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 1 | 100.00 | Using index |; | 1 | SIMPLE | aggregated_batch_resources | NULL | ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 61 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 302 | batch.aggregated_batch_resources.resource ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12057#issuecomment-1196612910:1823,SIMPL,SIMPLE,1823,https://hail.is,https://github.com/hail-is/hail/pull/12057#issuecomment-1196612910,1,['SIMPL'],['SIMPLE']
Usability,"FWIW, I finally found a simpler reproducer. It really takes some doing to convince the simplifier to apply this rule. This operation should use a constant ~1GiB of RAM (in reality, in a non-broken pipeline it uses closer to 8GiB, but, still, a constant amount of RAM), but in reality memory use grows with each row processed. ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.key_by(); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```; The simplifier cannot simplify the pipeline if the key is still present so this pipeline is sufficient to restore normal memory usage:; ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```. The ""bad"" `WritePartition` body IR looks like this:; ```; (StreamFlatMap __iruid_447; (StreamRange -1 True; (GetField start (Ref __iruid_446)); (GetField end (Ref __iruid_446)); (I32 1)); (StreamMap __iruid_448; (StreamRange 1 False (I32 0) (I32 10) (I32 1)); (InsertFields; (Literal Struct{} <literal value>); (""rows"" ""garbage""); (rows (Ref __iruid_448)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1))))))); ```; The ""good"" IR looks like this:; ```; (StreamFlatMap __iruid_480; (StreamRange -1 True; (GetField start (Ref __iruid_479)); (GetField end (Ref __iruid_479)); (I32 1)); (Let __iruid_481; (MakeStruct; (idx (Ref __iruid_480)); (rows; (ToArray; (StreamRange 1 False (I32 0) (I32 10) (I32 1))))); (StreamMap __iruid_482; (ToStream True (GetField rows (Ref __iruid_481))); (InsertFields; (Ref __iruid_481); (""idx"" ""rows"" ""garbage""); (rows (Ref __iruid_482)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1)))))))); ```. Notice, in particular, that the `StreamMap` inside the `StreamFlatMap` uses memory management because",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103:24,simpl,simpler,24,https://hail.is,https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103,8,['simpl'],"['simpler', 'simplifier', 'simplify']"
Usability,"FYI @danking. If you don't like how this is structured, then please give me high level feedback on what you would do differently.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10898#issuecomment-928209199:87,feedback,feedback,87,https://hail.is,https://github.com/hail-is/hail/pull/10898#issuecomment-928209199,2,['feedback'],['feedback']
Usability,"FYI, I create a `yDummy` of all zeros in order to very simply reuse the regression utils we have. Effect on performance is negligible.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1655#issuecomment-292960736:55,simpl,simply,55,https://hail.is,https://github.com/hail-is/hail/pull/1655#issuecomment-292960736,2,['simpl'],['simply']
Usability,"Failing tests likely due to recent commit, should be simple fix and re-push.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1648#issuecomment-294171904:53,simpl,simple,53,https://hail.is,https://github.com/hail-is/hail/pull/1648#issuecomment-294171904,2,['simpl'],['simple']
Usability,"Feature/Comment. Once documented the invocation of hail for running over a Spark cluster it proves crystal clear how to proceed, via `shadowJar` compilation and `spark-submit --master`. However it is not fully intuitive to have a `hail` command with a `--master` switch and a `shadowJar` compilation for `spark-submit`. A unifying script (eg. `bin/hail-submit`) that infers from command line options whether it is a local or cluster run, and from defaults infers the location of either the hail script or the `shadowJar` jar, could make the invocation simpler.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/419:107,clear,clear,107,https://hail.is,https://github.com/hail-is/hail/issues/419,3,"['clear', 'intuit', 'simpl']","['clear', 'intuitive', 'simpler']"
Usability,"Feedback welcome, not for merging. Goal with ScoreCovariance was to get a working interface rather than optimize speed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2219:0,Feedback,Feedback,0,https://hail.is,https://github.com/hail-is/hail/pull/2219,1,['Feedback'],['Feedback']
Usability,"First of several web-related commits. Simply adds Lerna to manage (from future PRs) web apps and related micro services, as a monorepo. Deduplicate dependencies, install using a single command. The package.lock file is the majority of LOC, and it's automatically generated by npm install for a given package.json at a given point in time. We should commit these to ensure that subsequent npm install commands generated the same dependency tree. I think we should assume that this file is correct for the moment. https://stackoverflow.com/questions/44206782/do-i-commit-the-package-lock-json-file-created-by-npm-5. Lerna: https://lernajs.io. We can also choose not to use Lerna here and treat all web-related micro services as completely independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5314:38,Simpl,Simply,38,https://hail.is,https://github.com/hail-is/hail/pull/5314,1,['Simpl'],['Simply']
Usability,First stage of RegUtil simplification,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1839:23,simpl,simplification,23,https://hail.is,https://github.com/hail-is/hail/pull/1839,2,['simpl'],['simplification']
Usability,"First stage, esp. interested in feedback on structure of computation. Second stage will fill out docs and add global annotation for regression of `ys` against `covs` only.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2181:32,feedback,feedback,32,https://hail.is,https://github.com/hail-is/hail/pull/2181,1,['feedback'],['feedback']
Usability,"First step in RVD changes. Rewrites `Interval` to support endpoints that are `Row`s of different lengths. Hopefully comments and test suite are enough to make the semantics clear. If not, let me know what is unclear and I'll add documentation and/or test cases.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4072:173,clear,clear,173,https://hail.is,https://github.com/hail-is/hail/pull/4072,1,['clear'],['clear']
Usability,First version of hailctl batch. I'm not a big batch user at this time so feedback on both code and desired functionality is welcome. @konradjk,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6503:73,feedback,feedback,73,https://hail.is,https://github.com/hail-is/hail/pull/6503,1,['feedback'],['feedback']
Usability,Fix Simplify bug related to TableGetGlobals(TableMultiWayZipJoin),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5104:4,Simpl,Simplify,4,https://hail.is,https://github.com/hail-is/hail/pull/5104,1,['Simpl'],['Simplify']
Usability,Fix TableKeyByAndAggregate simplify bug,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4904:27,simpl,simplify,27,https://hail.is,https://github.com/hail-is/hail/pull/4904,2,['simpl'],['simplify']
Usability,Fix deoptimization in Simplify.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5172:22,Simpl,Simplify,22,https://hail.is,https://github.com/hail-is/hail/pull/5172,1,['Simpl'],['Simplify']
Usability,Fix invalid simplification rule (can't take ArrayLen of set),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5889:12,simpl,simplification,12,https://hail.is,https://github.com/hail-is/hail/pull/5889,2,['simpl'],['simplification']
Usability,Fix simplification for integer subtraction; Extend scope of simplifier to more numeric types.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12754:4,simpl,simplification,4,https://hail.is,https://github.com/hail-is/hail/pull/12754,2,['simpl'],"['simplification', 'simplifier']"
Usability,Fixed inlining of ArrayAgg nodes without aggs in the body. Also added; simplify rule to rewrite these nodes to just the body.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7219:71,simpl,simplify,71,https://hail.is,https://github.com/hail-is/hail/pull/7219,1,['simpl'],['simplify']
Usability,Fixed the following things:; 1. initOp was in wrong place for AggregateRows; 2. no clearing of rv aggregators between groups in AggregateRows; 3. The post-agg function wasn't being used in AggregateCols. I added more tests in Python.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3724:83,clear,clearing,83,https://hail.is,https://github.com/hail-is/hail/pull/3724,1,['clear'],['clearing']
Usability,"Fixes #12540. CHANGELOG: When using Query-on-Batch, hl.hadoop* methods now properly support creation and modification time. Creation time is supported by modern Linuxes but only through a new statx API which is not exposed by the Python standard library. There is a 0.1 version library from 2021 which exposes statx including the ""birth time"". I chose to raise an exception for now. Each cloud does support a ""modification time"" but it generally refers to changes to metadata or is just the creation time:; - https://cloud.google.com/storage/docs/json_api/v1/objects#resource (see updated); - https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html#API_GetObject_ResponseSyntax (""Last-Modified"", is always creation time); - https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_ResponseSyntax same as above; - https://learn.microsoft.com/en-us/rest/api/storageservices/get-blob (see Last-Modified and x-ms-creation-time)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12571:858,learn,learn,858,https://hail.is,https://github.com/hail-is/hail/pull/12571,1,['learn'],['learn']
Usability,Fixes #13556. I haven't tested these changes -- would like to get initial feedback first.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13744:74,feedback,feedback,74,https://hail.is,https://github.com/hail-is/hail/pull/13744,1,['feedback'],['feedback']
Usability,"Fixes #13706. When I reworked `build.gradle` to be simpler and conform with modern gradle standards, I forgot to dump all of our dependencies into our test runtime classpath. This PR ensures that the test runtime classpath is the same as our runtime classpath in QoB and in QoS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13740:51,simpl,simpler,51,https://hail.is,https://github.com/hail-is/hail/pull/13740,1,['simpl'],['simpler']
Usability,"Fixes #13788:; - Add `raise_unless_column_indexed` guard and apply to all column-indexed parameters in `statgen.py`.; - Rename `check_row_indexed` and `check_entry_indexed` as I'm allergic to functions called ""check"" - now it's clearer what they do.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13849:228,clear,clearer,228,https://hail.is,https://github.com/hail-is/hail/pull/13849,1,['clear'],['clearer']
Usability,"Fixes #13815. I tried to simplify the concepts here to be unified across all instance collection types. I renamed ""provisioned"" to ""live"". Schedulable means only workers that are active and from the latest instance version. I think the example figures are self explanatory. ; <img width=""1594"" alt=""Screenshot 2023-10-30 at 11 33 39 AM"" src=""https://github.com/hail-is/hail/assets/1693348/0c8f4d2e-019e-419e-86b6-12de510ac5a4"">. <img width=""1569"" alt=""Screenshot 2023-10-30 at 11 35 29 AM"" src=""https://github.com/hail-is/hail/assets/1693348/131f4978-76c4-4a6e-9e72-ecf9f99c8d5e"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13943:25,simpl,simplify,25,https://hail.is,https://github.com/hail-is/hail/pull/13943,1,['simpl'],['simplify']
Usability,"Fixes #13902. I'm pretty sure the kernel was randomly choosing the worker process to be killed when another process caused the kernel memory to be exhausted on OOM causing the non-responsiveness of the worker. It was strongly discourage from setting an explicit kernel memory limit on containers in the documentation. However, it might be fine to set it to the same memory limit as the other 3 memory settings from reading this [documentation](https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt) on memory settings.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13972:180,responsiv,responsiveness,180,https://hail.is,https://github.com/hail-is/hail/pull/13972,1,['responsiv'],['responsiveness']
Usability,Fixes #2159. Error message is now:; ```; FatalError: HailException: corrupt or outdated VDS: invalid metadata; Recreate VDS with current version of Hail.; Detailed exception:; No usable value for sample_schema; Did not find value which can be converted into java.lang.String. Java stack trace:; is.hail.utils.HailException: corrupt or outdated VDS: invalid metadata; Recreate VDS with current version of Hail.; Detailed exception:; No usable value for sample_schema; Did not find value which can be converted into java.lang.String; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:27); 	at is.hail.variant.VariantSampleMatrix$$anonfun$1.apply(VariantSampleMatrix.scala:77); 	at is.hail.variant.VariantSampleMatrix$$anonfun$1.apply(VariantSampleMatrix.scala:72); 	at is.hail.utils.richUtils.RichHadoopConfiguration$.is$hail$utils$richUtils$RichHadoopConfiguration$$using$extension(RichHadoopConfiguration.scala:226); 	at is.hail.utils.richUtils.RichHadoopConfiguration$.readFile$extension(RichHadoopConfiguration.scala:251); 	at is.hail.variant.VariantSampleMatrix$.readFileMetadata(VariantSampleMatrix.scala:72); 	at is.hail.variant.VariantSampleMatrix$.read(VariantSampleMatrix.scala:51); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:434); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:433); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.HailContext.readAll(HailContext.scala:433); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.N,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2173:179,usab,usable,179,https://hail.is,https://github.com/hail-is/hail/pull/2173,2,['usab'],['usable']
Usability,"Fixes #3920. I'm a bit dubious on `collectPerPartitions` because it can only be safely used if there's a `ctx.region.clear` in the right spot. This should avoid some issues that caitlin was experiencing. The root issue is that `clearingRun` clears once per item, but, after the `cmapPartitions` there is only one item per partition. That item was produced by iterating through every element (with `it.foreach`) and accumulating some state. When `it.foreach` is finished, the entire partition will be in memory. On sufficiently large datasets, YARN will kill the executors for exceeding memory limits. We previously observed these errors coming from Java, but now that the regions are in native code, there are no JVM limits, the memory usage is instead noticed by YARN at the container-level. The fix is to clear after we are finished with each row, i.e. before the lambda passed to `foreach` returns.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3921:117,clear,clear,117,https://hail.is,https://github.com/hail-is/hail/pull/3921,4,['clear'],"['clear', 'clearingRun', 'clears']"
Usability,Fixes #6888. Also simplify code to remove redundant checks.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6897:18,simpl,simplify,18,https://hail.is,https://github.com/hail-is/hail/pull/6897,1,['simpl'],['simplify']
Usability,"Fixes https://github.com/hail-is/hail/issues/14130. We pervasively assume:; 1. That our entire system is used within a single Python thread.; 2. That once an event loop is created that's the only event loop that will exist forever. Pytest (and newer version of IPython, afaict) violate this pretty liberally. ~~pytest_asyncio has [explicit instructions on how to run every test in the same event loop](https://pytest-asyncio.readthedocs.io/en/latest/how-to-guides/run_session_tests_in_same_loop.html). I've implemented those here.~~ [These instructions don't work](https://github.com/pytest-dev/pytest-asyncio/issues/744). It seems that the reliable way to ensure we're using one event loop everywhere is to use pytest-asyncio < 0.23 and to define an event_loop fixture with scope `'session'`. I also switched test_batch.py into pytest-only style. This allows me to use session-scoped fixtures so that they exist exactly once for the entire test suite execution. Also:; - `RouterAsyncFS` methods must either be a static method or an async method. We must not create an FS in a sync method. Both `parse_url` and `copy_part_size` now both do not allocate an FS.; - `httpx.py` now eagerly errors if the running event loop in `request` differs from that at allocation time. Annoying but much better error message than this nonsense about timeout context managers.; - `hail_event_loop` either gets the current thread's event loop (running or not, doesn't matter to us) or creates a fresh event loop and sets it as the current thread's event loop. The previous code didn't guarantee we'd get an event loop b/c `get_event_loop` fails if `set_event_loop` was previously called.; - `conftest.py` is inherited downward, so I lifted fixtures out of test_copy.py and friends and into a common `hailtop/conftest.py`; - I added `make -C hail pytest-inter-cloud` for testing the inter cloud directory. You still need appropriate permissions and authn.; - I removed extraneous pytest.mark.asyncio since we use auto mo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14097:457,guid,guides,457,https://hail.is,https://github.com/hail-is/hail/pull/14097,1,['guid'],['guides']
Usability,"Flags now use the same user configuration machinery we use for Batch and QoB. I am not certain this is the right choice. Feedback very welcome. The configuration_of function lets us uniformly treat any configuration by checking, in order: explicit argument, envvar, config file, or a fallback. I added a bit of code to allow us to support the envvars which do not conform to the new envvar scheme. I also removed a few flags that are no longer used. I kind of think these flags should actually be under a new section like ""query_compiler"" or something. @tpoterba, thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12423:121,Feedback,Feedback,121,https://hail.is,https://github.com/hail-is/hail/pull/12423,1,['Feedback'],['Feedback']
Usability,"Focus on readability of the tutorial section. Removes Expressions from Tutorials (moves to How-To), simplifies Table tutorial (I don't think users need to care about Expressions at the outset, they should just know how to manipulate the major structures). cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6744:100,simpl,simplifies,100,https://hail.is,https://github.com/hail-is/hail/pull/6744,1,['simpl'],['simplifies']
Usability,Follow up to #13458 for making adding job groups simpler.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13467:49,simpl,simpler,49,https://hail.is,https://github.com/hail-is/hail/pull/13467,1,['simpl'],['simpler']
Usability,"For @tpoterba's benefit (and to get things clear), here's the current proposal:; - Move extra gcloud arguments to `--extra-gcloud-<description>-args=""--arg1 ... --argN""` where there is one such argument for each invocation of gcloud inside a hailctl command. gcloud args no longer go at the end.; - Only `hailctl dataproc submit` supports `--` which is used to separate submit arguments from the script arguments,; - Remove all gcloud arguments that are pass through in all commands, but mention them in the command help so users don't need to look at the gcloud help for commonly used options.; - gcloud options that are needed by some hailctl command should be consistently available among all hailctl commands (where appropriate, and where in some cases they may simply be pass-through).; - The other consistency changes @nawatts highlighted. (I wouldn't be surprised if I other issues come up when I make the changes, but this is a start.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842#issuecomment-758255396:43,clear,clear,43,https://hail.is,https://github.com/hail-is/hail/pull/9842#issuecomment-758255396,4,"['clear', 'simpl']","['clear', 'simply']"
Usability,"For Hail Batch on Terra Azure, the production artifact is Helm chart containing the necessary kubernetes resources to run a Hail Batch deployment in a Terra k8s cluster. This deployment contains slightly modified containers of the batch front-end, batch driver and a mysql database. This chart is currently built manually using the targets in `batch/terra-chart/Makefile`. As this process is not currently automatically tested, it's very prone to bit rot. This PR is an amalgamation of fixes that I needed to make to get `main` to build in the current Terra. A non-exhaustive list of the changes are:. - After changing from gradle to mill, the some Dockerfiles and make targets needed to change to account for the new location of the JAR.; - I removed some redundancy in invocations of `docker build` by relying on the generic targets that we now have in the top level Makefile.; - Terra changed how they handle identity management for the kubernetes deployment, from `aadpodidentity` to `workloadIdentity`. This changes the chart to work with their new inputs they provide. Ultimately, terra should have a CI system that we can push charts to and receive feedback on whether it passed our test suite in their test environment.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14450:1156,feedback,feedback,1156,https://hail.is,https://github.com/hail-is/hail/pull/14450,1,['feedback'],['feedback']
Usability,"For a very fast operation that is expected by the user to be immediately executed, the progress bar would suggest that operation completed very quickly, but wouldn't tell them that the operation that was actually completed was generating an IR with that operation's node present.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7828#issuecomment-572729552:87,progress bar,progress bar,87,https://hail.is,https://github.com/hail-is/hail/issues/7828#issuecomment-572729552,2,['progress bar'],['progress bar']
Usability,"For example, documentation for `g.isHomRef` says ""true if this call is 0/0"". No mention of when it can be `false` or missing. Should clearly reflection the option vs non-option register variants in @danking new function registry code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/829:133,clear,clearly,133,https://hail.is,https://github.com/hail-is/hail/issues/829,1,['clear'],['clearly']
Usability,For feedback - a couple of potential templates for capturing security impacts at either the issue or PR level.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14666:4,feedback,feedback,4,https://hail.is,https://github.com/hail-is/hail/pull/14666,1,['feedback'],['feedback']
Usability,"For posterity, we decided to make the code / SQL queries simpler here trading off efficiency and speed with having easy to verify correctness and readability. Once the initial compaction is done, this should run pretty quickly and we can scale back how aggressively we run the compaction. We may have to change this approach in the future if there's lots of simultaneous users.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13213#issuecomment-1621923414:57,simpl,simpler,57,https://hail.is,https://github.com/hail-is/hail/pull/13213#issuecomment-1621923414,2,['simpl'],['simpler']
Usability,"For rrm and grm, I've pushed overall rescaling to the faster block matrix side and thereby removed the action that counts the number of variants after filtering. The behavior is identical except that we no longer warn when constant variants are dropped, but I've clarified the behavior in the docs. In the unfathomable case that all variants are constant, the user will receive the error message `HailException: block matrix must have at least one row` when the BlockMatrix is being created. For rrm, I've also simplified the filtering, as well as the expression algebra for std_dev from; ```; hl.sqrt((mt.__ACsq + (n_samples - mt.__n_called) * mt.__mean_gt ** 2) / n_samples - mt.__mean_gt ** 2); ```; to; ```; hl.sqrt(mt.__ACsq - (mt.__AC ** 2) / mt.__n_called); ```; with the added benefit of combining two annotates.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3944:511,simpl,simplified,511,https://hail.is,https://github.com/hail-is/hail/pull/3944,1,['simpl'],['simplified']
Usability,"For the multiple JPICs, I was thinking that some day there could be a JPIC per cloud. I can try and convert it back so it's clear there is one instance of the class if that is clearer for now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9972#issuecomment-773536457:124,clear,clear,124,https://hail.is,https://github.com/hail-is/hail/pull/9972#issuecomment-773536457,4,['clear'],"['clear', 'clearer']"
Usability,"For the normal, poisson, and chi-square distributions, we have sampling (`rand_norm`), density (`dnorm`), cumulative probability (`pnorm`), and quantile (`qnorm`) functions. For beta and gamma distributions we only have the sampling functions. We should add the rest, which should be a simple matter of exposing library functions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14247:286,simpl,simple,286,https://hail.is,https://github.com/hail-is/hail/issues/14247,1,['simpl'],['simple']
Usability,"For your consideration… We often have a `pathlib.Path` or `cloudpathlib.CloudPath` that we've built up by parts, which is then the path to be used as an input resource:. ```python; res = mybatch.read_input(str(mycloudpath)); ```. Periodically we accidentally omit the `str(…)`, which leads to a semi-obscure error message and an extra editing round-trip. There is a point of view that `read_input()` and `read_input_group()` could also accept `os.PathLike` objects directly, and have Hail convert them to `str` itself, e.g. in `_new_input_resource_file()` which underlies both methods, as per this PR. The difficulty is how to do that conversion: `str(…)` does the trick for [`pathlib.Path`](https://docs.python.org/3.12/library/pathlib.html#operators) and [`cloudpathlib.CloudPath`](https://cloudpathlib.drivendata.org/stable/api-reference/cloudpath/), returning the path and URL, respectively, as a string. But it looks like in theory there might be [`os.PathLike`](https://docs.python.org/3/library/os.html#os.PathLike) subclasses that don't define `__str__()` to produce a usable path/URL. The official conversion method appears to be [`os.fspath()`](https://docs.python.org/3/library/os.html#os.fspath), but that does not do the right thing for `cloudpath.CloudPath` — there it downloads the remote file and returns a local path — which is not at all what Hail needs. However probably this is a theoretical concern and `str(…)` will be fine…",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14544#issuecomment-2105616965:1077,usab,usable,1077,https://hail.is,https://github.com/hail-is/hail/pull/14544#issuecomment-2105616965,2,['usab'],['usable']
Usability,FreeVariables$$compute$1$1.apply(FreeVariables.scala:27); at is.hail.expr.ir.FreeVariables$$anonfun$is$hail$expr$ir$FreeVariables$$compute$1$1.apply(FreeVariables.scala:24); at scala.collection.Iterator$$anon$11.next(Iterator.scala:410); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.fold(TraversableOnce.scala:212); at scala.collection.AbstractIterator.fold(Iterator.scala:1334); at is.hail.expr.ir.FreeVariables$.is$hail$expr$ir$FreeVariables$$compute$1(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$.apply(FreeVariables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:6923,Simpl,Simplify,6923,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"From @armartin on a pretty simple line of code (ukbb was just loaded from bgen, tgp was just ld_pruned, but `count`ed before that, so I don't think that was the problem):. `ukbb_in_tgp = ukbb.filter_rows(hl.is_defined(tgp[ukbb.row_key, :]))`. ```; FatalError: ClassCastException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 40.0 failed 20 times, most recent failure: Lost task 0.19 in stage 40.0 (TID 2222, pca-w-8.c.daly-ibd.internal, executor 25): java.lang.ClassCastException. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3447:27,simpl,simple,27,https://hail.is,https://github.com/hail-is/hail/issues/3447,1,['simpl'],['simple']
Usability,"Further pruned. Removed all GraphQL libraries, besides graphql-tag, which I like, because 1) simple hash-based cache: no need to walk complex graph to normalize cache, because in most cases I'm perfectly fine with not re-using cache across different queries (that may have some shared fields). Apollo does something ""smarter"", but much slower: walks a query, checks that the requested fields for a node are the same, and that the node's id is the same, as some other query. 2) no runtime validation of query shape via graphql-tag...uses simple template strings, which are free. We don't care about schema validation in the client...because the server will error when schema is invalid. This should be compile time validated instead, in this case via integration tests. Also removed react-icons... I was going to use this in place of material-design-icons, because I thought loading the full font, when I needed only a few icons, would be unnecessarily expensive. It turns out that I cannot find a library where a single icon import (react-icons or MaterialUI) is smaller than Google's entire material design font: a single font (there are several needed to cover all icons) is ~500B. A single react-icons icon is ~2KB on dev (production may be smaller due to tree shaking). Also, am opposed to CSS-in-JS: slower, worse tooling, larger. Benefits are dynamic selectors, which are really no advantage that I can see (without them can still dynamically apply classes, as in the yee ol days of pleb vanilla js). Home page down to <2kb when not logged in, and 3.1KB logged in. This includes header, simple body, and dark mode button.; <img width=""2636"" alt=""screen shot 2018-12-19 at 11 49 59 pm"" src=""https://user-images.githubusercontent.com/5543229/50264482-ed4c3000-03e8-11e9-80d1-81d195a7b37a.png"">; <img width=""2636"" alt=""screen shot 2018-12-19 at 11 50 33 pm"" src=""https://user-images.githubusercontent.com/5543229/50264483-ed4c3000-03e8-11e9-8180-1409ca16573f.png"">. edit: Further .1KB shaved (gzipp",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-448868665:93,simpl,simple,93,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-448868665,4,['simpl'],['simple']
Usability,Getting Started Guide for PyHail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1218:16,Guid,Guide,16,https://hail.is,https://github.com/hail-is/hail/issues/1218,1,['Guid'],['Guide']
Usability,"Going off a suspicion that the JVM jit won't compile methods containing irreducible control flow, I tried to fix StreamFlatMap to be reducible. A simple benchmark based on `testES2FlatMap` showed a 2x speedup, which seems to confirm the suspicion. What caused the irreducibility was the following set of control flow paths (pretend the `Lpull` label was defined in the old version too):; * `Lpull -> LinnerPull`; * `Lpull -> LouterPull`; * `LinnerPull -> innerSource.eos -> LinnerEos -> LouterPull`; * `LouterPull -> outerSource.push -> LinnerPull`. The later two paths form a loop, and the first two make two entries into the loop - the basic irreducible control flow pattern. The fix redirects the last path to go to `Lpull` instead, which will happen to branch to `LinnerPull`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9429:146,simpl,simple,146,https://hail.is,https://github.com/hail-is/hail/pull/9429,1,['simpl'],['simple']
Usability,Going to change this to be stacked on #8783. That will let me write the `Simplify` rules the way they ought to be written,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8776#issuecomment-628108350:73,Simpl,Simplify,73,https://hail.is,https://github.com/hail-is/hail/pull/8776#issuecomment-628108350,1,['Simpl'],['Simplify']
Usability,"Good call, done. It would be nice to factor out the common parts of handling refs, whether they're normal children or the only node in a block, but it's not clear how to do that without a pretty big structural change.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13627#issuecomment-1724263938:157,clear,clear,157,https://hail.is,https://github.com/hail-is/hail/pull/13627#issuecomment-1724263938,2,['clear'],['clear']
Usability,"Gotcha, thanks, the trouble with reading your reply on the go. I had assumed you contributed to both from your reply. Glad to hear you're taking aiohttp performance seriously. Regarding flow-control, yep, that pr was merged https://github.com/huge-success/sanic/pull/1179. I haven't seen any further conversations from you or Sanic devs on the issue.; * It's not just on master, it's in 0.8. Part of my concerns over Sanic came from reading your post @ https://www.reddit.com/r/Python/comments/876msl/sanic_python_web_server_thats_written_to_die_fast/ ; this now seems outdated, and it would be interesting to hear the reply of a Sanic contributor. Re: ""The last cherry: Sanic has super fast URL router because it caches matching results. The feature is extremely useful for getting awesome numbers with `wrk` tool but in real life URL paths for server usually not constant. URLs like `/users/{userid}` don't fit in cache well :)""; - Surely simple (typical-use, i.e /path or /path/<param>) pattern matching isn't a large performance constraint. I would be surprised if this were a bottleneck in either Sanic or aiohttp.; - If aiohttp is bottlenecked by this, and isn't caching matches, why not? The most common route is say /. Edit: To be clear, the bench mentioned above used 1 worker for Sanic and aiohttp, both using uvloop. Bench attached. [bench.zip](https://github.com/hail-is/hail/files/2841473/bench.zip)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5242#issuecomment-461455096:941,simpl,simple,941,https://hail.is,https://github.com/hail-is/hail/pull/5242#issuecomment-461455096,4,"['clear', 'simpl']","['clear', 'simple']"
Usability,"Great feedback, @tpoterba . I think I addressed all the comments. Back to you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1116#issuecomment-262160105:6,feedback,feedback,6,https://hail.is,https://github.com/hail-is/hail/pull/1116#issuecomment-262160105,2,['feedback'],['feedback']
Usability,"Great feedback, thanks @danking. I think I address or responded to all the comments. I also changed the behavior of batch not to run any node until all its ancestors have completed running, which could happen if something failed which caused something else to get cancelled that was always_run. It fixes: https://github.com/hail-is/hail/issues/5903.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5891#issuecomment-484330528:6,feedback,feedback,6,https://hail.is,https://github.com/hail-is/hail/pull/5891#issuecomment-484330528,2,['feedback'],['feedback']
Usability,"Great feedback, thanks! I think I addressed all the comments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1110#issuecomment-265057616:6,feedback,feedback,6,https://hail.is,https://github.com/hail-is/hail/pull/1110#issuecomment-265057616,2,['feedback'],['feedback']
Usability,"Great feedback. Addressed comments, back to you. In the scope lists, I use the format: `variable (*Type*): description`, where the type is in italics but not a hyperlink, but I put a hyperlink in the description when it seemed appropriate. ```; *:ref:`foo`; ```. didn't format the hyperlink. Also, I don't think we can put hyperlinks in double-back-quote literal/code blocks. I didn't address the math stuff. I think we can merge this (and other doc migrations) when it is ready and fix that separately.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1225#issuecomment-271382041:6,feedback,feedback,6,https://hail.is,https://github.com/hail-is/hail/pull/1225#issuecomment-271382041,2,['feedback'],['feedback']
Usability,"Great, and thanks for the feedback. I'll close the issue now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/902#issuecomment-256958955:26,feedback,feedback,26,https://hail.is,https://github.com/hail-is/hail/issues/902#issuecomment-256958955,2,['feedback'],['feedback']
Usability,"Great, thanks Jackie! Do you remember about how long the import step took for 0.1?. Second, you're running many linear regressions, right? If those still fail (or run much slower than 0.1), can you also try just a single linear regression? That's a simpler baseline to start with.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3945#issuecomment-405978394:249,simpl,simpler,249,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405978394,2,['simpl'],['simpler']
Usability,"Great, this is much clearer now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1000#issuecomment-257306183:20,clear,clearer,20,https://hail.is,https://github.com/hail-is/hail/pull/1000#issuecomment-257306183,2,['clear'],['clearer']
Usability,"Great, this is way simpler. Is the key_by/drop necessary? What about just making nested a string?. Does this also fail?. ```; t = hl.utils.range_table(1); t = t.annotate(x = hl.bind(lambda s, nested: s.contains(nested), hl.set({'foo'}), hl.null(...))); t._force_count(); ```. I'm going to guess no and that it has something to do with writing the row (which is why isolating it in the IRSuite isn't working).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4522#issuecomment-430009988:19,simpl,simpler,19,https://hail.is,https://github.com/hail-is/hail/issues/4522#issuecomment-430009988,2,['simpl'],['simpler']
Usability,Greatly simplified the evaluation matching.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/574#issuecomment-240128679:8,simpl,simplified,8,https://hail.is,https://github.com/hail-is/hail/pull/574#issuecomment-240128679,2,['simpl'],['simplified']
Usability,"Greatly simplifies the `NormalizeNames` pass to be logically independent of the binding structure. This leaves the old implementation, and asserts that they agree. Will delete the old implementation in a follow up.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14514:8,simpl,simplifies,8,https://hail.is,https://github.com/hail-is/hail/pull/14514,1,['simpl'],['simplifies']
Usability,"HDF5 ""files"" are usually literally a single file. While fine for traditional file systems, this is not a good fit for object stores like GCS and S3. Object stores tend to scale horizontally providing high aggregate bandwidth across many individual objects. There appear to be some efforts to permit HDF5 to read and write to object stores in an object-store-friendly manner. In particular, there is a [GCS connector](https://www.hdfgroup.org/solutions/cloud-amazon-s3-storage-hdf5-connector/). It's not an object store, but there's also support for [Hadoop HDFS](https://www.hdfgroup.org/solutions/hadoop-hdfs-hdf5-connector/). There's also [the Virtual Object Layer](https://docs.hdfgroup.org/hdf5/develop/_h5_v_l__u_g.html) which appears to be a file system abstraction that would permit storing HDF5 ""files"" in multiple objects which plays well with cloud object store scaling. We should prioritize an importer because no one has asked for HDF5 export nor is it clear that the HDF5 client libraries make it easy to write a single HDF5 ""file"" from a cluster of cores separated by a network. An importer would look something like `MatrixVCFReader`. It will need to use an HDF5 Java client library. An HDF5 client API is described [here](https://docs.hdfgroup.org/hdf5/develop/_h_d_f5_l_i_b.html) but they don't link to any JARs or maven repositories. This [support thread from 2022](https://forum.hdfgroup.org/t/how-to-get-started-wih-hdf5-java/10346/14) appears to ultimately conclude that [netcdf-java](https://forum.hdfgroup.org/t/how-to-get-started-wih-hdf5-java/10346/24) supports reading HDF5 files. Including netcdf-java in a gradle or maven project is described [here](https://docs.unidata.ucar.edu/netcdf-java/current/userguide/using_netcdf_java_artifacts.html). It is not entirely clear how to use netcdf-java to access objects in Google Cloud Storage or Azure Blob Storage. There's an [open issue to support S3](https://github.com/Unidata/netcdf-java/issues/111). ---. OK, so, this is roug",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14311#issuecomment-1955112694:965,clear,clear,965,https://hail.is,https://github.com/hail-is/hail/issues/14311#issuecomment-1955112694,2,['clear'],['clear']
Usability,"Had this refractory Dataproc failure, that kind-of pointed to serialization errors, but which @tpoterba clearly saw wasn't due to serialization, as a test in which the HadoopFS class was explicitly serialized and deserialized succeeded. The problem appeared to be in something affecting sparkContext's ability to broadcast, as even the standard SerializableHadoopConfiguration would appear null in map-reduce operations. I therefore created a clean-slate branch from master, and have issued this here. It passes all tests, including a local reproduction of the Dataproc test, by spinning up 1 spark master, 2 workers, and passing initializing hail with master=spark-master:7077 (thanks @cseed).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6263:104,clear,clearly,104,https://hail.is,https://github.com/hail-is/hail/pull/6263,1,['clear'],['clearly']
Usability,"Had to fix this:. ```; val base = Literal(TStruct(""1"" -> TInt32, ""2"" -> TInt32), Row(1,2)); val ir4 = InsertFields(InsertFields(base, Seq(""3"" -> I32(0), ""4"" -> I32(1)), None), Seq(""3"" -> I32(5)), None); ```. which was getting simplified to:. ```; InsertFields(base, Seq(""4"" -> I32(1), ""3"" -> I32(5), None); ```. which changes the order of the fields. Now I explicitly construct a `fieldOrder` to remedy this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11198:226,simpl,simplified,226,https://hail.is,https://github.com/hail-is/hail/pull/11198,1,['simpl'],['simplified']
Usability,"Hail doesn't have this built in. I think your best bet would be to generate a dot file and then run [DOT](https://en.wikipedia.org/wiki/DOT_(graph_description_language)) on it. You could maybe use [pydot](https://github.com/pydot/pydot). It should be as simple as grabbing the samples from your MT and creating a bunch of nodes, then grabbing the edges from the pc relate table and generating edges.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12489#issuecomment-1335445679:254,simpl,simple,254,https://hail.is,https://github.com/hail-is/hail/issues/12489#issuecomment-1335445679,2,['simpl'],['simple']
Usability,"Hand deployed (currently running). Only visible change is to router, add proxy rules from ukbb-hail.is to the ukbb-rg servers. The web site has two parts: static HTML served by nginx and a interactive, data-driven Shiny site run by R/shiny/shiny server. Servers run as stateful sets. Static HTML and ; data for Shiny were hand-populated. Currently giving them each one core. Given how much state is involved here, it's not clear how to autoscale this like we do with the other services.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6573:423,clear,clear,423,https://hail.is,https://github.com/hail-is/hail/pull/6573,1,['clear'],['clear']
Usability,"Haven't figured it out yet, but reproduced the error with a simpler pipeline that just uses one annotate instead of `sample_qc`:. ```; P = 1; S = 1000; V = 50000; for N in range(350, 400, 1):; try:; mt = hail.balding_nichols_model(P, S, V, N); mt = mt.annotate_cols(n_called = hl.agg.filter(hl.is_defined(mt.GT), hl.agg.count())); mt = mt.filter_cols(mt.n_called > 0); print(""\n[PASS] with"", N, ""partitions:"", mt.count()); except Exception as e:; print(""\n[FAIL] with "", N, ""partitions""); raise e; break; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944#issuecomment-652065734:60,simpl,simpler,60,https://hail.is,https://github.com/hail-is/hail/issues/8944#issuecomment-652065734,2,['simpl'],['simpler']
Usability,"Heh. At least in my version of Docker, those are implicitly relative to the root not the WORKDIR:; ```; (base) dking@wm28c-761 /tmp % cat Dockerfile ; FROM ubuntu:20.04; WORKDIR /foo/bar; VOLUME baz; (base) dking@wm28c-761 /tmp % docker build -t foo . ; [+] Building 0.1s (6/6) FINISHED ; => [internal] load build definition from Dockerfile 0.0s; => => transferring dockerfile: 34B 0.0s; => [internal] load .dockerignore 0.0s; => => transferring context: 2B 0.0s; => [internal] load metadata for docker.io/library/ubuntu:20.04 0.0s; => [1/2] FROM docker.io/library/ubuntu:20.04 0.0s; => CACHED [2/2] WORKDIR /foo/bar 0.0s; => exporting to image 0.0s; => => exporting layers 0.0s; => => writing image sha256:217748640e5c53f72b8de9917010e5742fb8bef99a37dcb13ec59a903cb5834c 0.0s; => => naming to docker.io/library/foo 0.0s. Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them; (base) dking@wm28c-761 /tmp % docker run foo /bin/sh -c 'pwd && ls -l . && ls -l / && ls -l /baz'; /foo/bar; total 0; total 56; drwxr-xr-x 2 root root 4096 May 9 15:06 baz; lrwxrwxrwx 1 root root 7 Oct 19 2022 bin -> usr/bin; drwxr-xr-x 2 root root 4096 Apr 15 2020 boot; drwxr-xr-x 5 root root 340 May 9 15:06 dev; drwxr-xr-x 1 root root 4096 May 9 15:06 etc; drwxr-xr-x 3 root root 4096 May 9 15:01 foo; drwxr-xr-x 2 root root 4096 Apr 15 2020 home; lrwxrwxrwx 1 root root 7 Oct 19 2022 lib -> usr/lib; drwxr-xr-x 2 root root 4096 Oct 19 2022 media; drwxr-xr-x 2 root root 4096 Oct 19 2022 mnt; drwxr-xr-x 2 root root 4096 Oct 19 2022 opt; dr-xr-xr-x 238 root root 0 May 9 15:06 proc; drwx------ 2 root root 4096 Oct 19 2022 root; drwxr-xr-x 5 root root 4096 Oct 19 2022 run; lrwxrwxrwx 1 root root 8 Oct 19 2022 sbin -> usr/sbin; drwxr-xr-x 2 root root 4096 Oct 19 2022 srv; dr-xr-xr-x 13 root root 0 May 9 15:06 sys; drwxrwxrwt 2 root root 4096 Oct 19 2022 tmp; drwxr-xr-x 10 root root 4096 Oct 19 2022 usr; drwxr-xr-x 11 root root 4096 Oct 19 2022 var; total 0; (base) dki",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12990#issuecomment-1540332989:901,learn,learn,901,https://hail.is,https://github.com/hail-is/hail/pull/12990#issuecomment-1540332989,2,['learn'],['learn']
Usability,"Heh. The fix is almost trivial, just gotta RTFM for http. Users will need to log out / clear cookies before this will take effect.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12379:87,clear,clear,87,https://hail.is,https://github.com/hail-is/hail/pull/12379,1,['clear'],['clear']
Usability,Help not clear for alternate allele,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/433:9,clear,clear,9,https://hail.is,https://github.com/hail-is/hail/issues/433,2,['clear'],['clear']
Usability,"Here are some slightly scattered thoughts:. You're pointing out that sometimes, it is better to unroll a stream, meaning the consumer code is repeated once per stream element. There is a more general version of this, where you want to concatenate several streams, and you might want to repeat the consumer code once per source stream. My instinct in cases like that is that both options (unroll the stream or not) should be explicitly representable in the IR, and the choice should be made before code generation. I think the fundamental issue you're pointing out is that MakeStream is most naturally a push stream (it wants to be the one driving the outer loop), and that because we don't support push streams we're forced to generate suboptimal code. But zip doesn't work for push streams. I think the only general solution is to support both push streams and pull streams explicitly, but that would add a significant amount of complexity. That may be worth doing at some point, but I definitely think we should get the simpler version working first.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8148#issuecomment-590972329:1022,simpl,simpler,1022,https://hail.is,https://github.com/hail-is/hail/pull/8148#issuecomment-590972329,2,['simpl'],['simpler']
Usability,Here's a clear instance of buffer corruption after a transient error (in this case an SSLException). https://batch.hail.is/batches/7996481/jobs/182741; ```; 2023-09-13 16:37:36.612 JVMEntryway: INFO: is.hail.JVMEntryway received arguments:; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 0: /hail-jars/gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 1: is.hail.backend.service.Main; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 2: /batch/1c00c7157d4d41bcbf508f12d75329b1; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 3: /batch/1c00c7157d4d41bcbf508f12d75329b1/log; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 4: gs://hail-query-ger0g/jars/be9d88a80695b04a2a9eb5826361e0897d94c042.jar; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 5: worker; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 6: gs://gnomad-tmp-4day/parallelizeAndComputeWithIndex/s_yyHm37RY7YTSWH29gP5SM0RwKxgs9EXbg9_YMf7ho=; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 7: 38854; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 8: 47960; 2023-09-13 16:37:36.613 JVMEntryway: INFO: Yielding control to the QoB Job.; 2023-09-13 16:37:36.614 Worker$: INFO: is.hail.backend.service.Worker be9d88a80695b04a2a9eb5826361e0897d94c042; 2023-09-13 16:37:36.614 Worker$: INFO: running job 38854/47960 at root gs://gnomad-tmp-4day/parallelizeAndComputeWithIndex/s_yyHm37RY7YTSWH29gP5SM0RwKxgs9EXbg9_YMf7ho= with scratch directory '/batch/1c00c7157d4d41bcbf508f12d75329b1'; 2023-09-13 16:37:36.617 GoogleStorageFS$: INFO: Initializing google storage client from service account key; 2023-09-13 16:37:36.821 services: WARN: A limited retry error has occured. We will automatically retry 4 more times. Do not be alarmed. (next delay: 1938). The most recent error was javax.net.ssl.SSLException: Connection reset.; 2023-09-13 16:37:38.893 WorkerTimer$: INFO: readInputs took 2278.496020 ms.; 2023-09-13 16:37:38.893 : INFO: RegionPool: initialized for thread 9: pool-2-thread-1; 2023-09-13 16:37:38.903 ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13356#issuecomment-1719508553:9,clear,clear,9,https://hail.is,https://github.com/hail-is/hail/issues/13356#issuecomment-1719508553,2,['clear'],['clear']
Usability,"Here's a larger rewrite of Github readme, ready for feedback. The gitter links reflect hail and hail-dev as we want them to be, so before merging we should rename hail to hail-dev and create hail. I also think it'd be good to give a bit more context for users on what ""pre-alpha, very active dev"" does and does not mean. In particular, that Hail is usable and tested now, but liable to change in non backward-compatible ways. Thoughts on including / wording this?. We should also consider moving the Roadmap somewhere on the forum. I think the development forum is a good place for more detailed instructions on collaboration (forking, etc) and best practices.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/699#issuecomment-243136925:52,feedback,feedback,52,https://hail.is,https://github.com/hail-is/hail/pull/699#issuecomment-243136925,4,"['feedback', 'usab']","['feedback', 'usable']"
Usability,"Here's a prototype. Still a lot to do, but I'd appreciate initial feedback before I flesh out all of the functionality. This supports the following search types:. ```; state = running; instance = worker1; cost >= 0.005; duration > 100; ""exact_match""; partialmatch; time_started > 2023-02-28T17:46:06Z; time_ended < 2023-02-28T18:46:06Z; my_key = foo; my_key != foo; job_id > 50; job_id <= 100; instance_collection = job_private; ```. <img width=""686"" alt=""Screen Shot 2023-02-28 at 2 08 53 PM"" src=""https://user-images.githubusercontent.com/1693348/221956324-fc595606-f45b-4db3-9927-eac0590a0960.png"">; <img width=""663"" alt=""Screen Shot 2023-02-28 at 2 09 14 PM"" src=""https://user-images.githubusercontent.com/1693348/221956338-051c72bb-8e3d-4422-8733-fc3e2c70a099.png"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12740:66,feedback,feedback,66,https://hail.is,https://github.com/hail-is/hail/pull/12740,1,['feedback'],['feedback']
Usability,"Here's my current rough list of things to be done before hail2 is as usable as hail1. It's still pretty long!. ## Necessary code work:; - Add the rest of the core methods from VDS/KT to api2 (#2591 does most for KT, order_by is the only outstanding KT method that's not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggis",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:69,usab,usable,69,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554,2,['usab'],['usable']
Usability,"Here's the terraform configurations in GCP and Azure:. - GCP: Batch has admin storage permissions, as granted here https://github.com/hail-is/hail/blob/1f5e1540c04abfde58ead1084841fec5aa6e0ed3/infra/gcp/main.tf#L415-L424. We also grant it a Viewer role on the query bucket after that which seems redundant. We should really not grant it global storage admin and instead give it admin for just the query bucket and other associated batch buckets. I checked in hail-vdc and batch does not have the global storage admin role, and it has the Viewer role on the query bucket. I've changed that role now to admin on the query bucket. - Azure: Story is simpler. The `query` storage container is part of the `batch` storage account. The batch SP has ownership over the `batch` storage account and by extension all of the containers inside it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11870#issuecomment-1138806011:646,simpl,simpler,646,https://hail.is,https://github.com/hail-is/hail/pull/11870#issuecomment-1138806011,2,['simpl'],['simpler']
Usability,Here's what I have now. Higher-level feedback appreciated. Note there are 4 hidden methods to convert between old interface and new. `VariantDataset._to_new_variant_dataset`; `NewVariantDataset._to_old_variant_dataset`; `KeyTable._to_new_keytable`; `NewKeyTable._to_old_keytable`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2244:37,feedback,feedback,37,https://hail.is,https://github.com/hail-is/hail/pull/2244,1,['feedback'],['feedback']
Usability,"Hey @JKosmicki,. Your branch has diverged from master a fair bit at this point. I can get this PR moving again if you do two simple things for me:; - rebase your commit on hail-is's master; - apply a patch I created, which fixes some compile errors. If you don't already have a remote (you can list remotes with `git remote -v`) for `hail-is/hail`, let's create one:. ``` bash; git remote add hi https://github.com/hail-is/hail.git; ```. I'll refer to this remote as `hi` from now on. If you already had a remote for `hail-is/hail` then substitute its name below for `hi`. First, we rebase to get the latest code from `hail-is/hail`'s `master` branch. ``` bash; git fetch hi; git rebase hi/master tdt; ```. And now we download [this `.patch` file](https://github.com/danking/hail/commit/6ea3d77684596abf171920e014c2aedd2a209f9c.patch) and apply it to the `tdt` branch:. ``` bash; git am the/path/to/that/file/you/downloaded.patch; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/753#issuecomment-248645143:125,simpl,simple,125,https://hail.is,https://github.com/hail-is/hail/pull/753#issuecomment-248645143,2,['simpl'],['simple']
Usability,"Hey @danking,; Thanks so much for the advice. Your team has been very helpful and responsive. - I made the adjustment to my `create_intervals` function; - Why is writing the hail table first more efficient than just directly exporting from the grouped matrixtable?. I tried your suggestion of writing the data to a table first, but my `cols` field doesn't contain the computed HWE values. These are contained within the `entries` field. Table description is below. I tried modifying the code to what is shown below but I'm still having the same issue. Also tried increasing the RAM to max available per CPU. One thing I noticed is the `mt_hwe_vals` variable in my code below is a MatrixTable and not a GroupedMatrixTable. Is this correct?. ```; ----------------------------------------; Global fields:; None; ----------------------------------------; Column fields:; 'ancestry': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'filters': set<str>; 'variant_qc': struct {; gq_stats: struct {; mean: float64, ; stdev: float64, ; min: float64, ; max: float64; }, ; call_rate: float64, ; n_called: int64, ; n_not_called: int64, ; n_filtered: int64, ; n_het: int64, ; n_non_ref: int64, ; het_freq_hwe: float64, ; p_value_hwe: float64, ; p_value_excess_het: float64; }; 'info': struct {; AC: array<int32>, ; AF: array<float64>, ; AN: int32, ; homozygote_count: array<int32>; }; 'a_index': int32; 'was_split': bool; ----------------------------------------; Entry fields:; 'hwe': struct {; het_freq_hwe: float64, ; p_value: float64; }; ----------------------------------------; Column key: ['ancestry']; Row key: ['locus', 'alleles']; ----------------------------------------; ```. ```python; ancestry_table = hl.Table.from_pandas(ancestry.astype({""person_id"":str}), key='person_id'); mt = mt.annotate_cols(ancestry = ancestry_table[mt.s].ancestry); mt_hwe_vals = mt.group_cols_by(mt.ancestry).aggregate(hwe = hl.agg.hardy_weinberg_test(mt.GT)). # T",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287#issuecomment-1674895492:82,responsiv,responsive,82,https://hail.is,https://github.com/hail-is/hail/issues/13287#issuecomment-1674895492,2,['responsiv'],['responsive']
Usability,"Hey @natestockham,. I'm glad you resolved the breeze issue. I imagine you were encountering a situation where the native libraries were not extant / not where expected / not the correct architecture. Three of the newly failing tests are related to plink. The output included in `tests.zip` indicates that you're using a fairly old version of plink,; ```; PLINK v1.90b1b 64-bit (20 May 2014); ```; Our testing server uses versions of plink from 2016. It's possible these tests are over constrained and need to be relaxed. I will investigate the precision required to pass the two tests in `IBDSuite`. However, part of one failure in the `IBDSuite` and the failure in the `ImputeSexSuite` are both caused by plink failing to produce output on certain input files. I strongly suspect these are bugs in plink version `1.90b1b` because plink `1.90b3.38` (from 2016, the version used on our test server) does not err on such files. This leaves one final test: `LinearMixedRegressionSuite.genAndFitLMM`. This is the test I have been writing about above and I can confirm that this is a bug (or, perhaps, overly precise test) **on our end** that we are actively investigating. Hail is usable even though the tests do not pass (you can run `./gradlew shadowJar` to produce a working jar), but I will advise you against relying on the results of `lmmreg` until we can confirm why this test is failing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419#issuecomment-281861771:1177,usab,usable,1177,https://hail.is,https://github.com/hail-is/hail/issues/1419#issuecomment-281861771,2,['usab'],['usable']
Usability,"Hey @shengqh !. Yeah, this is a bug in Kryo, a serialization library used by Spark, which cannot handle the size of data you're producing. This is partly a deficiency in Hail: we assume that PLINK files are relatively small, in particular that the number of variants is small. This issue was supposedly resolved in Spark 2.4.0+ and 3.0.0+ by https://github.com/apache/spark/commit/3e033035a3c0b7d46c2ae18d0d322d4af3808711 . You appear to be running Apache Spark version 3.3.2, so I'm surprised you encountered this. Can you confirm which version of the Kryo JAR you have in your environment?. Can you also share a bit of information about this PLINK file? `import_plink` could obviously be modified to support 30M+ variant PLINK files, but I'd like to understand better why such large PLINK files exist. Do you expect these files to continue to grow in size? Do other consumers of these PLINK files want one PLINK file per chromosome? Would it be possible to generate many PLINK files per chromosome such that all the PLINK files have roughly the same size in bytes?. Thanks for your feedback and help improving Hail!. Related issue: https://github.com/hail-is/hail/issues/5564 .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168#issuecomment-1904412205:1084,feedback,feedback,1084,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1904412205,2,['feedback'],['feedback']
Usability,"Hey @williambrandler ! Thanks for your contribution to Hail. We endeavor to keep our docs always accurate and up-to-date. Our continuous deployment system verifies the correctness of our Google Dataproc and Azure HDInsight instructions before releasing a new version of Hail to PyPI. Does Databricks have an open source program that would provide us with free credits to incorporate the Databricks platform into our continuous deployment process? Alternatively, I'm comfortable accepting these new instructions with a disclaimer that clearly identifies these instructions as contributed by Databricks and not maintained by the Hail team. Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11800#issuecomment-1112572464:534,clear,clearly,534,https://hail.is,https://github.com/hail-is/hail/pull/11800#issuecomment-1112572464,2,['clear'],['clearly']
Usability,"Hey, thanks for all the pictures, this is really clear. Looking at this, tho, I have question: what problem is it solving? Maybe asked another way, what does it look like without this that's an issue?. For a narrow window, you get a double scrollbar: one on the table and one on the window. That has always seemed like bad design to me.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7786#issuecomment-580065507:49,clear,clear,49,https://hail.is,https://github.com/hail-is/hail/pull/7786#issuecomment-580065507,2,['clear'],['clear']
Usability,"Hi @alanmejiamaza ,. Just to be clear, you did `pip install hail` and then you opened a notebook and ran something like:; ```; import hail as hl; hl.init(); from hail.plot import show; from pprint import pprint; hl.plot.output_notebook(); ht = hl.utils.range_table(1000); ht = mt.annotate(DP = hl.rand_unif(0, 100)); p = hl.plot.histogram(ht.DP, range=(0,30), bins=30, title='DP Histogram', legend='DP'); show(p); ```; And the plot didn't appear? Did you get a message saying ""BokehJS 1.4.0 successfully loaded.""? What version of Jupyter are you using? What web browser are you using?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12717#issuecomment-1452599951:32,clear,clear,32,https://hail.is,https://github.com/hail-is/hail/issues/12717#issuecomment-1452599951,2,['clear'],['clear']
Usability,"Hi @daniel-goldstein / @danking - thanks for the feedback, and sorry for the delay! I've pushed those changes now :)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14328#issuecomment-1978272030:49,feedback,feedback,49,https://hail.is,https://github.com/hail-is/hail/pull/14328#issuecomment-1978272030,2,['feedback'],['feedback']
Usability,"Hi @danking, thanks for this. On the topic of asserts, there are really two interacting issues:. 1. Asserts are intended to ensure invariants, i.e. conditions that should always be true. In correct code, assertions should never raise so disabling them should have no consequences at runtime. In practice, however, they are often casually used to catch value errors, which can be expected to occur if a user-facing method receives bad/nonsensical inputs (e.g. here: https://github.com/hail-is/hail/blob/1940547d35ddddb084ad52684e36153c1e03a331/hail/python/hailtop/hailctl/dataproc/diagnose.py#L62); 2. Python's language design allows anyone calling your code to disable asserts for optimization purposes, because disabling asserts should never change the semantics of the program. Putting these two features together, you can arrive at a situation where a user thinks they're turning off asserts (which should never raise anyway) and instead stops catching value errors (whose absence can never be guaranteed). All that said, if the final answer is: ""if you invoke `-O` you deserve what's coming"", I'm happy to drop it :). Thanks for taking a look at the example. If I understand you correctly, it sounds like I passed the wrong inputs to the function, in which case it might be clearer to raise a ValueError instead of an AssertionError in the end. On a closer look, it seems like most of the instances of `assert(x, y)` are actually in scala code-- my mistake. Thanks again for looking into this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12952#issuecomment-1531675665:1278,clear,clearer,1278,https://hail.is,https://github.com/hail-is/hail/issues/12952#issuecomment-1531675665,2,['clear'],['clearer']
Usability,"Hi @jmarshall, you're very right about the memoization aspect. I ended up just scrapping the data structure entirely in #12918 and doing this in a breadth-first way that seemed more intuitive anyway.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12915#issuecomment-1518367237:182,intuit,intuitive,182,https://hail.is,https://github.com/hail-is/hail/issues/12915#issuecomment-1518367237,2,['intuit'],['intuitive']
Usability,"Hi Jerome, yup, the first three require plink 1.9 and the fourth requires qctool. I'm surprised FisherExactSuite didn't fail as well, perhaps you have R installed or pulled Hail before that went into master. Thanks for the feedback, super helpful!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/594#issuecomment-240399174:223,feedback,feedback,223,https://hail.is,https://github.com/hail-is/hail/issues/594#issuecomment-240399174,2,['feedback'],['feedback']
Usability,"Hi TJ! @tpoterba tells me he told you to make an Issue, but he forgot that we're trying to limit Issues to bug reports. Would you mind reposting this feature request on the forum and we'll follow up there?. http://discuss.hail.is/c/features. Can you also spell out a bit more what information you'd like for each parent-proband trio and how this information can be useful? We think the forum will be an easier place to get community feedback to nail down the best spec for all. Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1055#issuecomment-258299456:433,feedback,feedback,433,https://hail.is,https://github.com/hail-is/hail/issues/1055#issuecomment-258299456,2,['feedback'],['feedback']
Usability,"Hi Vlad, thanks for the PR! I'm afraid there are some internal migrations we're making that are probably not clear from just looking at the codebase. Are you up to date on our `main`? We've found working with `config.mk` cumbersome because it can be stale if you switch between different instances of Batch (e.g. one deployed in azure and the other in GCP). > DOCKER_ROOT_IMAGE used to build batch workers and benchmark. I've recently updated the scripts for building the batch worker VM image to query kubernetes directly and we should probably do the same for benchmark. > HAIL_TEST_GCS_BUCKET used to build query; KUBERNETES_SERVER_URL used to build amundsen. These services are both currently deleted in our `main`. > PROJECT, ZONE, REGION are probably not need, but might make sense to add for consistency. These will fail in an Azure deployment, and while we want to move away from `config.mk` entirely, we would at least want it to contain configurations that are valid across clouds.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11371#issuecomment-1041941055:109,clear,clear,109,https://hail.is,https://github.com/hail-is/hail/pull/11371#issuecomment-1041941055,2,['clear'],['clear']
Usability,"Hi all,. Here's the error message that I get when I go to install all of my python packages (scipy/uvloop/etc). ```; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; --; 872 | amazon-ebs: rm -rf build/deploy; 873 | amazon-ebs: mkdir -p build/deploy; 874 | amazon-ebs: mkdir -p build/deploy/src; 875 | amazon-ebs: cp ../README.md build/deploy/; 876 | amazon-ebs: rsync -r \; 877 | amazon-ebs: --exclude '.eggs/' \; 878 | amazon-ebs: --exclude '.pytest_cache/' \; 879 | amazon-ebs: --exclude '__pycache__/' \; 880 | amazon-ebs: --exclude 'benchmark_hail/' \; 881 | amazon-ebs: --exclude '.mypy_cache/' \; 882 | amazon-ebs: --exclude 'docs/' \; 883 | amazon-ebs: --exclude 'dist/' \; 884 | amazon-ebs: --exclude 'test/' \; 885 | amazon-ebs: --exclude '*.log' \; 886 | amazon-ebs: python/ build/deploy/; 887 | amazon-ebs: # Clear the bdist build cache before building the wheel; 888 | amazon-ebs: cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; 889 | ==> amazon-ebs: /usr/local/lib/python3.7/site-packages/setuptools/installer.py:30: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.; 890 | ==> amazon-ebs: SetuptoolsDeprecationWarning,; 891 | ==> amazon-ebs: /usr/local/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.; 892 | ==> amazon-ebs: setuptools.SetuptoolsDeprecationWarning,; 893 | amazon-ebs: sed '/^pyspark/d' python/requirements.txt \| grep -v '^#' \| xargs python3 -m pip install -U; 894 | amazon-ebs: Collecting aiohttp==3.8.1; 895 | amazon-ebs: Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB); 896 | amazon-ebs: ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 68.3 MB/s eta 0:00:00; 897 | amazon-ebs: Collecting aiohttp_session<2.8,>=2.7; 898 | amazon-eb",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:847,Clear,Clear,847,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,1,['Clear'],['Clear']
Usability,"Hi there @BioDCH, I reformatted your comment using [markdown code blocks](https://guides.github.com/features/mastering-markdown/#syntax). It looks like the unix user running `hail` does not have permission to edit `hail.log` file, this likely caused the other two errors. Please add `--log-file PATH` where `PATH` is a file path to which you have write access. For example:. ```; spark-submit --executor-memory 16g --executor-cores 4 --class org.broadinstitute.hail.driver.Main ******/hail-all-spark.jar ; --master yarn-client importvcf --log-file /user/hail/hail.log /user/hail/split_test.vcf splitmulti write -o /user/hail/split_test_1_1.vds exportvcf -o /user/hail/split_test_1_1.vcf; ```. Assuming you have write access to `/user/hail/hail.log`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/825#issuecomment-250746848:82,guid,guides,82,https://hail.is,https://github.com/hail-is/hail/issues/825#issuecomment-250746848,2,['guid'],['guides']
Usability,"Hi!. Trying to calculate polygenic risk score with code from the [Polygenic Score Calculation](https://hail.is/docs/0.2/guides/genetics.html#polygenic-score-calculation), getting error with stacktrace:. `2022-05-14 12:09:07 Hail: INFO: Running Hail version 0.2.94-f0b38d6c436f; 2022-05-14 12:09:08 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.; 2022-05-14 12:09:08 root: INFO: RegionPool: initialized for thread 30: Thread-4; 2022-05-14 12:09:09 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 34.3 KiB, free 434.4 MiB); 2022-05-14 12:09:09 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 434.4 MiB); 2022-05-14 12:09:09 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on 10.40.3.21:33951 (size: 3.2 KiB, free: 434.4 MiB); 2022-05-14 12:09:09 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:311; 2022-05-14 12:09:11 root: INFO: RegionPool: FREE: 64.0K allocated (64.0K blocks / 0 chunks), regions.size = 1, 0 current java objects, thread 30: Thread-4; 2022-05-14 12:09:11 root: ERROR: HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; From is.hail.utils.HailException: /data/public/prs/ex_antonk.bim:1013423: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; offending line: 11	.	0	135009883	CT	C; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:30); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:28); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.utils.Context.wrapException(Context.scala:21); 	at is.hail.utils.WithContext.foreach(Context.scala:51); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.colle",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:120,guid,guides,120,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['guid'],['guides']
Usability,"Hi, I found hl.init(sc=sc) returns error since hail-0.2.92.; It can reproduce simply run as following.; Is it a bug ??; Or should I run other ways ?. - Environments I tested. ; Hail version : 0.2.92 or later.; Mac book air (M1) , spark local mode; Rocky Linux 8.5 , spark local mode; Rocky Linux 8.5 , spark yarn cluster mode. - how to reproduce; ```; import os; os.environ['PYSPARK_SUBMIT_ARGS'] = ' \; --jars \; /Users/username/miniforge3/envs/hail/lib/python3.9/site-packages/hail/backend/hail-all-spark.jar \; --conf spark.executor.extraClassPath=./hail-all-spark.jar \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator \; --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \; pyspark-shell '. from pyspark import SparkContext; sc=SparkContext.getOrCreate(). import hail as hl; hl.init(sc=sc); ```. - Error logs ; ```; 22/05/11 14:31:21 WARN Utils: Your hostname, spacerider.local resolves to a loopback address: 127.0.0.1; using 172.20.10.4 instead (on interface en6); 22/05/11 14:31:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/username/miniforge3/envs/hail/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 22/05/11 14:31:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use set",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11827:78,simpl,simply,78,https://hail.is,https://github.com/hail-is/hail/issues/11827,1,['simpl'],['simply']
Usability,"Hi, i've been giving hail a first go today. It looks great, thanks. I've come across a problem. The worker nodes on our cluster only have 2GB `/tmp` dir which fills up on some hail operations. Using the `-t` flag doesn't help. E.g. ```; hail --tmpdir /local read $invds splitmulti write -o $outvds; ```. Will still fill the dir `/tmp/blockmgr-<uuid>/` and crash. Is there a simple solution to this?. [hail.log.txt](https://github.com/hail-is/hail/files/511675/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/902:374,simpl,simple,374,https://hail.is,https://github.com/hail-is/hail/issues/902,1,['simpl'],['simple']
Usability,"Hi, sorry to leave this hanging - we aren't especially well-equipped to answer this kind of question, since it seems to be a problem with the ES config. We just convert the Hail Table to a Spark DataFrame and call `saveToEs`: ; ```scala; def export(df: spark.sql.DataFrame, host: String = ""localhost"", port: Int = 9200,; index: String, indexType: String, blockSize: Int = 1000,; config: Map[String, String], verbose: Boolean = true) {. // config docs: https://www.elastic.co/guide/en/elasticsearch/hadoop/master/configuration.html. val defaultConfig = Map(; ""es.nodes"" -> host,; ""es.port"" -> port.toString,; ""es.batch.size.entries"" -> blockSize.toString,; ""es.index.auto.create"" -> ""true""). val mergedConfig = if (config == null); defaultConfig; else; defaultConfig ++ config. if (verbose); println(s""Config ${ mergedConfig }""). df.saveToEs(s""${ index }/${ indexType }"", mergedConfig); }; ```. I'd try debugging entirely in Spark to see if you can isolate the issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5643#issuecomment-476544584:475,guid,guide,475,https://hail.is,https://github.com/hail-is/hail/issues/5643#issuecomment-476544584,2,['guid'],['guide']
Usability,"Hi, sorry we missed this -- clearly we're not monitoring issues well. We do support on the forum: https://discuss.hail.is. If this is still an open question, please make a post there!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9837#issuecomment-827850982:28,clear,clearly,28,https://hail.is,https://github.com/hail-is/hail/issues/9837#issuecomment-827850982,2,['clear'],['clearly']
Usability,"Hi,. I'm just curious if you tried black on a code that uses Hail query. As far as I see, PEP8 conflicts with the code style adopted in the Hail docs, e.g. black would remove spaces in named function arguments:. ```; - mt = mt.annotate_entries(GT = lgt_to_gt(mt.LGT, mt.LA)); + mt = mt.annotate_entries(GT=lgt_to_gt(mt.LGT, mt.LA)); ```. On the other hand, query can be seen as a DSL on top of Python, so the same guidelines probably don't need to be applied to it. Wondering if you had thoughts about lining the query code? We will be writing a lot of that in the nearest future in the Centre for Population Genomics, and would love to set up some style checks, or even automate that with a tool like black. And on black - are you considering automating code refactoring with black as part of the CI? Or you wanted to just do checks, alongside with pylint?. Vlad",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9931#issuecomment-768677633:414,guid,guidelines,414,https://hail.is,https://github.com/hail-is/hail/pull/9931#issuecomment-768677633,2,['guid'],['guidelines']
Usability,"High level take-aways:. - Hail docs now have syntax highlighting (we just needed to import pygments.css).; - Search works again.; - There are now only two root HTML templates: `site/templates/base.html` and; `web_common/web_common/templates/layout.html`. I cannot unify these further; because our services and our main websites actually differ significantly.; - The search/nav bar is now present in the HTML, no JS nonsense to; asynchronously load it into place after HTML rendering.; - Site now has a `make watch` which watches for changes and automatically; re-renders the HTML.; - Site now has a few make rules that facilitate experimenting with how the docs; are displayed within the context of the current development version of site's; CSS & HTML.; - XSLT is now only used by the C++ tests. Smaller things:. - Removed bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9597:927,clear,clear,927,https://hail.is,https://github.com/hail-is/hail/pull/9597,1,['clear'],['clear']
Usability,"Hmm. Am I correctly reading from this that there are 8 of the exact same genome in the dataset?. I am feeling more confident that this is a symptom of the model. Theoretically, if a group of replicates were perfectly separated from the rest of the dataset by a PC or group of PCs, then the estimator for kinship will get zero's because the μ perfectly predicts the genotype.; <img width=""825"" alt=""screen shot 2018-05-07 at 10 44 55 am"" src=""https://user-images.githubusercontent.com/106194/39707912-af6d2bac-51e3-11e8-928b-4dc8d08474b2.png"">. It seems a little odd that 8 samples out of 5000 would manage to get at least one PC to differentiate them from the rest of the dataset. However, if that _is_ happening, then it follows that PC-Relate would dramatically decrease the estimated kinship because all the shared alleles are being marked as markers of ancestral relatedness rather than familial relatedness. Basically, it would be interesting to see the _ancestral_ relatedness as well. If you plot the top 10 PCs and color the replicates a different color, are they clearly separated by any of the PCs?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3490#issuecomment-387091122:1072,clear,clearly,1072,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-387091122,2,['clear'],['clearly']
Usability,"Hmm. What's special about `hl.concordance`... The other issue seems like it might be simpler, we're just setting a bad type on a field:; ```; E java.lang.ClassFormatError: Invalid signature for field in class __C8802Compiled referenced from constant pool index 1605 in method __C8802Compiled.addAndDecodeLiterals_region0_0(L__C9346addAndDecodeLiteralsSpills;)V; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13814#issuecomment-1778262286:85,simpl,simpler,85,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1778262286,2,['simpl'],['simpler']
Usability,Hopefully the dev doc can do most of the explaining here. Not sure exactly how often we want to rotate. Putting this up here now to get feedback and will apply the key updates it to `hail-vdc` later this week after a trial on my own cluster.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11015:136,feedback,feedback,136,https://hail.is,https://github.com/hail-is/hail/pull/11015,1,['feedback'],['feedback']
Usability,How long did these jobs run for? I was able to reproduce the OOM with this simple example and the resource usage file was present in GCS albeit with only 8 bytes written (the header). We don't show plots in the UI with just the header and no data. Do you have example Hail Query code that would generate an OOM more slowly?. ```python3; hl.eval(hl.range(1024 * 1024).map(lambda _: hl.range(1024 * 1024))); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13577#issuecomment-1737522562:75,simpl,simple,75,https://hail.is,https://github.com/hail-is/hail/issues/13577#issuecomment-1737522562,2,['simpl'],['simple']
Usability,"Hrm. One issue: I do not fully understand the minimum number of nodes allowed in GKE. Clearly, we need at least three master nodes to reach consensus. I'm not sure if any similar requirements exist for worker pools.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6774#issuecomment-519250516:86,Clear,Clearly,86,https://hail.is,https://github.com/hail-is/hail/pull/6774#issuecomment-519250516,1,['Clear'],['Clearly']
Usability,"Huh, checkpointing `sample.vcf` after the filter clears up the issue. This may be something to do with the result of import_vcf being used directly with `_same`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11450#issuecomment-1061867500:49,clear,clears,49,https://hail.is,https://github.com/hail-is/hail/pull/11450#issuecomment-1061867500,2,['clear'],['clears']
Usability,"I added a `StreamLen` IR node. The justification for this were optimization issues in `Simplify` situations like. ```; case ArrayLen(ToArray(StreamMap(s, _, _))) => ArrayLen(ToArray(s)); ```. The above is not a valid optimization in all cases because if the elements of `s` are not realizable, the optimization will have created an invalid IR that will fail at emit time since elements of an array must be realizable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8783:87,Simpl,Simplify,87,https://hail.is,https://github.com/hail-is/hail/pull/8783,1,['Simpl'],['Simplify']
Usability,"I added a test to demonstrate the problem. The `InsertFields` is overwriting the type of a field that is not part of the requested type. Previously we would just not insert anything and leave the rebuilt child alone. But when the child is a `Ref` or a `Literal` or something that doesn't actually get rebuilt differently, the old way would lead to a situation where the rebuilt IR is not a supertype of the original IR. By inserting a `SelectFields` to subset away the fields that would have been overwritten, we avoid this problem. . Happy to further elaborate if the above isn't clear.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9633:581,clear,clear,581,https://hail.is,https://github.com/hail-is/hail/pull/9633,1,['clear'],['clear']
Usability,"I added libraries to the sidebar, added a libraries page, and moved up ""cheat sheets"" and ""how to guides"" about ""Datasets"" and ""Annotation Database"". I figure documentation should be together, as opposed to split up by datasets. Looks like: ; <img width=""1579"" alt=""Screen Shot 2020-04-03 at 2 30 41 PM"" src=""https://user-images.githubusercontent.com/13773586/78395546-aa9d6f80-75bb-11ea-8235-ec18db91c541.png"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8452:98,guid,guides,98,https://hail.is,https://github.com/hail-is/hail/pull/8452,1,['guid'],['guides']
Usability,"I agree cancel_after_n_failures should be on the group. That lets us match Spark semantics for QoB. 1. I agree, callback per group seems valuable.; 2. I agree attributes seem useful on groups.; 3. I agree, not much value in updates being at the job-group level. . Depends what you mean by prefix search, if that means `LIKE ""X%""`, I think that'll be quite fast on a normal index because you can jump directly to the first record whose prefix is X. I don't see how a fulltext index could do any better in that case. On the other hand, if you mean `LIKE ""%X""` then I agree, a normal index is useless and MySQL will do a table scan. In that case, I expect a fulltext index to be a substantial improvement. > I believe my plan is basically already doing this. It might not be clear because I didn't put the migrations in. But basically all of the current batches tables are now indexed by batch_id, job_group_id where the current ""batch"" has job_group_id = 1. Ah, that sounds good. So the plan would be to drop, for example, `aggregated_batch_resources_v2` and the other tables which are now replaced with the job group ones? That's exactly what I had in mind.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12697#issuecomment-1450945048:772,clear,clear,772,https://hail.is,https://github.com/hail-is/hail/pull/12697#issuecomment-1450945048,2,['clear'],['clear']
Usability,"I agree completely. I certainly don't think we can hide or replace Bokeh (I hope the explicit emphasis on Bokeh in the documentation makes this clear), but I think we should continue to add common-case utilities to `hl.plot` life easier for users (and ourselves).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5251#issuecomment-461245241:144,clear,clear,144,https://hail.is,https://github.com/hail-is/hail/pull/5251#issuecomment-461245241,2,['clear'],['clear']
Usability,"I agree with your criticism, although my feeling is that rows and r in your proposal are noisy and unnecessary. Two thoughts:. I think this is best resolved in the context of embedding the expression language in Python. I think understanding pandas and what's involved in building a pandas-like interface for VariantDatasets is a good way to start. If we do address it in the current setup, what do we want to write? How about `kt.aggregate('filter(col1 < col2).count()` or, assuming we're doing a summing col1, `filter(col1 < col2).sum(col1)`. Then all the lambdas go away. We clearly need the scope in aggregators. Why not make that explicit, and throw out the single implicit value? Then `filter(col1 < col2).with(col3 = col1 * col2).mean(col3)`. I'm not sure about flatMap. `flatWith(col3 = <array expr>)`? I guess that's the same as `with(col3 = <array expr>).explode(col3)`. Then Aggregables look like Structs:. ```; Aggregable {; col1: Int,; col2: Int, ...; }; ```. Then there's nothing funny going on.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1410#issuecomment-282784540:578,clear,clearly,578,https://hail.is,https://github.com/hail-is/hail/issues/1410#issuecomment-282784540,2,['clear'],['clearly']
Usability,"I also added skipBytes for use with RowMatrix.readBlockMatrix. @cseed I still need to experiment on compression w.r.t. banded LD project, which should inform the choice of BDM BufferSpec further, but using the general infrastructure is clearly better than the one-off BDM buffers I'd written before. Is it reasonable to merge this to master (post review)?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2936:236,clear,clearly,236,https://hail.is,https://github.com/hail-is/hail/pull/2936,1,['clear'],['clearly']
Usability,"I also changed the highlight color for the GitHub icon because it was too dark to clearly see. The username and password for our Font Awesome account are in the usual place. I also had a bit too much fun using ""GIPHY CAPTURE"", Giphy's Mac video capture app to create this gif of my change:; ![highlighticon](https://user-images.githubusercontent.com/106194/112545998-4147db00-8d8f-11eb-893e-6f01ea76b79b.gif)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10228:82,clear,clearly,82,https://hail.is,https://github.com/hail-is/hail/pull/10228,1,['clear'],['clearly']
Usability,"I also feel like we should have some tests that assert correctness of very simple comparisons. Like 0 < 1, NA != 1, NA == NA. Do these exist in python?. In the pain of my recent work on contextrdd and off heap regions I've spent a lot of time reducing our test cases to actual minimal examples. It would save engineering time in the long run to add simple, tiny examples every time we make changes or add functionality.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3582#issuecomment-389883212:75,simpl,simple,75,https://hail.is,https://github.com/hail-is/hail/pull/3582#issuecomment-389883212,4,['simpl'],['simple']
Usability,"I also harmonized the delete endpoint URLs so that `jobs`, `batch`, and `dag` all use `DELETE /{type}/{id}`. @jigold is reviewing all the infrastructural changes that prepare for this. This is relatively independent of the restructuring so I figure I can assign it to a new person. @jbloom22 if you'd rather not review `batch` things, I can roll the dice again. Otherwise, here's an opportunity to learn about how that's working.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4807:398,learn,learn,398,https://hail.is,https://github.com/hail-is/hail/pull/4807,1,['learn'],['learn']
Usability,"I also now suspect that the strange behavior I was seeing was due to caching on Chrome's side. This would explain why I was seeing nothing in server logs, and why behavior was inconsistent between browsers. I even watched logs of all 6 gateways (3 gateway, 3 internal), and the monitoring router, nothing. I also saw differences in redirect behavior between Safari and Chrome. Cleared browser cache (hard refreshes weren't doing anything), and started also testing in Firefox. Lastly, the proxy_set_header Host does not appear to be needed for Grafana or Prometheus to operate, so I have excluded it (tested with the Cluster dashboard). This also reduces the number of places we need to specify which external domain Grafana/Prometheus sit behind. edit: To be clear I also tried to find documentation on the use of GF_SERVER_DOMAIN and could not. GF_SERVER_DOMAIN doesn't even appear in Grafan's repository (at least, GitHub search doesn't find it, although it does find GF_SERVER_ROOT_URL)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7015#issuecomment-541336418:377,Clear,Cleared,377,https://hail.is,https://github.com/hail-is/hail/pull/7015#issuecomment-541336418,3,"['Clear', 'clear']","['Cleared', 'clear']"
Usability,"I am not sure what persist should mean in the service backend. For some linear; algebra work, persist appears to be used to store the results of an expensive; query. In that setting, we should clearly checkpoint the dataset. cc: @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11936:193,clear,clearly,193,https://hail.is,https://github.com/hail-is/hail/pull/11936,1,['clear'],['clearly']
Usability,"I am not sure why I thought my previous fix fixed anything. I was; not clearing the correct region. This fix clears the region; appropriately, i.e., clears it whenever it is finished with; a value from the producers region.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3616:71,clear,clearing,71,https://hail.is,https://github.com/hail-is/hail/pull/3616,3,['clear'],"['clearing', 'clears']"
Usability,"I am proposing a new iterator abstraction that I think should be preferred to Scala `Iterator` throughout most of the codebase, especially for iterators of region values. This is a low-level change, which could affect all code involving iterators, so I welcome feedback from everybody. The new abstractions are what I called `FlipbookIterator` and `StagingIterator` (I'm open to name suggestions). My goal was to simplify and raise the level of abstraction of most of the iterator manipulating code in the codebase—which can be subtle and bug-prone, and difficult to read—while paying as minimal as possible a performance overhead for the abstraction. This was surprisingly subtle to find the right abstractions and get their implementation right, and my hope is that all the non-obvious iterator code will now be concentrated in a small, well tested, component. `FlipbookIterator` solves the confusing behavior where `hasNext` potentially wipes out the current value. (All methods on `FlipbookIterator` and `StagingIterator` should obey the rule that methods defined without trailing `()` do not change the state of the iterator in any way detectable through the API.) The core interface of `FlipbookIterator[A]` consists of the methods. * `isValid: Boolean`; * `value: A`; * `advance(): Unit`. The metaphor is a flipbook, where when you turn the page, you no longer have access to the previous page; where you can read the current page as many times as you want (no need to copy it); and where you only know you've reached the end of the flipbook when you turn the page and find that the next page is empty. In `FlipbookIterator`, `advance()` turns the page, `isValid` asks if the page you are on is non-empty, and `value` gives you the value on the current page (which is an error if the page is empty). `StagingIterator` is a subtype of `FlipbookIterator` which adds a bit of state to each page, together with the methods `consume()` and `stage()`. The bit of state on each page tracks whether the",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3016:261,feedback,feedback,261,https://hail.is,https://github.com/hail-is/hail/pull/3016,2,"['feedback', 'simpl']","['feedback', 'simplify']"
Usability,"I assigned @catoverdrive, but @cseed @tpoterba @chrisvittal may also be interested and/or have useful feedback.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5331#issuecomment-462992065:102,feedback,feedback,102,https://hail.is,https://github.com/hail-is/hail/pull/5331#issuecomment-462992065,2,['feedback'],['feedback']
Usability,"I backed off the support for treating deep NAs as nonequal. That makes the change simpler, and also easier to test.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8859#issuecomment-634159069:82,simpl,simpler,82,https://hail.is,https://github.com/hail-is/hail/pull/8859#issuecomment-634159069,2,['simpl'],['simpler']
Usability,"I believe #14547 introduced a bug that broke IR function deserialization in QoB by changing `value_parameter_names` from `Array[String]` to `Array[Name]`. This fixes the issue by pushing the introduction of the `Name` wrapper object to after deserialization. Another option is to incorporate the `{ str: String }` structure of `Name` into the python -> scala payload, but I'm not sure I see a use case for that and we can always do that later (there is no issue of backwards compatibility with this communication between python and scala). My main concern here is that clearly this isn't tested. I'd appreciate guidance on the current advised practice for testing this behavior.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14579:569,clear,clearly,569,https://hail.is,https://github.com/hail-is/hail/pull/14579,2,"['clear', 'guid']","['clearly', 'guidance']"
Usability,"I broke up #9450. This PR moves just `NDArrayMatMul` to `emitI`, and does so by introducing a new, simpler `NDArrayEmitter` called `NDArrayEmitter2`. In a subsequent PR, I'll delete the old `NDArrayEmitter` entirely and move everything over to new version.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9480:99,simpl,simpler,99,https://hail.is,https://github.com/hail-is/hail/pull/9480,1,['simpl'],['simpler']
Usability,"I can try and be clever with how to test this by hand by not writing the spec to cloud storage, but before I do that, I'd like feedback first.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11391:127,feedback,feedback,127,https://hail.is,https://github.com/hail-is/hail/pull/11391,1,['feedback'],['feedback']
Usability,I can where this change makes many things simpler. I like the way you're going with it. Thank you.; There seem to be a few changes related to scopes - perhaps promoting bindings to various scopes eagerly. I think these have made the review slightly harder.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14402#issuecomment-1989477810:42,simpl,simpler,42,https://hail.is,https://github.com/hail-is/hail/pull/14402#issuecomment-1989477810,2,['simpl'],['simpler']
Usability,"I can't remember why I did it the other way, but your way seems simpler.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9523#issuecomment-701544404:64,simpl,simpler,64,https://hail.is,https://github.com/hail-is/hail/pull/9523#issuecomment-701544404,2,['simpl'],['simpler']
Usability,"I changed the `deploy` step to now take the built docs and publish them to a folder in hail-common. In the future, `make_pip_versioned_docs` will be deleted, so that we stop rebuilding an old version of the docs on every commit. We will simply serve the most recent version of the docs from here.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11294:237,simpl,simply,237,https://hail.is,https://github.com/hail-is/hail/pull/11294,1,['simpl'],['simply']
Usability,I commented on Zulip about how to make this error the same for every backend. I think it should be a simple change to use `parallelizeAndComputeWithIndex`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10819#issuecomment-906833242:101,simpl,simple,101,https://hail.is,https://github.com/hail-is/hail/pull/10819#issuecomment-906833242,2,['simpl'],['simple']
Usability,"I could not re-open [the old PR](https://github.com/hail-is/hail/pull/3392) because I force-pushed after a rebase. ---. We want all allocations of `Region` to be controlled with a `using` or within a `RVDContext` (which will be appropriately closed). When we have achieved this, we can move the `Region` off-heap which provides a number of benefits including the use of raw-pointers in our Hail Object Representation as well as allocation free communication with other languages. This PR makes `LoadVCF` and `HailContext.readRows` use the regions in the `RVDContext`. Note that the _consumer_ is responsible for clearing the region when they're done with the current values. This is why `writePartitions` now includes `ctx.clear()`. Moreover, _producers_ must _not_ clear the region. These changes are tested by our whole infrastructure, but in particular, `is.hail.annotations.AnnotationsSuite.testReadWrite` exercises a lot of this. NB: We no longer clear the region between each read of a row. This means we could blow memory if we don't clear in the consumer. The other consumers are: aggregations, collects, shuffles, and joins. The tests pass though, so I guess I'm not too concerned for now. Once this is merged, I'll follow swiftly with uses of the RVDContext's region else where in our infrastructure. cc: @cseed . ---. I also included a couple miscellaneous clean ups like unifying `OrderedRVD.rdd` and `UnpartitionedRVD.rdd` as well as adding a use of `Region.scoped` in `HailContext`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3394:612,clear,clearing,612,https://hail.is,https://github.com/hail-is/hail/pull/3394,5,['clear'],"['clear', 'clearing']"
Usability,"I did not fix the variant chunks or phenotypes classes to not be actual classes. But I would like your feedback on the rewritten `io.py`. It still might be overkill, but getting closer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13804#issuecomment-1781180710:103,feedback,feedback,103,https://hail.is,https://github.com/hail-is/hail/pull/13804#issuecomment-1781180710,2,['feedback'],['feedback']
Usability,"I didn't quite everything done in worker.py or managing the different secrets. However, I'd still appreciate feedback on the structure before I work on this more.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10920#issuecomment-934758488:109,feedback,feedback,109,https://hail.is,https://github.com/hail-is/hail/pull/10920#issuecomment-934758488,2,['feedback'],['feedback']
Usability,"I didn't set that to a value,and kept it by default.; I have no idea about which variables should be set to some value, is there a guide to show all the variables I should set ? I didn't see something like this in the hail website?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-338462427:131,guid,guide,131,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338462427,2,['guid'],['guide']
Usability,"I do not know why but /etc triggers errors about:; ```; archive/tar: write too long; ```; Even though /etc is not very large (1.4MB). I suspect there is some symlink; or other nonsense which is breaking Kaniko. The solution, after much trial and error, was simple: copy over directories that do not; cause issues and copy only the necessary files out of etc. A mix of speculation and; binary search lead me to the conclusion that /etc/ld.so.* are the only files necessary; from /etc for python to run correctly. These files tell the kernel how to link python3.7; to the various libraries on which it depends (which live in lib and lib64). Anyway, I've tested that this image can build itself, so it should be good enough for; our purposes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10399:257,simpl,simple,257,https://hail.is,https://github.com/hail-is/hail/pull/10399,1,['simpl'],['simple']
Usability,"I don't have any specific ideas, no. Just noticing that this seems to implement a stronger abstraction: a type for default values. I don't know of any cases where we use default values, other than unreachable values, but if there were, it looks like this could be used. Mostly, that seems simpler conceptually than ""unreachable values"", since it doesn't involve control flow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10539#issuecomment-870779483:289,simpl,simpler,289,https://hail.is,https://github.com/hail-is/hail/pull/10539#issuecomment-870779483,2,['simpl'],['simpler']
Usability,"I don't like the proliferation of `.copy` methods -- I find it extremely hard to reason about what they're actually doing and where they should be used. I think it would be reasonable for each PType to implement a `setRequired` method, which seems to require the same amount of total code, but makes things a bit simpler.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8127#issuecomment-589025030:313,simpl,simpler,313,https://hail.is,https://github.com/hail-is/hail/pull/8127#issuecomment-589025030,2,['simpl'],['simpler']
Usability,"I don't see the utility in creating an unnecessary stack trace to see 'method ""variant QC"" requires a split dataset'. I think there is value in having clear, short, stack-trace-free error messages when it's clear what the problem is and what the user needs to do. I think that printing unnecessary stack traces will cause users to view hail even more as a tool in development, and they will be more inclined to ask us about errors rather than try to figure out how whether they made a simple mistake using the interface.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287149290:151,clear,clear,151,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287149290,6,"['clear', 'simpl']","['clear', 'simple']"
Usability,"I don't think so. The change is clearly fixes an issue and is an improvement. That said, write failures are rare and I just want to flush out any other rare errors so the tests are reliable.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10023#issuecomment-776868666:32,clear,clearly,32,https://hail.is,https://github.com/hail-is/hail/pull/10023#issuecomment-776868666,2,['clear'],['clearly']
Usability,"I don't think the whitespace stuff belongs in a method, since that's expr language doc. I think if anything, the nMales/nFemales/nSamples stuff should go in query_samples, but I think the docs are pretty clear now",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1349#issuecomment-284852670:204,clear,clear,204,https://hail.is,https://github.com/hail-is/hail/issues/1349#issuecomment-284852670,2,['clear'],['clear']
Usability,"I don't think this keeps too much garbage in memory. Your next method extracts exactly the data it needs from its producer. No garbage there, you asked for only data you absolutely need. You stated (via `addReferenceTo`) that your region references these child regions, so that memory must be accessible at least as long as your region is accessible. Whoever is consuming your data can release all this memory by clearing the region you're using. The only nodes which should be clearing are folks who call `next` multiple times *and don't need that data to have the same lifetime*. This is true for filter, only surviving values must live, other values' lifetimes may end when we discover they fail the filter condition. It's also true for `write` because after one value is dumped into a file, it is no longer needed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7952#issuecomment-578798366:413,clear,clearing,413,https://hail.is,https://github.com/hail-is/hail/pull/7952#issuecomment-578798366,4,['clear'],['clearing']
Usability,"I don't think we have a clear policy on this. When I'm making stacked changes, I use one-commit per PR so that they can be reviewed independently. You're welcome to take either approach.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8920#issuecomment-638969261:24,clear,clear,24,https://hail.is,https://github.com/hail-is/hail/pull/8920#issuecomment-638969261,2,['clear'],['clear']
Usability,I feel that I've learned more about RVDs and partitioners. The front end of this change looks correct. :+1: from me.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5424#issuecomment-467119054:17,learn,learned,17,https://hail.is,https://github.com/hail-is/hail/pull/5424#issuecomment-467119054,2,['learn'],['learned']
Usability,"I figured, noticed the double post :). ```; The exception in your above message is coming from the Apply node being inferred as a PVoid by your case _ => PVoid code. Writing the rule for the apply node should fix that.; ```. Right. It's just that I tried to write the rule, and quickly ran across the fact that Seq[IR] would be inferred such that the first IR had a different type from the 2nd or Nth. This is what I had written:. ```scala; case ApplySpecial(name, irs) => {; val it = irs.iterator; val head = it.next(); head.inferSetPType(env). while(it.hasNext) {; val value = it.next(). value.inferSetPType(env); assert(value.pType2 == head.pType2); }. head.pType2; }; ```. With the result in one case that `head.pType2` was bool, `value.pType2` was something else. Without a type union, it wasn't clear to me what to return. One possibility was that I shouldn't handle this node, so I started with that possibility, which I know understand isn't right. The other was that the implementation was wrong, and my first guess there is that one of the IRs dictates the type (say the first), the 2nd is that there is a simple precedence rule, the 3rd is that the type inference procedure has some branching logic over the collection.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6594#issuecomment-513007861:801,clear,clear,801,https://hail.is,https://github.com/hail-is/hail/pull/6594#issuecomment-513007861,4,"['clear', 'simpl']","['clear', 'simple']"
Usability,"I find the current installation docs totally overwhelming. If you are using Hail; on a Mac you should not see any unnecessary crap about Linux, clusters, and; BLAS. This change introduces four flows: mac, linux, dataproc, cluster. Each page's; complexity matches the true complexity of installing Hail on that platform. In; particular, note how simple the Linux and Mac OS X pages are. It also clears up the ""other cluster"" case. Our current docs are too complex and; don't push people towards simple solutions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9017:345,simpl,simple,345,https://hail.is,https://github.com/hail-is/hail/pull/9017,3,"['clear', 'simpl']","['clears', 'simple']"
Usability,"I fixed scorecard deploy stuff and now it is working with `dev deploy`. I also pushed some CSS changes:; - body { margin: 0; } that removes the extra header spacing; - but added an 0 8px 8px 8px margin to #content; - simplified the header layout CSS; - fixed the header item clickable area, should be bigger and uniform across header items; - fixed the misalignment on Safari. I'm pretty happy with this for this iteration.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7064#issuecomment-531991835:217,simpl,simplified,217,https://hail.is,https://github.com/hail-is/hail/pull/7064#issuecomment-531991835,2,['simpl'],['simplified']
Usability,"I give up, every change I make seems to break something, and it's not clear that any of these changes actually are helping.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13371#issuecomment-1664756542:70,clear,clear,70,https://hail.is,https://github.com/hail-is/hail/pull/13371#issuecomment-1664756542,2,['clear'],['clear']
Usability,"I guess in simple terms I'm more of a member of the ""getting things done"" community than the; ""modern C++"" community. I have seen std::unique_ptr used in practice, and it was a bad experience.; And I stand by my contention that it doesn't solve any of the hard problems (whereas shared_ptr; very much does). Now I realize that people writing books about C++ write a good deal about move semantics and; unique_ptr. My interpretation is that there's a lot of writing about it because it involves concepts; which simply don't occur in any other commonly-used languages, and as such it requires a; good deal of explanation and justification because it's peculiar and unfamiliar. I suggest that; other languages haven't invented this concept because it's a) confusing and b) not particularly; useful. There's one really good thing you get from move semantics: the ability to resize a std::vector<T>; or std::unordered_map<T> without constructing deep copies of each T object. In the cases; where that's useful, it's very useful for optimizing performance without totally bypassing all your; abstraction mechanisms. The other ways people attempt to exploit move semantics are IMO; just a bad idea: if you want to pass around a large expensive-to-create object, then do it the; Java way by putting it on the heap and passing around some kind of reference, and *everyone* can understand it, not just experts in modern C++. Another angle on this debate would be to look at some open-source C++ projects and see how; often they actually use unique_ptr and/or std::move. My guess is that it's much less common; in practice than you might think from reading books about C++, because the overlap between; ""object ownership is passed around"" and ""... but we always know precisely who has ownership""; is not a very big part of the design space - compared to a whole lot of ""always owned by the object which created it"" and ""used in several places at once and we don't know who will be the last to drop it"". [Update: ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3718#issuecomment-396683489:11,simpl,simple,11,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396683489,4,['simpl'],"['simple', 'simply']"
Usability,"I had a choice on how to implement this and I decided to add a JobTask class that takes care of a single pod and the Job changes to just be a manager of the pods. However, I could have done it all within the Job if you think that is clearer. Happy to refactor if needed. Please look and see if I have enough tests. The tests are passing, but I'm getting this error message. Is this expected or a bug in my code? . ```; INFO	| 2019-02-22 11:48:48,126 	| _internal.py 	| _log:87 | 127.0.0.1 - - [22/Feb/2019 11:48:48] ""POST /pod_changed HTTP/1.1"" 204 -; INFO	| 2019-02-22 11:48:48,210 	| _internal.py 	| _log:87 | 127.0.0.1 - - [22/Feb/2019 11:48:48] ""POST /pod_changed HTTP/1.1"" 204 -; INFO	| 2019-02-22 11:48:48,833 	| server.py 	| mark_complete:190 | wrote log for job 61, main task to logs/job-61-main.log; INFO	| 2019-02-22 11:48:48,845 	| server.py 	| set_state:272 | job 61 changed state: Created -> Complete; INFO	| 2019-02-22 11:48:48,851 	| server.py 	| parent_new_state:287 | parent 61 successfully complete for 63; INFO	| 2019-02-22 11:48:48,857 	| server.py 	| parent_new_state:292 | all parents successfully complete for 63, creating pod; INFO	| 2019-02-22 11:48:48,918 	| server.py 	| create_pod:135 | created pod name: job-63-main-qqwb2 for job 63, main task; INFO	| 2019-02-22 11:48:48,929 	| server.py 	| mark_complete:330 | job 61 complete, exit_code 0; INFO	| 2019-02-22 11:48:48,995 	| _internal.py 	| _log:87 | 127.0.0.1 - - [22/Feb/2019 11:48:48] ""POST /pod_changed HTTP/1.1"" 204 -; [2019-02-22 11:48:49,043] ERROR in app: Exception on /test [POST]; Traceback (most recent call last):; File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1982, in wsgi_app; response = self.full_dispatch_request(); File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1615, in full_dispatch_request; return self.finalize_request(rv); File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1630, in finalize_request",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5418:233,clear,clearer,233,https://hail.is,https://github.com/hail-is/hail/pull/5418,1,['clear'],['clearer']
Usability,"I had to modify the way stream lengths are tracked in the emitter to be able to handle StreamTake. The new way is also simpler, and moves in the direction of the new CodeBuilder style. Now `SizedStream` is ; ```; case class SizedStream(setup: Code[Unit], stream: Stream[EmitCode], length: Option[Code[Int]]); ```; The `setup` must be emitted before either the `stream` or the `length` are used. This allows the length and stream to share setup code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8519:119,simpl,simpler,119,https://hail.is,https://github.com/hail-is/hail/pull/8519,1,['simpl'],['simpler']
Usability,"I hardcoded us-central1, which is the only thing we're using right now. Otherwise, we'd have to change CI before deploy. Also, clearly a fixed global zone is naive, so I think we have to reconsider the GCP configuration going forward. FYI @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8016:127,clear,clearly,127,https://hail.is,https://github.com/hail-is/hail/pull/8016,1,['clear'],['clearly']
Usability,"I have a fairly bad case of PTSD around over-use of std::unique_ptr and std::move at; Oracle/Endeca. I think std::unique_ptr<T> is deeply confusing and evil because, in the; simplest terms, it doesn't have the normal semantics of a ""pointer"", i.e. two or more pointers; can refer to a single object. And that problem becomes massively aggravated in the; almost-universal situation of ""borrowing"" a pointer for the duration of a procedure call. Once you let std::unique_ptr<T> into your code, it can creep out into a whole lot of places; where it adds complexity and confusion without solving any real problem. In this particular case, the complexity of managing the memory chunks isn't that hard,; they all get cleaned up by the Region destructor, and adding another layer of software; with the Chunk class seems to obscure rather than clarify what is happening. C++11 added some wonderful features, and some lousy ones. std::unique_ptr is best avoided.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3718#issuecomment-396297556:174,simpl,simplest,174,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396297556,2,['simpl'],['simplest']
Usability,I have a second PR coming that will simplify the makefiles but is not a functional change.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8149#issuecomment-590890096:36,simpl,simplify,36,https://hail.is,https://github.com/hail-is/hail/pull/8149#issuecomment-590890096,2,['simpl'],['simplify']
Usability,"I have an RFC proposal to just handle the ambiguity: https://github.com/hail-is/hail-rfcs/blob/main/rfc/0008-handle-vcf-array-field-ambiguity. I proposed a PR to fix this: https://github.com/hail-is/hail/pull/13465 However, I missed a key issue: many VCF's *elide* fields to indicate missingness. That is not ambiguous: a field that is entirely elided is clearly missing, not an array of one missing value. You can't do this in a FORMAT (aka entry aka genotype) field, but you can do this in an INFO field a la:; ```; ##fileformat=VCFv4.2; ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes, for each ALT allele, in the same order as listed"">; ##INFO=<ID=NUMS,Number=*,Type=Float,Description=""some numbers"">; ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT ...; ... AC=1,1;AN=1 ...; ```; the `NUMS` field should be read as missing. My PR considered it unacceptably ambiguous because it thought it had been `NUMS=.`. I don't think we can fix this problem entirely from Python. We need to use Scala-side logic because after we parse in Scala, we lose the knowledge that a field was entirely elided versus a single missing dot.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13346#issuecomment-1773555545:355,clear,clearly,355,https://hail.is,https://github.com/hail-is/hail/issues/13346#issuecomment-1773555545,2,['clear'],['clearly']
Usability,"I have core tests in place and would appreciate feedback on more exotic tests to add. There are similarities between `buildSampleAggregations` and `makeSampleFunctions` in Aggregators but differences throughout as well, so I'm not sure how hard to push on pulling out elements.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1708:48,feedback,feedback,48,https://hail.is,https://github.com/hail-is/hail/pull/1708,1,['feedback'],['feedback']
Usability,"I have no explanation for the behavior of `pip`, it simply refuses to upgrade to the latest cloud tools. ```; + pip search cloudtools; cloudtools (1.1.16) - Collection of utilities for working on the Google Cloud Platform.; datawire-cloudtools (0.2.6) - Datawire Cloud Tools; cloudseed (0.0.1) - Cloudtools. real	0m0.867s; user	0m0.649s; sys	0m0.084s; + pip install -U cloudtools; Collecting cloudtools; Downloading https://files.pythonhosted.org/packages/46/78/966c9af5b88a01af73bb56486e853c00ff4865de0bf380282aa54fdec43a/cloudtools-1.1.15-py3-none-any.whl; Installing collected packages: cloudtools; Successfully installed cloudtools-1.1.15. real	0m1.718s; user	0m1.378s; sys	0m0.158s; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4241#issuecomment-418776700:52,simpl,simply,52,https://hail.is,https://github.com/hail-is/hail/pull/4241#issuecomment-418776700,2,['simpl'],['simply']
Usability,"I have not tested this, though I faithfully copied the commands from existing; deploy scripts (except for creating a github release). A change that I think is valuable regardless of automation is the conversion of; deploy from a series of Makefile targets to a bash script. I also add a deploy build.yaml step which simply calls the deploy script,; setting up appropriate credentials. I only had to add one set of credentials: the PyPI credentials. I've already; created that secret in the cluster. Hand deploys are still very easy. You need curl >=7.55.0 (that version; implemented reading headers from a file). You need to set up two things:; 1. create $HOME/.pypirc and put this there:; ```; [pypi]; username: hailteam; password: GET_THIS_FROM_THE_USUAL_PLACE; ```; 2. get a github access token with repo; privileges (https://github.com/settings/tokens), create; $HOME/.github-oauth-header, and put this there:; ```; Authorization: token YOUR_ACCESS_TOKEN_HERE; ```; Now, to do a hand deploy run:; ```; make deploy GITHUB_OAUTH_HEADER_FILE=$HOME/.github-oauth-header DEPLOY_REMOTE=THE_REMOTE_FOR_hail-is/hail; ```. The github credentials are used to create a GitHub release.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8533:316,simpl,simply,316,https://hail.is,https://github.com/hail-is/hail/pull/8533,1,['simpl'],['simply']
Usability,I have seen a number of folks try and do matrix table like things on tables. Latest example: https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Sum.20rows.20in.20hail.20table . Let's make unlocalize_entries more natural and usable for everyone and encourage it!,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5405:249,usab,usable,249,https://hail.is,https://github.com/hail-is/hail/issues/5405,1,['usab'],['usable']
Usability,"I haven't read over this, but I don't like the behavior. Assert and friends are for unexpected errors, and fatal is for expected errors. How is abort different from assert?. All errors should give full JVM + Python stack traces. I see this necessary for two reasons: It makes it much easier for users to report bugs to us, which means they get faster turnaround and we spend less time going back and forth about log files (which usually were ephemeral or they've overwritten) and often ""expected"" bugs are actually correct behavior on the user's end and a bug on our side, but no context is given for us to diagnose the real problem. For usability, it is obviously best if the user-visible error appears at the bottom.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287147990:638,usab,usability,638,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287147990,2,['usab'],['usability']
Usability,"I hope this makes file localization and the Batch setup clearer. I didn't know how to do this better in words. <img width=""728"" alt=""Screen Shot 2020-05-13 at 11 03 16 AM"" src=""https://user-images.githubusercontent.com/1693348/81830010-8792a380-9509-11ea-9f74-9068bd9872fd.png"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8781:56,clear,clearer,56,https://hail.is,https://github.com/hail-is/hail/pull/8781,1,['clear'],['clearer']
Usability,"I imagine this is a low priority issue, but is there a workaround for learning what the structure of a grouped MT is in the meantime? Or has there been any progress on this?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7410#issuecomment-585212012:70,learn,learning,70,https://hail.is,https://github.com/hail-is/hail/issues/7410#issuecomment-585212012,2,['learn'],['learning']
Usability,"I intend the Tour of Hail Query to assume no genetics knowledge. Indeed, it probably won't ever mention genetics. I removed the sentence-as-bulleted list. I like them, but I'm not the reader here 😉. I intend for each of these documents to be separate files, and people with git experience can skip the git doc. I agree that we use git in one of the typical ways. However, I've learned that Atom's GitHub support doesn't consider the possibility of PRs from one remote to another. We also have some conventions around git messages and stacked PRs that I think are worth getting in writing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10020#issuecomment-776868568:377,learn,learned,377,https://hail.is,https://github.com/hail-is/hail/pull/10020#issuecomment-776868568,2,['learn'],['learned']
Usability,"I just noticed that the spacing doesn't follow the style guide. Not critical, but try to autoformat before PRing",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1494#issuecomment-284814488:57,guid,guide,57,https://hail.is,https://github.com/hail-is/hail/pull/1494#issuecomment-284814488,2,['guid'],['guide']
Usability,"I just realized, `refreshBuffer` is generally always accompanied by a (possibly implicit), `bufferCursor = start`, so that's a simplification that I'm going to try.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9304#issuecomment-676511001:127,simpl,simplification,127,https://hail.is,https://github.com/hail-is/hail/pull/9304#issuecomment-676511001,2,['simpl'],['simplification']
Usability,I kept things simple. Next round we should add a richer example. Note we'll update 1.5.2 to 1.6.2 once fix is in.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/690:14,simpl,simple,14,https://hail.is,https://github.com/hail-is/hail/pull/690,1,['simpl'],['simple']
Usability,"I looked closer at the logic in the old combiner and realized it was permitting things within 1 window-size of the window to be binned. I wasn't doing this at all, so implemented it. This has nice performance properties, but uses more memory than the user requests, so I'm using just a 25% ""grace window"" plus the buffer to have both good performance and low memory usage. ```; Name Ratio Time 1 Time 2; ---- ----- ------ ------; table_aggregate_downsample_worst_case 39.5% 57.617 22.773; table_aggregate_downsample_dense 26.6% 127.079 33.843; ----------------------; Geometric mean: 32.4%; Simple mean: 33.1%; Median: 33.1%; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7197#issuecomment-538549413:591,Simpl,Simple,591,https://hail.is,https://github.com/hail-is/hail/pull/7197#issuecomment-538549413,1,['Simpl'],['Simple']
Usability,"I looked into this a bit and its not simple. There's a [BOMInputStream](https://commons.apache.org/proper/commons-io/javadocs/api-2.5/org/apache/commons/io/input/BOMInputStream.html) and [definitions of the BOMs](https://commons.apache.org/proper/commons-io/javadocs/api-2.5/org/apache/commons/io/ByteOrderMark.html) in commons. After handling compression and if we are looking at the first byte in the file, we need to check if the first 2-4 bytes are one of the magic BOM constants, if yes we should drop that. Unfortunately, the BOMInputStream doesn't propagate position information along. We probably need a PositionedBOMInputStream and I'm not exactly sure what getPosition should return.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6342#issuecomment-1265654206:37,simpl,simple,37,https://hail.is,https://github.com/hail-is/hail/issues/6342#issuecomment-1265654206,2,['simpl'],['simple']
Usability,"I love simpler solutions that leverage mutation, but in this case, `ggplot.py` and `geom.py` are circularly dependent if we want to use `GGPlot` in `geom.py`. I return a Boolean indicating if this geom makes the plot static. I do not love it because there is little indication of what that return value means, but I do not see another simple solution.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12336:7,simpl,simpler,7,https://hail.is,https://github.com/hail-is/hail/pull/12336,2,['simpl'],"['simple', 'simpler']"
Usability,"I made some edits that I think helped to reduce the number of places that are aware of the notion of a default_region. It's really now just isolated to the `InstanceCollectionManager`, since that's the piece of code that's making the decision ""use the default region when the cluster is small"". I didn't quite like the pattern of retrieving a default from a `LocationMonitor` just to give it right back to the location monitor in the next line. I think this way the `LocationMonitor` API is much simpler, and we can actually remove its `default_location` method entirely as I believe it is no longer used. I can do that in a follow-up PR if you like this approach. One other thing is I wanted to articulate the distinction between the ""region CI needs its jobs in"" and the ""default region that batch will spin up workers in for small clusters"". While they are in practice the same, I found that treating them both as the ""default_region"" tied the logic around jobs for CI closely with internal Batch decisions and made it more confusing for me to reason about. I tried to separate out these two concepts so that in the future when jobs support region-specific scheduling it will be easier to excise the CI-specific code from the Batch scheduler. Another thing that I realized during this process is that Azure has regions and zones just like GCP, though they may differ slightly since we don't need to specify a zone for a VM and such. I am fine with using the term ""location"" to mean ""where we scheduled the VM, either zone or region depending on the cloud provider"", but I would also like to follow up with a sweep that makes this language more precise where possible. For example, the `possible_cloud_locations` function is really just `possible_cloud_regions`, and we could even go so far as mandating a `region` field in the global config instead of having `azure_location` and `gcp_region`, which are synonymous even though named differently. It also leads me to wonder why we only schedule in a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12078#issuecomment-1207095240:496,simpl,simpler,496,https://hail.is,https://github.com/hail-is/hail/pull/12078#issuecomment-1207095240,2,['simpl'],['simpler']
Usability,I moved to TBoolean and simplified the error messages. Back to you.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/511#issuecomment-236389770:24,simpl,simplified,24,https://hail.is,https://github.com/hail-is/hail/pull/511#issuecomment-236389770,2,['simpl'],['simplified']
Usability,"I need help with the emit rule. I have what I believe to be an [XY problem](https://en.wikipedia.org/wiki/XY_problem). . The X: Implement maximal independent set in generated code.; The Y: Compile an IR as a function such that it can be passed _in generated code_ to a helper method akin to [this current implementation](https://github.com/chrisvittal/hail/blob/b286ba4a1463a81ec157e6add6d6d56c00de1138/hail/src/main/scala/is/hail/utils/Graph.scala#L50) of maximal independent set. At this point it becomes a simple method call that takes an `UnsafeIndexedSeq`, unpacks it to an array of tuples, and calls one of the other versions of maximal independent set (returning an array) that is then converted so it can be the return type of this `emitI` match arm. Thoughts, advice?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12295#issuecomment-1272085468:509,simpl,simple,509,https://hail.is,https://github.com/hail-is/hail/pull/12295#issuecomment-1272085468,2,['simpl'],['simple']
Usability,I need this for upcoming improvements to SplitMethod. Summary:; - add Block.replace; - have Block track uses; - makes SimplifyControl simpler; - Method.findBlocks prunes dead uses,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9000:118,Simpl,SimplifyControl,118,https://hail.is,https://github.com/hail-is/hail/pull/9000,2,"['Simpl', 'simpl']","['SimplifyControl', 'simpler']"
Usability,I need to test this with dev deploy and make sure it actually works. But would appreciate feedback on the design before I start doing that.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8445:90,feedback,feedback,90,https://hail.is,https://github.com/hail-is/hail/pull/8445,1,['feedback'],['feedback']
Usability,"I need to write another scala test, but it's working as expected in; large test cases in benchmarks. ```; Name Ratio Time 1 Time 2; ---- ----- ------ ------; table_aggregate_downsample_worst_case 57.8% 57.617 33.278; table_aggregate_downsample_dense 30.0% 127.079 38.119; ----------------------; Geometric mean: 41.6%; Simple mean: 43.9%; Median: 43.9%; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7197:319,Simpl,Simple,319,https://hail.is,https://github.com/hail-is/hail/pull/7197,1,['Simpl'],['Simple']
Usability,"I now pass the scores_table through as a Table rather than localizing and passing through colKeys, colKeyType, and scores annotations. The column key can now be any type. Both string and integer keys are tested from Python. However, `requireUniqueSamples` still requires a single string ID (this was the remaining problem of going generic), so I've removed this check and would appreciate feedback on the best approach to checking uniqueness, preferably on the localized `keys` in PCRelate so as not to trigger additional actions. I could use keyType.valuesSimilar to compare any two elements...it's a bit weird to have a tolerance on floats here. As noted, I'm also a bit wary that I'm relying on `scores` from `pca` to be in the same order as the columns on the matrix table. This is currently true, but could change. @danking I think the joins in `fuse` should also be zipPartitions, I've noted it in a FIXME. I'm also concerned that the number of diagonal blocks is an upper bound on parallelism for the matrix multiply. We should be able to fix that by immediately writing and then reading phi.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3211#issuecomment-376385065:389,feedback,feedback,389,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376385065,2,['feedback'],['feedback']
Usability,"I picked the name since Cronus is the father of Zeus. Perhaps Saturn is more appropriate. Open to suggestions here. The UX flow:. 1. User loads up `https://hail.is/cronus` and sees a form with a button.; 2. Pressing the button starts a pod running Jupyter for the user that no one else has access to; 3. refreshing the page or going to `https://hail.is/cronus` again redirects to the Jupiter instance; 4. to get a fresh Jupyter instance, the user can clear their cookies. The components:. - a flask app (`cronus/cronus.py`) which launches pods and handles authentication (via cookies); - an nginx reverse proxy which uses `auth_request` to check the permissions with the flask app; - a pod running `Jupyter notebook` with hail `pip` installed. TODO:. - [x] add make targets to generate the `cronus-job` image (the jupyter notebook image); - [ ] maybe simplify the directives used in nginx? I kept throwing shit at it until it worked; - [ ] figure out how to teach flask url_for to use a root other than `/`. I don't know what HTTP proxy headers to set to inform it that it lives at a subdirectory of `hail.is`; - [ ] get rid of the button? creating a new pod needs to be a `POST` so that the web browser doesn't access twice or eagerly access it, etc. maybe I can use javascript on the root page to make the post request and redirect the page.; - [ ] testing? I could add some basic things, but the most time consuming and annoying thing was getting the reverse proxy settings right and testing that requires an nginx instance. @cseed I randomly assigned, should I be picking from you and Tim? What's the plan for review on these new things?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576:120,UX,UX,120,https://hail.is,https://github.com/hail-is/hail/pull/4576,3,"['UX', 'clear', 'simpl']","['UX', 'clear', 'simplify']"
Usability,"I prefer reworking count, killing the genotypes parameter, so that it's always just a simple/efficient way to get (nSamples, nVariants, nGenotypes, nCalled, callRate). I don't see why a tuple is better than a dict.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1505#issuecomment-284860282:86,simpl,simple,86,https://hail.is,https://github.com/hail-is/hail/issues/1505#issuecomment-284860282,2,['simpl'],['simple']
Usability,"I put point_type back. Should be ready to go now. Also, fixed the close definition, good catch. I also removed an additional use of _convert_to_j in import_bgen to get the tests to pass from this PR (sorry my stacking got a bit mixed up): https://github.com/hail-is/hail/pull/5150/files#diff-36d21c1427efe06a781cd36ef5aa8678R961. You can also wait for that to go in and I'll rebase if you're worried about the change. Finally, the imports are a bit of a mess since I wanted to use hail_type in interval.py which is also imported by the types and expr files. @tpoterba I think we should remove types from expr and remove java from utils (we're confusing user utils like hadoop_* and Interval from internal utils like Env and java stuff which don't seem related) and have a clear ""import"" graph: javautils > types > utils > expr.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5152#issuecomment-456684801:772,clear,clear,772,https://hail.is,https://github.com/hail-is/hail/pull/5152#issuecomment-456684801,2,['clear'],['clear']
Usability,"I rage programmed here a bit. I was pretty frustrated with this class when; trying to debug some other issues in the Shuffler IR. I have two aims with this; PR:; 1. Use a clear, consistent naming scheme throughout the file; 2. Use concise definitions. In particular, I unified the terminology to use these words:; - name: the function's name; - valueParameterTypes: the type of each value-level parameter; - typeParameters: the type-level parameters, these are always type variables, I; considered calling them typeVariables, but I like the symmetry with valueParameters; - returnType and returnPType; - typeArguments and valueArguments: these refer to the concrete values to which the parameters are bound. I also simplified some anonymous class definitions by providing constructor arguments; instead of methods that are always overridden by `val`s.; Oh, and I changed `IRFunction` to `JVMFunction` because there are already ""IR"" functions; and an ""irRegistry"" and it was super confusing to not have the IRFunctions inside the; ""irRegistry"". I did not use `CodeFunction` because these are actually implemented by; a number of different JVM Bytecode building tools: `Code`, `PCode`, `EmitCode`, and; `IEmitCode`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8718:171,clear,clear,171,https://hail.is,https://github.com/hail-is/hail/pull/8718,2,"['clear', 'simpl']","['clear', 'simplified']"
Usability,"I ran the stress test. It finished in 8 minutes which makes for a paltry 2 jobs per second. That was largely driven by three jobs that took 5 minutes (!!!) to upload their logs to GCS. No idea what's going on there, but clearly unrelated to these DB changes. If you ignore those jobs and the private jobs, which required VM spin up, it only took 3 minutes, which is still an unfortunate 6 jobs per second, but I have more speed coming.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10985#issuecomment-954864994:220,clear,clearly,220,https://hail.is,https://github.com/hail-is/hail/pull/10985#issuecomment-954864994,2,['clear'],['clearly']
Usability,I realized I was missing some region clears from aggregate methods on ContextRDD.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3514:37,clear,clears,37,https://hail.is,https://github.com/hail-is/hail/pull/3514,1,['clear'],['clears']
Usability,"I renamed RichProgressBar and SimpleRichProgressBar to ...CopyToolProgressBar because that is more accurate. I enhanced both to now include a count and a rate with the right units based on the description. It is a bit flaky because I need the descriptions to be exactly ""files"" or exactly ""bytes"" to pick the right units, but this seems fine for the specific case of th CopyToolProgressBar. There is probably a better way to build these UIs. I am sure we will start to figure that out as we use rich more. Before:; <img width=""830"" alt=""Screenshot 2023-10-16 at 18 28 14"" src=""https://github.com/hail-is/hail/assets/106194/95f8828e-beb3-46d2-9403-18ff7aa60256"">. After:; <img width=""830"" alt=""Screenshot 2023-10-16 at 18 27 53"" src=""https://github.com/hail-is/hail/assets/106194/01186b7c-d59f-4a0e-a1f6-9279fb50ae7e"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13832:30,Simpl,SimpleRichProgressBar,30,https://hail.is,https://github.com/hail-is/hail/pull/13832,1,['Simpl'],['SimpleRichProgressBar']
Usability,"I saw an error in a CI job that was copying in some files. To be clear,; this change would not restart a copy of the entire directory. It just; retries the directory listing. We currently use O(N_FILES) memory to; store the list of files in a directory *before* we start copying. ```; Traceback (most recent call last):; File ""/usr/lib/python3.7/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/usr/lib/python3.7/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiotools/copy.py"", line 110, in <module>; asyncio.run(main()); File ""/usr/lib/python3.7/asyncio/runners.py"", line 43, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1501, in uvloop.loop.Loop.run_until_complete; File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiotools/copy.py"", line 104, in main; files=files; File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiotools/copy.py"", line 76, in copy_from_dict; transfers=transfers; File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiotools/copy.py"", line 50, in copy; bytes_listener=make_tqdm_listener(byte_pbar)); File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiotools/fs/copier.py"", line 439, in copy; await copier._copy(sema, copy_report, transfer, return_exceptions); File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiotools/fs/copier.py"", line 532, in _copy; raise e; File ""/usr/local/lib/python3.7/dist-packages/hailtop/aiotools/fs/copier.py"", line 527, in _copy; ], return_exceptions=return_exceptions, cancel_on_error=True); File ""/usr/local/lib/python3.7/dist-packages/hailtop/utils/utils.py"", line 519, in bounded_gather2; return await bounded_gather2_raise_exceptions(sema, *pfs, cancel_on_error=cancel_on_error); File ""/usr/local/lib/python3.7/dist-packages/hailtop/utils/utils.py"", line 504, in bounded_gather2_raise_exceptions; return await asyncio.gather(*tasks); File ""/usr/local/lib/python3.7/dist-packages/hailtop/utils/utils.py"", lin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11511:65,clear,clear,65,https://hail.is,https://github.com/hail-is/hail/pull/11511,1,['clear'],['clear']
Usability,"I saw this again today in a fairly simple and isolated test. I'm beginning to wonder if this is just a new form of transient error. We pick 22 random characters from a 62 character alphabet. Odds of collision are minuscule:; ```; In [2]: (1/62)**22; Out[2]: 3.693029961058969e-40; ```; I verified `SecureRandom` with no constructor uses a randomly chosen seed. There's three exceptions there (all the same one). The deepest one came during a write. The next two came during closes. The outermost exception is from the `using` cleaning up. I'm not sure where the middle exception comes from, I can't imagine who would try to `close` the stream other than `using`. Regardless, it appears that the upload fails in some unrecoverable way. We're writing 2GiB in 256 8MiB chunks in this test, so we have more chances for something to go wrong. Maybe we just have to retry the entire partition when this happens?. https://ci.hail.is/batches/7404773/jobs/145; ```; starting test is.hail.fs.gs.GoogleStorageFSSuite.testSeekMoreThanMaxInt...; Exception:; is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-6BO4gZ18Lheigp3ir9RSOh&uploadType=resumable&upload_id=ADPycduiXx2Jtiy_0Ll131_pPeEYKnnA23Hlk28_9TFESUMaubA9OqLK_n8Td5rPhTXnlpssGo796Q4bJxUeblhmSaYcCSWAMg2k; chunkOffset: 16777216; chunkLength: 8388608; localOffset: 1325400064; remoteOffset: 1342177280; lastChunk: false. 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756:35,simpl,simple,35,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756,2,['simpl'],['simple']
Usability,I see the docs for the PyHail API but is there a getting started guide available yet? Also are there any plans to make a PyHail package available for installation through PyPI?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1218:65,guid,guide,65,https://hail.is,https://github.com/hail-is/hail/issues/1218,1,['guid'],['guide']
Usability,"I simplified the TLS context methods into three cases: internal server, external; client session, internal client. I added a blocking shim around aiohttp so that all our HTTP goes through; aiohttp. I added automatic retrying directly into the httpx library.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9743:2,simpl,simplified,2,https://hail.is,https://github.com/hail-is/hail/pull/9743,1,['simpl'],['simplified']
Usability,"I staged `import_matrix_table` and achieved substantial performance improvements. A few changes were necessary:; - `FunctionBuilder` now accepts `Code[Unit]` to be added to the `init` method of the function object; - SRVB now has an `init` method that should be called in the `init` method of a function object if many methods will share the SRVB; - `CodeChar` now exists. The main change is in `ImportMatrix.scala` which is both staged and based on scanning the string rather than using `String.split`. The approach is essentially a simplified, staged version of `import_vcf`. I benchmarked the change with:; ```; In [2]: %%time ; ...: import hail as hl ; ...: m = hl.import_matrix_table('/tmp/foo.tsv.gz', ; ...: row_fields={'f0': hl.tstr}, ; ...: no_header=True, ; ...: sep=' ', ; ...: min_partitions=16) ; ...: m = m.key_rows_by(locus=hl.parse_locus(m.f0)) ; ...: m._force_count_rows() ; ```. `/tmp/foo.tsv.gz` is a gzipped (not blocked) 1GB of 1000 rows each containing one row column and 500k sample columns. The entries are the integers from 0 to 499,999. The first column is the first run (when the JIT is warmed) and the second column is the mean of two subsequent runs. All times in seconds. Everything is necessarily executed on one core. | version | cold | warm |; | --- | --- | --- |; | this PR | 48 | 39.35 |; | this PR with one monolithic method | 235 | 73 |; | master (5fe6737263b4) | 91s | 83.5 |. I was disappointed with the performance of the monolithic method, so I dug in with `-XX:+PrintCompilation` and found that the JIT was having trouble doing on-stack replacement of the entry parsing loop. There was a cryptic message about the stack not being empty during an OSR compilation. I take this result as evidence that, in the JVM, small, fine-grained methods are critical for reliable performance. The new code, after JIT warming, is reading at 250 MB/s (1GB / 40 seconds) which is a half to a third of the performance of `cat`. It's more than twice as fast as the old code. Asi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6987:534,simpl,simplified,534,https://hail.is,https://github.com/hail-is/hail/pull/6987,1,['simpl'],['simplified']
Usability,"I still dislike job_group_tree because trees are usually represented in terms of their ancestor or parent-child relationships, neither of which are what this is. That said, I don't think we should block this PR on a naming quibble. We can do renames separately. We should update the RFC to be clear about the unique identifiers of the three things groups, jobs, and batches. (In particular, jobs are uniquely identifier by batch id and job id, group id is not part of it).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13475#issuecomment-1760376350:293,clear,clear,293,https://hail.is,https://github.com/hail-is/hail/pull/13475#issuecomment-1760376350,2,['clear'],['clear']
Usability,I suspect we can eliminate any unnecessary overhead by staging this. I figured I should get feedback on it first before I expend the energy on that. I also include `VariantView` and `AltAlleleView` as examples of using `StructView` to create succinct views.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2418:92,feedback,feedback,92,https://hail.is,https://github.com/hail-is/hail/pull/2418,1,['feedback'],['feedback']
Usability,I talked to Cotton about it and he said not to. But it's not clear how much of a difference that makes yet anyway. I think this version is pretty good and an improvement. Plus it'll add a benchmark which we can work on optimizing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9209#issuecomment-668622849:61,clear,clear,61,https://hail.is,https://github.com/hail-is/hail/pull/9209#issuecomment-668622849,2,['clear'],['clear']
Usability,"I think I can simplify the computation of the principal components. First let me summarize how the paper presents PC-AiR. ### Original Presentation. Suppose that there are $n_u$ individuals in the unrelated set and $p$ SNPs. Let $X$ be the $n_u \times p$ standardized genotype matrix for the unrelated individuals. The paper starts by computing. $$\Psi \coloneqq \frac{1}{p}XX^T.$$. Next the paper eigendecomposes $\Psi$:. $$\Psi = U \Sigma^2 U^T,$$. where $U$ are the eigenvectors and $\Sigma^2$ is the diagonal matrix with the eigenvalues along the diagonal. Then the paper computes a $p \times n$ matrix $W$ called the **SNP weight matrix**:. $$W \coloneqq X^T U.$$. Suppose that there are $n_r$ individuals in the related set and let $Y$ be the $n_r \times p$ standardized genotype matrix for the related individuals. The paper computes the principal components associated with the related samples with. $$ \frac{1}{p} Y W (\Sigma^2)^{-1}.$$. ### Simplifications. The first simplification that I noticed is that we can do away with the $\frac{1}{p}$ terms. Because $\Psi$ is scaled by $p^{-1}$, the inverse of the eigenvalues, $(\Sigma^2)^{-1}$ is scaled by $p$, which cancels out the $1/p$ term in the calculation of the principal components for the related individuals. From here on, let us redefine $\Sigma^2$ as the diagonal matrix containing the eigenvalues of $XX^T$ (not $\frac{1}{p} XX^T$). Next, by examining the relationship between singular value decomposition (SVD) and eigendecomposition ([Wikipedia link](https://en.m.wikipedia.org/wiki/Singular_value_decomposition#Relation_to_eigenvalue_decomposition)), I realized that it is not necessary to compute $\Psi$. Instead, we can get $U$ and $\Sigma$ from the SVD of $X$:. $$X = U\Sigma V^T,$$. where $V$ is a $p \times p$ basis of the new PCA coordinate space. Then while investigating the meaning of $W$, I realized that $W = X^T U = V \Sigma^T U^T U = V \Sigma^T$. Taking these simplifications into account, I realized that the paper",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14326#issuecomment-1962279184:14,simpl,simplify,14,https://hail.is,https://github.com/hail-is/hail/pull/14326#issuecomment-1962279184,3,"['Simpl', 'simpl']","['Simplifications', 'simplify']"
Usability,"I think I'd flip the logic. I'm not sure if this one is wrong:. ```; In [9]: hl.eval((p, hl.range(2).map(lambda x: p))); Out[9]: (0.46124206583236194, [0.46124206583236194, 0.46124206583236194]); ```. But if it's right, clearly this one is wrong:. ```; In [7]: p = 1 - r. In [8]: hl.eval(hl.range(2).map(lambda x: p)); Out[8]: [0.46124206583236194, 0.06052003544873086]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7572#issuecomment-557020739:220,clear,clearly,220,https://hail.is,https://github.com/hail-is/hail/issues/7572#issuecomment-557020739,2,['clear'],['clearly']
Usability,"I think I'm seeing more where this approach is coming from, specifically we put batches as they exist today in a special category of having no updates and avoid the new code path in that case. An alternative which pairs with my above suggestion of not adding new staging tables is that all batches have at least 1 update. I feel like if we can force all batches down the new code path we'll be incentivized to make it really low overhead for batches that only submit jobs once, and that will benefit all batches, as well as simplifying the mental model. I may be wrong that we can do this with minimal performance tradeoff, but I'd like to try it first.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12010#issuecomment-1219807488:524,simpl,simplifying,524,https://hail.is,https://github.com/hail-is/hail/pull/12010#issuecomment-1219807488,2,['simpl'],['simplifying']
Usability,"I think Tim is right and that seems better than an undocumented hidden option, though I admit it's about as undocumented and hidden.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7964#issuecomment-578799305:51,undo,undocumented,51,https://hail.is,https://github.com/hail-is/hail/pull/7964#issuecomment-578799305,4,['undo'],['undocumented']
Usability,"I think functionality wise this is all ready to go. Added to the docs as well, though those probably need another iteration. Either way, it's safe to start looking this over and give some feedback.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1929:188,feedback,feedback,188,https://hail.is,https://github.com/hail-is/hail/pull/1929,1,['feedback'],['feedback']
Usability,"I think if it's not too hard of a change, we should add the files with encoded secrets to something like `infra/gcp/data/...`. This makes it clear that these files have a different purpose and gives some indication that they're specific to your repo. If you want to also add prefixing the file name with the repo, then that would make it even clearer. But if it's too much work, don't bother. Maybe something like `infra/gcp/data/hail-is/` etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11724#issuecomment-1171321194:141,clear,clear,141,https://hail.is,https://github.com/hail-is/hail/pull/11724#issuecomment-1171321194,4,['clear'],"['clear', 'clearer']"
Usability,I think it's clearer with one instance of the JPIC,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9972#issuecomment-773722261:13,clear,clearer,13,https://hail.is,https://github.com/hail-is/hail/pull/9972#issuecomment-773722261,2,['clear'],['clearer']
Usability,"I think maybe I'm overcomplicating the regions thing. Just not specifying regions clearly means you can schedule anywhere. `regions(None)` is confusing, but users should never do that directly. It will only happen when folks are programmatically generating jobs. People doing that are experts who will understand that `None` is just a stand in for ""any region"".",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1270359051:82,clear,clearly,82,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1270359051,2,['clear'],['clearly']
Usability,"I think that's right, though we serialize other potentially private information. I think we ought to have a per-organization (Hail billing project?) cache, but also not very high priority. I'd be pretty chuffed to learn we're running important enough stuff that people are attempting timing attacks on our cache to learn what queries other people are executing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10309#issuecomment-821250865:214,learn,learn,214,https://hail.is,https://github.com/hail-is/hail/pull/10309#issuecomment-821250865,4,['learn'],['learn']
Usability,I think the best way to provide feedback is with things like progress bars.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7828#issuecomment-572727108:32,feedback,feedback,32,https://hail.is,https://github.com/hail-is/hail/issues/7828#issuecomment-572727108,4,"['feedback', 'progress bar']","['feedback', 'progress bars']"
Usability,"I think the clear default answer is referential transparency. Whether you bind something in a python variable, or you inline that definition, should be semantically equivalent. Unless we come up with a compelling reason to break that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7418#issuecomment-548485790:12,clear,clear,12,https://hail.is,https://github.com/hail-is/hail/issues/7418#issuecomment-548485790,2,['clear'],['clear']
Usability,"I think the proposed new default and the option to change it is much more intuitive than the current behavior and worth a change. Though, I think it would be most polite to announce it on zulip/email list a week or two in advance of the release (which you may already planned to do).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11884#issuecomment-1145290949:74,intuit,intuitive,74,https://hail.is,https://github.com/hail-is/hail/pull/11884#issuecomment-1145290949,2,['intuit'],['intuitive']
Usability,I think this interface is clearer and it will be a necessary change when atomic batch creation causes the batch_id to be None until the entire batch is submitted.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6241:26,clear,clearer,26,https://hail.is,https://github.com/hail-is/hail/pull/6241,1,['clear'],['clearer']
Usability,I think this is a bit more clear about Hail JARs and gives a working snippet of code (for version 1.6.2).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1080:27,clear,clear,27,https://hail.is,https://github.com/hail-is/hail/pull/1080,1,['clear'],['clear']
Usability,I think this is due to HDFS filling up. Possibly related to the fact Tim was creating a copy of ExAC. I will retry the job once we clear up some space.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/301#issuecomment-210901646:131,clear,clear,131,https://hail.is,https://github.com/hail-is/hail/issues/301#issuecomment-210901646,2,['clear'],['clear']
Usability,"I think this is the intended behavior (at the very least a warning), but at the moment it simply silently does nothing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3756:90,simpl,simply,90,https://hail.is,https://github.com/hail-is/hail/issues/3756,1,['simpl'],['simply']
Usability,I think this little change adds a lot of usability to the method. You do not need to know how the names of the tables are constructed in the function.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11077:41,usab,usability,41,https://hail.is,https://github.com/hail-is/hail/pull/11077,1,['usab'],['usability']
Usability,"I think this should resolve the issues we were seeing with OnlineBoundedGather2. Changes:; - cancelled tasks (those that raise CancelledError) are ignored (we don't propagate cancelled out of background tasks); - Make sure all exceptions are either reraised or logged; - The first exception is raised out of exit, not call; - call raises PoolShutdownError if the pool is shutdown; - _shutdown doesn't signal _done_event until all cancelled tasks are complete; - call clears _done_event (not strictly necessary because exit checks pending, but seems safer); - added copious docstrings",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10342:467,clear,clears,467,https://hail.is,https://github.com/hail-is/hail/pull/10342,1,['clear'],['clears']
Usability,"I think this was inadvertantly broken. The `Progress.disable` property needs to be set *before* you start the progress bar, otherwise it has no effect. Clients of all these progress bars should not touch their `Progress` instance, that is an implementation detail. I have changed rich_progress_bar.py to use `_progress` to clearly communicate this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13668:110,progress bar,progress bar,110,https://hail.is,https://github.com/hail-is/hail/pull/13668,3,"['clear', 'progress bar']","['clearly', 'progress bar', 'progress bars']"
Usability,"I think this was inadvertantly broken. The `Progress.disable` property needs to be set *before* you start the progress bar, otherwise it has no effect. Clients of all these progress bars should not touch their `Progress` instance, that is an implementation detail. I have changed rich_progress_bar.py to use `_progress` to clearly communicate this. Unrelatedly, it seems that `add_task` accepts varargs which become arbitrary additional metadata for the task. There is no `disable` keyword, that is just added as additional metadata. Instead, we must use the `visible` keyword to enable/disable the task. I verified this looks right now:. ```python3; In [1]: import hailtop.batch_client.aioclient as ac; ...: try:; ...: client = await ac.BatchClient.create('hail'); ...: b = client.create_batch(); ...: resources = {'machine_type': ""g2-standard-4"", 'storage': '100Gi'}; ...: j = b.create_job(; ...: '2.0.1-debian-11-r122',; ...: ['python', '-c', 'import torch; assert torch.cuda.is_available()'],; ...: resources=resources,; ...: ); ...: await b.submit(); ...: await b.wait(); ...: finally:; ...: await client.close(); https://batch.hail.is/batches/8038881 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 1/1 0:00:00 0:01:53; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13669:110,progress bar,progress bar,110,https://hail.is,https://github.com/hail-is/hail/pull/13669,3,"['clear', 'progress bar']","['clearly', 'progress bar', 'progress bars']"
Usability,"I think tying the reset to the iterator is a mistake. First, iterator is the wrong abstraction here. Whole-stage code generation should use the aggregator/array strategy we're using in Emit to generate nothing, conditionals and loops for map, filter and flatMap, respectively. Ideally read ... do stuff ... write will generate an RDD with no per-element iterators at all. I want to make sure this picture is clear. Second, we want to vectorize in the database sense: we want to process multiple rows together in batches. Then overall structure of a stage is a loop over the batches, and and a loop within batches. Thus, the common case should not be we reset after every element, so I think it's the wrong direction to bake it in. The place where we do this should be interface points with the Spark stack which should be looked at with scorn and derision and as the organizing model. Finally, this points to an ongoing difference in our views about the meaning of context. I see context as serving two purposes (neither of which involve reset):. - First, context is a set of resources needed to process a partition that should be released when the partition is complete. For example, I'm working on GenomicsDB which needs to localize a GenomicsDB shard to a local file that needs to be cleaned up when the partition is complete. - Second, it is a way to tell an iterator where to return its value. (This is the ""current"" region business.). I'd be happy to separate these, but I don't see clean way. In no case do I see generic logic to manage the lifetime of regions (e.g. knowing when to call reset) inside the Context.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3365#issuecomment-381180739:408,clear,clear,408,https://hail.is,https://github.com/hail-is/hail/pull/3365#issuecomment-381180739,2,['clear'],['clear']
Usability,"I think we also need to be clear when installing something that will break everyone's local tests (email, dev post, something).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3273#issuecomment-377700023:27,clear,clear,27,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377700023,2,['clear'],['clear']
Usability,"I think we should find a time to discuss this in person if the following explanation doesn't make sense. . Right now, for small batches, we send one REST request to the server to both create the batch and create the jobs. However, if we want one REST request for an update (ideal for the query service and low latency jobs?), we have to use relative job ids because (1) we don't know the absolute start index of the jobs until we've gotten the start id of the update back from the server and (2) the job dependencies can be a mix of known job ids that have already been previously submitted in a previous creation/update. The negative job IDs are a way to deal with a mix of relative ids within an update and known, submitted job ids. We can simplify things if we require all updates make two requests to the server to (1) get the start id and establish the update and then (2) submit new jobs with all absolute job IDs. I'd have to make sure this will actually simplify things because I also ran into a bifurcation in how the job IDs are handled in `BatchBuilder.create_job()`. We currently populate the spec with a job id before we've made any requests to the server. We need to know how many total jobs there are before we can figure out the job ids because the API for creating a new update requires reserving a block of job IDs which then returns the start id. This complexity is because we allow multiple updates to occur simultaneously to a batch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12010#issuecomment-1215919856:742,simpl,simplify,742,https://hail.is,https://github.com/hail-is/hail/pull/12010#issuecomment-1215919856,4,['simpl'],['simplify']
Usability,"I think we should have the following design that runs the benchmarks in k8s because then we are using google's internal network to transmit data (compared to running on my local computer via a cloud proxy):. - Have a `db-benchmark` namespace in k8s specifically for this. 1. create_db.py; a. This will take the parameters needed for `gcloud sql instances create` including database flags, disk space, cores, etc. and create an instance; b. Get the IP address of the instance (hopefully the REST API works for this); c. Create a database; d. Create user and password for the database; e. Create config file; f. Create secret in the db-benchmark namespace from the config file; ; 2. run.py; a. Build the docker image with the benchmark.py code and installs aiomysql, etc.; b. Create pod which mounts the correct secret with the sql config for the instance to use. Environment variables specify the n_replicates, etc. Print out the pod name.; c. Wait for the pod to complete (you have code in CI that does this); d. Download logs; e. Delete the pod. 3. cleanup.py; a. Delete mysql instance; b. Delete kubernetes secret in db-benchmark namespace. Thoughts? . I tried to think about how to use the current build system and what I would do is add a new CreateSQLInstance step, CreateDatabase takes the instance name and IP address as a parameter, and have CI take a path to the build.yaml file to build from. But this wasn't straightforward with how to do this, so I thought the above was simpler to reason about.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7181#issuecomment-538453887:1483,simpl,simpler,1483,https://hail.is,https://github.com/hail-is/hail/pull/7181#issuecomment-538453887,2,['simpl'],['simpler']
Usability,"I think we should provide more information than the progress bar, but I concede that all three panels shown above is probably too much information by default when you're in ipython or python. In contrast, `hailctl batch submit` should probably display lots of information by default with a `--silent` flag to shut it off.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13063#issuecomment-1572344856:52,progress bar,progress bar,52,https://hail.is,https://github.com/hail-is/hail/issues/13063#issuecomment-1572344856,2,['progress bar'],['progress bar']
Usability,"I think we shouldn't be doing this type of feature without proper planning and a vision for the overall user experience. Perhaps this sort of item should go on a formal road map and not as an ""issue""?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13063#issuecomment-1572357250:104,user experience,user experience,104,https://hail.is,https://github.com/hail-is/hail/issues/13063#issuecomment-1572357250,2,['user experience'],['user experience']
Usability,"I think you're right. I tried a number of things, but I need something to key the column by, and a global has no concept a key (which is why it is a global). I found this very confusing. . Let's say mt.C contains phenotypes for samples 1..n. This is, in my mind, a distributed array, with someone fancy (non-integer) indexing support. Great, but I don't care about that, I just want a distributed array. I want to localize_entries, but this creates a hail Table, which drops my phenotypes, because that's now a table and not a matrix table (why! all I wanted was to create a new field in my MT with the result of a column aggregation per row). So the natural thing I reach to is storing my phenotypes elsewhere. I think: ""I want to continue benefitting from Hail query planner), so I try not to materialize the phenotypes in memory. If I say mt.annotate_globals(Y = mt.C) I expect that to just work, because in my mind, I took something that was a a distributed array, but with more powerful indexing support, and converted it to something that is even more array like, that I'm going to need to understand how to index myself (which I'm fine with since I'm moving the thing to globals). Alternatively, I could also expect that globals now contains a reference to a new table, that contains only the column index, and value (phenotype), which seems fine. Neither of these options happens. Instead, I need to realize the array in memory on my master, which seems like a potentially bad idea. The bigger problem though is that I want 1 change (simplify indexing or make a reference to the array), and I seem to need 3 (that + memory + loss of distribution). . In short: I want to be able to choose whether I realize the values in memory, not be forced into it. Let me know if there's something I missed!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9121#issuecomment-662693797:1542,simpl,simplify,1542,https://hail.is,https://github.com/hail-is/hail/issues/9121#issuecomment-662693797,2,['simpl'],['simplify']
Usability,"I thought about it a bit, and I think it is clear what to do (ultimately) for registered functions: we need a variant that takes PCode instead of Code[_], and then we can begin to migrate the functions incrementally. A separate thread of work, obviously.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8351#issuecomment-603808832:44,clear,clear,44,https://hail.is,https://github.com/hail-is/hail/pull/8351#issuecomment-603808832,2,['clear'],['clear']
Usability,"I thought about porting some of the typechecker stuff from hail, but they don't serve quite the same purpose, and the functions themselves are pretty simple. This does move the schema definitions to the bottom of the file rather than at the top, but this way we have a schema description that includes requiredness and is guaranteed to be the thing we're actually validating on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9861:150,simpl,simple,150,https://hail.is,https://github.com/hail-is/hail/pull/9861,1,['simpl'],['simple']
Usability,I thought this was the simplest way of solving this. I could also have checked the container name in Container.run and selected the right semaphore there.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7649:23,simpl,simplest,23,https://hail.is,https://github.com/hail-is/hail/pull/7649,1,['simpl'],['simplest']
Usability,I took a look at what we are currently outputting. I think this is relatively straightforward except for the HWE test. I don't know of a multiallelic version of HWE. A simple approach would be to compute HWE for each alternate allele compared to the reference allele. Where this gets tricky is how to handle heterozygotes where the second allele is not the reference allele. Example: 1/2 genotype.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2206#issuecomment-328648857:168,simpl,simple,168,https://hail.is,https://github.com/hail-is/hail/issues/2206#issuecomment-328648857,2,['simpl'],['simple']
Usability,"I tried adding clearer names, but I thought that talking about ""new"" vs ""old"" was relatively clear. I may be too deep in it to judge these days.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8867#issuecomment-634763312:15,clear,clearer,15,https://hail.is,https://github.com/hail-is/hail/pull/8867#issuecomment-634763312,4,['clear'],"['clear', 'clearer']"
Usability,"I understand what is going on now. The issue is that the temp directory is getting removed after the first batch.run(), but we're assuming those input files are still there. I think we should just clear the files and definitions cache after submission.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12530#issuecomment-1426386771:197,clear,clear,197,https://hail.is,https://github.com/hail-is/hail/pull/12530#issuecomment-1426386771,2,['clear'],['clear']
Usability,"I use codec.py extensively for debugging the shuffler. Recently the Scala-side support for codec.py was deleted. This PR restores support and adds some simple tests. I need to thread the physical type back to the caller of compile, thus all the changes in CompileAndEvaluate and Backend. They should look better with whitespace changes hidden.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8197:152,simpl,simple,152,https://hail.is,https://github.com/hail-is/hail/pull/8197,1,['simpl'],['simple']
Usability,"I used `RegionValueVariant` to clean up some of the code, and fixed a couple of bugs from #2451 in the process. I also replaced the `aggregatePartitions` method I wrote in e5f87c3 following @danking's comment, which was defined on `OrderedRDD2`, with `aggregateWithContext`, which is defined on a rich wrapper around `RDD`. I put it in the spark package to get access to private methods, making the implementation cleaner. It is now a simple modification of the implementation of `RDD.aggregate`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2423#issuecomment-347624179:435,simpl,simple,435,https://hail.is,https://github.com/hail-is/hail/pull/2423#issuecomment-347624179,2,['simpl'],['simple']
Usability,"I want cancel_after_n_failures to be on a job group. The things a job group doesn't have which maybe it should is:; - callback; - attributes; - updates. I think updates should be on a batch and not part of a job group. An update can add jobs to multiple job groups. Otherwise, the batches table should only have static fields that apply to the entire batch. I think we can do callbacks and attributes on a job group. I added a PATCH endpoint to be able to update a job group's cancel_after_n_attributes as the hailtop.batch interface was going to automatically generate job groups without any configuration settings. As for the full text search, I think prefix searches are faster with full text search than with a regular index, but I could be wrong. We'd have to benchmark it. > If we made batches simpler, does that ease complexity and decrease code duplication? In particular, what if batches didn't contain jobs at all? Instead, a batch contains exactly one job group. That job group contains zero or more job groups. Job groups manage: resource aggregation, cancellation, etc. I believe my plan is basically already doing this. It might not be clear because I didn't put the migrations in. But basically all of the current batches tables are now indexed by batch_id, job_group_id where the current ""batch"" has job_group_id = 1.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12697#issuecomment-1450603163:800,simpl,simpler,800,https://hail.is,https://github.com/hail-is/hail/pull/12697#issuecomment-1450603163,4,"['clear', 'simpl']","['clear', 'simpler']"
Usability,"I want this for interface purposes, but it's really not usable due to performance. It takes 2 minutes to collect sample.vcf. I think that py4j is the main culprit, but the history stuff also slows it down a ton.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2209:56,usab,usable,56,https://hail.is,https://github.com/hail-is/hail/pull/2209,1,['usab'],['usable']
Usability,I want to do testing with dev deploy. Putting this up so I can get feedback.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7910:67,feedback,feedback,67,https://hail.is,https://github.com/hail-is/hail/pull/7910,1,['feedback'],['feedback']
Usability,"I want to explore having a KeyedSeqOp IR class instead of the key as an argument to the SeqOp IR. I think that would simplify the code, especially if we have a second kind of SeqOp such as windowed. I can't remember why this didn't work before when I tried it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3824#issuecomment-399712664:117,simpl,simplify,117,https://hail.is,https://github.com/hail-is/hail/pull/3824#issuecomment-399712664,2,['simpl'],['simplify']
Usability,"I want to have a functionality when import VCF, disable the filter based on `sum(AD) != DP`. Although this is a good sanity check, but since we are not clear if this error will lead to inaccurate genotype calls, there will be an option for analyst to keep those calls.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/427:152,clear,clear,152,https://hail.is,https://github.com/hail-is/hail/issues/427,1,['clear'],['clear']
Usability,"I want to respond to some of your objections to unique_ptr. > If you buy into using std::unique_ptr, then everyone who writes or reads the code has to get; their head around the massively confusing and counter-intuitive concept of move semantics (a; form of assignment which modifies the source) and the somewhat bizarre terminology and syntax; used to express that in C++. I agree that move semantics takes getting used to, but I think it is much too integrated into modern C++ to ignore, going far beyond unique_ptr. Writing interfaces that take advantage of move semantics requires understanding rvalue-references in more detail, but for users of those move-enabled interfaces I think the guidelines are easy to teach: a variable will only be modified by moving if it is explicitly tagged with a `std::move`, so all you have to remember is ""after a `std::move(foo)`, the variable `foo` may only be assigned to or deleted."". > And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). Keeping in mind the model that letting a function/class `foo` hold a `unique_ptr<Widget>` means explicitly ""`foo` owns this Widget, and is responsible for deleting it or passing ownership somewhere else"", these questions have pretty clear answers. * If a function `bar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Wid",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:210,intuit,intuitive,210,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638,4,"['guid', 'intuit']","['guidelines', 'intuitive']"
Usability,"I wanted to chime in on this briefly because I think it a good example use case and its design will influence many future methods, so it is important to get the design right. Thoughts:. - the underscore stuff is a non-starter in my opinion, and too clever by half. A lot of my feedback on your stuff is guided by the general heuristic that you should start by writing down the code you want, and then decide how to implement. You'd never want to write this _ stuff if you didn't have to. - I'm still not quite sure what tablify does (in part because the name is too clever by half and in part because it doesn't appear to always return tables). - But I think the idea of tablify is something we want, which is to convert (possibly indexed expressions) back into relational objects (Table, MatrixTable) because the latter support a wider set of operations and don't have the ""source mismatch problem"". Tim and I discussed this yesterday and we suggest the following interface:. ```; t = build_table(); .set_globals(x = 5, batch = batch); .set_rows(locus = locus, aaf = aaf); .build(); ```. and. ```; mt = build_table_matix(); .set_globals(dataset = dataset); .set_rows(locus = locus, aaf = aaf); .set_entries(GT = GT); .build(); ```. where the input expressions for each part must all come from the same source (or be compatible, e.g., constants) and the resulting (matrix) table inherits the keys from the original table. I think there is an unresolved question about how to handle potential name conflicts (e.g. a column key named locus).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2852#issuecomment-363841964:277,feedback,feedback,277,https://hail.is,https://github.com/hail-is/hail/pull/2852#issuecomment-363841964,4,"['feedback', 'guid']","['feedback', 'guided']"
Usability,I wanted to get feedback on the code I've written thus far before I start testing everything. I'm worried it might be too complicated / brittle to maintain. I also chose to blow away the entire existing environment rather than resetting the variables with new values. Not sure if that's what we want.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279:16,feedback,feedback,16,https://hail.is,https://github.com/hail-is/hail/pull/13279,1,['feedback'],['feedback']
Usability,I wanted to remove /batch in a different PR so it was clear what additional changes there were besides `rm /batch`. I can make it a separate commit though and that should fulfill the same purpose.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7474#issuecomment-551147727:54,clear,clear,54,https://hail.is,https://github.com/hail-is/hail/pull/7474#issuecomment-551147727,2,['clear'],['clear']
Usability,"I was able to install hail on my Macbook using a virtenv for python 2.7 and was able to import hail. . However, when I want to create a hail context as outlined in the installation guide, I get the following message: ; ``; Python 2.7.13 (default, Jul 18 2017, 09:16:53) ; [GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)] on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-422>"", line 2, in __init__; File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs); File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 68, in __init__; SparkContext._ensure_initialized(); File ""/Users/ih/hailenv/lib/python2.7/site-packages/pyspark/context.py"", line 283, in _ensure_initialized; SparkContext._gateway = gateway or launch_gateway(conf); File ""/Users/ih/hailenv/lib/python2.7/site-packages/pyspark/java_gateway.py"", line 77, in launch_gateway; proc = Popen(command, stdin=PIPE, preexec_fn=preexec_func, env=env); File ""/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 390, in __init__; errread, errwrite); File ""/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 1024, in _execute_child; raise child_exception; OSError: [Errno 2] No such file or directory; ``; Any idea what is going on with my installation, did somebody encounter this before already?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2062:181,guid,guide,181,https://hail.is,https://github.com/hail-is/hail/issues/2062,1,['guid'],['guide']
Usability,I was asked to agree to some license after clearing my gradle cache. I do not think anyone needs this.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10099:43,clear,clearing,43,https://hail.is,https://github.com/hail-is/hail/pull/10099,1,['clear'],['clearing']
Usability,"I was hoping that a greater restructure would lead to a more elegant solution, but after so many footguns it just felt worth making this change. The main point is shelling out in the Makefiles to ask Kubernetes directly for what the global config values are instead of hard-coding them. Specifically, the changes are:. - `KUBERNETES_SERVER_URL` was simply not used anymore in the Makefiles so I deleted it.; - `DOCKER_ROOT_IMAGE`, `INTERNAL_IP`, `IP` and `CLOUD` were only used in a couple Makefiles so I moved the `kubectl` invocation into where they're used so that Makefiles that don't depend on those variables won't incur the cost of querying them; - `DOCKER_PREFIX` and `DOMAIN` were used pretty widely, so I kept them in config.mk because most Makefiles will need to query those values anyway. The added startup time for `make deploy` feels pretty insignificant.; - With this change in place, there's no need to render config.mk anymore so I deleted the shell function for doing so",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11414:349,simpl,simply,349,https://hail.is,https://github.com/hail-is/hail/pull/11414,1,['simpl'],['simply']
Usability,"I was never clear on what `sign == 0` meant, but it appears not to be used: the tightened assertion passes everything.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8655#issuecomment-620651570:12,clear,clear,12,https://hail.is,https://github.com/hail-is/hail/pull/8655#issuecomment-620651570,2,['clear'],['clear']
Usability,"I was trying to filtervariants with an interval_list, and I wrote:. filtervariants list --keep -i /user/satterst/exome_evaluation_regions.v1.interval_list count; (when clearly I should have done filtervariants intervals... instead of filtervariants list...). and it kept getting most of the way done and then failing, with the error message:; hail: count: fatal: invalid variant. Invalid variant? I double-checked that my dataset was OK by running count on the whole thing, telling me that the filtering was the problem, so I created different versions of the interval_list file, trying to figure out if something was specified incorrectly in the file... I was literally troubleshooting the interval_list file for over half an hour before I realized what the problem was. And it's not the first time I've made this mistake. . I humbly submit that a better error message here would be helpful, something like:; filtervariants: fatal: list expected but intervals encountered",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/383:168,clear,clearly,168,https://hail.is,https://github.com/hail-is/hail/issues/383,1,['clear'],['clearly']
Usability,"I wasn't sure what to do for the SparkAnnImpExport. I also don't love how tuples are represented as rows in AnnotationImpExport (and `Table.show()`). I'd prefer parentheses instead of brackets, but I decided to keep it as is for now. Otherwise, I think I'll have to write a tuple parser. It also wasn't clear to me what the best way is to incorporate TTuple into the Type `gen`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2922:303,clear,clear,303,https://hail.is,https://github.com/hail-is/hail/pull/2922,1,['clear'],['clear']
Usability,"I wasn't very clear initially, I think if `apt` hasn't shown reason to be retried then we can leave it without a retry. If it ever seriously acts up there's one less thing in the way.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9906#issuecomment-767083626:14,clear,clear,14,https://hail.is,https://github.com/hail-is/hail/pull/9906#issuecomment-767083626,2,['clear'],['clear']
Usability,"I will submit a larger batch PR soon, not sure this is worth addressing until then, because this PR addresses questions of state and will take care of this. ```python; self.exit_code = pod.status.container_statuses[0].state.terminated.exit_code; ```. We should probably do something like . ```python; self.exit_code = max(status.state.terminated.exit_code for status in pod.status.container_statuses); ```; although I also see that in update_job_with_pod we effectively restrict to a single container. I'm not sure why this limit exists, but if needed, should probably occur during creation. In the upcoming PR, which moves state to MySQL 5.7+, and a different server model (async), I think it would be neat to represent meta-state (across all containers, and potentially the job subgraph whose first node is the inspected job) as:. ```go; const (; 	Cancelled = -3; 	Initialized = -2; 	Created = -1; ); ```. with values >=0 being the maximum of the linux error codes, 0-255, of the subgraph. Simple queries. Alternative is to use NULL when not completed, but when used in a client would require a null check, or potentially have surprising side effects (i.e where the default value is 0). We could also use a separate, text-based status field, but I will store a queryable JSON field containing the full status as well. In a similar vein, we have some state race conditions. For instance:. ```python; self.pod_template = kube.client.V1Pod(; metadata=kube.client.V1ObjectMeta(generate_name='job-{}-'.format(self.id),; labels={; 'app': 'batch-job',; 'hail.is/batch-instance': instance_id,; 'uuid': uuid.uuid4().hex; }),; spec=pod_spec). self._pod_name = None; self.exit_code = None. self._state = 'Created'; log.info('created job {}'.format(self.id)). self._create_pod(); ```. Here, every time pod creation fails, _state will be misaligned, and will have potential side effects (say in get_log). One solution could be to validate and rewind state in _create_pod. In any case, I will do my best to addres",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5118:992,Simpl,Simple,992,https://hail.is,https://github.com/hail-is/hail/issues/5118,1,['Simpl'],['Simple']
Usability,I would appreciate a review from anyone who has time. First of two (probably) for fast VCF parser. Main functionality still goes through HTSJDK. Next one will handle the genotypes. Signature for parseLines is a bit nuts but it definitely reduces the code size. @danking calling `hasNext` on my iterator invalidates it. I think this is inevitable and we should embrace it. Seems to work fine. Warn when filtering alleles due to invalid REF or symbolic alts. Much better than dropping data silently. Added `clear` to `ArrayStack` and `RegionValueBuilder`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2419:505,clear,clear,505,https://hail.is,https://github.com/hail-is/hail/pull/2419,1,['clear'],['clear']
Usability,"I'd appreciate feedback, but I realize there's more ways to abstract the code and make it more reusable.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10986#issuecomment-947023708:15,feedback,feedback,15,https://hail.is,https://github.com/hail-is/hail/pull/10986#issuecomment-947023708,2,['feedback'],['feedback']
Usability,"I'd argue this is a nicer UX - Having an ""invalid"" or ""unknown"" type lets people with weird alleles (and people do have weird alleles) actually run their pipelines instead of erroring out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3491#issuecomment-386425195:26,UX,UX,26,https://hail.is,https://github.com/hail-is/hail/pull/3491#issuecomment-386425195,2,['UX'],['UX']
Usability,"I'd like your initial feedback before I start testing this on Azure. A substantially earlier version seemed to work fine on GCP with dev deploy. The major conceptual change I made is a `resource` now contains a `prefix` and a `version`. The `resource_name` is just `{prefix}/{version}`. The prefixes for GCP are the same as they were before and don't vary by region. However, the new prefixes for Azure are region specific. The version is `1` for all current resources. . I added a `latest_resource_versions` table that has the prefix mapped to the latest version. This is used to generate the current resource names. There is a new CloudResourceManager that is in charge of managing the spot billing pricing cache and updating the prices in the cache and the database from the cloud provider's API. Since I couldn't easily rename resources to products everywhere in the database due to anonymous foreign key constraints, I had to rename the existing `CloudResourceManager` to `CloudDriverAPI`. Feel free to suggest a better name. The GCPResourceManager is a skeleton right now, but we'll have to flesh it out in the new year when GCP moves to spot billing with varying prices. For the `AzureResourceManager`, I use a new pricing client to grab the latest vm and disk prices. I support all possible disk prices, but for now, I limited the VM query to just get the machine types we support right now. In the future, we could get all VM prices, but the query is around 40 seconds for that compared to 2 seconds now. I was worried if we had such a slow query that blocked driver startup, that would be bad and this is fine for now. There are two classes I added: a `Resource` and a `Price`. The Price is only implemented for Azure and is used to store cost results from the pricing API. The resource has a couple of different mixin classes with an abstract method to generate the quantified resource depending on the type (ex: ComputeResourceMixin). Then there's `AzureDiskResource`, `AzureVMResource`, e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11092:22,feedback,feedback,22,https://hail.is,https://github.com/hail-is/hail/pull/11092,1,['feedback'],['feedback']
Usability,"I'd love feedback, especially on:; * How/whether to test these things; * How to organize a growing collection of hash families, with different speed/power tradeoffs, and different key and hash word-lengths. (These will be used in inner-most loops, so performance matters, and I don't have a good sense of what Scala abstractions hurt performance.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2288:9,feedback,feedback,9,https://hail.is,https://github.com/hail-is/hail/pull/2288,1,['feedback'],['feedback']
Usability,"I'll add more tests, and I'm still considering whether to rip out or integrate WriteBlocksRDD for IRM. But given how similar this is to the latter, I'm ready for feedback on the new code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2559:162,feedback,feedback,162,https://hail.is,https://github.com/hail-is/hail/pull/2559,1,['feedback'],['feedback']
Usability,"I'll have to think about the circular thing, but I learned that; ```; from __future__ import annotations; ```; let's you use names directly rather than as strings.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8968#issuecomment-644774393:51,learn,learned,51,https://hail.is,https://github.com/hail-is/hail/pull/8968#issuecomment-644774393,2,['learn'],['learned']
Usability,"I'll think about this more, but making the CI version explicit rather than implicit would at least provide a clear progression of necessary deploys. We'd want to tag the CI versions in git so that folks know which commits are necessary to achieve the step-wise transition. Let's find some time to chat next next week.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11122#issuecomment-985759470:109,clear,clear,109,https://hail.is,https://github.com/hail-is/hail/pull/11122#issuecomment-985759470,2,['clear'],['clear']
Usability,I'm a bit worried about confusing people with two (almost) identical methods named differently. . What do you think about something like `rbind` for right-bind? Then it's clear they're in the same family,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5154#issuecomment-454854904:171,clear,clear,171,https://hail.is,https://github.com/hail-is/hail/pull/5154#issuecomment-454854904,2,['clear'],['clear']
Usability,"I'm fairly certain I know understand this and the AoU VDS creation issue. In Dataproc versions 1.5.74, 2.0.48, and 2.1.0, Dataproc introduced ""memory protection"" which is a euphemism for a newly aggressive OOMKiller. When the OOMKiller kills the JVM driver process, there is no hs_err_pid...log file, no exceptional log statements, and no clean shutdown of any sockets. The process is simply SIGTERM'ed and then SIGKILL'ed. From Hail 0.2.83 through Hail 0.2.109 (released February 2023), Hail was pinned to Dataproc 2.0.44. From Hail 0.2.15 onwards, `hailctl dataproc`, by default, reserves 80% of the advertised memory of the driver node for the use of the Hail Query Driver JVM process. For example, Google advertises that an n1-highmem-8 has 52 GiB of RAM, so Hail sets the `spark:spark.driver.memory` property to `41g` (we always round down). Before aggressive memory protection, this setting was sufficient to protect the driver from starving itself of memory. Unfortunately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:385,simpl,simply,385,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790,2,['simpl'],['simply']
Usability,"I'm going to close this if no one objects, I think the service obviates this issue and there is no clear win to be had with images.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4038#issuecomment-433529930:99,clear,clear,99,https://hail.is,https://github.com/hail-is/hail/issues/4038#issuecomment-433529930,2,['clear'],['clear']
Usability,"I'm going to start testing, but I think the only thing that wasn't clear to me was how to resolve these sorts of comments. Do I try and fix them now or in a separate PR with an issue to make sure it gets noted? https://github.com/hail-is/hail/pull/14170#discussion_r1473442106",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14170#issuecomment-1929629871:67,clear,clear,67,https://hail.is,https://github.com/hail-is/hail/pull/14170#issuecomment-1929629871,2,['clear'],['clear']
Usability,I'm happy with how much simpler this is.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-586726532:24,simpl,simpler,24,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-586726532,2,['simpl'],['simpler']
Usability,"I'm not either. It's clearly the right thing. We can write them in terms of `hl.eval`, but I don't think they will work quite the same since we don't have the point type and type inference could fail (e.g. the endpoints are None).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5152#issuecomment-455711797:21,clear,clearly,21,https://hail.is,https://github.com/hail-is/hail/pull/5152#issuecomment-455711797,2,['clear'],['clearly']
Usability,"I'm not seeing the leak. `MemoryBuffer.clear` only zeroes the `pos` and `end` variables, and all the allocated memory is in the java heap. If anything, maybe you want to do `cb.assign(lazyBuffer, Code._null)`?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12040#issuecomment-1191668397:39,clear,clear,39,https://hail.is,https://github.com/hail-is/hail/pull/12040#issuecomment-1191668397,2,['clear'],['clear']
Usability,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:70,clear,clear,70,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528,2,['clear'],['clear']
Usability,I'm opening this PR so I can get feedback more quickly by being at the front of the queue.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12263:33,feedback,feedback,33,https://hail.is,https://github.com/hail-is/hail/pull/12263,1,['feedback'],['feedback']
Usability,"I'm seeing deploy failures where the tests start failing part way through because batch becomes unavailable, for example: https://ci2.hail.is/jobs/2886/log. However, this can't be the whole story, because batch has a readiness check and it isn't clear why it should go unavailable. Either way, this seems safer because it makes sure you pick up the intended version.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6093:246,clear,clear,246,https://hail.is,https://github.com/hail-is/hail/pull/6093,1,['clear'],['clear']
Usability,"I'm still working out the best workaround for the library version. I tried a mix of gradle sub-project-ing and shading with John and they all didn't work out for various different reasons. Azure library was doing some weird classLoader stuff that didn't like being bulk-relocated, and force-upgrading jackson didn't work because pyspark bundles in the buggy version of jackson without shading it. We can try to work out the former but I decided to pause on that front and try instead to just not use the buggy Azure method from the compatible library version and hit the REST endpoint directly, which involves some XML parsing. Currently in the middle of that. Happy to discuss the various approaches at our 1:1 tomorrow or earlier. In terms of hail-side implementation, it's all here under the assumption that the underlying library doesn't cause classpath conflicts (which it currently does).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11617#issuecomment-1095033418:448,pause,pause,448,https://hail.is,https://github.com/hail-is/hail/pull/11617#issuecomment-1095033418,2,['pause'],['pause']
Usability,I'm worried that we're back into a bad state where we'll keep seeing the same job over and over again and not realize we've already learned from it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5655#issuecomment-475664792:132,learn,learned,132,https://hail.is,https://github.com/hail-is/hail/pull/5655#issuecomment-475664792,2,['learn'],['learned']
Usability,"I've been thinking about this for a while now, and I think that what's _extremely_ helpful for learning is seeing a lot of short code examples for a lot of different applications. I think what we want is a bunch of examples formatted something like this:. ```; TITLE: what the code does; --------------; TAGS: comma-delimited set of search terms. DESC [optional] one- or two-sentence (max) clarification of what is being done. >>> CODE. --OR--. if there are multiple ways to do something, patterns like:. Method 1, if (condition 1):; >>> CODE 1. Method 2 (if condition 1 is not true):; >>> CODE 2. USES: clickable links to functions used in the code above. Probably not required for basic things like annotate / select. but definitely good to have for ld_prune or trio_matrix or their ilk. UNDERSTANDING [optional] An understanding section with click-to-expand styling. This shouldn't be required for a contribution to the cookbook, but could really help in some cases.; ```. This format has the advantage of keeping everything very visually tight, which will help people who learn through examples just scan through and look for patterns (this is a lot of people, I think). It also lets us embed understanding sections, which I do see the value of.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4089#issuecomment-411863621:95,learn,learning,95,https://hail.is,https://github.com/hail-is/hail/pull/4089#issuecomment-411863621,4,['learn'],"['learn', 'learning']"
Usability,"I've made the changes you suggested patrick, but now we have a failing test. I'm getting a situation where Vt is clearly orthonormal, and U@S@Vt multiplies back to the input matrix, but U@U.t is not particularly close to the identity matrix. It's not clear why this is. The test is:. ```; np_rank_2_wide_rectangle = np.arange(12).reshape((4, 3)); rank_2_wide_rectangle = hl.nd.array(np_rank_2_wide_rectangle). ......... assert_evals_to_same_svd(rank_2_wide_rectangle, np_rank_2_wide_rectangle, full_matrices=False); ```. (The 4th test in the `test_svd` method)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9727#issuecomment-733190588:113,clear,clearly,113,https://hail.is,https://github.com/hail-is/hail/pull/9727#issuecomment-733190588,4,['clear'],"['clear', 'clearly']"
Usability,"I've not written a test for this because we use this pattern a lot, and we haven't been writing explicit test cases for all of our simplify rules, but let me know if you want one.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9011:131,simpl,simplify,131,https://hail.is,https://github.com/hail-is/hail/pull/9011,1,['simpl'],['simplify']
Usability,"I've removed the Python `tempfile` approach in favor of adding `new_local_temp_file` to utils and a corresponding function to HailContext in Scala, which currently hardcodes `file:///temp` as the local temp directory. It may be more natural to have a localTmpDir on HailContext like we have tmpDir. ; I see there is a notion of local temp files on TempDir on the Scala side, but it doesn't seem to be used on the Python side. I also don't see if/where we wipe temp files on exit. In any case, I've tested that now it all works nicely on GCP, so ready for feedback/review. I think factoring through `tofile` and `fromfile` is useful for wider interoperability for the same reason that NumPy exposes them, but it's also good if you don’t want to actually load the NumPy array into driver memory but just save it to read/copy later, or to load it multiple time without recomputing the BlockMatrix. And I've provided the simpler interface of `to_numpy` and `from_numpy` for the common case. I suspect that (de)serializing over the network and building the local matrix dominates local read/write, so that using a socket isn't going to do much better. I can profile more closely if/when we feel it's high priority to make this faster still.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433:555,feedback,feedback,555,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433,4,"['feedback', 'simpl']","['feedback', 'simpler']"
Usability,I've removed the `make test-deploy` stuff to simplify this PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844#issuecomment-481837110:45,simpl,simplify,45,https://hail.is,https://github.com/hail-is/hail/pull/5844#issuecomment-481837110,2,['simpl'],['simplify']
Usability,I've simplified / improved the test to show both modes of failure that indeed occur on master.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3749#issuecomment-396754583:5,simpl,simplified,5,https://hail.is,https://github.com/hail-is/hail/pull/3749#issuecomment-396754583,2,['simpl'],['simplified']
Usability,I've validated our setup has those requirements and we're just hitting a FatalError from a commit a few weeks ago. https://github.com/hail-is/hail/blob/a0e8eb81e0f4d7ad446723e7cc04d4c6ac4ad066/hail/python/hail/context.py#L59-L67. If I revert this file we're able to pass in the existing SparkContext with the expected `hl.init(sc=sc)`. As general feedback it may be better to warn here than force exit. I may be wrong but I don't see a way around this for people using remote notebooks to talk to Spark via Livy.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7080#issuecomment-537048154:347,feedback,feedback,347,https://hail.is,https://github.com/hail-is/hail/issues/7080#issuecomment-537048154,2,['feedback'],['feedback']
Usability,"I've worked to improve Skat with regard to usability and code readability / organization and to address issues / bugs that could provoke a crash. - Added group size (number of variants) as a column in the returned key table. - Added an optional maxSize parameter so large groups only return their size rather than filling memory and killing the entire job. - Now computeGramianLargeN is used if n * m exceeds 8000 * 8000 (about 512MB of doubles) or maxSize * maxSize if maxSize is given and smaller than 8000. This seems a reasonable approach for now to prevent OOM without exposing additional memory parameters, but once we have some user feedback I'd like to consider re-implementing computeGramianLargeN to use BLAS3 outer product on blocks of (fewer than m) rows of the n x m matrix rather than inner product on all pairs of columns, which I think will boost speed and make it reasonable to kill the smallN routine entirely (the current largeN case benefits from dot product of sparse vectors when using hard calls, but that also goes away when we move to generic 0.2 and rip out the hardcall/dosage complexity). Then it will be natural for maxSize to control the number of rows in a block. - Added accuracy and iterations parameters to allow users to tune Davies, with R settings for Davies (1e-6, 10k) as default. This allows users to re-run groups with tiny p-values if desired to obtain greater accuracy. The R package runs additional p-value routines that may be faster when the p-value is very small, will keep in mind should this become an issue. - In remark above the Skat class, I've added an overview of how math in paper corresponds to implementation. - Simplified and re-organized the Skat class to cut down on the number and complexity of passed parameters and make the meaning of the code more transparent with respect to the overview. Killed the SkatModel class. - Fixed an oversight whereby the largeN route was never called by logistic. - Fixed a bug whereby a weight of null was ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2248:43,usab,usability,43,https://hail.is,https://github.com/hail-is/hail/pull/2248,2,"['feedback', 'usab']","['feedback', 'usability']"
Usability,"IR for chisq, fet, ctt, hwe with simpler chisq implementation",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3833:33,simpl,simpler,33,https://hail.is,https://github.com/hail-is/hail/pull/3833,2,['simpl'],['simpler']
Usability,"If a user writes a map over a local array or stream value, which they know is large, they should be able to force scratch memory to be cleared after each row. This can be an underscored parameter for expert use only. We would need to add a `requires_memory_management_per_row` flag to the `StreamMap` node, and expose it in user facing methods which generate a `StreamMap` like `ArrayExpression.map`. Then the rule in `EmitStream` would need to combine this with the child stream's `requiresMemoryManagementPerRow`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14383:135,clear,cleared,135,https://hail.is,https://github.com/hail-is/hail/issues/14383,1,['clear'],['cleared']
Usability,"If the key columns do not appear first in the key table's `signature` (a `TStruct`), then `join` will mis-type the joined key table. The simplest example I could find:; ```python; In[1]: (KeyTable.range(0, 100).annotate('j = 1.0, i = 1'); .key_by(""i"").join(KeyTable.range(0, 100)); .schema); Out[1]: TStruct([u'index', u'j', u'i'], [TInt32(), TInt32(), TFloat64()]); ```. Note that `j` and `i`'s types have been switched. The type of `j` should be `TFloat64`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2231:137,simpl,simplest,137,https://hail.is,https://github.com/hail-is/hail/issues/2231,1,['simpl'],['simplest']
Usability,"If this is still an issue, please make a post on the forum, OK? We're more responsive there.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5657#issuecomment-476543562:75,responsiv,responsive,75,https://hail.is,https://github.com/hail-is/hail/issues/5657#issuecomment-476543562,2,['responsiv'],['responsive']
Usability,"If we go through route (2), this project can serve as a prototype C or C++ interface to Hail. This interface could take multiple forms. For example, we could actually re-build our memory representation implementations in C++ and compile SAIGE, at Hail-Query-compile-time (i.e. when we are compiling a *user's* query), to use whatever SType/PType that Hail has decided is the ideal. A simpler approach is to implement one canonical implementation of the Hail types in C++, fork & slightly modify SAIGE to accept these memory representations, compile SAIGE at Java compile time (i.e. in CI or when you run `make` on your laptop) against these mem reps, ship the compiled library with the Hail JAR, and expose it, via JNI, into the Hail Query language. This requires that the Query compiler can call a function which only supports arguments using one particular SType/PType.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13442#issuecomment-1679739816:384,simpl,simpler,384,https://hail.is,https://github.com/hail-is/hail/issues/13442#issuecomment-1679739816,2,['simpl'],['simpler']
Usability,"If we view IR as the least fixpoint of an algebra wherein recursive; references are replaced with a type parameter, a la:. IR[T] ::= I32() ...; | Cast(T, Type); | ...; | Let(T, String, T, Type); | ... Then IR is a functor and has a natural map operation. Recur is inspired by this intuition, but in the restricted situation of; Scala's built-in type recursion.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2507:281,intuit,intuition,281,https://hail.is,https://github.com/hail-is/hail/pull/2507,1,['intuit'],['intuition']
Usability,If you can make this IR rewrite pass determinism with/without optimization I will be totally confident in this change; https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/expr/ir/Simplify.scala#L294,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4104#issuecomment-411794524:194,Simpl,Simplify,194,https://hail.is,https://github.com/hail-is/hail/pull/4104#issuecomment-411794524,1,['Simpl'],['Simplify']
Usability,"If you're actually seeing some inconsistent results in some browser, I agree the solution isn't sufficient. Else, why not get the easy solution in, and do more work when it's needed. I see a potential problem statement, no clear reason why the present solution is problematic, and a desire to move to a different solution. . I looked into the relationship between fractional line widths and alpha a few days ago, when I wrote the comment suggesting that alpha blending could be an alternative solution. Antialiased fractional line width (which is also what you would get if the effective resolution is larger than the viewport resolution and then objects scaled), will act like an alpha-blended 1px line width. reference: https://community.khronos.org/t/how-to-draw-a-line-with-width-less-than-1-0/42022",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8964#issuecomment-645574948:223,clear,clear,223,https://hail.is,https://github.com/hail-is/hail/pull/8964#issuecomment-645574948,2,['clear'],['clear']
Usability,"If/when the need is pressing, we can extend parsing to deal with both unnamed and named and optional args in full generality. With sort and sortBy, I handled the possibilities more directly and think the documentation is clear as is. I also assume the Boolean parameter is a constant rather than an expression handling null etc, but I think that covers the use cases of these functions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/511#issuecomment-236266169:221,clear,clear,221,https://hail.is,https://github.com/hail-is/hail/pull/511#issuecomment-236266169,2,['clear'],['clear']
Usability,"Implemented simple buffers that read/write data directly from/to streams without blocking. Our other buffer specs write/read blocked data, so the data is encoded with the block info. To write out NDArrays that are compatibly with numpy, we need to just write out the straight bytes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5890:12,simpl,simple,12,https://hail.is,https://github.com/hail-is/hail/pull/5890,1,['simpl'],['simple']
Usability,"Implements a StagedIndexWriter with a very similar structure to the unstaged version. To test this, I threaded this through `IndexWriter.build` so that it now compiles a function that implements the CompiledIndexWriter interface:; ```; trait CompiledIndexWriter {; def init(path: String): Unit; def apply(x: Long, offset: Long, annotation: Long): Unit; def close(): Unit; }; ```; with a wrapper class that mimics the interface of the old IndexWriter. Eventually, we'll need this to lower TableWrite. (Kind of non-randomly assigning @chrisvittal, as I'd like feedback on whether the new-style imperative codegen looks right.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8737:558,feedback,feedback,558,https://hail.is,https://github.com/hail-is/hail/pull/8737,1,['feedback'],['feedback']
Usability,"Implements existing query service endpoints using websockets instead of long-running http requests. I open a new socket for each request instead of attempting to hold one open for each client to send all its requests; not sure if one is preferable to the other, but this one seemed easier to handle and more in line with what we were doing before. ~~I haven't put any sort of heartbeat on either end for now for simplicity; the `blocking_to_async` wrapper around the jvm execution interferes with the server's ability to send/receive pings and pongs, and I'm not currently handling retries for timeouts anyways; would love suggestions on how to make this more robust.~~. Since nginx's default behavior is to close the websocket after 60s of non-activity (which seems pretty reasonable), I have a 30s heartbeat on the server-side websocket connection. This meant rewriting the flow to split a task off to execute the blocking JVM function and keeping the websocket task open to handle the heartbeat. Currently, we rely on the client to close the connection once the jvm task is completed and the result response is received; if the connection is closed/something errors for some other reason, we check to see if the task is completed and cancel it if it's not. The client side still doesn't poll the server for existence, but if the socket is unexpectedly closed we'll retry the request.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9636:412,simpl,simplicity,412,https://hail.is,https://github.com/hail-is/hail/pull/9636,1,['simpl'],['simplicity']
Usability,"Implements simple tabulation and twisted tabulation hash methods. See [Fast and Powerful Hashing using Tabulation](http://arxiv.org/abs/1505.01523v5): simple tabulation is described in Section 2, twisted tabulation is described in Section 3, and Figure 1 on p.9 has C code for both.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2304:11,simpl,simple,11,https://hail.is,https://github.com/hail-is/hail/pull/2304,2,['simpl'],['simple']
Usability,Improve simplify,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3429:8,simpl,simplify,8,https://hail.is,https://github.com/hail-is/hail/pull/3429,2,['simpl'],['simplify']
Usability,"Improved the optimizer so the IR generated for:. ```; mt = hl.import_vcf('sample.vcf'); mt.info.CCC.show(); ```. is reasonable. Run optimizer in compile, so we optimize (transformed) agg and seq ops. Simplify runs:; - propagate Begins up if possible; - inline single-use Lets; - (Apply annotate ...) => InsertFields if possible; - Turn MakeStruct of a bunch of FieldRefs into InsertFields. The optimizer now turns this:. ```; (TableMapGlobals Struct{} ""{}""; (MatrixRowsTable; (MatrixMapRows None None; (MatrixRead None False False ...); (Let __uid_1; (MakeStruct; (<expr>; (GetField CCC; (GetField info; (Ref ... va))))); (ApplyIR annotate; (MakeStruct; (locus; (GetField locus; (Ref ... va))); (alleles; (GetField alleles; (Ref ... va)))); (MakeStruct; (<expr>; (GetField `<expr>`; (Ref Struct{`<expr>`:Int32} __uid_1)))))))); (MakeStruct)); ```. I shit you not, that's literally what's generated by:. ```; import hail as hl; mt = hl.import_vcf('sample.vcf'); mt.info.CCC.show(); ```. into:. ```; (TableMapGlobals Struct{} ""{}""; (MatrixRowsTable; (MatrixMapRows None None; (MatrixRead ... False False ...); (InsertFields; (SelectFields (locus alleles); (Ref ... va)); (<expr>; (GetField CCC; (GetField info; (Ref ... va))))))); (MakeStruct)); ```. The only thing that's missing is to push the MatrixRowsTable into the MatrixMapRows. @tpoterba, I thought you had code for this? What happened?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3966:200,Simpl,Simplify,200,https://hail.is,https://github.com/hail-is/hail/pull/3966,1,['Simpl'],['Simplify']
Usability,"In Getting Started from Source, clearly suggest the 0.1 branch",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2201:32,clear,clearly,32,https://hail.is,https://github.com/hail-is/hail/pull/2201,2,['clear'],['clearly']
Usability,"In `TableMapRows.execute`, we have the following code at the top of a function that gets passed to `tableMapPartitions`:. ```; val globalRegion = ctx.freshRegion; val globals = if (rowIterationNeedsGlobals); globalsBc.value.readRegionValue(globalRegion); else 0; ```. The problem with the above is that even though the globals were only broadcasted once, they could be read into memory multiple times, and don't get cleaned up until the end of the partition where spark closes the context. Imagine a pipeline that alternated between calling map rows and filtering (the filterings prevent the adjacent maps from being simplified into one). Every time we called map, we'd run the above code, reading a new copy of the globals into a new `globalRegion` in a way that won't be cleaned up until the end of the partition. . As per Cotton: You can fix this by having `SerializedRegionValue` (which is the thing being broadcast in `globalsBC`) hold on to a pointer that is returned for each user, but has to get closed by the same callback that's clearing the contexts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8244:617,simpl,simplified,617,https://hail.is,https://github.com/hail-is/hail/issues/8244,2,"['clear', 'simpl']","['clearing', 'simplified']"
Usability,"In looking at your PSelectFieldsStruct PR, I got a bit angry at the number of abstract methods on PStruct. This cleanup should make your PR smaller and simpler. We'll sort out the constructible methods at some point too. All the methods I changed were ones that are always used to do type-level manipulation to return a new constructible type that is fed into an RVB. Returning a PCanonicalStruct to these usages is the correct thing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8528:152,simpl,simpler,152,https://hail.is,https://github.com/hail-is/hail/pull/8528,1,['simpl'],['simpler']
Usability,"In order to track partition bounds and distinctness, we report the first and last seen keys when writing (matrix) tables. Previously we were copying the last seen key into the partition region. This is incorrect as the partition region has a lifetime of the entire partition and cannot be cleared, leaking memory. Fix this by giving the last seen key its own region that can be cleared before a new last seen key is saved. Tested manually.; See the following zulip thread for initial report.; https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/memory.20usage.20by.20range.20-.3E.20write/near/316404073",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12574:289,clear,cleared,289,https://hail.is,https://github.com/hail-is/hail/pull/12574,2,['clear'],['cleared']
Usability,"In the following hail call, the `sa` binding is not available in the filter's lambda argument. In almost all modern programming languages, bindings are lexical, descending all the way into nested code. We would like to support the same intuitive notion of binding in hail. ```; vds.annotate_samples_expr(; ""sa.mendel = gs.filter(g => va.mendel.filter(x => x.fam == sa.fam).length).count()""); ```. ### Design Suggestion. As we move towards the compiler, this should become more natural because these filters will always be inlined. We need only not reset the environment when descending into a lambda.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1351:236,intuit,intuitive,236,https://hail.is,https://github.com/hail-is/hail/issues/1351,1,['intuit'],['intuitive']
Usability,"In the short term, a fix which makes the UI usable again for these kinds of jobs is to check blob size, if it's over some threshold, show no log and instruct the user to download it. Then fix the download to use aiohttp's StreamResponse. We should maybe split this issue into a frontend-side and worker-side.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12852#issuecomment-1653991936:44,usab,usable,44,https://hail.is,https://github.com/hail-is/hail/issues/12852#issuecomment-1653991936,2,['usab'],['usable']
Usability,"In this PR, I rewrite `linear_regression_rows_nd` to use `_map_partitions` instead of `_group_within_partitions`. By doing this, I've eliminated the need to do a `key_by` at the end of `linear_regression_rows_nd`. I also think this makes the code clearer. . This PR also makes a few seemingly random changes that are actually bug fixes:. 1. When emitting `Apply` nodes, we were grabbing the `Code[Region]` from the first argument to the `MethodBuilder`. However, the assumption that the first argument will always be a `Region` seems to no longer be true. As such, we just construct a `CodeParam` from the `StagedRegion` we have available. . 2. In the NDArrayEmitter, I want to make sure I call the local `emit` method that passes off to `emitWithRegion`, for the same reason as 1: (Can't trust first argument to be a `Region`). 3. In `EmitStream`, I need to use `memoizeField` instead of `memoize`, because regular `memoize` saves to a `LocalRef`, and that will get reset to 0 when `next` is called on a stream. Lesson: don't trust locals for things that must live between elements of a stream. I feel like you have a better idea of how the Stream stuff gets emitted than I do Patrick. I'm curious if what I wrote in `process_block` could be written in a way that would lead to better code getting emitted, as I still need to figure out how to squeeze more performance out of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9469:247,clear,clearer,247,https://hail.is,https://github.com/hail-is/hail/pull/9469,1,['clear'],['clearer']
Usability,"In this PR:. - I add `BlockMatrix.from_ndarray`. The implementation isn't great, it just basically just evals the ndarray and adds NDArray support to `ValueToBlockMatrix`. A better version wouldn't cross the Python / Java boundary at all, but I want something that works on all backends, so for now this will have to suffice. Any solution will at least need to communicate the shape of the ndarray back to python, since it's tracked in the block matrix type. ; - With this new method, I can now get many tests in `test_linalg.py` to run on the local / service backends. Most BM lowering was apparently untested before, so some bug fixes were necessary, including:; - Support requiredness analysis on BlockMatrix, even though the answer is always required. ; - Use `CompileAndEvaluate` rather than `Interpret` to evaluate the child node in `ValueToBlockMatrix`. ; - Casting between Int32 and Int64 in various places in lowering. Almost always the culprit was a bad interaction between ndarray shapes (which are Int64) and `StreamRange` argument (which is an Int32). This is sort of a pervasive ndarray problem that will need to be systematically addressed at some point. I don't anticipate anyone making a BlockMatrix with blocks big enough to blow 32 bits though. ; - Lots of fixes to the `BlockMatrixBroadcast` rule for getting diagonal of a BlockMatrix, as it was clearly never run. It had `MakeStream(StreamIR)` which was not allowed, it didn't update the context appropriately, and it used the wrong axis to determine if something was a row vector.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10447:1366,clear,clearly,1366,https://hail.is,https://github.com/hail-is/hail/pull/10447,1,['clear'],['clearly']
Usability,"In-cluster I have the ability to create a pod, including the secret, which is slightly surprising to me. Does the ability create a pod give ability to mount any secret? Surely not. At the same time, my rbac for notebook clearly defines the only secret it can access:. ```; (base) alex:~/projects/hail/notebook2:$ k get role read-get-user-secret -o json; {; ""apiVersion"": ""rbac.authorization.k8s.io/v1"",; ""kind"": ""Role"",; ""rules"": [; {; ""apiGroups"": [; """"; ],; ""resourceNames"": [; ""get-users""; ],; ""resources"": [; ""secrets""; ],; ""verbs"": [; ""get""; ]; }; ]; }; ```. The other permissions are for service and pod resources. These pods are bound to the user's service account. I also don't appear to need to give that service account that is bound (SA ""B"") permission to read the mounted secret. This makes sense to me: the container should be able to access anything on its file system. The notebook leader defines what that is. cc @cseed, thought you may want to know. The following was from a manual in-cluster test:; <img width=""940"" alt=""Screenshot 2019-04-02 15 55 39"" src=""https://user-images.githubusercontent.com/5543229/55432272-78989e00-5560-11e9-960e-1362d277d759.png"">. Partial description of a recently created pod (sans status); ```sh; (base) alex:~/projects/hail/notebook2:$ k get pod notebook2-worker-d4snh -o yaml; apiVersion: v1; kind: Pod; metadata:; creationTimestamp: ""2019-04-02T19:50:21Z""; generateName: notebook2-worker-; labels:; app: notebook2-worker; hail.is/notebook2-instance: f4dc8213468f4799a3c7f94cb6969309; jupyter_token: 484b71e2c12d42c79b169b1991602d45; name: a_notebook; user_id: e7e7b9c420f0b0ff503ab6711355f27748522a8a37d9d22b2c8e0af4; uuid: 84873cf540014e128cce18f5481fb682; name: notebook2-worker-d4snh; namespace: default; resourceVersion: ""41241284""; selfLink: /api/v1/namespaces/default/pods/notebook2-worker-d4snh; uid: 8cb3c1c2-5580-11e9-bcd4-42010a8000c9; spec:; containers:; - command:; - jupyter; - notebook; - --NotebookApp.token=484b71e2c12d42c79b169b199",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5753#issuecomment-479174611:220,clear,clearly,220,https://hail.is,https://github.com/hail-is/hail/pull/5753#issuecomment-479174611,2,['clear'],['clearly']
Usability,"Indeed in my streamify, forcing MakeArray to remain a MakeArray fixes the problem. Now to investigate why MakeStream is the wrong solution, and why the new streamify isn't handling this correctly. to be clear, this branch finds the MakeArray inside of the MakeTuple and generates a ToArray(MakeStream), which both seems not super wrong and redundant. But the fact that's it's a value issue, with an array reading garbage, also make it look like a requiredeness/ copy function issue (though this was previously tested)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-583813511:203,clear,clear,203,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-583813511,2,['clear'],['clear']
Usability,"Information below. It isn't totally clear what to do here. I think the k8s refresh loop should probably restart pods (mark_unscheduled) that have been scheduled but aren't running after a timeout (few mins). ```; $ kubectl -n batch-pods describe pods batch-3-job-41-39d17b; Name: batch-3-job-41-39d17b; Namespace: batch-pods; Priority: 500000; PriorityClassName: user; Node: gke-vdc-preemptible-pool-9c7148b2-1f89/10.128.0.101; Start Time: Fri, 12 Jul 2019 13:17:15 -0400; Labels: app=batch-job; batch_id=3; hail.is/batch-instance=cd50b95a89914efb897965a5e982a29d; job_id=41; task=main; user=ci; uuid=f53f127847864f1cbf7d4bdc911a6646; Annotations: <none>; Status: Pending; IP: ; Containers:; main:; Container ID: ; Image: gcr.io/hail-vdc/ci-intermediate:oyyg6y2um4kx; Image ID: ; Port: <none>; Host Port: <none>; Command:; bash; -c; set -e; gcloud -q auth activate-service-account --key-file=/test-gsa-key/privateKeyData; gsutil -m cp -r /test/resources/* gs://hail-test-1c9nm/sj0nb47zqys1/pipeline/input/; State: Waiting; Reason: ContainerCreating; Ready: False; Restart Count: 0; Requests:; cpu: 100m; memory: 500M; Environment:; POD_IP: (v1:status.podIP); POD_NAME: batch-3-job-41-39d17b (v1:metadata.name); Mounts:; /gsa-key from gsa-key (rw); /test-gsa-key from test-gsa-key (rw); /var/run/secrets/kubernetes.io/serviceaccount from default-token-8h99c (ro); Conditions:; Type Status; Initialized True ; Ready False ; ContainersReady False ; PodScheduled True ; Volumes:; test-gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: test-gsa-key; Optional: false; gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: ci-gsa-key; Optional: false; default-token-8h99c:; Type: Secret (a volume populated by a Secret); SecretName: default-token-8h99c; Optional: false; QoS Class: Burstable; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; preemptible=true; Events:; Type Reason Age F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6625:36,clear,clear,36,https://hail.is,https://github.com/hail-is/hail/issues/6625,1,['clear'],['clear']
Usability,"Initial version of python interface. Still need to:. - document python interface (working with @jigold about the best way to do that); - add tests run through gradle. The interface mostly wraps commands. The main difference is that python has first class VDS objects, so the environment isn't necessary. Therefore, I had to restructure commands that take VDS names as arguments. It can be run like this:. ```; $ gradle shadowJar; $ PYTHONPATH=/path/to/hail/python SPARK_CLASSPATH=/path/to/hail/build/libs/hail-all-spark.jar pyspark; ```. Here's a simple example:. ```; >>> from pyhail import *; >>> hc = HailContext(sc) # create Hail context; >>> vds = hc.import_vcf('/Users/cseed/sample.vcf', n_partitions = 8); >>> vds.count(); {u'nSample': 100, u'nVariants': 346L, u'nGenotypes': 34600L}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1061:547,simpl,simple,547,https://hail.is,https://github.com/hail-is/hail/pull/1061,1,['simpl'],['simple']
Usability,Inline small ApplyIR nodes in simplify,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5899:30,simpl,simplify,30,https://hail.is,https://github.com/hail-is/hail/pull/5899,2,['simpl'],['simplify']
Usability,"Instead of writing the following to count genotypes with GQ<20, GQ>=20, and total nonmissing GQs in the callset:. ```; annotatevariants expr -c 'va.gq_less_20 = gs.count(g.gq < 20), va.gq_greater_20 = gs.count(g.gq >= 20), va.gq_total_nonmissing = gs.count(isDefined(g.gq))'; annotateglobal expr -c 'global.gq_less_20 = variants.sum(va.gq_less_20), global.gq_greater_20 = variants.sum(va.gq_greater_20), global.gq_total_nonmissing = variants.sum(va.gq_total_nonmissing)'; ```. It would be great to simply write:. ```; annotateglobal expr -c 'global.gq_less_20 = gs.count(g.gq < 20), global.gq_greater_20 = gs.count(g.gq >= 20), global.gq_total_nonmissing = gs.count(isDefined(g.gq))'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/393:498,simpl,simply,498,https://hail.is,https://github.com/hail-is/hail/issues/393,1,['simpl'],['simply']
Usability,"Interesting to see the benchmarks, thanks. I didn't realize there were any per-variant usages, I figured these were per-RDD. That makes me more okay with the original, but it's completely up to you. On a side note, I can't wait until we can work in C++, where using library facilities to simplify code isn't such a performance hit!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3094#issuecomment-372723395:288,simpl,simplify,288,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372723395,2,['simpl'],['simplify']
Usability,"Interesting: I tried in a new session (after checking out master, installing-editable), and this time I could break things with out-of-bounds slices, but `hl.eval(a[0:a.shape[0],0:1]) ` and `hl.eval(a[0:a.shape[0],0:2])` worked ok. So what's going on?. ```python; In [22]: hl.eval(a[0:a.shape[0],0:1]) ; Out[22]: ; array([[1],; [2],; [3],; [4],; [5]], dtype=int32). In [23]: hl.eval(a[0:a.shape[0],0:1]) ; Out[23]: ; array([[1],; [2],; [3],; [4],; [5]], dtype=int32). In [24]: a = a.T . In [25]: hl.eval(a) ; Out[25]: ; array([[ 1, 2, 3, 4, 5],; [ 7, 6, 8, 9, 10]], dtype=int32). In [26]: a = a.T . In [27]: hl.eval(a) ; Out[27]: ; array([[ 1, 7],; [ 2, 6],; [ 3, 8],; [ 4, 9],; [ 5, 10]], dtype=int32). In [28]: hl.eval(a[0:a.shape[0],0:1]) ; Out[28]: ; array([[1],; [7],; [0],; [2],; [0]], dtype=int32). In [32]: hl.eval(a[0:a.shape[0],0:1]) ; Out[32]: ; array([[ 1],; [ 7],; [ 0],; [ 4],; [32749]], dtype=int32); ``` . totally broken. Seems like 2 problems: 1) out of bounds checks not being done on inner dimension. 2) strides get scrambled between transposes, or something isn't being cleared after transposition.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9144#issuecomment-663267587:1090,clear,cleared,1090,https://hail.is,https://github.com/hail-is/hail/issues/9144#issuecomment-663267587,2,['clear'],['cleared']
Usability,"Interface change:. ``` scala; abstract class Type[T] extends BaseType {; def coerce(a: Any): T; // ...; }; ```. Note the two major changes:; - Every `Type` now must correspond to a Scala type; - Every `Type` must know how to convert appropriate values to their associated Scala type. We may then naturally modify methods like `evalCompose`:. ``` scala; def evalCompose[T](ec: EvalContext, typ: Type[T])(subexpr: AST); (g: (T) => Any): () => Any = {; val f = subexpr.eval(ec); () => {; val x = f(); if (x != null); g(typ.coerce(x)); else; null; }; }; ```. which will hopefully induce or enable downstream simplifications.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/624:604,simpl,simplifications,604,https://hail.is,https://github.com/hail-is/hail/issues/624,1,['simpl'],['simplifications']
Usability,Is it this simple?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9071:11,simpl,simple,11,https://hail.is,https://github.com/hail-is/hail/pull/9071,1,['simpl'],['simple']
Usability,Is there a way for me to test this further? My experiments show that clone+merge is ~20 seconds but download from GCS is ~3s. This should seed up the feedback substantially for anyone working on an image that transitively depends on other images.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7534:150,feedback,feedback,150,https://hail.is,https://github.com/hail-is/hail/pull/7534,1,['feedback'],['feedback']
Usability,Is there something in particular you had in mind? The example that exists now seems clear to me.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4259#issuecomment-424833285:84,clear,clear,84,https://hail.is,https://github.com/hail-is/hail/issues/4259#issuecomment-424833285,2,['clear'],['clear']
Usability,"It also fails on this simpler example:; ```; In [1]: import hail as hl ; ...: ; ...: temp = hl.utils.range_table(100) ; ...: temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True) ; Initializing Hail with default parameters...; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-c548354b6e81; LOGGING: writing to /Users/dking/projects/hail/hail-20210107-1038-0.2.61-c548354b6e81.log; Traceback (most recent call last):; File ""<ipython-input-1-a2e56feaf799>"", line 4, in <module>; temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-1092>"", line 2, in write; File ""/Users/dking/projects/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/hail/python/hail/table.py"", line 1271, in write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 114, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 379, in retry_transient_errors; return await f(*args, **kwargs); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 44, in async_request; raise FatalError(f'Error from server: {result[""value""]}'); FatalError: Error from server: java.util.NoSuchElementExce",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9856#issuecomment-756194693:22,simpl,simpler,22,https://hail.is,https://github.com/hail-is/hail/issues/9856#issuecomment-756194693,2,['simpl'],['simpler']
Usability,"It doesn't seem like headless mode is in effect, at least in the most recent published image. Will grab this and play around with it. Tested Dan's image in app.hail.is, seems to work, except for all of the .js/.css resources; first guess is SSL, but it's clearly a diff issue. I can't connect to your workers, can to his. Will update in a bit. Yours:; (notebook) alexkotlar:~/projects/hail-clone/notebook-api:$ k logs notebook-worker-5xq2w -f; [I 21:29:01.483 NotebookApp] Writing notebook server cookie secret to /home/jovian/.local/share/jupyter/runtime/notebook_cookie_secret; [I 21:29:03.742 NotebookApp] Serving notebooks from local directory: /home/jovian; [I 21:29:03.743 NotebookApp] The Jupyter Notebook is running at:; [I 21:29:03.743 NotebookApp] http://localhost:8888/instance/notebook-worker-service-qzppk/?token=...; [I 21:29:03.743 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).; [W 21:29:03.750 NotebookApp] No web browser found: could not locate runnable browser. Dan’s; [I 21:44:38.439 NotebookApp] Writing notebook server cookie secret to /home/jovyan/.local/share/jupyter/runtime/notebook_cookie_secret; [I 21:44:38.808 NotebookApp] [jupyter_nbextensions_configurator] enabled 0.4.1; [I 21:44:38.898 NotebookApp] Jupyter-Spark enabled!; [I 21:44:38.942 NotebookApp] JupyterLab extension loaded from /opt/conda/lib/python3.6/site-packages/jupyterlab; [I 21:44:38.942 NotebookApp] JupyterLab application directory is /opt/conda/share/jupyter/lab; [I 21:44:38.945 NotebookApp] Serving notebooks from local directory: /home/jovyan; [I 21:44:38.945 NotebookApp] The Jupyter Notebook is running at:; [I 21:44:38.946 NotebookApp] http://(notebook-worker-v7fr4 or 127.0.0.1):8888/instance/notebook-worker-service-sv5jl/?token=...; [I 21:44:38.946 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).; [I 21:44:55.324 NotebookApp] 302 GET /instance/notebook-worker-service-sv5jl/?acce",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5243#issuecomment-460092942:255,clear,clearly,255,https://hail.is,https://github.com/hail-is/hail/pull/5243#issuecomment-460092942,2,['clear'],['clearly']
Usability,"It is mighty fishy that both azure and google failed the callback test. What are we missing? If MJC returns, then the database was clearly updated. Subsequent DB queries should see those changes. total_jobs_in_batch won't change during the lifetime of the batch, so that should be correct (though we should probably LOCK IN SHARE MODE anyway). Assuming I'm reading the [reference manual](https://dev.mysql.com/doc/refman/5.7/en/innodb-consistent-read.html) correctly, that select should see the result of the UPDATE *or a later state*. The updates to a single row are serial. So there must exist a transaction that takes it from n_jobs-1 to n_jobs. That transaction thus must see n_jobs for new_n_completed. That transaction thus ought to update batches. Once that transaction is committed the subsequent query for notification should see the changes...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11352#issuecomment-1040809121:131,clear,clearly,131,https://hail.is,https://github.com/hail-is/hail/pull/11352#issuecomment-1040809121,2,['clear'],['clearly']
Usability,"It is possible to export a field of a `MatrixTable` to a TSV using something like `mt.n.export('file_name')`. This is not easily determined from the docs. At minimum, maybe let's add this to the how to guide about exporting. Right now, we only talk about exporting VCFs. https://hail.is/docs/0.2/guides/basics.html?highlight=export%20matrix%20table",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8278:202,guid,guide,202,https://hail.is,https://github.com/hail-is/hail/issues/8278,2,['guid'],"['guide', 'guides']"
Usability,"It seems this is probably a bit slower than the current code on GCP (but there is variation so I'm not completely sure, and it still seems fast). It does give a functional S3 fileystem, tho. I will post timings below. Timings were done with my `test-copy` timing framework. - Add size_hint to create_part, used by the S3 backend and passed by copy. - Add a weighted semaphore (that can acquire n instead of just 1) and use it to limit the data in flight. It isn't completely clear how to do this. I could do, say, use a semaphore with value 10 * PART_SIZE and acquire the size of the object (which will be up to PART_SIZE). That might be a good idea, but instead I used 10 * BUFFER_SIZE and acquire the minimum of the BUFFER_SIZE and object size. This specifically limits the total intermediate buffer size. 10 was a mostly random choice, so you might try benchmarking to see if it makes a difference. - I made the copy part size destination filesystem specific. This is because the S3 multi-part upload API calls the partition contents be loaded into memory and 128MiB is too much for parallel uploads. The S3 default is 8MiB. - I create a new async writeable paired with a syncronous byte collector. It is used for the S3 multi-part upload call, which requires an the body to be a bytes/bytearray. - I tried to use readinto/write instead of read/write in SourceCopier.{_copy_file, _copy_part}, but in S3, the get_object API call returns a StreamingBody:. https://botocore.amazonaws.com/v1/documentation/api/latest/reference/response.html. that doesn't support readinto(). - In SourceCopier._copy_part, it might be worth benchmarking reading the entire part into memory and then writing it out like we're forced to do on the AWS backend. To do this, we'd be forced to turn PART_SIZE down to ~8MiB.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10752:475,clear,clear,475,https://hail.is,https://github.com/hail-is/hail/pull/10752,1,['clear'],['clear']
Usability,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9348:132,feedback,feedback,132,https://hail.is,https://github.com/hail-is/hail/pull/9348,1,['feedback'],['feedback']
Usability,It was just a way to try and reduce the duplication in the code. The correct thing to do is to use requests and not have the overhead of an asynchronous library for a simple client. We can have this discussion in #6244.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6243#issuecomment-498329233:167,simpl,simple,167,https://hail.is,https://github.com/hail-is/hail/pull/6243#issuecomment-498329233,2,['simpl'],['simple']
Usability,"It wasn't scanning the full dataset anymore, but:. table.head().flatten() was generating a TableOrderBy(TableKeyBy(TableHead)). There was no way to remove this node, even if the table was already keyed by the sort fields, so we ended up doing an extra scan and possibly shuffle. This change simplifies the whole thing, and emits the correct IR from the beginning",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5172#issuecomment-455698384:291,simpl,simplifies,291,https://hail.is,https://github.com/hail-is/hail/pull/5172#issuecomment-455698384,2,['simpl'],['simplifies']
Usability,"It's clear we are failing to explain the necessity of a compatible BLAS library. I hope this will stem the flow of bug tickets and support questions related to a misconfigured, missing, or incompatible BLAS library.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8647:5,clear,clear,5,https://hail.is,https://github.com/hail-is/hail/pull/8647,1,['clear'],['clear']
Usability,"It's good that you documented it in #3706. When fixed I can simplify `tie_breaker` to `hl.signum(r.twice_maf - l.twice_maf)`, but I don't expect that to make a noticeable performance difference in the scheme of the full computation so it's not my highest priority.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3704#issuecomment-395117104:60,simpl,simplify,60,https://hail.is,https://github.com/hail-is/hail/pull/3704#issuecomment-395117104,2,['simpl'],['simplify']
Usability,"It's much clearer, awesome",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4494#issuecomment-427159094:10,clear,clearer,10,https://hail.is,https://github.com/hail-is/hail/pull/4494#issuecomment-427159094,2,['clear'],['clearer']
Usability,"It's not clear to me what the change that broke this was. Must have been when we added the pipeline docs, but I don't see what used to be calling `upload-docs`. Anyway, calling it now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8196:9,clear,clear,9,https://hail.is,https://github.com/hail-is/hail/pull/8196,1,['clear'],['clear']
Usability,It's not clear we should do this instead of just making the service work.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5236#issuecomment-459844874:9,clear,clear,9,https://hail.is,https://github.com/hail-is/hail/issues/5236#issuecomment-459844874,2,['clear'],['clear']
Usability,"It's not clear what happens to empty strings at the beginning. I think if you replace with this, we'll be all set:. Setting `limit` to negative disables limiting the number of splits. Trailing empty strings are preserved, so "",a,b,,"".split("","", -1) gives ["""", ""a"", ""b"", """", """"] whereas "",a,b,,"".split("","") gives ["""", ""a"", ""b""].",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1423#issuecomment-281819089:9,clear,clear,9,https://hail.is,https://github.com/hail-is/hail/pull/1423#issuecomment-281819089,2,['clear'],['clear']
Usability,"It's possible to get a list of (key, value) tuples from DictExpression by casting it to an array. ```python; hl.eval(hl.array(hl.literal({""foo"": 1, ""bar"": 2}))); # [('bar', 2), ('foo', 1)]; ```. This adds an `items` method to DictExpression that returns the same thing. This aligns with the `items` method of Python dicts and may be more intuitive/discoverable than casting to an array. #assign compiler",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10663:338,intuit,intuitive,338,https://hail.is,https://github.com/hail-is/hail/pull/10663,1,['intuit'],['intuitive']
Usability,It's probably not going to pass CI on the first try after the rebase. I'm mainly looking for feedback on the API first.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12010#issuecomment-1215231720:93,feedback,feedback,93,https://hail.is,https://github.com/hail-is/hail/pull/12010#issuecomment-1215231720,2,['feedback'],['feedback']
Usability,"It's working on a simple example on the Cray:. ```; >>> (hc; ... .import_vcf('file:///mnt/lustre/cseed/sample.vcf'); ... .vep('/mnt/lustre/cseed/vep.properties'); ... .write('file:///mnt/lustre/cseed/sample.vds', overwrite=True)); hail: info: Coerced sorted dataset; hail: info: vep: annotated 346 variants; >>> vds = hc.read('file:///mnt/lustre/cseed/sample.vds'); >>> vds.count(); {u'nVariants': 346L, u'nSamples': 100, u'nGenotypes': 34600L}; >>> vds.filter_variants_expr('isDefined(va.vep)').count(); {u'nVariants': 346L, u'nSamples': 100, u'nGenotypes': 34600L}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1558#issuecomment-287177936:18,simpl,simple,18,https://hail.is,https://github.com/hail-is/hail/pull/1558#issuecomment-287177936,2,['simpl'],['simple']
Usability,"Just a refactor, simplifies the interactions between `Worker`, `CloudWorkerAPI` and `CloudUserCredentials` and hopefully makes this code safer and easier to work with. Instead of the following occuring in worker.py:. 1. get credentials string from `CloudUserCredentials`; 2. tell `CloudWorkerAPI` to write credentials string to `path` owned by the job; 3. tell `CloudWorkerAPI` to mount cloudfuse using the credentials stored at `path`. we instead just do. 1. tell `CloudWorkerAPI` to mount cloudfuse using `CloudUserCredentials`. On its own I think this change makes the codepath simpler and easier to think about in terms of where credentials are stored, but this also gets rid of the requirement from `worker.py`'s point of view that credentials must be stored on the filesystem. This will make it easier to transition off of key files and over to metadata server tokens. In order to make the new statement sound in terms of types, we can't have `CloudWorkerAPI.mount_cloudfuse` just accept a `CloudUserCredentials` argument, because that means `GCPWorkerAPI` would need to be able to support an argument of type `AzureUserCredentials`, which would never happen and doesn't make sense. What we can do here is make `CloudWorkerAPI` generic over the subtype of `CloudUserCredentials` that it both produces and consumes. This allows us to use stricter types like `GCPUserCredentials` and `AzureUserCredentials` inside of `GCPWorkerAPI` and `AzureWorkerAPI` respectively and now the type system is happy. It also relaxes the restriction that both of the `GCPUserCredentials` and `AzureUserCredentials` need to conform to the same `cloudfuse_credentials` interface.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12962:17,simpl,simplifies,17,https://hail.is,https://github.com/hail-is/hail/pull/12962,2,['simpl'],"['simpler', 'simplifies']"
Usability,"Just to be clear, I'm proposing:. Pending -> Ready; Ready -> Error, Running; Running -> Ready, Error, Failed, Success",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6268#issuecomment-499339906:11,clear,clear,11,https://hail.is,https://github.com/hail-is/hail/pull/6268#issuecomment-499339906,2,['clear'],['clear']
Usability,"Just to be clear, as much as possible we aim to keep the main source code free of historical inconsistencies. That applies doubly to pull requests, which should be single, semantically coherent units.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-415089165:11,clear,clear,11,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-415089165,2,['clear'],['clear']
Usability,"Just to be clear, this pipeline was what I wrote when trying to replicate the bug Duncan was seeing, but it hit a different assertion error than the one he was hitting. He was hitting ""local in the wrong method builder"" problems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8325#issuecomment-603567150:11,clear,clear,11,https://hail.is,https://github.com/hail-is/hail/issues/8325#issuecomment-603567150,2,['clear'],['clear']
Usability,Just to make sure I understand -- the variable rename is to make sure it is clear that `HAIL_PRODUCTION_DOMAIN` means something different than `HAIL_DOMAIN` and is only applicable for CI? This is because the other services will have the correct deploy config?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14164#issuecomment-1898843580:76,clear,clear,76,https://hail.is,https://github.com/hail-is/hail/pull/14164#issuecomment-1898843580,2,['clear'],['clear']
Usability,"Keeping in mind Cotton's queries last week, researched and found much lighter alternative to ExprsesJS for the server api. A few years ago, Express had low impact on node performance; it has become bloated. Found a light (~200 LOC) ""framework"" called Polka, that is small enough to maintain ourselves. It mainly adds light route-matching capabilities, to avoid repeating boilerplate when writing the Node server. Easy to follow. It's also the fastest ""framework"" available, outside of C/Go/Rust. Matches Falcon, and allows 1 language for server/web. (Also Node has a far larger ecosystem).; * https://github.com/the-benchmarker/web-frameworks ; * Polka also nearly compatible with Express's middleware api, so many existing packages are either directly usable, or with minor modifications. This was a desire of mine, since nearly everything server-y for node is really written for Express. Last commit removes all Express, adds a rewritten express-jwt for access token verification, and shows client credential exchange, backed by Redis cache, for <=4ms fetching of",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-447583569:753,usab,usable,753,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-447583569,2,['usab'],['usable']
Usability,"KeyedBlockMatrix is a BlockMatrix with optional row and column Keys. I chose to make them optional when considering the need to constantly check key agreement. Here if both operands have row keys in a binary operation like add, then the keys are checked for agreement. The result has rowKeys iff at least one operand has rowKeys (and they agree). Similar rules apply to column keys and other operations where sensible. When promoting a BlockMatrix to a KeyedBlockMatrix, the keys are set to None. A BlockMatrix can be promoted to a KeyedBlockMatrix even if it's dimensions exceed Int.MaxValue; the simple rule is that you can't set keys on a dimension that is too large. This is convenient if you have a matrix where one dimension is huge but you still want keys on the other dimension. Checking keys helps ensure correctness, and I think the ability to set/drop keys on keyed matrices should be useful for linear algebra where a matrix operand comes un-keyed or you don't care about the keys on that operand. This key persistence is also natural when thinking about operations that add (unkeyed) scalars or vectors to keyed matrices (We'd later add optionally-keyed vectors as well, where keys are checked in vector addition, matrix/vector mult, vectorAddToEveryRow, etc). Keys are stored and checked on master, so for large dimensions users may want to rekey with simpler keys, via a map on the python side or with just indices. For simplicity, and since there's basically no additional overhead using an unkeyed KeyedBlockMatrix versus its underlying BlockMatrix, I think we should consider only having (optionally) keyed matrices exposed on the Python side (so a Python BlockMatrix is a Scala KeyedBlockMatrix, and you can do linear algebra numpy-style by just having no keys set). I plan to add writeKeyedBlockMatrix to MatrixTable in next step, with parameters to on whether to retain the keys (e.g., key_rows = true). On the Python side, this could then replace write_block_matrix rather than b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2718:598,simpl,simple,598,https://hail.is,https://github.com/hail-is/hail/pull/2718,1,['simpl'],['simple']
Usability,"LTRjZjJhNTdhZDkzOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""d384d00e-b18b-41bc-871f-4cf2a57ad938"",""prPublicId"":""d384d00e-b18b-41bc-871f-4cf2a57ad938"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,509,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13718:5422,Learn,Learn,5422,https://hail.is,https://github.com/hail-is/hail/pull/13718,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"LWJmMWY5Mzc1NTVhYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""759202b1-ae50-4125-b3a5-bf1f937555ac"",""prPublicId"":""759202b1-ae50-4125-b3a5-bf1f937555ac"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,509,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13836:5490,Learn,Learn,5490,https://hail.is,https://github.com/hail-is/hail/pull/13836,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"LWY3ZGM4YjIwOTVhNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""6e02a47f-633e-4605-b359-f7dc8b2095a6"",""prPublicId"":""6e02a47f-633e-4605-b359-f7dc8b2095a6"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,509,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13933:5490,Learn,Learn,5490,https://hail.is,https://github.com/hail-is/hail/pull/13933,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,Let me know if you think the error message is clear.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9164:46,clear,clear,46,https://hail.is,https://github.com/hail-is/hail/pull/9164,1,['clear'],['clear']
Usability,Let me look over the docs again. There were a number of methods with no documentation when this was created. I don’t don’t quite understand what you mean by too broad (could you clarify?) I just mean that anything that doesn’t have an explanation should not be in the online doc. If you’re saying that there are no longer any undocumented methods then yes let’s close.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7292#issuecomment-558279772:326,undo,undocumented,326,https://hail.is,https://github.com/hail-is/hail/issues/7292#issuecomment-558279772,2,['undo'],['undocumented']
Usability,"Let's build it from scratch, but better, faster, ... Philosophy: Minimal magic, minimal reliance on outside work, don't use it unless we understand it. Goal: <16ms interactions, including <16ms page transitions. Should feel identical to a desktop app in terms of performance, but maintain state like a website (i.e `get` variables). TODO:; - [ ] Profile/logout should be responsive: no user icon / dropdown until narrow view; - [x] Default to redirect rather than popup; - [x] Clicking on login should clear state if auth failed; - [ ] Write test for token verification on backend; - [ ] Add profile page; - [ ] Finish auth/redirect notebook logic in gateway; - [ ] Add notebook state endpoints in gateway; - [ ] Add notebook state view in frontend; - [ ] Break this up into ~10 commits, targeting <= 200 LOC each (with first commit being checking in package-lock.json); - [ ] Deal with cross-origin tracking issues in Safari. This may require using the ""custom domains"" feature of auth0, paid. Workaround could be to poll/websocket request to api server to refresh tokens. . To run:; ```sh; cd packages/web-client; docker build . -t blah; docker run --env-file=env-example -p 3000:3000 blah npm run start; ```; then navigate to `http://localhost:3000`. \# lines: Most come from the package.json.lock files. These maintain versioning information.; * [It is recommended to check in .lock files]( https://stackoverflow.com/questions/44206782/do-i-commit-the-package-lock-json-file-created-by-npm-5); * They're huge, sorry.; # Documentation; ### JS; https://javascript.info. We use the subset termed [ES2018](https://flaviocopes.com/es2018/). Compatibility across all browsers is ensured by [transpilation using BabelJS, to some lower JS target](https://babeljs.io/docs/en/). Polyfills should not be used, except when impossible to support a browser (this is configurable). I mostly don't care about anything that isn't an evergreen browser, so I think we should support: Edge, Safari, Chrome, Firefox. A",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:371,responsiv,responsive,371,https://hail.is,https://github.com/hail-is/hail/pull/5162,2,"['clear', 'responsiv']","['clear', 'responsive']"
Usability,"Let's rewrite to use this style. I think that will be both simple and performant, to make us all happy!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7646#issuecomment-561448218:59,simpl,simple,59,https://hail.is,https://github.com/hail-is/hail/pull/7646#issuecomment-561448218,2,['simpl'],['simple']
Usability,"Let's say I read an external file with `annotateglobal table -r global.all_scores`. I then need to assign each column to a genset , for example `global.GWAS_height = global.all_scores.filter(x => x.GWAS_HEIGHT == ""1"").map(x => x.V1).toSet` then create a per-variant annotation checking if the gene is in the gene-set `va.andrea.GWAS_height = global.GWAS_height.contains(va.andrea.genename)` and then I need to count the number of variants per individuals `sa.andrea.GWAS_height = gs.statsif(va.andrea.URV && va.andrea.GWAS_height,g.nNonRefAlleles).sum`. And I want to do this for each of the column in the file read with `annotateglobal table`. Clearly loop is needed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/390:645,Clear,Clearly,645,https://hail.is,https://github.com/hail-is/hail/issues/390,1,['Clear'],['Clearly']
Usability,Let's take what I learned about worker_processes into account when making a decision here. You might just be seeing clashing between 8 processes with 1 core limits.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11876#issuecomment-1168824908:18,learn,learned,18,https://hail.is,https://github.com/hail-is/hail/pull/11876#issuecomment-1168824908,2,['learn'],['learned']
Usability,Load less data in simple cases,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3626:18,simpl,simple,18,https://hail.is,https://github.com/hail-is/hail/pull/3626,2,['simpl'],['simple']
Usability,"LocalMatrix follows NumPy's broadcast rules (restricted to two-dimensional ndarrays), and I've tried to mirror the Numpy interface for all functions where it's reasonable to do so. I still need time to add a bunch of Python tests of the interface, but I'd be glad for feedback/review in the meantime. In a subsequent PR, I'll expose the rest of BlockMatrix's binary ops in Python with the similar syntax and rules. These changes will provide the matrix functionality needed for a clean mixed models pipeline (modulo a few Scala black boxes that I can return to once I have something working) and will hopefully be generally useful for adding/porting more methods in Python. Current longer-term plan is to expose RowMatrix as well, and consider how to best unify the interfaces. And one day LocalMatrix will actually be a NumPy array...",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3064:268,feedback,feedback,268,https://hail.is,https://github.com/hail-is/hail/pull/3064,1,['feedback'],['feedback']
Usability,"Logic is: in case when data representation of a collection of fields doesn't change, and one simply needs a subset of those values, it makes no sense to copy all of those values to a different Region, instead cast. ```scala; val rvdLP = LocalLDPrune.pruneLocal(standardizedRDD, r2Threshold, windowSize, Some(maxQueueSize)). val fieldIndicesToAdd = Array(""locus"", ""alleles"", ""mean"", ""centered_length_rec""); .map(field => bpvType.fieldIdx(field)); val sitesOnly = rvdLP.mapPartitions(; tableType.canonicalRVDType; )({ it =>; val region = Region(); val rvb = new RegionValueBuilder(region); val newRV = RegionValue(region). it.map { rv =>; region.clear(); rvb.set(region); rvb.start(tableType.canonicalPType); rvb.startStruct(); // this should be a selected fields PStruct; rvb.addFields(bpvType, rv, fieldIndicesToAdd); rvb.endStruct(); newRV.setOffset(rvb.end()); newRV; }; }); ```. With something that looked more like this. ```scala; val rvdLP = LocalLDPrune.pruneLocal(standardizedRDD, r2Threshold, windowSize, Some(maxQueueSize)). val newRvdView = rvdLP.getViewFromSelectedFields(PSelectedFields(Array(""locus"", ""alleles"", ""mean"", ""centered_length_rec"".map(field => bpvType.fieldIdx(field))); ```. presumably the implementation would not only not copy, but also not re-partition the data; cc @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6601:93,simpl,simply,93,https://hail.is,https://github.com/hail-is/hail/issues/6601,2,"['clear', 'simpl']","['clear', 'simply']"
Usability,"Looking at our documentation, we document `n` as `maximum number of splits`. That makes this seem like a bug to me, especially in the 0 case. But clearly people use this function and this change is breaking to anyone who uses it. My vote would be to do the deprecation thing I suggested above.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9383#issuecomment-684034614:146,clear,clearly,146,https://hail.is,https://github.com/hail-is/hail/issues/9383#issuecomment-684034614,2,['clear'],['clearly']
Usability,"Looking at the IR generated by table.flatten, this snippet:; ```; >>> import hail as hl; >>> t = hl.utils.range_table(10); >>> t2 = t.annotate(**{f'f{i}': i for i in range(5)}); >>> t2.flatten().collect(); ```; generates the following IR:; ```; (GetField rows; (TableCollect; (TableMapRows; (TableOrderBy (Aidx); (TableMapRows; (TableRange 10 8); (InsertFields; (SelectFields (idx); (Ref row)); None; (f0; (I32 0)); (f1; (I32 1)); (f2; (I32 2)); (f3; (I32 3)); (f4; (I32 4))))); (Let __uid_3; (Ref row); (InsertFields; (SelectFields (); (SelectFields (idx f0 f1 f2 f3 f4); (Ref row))); None; (idx; (GetField idx; (Ref __uid_3))); (f0; (GetField f0; (Ref __uid_3))); (f1; (GetField f1; (Ref __uid_3))); (f2; (GetField f2; (Ref __uid_3))); (f3; (GetField f3; (Ref __uid_3))); (f4; (GetField f4; (Ref __uid_3)))))))); ```; If we look at the last `TableMapRows` IR, the entire thing `(Let __uid_3 …)` is entirely a no-op, but we're still compiling and generating code for the (post-optimization) IR:; ```; (InsertFields; (SelectFields (); (Ref row)); None; (idx; (GetField idx; (Ref row))); (f0; (GetField f0; (Ref row))); (f1; (GetField f1; (Ref row))); (f2; (GetField f2; (Ref row))); (f3; (GetField f3; (Ref row))); (f4; (GetField f4; (Ref row)))); ```. (cc @tpoterba I added a second `ForwardLets` in `Optimize` before the `Simplify`, although I'm not sure that's actually the correct place to put it; in this case, I think it may eventually come out in the wash given how many passes we make through any given pipeline, but I've noticed that currently our python tends to generate IR of the form:; ```; (TableMapRows; (Let __uid_n; (Ref row); <mapped value, sometimes using (Ref __uid_n) and sometimes (Ref row)>; ```; and that redundant binding at the top level means that the first Simplify pass misses quite a few optimizations! I'm not super attached to leaving it there, but I do think we might want to consider forwarding Lets on any IRs from python before optimization.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7719:1324,Simpl,Simplify,1324,https://hail.is,https://github.com/hail-is/hail/pull/7719,2,['Simpl'],['Simplify']
Usability,Looking for some feedback and advice on what tests to build.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3285:17,feedback,feedback,17,https://hail.is,https://github.com/hail-is/hail/pull/3285,1,['feedback'],['feedback']
Usability,"Looking over the tutorial, it looks like the primitive functionality we would need to add are versions of intersect and merge. Once we have ordered point-interval joins (annotateRowsIntervalTable), I think both of these should be simple additions. It looks like most of the other bedtools functionality could be implemented in Python on top of those primitives.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3302#issuecomment-379259962:230,simpl,simple,230,https://hail.is,https://github.com/hail-is/hail/issues/3302#issuecomment-379259962,2,['simpl'],['simple']
Usability,"Looks good to me. PNDArray is a little unstable at the moment and probably going to get shaken up in January, so I don't have a clear sense of any must have default methods.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7734#issuecomment-567100923:128,clear,clear,128,https://hail.is,https://github.com/hail-is/hail/pull/7734#issuecomment-567100923,2,['clear'],['clear']
Usability,Looks good! Next steps:. - Use it!; - Test it! I'm not sure how much will break.; - Time it! Do something simple filter genotypes gq >= 20 and a sampleqc or something. Does it help? How much?; - Figure out how you're going to deal with annotations like `va.rare_genos = gs.filter(g => ... some rare condition ...).collect()`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1322#issuecomment-276272639:106,simpl,simple,106,https://hail.is,https://github.com/hail-is/hail/pull/1322#issuecomment-276272639,2,['simpl'],['simple']
Usability,Looks like this has been removed: https://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs/guides/v2-upgrade-guide#changes-in-v200. #assign services,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11698:107,guid,guides,107,https://hail.is,https://github.com/hail-is/hail/pull/11698,2,['guid'],"['guide', 'guides']"
Usability,"Looks like this has failures and needs a rebase. Your PR stack is getting pretty high so let's keep the bottom moving. Also, I rebased my lir branch on Value[T] and now I'm passing the asm4s tests and most other tests are failing on joinpoint which I didn't port. So this stack is now a blocker for me to resume that thread.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8156#issuecomment-594495172:305,resume,resume,305,https://hail.is,https://github.com/hail-is/hail/pull/8156#issuecomment-594495172,2,['resume'],['resume']
Usability,"Looks my comment got lost! Sorry. I said, I'd prefer we didn't copy the HailContext whole hog, but just write a simple wrapper that calls from hail2.HailContext to hail.HailContext, so something like:. ```; class HailContext:; def __init__(args...):; self.hc1 = hail.HailContext(args...). def import_bgen(args...):; return self.hc1.import_bgen(args...).to_hail2(); ```. etc. I don't think you even need docs unless there is something specifically different between the two. That way, we won't need to maintain two versions for things like doc changes and we won't get confused about which one is the ""real"" HailContext. Then, when we're ready to switch over, we can pull the docs across and throw away the stub.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2244#issuecomment-337717963:112,simpl,simple,112,https://hail.is,https://github.com/hail-is/hail/pull/2244#issuecomment-337717963,2,['simpl'],['simple']
Usability,"Made a more robust authentication library. One outstanding issue due to auth0js library, that we can solve by checking for and clearing wildcard auth0-prefixed cookies and startup, but this may have side-effects. Created an issue to track:; https://github.com/auth0/auth0.js/issues/897",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162#issuecomment-455907662:127,clear,clearing,127,https://hail.is,https://github.com/hail-is/hail/pull/5162#issuecomment-455907662,2,['clear'],['clearing']
Usability,"Made some logging improvements to the combiner in the process of; understanding the various components. Benchmarks, docs, perf.; improvements are next. Simple example of merging three GVCFs:. ```; 2020-03-27 15:17:58 Hail: INFO: GVCF combiner plan:; Branch factor: 2; Batch size: 2; Combining 3 input files in 2 phases with 2 total jobs.; Phase 1: 1 job corresponding to 2 intermediate output files.; Phase 2: 1 job corresponding to 1 final output file. 2020-03-27 15:17:58 Hail: INFO: Starting phase 1/2, merging 3 input GVCFs in 1 job.; 2020-03-27 15:17:58 Hail: INFO: Starting job 1/1 to create 2 merged files, corresponding to ~50.0% of total I/O.; 2020-03-27 15:21:20 Hail: INFO: Finished job 1/1, 50.0% of total I/O finished.; 2020-03-27 15:21:20 Hail: INFO: Finished phase 1/2.; 2020-03-27 15:21:20 Hail: INFO: Starting phase 2/2, merging 2 intermediate sparse matrix tables in 1 job.; 2020-03-27 15:21:27 Hail: INFO: Starting job 1/1 to create 1 merged file, corresponding to ~50.0% of total I/O.; 2020-03-27 15:24:47 Hail: INFO: wrote matrix table with 47031230 rows and 3 columns in 33 partitions to combiner_out.mt; 2020-03-27 15:24:47 Hail: INFO: Finished job 1/1, 100.0% of total I/O finished.; 2020-03-27 15:24:47 Hail: INFO: Finished phase 2/2.; 2020-03-27 15:24:47 Hail: INFO: Finished!; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8378:152,Simpl,Simple,152,https://hail.is,https://github.com/hail-is/hail/pull/8378,1,['Simpl'],['Simple']
Usability,"Made this change backwards compatible. Note that I have not made any changes to worker.py in this PR anymore, so there's no danger of incompatibility. I tested the JAR from this PR against default and ran a simple hail query to see that it behaved as usual. Separately, I made #12246, dev deployed it, then ran this same JAR against my dev namespace to see that it added all worker jobs to the same batch as the driver job.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12222#issuecomment-1262670715:207,simpl,simple,207,https://hail.is,https://github.com/hail-is/hail/pull/12222#issuecomment-1262670715,2,['simpl'],['simple']
Usability,Make laziness clear in GWAS tutorial,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7828:14,clear,clear,14,https://hail.is,https://github.com/hail-is/hail/issues/7828,2,['clear'],['clear']
Usability,"Makes some further progress on simplifying the `PruneDeadFields` pass, with the primary goal of decoupling it from the details of the binding structure. The primary change is to `memoizeValueIR`. Before, it passed in only the requested type of the node, and returned and environment containing all free variables and their requested types. Any bound variables would then need to be removed, and the environments of all children then merged. This low-level manipulation of environments made it closely tied to the binding structure, essentially redundantly encoding everything in `Binds.scala`. Now we pass an environment down into the children, which maps variables to a mutable state tracking the requested type. Each `Ref` node unions the requested type at the reference with the state in the environment. This lets us use the general environment infrastructure. I didn't do an assertion directly comparing the old and new implementations, as I've done with some other pass rewrites. But `PruneDeadFields` has pretty good test coverage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14509:31,simpl,simplifying,31,https://hail.is,https://github.com/hail-is/hail/pull/14509,1,['simpl'],['simplifying']
Usability,"Many of our tests look like:. ```scala; // ExprSuite.scala; assert(eval[Int](""a[0]"").contains(1)); assert(eval[Int](""a[1]"").contains(2)); assert(eval[Int](""a[2]"").isEmpty); assert(eval[Int](""a[3]"").contains(6)); assert(eval[Int](""a[-1]"").contains(8)); assert(eval[Int](""a[-2]"").contains(-1)); ```. Test failures from these expressions simply state that the result was not as expected. If these tests were instead written as below,. ```scala; assert(eval[Int](""a[0]"") == Some(1)); assert(eval[Int](""a[1]"") == Some(2)); assert(eval[Int](""a[2]"") == None); assert(eval[Int](""a[3]"") == Some(6)); assert(eval[Int](""a[-1]"") == Some(8)); assert(eval[Int](""a[-2]"") == Some(-1)); ```; then test failures would print both the expected value and the actual value:; ```; org.scalatest.exceptions.TestFailedException: Some(7) did not equal Some(1); ```. Furthermore, there are a tools in the [scalatest library](http://www.scalatest.org/at_a_glance/FlatSpec) which enable richer specifications. Suppose that Hail included a `randInt : (Int, Int) => Int` function, we might like to verify that this is true:. ```scala; eval[Int](""randInt(0, 10) * 2 + 1"") should (be > 0 and be (even)); ```. When this expression fails, the messages look like:. ```; org.scalatest.exceptions.TestFailedException: 7 was greater than 0, but 7 was odd; ```. These natural language matchers are a bit finicky. I'm not sure if I like them, but I do like having nice error messages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1286:335,simpl,simply,335,https://hail.is,https://github.com/hail-is/hail/issues/1286,1,['simpl'],['simply']
Usability,"Matrix can be promoted to a KeyedBlockMatrix even if it's dimensions exceed Int.MaxValue; the simple rule is that you can't set keys on a dimension that is too large. This is convenient if you have a matrix where one dimension is huge but you still want keys on the other dimension. Checking keys helps ensure correctness, and I think the ability to set/drop keys on keyed matrices should be useful for linear algebra where a matrix operand comes un-keyed or you don't care about the keys on that operand. This key persistence is also natural when thinking about operations that add (unkeyed) scalars or vectors to keyed matrices (We'd later add optionally-keyed vectors as well, where keys are checked in vector addition, matrix/vector mult, vectorAddToEveryRow, etc). Keys are stored and checked on master, so for large dimensions users may want to rekey with simpler keys, via a map on the python side or with just indices. For simplicity, and since there's basically no additional overhead using an unkeyed KeyedBlockMatrix versus its underlying BlockMatrix, I think we should consider only having (optionally) keyed matrices exposed on the Python side (so a Python BlockMatrix is a Scala KeyedBlockMatrix, and you can do linear algebra numpy-style by just having no keys set). I plan to add writeKeyedBlockMatrix to MatrixTable in next step, with parameters to on whether to retain the keys (e.g., key_rows = true). On the Python side, this could then replace write_block_matrix rather than being in addition to it. Later, LocalMatrix and RowMatrix would follow the same pattern of optionally keyed versions in Scala, with a common Matrix and KeyedMatrix abstraction. And in Python users would just have Matrix backed by KeyedMatrix on the Scala side. PS. In the filters, I switched to names keepRows and keepCols in KeyedBlockMatrix instead of rowsToKeep and colsToKeep, so the changes in BlockMatrix and BlockMatrixSuite are just renaming for consistency (as well as removing one unused line).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2718:1435,simpl,simplicity,1435,https://hail.is,https://github.com/hail-is/hail/pull/2718,1,['simpl'],['simplicity']
Usability,Matrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.ex,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10738,Simpl,Simplify,10738,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyValue']"
Usability,"Maximal independent set has had a bug/misfeature since https://github.com/hail-is/hail/pull/2975. That PR added an `hl.int64(...)` coercion around the tie_breaker function. This allowed users to pass tie_breakers that returned floating point numbers, but it *changed the meaning*. The sign of values with magnitude greater than or equal to one was preserved. All values in (-1, 1) were converted to 0, thus treating them as indistinguishable for the purposes of the MIS. This PR fixes this long standing bug and adds a simple test for that case. Supporting arbitrary numeric types is actually quite simple! The conversion from any Hail numeric type to float64 is sign-preserving (AFAIK), which is the only property we need to preserve the user's intended ordering. This change also introduces two mild, obvious performance improvements:; - Use one region for the entire MIS calculation, clearing for each invocation of tie_breaker (MIS is single-threaded); - Read the tie_breaker value using simple Region and type methods rather than allocating a new SafeRow each time the tie_breaker is invoked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7729:519,simpl,simple,519,https://hail.is,https://github.com/hail-is/hail/pull/7729,4,"['clear', 'simpl']","['clearing', 'simple']"
Usability,Maybe we can use GraalVM Native Image? https://docs.oracle.com/en/graalvm/enterprise/20/docs/reference-manual/native-image/Limitations/#native-image-compatibility-and-optimization-guide,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13675#issuecomment-1728007156:180,guid,guide,180,https://hail.is,https://github.com/hail-is/hail/issues/13675#issuecomment-1728007156,2,['guid'],['guide']
Usability,Maybe we should update the WARNING message to be clear that this is a transient error and we've automatically retried it and there's nothing to be worried about?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11817#issuecomment-1117649877:49,clear,clear,49,https://hail.is,https://github.com/hail-is/hail/pull/11817#issuecomment-1117649877,2,['clear'],['clear']
Usability,"Meant to assign this, just forgot to. Curious if you see any other ways to make this code simpler/faster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10075#issuecomment-784322347:90,simpl,simpler,90,https://hail.is,https://github.com/hail-is/hail/pull/10075#issuecomment-784322347,2,['simpl'],['simpler']
Usability,"Memory's local storage is a simple cache, so it is safe for k8s to; evict it from the node if the node is underutilized. https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#what-types-of-pods-can-prevent-ca-from-removing-a-node",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10864:28,simpl,simple,28,https://hail.is,https://github.com/hail-is/hail/pull/10864,1,['simpl'],['simple']
Usability,"More directly, this is known as the maximal independent set (MIS) problem, for which there are simple parallel algorithms: https://cstar.iiit.ac.in/~kkishore/MISStudy.pdf. MIS should be implemented in Spark GraphX, but I can't find it!; http://ilpubs.stanford.edu:8090/1085/2/primitives_tr_sig_alternate.pdf",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/863#issuecomment-250805502:95,simpl,simple,95,https://hail.is,https://github.com/hail-is/hail/issues/863#issuecomment-250805502,2,['simpl'],['simple']
Usability,More simplify rules,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3868:5,simpl,simplify,5,https://hail.is,https://github.com/hail-is/hail/pull/3868,2,['simpl'],['simplify']
Usability,"Mostly generated by feedback from Tobyn (thanks, Tobyn!). - [x] Rename Hailpedia back to something like ""Overview"" - ""pedia"" implies verbose, detailed, and independent records, not a high level survey of the library; - [ ] Link to the overview from the getting started page. Preferably in a very visible way; - [ ] (MatrixTable overview) explain how a structured matrix is different from a numeric matrix explicitly",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4908:20,feedback,feedback,20,https://hail.is,https://github.com/hail-is/hail/issues/4908,1,['feedback'],['feedback']
Usability,"Mostly infrastructure. Added NewAST base class for Matrix and KeyTable ASTs with a primitive term rewriting engine. This should eventually be a base for AST, too (because we'll want to rewrite value expressions, too). I broke VariantMetadata into two parts: VSMMetadata (static types/metdata for VSM) and VSMLocalValue (part of MatrixValue that is computed/stored on master and broadcast). Added MatrixRead, FilterSamples and FilterVariants matrix AST nodes. Simple optimizer that pushes filters into read and some minor optimizations of filters.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1778:459,Simpl,Simple,459,https://hail.is,https://github.com/hail-is/hail/pull/1778,1,['Simpl'],['Simple']
Usability,"Mostly minor. Let me know if you have any questions. If you merge this in to tp_annorework, I'll merge it in to master. Moved Annotation.emptySignature to Signature.empty.; Use convenience functions in more places (looked over all instances of List).; Rename Annotation.getSchema to .schema. Make schema virtual on Type. (Prefer virtual functions to match).; Some renaming in Signature.; Removed () on some simple functions (.getSchema(), .empty(), etc).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/219:407,simpl,simple,407,https://hail.is,https://github.com/hail-is/hail/pull/219,1,['simpl'],['simple']
Usability,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9777:1365,clear,clear,1365,https://hail.is,https://github.com/hail-is/hail/pull/9777,1,['clear'],['clear']
Usability,"Move `localKeySort` to `OrderedRVIterator`. Previously, its only dependence on the `producerRegion` parameter was to clear the region as it consumed the producer iterator. That's now handled in `localSort` by a `boundary`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4409:117,clear,clear,117,https://hail.is,https://github.com/hail-is/hail/pull/4409,1,['clear'],['clear']
Usability,My hacky attempt to allow setting a path to an alternate lapack library clearly doesn't work on the cluster: it's trying to look up a flag on the HailContext on workers. Open to suggestions on the right design here.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10770#issuecomment-897005443:72,clear,clearly,72,https://hail.is,https://github.com/hail-is/hail/pull/10770#issuecomment-897005443,2,['clear'],['clearly']
Usability,My intuition is that the reference should be directed the other way. PCA should refer to the GRM docs when discussing the GRM. The GRM docs should actually contain the text explaining the GRM.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1439#issuecomment-283120768:3,intuit,intuition,3,https://hail.is,https://github.com/hail-is/hail/pull/1439#issuecomment-283120768,2,['intuit'],['intuition']
Usability,"My issue with both of those names is the same as with `_tree`. It's not clear if you're storing the non-transitive or the transitive relation & its not clear if self-edges are included. I want a name that unambiguously says ""the self-edge and all the ancestor edges are in here"" or a name that is more domain-specific like ""job groups that need to be updated when a job in this job group is changed"". . `job_group_self_and_ancestor` feels like the shortest name so far that satisfies my concerns, but I'm open to other ones that are clear about self-edge-ness and transitive-ness.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13475#issuecomment-1761867398:72,clear,clear,72,https://hail.is,https://github.com/hail-is/hail/pull/13475#issuecomment-1761867398,6,['clear'],['clear']
Usability,"MySQL supports looping. It looks like we could [use a cursor with loop](https://stackoverflow.com/a/16350693/6823256) to iterate through the ancestors of the job group. That seems to me like the simplest possible solution here. We should leave any possible speed improvements to future work and not entangle that with job groups. Jackie, my comment during our chat about deadlocks was incorrect. The if statement does prevent deadlocks because it ensures that only one MJC tries to grab an exclusive lock rather than more than one.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13513#issuecomment-1701854650:195,simpl,simplest,195,https://hail.is,https://github.com/hail-is/hail/pull/13513#issuecomment-1701854650,2,['simpl'],['simplest']
Usability,"NOTE:. There are a few places yet that I have not plumbed through the `HailStateManager`:. hail/src/main/scala/is/hail/rvd/RVDContext.scala; 42: private[this] val theRvb = new RegionValueBuilder(HailStateManager(Map.empty), r). hail/src/main/scala/is/hail/linalg/BlockMatrix.scala; 2136: val rvb = new RegionValueBuilder(HailStateManager(Map.empty), region). hail/src/main/scala/is/hail/expr/ir/MatrixValue.scala; 34: val rvb = new RegionValueBuilder(HailStateManager(Map.empty), prevGlobals.value.region). hail/src/main/scala/is/hail/expr/ir/agg/ApproxCDFStateManager.scala; 649: val rvb = new RegionValueBuilder(HailStateManager(Map.empty), r). hail/src/main/scala/is/hail/expr/ir/agg/LinearRegressionAggregator.scala; 34: val rvb = new RegionValueBuilder(HailStateManager(Map.empty), region). These places looked like either worthless effort to plumb through or difficult (the RVB in MatrixValue) so would appreciate some guidance on how to handle these use cases. ""Just do the additional plumbing"" is valid advice or a workaround if it's not desirable to add that plumbing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12699#issuecomment-1442055878:925,guid,guidance,925,https://hail.is,https://github.com/hail-is/hail/pull/12699#issuecomment-1442055878,2,['guid'],['guidance']
Usability,Neat! Where'd you learn about lateral joins? I had not heard about them until now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13175#issuecomment-1603239327:18,learn,learn,18,https://hail.is,https://github.com/hail-is/hail/pull/13175#issuecomment-1603239327,2,['learn'],['learn']
Usability,Need to add the comments from #1367 and #1374 to the style-guide.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1394:59,guid,guide,59,https://hail.is,https://github.com/hail-is/hail/issues/1394,1,['guid'],['guide']
Usability,"Needs a bit more documentation, but looking to get feedback on the structure of the scala code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4058#issuecomment-409578166:51,feedback,feedback,51,https://hail.is,https://github.com/hail-is/hail/pull/4058#issuecomment-409578166,2,['feedback'],['feedback']
Usability,"New PR for NativeModule etc. - NativeModule now has a single big_mutex, so that it is single-threaded (releasing big_mutex; only while sleeping between polling file state). - The run_shell_get_first_line() has been removed, moving almost all configuration into the; module-build makefile; ; - Simplified Makefile. - Remove some historical code",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4211:293,Simpl,Simplified,293,https://hail.is,https://github.com/hail-is/hail/pull/4211,1,['Simpl'],['Simplified']
Usability,"Next steps:; 1. upload the profile, the `mt.describe()`, metadata.json.gz from the MT/HT to the team chat and get feedback (Chris, Patrick take a look). Decode appears quite slow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1839225404:114,feedback,feedback,114,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1839225404,2,['feedback'],['feedback']
Usability,"Nice work. Let's block release on this, clearly it was bugged before.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8436#issuecomment-609932494:40,clear,clearly,40,https://hail.is,https://github.com/hail-is/hail/pull/8436#issuecomment-609932494,2,['clear'],['clearly']
Usability,"Nice, and then steps 4 - 8 will be simplified / accelerated by #3185. I think once you've revised the latter, you'll find it cleaner to work in terms of indices the whole way through (no 7), indexing the MatrixTable rows to apply the final filter in 10.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3335#issuecomment-379866339:35,simpl,simplified,35,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-379866339,2,['simpl'],['simplified']
Usability,"No changelog because the copy tool is not properly public, though; maybe it can be public now. The main problem was that we were saturating our network bandwidth; with data we did not need. Why? As far as I can tell, `release` on; an `aiohttp.ClientResponse` is insufficient to stop the receipt of; more bytes. I realized one proper fix was to simply tell the cloud storage vendors; how much data we wanted to receive. That is the change to `open_from`; which I have made pervasively to all clouds. I also changed `release` to `close` because that seems more correct.; I do not understand why we only `release`d it before.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11778:344,simpl,simply,344,https://hail.is,https://github.com/hail-is/hail/pull/11778,1,['simpl'],['simply']
Usability,No detectable difference in performance:. ```; $ hail-bench compare /tmp/before.json /tmp/after2.json; Name Ratio Time 1 Time 2; ---- ----- ------ ------; matrix_table_decode_and_count 101.5% 4.216 4.278; ----------------------; Geometric mean: 101.5%; Simple mean: 101.5%; Median: 101.5%; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7143:253,Simpl,Simple,253,https://hail.is,https://github.com/hail-is/hail/pull/7143,1,['Simpl'],['Simple']
Usability,"No one has complained about this yet, but I suspect there's a lurking issue in `linreg`. On line 75 of LinearRegression.scala, we create a writable region value using a context managed region. This region will be kept alive (in the garbage collection sense) by the context until the end of the Task (which I believe is the end of processing one partition). As such, `linreg` will generate a bunch of garbage. We close the child as soon as we know it is no longer used, thus saving memory use, at the cost of copying the results. In a future where we can reference-count regions then we could avoid the copy and simply return the writable region value. This future is not here yet.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3590:611,simpl,simply,611,https://hail.is,https://github.com/hail-is/hail/pull/3590,1,['simpl'],['simply']
Usability,"No state. I printed the session in the logs (I was deploying into prod to test while I had a broken cookie). My session had nothing set except that it was marked as created on January 7th. This despite that I saw a log statement from when I hit /login,m that clearly showed me session with all the right values. My guess is that there was some old signing key or somehow the session got corrupted so you can decode it to get an empty session and add new fields but they fail to be written back.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8052#issuecomment-583226388:259,clear,clearly,259,https://hail.is,https://github.com/hail-is/hail/pull/8052#issuecomment-583226388,2,['clear'],['clearly']
Usability,"Not a long-term solution, but we do hacky dedups like this elsewhere in the compiler and it can clean up simple duplicated IRs. Not chained duplicated IRs, as you've noticed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12462:105,simpl,simple,105,https://hail.is,https://github.com/hail-is/hail/pull/12462,1,['simpl'],['simple']
Usability,Not clearing the region in persist triggers a bug in LDPrune,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3398:4,clear,clearing,4,https://hail.is,https://github.com/hail-is/hail/issues/3398,2,['clear'],['clearing']
Usability,"Not needed, simpler js-based solution in https://github.com/hail-is/hail/pull/7334",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7290#issuecomment-545056325:12,simpl,simpler,12,https://hail.is,https://github.com/hail-is/hail/issues/7290#issuecomment-545056325,2,['simpl'],['simpler']
Usability,"Not ready to be merged yet, but I'd like to open it up for feedback on the IR DSL.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4633:59,feedback,feedback,59,https://hail.is,https://github.com/hail-is/hail/pull/4633,1,['feedback'],['feedback']
Usability,"Note, @jigold gets the credit for this, ExportBGEN.scala was basically taken from an old PR of hers that never made it in. I just simplified it to only support the 8-bit case.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6462#issuecomment-506362677:130,simpl,simplified,130,https://hail.is,https://github.com/hail-is/hail/pull/6462#issuecomment-506362677,2,['simpl'],['simplified']
Usability,"Now it seems you should use string.isMissing, while this returns an error.; I suggest isMissing(a), which makes clear the proper use of the syntax.; In Brief: update help here: https://github.com/broadinstitute/hail/blob/master/docs/HailExpressionLanguage.md",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/374:112,clear,clear,112,https://hail.is,https://github.com/hail-is/hail/issues/374,1,['clear'],['clear']
Usability,"Now that we have fully deterministic randomness, there is no need to prevent simplify from changing the partitioning.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13218:77,simpl,simplify,77,https://hail.is,https://github.com/hail-is/hail/pull/13218,1,['simpl'],['simplify']
Usability,"Now that we have the SQL query monitoring, I would love to also see just the simple comparison of the total number of queries we perform over a 1-minute period under high load. We have the tools now to see just what chunk of overall database communication we are cutting down on, which is an achievement in itself. Just need to run the test!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11346#issuecomment-1036284520:77,simpl,simple,77,https://hail.is,https://github.com/hail-is/hail/pull/11346#issuecomment-1036284520,2,['simpl'],['simple']
Usability,"OK, I added a pair of simple tests and got everything working. There's one wrinkle: I don't want to ship jars around so I need the executors to have the same jar as the client. That means the need the test jar for the tests. I'm not quite sure how to properly parameterize that in the build system yet, so I'm just leaving it with the test jar for the moment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6221#issuecomment-499365037:22,simpl,simple,22,https://hail.is,https://github.com/hail-is/hail/pull/6221#issuecomment-499365037,2,['simpl'],['simple']
Usability,"OK, I pushed some docs and clarifying comments based on your feedback, but not functional code changes. Ready for another look.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10023#issuecomment-776843634:61,feedback,feedback,61,https://hail.is,https://github.com/hail-is/hail/pull/10023#issuecomment-776843634,2,['feedback'],['feedback']
Usability,"OK, I think this is ready for review again. I rebased, was able to simplify the online bounded gather a bit, and parallelized the GCS rmtree more, so that cleanup can happen in parallel with the merge operations as much as possible.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9934#issuecomment-785209202:67,simpl,simplify,67,https://hail.is,https://github.com/hail-is/hail/pull/9934#issuecomment-785209202,2,['simpl'],['simplify']
Usability,"OK, I've made most of the changes and I'd appreciate some feedback before I finalize the PR. Notable changes:; - The `hailctl dataproc` subcommand now has `--beta`, `--configuration=`, `--dry-run`, `--project=` and `--zone=`. These apply to all commands. There is a `GcloudRunner` object that takes these options, is set to the click context user `obj` field, and is used by all hailctl dataproc commands to invoke gcloud. Note, not all dataproc subcommands invoke gcloud, but the current design doesn't differentiate. Note, with `click`, the subcommand options must go on the subcommand, so `hailctl dataproc stop --dry-run` is an error.; - hailctl no longer takes `--region` (for gcloud dataproc commands). I compute region in `GcloudRunner` by checking dataproc/region or falling back to determining the region from the zone. I error if the region and zone are incompatible (gcloud would also do this).; - I stripped all gcloud pass through args from `hailctl dataproc modify`. There aren't any left. Invoking `modify` now looks like:. ```; hailctl dataproc modify my-cluster \; --extra-glcoud-update-args='---num-workers=2 --num-secondary-workers=100'; ```. The `extra` in the option name sounds a little weird since they are the only options (and the command isn't run if they aren't specified), but I'm leaving it for consistency for now. I moved the help text from the removed options into the help for the modify command itself. The output of `modify --help` is included below.; - I plan to leave the `--async` option to stop, although it is pass through.; - Then there is `--files` for submit. This is passed through, but `--py-files` is needed (it is not passed through, but modified). Do I leave `--files`? I'm currently inclined to.; - Finally, I need to strip out the pass through arguments for start like I did with update. ```; $ hailctl dataproc modify --help; Usage: hailctl dataproc modify [OPTIONS] CLUSTER_NAME. Modify an existing Dataproc cluster. 'hailctl dataproc modify' works ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842#issuecomment-767112772:58,feedback,feedback,58,https://hail.is,https://github.com/hail-is/hail/pull/9842#issuecomment-767112772,2,['feedback'],['feedback']
Usability,"OK, I've moved it and made the interface as close as I could to the previous `scatter`. One thing is the default value for `n_divisions`. It was 500 before, now I've set it to `None` (i.e. no downsampling). I'm fine either way, but it seems somewhat more intuitive to me for the default to be no downsampling.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5601#issuecomment-473338696:255,intuit,intuitive,255,https://hail.is,https://github.com/hail-is/hail/pull/5601#issuecomment-473338696,2,['intuit'],['intuitive']
Usability,"OK, another idea to make this easier (maintaining this image separate from the build process is going to be painful): buildImage should have an optional script that runs before the docker build call. If you do this, you can just cat > Dockerfile with a very simple docker file to create the bootstrap image.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7534#issuecomment-557184077:258,simpl,simple,258,https://hail.is,https://github.com/hail-is/hail/pull/7534#issuecomment-557184077,2,['simpl'],['simple']
Usability,"OK, here's my understanding of prometheus and our use of it after chatting with @daniel-goldstein :; 1. The Python client treats Summary as just a pair of a Gauge and Counter. It's only useful if you need to track the number of times you set/increments/decrement a value and the value itself. For example, the total number of visits to a web page. Some clients for other languages treat Summaries as histogram-like things, but the Python client does not.; 2. A Histogram, with a domain-relevant array of buckets, is the right tool for visualizing a distribution of values. In this PR, we treat percent-of-cores-in-use-on-instance as a Histogram. This should let us see the distribution of instances according to what percent of the cores are revenue-generating versus not.; 3. A Gauge is the right tool for visualizing any other value. In this PR, we use a gauge to measure the total jobs, the used cores, the total free cores, the total cores, the total cost per hour (ignoring disk), and the total revenue per hour (ignoring disk). ; 4. It is important to use `remove` for metrics whose label set changes over time. For example, if all the jobs owned by a particular user finish, then the metrics labelled with that user ought to become `0`. The database query will elide such records; therefore, it is important to `remove` such labels from the `USER_CORES` and `USER_JOBS`. We prefer `remove` to `clear` so as to avoid the case where prometheus collects metrics in between a call to `clear` and a call to `set` which restores the value for a still valid label.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12253#issuecomment-1273927865:1401,clear,clear,1401,https://hail.is,https://github.com/hail-is/hail/pull/12253#issuecomment-1273927865,4,['clear'],['clear']
Usability,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:466,learn,learn,466,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385,2,['learn'],['learn']
Usability,"OK, so, I took the GRCh38 file that we test against and named it `bar`. I downloaded the gist and named it `foo`. | header | footer | success? |; |---|---|---|; |foo|bar|success|; |bar|bar|success|; |bar|foo|failure|; |foo|foo|failure|. So clearly the issue is the variants. Here's an example of running on just the first handful of variants: https://batch.hail.is/batches/8089052. ```; chr1	1339585	.	G	A	.	.	.; chr1	24907372	.	C	T	.	.	.; chr1	36859143	.	G	T	.	.	.; chr1	37969436	.	T	C	.	.	.; chr1	40416828	.	G	A	.	.	.; chr1	41581842	.	G	A	.	.	.; chr1	43920822	.	T	C	.	.	.; chr1	45327881	.	G	A	.	.	.; chr1	46817055	.	CT	C	.	.	.; chr1	54999203	.	C	T	.	.	.; chr1	65218884	.	C	T	.	.	.; chr1	102962250	.	G	T	.	.	.; chr1	111756087	.	G	C	.	.	.; chr1	113881802	.	G	A	.	.	.; chr1	117920205	.	G	A	.	.	.; chr1	151408784	.	G	C	.	.	.; chr1	151428261	.	C	T	.	.	.; chr1	152305539	.	G	C	.	.	.; chr1	152884596	.	C	A	.	.	.; chr1	153933240	.	C	T	.	.	.; chr1	156624012	.	G	A	.	.	.; chr1	159205821	.	CT	C	.	.	.; chr1	173803162	.	G	T	.	.	.; chr1	179813831	.	G	A	.	.	.; chr1	179917551	.	T	C	.	.	.; chr1	180935962	.	G	C	.	.	.; chr1	180941229	.	G	A	.	.	.; chr1	186893053	.	C	A	.	.	.; chr1	201363319	.	G	A	.	.	.; chr1	223749094	.	A	G	.	.	.; chr1	224294328	.	G	A	.	.	.; chr1	235809337	.	G	A	.	.	.; chr1	241592073	.	G	T	.	.	.; chr2	9376947	.	G	A	.	.	.; chr2	11618532	.	C	T	.	.	.; ```. We can see the characteristic super high memory use.; <img width=""570"" alt=""Screenshot 2023-11-28 at 16 35 26"" src=""https://github.com/hail-is/hail/assets/106194/e5dfa586-5c77-479b-8050-9b0b7d2fe319"">. ---. If we use the same header, but just one variant, it succeeds, but notice that the RAM use grows rapidly. https://batch.hail.is/batches/8089064/jobs/3; ```; chr1	241592073	.	G	T	.	.	.; ```; <img width=""577"" alt=""Screenshot 2023-11-28 at 16 37 39"" src=""https://github.com/hail-is/hail/assets/106194/90c5ab45-9ca4-43e0-9a97-bf6032863f32"">. ---. If we use the same header with this variant from our (successful) test VCF, the RAM use grows",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344:240,clear,clearly,240,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344,2,['clear'],['clearly']
Usability,"OK, so. - 401 unauthorized when you don't have a valid oauth2 token; - set env var in notebook indicating hail token location (we can't mount to user's home dir because we do not know which user name the image will run as); - rebased. @akotlar we seem to be down to one key difference of opinion:. > The less information reveled the better: as you mentioned, do you want foreign agents who don't already know of your endpoint to learn that you serve it? I'd argue that your API is made public through documentation and web links, not through your error code. The people who don't read those shouldn't have an easier time learning of them. agree: api is in GH, ergo public, so only point of contention is:. > The less information reveled the better: as you mentioned, do you want foreign agents who don't already know of your endpoint to learn that you serve it? ... The people who don't read those shouldn't have an easier time learning of them. Point: its not just foreign agents but anyone who hits the API, including us making mistakes, ergo, I reformulate:. > ... do you want [someone] who [forgot about or is unaware] of your endpoint to learn that you serve it? ... The people who don't read those shouldn't have an easier time learning of them. Yes, because I know I will make mistakes (and users will make config mistakes) and I want an easily debuggable system. The risk is that an attacker may learn `/jobs` exists. If that knowledge substantially improves an attacker's ability to infiltrate batch, then we've made a severe error in securing batch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844#issuecomment-483791146:429,learn,learn,429,https://hail.is,https://github.com/hail-is/hail/pull/5844#issuecomment-483791146,14,['learn'],"['learn', 'learning']"
Usability,"OK, this one is slightly subtle. A physical value at runtime actually has two forms:. 1. It is a bunch a bunch of bytes in memory at a particular address (e.g. a struct field, an array element, or a freestanding value in memory). 2. It is a value made up of JVM primitive values (or, more abstractly, Code[T]'s) that can be operated on immediately. Note, one option for (2) is just the address (1). This is what we do for structs (but note, not for arrays). Therefore, one thing we need is an operation that constructs a PValue from a physical type and an address to go from (1) => (2). I call this `PType.load`. It will be used in, for example, loadElement or loadField. See the use in loadElement below in PCanonicalIndexableValue. We also need something that goes from (2) => (1). There are two cases, whether the memory has been allocated already, or not, and I call them `PValue.store` and `PValue.allocateAndStore`. PType.load should be abstract and the implementation should be pushed to the leaves. I will do that once the full set of PValues are filled in. load/store will eventually allow us to eliminate all the IRIntermediate business. There was some complaint about my `PValue.apply` switching on PType. Some of the calls to it will go away in favor of load. I think of load as a kind of PValue constructor that takes a single argument pointing to memory. There will be other constructors depending on the PType. Those will eliminate the other calls to PValue.apply. Hopefully this discussion clears things up. FYI @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8247:1506,clear,clears,1506,https://hail.is,https://github.com/hail-is/hail/pull/8247,1,['clear'],['clears']
Usability,"Obviously, look forward to feedback on the UI and let me know if you run into any UI bugs. Another todo that I've started:; - write a UI testing playbook to enumerate all the UI interactions we want to test (by hand) to validate this code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112#issuecomment-534267706:27,feedback,feedback,27,https://hail.is,https://github.com/hail-is/hail/pull/7112#issuecomment-534267706,2,['feedback'],['feedback']
Usability,"Oh I see. Thanks for clarifying - I wasn't sure what that bit did! That should be a simple fix, though perhaps at this point not worth it as this is not a fruitful optimisation for this query",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1830665552:84,simpl,simple,84,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1830665552,2,['simpl'],['simple']
Usability,"Oh grrr, the current build is extra borked because a minor version bump in the azure blob storage library broke. I'll back out that change. Oh I think I totally misunderstood the ""pip-installed images"". [here](https://ci.hail.is/batches/774665/jobs/63) is the job I was initially confused about. Not clear why in that batch only the pip-installed hail failed the lint and not the `check_hail` step",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11502#issuecomment-1062078939:300,clear,clear,300,https://hail.is,https://github.com/hail-is/hail/pull/11502#issuecomment-1062078939,2,['clear'],['clear']
Usability,"Oh, shit, I approved. Do we have a working protocol for multi-user reviews? This was clearly not it. I guess the rule should be to dismiss your review if someone else has reviewed?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4921#issuecomment-445296624:85,clear,clearly,85,https://hail.is,https://github.com/hail-is/hail/pull/4921#issuecomment-445296624,2,['clear'],['clearly']
Usability,Ok I think this works and is simple. @chrisvittal let me know what you think,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5354#issuecomment-464203094:29,simpl,simple,29,https://hail.is,https://github.com/hail-is/hail/pull/5354#issuecomment-464203094,2,['simpl'],['simple']
Usability,Ok clearly I need to install g++.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5354#issuecomment-464188941:3,clear,clearly,3,https://hail.is,https://github.com/hail-is/hail/pull/5354#issuecomment-464188941,2,['clear'],['clearly']
Usability,Ok squashed the LDPrune one. I forgot clear in persist. (Still on the stack is to figure out why not clearing causes all these weird issues.),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3414#issuecomment-383200056:38,clear,clear,38,https://hail.is,https://github.com/hail-is/hail/pull/3414#issuecomment-383200056,4,['clear'],"['clear', 'clearing']"
Usability,"Ok, I added a caution and cleared up the note. I chose 50 MB as the biggest recommended file size since that will take ~5 seconds to write.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4644#issuecomment-433548391:26,clear,cleared,26,https://hail.is,https://github.com/hail-is/hail/pull/4644#issuecomment-433548391,2,['clear'],['cleared']
Usability,"Ok, I like all but `view_join_X` - I hate it less than what it was before (i.e. `index_X`) but it's not super intuitive",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2701#issuecomment-357081571:110,intuit,intuitive,110,https://hail.is,https://github.com/hail-is/hail/pull/2701#issuecomment-357081571,2,['intuit'],['intuitive']
Usability,"Ok, I think I get it now. The hacky solution (import `hail` in `typecheck`) doesn't seem too bad, especially if we document it so we remember to undo it if we find a better solution.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3138#issuecomment-373051517:145,undo,undo,145,https://hail.is,https://github.com/hail-is/hail/pull/3138#issuecomment-373051517,2,['undo'],['undo']
Usability,"Ok. I thought about this some more. What you've implemented is essentially a ""taint"" in Kubernetes. I ultimately want both taints and something more complicated that will have to be integrated into the scheduler. I think for now your change is self contained and it will be easy to transform later on without too much complexity or breaking changes for users. I think if you want to rename ""label"" to ""taint"" then that might make it clearer what's going on. cc: @daniel-goldstein",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11879#issuecomment-1145343746:433,clear,clearer,433,https://hail.is,https://github.com/hail-is/hail/pull/11879#issuecomment-1145343746,2,['clear'],['clearer']
Usability,"Ok. In ""Setting limit to negative disables limiting the number of split and trailing empty strings are preserved"", you're missing ""s"" on split, and it's not clear if negative is necessary for trailing empty strings to be preserved. How about:. Setting limit to negative disables limiting the number of splits. Trailing empty strings are preserved, so ""a,b,,"".split("","", -1) gives [""a"", ""b"", """"]",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1423#issuecomment-281771114:157,clear,clear,157,https://hail.is,https://github.com/hail-is/hail/pull/1423#issuecomment-281771114,2,['clear'],['clear']
Usability,"On certain occasions, the file inside the FASTA reader can be closed. It; is not yet understood why. Tests indicate that simply reopening the file; seems to resolve the issue when we run the appropriate exception. This also removes the need for SerializableReferenceSequenceFile, and so; deletes it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9436:121,simpl,simply,121,https://hail.is,https://github.com/hail-is/hail/pull/9436,1,['simpl'],['simply']
Usability,"On my rowstore1 branch I now have it working with careful use of flock() (to steer clear of the cases; where NFS behavior diverges from local filesystems, using perl's rename command (which should; be safe assuming it uses the POSIX rename() syscall) to avoid having to lock/unlock from a Makefile. Also a bunch of Makefile changes to use commands from /bin or /usr/bin when they exist, but; otherwise to give a warning and pick up whatever might be found on $PATH. That seems a suitable; compromise between avoid-mysterious-behavior and give-best-effort-on-nonstandard-platform.; [In doing so, I noticed that I actually was picking up /Users/rcownie/anaconda2/envs/py36/bin/curl; rather than /usr/bin/curl - and I don't know whether there's any difference]. But current consensus is that we should figure out how to ship with a known-good compiler; and libraries, so I'm looking into that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-413647683:83,clear,clear,83,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413647683,2,['clear'],['clear']
Usability,"On std::unique_ptr, I may be a contrarian, but I don't care what the ""C++ community"" thinks about it.; If you buy into using std::unique_ptr<T>, then everyone who writes or reads the code has to get ; their head around the massively confusing and counter-intuitive concept of move semantics (a ; form of assignment which modifies the source) *and* the somewhat bizarre terminology and syntax; used to express that in C++. And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). . I would be fine with that extra learning curve and complexity if unique_ptr<T> solved a difficult; problem. But - by definition! - it doesn't. It only works for the easy case where you have one; pointer to each object. And anywhere that you *might* want to use unique_ptr<T>, shared_ptr<T> provides a superset; of the functionality at only a small extra cost in memory and runtime. So my rule is, if you need; a smart pointer, use shared_ptr<T>. And if there's some place where the memory or performance; cost of shared_ptr<T> is truly proved to be painful, then use a few raw pointers where absolutely; necessary.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3718#issuecomment-396320515:255,intuit,intuitive,255,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396320515,4,"['intuit', 'learn']","['intuitive', 'learning']"
Usability,"Once the current auth overhaul is through and we go ""keyless"", the only secret left that we mount into user jobs is the deploy config, which at that point feels kind of silly. It's also nearly always the same deploy config value that we serialize and write to a file for every job. It seems cleaner and simpler to me that we create one deploy config for the worker, and the worker readonly mounts that config into every job. Note that this is overridable so that any pre-existing jobs that specify a deploy-config secret and all the special deploy-config stuff that we do in build.yaml should not be affected",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13203:303,simpl,simpler,303,https://hail.is,https://github.com/hail-is/hail/pull/13203,1,['simpl'],['simpler']
Usability,"One more thing: I feel like you can simplify some additional stuff by getting rid of the T parameter on CodeAggregator and call the invoke instance that takes arrays of `Class`es and `Code`s. That way, you don't have to track T. Again, I think you can get the necessary types from the ApplyAggOp instance.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2623#issuecomment-359279810:36,simpl,simplify,36,https://hail.is,https://github.com/hail-is/hail/pull/2623#issuecomment-359279810,2,['simpl'],['simplify']
Usability,"One obvious point of optimization that Dan already identified is the way we were keying our data is causing full shuffles, as we were keying the data by a string variant ID in the form `1-32683987-ACTCTT-A` instead of locus-allele. Changing back to keying on locus-allele fixes this issue for our more straightforward searches, but we have a search that looks for pairs of possible compound heterozygous variants in the same gene, and that still is resulting in 2 full shuffles. I'm a little at a loss for how to fix this, because we are grouping by an unsorted field so I'm not sure how to prevent us from working with an unsorted dataset. The offending code right now is as follows (somewhat simplified for readability):. ```; primary_variants = hl.agg.filter(ch_ht[HAS_ALLOWED_ANNOTATION], hl.agg.collect(ch_ht.row)); secondary_variants = hl.agg.filter(ch_ht[HAS_ALLOWED_SECONDARY_ANNOTATION], hl.agg.collect(ch_ht.row)); ch_ht = ch_ht.group_by('gene_ids').aggregate(v1=primary_variants, v2=secondary_variants); ch_ht = ch_ht.explode(ch_ht.v1); ch_ht = ch_ht.explode(ch_ht.v2); ch_ht = ch_ht.annotate(grouped_variants=hl.sorted([ch_ht.v1, ch_ht.v2], key=lambda v: (v.locus, v.alleles))); ch_ht = ch_ht.key_by(; locus=ch_ht.grouped_variants[0].locus, ; alleles=ch_ht.grouped_variants[0].alleles,; locus2=ch_ht.grouped_variants[1].locus, ; alleles2=ch_ht.grouped_variants[1].alleles,; ); ch_ht = ch_ht.distinct(); ...; # more filtering and annotating; ...; return ch_ht._key_by_assert_sorted('locus', 'alleles'); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1776044401:694,simpl,simplified,694,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1776044401,2,['simpl'],['simplified']
Usability,"Oof, good catch! The thing we're trying to avoid is `e^x` overflowing for large positive `x`. In double precision, the smallest `x` that overflows is 710. So to test that we handle overflow correctly, you can check `sigmoid(710) == 1.0` and `sigmoid(-710) == 0.0` (using approximate equality). Actually, after playing with this, if you just use the simple definition `sigmoid(x) = 1 / (1 + np.exp(-x))`, then `sigmoid(-710)` does overflow, but it returns the right answer since `np.exp(710)` returns `inf`, and `1 / inf == 0.0`. But `math.exp(710)` throws an exception. `hl.exp` seems to have the numpy behavior, so I think the simple version actually works. But we should add the above test. I think wrapping this in an exposed function is a good idea. I agree it should be called `expit`, both for consistency with scipy, and because as you say, `sigmoid` really just means an S shaped function. And if we do expose `expit`, we should probably expose its inverse `logit` too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10606#issuecomment-866034244:349,simpl,simple,349,https://hail.is,https://github.com/hail-is/hail/pull/10606#issuecomment-866034244,4,['simpl'],['simple']
Usability,Our error message on functions that read TSV are much clearer than they used to be. I don't think this needs to be a separate command.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/216#issuecomment-279518768:54,clear,clearer,54,https://hail.is,https://github.com/hail-is/hail/issues/216#issuecomment-279518768,2,['clear'],['clearer']
Usability,"Overall this is good, but I think we should simplify the interface. 1. Require `entry_to_double`. Don't support genotypes or do normalization. 2. Only have the one version that returns the triple. The user can reannotate the original dataset if that's what they want. 3. Write a `VariantDataset.genotype_matrix_pca` in Python that looks at the `.GT` field and does the necessary normalization before calling `pca`. This should be written completely in Python.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2454#issuecomment-348531819:44,simpl,simplify,44,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348531819,2,['simpl'],['simplify']
Usability,"PBetterLocus is represented as a Long. The high 32 bits are the index of; the contig in its reference genome. The low 32 bits are the position. A key assumption here is that there will never be more than INT_MAX; contigs in any reference genome. With that, we can simply compare; PBetterLocus with Long comparision as they are all nonnegative.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8431:264,simpl,simply,264,https://hail.is,https://github.com/hail-is/hail/pull/8431,1,['simpl'],['simply']
Usability,"PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2NDVjMDg3ZS00NzIwLTRkZTgtYmI0NC00MWNkOTY0NTBmZjUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjY0NWMwODdlLTQ3MjAtNGRlOC1iYjQ0LTQxY2Q5NjQ1MGZmNSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""645c087e-4720-4de8-bb44-41cd96450ff5"",""prPublicId"":""645c087e-4720-4de8-bb44-41cd96450ff5"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""}],""packageManager"":""pip"",""projectPublicId"":""0ba777e1-bc27-41cc-aefa-0ed1a253829e"",""projectUrl"":""https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,718],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14220:3841,Learn,Learn,3841,https://hail.is,https://github.com/hail-is/hail/pull/14220,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZGRlNzcwZi0yMzMyLTQ5ZjktOWI1My05ZDY1OGJlOTVjMmQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdkZGU3NzBmLTIzMzItNDlmOS05YjUzLTlkNjU4YmU5NWMyZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7dde770f-2332-49f9-9b53-9d658be95c2d"",""prPublicId"":""7dde770f-2332-49f9-9b53-9d658be95c2d"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,718],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14228:3789,Learn,Learn,3789,https://hail.is,https://github.com/hail-is/hail/pull/14228,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5ZWNjYjQ0YS1jYWZiLTQ0OTgtYjU1NS02NDdmZjUwY2ExOTQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjllY2NiNDRhLWNhZmItNDQ5OC1iNTU1LTY0N2ZmNTBjYTE5NCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""9eccb44a-cafb-4498-b555-647ff50ca194"",""prPublicId"":""9eccb44a-cafb-4498-b555-647ff50ca194"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""}],""packageManager"":""pip"",""projectPublicId"":""fdd23464-9a67-49b8-8d9c-08502282c5fb"",""projectUrl"":""https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,718],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14225:3775,Learn,Learn,3775,https://hail.is,https://github.com/hail-is/hail/pull/14225,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZDFmMzFlYi1hYTcyLTQyMTYtOTgzNC01MDljMDdhOWFmNTMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFkMWYzMWViLWFhNzItNDIxNi05ODM0LTUwOWMwN2E5YWY1MyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ad1f31eb-aa72-4216-9834-509c07a9af53"",""prPublicId"":""ad1f31eb-aa72-4216-9834-509c07a9af53"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,718],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14227:4021,Learn,Learn,4021,https://hail.is,https://github.com/hail-is/hail/pull/14227,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMzQ0ZjYzNy00MjQwLTQxNmEtYjE2Yi1kODhmYjc2YTUwZmYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUzNDRmNjM3LTQyNDAtNDE2YS1iMTZiLWQ4OGZiNzZhNTBmZiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e344f637-4240-416a-b16b-d88fb76a50ff"",""prPublicId"":""e344f637-4240-416a-b16b-d88fb76a50ff"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""}],""packageManager"":""pip"",""projectPublicId"":""92d13c88-936f-40d3-b692-29e637c1a00c"",""projectUrl"":""https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,718],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14226:3766,Learn,Learn,3766,https://hail.is,https://github.com/hail-is/hail/pull/14226,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,Part 1 of improving dev deploy usability. This PR:. - Moves definition of profiles out of CI so that new build steps can be added as part of development.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6660:31,usab,usability,31,https://hail.is,https://github.com/hail-is/hail/pull/6660,1,['usab'],['usability']
Usability,"Personally, I'm not a fan of the `n` prefix that Spark and friends use everywhere they what ""number of"". I think `rows` (the Breeze naming style) is always clear in context.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2542#issuecomment-350358236:156,clear,clear,156,https://hail.is,https://github.com/hail-is/hail/pull/2542#issuecomment-350358236,2,['clear'],['clear']
Usability,"Pick a backwards compatibility test table, `1.5.0/6.ht` is the simplest one. ```; In [2]: ht = hl.read_table('hail/src/test/resources/backward_compatability/1.5.0/table/6.ht/'. In [3]: ht.aggregate(hl.agg.collect(ht.nd)); Out[3]:; [array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32)]. In [4]: ht.select('nd').show(); +-------+----------------------------------------------------------------+; | idx | nd |; +-------+----------------------------------------------------------------+; | int32 | ndarray<int32, 2> |; +-------+----------------------------------------------------------------+; | 0 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 1 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 2 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 3 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 4 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; +-------+----------------------------------------------------------------+; ```. The first result looks more correct to mine eyes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9640:63,simpl,simplest,63,https://hail.is,https://github.com/hail-is/hail/issues/9640,1,['simpl'],['simplest']
Usability,"Please look over the `FAQ.md` page and let me know if this is what you had in mind in terms of layout, organization, question complexity, and range of topics. I haven't done a thorough pass through of the Hail slack channel yet. Once I have your feedback, I'll continue adding and refining examples.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/481:246,feedback,feedback,246,https://hail.is,https://github.com/hail-is/hail/pull/481,1,['feedback'],['feedback']
Usability,Please update to be consistent with python/pyhail/docs/style-guide.txt and resubmit.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1114#issuecomment-266934270:61,guid,guide,61,https://hail.is,https://github.com/hail-is/hail/pull/1114#issuecomment-266934270,6,['guid'],['guide']
Usability,"Plus:; - Boolean ldc (load constant) instructions need an int, not a boolean. JVM seems OK with it, but the asm bytecode verifier rejects it.; - In Apply codegen, the zip in function lookup was potentially truncating the arguments, selecting an incorrect function. Fix, and simplify the definition of `methods`.; - Fix/simplify asm error reporting from asm in lir Emit. The old code was crashing inside asm. I used the new code to debug some bytecode issues, it works well.; - compute max locals/stack, needed by the asm verifier (CheckClass). @konradjk This fixes your class not found issue.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8537:274,simpl,simplify,274,https://hail.is,https://github.com/hail-is/hail/pull/8537,2,['simpl'],['simplify']
Usability,Ported ImportBgenSuite to Python. I mostly did this to make this simpler.; Removed some unused funtions in RichMatrixTable. We can double-check with the community before merging.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3743:65,simpl,simpler,65,https://hail.is,https://github.com/hail-is/hail/pull/3743,1,['simpl'],['simpler']
Usability,"Potentially relevant: https://community.plotly.com/t/graphing-storage-in-units-of-1024-kilobytes-megabytes-etc/14305/2. I think it's a little bit of work to get to a place where units show up nicely for memory. Going to want to find the max value in the column in bytes, figure out what scale we are at (bytes, kilobytes, megabytes, gigabytes, etc.) then set custom tick range and tickvals accordingly. Also should probably make it clear whether we are in ""megabytes"" or ""mebibytes"" or whatever they're called.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11690#issuecomment-1080637072:432,clear,clear,432,https://hail.is,https://github.com/hail-is/hail/pull/11690#issuecomment-1080637072,2,['clear'],['clear']
Usability,"Pretty simple pipeline, only failed about ~3/4 through the final (write) stage...; ```; mt = hl.read_matrix_table(); sample_group_filters = {; ""qc_samples_raw"": mt.meta.high_quality,; ""release_samples_raw"": mt.meta.release,; ""all_samples_raw"": True; }; mt = mt.select_cols(**sample_group_filters); mt = unphase_mt(mt.select_rows(*mt.row_key)); call_stats_expression = []; for group in sample_group_filters.keys():; call_stats_expression.append(; hl.struct(call_stats=hl.agg.call_stats(hl.agg.filter(mt[group], mt.GT), mt.alleles),; meta={'group': group}); ); mt.annotate_rows(qc_callstats=call_stats_expression).drop_cols().write(); ```. ```; Traceback (most recent call last):; File ""/tmp/a913d6ce5b814a63ad7af31060416237/pyscripts_Xr0D99.zip/gnomad_hail/slack_utils.py"", line 77, in try_slack; File ""/tmp/a913d6ce5b814a63ad7af31060416237/generate_qc_annotations.py"", line 247, in main; generate_call_stats(mt).write(annotations_mt_path(data_type, 'call_stats'), args.overwrite); File ""<decorator-gen-556>"", line 2, in write; File ""/tmp/a913d6ce5b814a63ad7af31060416237/hail-devel-a1d6ecc71ce3.zip/hail/typecheck/check.py"", line 481, in _typecheck; File ""/tmp/a913d6ce5b814a63ad7af31060416237/hail-devel-a1d6ecc71ce3.zip/hail/matrixtable.py"", line 2027, in write; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/a913d6ce5b814a63ad7af31060416237/hail-devel-a1d6ecc71ce3.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: IllegalArgumentException: requirement failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 9716 in stage 1.0 failed 20 times, most recent failure: Lost task 9716.19 in stage 1.0 (TID 10060, exomes3-sw-dfpw.c.broad-mpg-gnomad.internal, executor 134): java.lang.IllegalArgumentException: requirement failed; 	at scala.Predef$.require(Predef.scala:212); 	at is.hail.variant.Call$.alleleByIndex(Call.scala:128); 	at is.hail.expr.FunctionRegistry$$anonfun$",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:7,simpl,simple,7,https://hail.is,https://github.com/hail-is/hail/issues/3465,1,['simpl'],['simple']
Usability,"Previously the below would display `0.GT | 1.GT` (simply the index in the entries array). ```; In [2]: import hail as hl ; ...: mt = hl.balding_nichols_model(3, 100, 100) ; ...: mt = mt.key_cols_by(sample_id = 'sample-' + hl.str(mt.sample_idx)) ; ...: mt.show(n_rows=10, n_cols=10) ; 2019-06-19 16:20:33 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 100 samples, and 100 variants...; +---------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+; | locus | alleles | sample-0.GT | sample-1.GT | sample-2.GT | sample-3.GT | sample-4.GT | sample-5.GT | sample-6.GT | sample-7.GT | sample-8.GT | sample-9.GT |; +---------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+; | locus<GRCh37> | array<str> | call | call | call | call | call | call | call | call | call | call |; +---------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+; | 1:1 | [""A"",""C""] | 0/0 | 0/0 | 0/1 | 1/1 | 0/1 | 0/0 | 0/1 | 0/1 | 0/1 | 0/1 |; | 1:2 | [""A"",""C""] | 1/1 | 0/1 | 0/0 | 0/1 | 1/1 | 1/1 | 0/1 | 1/1 | 0/0 | 1/1 |; | 1:3 | [""A"",""C""] | 1/1 | 0/1 | 0/0 | 1/1 | 0/0 | 1/1 | 1/1 | 0/1 | 0/0 | 1/1 |; | 1:4 | [""A"",""C""] | 0/0 | 0/1 | 0/0 | 1/1 | 0/1 | 0/0 | 0/1 | 0/0 | 0/0 | 0/1 |; | 1:5 | [""A"",""C""] | 0/1 | 0/0 | 0/0 | 0/0 | 0/1 | 0/0 | 0/1 | 0/1 | 0/0 | 1/1 |; | 1:6 | [""A"",""C""] | 0/0 | 1/1 | 1/1 | 0/1 | 0/1 | 1/1 | 0/1 | 0/1 | 1/1 | 1/1 |; | 1:7 | [""A"",""C""] | 0/0 | 0/1 | 1/1 | 0/1 | 0/1 | 0/1 | 0/0 | 0/1 | 0/0 | 0/1 |; | 1:8 | [""A"",""C""] | 0/1 | 0/1 | 1/1 | 1/1 | 0/1 | 0/1 | 1/1 | 1/1 | 0/1 | 0/1 |; | 1:9 | [""A"",""C""] | 0/0 | 0/1 | 1/1 | 1/1 | 1/1 | 0/1 | 1/1 | 1/1 | 1/1 | 1/1 |; | 1:10 | [""A"",""C""] | 0/1 | 0/1 | 0/1 | 0/0 | 0/1 | 0/0 | 0/1 | 0/1 | 0/0 | 0/1 |",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6405:50,simpl,simply,50,https://hail.is,https://github.com/hail-is/hail/pull/6405,1,['simpl'],['simply']
Usability,"Previously, MatrixMapRows was calling into an IR-generated function for each element. Now we aggregate the entire row from within Python. On a 6-aggregator benchmark on a shard of gnomAD, this improved things about 50% (1m59 => 1m02). Some notable changes:; - I added a Begin for sequencing void-type IR,; - I added ArrayFor for looping over arrays (@danking); - I added a SeqOp that represents calling the RegionValueAggregator in seqOp in the IR after extracting aggregators, it holds the index of the aggregator to call seqsOp on, since there might be multiple,; - added Void literal (which I didn't end up using, but I left it in for now),; - TAggreable symbol table is no longer used in compiling the extracted aggregators. The arguments need to specified explicitly and otherwise it is just another function (but takes an extra special argument, the array of RVAggregators),. This suggests some additional improvements/simplifications to the aggregator interface that I will write up on the dev forum.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3422:925,simpl,simplifications,925,https://hail.is,https://github.com/hail-is/hail/pull/3422,1,['simpl'],['simplifications']
Usability,"Progress bars for batch submit (which work even if individual bunches fail). Stacked on #7875. <img width=""885"" alt=""Screen Shot 2020-01-14 at 3 53 40 PM"" src=""https://user-images.githubusercontent.com/106194/72382076-829e1e80-36e6-11ea-9626-1e67e5aa54ce.png"">. Now also works in Jupyter Notebook (you get a GUI bar). I added `hailtop.utils.tqdm` and `hailtop.utils.TQDM_DEFAULT_DISABLE` because the ""correct"" default argument for disable is different between Jupyter Notebook and the console tqdm. In particular, console tqdm treats `None` as ""if I'm connected to a TTY, display, otherwise hide"". Jupyter tqdm treats `None` as ""do not display"" (which is clearly the wrong default, but 🤷‍♀ ).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7876:0,Progress bar,Progress bars,0,https://hail.is,https://github.com/hail-is/hail/pull/7876,2,"['Progress bar', 'clear']","['Progress bars', 'clearly']"
Usability,"Proposed change for `ld_prune` motivated by user difficulty importing and pruning 1kg. As we don't have near-term plans for a version that exploits phasing, I think it's best to make this runnable regardless of phasing, while documenting that the algorithm ignores phasing. I've added this description, fixed a doc bug (unit is bases, not kilobases) and changed the parameter `window` to `bp_window_size`, which is consistent with `window_by_locus` and I think clearer. (I'll note it on our breaking changes dev post). If we add a method that incorporates phasing in 0.2 lifetime, it can be a separate method or we can add a parameter `use_phasing` with default value `False`. (actually, it should be a separate method since r^2 correlation won't be the right measure for that).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3575:461,clear,clearer,461,https://hail.is,https://github.com/hail-is/hail/pull/3575,1,['clear'],['clearer']
Usability,"Proposed interface changes:. class TextTableConfiguration. class TextTableReader. TextTableReader(conf); TextTableReader(delimiter = ""#"", ...). // only read fields ; TextTableReader.read(columnTypes: Map[String, Type], path: String, [select]): (TStruct, RDD[Annotation]). (and JSON). for JSON:. JSONReader.read(t: Type, path: String): RDD[Annotation]. in expr language:. support. Variant(""chr:pos:ref:alt1,...,altN"") . (so Variant(v.toString) == v) and. Variant(chr: String, pos: Int, ref: String, alts: Array[String]). Then we can do:. annotatevariants table -v 'Variant(Chrom, Pos, Ref, Alts.split("",""))'. annotatevariants table -v 'Variant(Variant)'. To get this behavior, you'll have to build the EvalContext from the table type. Add. TStruct.filter(predicate: (Field) => Boolean): (TStruct, Filterer). where. type Filterer = (Annotation) => Annotation. This should make implementating importvariants table simple and elegant.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/462#issuecomment-232740494:911,simpl,simple,911,https://hail.is,https://github.com/hail-is/hail/pull/462#issuecomment-232740494,2,['simpl'],['simple']
Usability,Putting WIP because I'm also going to get some feedback from Wenhan start of next week,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14562#issuecomment-2129755103:47,feedback,feedback,47,https://hail.is,https://github.com/hail-is/hail/pull/14562#issuecomment-2129755103,2,['feedback'],['feedback']
Usability,"ROM jobs FORCE INDEX(jobs_batch_id_state_always_run_cancelled); -> LEFT JOIN jobs_telemetry ON jobs.batch_id = jobs_telemetry.batch_id AND jobs.job_id = jobs_telemetry.job_id; -> WHERE jobs.batch_id = BATCH_ID AND (jobs.batch_id < BATCH_ID OR (jobs.batch_id = BATCH_ID AND jobs.job_id <= 15000)) AND inst_coll = ""standard"" AND jobs.state = 'Ready' AND always_run = 0 AND cancelled = 0; -> ORDER BY jobs.batch_id, inst_coll, state, always_run, -n_regions DESC, regions_bits_rep, jobs.job_id; -> LIMIT 300;; +----+-------------+----------------+------------+--------+------------------------------------------+------------------------------------------+---------+-------------------------+-------+----------+----------------------------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+----------------+------------+--------+------------------------------------------+------------------------------------------+---------+-------------------------+-------+----------+----------------------------------------------------+; | 1 | SIMPLE | jobs | NULL | range | jobs_batch_id_state_always_run_cancelled | jobs_batch_id_state_always_run_cancelled | 136 | NULL | 24092 | 10.00 | Using index condition; Using where; Using filesort |; | 1 | SIMPLE | jobs_telemetry | NULL | eq_ref | PRIMARY | PRIMARY | 12 | const,batch.jobs.job_id | 1 | 100.00 | NULL |; +----+-------------+----------------+------------+--------+------------------------------------------+------------------------------------------+---------+-------------------------+-------+----------+----------------------------------------------------+; 2 rows in set, 1 warning (0.00 sec); ```. I'm open to other ideas for how to fix this. This change is a starting point for how to mitigate the issue in the short term. However, I think a longer term plan needs to be implemented which I already have considered with another design proposal.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13268:2415,SIMPL,SIMPLE,2415,https://hail.is,https://github.com/hail-is/hail/pull/13268,1,['SIMPL'],['SIMPLE']
Usability,"Re-implement export vcf in generated code. There is a fair amount of 'duplicated' code here between table export; and vcf export, however, I belive this to be fine. We can always; refactor VCFPartitionWriter to be a subclass of SimplePartitionWriter,; but that would require a little special casing as VCF export needs; access to the column values and SimplePartitionWriter assumes such; a thing is not necessary. As far as VCF export itself, we simply duplicate the logic present in; ExportVCF but with generated code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11450:228,Simpl,SimplePartitionWriter,228,https://hail.is,https://github.com/hail-is/hail/pull/11450,3,"['Simpl', 'simpl']","['SimplePartitionWriter', 'simply']"
Usability,"Re: testing, I wanted to wait on the spawned batch and ensure that it passed, but I had trouble doing that because it looks like the new rich progress bars are printed to stdout so I can't make use of json output and `jq`. Can we print the progress bars to stderr instead?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12471#issuecomment-1324141580:142,progress bar,progress bars,142,https://hail.is,https://github.com/hail-is/hail/pull/12471#issuecomment-1324141580,4,['progress bar'],['progress bars']
Usability,"Reading function/contexts from GCS on query workers can contribute a significant portion of the runtime for small jobs. For a simple query like `hl.utils.range_table(10).collect()`, the jobs in the batch can range in time from 5-9 seconds depending on GCS latency. This builds on #9484 to add write-through capability to `memory` and a `ServiceCacheableFS` in Scala. The cacheable FS reads/writes through `memory` and falls back to GCS, so in the good path the ServiceBackend writes the compiled function and contexts to `memory`, workers read inputs and write outputs exclusively from/to memory, from which the ServiceBackend reads the results. From small benchmarks in dev, this cuts down read times on the workers by ~30-40% compared to the worst case GCS latencies and roughly matches the current implementation in the best case. Writing the outputs is comparable to writing through an already warmed up GCS connection.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10315:126,simpl,simple,126,https://hail.is,https://github.com/hail-is/hail/pull/10315,1,['simpl'],['simple']
Usability,"Ready for another look. I had to modify the classes some to make it work, particularly for getting the `type` out of the test. Now the type is with the Test rather than the TestResult, perhaps you see a better way?. Related notes, mostly relevant to future PRs once we have some feedback and a sense of performance:. I think LogisticRegressionNullFit should be a separate class, as it plays a conceptually and practically different role. I don't want to attach vectors of length nSamples (like mu) to each LogisticRegressionFit output, even though they would speed up the score test and first iteration of fitting per variant to not recompute them for every variant. I did put some of this efficiency in the score test (only computing the extra coordinate of score and row / column of fisher per variant). df would also then go away for LogisticRegressionFit, but I'd add the diagonal of its inverse for use in Wald (see below). The model fit function would then take a LogisticRegressionNullFit to use in the first iteration. The bigger future gains will come from not computing or inverting the Fisher matrix at all in the iteration, but rather using QR magic. val sqrtW = sqrt(mu :\* (1d - mu)); val QR = qr.reduced(X(::, _) :_ sqrtW); solve QR.R \* deltaB = QR.Q.t \* (y - mu) with R upper triangular (need to wrap lapack function). for Wald: return diagonal of inverse as well, namely diagonal of inv(R)^T \* inv(R), rather than inverting fisher again. for Score, this version of this may be faster:; val sqrtW = sqrt(mu :\* (1d - mu)); val Qty0 = qr.reduced.justQ(X(::, _) :_ sqrtW).t \* ((y - mu) :/ sqrtW); val chi2 = Qty0 dot Qty0. for Firth, modify score using:; val QQ = QR.Q :\* QR.Q; val h = sum(QQ(*, ::))",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/585#issuecomment-241153168:279,feedback,feedback,279,https://hail.is,https://github.com/hail-is/hail/pull/585#issuecomment-241153168,2,['feedback'],['feedback']
Usability,"Recent log demonstrating the failure: https://cloudlogging.app.goo.gl/ayiTFRnkLdrSzY2j7. In retrospect this seems kind of obvious. Consider `JVMEntryway`. The first `log` statement occurs on line 98 (the line after we set the filename). I think, in my head, the Appender would be created when we initialized the Logger on line 17. That's apparently incorrect. The Appender is lazily created when some internal buffer fills and the logger flushes that buffer. That internal buffer is most likely to fill on the `log.error` lines because they dump a (large) stack trace to the log. That's why we always see the error there. The fix is simple: we track the currently desired output filename and, if we happen to create an appender *after* someone has called `changeFileInAllAppenders`, we initialize that new appender with the filename. This change ensures that, except for a short period during start up, there is always a valid filename. That short period is just the time between the JVM starting, allocating a `JVMEntryway`, calling `main` and getting to line 97. During that time, we carefully use `System.err.println` (not a logger) if something goes wrong.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13664:633,simpl,simple,633,https://hail.is,https://github.com/hail-is/hail/pull/13664,1,['simpl'],['simple']
Usability,"Refactors `Bindings` to return an object encoding the change to the environment (any new bindings, whether the agg/scan env is promoted, etc). This allows the deletion of `SegregatedBindingEnv`. Follow up work will use this to replace the other specializations of `GenericBindingEnv`, and to greatly simplify compiler passes, such as `NormalizeNames` and `PruneDeadFields`, which currently need to redundantly encode the binding structure of every node.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14496:300,simpl,simplify,300,https://hail.is,https://github.com/hail-is/hail/pull/14496,1,['simpl'],['simplify']
Usability,"Regarding SSR-only mode. This is the default behavior. SSR is mostly a function of routing. If we allow the client to handle routes, we save the roundtrip in reconciling current app state (current DOM) with the next state (next page's DOM). To ""enable"" this functionality, instead of using `<Link>` use `<a>`. Nextjs has excellent documentation and a responsive maintainer base: https://github.com/zeit/next.js/issues/575",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-454796376:351,responsiv,responsive,351,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-454796376,2,['responsiv'],['responsive']
Usability,"Regarding the `pyspark` issue, it looks like you have to use `--properties-file` and then put that comma-sepearted list as a newline-separated list in a file. That error message is pyspark's rather terrible way of telling you that it doesn't support a `--properties` option. Regarding the old version of VDS, the `master` branch of hail is now an unstable development branch. If you want a consistent user experience with backwards compatible interfaces, please check out and exclusively use the `0.1` branch. Tim discusses the wider change [here](http://discuss.hail.is/t/deployment-changes-branching-off-for-faster-development/261/1). The VDS format will likely change on the scale of days on the `master` branch. Regarding the `hail/scripts` folder, that is a repository of scripts that our build system uses as templates to create a pre-compiled, ready-to-go distribution that only requires a Spark installation. These distributions are available from the Google Storage API at gs://hail-common/distributions. If you're building from source, I recommend following exactly the steps listed [here](https://hail.is/docs/stable/getting_started.html#building-hail-from-source) so as to avoid any future hiccups. NB: the steps for [Running Hail Locally](https://hail.is/docs/stable/getting_started.html#running-hail-locally) are for using the pre-compiled distribution, not for the result of building hail directly from source.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2062#issuecomment-320242551:401,user experience,user experience,401,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320242551,2,['user experience'],['user experience']
Usability,"RegionPool does have a finalize method, so presumably that will be called on the driver if needed (I don't really know if or when java calls finalizers). I implemented a `clear()` method that reclaims all RegionMemory owned by the pool, but leaves the pool ready to be used by the next task.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8287#issuecomment-597830451:171,clear,clear,171,https://hail.is,https://github.com/hail-is/hail/pull/8287#issuecomment-597830451,2,['clear'],['clear']
Usability,"Remaining is that found in Etypes, in the _buildSkip function. This is slightly tricky, because there is a place in the code where there is no corresponding PType, and the solution to fix that is a bit involved, or if straightforward, beyond my current understanding of ETypes. I made an issue here: https://github.com/hail-is/hail/issues/7701. Stacked on https://github.com/hail-is/hail/pull/7687. edit: I removed the ETypes issue, by creating a packBitsToBytes function on UnsafeUtils. We may not want this change however, because I think array packing may needs to be the same as the array implementation (I think readBytes fills the allocated memory with the InputBuffer's encoded missingness data, which needs same number of bytes as what is encoded), in which case that coupling becomes less clear if the utility function is on UnsafeUtils. I could move it back to PContainer, or may _buildSkip take a ptype. . There are other places where (n + 7) >>> 3 are used, so this seems pretty general, hence UnsafeUtils (where we have some other bitwise ops, happy to move elsewhere). PTuple is one.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7702:798,clear,clear,798,https://hail.is,https://github.com/hail-is/hail/pull/7702,1,['clear'],['clear']
Usability,"Remove AST hierarchy, FunctionRegistry, AST parser, dependencies (tests) and any other dead code I could find. > 4 additions and 6,710 deletions. Aw, yiss. Full disclosure: this deletes some tests (SKAT, PCRelate, etc.) that currently have no corresponding tests in Python. My plan is to do a ""test audit"" and assign out tests to make sure we have a complete set of tests for the current functionality (including stuff that was deleted here and things that are simply missing tests, e.g. the MatrixIR parser, some IR nodes, etc.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3990:461,simpl,simply,461,https://hail.is,https://github.com/hail-is/hail/pull/3990,1,['simpl'],['simply']
Usability,Remove conversions from the function registry. They are now inserted by Python and explicit in the expression language. This should simplify lots of stuff on the back end.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3120:132,simpl,simplify,132,https://hail.is,https://github.com/hail-is/hail/pull/3120,1,['simpl'],['simplify']
Usability,"Remove the `Begin` node, as its behavior can now be represented by the `Let` node. Besides removing redundant nodes, this will also make the new ssa-style text representation simpler. The `Begin` node emmitter performed method splitting, emitting groups of 16 children in seperate methods. This preserves that behavior by doing a similar optimization in the `Let` emitter. This is a significant change in how we split generated code into methods, so we should watch out for how this affects things.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14068:175,simpl,simpler,175,https://hail.is,https://github.com/hail-is/hail/pull/14068,1,['simpl'],['simpler']
Usability,"Replaces https://github.com/hail-is/hail/pull/13260. - `test_spectral_moments` times out in a PR: (QoB) https://hail.zulipchat.com/#narrow/stream/127527-team/topic/timeouts/near/376698259, (spark) https://ci.hail.is/batches/7653376/jobs/74, (spark) https://ci.hail.is/batches/7653376/jobs/72, (spark) https://ci.hail.is/batches/7653376/jobs/62. I also backed local off to 4m even though it has no evidence of time outs. Seems simpler for Spark and local to be the same.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13278:426,simpl,simpler,426,https://hail.is,https://github.com/hail-is/hail/pull/13278,1,['simpl'],['simpler']
Usability,"Replaces setAllMissing (1, staged-only function), clearMissingBits (3 functions with both staged and unstated implementations) with staged/non-staged initialization functions, mirroring the PContainer API. Semantically this is more correct (for instance clearMissingBits was used mostly behind the condition like `if (init)`), and represents 2 fewer functions to maintain (3 if you count that we may have eventually wanted a setAllMissing in the non-staged world)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7831:50,clear,clearMissingBits,50,https://hail.is,https://github.com/hail-is/hail/pull/7831,2,['clear'],['clearMissingBits']
Usability,"Replying to cseed on code-reuse and cacheing/locking. a) Even with whole-stage codegen, there's a possibility that during development a user; will be tweaking a query in ways which don't change all the stages. And in that case the re-use; would give hits on some stages. The plan is not really to aim at structuring things to get a; high level of re-use, but just to opportunistically exploit re-use which happens to occur -; e.g. if the early stages of an analysis involve reading an existing file and filtering in various; ways, then that may not be changed at all by changes to what happen in the real analysis; after the filtering. And this is also influenced by the medium-term goal of having a Hail service; which (amongst other things) can do simple analyses on small data in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could m",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:750,simpl,simple,750,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385,2,['simpl'],['simple']
Usability,"Research on UX/UI, and impact on customer acceptance. Is there a reason to invest in surface credibility (beyond functionality)?. 1) http://credibility.stanford.edu/pdf/p80-fogg.pdf",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-450537877:12,UX,UX,12,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-450537877,2,['UX'],['UX']
Usability,Resolves #5673 in the most simple way. cc @tpoterba you may have thoughts on this.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5674:27,simpl,simple,27,https://hail.is,https://github.com/hail-is/hail/pull/5674,1,['simpl'],['simple']
Usability,"Resolves issue #763.; ### Simple Types. The Function Registry distinguishes between fields and functions because they were distinguished in the existing `AST.scala`. Moreover, for unary functions, there are registration methods for both pure functions and computations in the `Option` monad. Registration requires only a name and an implementation. Unfortunately, the Scala compiler fails to infer the type parameters from an expression like `_.isHomRef`. . ``` scala; registerOptionField(""dosage"", { (x: Genotype) => x.dosage.map(a => a: IndexedSeq[Double]) }); registerField(""isHomRef"", { (x: Genotype) => x.isHomRef }); ```. ``` scala; register(""Variant"", { (x: String) =>; val Array(chr, pos, ref, alts) = x.split("":""); Variant(chr, pos.toInt, ref, alts.split("","")); }); register(""Variant"", { (x: String, y: Int, z: String, a: String) => Variant(x, y, z, a) }); ```. The `HailRep` type class associates Scala types with Hail expression types. For example, the function registry knows that `Variant` returns a `TVariant` because of this implicit:. ``` scala; implicit object variantHr extends HailRep[Variant] {; def typ = TVariant; }; ```; ### Polymorphic Types. I don't have an answer for the various kinds of polymorphism present in the Hail expression language. There is unbounded polymorphism:. ``` scala; case (t: TArray, ""length"") => TInt; ```. as well as bounded polymorphism:. ``` scala; case (""pow"", _) => TDouble; args.map(_.`type`) match {; case Array(a: TNumeric, b: TNumeric) => TDouble; // ...; }; ```. Both of these are still handled by explicit case matching.; ### Struct Types. Functions returning structs can use `registerAnn` to specifically provide a return type. ``` scala; registerAnn(""foo"", TStruct((""bar"", TDouble)), { (x: Int) => Annotation(x / 2.0) } ; ```. In general, the `register` `HailRep` implicits can be overridden as well, but this case is common enough to merit a concise alternative.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/807:26,Simpl,Simple,26,https://hail.is,https://github.com/hail-is/hail/pull/807,1,['Simpl'],['Simple']
Usability,"Revert ""[batch] Simplify iptables rules for worker network namespaces…",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11266:16,Simpl,Simplify,16,https://hail.is,https://github.com/hail-is/hail/pull/11266,1,['Simpl'],['Simplify']
Usability,"Revert ""[query] NDArray Reshape Simplification""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9877:32,Simpl,Simplification,32,https://hail.is,https://github.com/hail-is/hail/pull/9877,1,['Simpl'],['Simplification']
Usability,"Right now in master, the batch database gets cleared each time batch is deployed. Before we can remove this, we need to write all job task logs to GCS and insert the URI into the database. Otherwise, batch will try and read the logs for a previous job and not find them on the node.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5845:45,clear,cleared,45,https://hail.is,https://github.com/hail-is/hail/issues/5845,1,['clear'],['cleared']
Usability,"Right now it's not entirely clear what to do to ensure that a build works on the dataflow cluster, as well as to generate a set of benchmarks that capture a set of performance statistics well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/156:28,clear,clear,28,https://hail.is,https://github.com/hail-is/hail/issues/156,1,['clear'],['clear']
Usability,"Root cause found. Each time a batch test runs it generates a bunch of garbage because batch unsafely handles `cancel`. Here's the bad sequence:. - batch adds a job to `job_id_job`; - batch makes an HTTP request to k8s to create the pod, THREAD IS NOW PAUSED WAITING FOR RESULT; - flask handles a new request to cancel said job, tries to delete the pod; - [_delete_pod says: if `_pod_name` is `None`, don't do anything](https://github.com/hail-is/hail/blob/master/batch/batch/server/server.py#L83), so it does nothing but tells the client 200 OK!; - THREAD WAITING ON k8s WAKES UP: oh good, pod created. I think the fix is to check after pod creation if our state was set to canceled. If yes, delete said pod.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5168#issuecomment-456618542:251,PAUSE,PAUSED,251,https://hail.is,https://github.com/hail-is/hail/issues/5168#issuecomment-456618542,1,['PAUSE'],['PAUSED']
Usability,"Rs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1NDBhNTVlYS05Y2JkLTRlZWEtYmJmZi00ZWU2NjlhZWJmYWQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjU0MGE1NWVhLTljYmQtNGVlYS1iYmZmLTRlZTY2OWFlYmZhZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""540a55ea-9cbd-4eea-bbff-4ee669aebfad"",""prPublicId"":""540a55ea-9cbd-4eea-bbff-4ee669aebfad"",""dependencies"":[{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,509],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13516:4017,Learn,Learn,4017,https://hail.is,https://github.com/hail-is/hail/pull/13516,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"Rs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZWIyYjAwNS1lYjhhLTRiMzgtYjkwMS04YzRmNTY2OGM3ZDYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFlYjJiMDA1LWViOGEtNGIzOC1iOTAxLThjNGY1NjY4YzdkNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""aeb2b005-eb8a-4b38-b901-8c4f5668c7d6"",""prPublicId"":""aeb2b005-eb8a-4b38-b901-8c4f5668c7d6"",""dependencies"":[{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,509],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13517:3841,Learn,Learn,3841,https://hail.is,https://github.com/hail-is/hail/pull/13517,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"S V'_1` is a full SVD of `R` (which is small and easily computable), then `(U U_1[:, :k]) S[:k, :k] (V V_1[:, :k])'` is a reduced SVD of `A`. This is implemented in `KrylovFactorization.reduced_svd`. # Spectral moments; We can also easily compute estimates of spectral moments, i.e. moments of the set of all eigenvalues of `A'A`. The estimator exploits the following key facts:; * If `v` is a random vector of independent entries with mean 0, std. dev. 1 (equivalently `E(v) = 0`, `E(vv') = I`), then `E(v'Xv) = tr(X)`; * `tr(X)` equals the sum of the eigenvalues of `X`, `∑_i 𝜆_i`. More generally, if `f` is any matrix function, `tr(f(X)) = ∑_i f(𝜆_i)`.; * If `w` is a unit-norm vector, and `UR = AV` is the factorization `_krylov_factorization(A, w, p)`, then `w' f(A'A) w` is well-approximated by `w' f(VV'A'AVV') w = w'V f(R'U'UR) V'w = w'V f(R'R) V'w`, and is exact if `f` is a degree `2p+1` polynomial. Moreover, since `w` is the first column of `V`, i.e. `w = Ve_1`, the above further simplifies `w'V f(R'R) V'w = e'_1 f(R'R) e_1`. Finally, if `R = U_1 S V'_1` is an SVD, this reduces to `e'_1 f(R'R) e_1 = e'_1 f(V_1 S^2 V'_1) e_1 = e'_1 V_1 f(S^2) V'_1 e_1 = V_1[0, :] f(S^2) V_1[0, :]'`.; * The previous bullet has a block generalization. If `W` is an orthonormal matrix with `k` columns, and `UR = AV` is the factorization `_krylov_factorization(A, W, p)`, and `R = U_1 S V'_1` is an SVD, then `W' f(A'A) W` is well-approximated by `V_1[:k, :] f(S^2) V_1[:k, :]'`, and this is exact if `f` is a degree-p polynomial. We can combine the above into an estimator for the p-th spectral moment, `𝜇_p = ∑_i 𝜆_i^p`. We get an unbiased estimator by generating a random vector `v`, and using `E(v' (A'A)^p v) = tr((A'A)^p) = 𝜇_p`. The estimator can be computed exactly using the Krylov factorization as above, i.e. `v' (A'A)^p v = V_1[0, :] S^{2p} V_1[0, :]'`. But this estimator has large variance, so we can just average over many independent estimators. We combine `k` random vectors into a rando",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11045:1902,simpl,simplifies,1902,https://hail.is,https://github.com/hail-is/hail/pull/11045,1,['simpl'],['simplifies']
Usability,"SEC; ----. - Web Application Security, A Beginner's Guide https://www.amazon.com/Web-Application-Security-Beginners-Guide/dp/0071776168; - The Web Application Hacker's Handbook: Finding and Exploiting Security Flaws https://www.amazon.com/Web-Application-Hackers-Handbook-Exploiting/dp/1118026470; - http://cryto.net/~joepie91/blog/2016/06/13/stop-using-jwt-for-sessions/; - http://cryto.net/~joepie91/blog/2016/06/19/stop-using-jwt-for-sessions-part-2-why-your-solution-doesnt-work/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6720#issuecomment-514358731:52,Guid,Guide,52,https://hail.is,https://github.com/hail-is/hail/issues/6720#issuecomment-514358731,2,['Guid'],['Guide']
Usability,"Scala's reflective access warning refers to referencing a member of an anonymous class that is not also a member of the implemented int.rface / super-class. Because there is no concrete, non-anonymous type that contains that member, there is no normal means to access / call that member. Scala hacks around this issue by inserting a use of Java's reflection library to look up the member at run-time. The solution is simple: make the class named / non-anonymous/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3624:417,simpl,simple,417,https://hail.is,https://github.com/hail-is/hail/pull/3624,1,['simpl'],['simple']
Usability,"Screenshots should give the main overview of the changes; Questions for reviewers. Technical:; - [X] Are there any CSS conventions within Hail? I assume I need to migrate the ad-hoc ""style"" tags into CSS?; - [X] There still seems to be a bunch of unused space after truncated batch names. I'm not sure why. UX:; - [x] I've moved the status indicator to the front of the line. Is that ok?; - to help with layout within the batch-name box; - to put it in a reliable place (ie not moving around based on how long the name is); - [x] I'm not really sure I like the change to Pending. Curious for others' thoughts. #### Example: Batches page; (layout and columns). ##### Before:; <img width=""1735"" alt=""image"" src=""https://github.com/user-attachments/assets/c2966f9a-1802-479f-8fb4-3882a4552fad"">. ##### After:; <img width=""1748"" alt=""image"" src=""https://github.com/user-attachments/assets/4a6a5c5a-23a5-42a4-bc8e-6624f83880fa"">. #### Example: Batch Details page; (Renaming confusing 'Pending' field). ##### Before:; <img width=""1044"" alt=""image"" src=""https://github.com/user-attachments/assets/ebb3eb52-69d7-44ba-a2c5-f0f219a0b5bb"">. ##### After:; <img width=""1059"" alt=""image"" src=""https://github.com/user-attachments/assets/6fa01eae-567d-49e5-a59e-768bf936a1b1"">. Fixes #14628. Adds and shuffles content on the new Batches table",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14640:307,UX,UX,307,https://hail.is,https://github.com/hail-is/hail/pull/14640,1,['UX'],['UX']
Usability,See attached log. Error not clear:. `[Stage 0:==========> (596 + 168) / 2836]hail: write: caught exception: Job aborted.`. [hail.log.txt](https://github.com/broadinstitute/hail/files/269500/hail.log.txt),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/391:28,clear,clear,28,https://hail.is,https://github.com/hail-is/hail/issues/391,1,['clear'],['clear']
Usability,"See each message below. ---. [[query/vds] Fix local_to_global with missing fill](https://github.com/hail-is/hail/pull/13325/commits/7d84189ca1a1b9460f4e0c96821cd43b8b0068fa) ; ; There was a logic error in constructFromIndicesUnsafe, if a missing; value was pushed, pushing a present value with the same index would not; clear the missing bit. ---. [[batch/test] Wait for job to be running in list_jobs_v2 test](https://github.com/hail-is/hail/pull/13325/commits/724da249255c06ea4ed1816704e4de51bd8f9b89). ---. [[qob] halve the number of active tests](https://github.com/hail-is/hail/pull/13325/commits/c2638702325526b29bebd416fceeedea52d42245). ---. [[batch] Turn off oms_agent in test and dev](https://github.com/hail-is/hail/pull/13325/commits/bbd65e4f66d41ef69c130091b0506087975c4851). ---",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13325:320,clear,clear,320,https://hail.is,https://github.com/hail-is/hail/pull/13325,1,['clear'],['clear']
Usability,"See the FAQ Style Guide. **Annotations**; - [ ] Do I need to define the types when using `annotatesamples table`?; - [ ] How does Hail annotate variants overlapping different intervals in an interval list?; - [ ] How do I input phenotype information into Hail?; - [ ] Is there a way to see all annotations present in the dataset?. **Expression Language**; - [ ] Can I use regular expressions in the Hail expression language?; - [ ] how can i filter samples based on whether or not they have a particular variant?. **Data Representation**; - [ ] How are insertion and deletion variants coded in the VDS?; - [ ] How are the boundaries for Pseudo-autosomal variants determined?. **Exporting Data**; - [ ] How can I export all global annotations to a file?; - [ ] How do I export my data so there are separate VCFs per chromosome?; - [ ] How do I export my annotations as a JSON file?; - [ ] How do I export updated call statistics (AC, AF) to the info field of the VCF?. **Developer Tools**; - [ ] Is there a style guide I should use for IntelliJ?. **Importing Data**; - [ ] How do I import data from a VCF file?; - [ ] How do I import annotations in JSON format?; - [ ] Is the UCSC file 0 or 1 based?. **Methods**; - [ ] Does Hail handle sex chromosomes differently in variantqc and sampleqc?; - [ ] How do I parse the variant annotations from VEP to find the worst functional consequence?; - [ ] How do I find all variants where the functional change on the canonical transcript results in a missense mutation?; - [ ] Is rHetHom calculated over indels+SNPs or just SNPs?; - [ ] Are sampleqc and variantqc calculated only on PASS variants?. **Optimize Pipeline**; - [ ] When should I write my data to a VDS file?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/812:18,Guid,Guide,18,https://hail.is,https://github.com/hail-is/hail/issues/812,2,"['Guid', 'guid']","['Guide', 'guide']"
Usability,"Seeing if this passes tests. If so, it's a bit simpler",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8105:47,simpl,simpler,47,https://hail.is,https://github.com/hail-is/hail/pull/8105,1,['simpl'],['simpler']
Usability,"Seems to average 60MB/s. No clear culprits. Zstd decoding is the top hit right now. The hottest generated code is inplace decoding of an optional array of optional int32. Really sucks because things like `LA` are somehow getting written as element optional, even though, by construction their elements are not optional. ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:; +EArray[EBaseStruct{; LA:EArray[EInt32]; ,LGT:EInt32; ,LAD:EArray[EInt32]; ,LPGT:EInt32; ,LPL:EArray[EInt32]; ,RGQ:EInt32,; gvcf_info: EBaseStruct{; AC:EArray[EInt32]; ,AF:EArray[EFloat64]; ,AN:EInt32,AS_BaseQRankSum:EArray[EFloat64]; ,AS_FS:EArray[EFloat64]; ,AS_InbreedingCoeff:EArray[EFloat64]; ,AS_MQ:EArray[EFloat64]; ,AS_MQRankSum:EArray[EFloat64]; ,AS_QD:EArray[EFloat64]; ,AS_QUALapprox:EArray[EInt32]; ,AS_RAW_BaseQRankSum:EBinary,AS_RAW_MQ:EArray[EFloat64]; ,AS_RAW_MQRankSum:EArray[EBaseStruct{`0`:EFloat64,`1`:EInt32}]; ,AS_RAW_ReadPosRankSum:EArray[EBaseStruct{`0`:EFloat64,`1`:EInt32}]; ,AS_ReadPosRankSum:EArray[EFloat64]; ,AS_SB_TABLE:EArray[EArray[EInt32]]; ,AS_SOR:EArray[EFloat64]; ,AS_VarDP:EArray[EInt32]; ,BaseQRankSum:EFloat64,ExcessHet:EFloat64,FS:EFloat64,InbreedingCoeff:EFloat64,MQ:EFloat64,MQRankSum:EFloat64,MQ_DP:EInt32,QD:EFloat64,QUALapprox:EInt32,RAW_GT_COUNT:EArray[EInt32]; ,RAW_MQandDP:EArray[EInt32]; ,ReadPosRankSum:EFloat64,SOR:EFloat64,VarDP:EInt32}; ,DP:EInt32; ,GQ:EInt32; ,MIN_DP:EInt32; ,PID:EBinary; ,PS:EInt32; ,SB:EArray[EInt32]; }; ]; }; ```. Async profiler periodic sampling:; <img width=""2032"" alt=""Screenshot 2023-10-10 at 18 06 38"" src=""https://github.com/hail-is/hail/assets/106194/ee5df1c7-9c4a-4a4c-9ff4-caf599f1883b"">; <img width=""517"" alt=""Screenshot 2023-10-10 at 18 07 10"" src=""https://github.com/hail-is/hail/assets/106194/2bb5ba37-dab4-4b29-bb03-6cc2b08dafb9"">; Sync profiler (note safe point bias); <img width=""2032"" alt=""Screenshot 2023-10-10 at 18 32 14"" src=""https://github.com/hail-is/hail/assets/106194/85f1c1b6-3ac1-4b87-9e32-e6abdd02bb49"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13787#issuecomment-1756358633:28,clear,clear,28,https://hail.is,https://github.com/hail-is/hail/pull/13787#issuecomment-1756358633,2,['clear'],['clear']
Usability,Segfault and incorrect results for simple aggregation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8076:35,simpl,simple,35,https://hail.is,https://github.com/hail-is/hail/issues/8076,2,['simpl'],['simple']
Usability,"Should be good to go. There were two problems:. I needed to make the encoder/decoder `@transient lazy`. The encoder/decoder call generated code but can't be serialized. The make functions handle serialization and loading of the generated code. Also, RegionValueAggregators used in scans can have result called multiple times, so I needed to add a MemoryBuffer.clearPos.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5414#issuecomment-466625216:360,clear,clearPos,360,https://hail.is,https://github.com/hail-is/hail/pull/5414#issuecomment-466625216,2,['clear'],['clearPos']
Usability,"Should be pretty clear what I'm doing, but let me know if you want me to walk through the design process here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10628#issuecomment-880902195:17,clear,clear,17,https://hail.is,https://github.com/hail-is/hail/pull/10628#issuecomment-880902195,2,['clear'],['clear']
Usability,"Should be simple, run this library on logs before serving them:. https://github.com/ralphbean/ansi2html",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7400:10,simpl,simple,10,https://hail.is,https://github.com/hail-is/hail/issues/7400,1,['simpl'],['simple']
Usability,Should have been clear about that though!!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3004#issuecomment-369286513:17,clear,clear,17,https://hail.is,https://github.com/hail-is/hail/pull/3004#issuecomment-369286513,2,['clear'],['clear']
Usability,"Simple replication:; ```. In [6]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14051#issuecomment-1834356993:0,Simpl,Simple,0,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834356993,1,['Simpl'],['Simple']
Usability,"Simple reproduction:. ```python; In [1]: import hail as hl . In [2]: t = hl.nd.array([[1,2,3,4], [1,2,3,4]]) . In [3]: hl.eval(t[0:1000,1000]) ; Out[3]: array([32756, 32756], dtype=int32); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9144#issuecomment-669592521:0,Simpl,Simple,0,https://hail.is,https://github.com/hail-is/hail/issues/9144#issuecomment-669592521,1,['Simpl'],['Simple']
Usability,Simpler and more ergonomic!,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9981:0,Simpl,Simpler,0,https://hail.is,https://github.com/hail-is/hail/pull/9981,1,['Simpl'],['Simpler']
Usability,Simplifed RegUtils and retrofit to 0.1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1863:0,Simpl,Simplifed,0,https://hail.is,https://github.com/hail-is/hail/pull/1863,1,['Simpl'],['Simplifed']
Usability,"Simplified `NDArrayRef` considerably by switching to `CodeBuilder` interface, adding `EmitCode.mapN`, and adding `PNDArrayCode`. . Thanks @patrick-schultz for contributing code for `EmitCode.mapN`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8568:0,Simpl,Simplified,0,https://hail.is,https://github.com/hail-is/hail/pull/8568,1,['Simpl'],['Simplified']
Usability,Simplified the dev deploy interface: just specify fully qualified branch (user/repo:branch) and a list of steps (instead of profile) which are transitively closed over dependencies. Pick up namespace from the user database.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6915:0,Simpl,Simplified,0,https://hail.is,https://github.com/hail-is/hail/pull/6915,1,['Simpl'],['Simplified']
Usability,"Simplified, increased contrast of link styling.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/651:0,Simpl,Simplified,0,https://hail.is,https://github.com/hail-is/hail/pull/651,1,['Simpl'],['Simplified']
Usability,Simplify BM.write_from_entry_expr,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3981:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/3981,1,['Simpl'],['Simplify']
Usability,Simplify Concordance,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3987:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/3987,1,['Simpl'],['Simplify']
Usability,Simplify GeneralRDD,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3443:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/3443,1,['Simpl'],['Simplify']
Usability,Simplify IBD,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3983:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/3983,1,['Simpl'],['Simplify']
Usability,Simplify LD prune schema,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3980:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/3980,1,['Simpl'],['Simplify']
Usability,Simplify RichRDDByteArray,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2265:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/2265,1,['Simpl'],['Simplify']
Usability,Simplify boolean equality comparisons,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5010:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/5010,1,['Simpl'],['Simplify']
Usability,Simplify fix,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4564:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/4564,1,['Simpl'],['Simplify']
Usability,Simplify ld_prune tie breaker,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5079:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/5079,1,['Simpl'],['Simplify']
Usability,Simplify literal nodes of primitive types or missing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5141:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/5141,1,['Simpl'],['Simplify']
Usability,Simplify nested TableMapRows,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5259:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/5259,1,['Simpl'],['Simplify']
Usability,Simplify read logic,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2358:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/2358,1,['Simpl'],['Simplify']
Usability,Simplify the read logic by no longer reading multiple files at once. This functionality is preserved in the newly-added union function.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2358:0,Simpl,Simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/2358,1,['Simpl'],['Simplify']
Usability,Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.is$hail$expr$ir$Optimize$$runOpt$1(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply$mcV$sp(Optimize.scala:25); at i,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:11369,Simpl,Simplify,11369,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30);,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:9406,Simpl,Simplify,9406,https://hail.is,https://github.com/hail-is/hail/issues/8338,2,['Simpl'],['Simplify']
Usability,Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10374,Simpl,Simplify,10374,https://hail.is,https://github.com/hail-is/hail/issues/8338,2,['Simpl'],['Simplify']
Usability,Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30);,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8438,Simpl,Simplify,8438,https://hail.is,https://github.com/hail-is/hail/issues/8338,2,['Simpl'],['Simplify']
Usability,Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.is$hail$expr$ir$Optimize$$runOpt$1(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply$mcV$sp(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.expr.ir.Optimize$$anonfun$apply$,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:11454,Simpl,Simplify,11454,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyValue']"
Usability,"Simply adds a /user page. Assigned to dan, but he's sick, should I assign someone else?. cc @cseed, @danking @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5752:0,Simpl,Simply,0,https://hail.is,https://github.com/hail-is/hail/pull/5752,1,['Simpl'],['Simply']
Usability,"Simply enables CORS from all domains. This would be insecure, but our endpoints are read-only operations on public GitHub resources, against a fixed list of users, there is no database to inject, and there are no cookies or local storage entries to steal. I think it's safe enough for the time being, but open to suggestions. Also expose /json endpoint to return all index.html data without rendering a page.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4945:0,Simpl,Simply,0,https://hail.is,https://github.com/hail-is/hail/pull/4945,2,['Simpl'],['Simply']
Usability,"Slightly tweak the `Bindings` class to store a single array of (name, type) pairs, with the various environments referring back to that array. This simplifies passes that want to create a single mutable state for each binding, even those that are bound in multiple environments (e.g. eval and agg).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14517:148,simpl,simplifies,148,https://hail.is,https://github.com/hail-is/hail/pull/14517,1,['simpl'],['simplifies']
Usability,"Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""92bcf51f-c710-4a85-9af1-5ae170a8797a"",""prPublicId"":""92bcf51f-c710-4a85-9af1-5ae170a8797a"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.5""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13938:10067,Learn,Learn,10067,https://hail.is,https://github.com/hail-is/hail/pull/13938,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"So I did some simple formatting on the ""Filter loci by a list of locus intervals"" example. . The cloud sphinx theme you mentioned on zulip has toggleable sections that look a bit nicer. I could emulate that formatting by writing a sphinx extension if we wanted to get fancier, but what do you think of this layout?. IMAGE 1. <img width=""720"" alt=""screen shot 2018-08-22 at 11 23 34 am"" src=""https://user-images.githubusercontent.com/35241112/44473344-1eb11c80-a5fe-11e8-954d-41440a031d24.png"">. IMAGE 2; clicking on `show` would expose more content:. <img width=""699"" alt=""screen shot 2018-08-22 at 11 23 46 am"" src=""https://user-images.githubusercontent.com/35241112/44473350-2375d080-a5fe-11e8-98e9-31f1c3bb825c.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4089#issuecomment-415074240:14,simpl,simple,14,https://hail.is,https://github.com/hail-is/hail/pull/4089#issuecomment-415074240,2,['simpl'],['simple']
Usability,"So I think I'd appreciate a review on this. Would especially appreciate feedback about the question I wrote in the PR body as well as what to do about documentation and testing:. - We have pretty expansive FS testing, but not for these new shim functions. Should we convert some of our tests to use these functions instead of the FS objects themselves?; - We don't have `hailtop` docs, and afaik this is the first module outside of `hailtop.batch` that would be public. Where should its docs go?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12731#issuecomment-1499652542:72,feedback,feedback,72,https://hail.is,https://github.com/hail-is/hail/pull/12731#issuecomment-1499652542,2,['feedback'],['feedback']
Usability,"So I think the root issue here is the unnecessary duplication between `pyRegisterIR` and `pyRegisterIRForServiceBackend`. The only real difference is that one takes and already parsed IR, and the other takes a string and calls the parser. The callers of `pyRegisterIR` in python all call into the parser first, but I don't see any reason it has to make two calls across the python/scala bridge; I think `pyRegisterIR` should just take the IR as a string and call the parser like `pyRegisterIRForServiceBackend` does. With that change, it should be possible to make one a simple wrapper around the other (or maybe even get rid of `pyRegisterIRForServiceBackend` completely). That way the core logic is shared between backends and is getting tested. Let me know if you want help with this, or if you'd like me to make a separate PR for this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14579#issuecomment-2174358685:571,simpl,simple,571,https://hail.is,https://github.com/hail-is/hail/pull/14579#issuecomment-2174358685,2,['simpl'],['simple']
Usability,"So my reading now of `seed` is that it uniquely identifies a sequence of numbers. I read the docs now, and I'm not sure I agree with these sentences:; > The values are seeded when the function is called, so calling a random Hail function and then using it several times in the same expression will yield the same result each time.; > ; > Evaluating the same expression will yield the same value every time, but multiple calls of the same function will have different results. I think the trouble is with the meaning of ""called"", ""using"", and ""evaluating"". I see now that you mean calling the python function by ""called"", but that wasn't clear to me on first reading. ""Using"" I think just means appearing in the source code, which feels right. The last sentence, I think, is not true, given the below:. ```python; In [31]: z = hl.rand_unif(0, 1, seed=0); ...: ; ...: t = hl.utils.range_table(2); ...: t = t.annotate(; ...: x = hl.literal([1,2,3]).map(lambda i: hl.rand_unif(0,1,seed=0)),; ...: y = hl.literal([1,2,3]).map(lambda i: hl.rand_unif(0,1,seed=0)),; ...: z = hl.literal([1,2,3]).map(lambda i: z)); ...: ; ...: t.show(); ```. I think I really prefer the `[z,z]` means two draws. If you want one draw, you gotta use a let or `annotate_globals` or something.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4166#issuecomment-415835792:637,clear,clear,637,https://hail.is,https://github.com/hail-is/hail/pull/4166#issuecomment-415835792,2,['clear'],['clear']
Usability,"So this PR is mostly Patrick ripping out `RegionValues` in a lot of places in favor of just using a `Long`. I think this is useful because it simplifies the memory management situation by ensuring that the only regions to worry about at a particular `TableIR.execute` are the one on the `RegionContext` and any regions created in that `execute`. . One exception to this is that currently we have methods `toCRDDRegionValue` and `toCRDDPtr` to switch back to a `RegionValue` based CRDD for compatibility with all the join stuff (really, anything that uses `OrderedRVIterator`). In addition, this PR goes through and tries to systematically fix places where we were not manging regions correctly. This makes it somewhat subtle and hard to review. Some things I'd focus on are: . - Anywhere a boundary was removed.; - `TableKeyByAndAggregate` and `TableAggregateByKey` (noted below. I haven't done anything aggregator related prior to this, don't fully understand them); - Spot check of any of the places I listed under ""Addressed"" below.; - The implementations of `toCRDDRegionValue` and `toCRDDPtr`. . Addressed:. ```; - TableFilter; - TableSubset (just the parent of head and tail); - TableHead (via rvd.head); - TableTail (via rvd.tail); - TableExplode; - LinearRegression; ```. No change needed:. ```; - TableMapGlobals; - TableRange; - TableLiteral; - TableOrderBy; - TableDistinct; - TableKeyBy; - TableRename; - TableUnion; - TableParallelize; - TableRead; ```. Didn't / Minimally Changed, but wasn't really sure about:. ```; - TableAggregateByKey; - TableKeyByAndAggregate; - TableMapRows (specifically, the bit about computing `scanPartitionAggs); ```. cc @patrick-schultz @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8315:142,simpl,simplifies,142,https://hail.is,https://github.com/hail-is/hail/pull/8315,1,['simpl'],['simplifies']
Usability,"So what I did to address the comments:; 1. I encoded the task names and the offsets of the data into the response from the worker to the front end and got rid of the MultiPart Reader/Writer.; 2. I reorganized the front end code so it's hopefully clearer what's going on.; 3. I got rid of the periodically_call changes and just did what I wanted directly in the `measure` function in the Resource Manager. Now it should be guaranteed that we do not call the measure function with the write more than once every 5 seconds. I do not want to retry calling this function at all on any error including transient errors. Otherwise, I can't figure out how the set of changes in this PR would use up all the disk space.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11750#issuecomment-1137707785:246,clear,clearer,246,https://hail.is,https://github.com/hail-is/hail/pull/11750#issuecomment-1137707785,2,['clear'],['clearer']
Usability,"So ya this is what was giving me pause so would appreciate your take. I threw WIP on so I can make sure it's properly tested before it merges. Here are my thoughts:; - I can manually exercise all the commands easily enough. Flexing all the options is harder, but I can compare the help for each command. The fact that these files are all lint-free and typecheck gives me confidence I did have before.; - I'm not worried about breaking dev stuff. Basically the only thing I am worried about breaking is the dataproc group.; - I was planning on running the test dataproc scripts prior to removing the WIP, which is something, but obviously does not test all the options. I think it would be nice to get a close review for dataproc start/submit (the biggest ones that people rely on the most) and everything else can be at whatever granularity you feel comfortable with.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13109#issuecomment-1570824362:33,pause,pause,33,https://hail.is,https://github.com/hail-is/hail/pull/13109#issuecomment-1570824362,2,['pause'],['pause']
Usability,"So, here's a profile of the no-leb dataset. I applied all the simple tricks I could think of. We memcpy runs of present ints or floats in arrays. Patrick's improvements. A few other little cleanups. Read bandwidth with one core is ~60MB/s (of uncompressed bytes). Zstd is getting ~28% of our core. A comment from 2019 claimed [200 MB/s](https://github.com/luben/zstd-jni/issues/94#issuecomment-471114842) from the Zstd JNI library we're using. That roughly tracks (0.28 * 200 = 56). The native C library, on a 400MB/s link (roughly my SSD's link) claims closer to 1000 MB/s (of uncompressed bytes) (see [my sheet](https://docs.google.com/spreadsheets/d/1uDYfXWDIwt_-XiclFWdLDiXamVbxhswt_D-v8fVrlRU/edit#gid=0)). I suspect we need either different on-disk formats, different in-memory formats, or vectorized storage to substantially improve the speed. Reading all these tiny arrays is unfortunately really branchy. If we had a PType and EType for arrays that was memcpy-able, that might give us a big win? In particular, suppose we could determine the bytesize of a nested structure including arrays. We write that size into the stream, then write all the bytes. Decoding is: read size, read that many bytes, done. <img width=""1545"" alt=""Screenshot 2023-10-11 at 16 36 27"" src=""https://github.com/hail-is/hail/assets/106194/afaeeacc-ab07-4e2c-9638-8d007276333d"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13792#issuecomment-1758518398:62,simpl,simple,62,https://hail.is,https://github.com/hail-is/hail/issues/13792#issuecomment-1758518398,2,['simpl'],['simple']
Usability,"So, something weird is going on that I don't understand, and we should probably hold off on merging this for now. When I emit the stream code directly, bypassing the compiler, the new reducible version is clearly faster: running; ```scala; val f = compile1[Int, Unit] { (mb, n) =>; val outer = Stream.range(mb, 0, 1, n); val flatMap = outer.flatMap(i => Stream.range(mb, 0, 1, i)); flatMap.forEach(mb, i => Code._empty); }; val n = 50000; var t = System.nanoTime(); f(n); println(s""first run: ${(System.nanoTime() - t) / 1000000} ms""); for (i <- 1 to 10) { f(n) }; t = System.nanoTime(); for (i <- 1 to 50) { f(n) }; println(s""warmed up mean: ${(System.nanoTime() - t) / (1000000 * 50)} ms""); ```; on main prints; ```; first run: 2088 ms; warmed up mean: 1972 ms; ```; and on this PR; ```; first run: 867 ms; warmed up mean: 937 ms; ```; (As an aside, the lack of burn in is interesting. I think it means either the function is never getting jit compiled, or OSR kicks in on the first run and is as effective as full compilation.). On the other hand, running the benchmark; ```scala; ht = hl.utils.range_table(30); ht = ht.annotate(sum=hl.sum(hl.range(5_000).flatmap(lambda x: hl.range(x)))); ht._force_count(); ```; I get; ```; > hail-bench compare main-bench.json branch-bench.json; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; table_annotate_flatMap 371.8% 0.795 2.958; ```. I'm currently at a loss for theories to explain this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9429#issuecomment-690420227:205,clear,clearly,205,https://hail.is,https://github.com/hail-is/hail/pull/9429#issuecomment-690420227,2,['clear'],['clearly']
Usability,"So.... this is technically working, but I'm not very happy with how difficult the logic is to parse through. I'm going to work at tidying it up into a more readable format but would love feedback on how to do that. cc @tpoterba @cseed @patrick-schultz",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6727#issuecomment-516096236:187,feedback,feedback,187,https://hail.is,https://github.com/hail-is/hail/pull/6727#issuecomment-516096236,2,['feedback'],['feedback']
Usability,"Some initial thoughts:; * I'm not sure we should have implicitly broadcasting operations in the IR. It seems simpler to make broadcast an explicit operation, which we make sure to deforest. In fact, broadcast is a special case of the generic tensor index operation I'll describe below. Implicitly broadcasting operations could be provided in the Python interface, making broadcasts explicit when constructing the IR.; * I'm also not sure how much special treatment we should give to block matrices in the IR. I now like to think of block matrices as just 4-tensors, with matrix operations like matrix multiplication lowering to operations on 4-tensors. If we allow tensors to have some distributed dimensions and some ""small"" dimensions, then at least in the backend we might not need special handling of block structures. It may still be helpful to have a special block matrix/tensor representation at the top level IR, or maybe that should only live in Python—I'm not sure. Here's a proposal for a set of primitive tensor operations. * Outer product: Takes two tensors, T1 and T2, with shapes [n1, ..., ni] and [m1, ..., mj], and entry types t1 and t2, and makes a tensor Out with shape [n1, ..., ni, m1, ..., mj] and entry type (t1, t2). If we want to support sparse tensors, this should take a flag specifying how the sparse structure of the output is determined from those of the inputs. I'll call the possible flags ""and"", ""or"", and ""true"". The ""and"" flag says that Out(n, m) is defined iff T1(n) AND T2(m) are both defined. If we will be multiplying the pairs, or applying any other operation with our default missingness semantics, this is the appropriate setting.; The ""or"" flag says Out(n, m) is defined iff T1(n) OR T2(m) is defined, as is appropriate if we are adding the pairs.; ""true"" just means make Out dense, regardless of the sparsity of the inputs. * Map. I don't think there's much to say here. * Generic index operations (not sure what to call these). I'll first give some example",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5190#issuecomment-457598772:109,simpl,simpler,109,https://hail.is,https://github.com/hail-is/hail/pull/5190#issuecomment-457598772,2,['simpl'],['simpler']
Usability,"Some useful reading:; - [Phantom References in Java Reference Objects](http://www.kdgregory.com/index.php?page=java.refobj#PhantomReferences); - [java.lang.ref](https://docs.oracle.com/javase/8/docs/api/java/lang/ref/package-summary.html#reachability); - [java.lang.ref.PhantomReference](https://docs.oracle.com/javase/8/docs/api/java/lang/ref/PhantomReference.html). The structure is now this:; - `RegionPool` becomes `RegionPoolNativeMemoryOwner`; - a new `RegionPool` class is simply a (unique) reference to a `RegionPoolNativeMemoryOwner`; - `RegionPoolNativeMemoryFreer` is a `PhantomReference` to `RegionPool`; - There is just one instance of all three classes in memory at any given time.; - A single thread is blocking on the reference queue waiting for something to free. How it works:; - The reachability of `RegionPool` defines the reachability the native memory.; - When the `RegionPool` becomes unreachable, the JVM places the corresponding `RegionPoolNativeMemoryFreer` on its reference queue.; - The `cleaner` thread removes the phantom reference from the queue; - At this point, the `RegionPool` is effectively gone, there are no references to it anywhere. Because of that fact, the `RegionPoolNativeMemoryFreer` can free all the native memory by calling `RegionPoolNativeMemoryOwner.free`.; - The `cleaner` thread removes the `RegionPoolNativeMemoryFreer` from the `refs` set which allows the `RegionPoolNativeMemoryFreer` itself to be GC'ed. We do leak the cleaner thread. It will live for the entirety of the JVM process, which seems fine since once you start Hail, you probably want to keep using Hail. I can't find a reference for this, but I'm fairly certain you need to prevent the PhantomReference itself from being GC'ed. That's why I have that set of refs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8203:480,simpl,simply,480,https://hail.is,https://github.com/hail-is/hail/pull/8203,1,['simpl'],['simply']
Usability,Somewhat surprising that no one has written a shade plugin that renames SO symbols 🤷 . That's clearly the correct answer here.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8576#issuecomment-616208715:94,clear,clearly,94,https://hail.is,https://github.com/hail-is/hail/pull/8576#issuecomment-616208715,2,['clear'],['clearly']
Usability,"Sorry I didn't get to this, Nik! I've been trying to think if we should revisit our experimental module guidelines in light of the questions we're getting on Zulip, but I think things are probably fine.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8265#issuecomment-600357758:104,guid,guidelines,104,https://hail.is,https://github.com/hail-is/hail/pull/8265#issuecomment-600357758,2,['guid'],['guidelines']
Usability,"Sorry about this! Will do!. On Tue, Mar 7, 2017 at 13:36 Tim Poterba <notifications@github.com> wrote:. > I just noticed that the spacing doesn't follow the style guide. Not; > critical, but try to autoformat before PRing; >; >; >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/1494#issuecomment-284814488>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/ADVxgc012iIeaevvZPZfYZuXXj1nuiE2ks5rjaOQgaJpZM4MVwyK>; > .; >; >; >; >; >; >; >; >; >; >; >; >; >; >; >; >; >; >; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1494#issuecomment-284817572:163,guid,guide,163,https://hail.is,https://github.com/hail-is/hail/pull/1494#issuecomment-284817572,2,['guid'],['guide']
Usability,"Sorry to drop another big one on you, Chris, but you have the context for this. . The big diff doesn't reflect the size of the conceptual change here. This PR does as follows:; * Breaks up and moves CodeOrdering to its own package under `ir`. ; * Changes all CodeOrdering factories to take STypes instead of PTypes; * Removes some factory methods, like `pType.codeOrdering`.; * There are now two places to construct orderings: `EmitClassBuilder.getOrderingFunction` (which takes stypes and an `Op`), and `CodeOrdering.makeOrdering`.; * I slightly changed the method layout to memoize within each ordering. We check the types on each method call.; * There are only a couple meaningful changes in the typed ordering generators. I changed CallOrdering and StringOrdering a bit to more clearly describe what they're doing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10091#issuecomment-784737260:782,clear,clearly,782,https://hail.is,https://github.com/hail-is/hail/pull/10091#issuecomment-784737260,2,['clear'],['clearly']
Usability,"Sorry will fix this, trying to break up the larger PR clearly failed. One min.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7599#issuecomment-557715665:54,clear,clearly,54,https://hail.is,https://github.com/hail-is/hail/pull/7599#issuecomment-557715665,2,['clear'],['clearly']
Usability,"Sorry, I should have been clearer. I think the first line shouldn't have any ""#""s and for the following lines, ""###"" is fine.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2256#issuecomment-332298462:26,clear,clearer,26,https://hail.is,https://github.com/hail-is/hail/pull/2256#issuecomment-332298462,2,['clear'],['clearer']
Usability,"Sorry, I wasn't clear before. The Batch LD Clumping example does not require Hail Query (and, more importantly, a JVM) to be installed on *the computer that submits the batch*. Hail is imported and used inside of the Batch task that performs GWAS. That task runs inside a Docker container that has Hail installed (its derived from `hailgenetics/hail`). I'm hesitant to make the *submission* of a batch dependent on the Hail Query library. Particularly when we have relatively low-effort alternative approaches. I'm delighted any time I see batch tasks use Hail Query! Konrad's Pan UKB work also does this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9194#issuecomment-671357400:16,clear,clear,16,https://hail.is,https://github.com/hail-is/hail/pull/9194#issuecomment-671357400,2,['clear'],['clear']
Usability,"Sorry, I've been on my honeymoon and just got back. I resume work on this in the new year. Apologies for the delay.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1866888177:54,resume,resume,54,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1866888177,2,['resume'],['resume']
Usability,"Sounds good Dan, and agreed it's a long term issue. Regarding point 2, I also don't really like the idea of non-preemtible nodes from a resource utilization standpoint. I think we could probably write our own peak load predictor, or use one of the existing tools, outside of the kube ecosystem. There has been some interesting work using some relatively simple learning models to predict load. It would be interesting to use an RNN for this, but linear regression seems to work pretty well. This could be an interesting topic to investigate. https://medium.com/netflix-techblog/scryer-netflixs-predictive-auto-scaling-engine-part-2-bb9c4f9b9385",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5269#issuecomment-461549683:354,simpl,simple,354,https://hail.is,https://github.com/hail-is/hail/issues/5269#issuecomment-461549683,4,"['learn', 'simpl']","['learning', 'simple']"
Usability,"Sounds good. Thanks for the feedback. If it requires a significant effort to modify the code base to remove this behavior or if the change is not desired, it may be worth including a warning/info section describing this behavior in the documentation.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14004#issuecomment-1813182236:28,feedback,feedback,28,https://hail.is,https://github.com/hail-is/hail/issues/14004#issuecomment-1813182236,2,['feedback'],['feedback']
Usability,"Spark depends on a very old verison of SLF4J. We cannot upgrade. We added this dependency ages ago to fix some undocumented issue with logging and SLF4J. It seems reasonable to me that we should just accept whatever version of SLF4J that Spark provides. This removes this message:; ```; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; ```. Which, IMO, really should be a stop-the-world error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14055:111,undo,undocumented,111,https://hail.is,https://github.com/hail-is/hail/pull/14055,1,['undo'],['undocumented']
Usability,"Stacked on #2466 . 1. Not sure when region value builders should be cleared. I put them in this PR. If they are needed, then a `clear()` needs to be added to `VariantSampleMatrix.join`. 2. `coalesce` is giving me a different number of partitions for OrderedRDD2 compared to OrderedRDD for the test of identical variants. I think it's because the function `calculateKeyRanges` is different between the two. 3. I know I should incorporate the RegionValueVariant and clean up my BitPackedVectorView, but I wanted to have something that's stable so Genotype can be ripped out.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2467:68,clear,cleared,68,https://hail.is,https://github.com/hail-is/hail/pull/2467,2,['clear'],"['clear', 'cleared']"
Usability,"Stacked on #7000. Adds a new IR renderer in Python which integrates a CSE pass. It would be easy to argue that a CSE pass should be separate from the renderer. But we can't easily make the Python IR mutable, because a given IR tree might be used in multiple larger IR (which is exactly what this pass is taking advantage of!) so mutation which depends on the larger context won't work. So rather than rebuild the entire IR every time we print, I decided for now this is best integrated into the renderer. I think longer term this should be ported to scala as a full CSE pass (which first does hash-consing/value-numbering to find all repeated subexpressions). This is not a simple algorithm, but I did my best to make it understandable. If anything feels harder to follow than it should be, I'd like to try to improve it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7009:674,simpl,simple,674,https://hail.is,https://github.com/hail-is/hail/pull/7009,1,['simpl'],['simple']
Usability,"Stacked on #8283. This is WIP that converts the `ContextRDD` in `RVD` to a `ContextRDD[Long]`. This clarifies the region ownership semantics. Before, it wasn't clear what relation there was between the context region and the `RegionValue` region.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8290:160,clear,clear,160,https://hail.is,https://github.com/hail-is/hail/pull/8290,1,['clear'],['clear']
Usability,"Stacked on #9400 . This PR modifies stream consumers' emit cases to look up `separateRegions` on the child stream's type, using that to construct the appropriate `StagedRegion`, then passing that region into `emitStream`. It also removes `EmitAllocationStrategy`, as this is now encoded in the IR. We may at some point want something similar to choose what allocation behavior to generate during lowering, but that is left for future work. Getting this to work well required some changes to the `StagedRegion` design. First, when a stream node needs to create a fresh region which it owns, the new region is now created as a child of the `outerRegion`, not the consumer's `eltRegion` as was done before. This simplifies the semantics of the parent/child relationship: now the lifetime of a child region is always nested inside that of its parent. The second change also has to do with the tree structure of `StagedRegion`s. Before, any `StagedRegion` could have children, which meant we could have arbitrarily deep trees of `StagedRegion`s, and also that every `StagedRegion` had to know whether children would be genuine sub-regions or just aliases of the parent. Now, the `StagedRegion` hierarchy is split into `ParentStagedRegion` and `ChildStagedRegion`. A `ParentStagedRegion` can have children, while a `ChildStagedRegion` cannot. The main effect of this is that the `allowAllocations` bit is no longer hereditary. A `ChildStagedRegion` can be converted into a `ParentStagedRegion`, and hence another generation of children can be created, but now doing so requires explicitly specifying `allowAllocations` for the new generation. In emit, this happens at stream consumers, where the allocation strategy will be read off the PType of the stream. The full hierarchy is now:; * `StagedRegion` - The root class is the type for passing around unowned regions. Besides writing into the region, the method `asRoot` allows converting to a `RootStagedRegion` by specifying `allowAllocations`; * `ParentS",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9401:709,simpl,simplifies,709,https://hail.is,https://github.com/hail-is/hail/pull/9401,1,['simpl'],['simplifies']
Usability,"Stacked on #9489 . This PR enforces a stronger invariant on `lir.Block`: a block can never contain dead code, i.e. code that follows a control statement. Prior to this, dead code could be added to a block, only to be removed later. But it's just as easy to have `Block.append` check if a statement to be added would be dead, and just not add it in the first place. And having the stronger invariant always hold allows for some simplifications in the code, in addition to a simpler mental model.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9490:427,simpl,simplifications,427,https://hail.is,https://github.com/hail-is/hail/pull/9490,2,['simpl'],"['simpler', 'simplifications']"
Usability,"Stacked on https://github.com/hail-is/hail/pull/5354. This is a very naive implementation of approximate quantiles that @patrick-schultz and I wrote last Friday. The diff will only contain ApproximateQuantiles.cpp and ApproximateQuantiles_test.cpp and a one-line change to the Makefile when https://github.com/hail-is/hail/pull/5331 is merged (which simplifies the addition of new test files to `Makefile`). I'm not sure what testing means in this context because it is an approximate algorithm. We added a test that calculates the ranks for a bunch of elements and prints them. This at least verifies we do not segfault on a simple example. Some subset of the interested parties: @jbloom22 @cseed @catoverdrive @patrick-schultz. Next steps:; - translate to Scala and hook into an actual aggregator; - hook into some future C++ aggregator infrastructure. ---; # The Algorithm Idea. The idea is to keep a logarithmic amount of data but still be able to reproduce an approximation of the original rank (how many elements are less than the given element). We start with a buffer of size `2^N`. ```; +-------------+; | |; +-------------+; ```. We insert elements from the stream until the buffer is full:. ```; +-------------+; | 1 2 ... 2^N |; +-------------+; ```. Then we 1) sort the buffer, 2) allocate another buffer of equal size, and 3); copy half the elements, randomly choosing to start from the zeroth or oneth; element. In the figure below we started with the zeroth element. We now consider; the first buffer empty. Note that the second buffer is only half-full. ```; +-------------------------------+; 2 | 1 3 ... 2^N - 1 |; +-------------------------------+; 1 | |; +-------------------------------+; ```. We now fill the first buffer again and repeat the process, now filling the; second buffer entirely and emptying the first buffer again. Because the second; buffer is now full, we run this compaction process on it, producing a third; buffer which is one half full. The probability of an",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5332:350,simpl,simplifies,350,https://hail.is,https://github.com/hail-is/hail/pull/5332,2,['simpl'],"['simple', 'simplifies']"
Usability,Stacked on: https://github.com/hail-is/hail/pull/5891. I found getting .in (or not) consistent between the configuration and the files was just error prone. I think this is just simpler.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5907:178,simpl,simpler,178,https://hail.is,https://github.com/hail-is/hail/pull/5907,1,['simpl'],['simpler']
Usability,"Stacked on: https://github.com/hail-is/hail/pull/7440. Changes:; - start the instance with a 1-time use activation token in the metadata; - on activation, clear the activation token, send the worker the normal token and batch-gsa-key; - upgrade the worker image to -6 which has the latest cloud-sdk (v269). As far as I can tell, the metadata server is still available from within the worker container after the upgrade, so I'm not 100% sure why this change was necessary. However, it will make things easier to lock down later. I think the picture we want is:; - store the worker and batch logs in different buckets,; - the worker instance service account only has instance.delete* and object.insert on the worker log bucket,; - the service account used by the worker only has object.insert on the batch logs bucket,; - we block access to the metdata srever from within the docker containers.Leaving this for reference:. https://stackoverflow.com/questions/32512597/block-docker-access-to-specific-ip. This isn't 100% trivial because the metadata server is also the DNS server. We could try blocking everything except udp/53. I think ideally, we'd put the docker containers on a different network that could only route to the outside and use a public DNS server like 8.8.8.8. *An instance doesn't need extra permissions to shut itself down, so we could just do `shutdown -h now` on the worker and have the batch driver actually delete the instance. I think once this goes in we can try scale up tests again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7447:155,clear,clear,155,https://hail.is,https://github.com/hail-is/hail/pull/7447,1,['clear'],['clear']
Usability,"Stacks on #5437. When #5437 is merged, only change will be the addition of a `requires_auth` decorator - which redirects users to the login page when unauthorized, keeping a reference to the referring url - the protection of all routes other than login/logout, and 4 lines to the `/auth0-callback` route to read/clear the referrer session cookie. Admin pages are currently protected in the same way, but I can drop protection from whatever routes you wish. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5448:312,clear,clear,312,https://hail.is,https://github.com/hail-is/hail/pull/5448,1,['clear'],['clear']
Usability,"String,qual:Float64,filters:Set[String],info:Struct{CIEND:Array[Int32],CIPOS:Array[Int32],CS:String,END:Int32,IMPRECISE:Boolean,MC:Array[String],MEINFO:Array[String],MEND:Int32,MLEN:Int32,MSTART:Int32,SVLEN:Array[Int32],SVTYPE:String,TSD:String,AC:Array[Int32],AF:Array[Float64],NS:Int32,AN:Int32,EAS_AF:Array[Float64],EUR_AF:Array[Float64],AFR_AF:Array[Float64],AMR_AF:Array[Float64],SAS_AF:Array[Float64],DP:Int32,AA:String,VT:Array[String],EX_TARGET:Boolean,MULTI_ALLELIC:Boolean,STRAND_FLIP:Boolean,REF_SWITCH:Boolean,DEPRECATED_RSID:Array[String],RSID_REMOVED:Array[String],GRCH37_38_REF_STRING_MATCH:Boolean,NOT_ALL_RSIDS_STRAND_CHANGE_OR_REF_SWITCH:Boolean,GRCH37_POS:Int32,GRCH37_REF:String,ALLELE_TRANSFORM:Boolean,REF_NEW_ALLELE:Boolean,CHROM_CHANGE_BETWEEN_ASSEMBLIES:Array[String]},a_index:Int32,was_split:Boolean,old_locus:Locus(GRCh38),old_alleles:Array[String]},entry:Struct{GT:Call}}; after: Matrix{global:+Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{CIEND:Array[Int32],CIPOS:Array[Int32],CS:String,END:Int32,IMPRECISE:Boolean,MC:Array[String],MEINFO:Array[String],MEND:Int32,MLEN:Int32,MSTART:Int32,SVLEN:Array[Int32],SVTYPE:String,TSD:String,AC:Array[Int32],AF:Array[Float64],NS:Int32,AN:Int32,EAS_AF:Array[Float64],EUR_AF:Array[Float64],AFR_AF:Array[Float64],AMR_AF:Array[Float64],SAS_AF:Array[Float64],DP:Int32,AA:String,VT:Array[String],EX_TARGET:Boolean,MULTI_ALLELIC:Boolean,STRAND_FLIP:Boolean,REF_SWITCH:Boolean,DEPRECATED_RSID:Array[String],RSID_REMOVED:Array[String],GRCH37_38_REF_STRING_MATCH:Boolean,NOT_ALL_RSIDS_STRAND_CHANGE_OR_REF_SWITCH:Boolean,GRCH37_POS:Int32,GRCH37_REF:String,ALLELE_TRANSFORM:Boolean,REF_NEW_ALLELE:Boolean,CHROM_CHANGE_BETWEEN_ASSEMBLIES:Array[String]},a_index:Int32,was_split:Boolean,old_locus:Locus(GRCh38),old_alleles:Array[String]},entry:Struct{GT:Call}}; ```; It is not clear how these differ (if at all?).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4524:2201,clear,clear,2201,https://hail.is,https://github.com/hail-is/hail/issues/4524,1,['clear'],['clear']
Usability,"Style guide draft with 3 sample commands and HTML/JS code . Not intended for merging to master. If you're happy with this, then I'll update the rest of the commands with the style guide I specified. The style guide does not address how to format tables (work in progress). **Style Guide:**; - docs/DocsStyleGuide.md. **Example Markdown Command Files to look at:**; - docs/commands/annotateglobal_expr; - docs/commands/annotateglobal_list; - docs/commands/annotateglobal_table. **HTML/JS code:**; - docs/index.html; - docs/buildDocs.js",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/569:6,guid,guide,6,https://hail.is,https://github.com/hail-is/hail/pull/569,4,"['Guid', 'guid']","['Guide', 'guide']"
Usability,Style: spaces in simple one line statements.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/513:17,simpl,simple,17,https://hail.is,https://github.com/hail-is/hail/pull/513,2,['simpl'],['simple']
Usability,"Submit = () => {; console.log(this.bar) //prints foo; }. // Don't; onSubmitBad() {; console.log(this.bar) //may be undefined; }; }. const barrer = new Something();; console.info(""good"", barrer.onSubmit());; console.info(""bad"", barrer.onSubmitBad());; ```. # Tips . ### Client-side routing; Wrap a normal anchor tag in `<Link ></Link>`; ex:; ```jsx; <Link href='/path/to/page'><a>Page Name</a></Link>; ```. This simply adds the client-side routing logic, and passes the href to <a href=. . ### Prefetching; One of the neat things about Next is how easy it makes prefetching pages. This allows perceived page loading times on the order of 5ms, even when the page requires very complex state (say a GraphQL or series of REST calls with large responses). ```jsx; <Link href='/expensive-page' prefetch><a>Expensive Page</a></Link>; ```; ### Make your app do ONLY server-side routing; Meaning every time you click on a link in your page, you hit the server, just like the first visited page. . Simply use `<a>` directly. ### Caching and sidecar requests; Broadly, there are three strategies: browser caching, server caching, and service-worker caching. In this project we will likely use all three. Server caching is an excellent strategy for pages that serve only public data. In this strategy we pre-generate the static html, serve that, and invalidate the cache once in a while. An example of this can be found in https://github.com/hail-is/hail/pull/5162/commits/e131a931c58a204104d45d0010341423b1ab9500; * Care needs to be taken with the server-side option, not to leak authentication state, since this will, at least by default, be shared across all users. . # Styleguide; 1. Typescript everywhere. # Performance; 1. [React SSR vs Nunjucks](https://malloc.fi/performance-cost-of-server-side-rendered-react-node-js) ; * [React SSR performance (well, React DOM in general) is a focus for 2019](https://github.com/facebook/react/issues/13525); ![v2-chart-1](https://user-images.githubusercontent.com/5543",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:14131,Simpl,Simply,14131,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['Simpl'],['Simply']
Usability,Subquery simplification is in progress!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1270347717:9,simpl,simplification,9,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1270347717,2,['simpl'],['simplification']
Usability,"Suggestions:; 1) change `va.maf` to `va.panel_maf` in the example, say first something like ""Suppose we have already added a variant annotation `va.panel_maf` with allele frequencies computed from a reference panel.""; 2) add ""if unspecified, MAF will be estimated from the dataset"" to `-m`. How about using `-maf` instead of `-m`, it's still super short and much clearer?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/894#issuecomment-251433966:363,clear,clearer,363,https://hail.is,https://github.com/hail-is/hail/pull/894#issuecomment-251433966,2,['clear'],['clearer']
Usability,"Summary of Changes; - Preserve MT structure for entry fields; - Harmonize MT and T `show` interface in a backwards compatible way; - Simplify `Expression.show` code slightly; - A comprehensive, colocated set of `show` tests",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6089:133,Simpl,Simplify,133,https://hail.is,https://github.com/hail-is/hail/pull/6089,1,['Simpl'],['Simplify']
Usability,"Summary of changes:; - Added index_bgen to Python Backend; - Move most Backend functions to SparkBackend. Everything about the current code assumes a single user, but the ServiceBackend will have a different, mutli-user interface.; - Added Backend and FS to ExecuteContext.; - renamed Backend clear => stop",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8386:293,clear,clear,293,https://hail.is,https://github.com/hail-is/hail/pull/8386,1,['clear'],['clear']
Usability,"Summary of changes:; - At the end of schedule, log total time and number of jobs scheduled.; - Only log database timing if total query took >20ms.; - Make sure context_manager is cleaned up in gear.Transaction.; - Limit workers to max 250 requests/s incoming to batch driver. I used an nginx limit to do this, but it is per pod, so I turned off autoscaling and increased CPU to roughly what I saw when 100K cores was hammering against a dead driver.; - Increase the worker exponential backoff from 30s to 2m. The main thing I was trying to address was the driver getting overloaded when trying to restart with a large standing cluster. It isn't totally clear why the cluster failed in the first place. I made a few other changes to mitigate the issue before adding the nginx limit, so I'm not 100% sure which combination of changes fixed the problem:. - I put a 60s timeout on the scheduler loop. This probably isn't necessary, although the scheduler does get bogged down if many of the instances it tries to schedule on are not responding. - I put a 10s timeout on mark_job_complete. - I put a maximum of 150 active mark_job_complete requests being processed, and returned service unavailable when the max was hit. I don't think this problem is completely solved. I think we want to keep the driver in the ~80% CPU load regime where everything is being processed quickly. I think we want to back off workers if, for example, mark_job_complete is taking more than 95%ile in the not overloaded case. I'm not sure who should do this, although it could be the batch-driver if internal-gateway is doing front-line throttling. Exiting in the overload case should be very cheap. We might want to prioritize mark_job_complete over the scheduler in that case, too. @danking I'd love to get some metrics for the scheduling loop: schedules/s, jobs/s, and time once this goes in. Should I switch to logging json to make that easier?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8149:653,clear,clear,653,https://hail.is,https://github.com/hail-is/hail/pull/8149,1,['clear'],['clear']
Usability,"Summary of changes:; - rip out method wrapping from Emit level; - Emit now uses locals everywhere instead of fields; - improved SimplifyControl; - Changed CodeRegion to call Memory directly, instead of calling Region methods. This saves a bytecode on native memory accesses.; - add lir.SplitMethod to break up methods. For large methods, this breaks the body of each basic block into one (or more) external functions and spills locals to fields. Splitting is controlled by SplitMethod.TargetMethodSize, currently set to 2000. PR'ing for testing. I have a few more improvements and then I will performance test. Here are the method sizes after splitting for the large `MakeStruct` example:. ```; is/hail/codegen/generated/C8; <init> 4; apply 235; apply 19; setPartitionIndex 11; addPartitionRegion 5; __wrapped16 30; __wrapped17 2003; __wrapped18 2008; __wrapped19 2006; __wrapped20 2008; __wrapped21 2006; __wrapped22 2008; __wrapped23 2006; __wrapped24 2008; __wrapped25 2006; ... you get the picture, remaining 100 methods elided ...; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8333:128,Simpl,SimplifyControl,128,https://hail.is,https://github.com/hail-is/hail/pull/8333,1,['Simpl'],['SimplifyControl']
Usability,"Summary: hailctl batch list --help; ```; usage: hailctl batch list [-h] [--query QUERY] [--limit LIMIT] [--all] [--before BEFORE] [--full] [--no-header] [-o O]. List batches. optional arguments:; -h, --help show this help message and exit; --query QUERY, -q QUERY; see docs at https://batch.hail.is/batches; --limit LIMIT, -l LIMIT; number of batches to return (default 50); --all, -a list all batches (overrides --limit); --before BEFORE start listing before supplied id; --full when output is tabular, print more information; --no-header do not print a table header; -o O specify output format (json, yaml, csv, tsv, or any tabulate format); ```. Details:; * Default listing to a limit of 50 records, once batch statuses are; cached from `list_batches`, this should result in 1 http request for the; default behavior of this tool.; * Teach --limit option to cap the number of records returned; * Teach --all to override --limit; * Teach --before to pass a last_batch_id query parameter to list_batches; * Teach --full to print all status information; * Teach --no-header to enable not printing a header for tabular output; * Teach -o {format} to change the output format the following are supported:; - json: always full json output, like hitting the list enpoint manually; - yaml: like json, but yaml!; - csv/tsv: simple comma/tab separated output for machine processing; - any python-tabulate output format, listed here:; https://github.com/astanin/python-tabulate#table-format. The only default that has been changed is the listing limit.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9557:1317,simpl,simple,1317,https://hail.is,https://github.com/hail-is/hail/pull/9557,1,['simpl'],['simple']
Usability,"T 21 lock struct(s), heap size 1136, 12 row lock(s), undo log entries 5; MySQL thread id 962402, OS thread handle 139741222766336, query id 6809292838 10.32.5.50 jigold updating; UPDATE instances_free_cores_mcpu; SET free_cores_mcpu = free_cores_mcpu + cur_cores_mcpu; WHERE instances_free_cores_mcpu.name = in_instance_name; *** (1) WAITING FOR THIS LOCK TO BE GRANTED:; RECORD LOCKS space id 1578686 page no 3 n bits 72 index PRIMARY of table `jigold`.`instances_free_cores_mcpu` trx id 1215034153 lock_mode X locks rec but not gap waiting; Record lock, heap no 3 PHYSICAL RECORD: n_fields 4; compact format; info bits 0; 0: len 30; hex 62617463682d776f726b65722d6a69676f6c642d7374616e646172642d62; asc batch-worker-jigold-standard-b; (total 34 bytes);; 1: len 6; hex 0000486bf32c; asc Hk ,;;; 2: len 7; hex 600001287513cb; asc ` (u ;;; 3: len 4; hex 80002de6; asc - ;;. *** (2) TRANSACTION:; TRANSACTION 1215034156, ACTIVE 0 sec inserting; mysql tables in use 6, locked 6; 22 lock struct(s), heap size 1136, 13 row lock(s), undo log entries 7; MySQL thread id 962349, OS thread handle 139741180090112, query id 6809294284 10.32.5.50 jigold update; INSERT INTO batch_inst_coll_cancellable_resources (batch_id, inst_coll, token, n_running_cancellable_jobs, running_cancellable_cores_mcpu); VALUES (OLD.batch_id, OLD.inst_coll, rand_token, -1, -OLD.cores_mcpu); ON DUPLICATE KEY UPDATE; n_running_cancellable_jobs = n_running_cancellable_jobs - 1,; running_cancellable_cores_mcpu = running_cancellable_cores_mcpu - OLD.cores_mcpu; *** (2) HOLDS THE LOCK(S):; RECORD LOCKS space id 1578686 page no 3 n bits 72 index PRIMARY of table `jigold`.`instances_free_cores_mcpu` trx id 1215034156 lock_mode X locks rec but not gap; Record lock, heap no 3 PHYSICAL RECORD: n_fields 4; compact format; info bits 0; 0: len 30; hex 62617463682d776f726b65722d6a69676f6c642d7374616e646172642d62; asc batch-worker-jigold-standard-b; (total 34 bytes);; 1: len 6; hex 0000486bf32c; asc Hk ,;;; 2: len 7; hex 60000128751",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11959:1985,undo,undo,1985,https://hail.is,https://github.com/hail-is/hail/pull/11959,1,['undo'],['undo']
Usability,"TE 2].; > ; > I don't think changing these will have the desired effect and may make it impossible for someone to reproduce the database. The only changes to _existing_ sql you'll need to make are in the sql strings in python code.; > ; > 2. This needs to be written as a migration and maybe could be simplified?; > ; > I think this needs to be done as a database migration. We'll have no need for a stored procedure once complete. You can assume current columns and constraints exist, dispense with the error checking and simplify. Can you convert this to a sql script and add it to the end of the list of migrations in `build.yaml`? You'll probably want `online: false` too. I fear you'll have to take inspiration from `rename-job-groups-tables.sql` by applying one `ALTER TABLE` command then drop and recreate EVERYTHING that references that name (constraints, triggers, procedures etc). This will likely involve copy+paste and rename. Alternatively, create, execute then drop the procedure within `rename-job-groups-cancelled`.; > ; > [NOTE 1] migration applied in `build.yaml`; > ; > The relevant build step in `build.yaml` can be found by searching for the entry starting with the yaml below. This controls which migrations are applied and in what order.; > ; > ```yaml; > kind: createDatabase2; > name: batch_database; > databaseName: batch; > ```; > ; > [NOTE 2] estimated-current.yaml; > ; > I don't agree with why we have this. It would be nice to generate this automatically. Anyway, please keep your changes to this file as it's meant for documentation purposes only. None of it is applied and who knows how much of it works. Got it! I wasn't sure how Hail usually does schema update. Based on your above description the process becomes clearer ro me. Here's my second try:. - Updated `build.yaml` in the `batch` database migrations section.; - Simplified the sql in `rename-job-groups-cancelled-column.sql`. Do you mean `estimated-current.sql` rather than `estimated-current.yaml` above?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14672#issuecomment-2334778045:2165,clear,clearer,2165,https://hail.is,https://github.com/hail-is/hail/pull/14672#issuecomment-2334778045,3,"['Simpl', 'clear']","['Simplified', 'clearer']"
Usability,"Talked with jon, summary:. Clearly there are people who need larger block sizes due to data size and partition limits. There are also people who try to use the default block size with smaller data sets and without highmem machines. These people usually have a bad time. We should pay attention to reports of this and figure out how we can better educate people on using smaller block sizes for smaller data.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5375#issuecomment-464193120:27,Clear,Clearly,27,https://hail.is,https://github.com/hail-is/hail/pull/5375#issuecomment-464193120,1,['Clear'],['Clearly']
Usability,"Tested deletion in a separate database. 0 rows is instantaneous. 100,000,000 rows is 10 seconds. So at worst, it's probably on order of 10 minutes to drop a table since the table I had was very simple with not a lot of columns. Will rebase and then get this merged.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12710#issuecomment-1446634047:194,simpl,simple,194,https://hail.is,https://github.com/hail-is/hail/pull/12710#issuecomment-1446634047,2,['simpl'],['simple']
Usability,"Thank you all for another round of detailed critique!. OK, I think the only remaining critical fix is to hard-code a mainclass. This is a wee bit complicated because I need to multiplex the ServiceBackendSocketAPI2 and the Worker. I hope to do this tomorrow AM. I'll then dismiss reviews. I also have a list of todos generated by this process which will feedback into some master QoB doc that integrates the two teams necessary todos.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194#issuecomment-1033173934:354,feedback,feedback,354,https://hail.is,https://github.com/hail-is/hail/pull/11194#issuecomment-1033173934,2,['feedback'],['feedback']
Usability,Thank you for the clear and easy-to-follow instructions! I've rebased my commit and applied your patch. What do I need to do now?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/753#issuecomment-251409770:18,clear,clear,18,https://hail.is,https://github.com/hail-is/hail/pull/753#issuecomment-251409770,2,['clear'],['clear']
Usability,"Thanks @danking for helping with this, and for the nudge to finally get it implemented!. Some more next steps:; * Make a benchmarking setup to collect data on performance and accuracy. I want to use the same metrics for measuring error as [here](http://quantiles.github.io/) (Kolmogorov-Smirnov divergence and total variation distance between the true and estimated CDFs, which are both simple to compute). As a first sanity check, we should get numbers in the same ballpark as they did (worse at first, because we started with a very naive algorithm).; * Make improvements to the algorithm, evaluating the gains in the benchmarks.; * When we feel we understand the behavior of the accuracy measures, we can pick a conservative upper error bound and turn that into an automated test.; * Also once we understand the behavior of the accuracy measures, figure out how to communicate that to users. One thought is to offer a few default choices of parameters, and for each document memory usage, empirical error from our benchmarks, and a theoretical upper bound on the error (of the form ""with probability > .99 the estimated q quantile element will have true quantile q ± .001""). This allows users to make an informed decision based on their use case. That looks like a lot, but I think those are all relatively simple. I'm also using this as a test case for thinking about how to implement approximate/randomized methods in Hail in general.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5332#issuecomment-463200410:387,simpl,simple,387,https://hail.is,https://github.com/hail-is/hail/pull/5332#issuecomment-463200410,4,['simpl'],['simple']
Usability,Thanks for reporting this. I had tried to remove our dependence on `setuptools` but had not done a good enough job clearly.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14630#issuecomment-2243322335:115,clear,clearly,115,https://hail.is,https://github.com/hail-is/hail/issues/14630#issuecomment-2243322335,2,['clear'],['clearly']
Usability,Thanks for the clear bug report @uqrmaie1! Let me know if you have any more trouble.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2763#issuecomment-360660531:15,clear,clear,15,https://hail.is,https://github.com/hail-is/hail/issues/2763#issuecomment-360660531,2,['clear'],['clear']
Usability,"Thanks for the feedback, I've simplified the logic, made the python test more comprehensive, and made element retrieval more direct and applicable to sparse block matrices. I'll clarify that the latter is supported in the sparse case as soon as #3539 goes in.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3611#issuecomment-389940384:15,feedback,feedback,15,https://hail.is,https://github.com/hail-is/hail/pull/3611#issuecomment-389940384,4,"['feedback', 'simpl']","['feedback', 'simplified']"
Usability,"Thanks guys, something new to learn!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7826#issuecomment-575745357:30,learn,learn,30,https://hail.is,https://github.com/hail-is/hail/issues/7826#issuecomment-575745357,2,['learn'],['learn']
Usability,"Thanks so much Daniel!! This is awesome. I can't seem to be able to merge though, probably due to permissions?; <img width=""516"" alt=""Screen Shot 2021-04-22 at 9 58 00 am"" src=""https://user-images.githubusercontent.com/1575412/115636406-3ada5e00-a351-11eb-887d-3882271f6369.png"">. There are also conflicts, but I'm resolving them right now :). UPD: Ah, learned from Leo that the merge button will be available after the tests pass :)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10347#issuecomment-824439697:353,learn,learned,353,https://hail.is,https://github.com/hail-is/hail/pull/10347#issuecomment-824439697,2,['learn'],['learned']
Usability,"Thanks, @tomwhite! This is great. Is there a Hive CLI equivalent of `LIKE PARQUET <file>`? I can't figure out how to get Hive to infer the schema from the Parquet file rather than specifying it explicitly. It would be awesome to be able to query the genotypes, too. It seems like we could write a SerDe (now I'm thinking ImpEx isn't so bad :)) to unpack the genotypes. Does that sound like the right approach?. On a related note, we've played with storing VDS natively as Parquet as (variant, variant annotations, array(genotype)). Even when I ported over some of the GenotypeStream encoding tricks (OD instead of DP, etc.), it was 2-3x larger (using Snappy compression vs. our internal LZ4 compression). That's disappointing, esp. when we have 30+TB datasets on the way. What's worse, simple operations like counting genotypes (`count -g`) are 5-10x in the native representation. Current master:. ```; $ hail importvcf profile225.vcf.bgz write -o profile225.vds read -i profile225.vds count -g; hail: info: timing:; importvcf: 508.829ms; write: 3m6.7s; read: 1.629s; count: 13.934s; $ du -sh profile225.vds; 2.0G profile225.vds; ```. And with the `jg_dataframe1` experimental branch, which uses native Parquet and computes the count using a UDF that computes the sum per array (fastest Parquet-based implementation we've found so far):. ```; $ hail importvcf profile225.vcf.bgz write -o profile225.vds read2 -i profile225.vds count2; hail: info: timing:; importvcf: 492.354ms; write: 5m57.1s; read2: 1.466s; count2: 1m44.1; $ du -sh profile225.vds; 5.4G profile225.vds; ```. That's 2.7x larger and >7x slower. This includes the fact that the Parquet version is only loading the GT field of the genotypes (!). This might be a non-starter for us. We'd love the flexibility and interoperability of standard Parquet. If you have other ideas about how to get Parquet close to what we currently have, I'd love to talk more.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/480#issuecomment-234027310:786,simpl,simple,786,https://hail.is,https://github.com/hail-is/hail/pull/480#issuecomment-234027310,2,['simpl'],['simple']
Usability,"That would work, though I think it's probably simpler to have min and max be the first and last elements of the pivots array (which should be required to be sorted).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10816#issuecomment-906667906:46,simpl,simpler,46,https://hail.is,https://github.com/hail-is/hail/pull/10816#issuecomment-906667906,2,['simpl'],['simpler']
Usability,"That's what I expected. Your name just came up in the roulette. I'll also want @cseed to give feedback, since I made these from his original work on https://github.com/cseed/hail/tree/partitioned-combiner.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4824#issuecomment-441771321:94,feedback,feedback,94,https://hail.is,https://github.com/hail-is/hail/pull/4824#issuecomment-441771321,2,['feedback'],['feedback']
Usability,"The ATGU intranet service is home for some tools we're going to build help support ATGU operations. After talking to the administrators, we started a simple tool for the admins to curate resources for members of the group. We've also talked about things related to personnel and financial and grant management. Although this will likely be a slightly different resource, we're talking to the PMs about tools we can build to help pulling together large-scale datasets like gnomAD. The complexity of doing this is becoming a blocker for producing such datasets. We're Hail. Whatever we build is part of Hail. Things that we own and operate and deploy together live in our monorepo.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9684#issuecomment-723166642:150,simpl,simple,150,https://hail.is,https://github.com/hail-is/hail/pull/9684#issuecomment-723166642,2,['simpl'],['simple']
Usability,"The Google docs aren't clear about whether the hash needs to be a suffix or prefix: . > add the hash of the sequence number as part of the object name to make it non-sequential. I'm somewhat hesitant to make this change since it means our part outputs are no longer sorted lexicographically, and this property has been very useful in the past.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10836#issuecomment-914241609:23,clear,clear,23,https://hail.is,https://github.com/hail-is/hail/pull/10836#issuecomment-914241609,2,['clear'],['clear']
Usability,"The RNGSplit emitter assumed the components of `dynBitstring` were always inferred to be required, but it seems to be impossible to construct the bitstrings in a way that the requiredness inference can always see that. This first makes the type of `dynBitstring` more constrained to simplify the emitter. Before it was allowed to be a single long, or an arbitrarily nested tuple all of whose leaves are longs. But I believe only flat tuples are actually being generated, so this makes that the enforced type. Then the emitter asserts all fields are present at runtime.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12060:283,simpl,simplify,283,https://hail.is,https://github.com/hail-is/hail/pull/12060,1,['simpl'],['simplify']
Usability,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:117,clear,clearly,117,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741,4,"['clear', 'simpl']","['clearly', 'simplification']"
Usability,"The `BlockingInputBuffer` allocates a somewhat large array of; bytes each time it is allocated. As such, it is important to avoid; allocating a `BlockingInputBuffer` for each row if each row is; significantly smaller than the buffer size. This change removes problematic methods from `RegionValue`, `RVD`,; and `CodecSpec` that have poor performance. In every case, a small; code change enables one allocation per-partition. This required the; implementation of `RestartableByteArrayInputStream` which is a thread-; unsafe version of `ByteArrayInputStream` that, crucially, can; be restarted with a new `Array[Byte]`. ---. I rebased this off of my shuffler branch. With this change on the shuffler branch (which otherwise didn't change Spark shuffles), I saw these benchmark results:; ```; # hailctl dev benchmark compare more-allocs.json fewer-allocs.json; Name Ratio Time 1 Time 2; ---- ----- ------ ------; shuffle__key_rows_by_mt 105.2% 25.528 26.860; shuffle__key_rows_by_4096_byte_rows 102.7% 1.052 1.081; shuffle__key_rows_by_65k_byte_rows 102.7% 19.311 19.832; shuffle__order_by_10m_int 47.0% 93.554 44.011; ----------------------; Geometric mean: 85.0%; Simple mean: 89.4%; Median: 102.7%; ```. The first benchmark is dominated by LZ4 calls in Kryo. The second and third benchmarks are dominated by the construction of the MT. I suspect this is due to unnecessary data copying (when Hail constructs an array of structs it creates the structs out of line and copies them into place).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7108:1163,Simpl,Simple,1163,https://hail.is,https://github.com/hail-is/hail/pull/7108,1,['Simpl'],['Simple']
Usability,"The `HailContext.getOrCreate` method seems to have been broken in #5512. This patch fixes the issue and adds a regression test so that it won't break again. Since this test must add create a new Hail context, I had to add a gradle task that runs every suite in a separate JVM. I'm not a gradle expert, so if there's a simpler way to accomplish this execution mode, feel free to suggest :).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5871:318,simpl,simpler,318,https://hail.is,https://github.com/hail-is/hail/pull/5871,1,['simpl'],['simpler']
Usability,"The `delete_azure_batch_instances` step is failing on various PRs with the error `jq: command not found`. This appears to be because we do not pin the version for the `mcr.microsoft.com/azure-cli` image, and while that image was previously based on the Alpine image, [now it is based on the Azure Linux image](https://learn.microsoft.com/en-us/cli/azure/run-azure-cli-docker), and does not appear to have `jq` (or `kubectl`) preinstalled on it. This change updates the commands run in the `azure-cli` container for this CI step to install `jq` and `kubectl` via `curl` before running the relevant commands. The `curl` commands were tested locally by running `docker run -it mcr.microsoft.com/azure-cli` and trying them out in the image's shell. This change also adds the installation commands in the other place where this image is used (when cleaning up from `buildImage2` jobs that are run in Azure).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14677:318,learn,learn,318,https://hail.is,https://github.com/hail-is/hail/pull/14677,1,['learn'],['learn']
Usability,The `repr` for SparkContext displays like this: `<pyspark.context.SparkContext object at 0x7ff241c5f690>`. We don't have a history available for a SparkContext object. Not clear how to fix this other than use `sc` if a non-default arg is given for `sc` in HailContext constructor.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2180:172,clear,clear,172,https://hail.is,https://github.com/hail-is/hail/issues/2180,1,['clear'],['clear']
Usability,"The actual necessary fix is `history.pushState("""", document.title, loc.pathname + loc.search);` instead of `history.pushState("""", document.title, loc.pathname);`. Given the nervousness around JS and its use in docs (many imperative scripts interacting), I've decided to take a simpler approach that guarantees that Firefox will have behavior inconsistent with Chrome/Safari. In practice it isn't so bad (initially scrolls too far instead of starting at top of page). There may also be a chance that the browser's built-in scroll will act after the JS command, but there simply isn't a better way (besides setting a longer timeout), or the version that alters the url.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7385:277,simpl,simpler,277,https://hail.is,https://github.com/hail-is/hail/pull/7385,2,['simpl'],"['simpler', 'simply']"
Usability,"The asyncio event loop only keeps weak references to tasks, so wherever we call `asyncio.create_task` we need to ensure that we keep a strong reference to its result. Specifically, `BackgroundTaskManager` needs to keep strong references not weak references to the tasks it creates. This is easy to do without accumulating garbage by using a done callback on the task to remove itself from the set. However, this felt iffy with the threadsafe futures, which were only used in sync.py anyway, so I pushed that functionality directly into sync.py and removed it from the `BackgroundTaskManager`. To simplify the ownership story for tasks, this changes `BackgroundTaskManager` to *not* return the task and instead hold onto strong references. If a client wants a reference to the task it creates, it should call `asyncio.create_task` directly and manage the lifecycle of the spawned task. This required only a few small changes in worker.py since most of the codebase does not assign the result of `task_manager.ensure_future`. The only change that gave me pause was the handling of `mjs_fut`, whose lifetime is a little tricky since it is potentially passed to yet another task. I think this shows a general weakness in the handling of ownership and lifetimes in between the Job and Worker classes and think a larger refactor can make this less error-prone but is out of scope for this fix. So I'd appreciate an especially scrutinizing look at that piece of the code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12692:596,simpl,simplify,596,https://hail.is,https://github.com/hail-is/hail/pull/12692,2,"['pause', 'simpl']","['pause', 'simplify']"
Usability,"The auth driver currently uses the old secret format. The new secret format; includes SSL information. This change defines the secret format once in hailtop; and uses it everywhere. I also simplified the auth secret format: everyone uses; SSL/TLS to talk to databases now, so assume all necessary files are present.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9113:189,simpl,simplified,189,https://hail.is,https://github.com/hail-is/hail/pull/9113,1,['simpl'],['simplified']
Usability,The bulk of this PR is plumbing to change `TLocus(ReferenceGenome) => TLocus(String)` and bring reference genomes off of global mutable state onto the Backend (both in scala and python). This allows mutable reference genomes in QoB and by extension liftovers. This also removes some duplication between local_backend and spark_backend in python and simplifies the initialization of reference genomes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12699:349,simpl,simplifies,349,https://hail.is,https://github.com/hail-is/hail/pull/12699,1,['simpl'],['simplifies']
Usability,"The change regarding the copy tool progress bar is because on non-verbose mode (like in the local backend) it was generating some weird whitespace by just creating the progress bar not disabled even though none of the tasks were visible. In jupyter notebooks, whitespace rendered as `5l` in the jupyter output.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13681#issuecomment-1729901749:35,progress bar,progress bar,35,https://hail.is,https://github.com/hail-is/hail/pull/13681#issuecomment-1729901749,4,['progress bar'],['progress bar']
Usability,"The command is hidden because to generate reasonable memory overhead and subsequent task sizes for even 10k samples and 10k variants, we should parallelize data generation of the RDD, rather than using `sc.parallelize` on a matrix at driver. That will be a subsequent improvement. For reference, running an IntelliJ test that simply generates the integer matrix of genotypes for 10k samples and 10k variants and 4 populations with the rest default takes about 7 seconds (one core). Small examples still work fine using this command, but PCA fails at the following scale unless repartition is used first:. ```; hail \; baldingnichols \; -k 3 \; -n 2000 \; -m 10000 \; -f .02,.03,.1 \; -d .2,.3,.5 \; -s 0 \; repartition -n 8 \; printschema -o ~/data/baldingnichols/schema.json \; pca -k 3 -s 'sa.pc' -e 'global.evals' \; showglobals -o ~/data/baldingnichols/global.tsv \; exportsamples -c 'sample = s, pop = sa.bn.pop, pc = sa.pc.*' -o ~/data/baldingnichols/samples.tsv \; exportvariants -c 'variant = v, freq = va.bn.*' -o ~/data/baldingnichols/variants.tsv; ```. Here is the annotation scheme created by `baldingnichols`:. ```; Global annotation schema:; global: Struct {; bn: Struct {; seed: Int,; nPops: Int,; nSamples: Int,; nVariants: Int,; popDist: Array[Double],; Fst: Array[Double]; }; }. Sample annotation schema:; sa: Struct {; bn: Struct {; pop: Int; }; }. Variant annotation schema:; va: Struct {; bn: Struct {; ancAF: Double,; AF0: Double,; AF1: Double,; AF2: Double; }; }; ```. The following python code shows three tight clusters corresponding to population using PC1 and PC2, and that PC3 is noise:. ```; import numpy as np; import matplotlib.pyplot as plt; import pandas as pd. %matplotlib inline. df = pd.read_table(""samples.tsv""); colors = {0: 'r', 1: 'b', 2: 'g'}. df.plot('pc.PC1', 'pc.PC2', 'scatter', c=df['pop'].map(colors), alpha=.3); plt.show(). df.plot('pc.PC1', 'pc.PC3', 'scatter', c=df['pop'].map(colors), alpha=.3); plt.show(). df.plot('pc.PC2', 'pc.PC3', 'scatter', c=d",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1029#issuecomment-257211215:326,simpl,simply,326,https://hail.is,https://github.com/hail-is/hail/pull/1029#issuecomment-257211215,2,['simpl'],['simply']
Usability,"The creeping expansion of the interface is on me as we tried to not break 0.1. I'd appreciate discussing in person what makes the most sense for 0.1. Here are the pieces I think we should separate for devel, though we could consider providing a meta-interface as well that combines some of them for usability. I'm writing (U, S, L) for a local matrix of eigenvectors U, an array of eigenvalues S, and an array of labels L on the rows of U (as with labels for SymmetricMatrix). 1) VDS to a (labeled) symmetric matrix (we have these: GRM, RRM, LD matrix, and Dan is working on a way to read and write them). 2) Symmetric matrix to (U, S, L), which we'll want to write and read. This modularizes the single-core eigen-decomposition bottleneck. 3) Variant-labeled (V, S, L) and VDS with those variants to transport (V, S, L) to sample-labeled (U, S, L). Currently this also requires knowing the number of samples used to make the LDMatrix since that number is used in its normalization. I agree it feels unnatural to need to remember this; to avoid it we'd need an unnormalized version. 4) Sample-labeled (U, S, L) and VDS to global fit of LMM including delta. This is currently a local computation that's been pretty fast in practice but as sample sizes increase we will want to distribute evaluating many values of delta in parallel. Note this step only uses the sample annotations on the VDS, so logically it could also be on KeyTable (which would be the sample KeyTable of the VDS). 5) Sample-labeled (U, S, L), VDS, and delta to per-variant-fit of LMM. This VDS can now contain exactly the variants one wants to fit. (5) should eventually be decomposed as well. The first command should project from Matrix to Matrix (projecting both numeric cells and a list of numeric sample annotations) and some additional small data. Then (6) will do per variant tests starting from after this projection (that is, after what is the BIG computation when you have tens of millions of variants). That way users can",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1984#issuecomment-319971210:299,usab,usability,299,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-319971210,2,['usab'],['usability']
Usability,"The current `_variants_per_file` interface isn't usable by mortals. We should have something like `hl.import_bgen('/path/to/bgen', ..., variants=ht.key)` where `ht` is a table with key locus and alleles. This can use the new index file format to get the set of variants to load. Depends on: https://github.com/hail-is/hail/issues/4018",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4019:49,usab,usable,49,https://hail.is,https://github.com/hail-is/hail/issues/4019,1,['usab'],['usable']
Usability,The current help in `Representation of sequence data in Hail` is not clear regarding the `altAllele`; for example make clear that `aa.ref` should be `v.altAllele.ref`.; Cheers,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/433:69,clear,clear,69,https://hail.is,https://github.com/hail-is/hail/issues/433,2,['clear'],['clear']
Usability,"The current implementation of `Container.delete`,; ```python; async def delete(self):; log.info(f'deleting {self}'); self.deleted_event.set(); await self.delete_container(); ```. provokes a race between the `run` task and the `delete` task. The former sees the `deleted_event`, raises and jumps to `delete_container`, so both tasks might be trying to delete the container at the same time. This races here,; ```python; if self.container_is_running():; try:; log.info(f'{self} container is still running, killing crun process'); self.process.terminate(); self.process = None; await check_exec_output('crun', 'kill', '--all', self.container_name, 'SIGTERM'); except asyncio.CancelledError:; raise; except Exception:; log.exception('while deleting container', exc_info=True). ```; where we might queue two `crun kill` calls, the second of which fails because it cannot find any such container. Calling `delete_container` from within the `delete` method is a remnant from an older implementation of deletion, before we used `deleted_event` to explicitly signal to the `run` task that it's time to wrap things up. This is no longer necessary. The simplified way to think about deletion now is:. - Calling `Container.delete` just sets an `asyncio.Event` that the container has been deleted.; - Anything in the `run` task of the container that can be interrupted by a deletion waits on that event and short circuits the run process if it is set.; - The `run` task is the only task that calls `delete_container`, and always calls it when it is done.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10714:1142,simpl,simplified,1142,https://hail.is,https://github.com/hail-is/hail/pull/10714,1,['simpl'],['simplified']
Usability,"The decoder uses a `StagedArrayBuilder` to hold elements while being sorted. The array builder is stored in a class field. When the same decoder function is called more than once, that array builder is reused. Before this fix, the array builder was never cleared, so if the decoder function was called more than once, the array builder would still contain the elements from previously decoded dicts. Since it's highly non-obvious that you need to call `clear` immediately after `new StagedCodeBuilder`, this PR makes the constructor take a CodeBuilder, and always inserts a clear at the call site. I also took the opportunity to CodeBuilderify the rest of the interface.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13939:255,clear,cleared,255,https://hail.is,https://github.com/hail-is/hail/pull/13939,3,['clear'],"['clear', 'cleared']"
Usability,"The default OS for dataproc instances is based on debian8, which uses g++-4.9.x; That has a libstdc++ with an old-ABI implementation of std::list and std::string. To build; a libhail.so which can link against the default libstdc++ on g++-4.x systems, we need to; avoid the use of std::string inside libhail.so (but it's ok to use it in dynamic-generated code,; which will be built with a compiler which matches the libstdc++). This commit introduces a minimal hail::hstring and hail::hstringstream with the necessary; functionality for NativeModule.cpp. Since these don't have a std::hash, I also imported the source code for the (free and uncopyrighted); MurmurHash3, a fast high-quality (but non-crypto) hash function which can give a 128bit hash. ; This simplifies the calculation of the 80bit hash used for module-keys. In addition to using these prebuilt libraries, we also need to get g++ installed on the dataproc; master node, which could be done with ""sudo apt-get install build-essential"". But I'm not yet sure where; that initialization step needs to go.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4422:757,simpl,simplifies,757,https://hail.is,https://github.com/hail-is/hail/pull/4422,1,['simpl'],['simplifies']
Usability,"The default is to put the modules in ${HOME}/hail_modules, which in many; environments; would indeed be an NFS directory. It only goes to /tmp/hail_modules if; ${HOME} is undefined. The thinking behind this is that there's a huge amount of re-use of code; for an individual; from one Hail analysis to the next, but probably much less overlap between; different users.; And while multi-user sharing ought to work, it raises potential issues; about file access; permissions which seemed like trouble without a clear benefit. On Fri, Aug 3, 2018 at 10:49 AM Patrick Schultz <notifications@github.com>; wrote:. > *@patrick-schultz* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207567962>:; >; > > +#include <string>; > +#include <vector>; > +; > +#if 0; > +#define D(fmt, ...) { \; > + char buf[1024]; \; > + sprintf(buf, fmt, ##__VA_ARGS__); \; > + fprintf(stderr, ""DEBUG: %s,%d: %s"", __FILE__, __LINE__, buf); \; > +}; > +#else; > +#define D(fmt, ...) { }; > +#endif; > +; > +namespace hail {; > +; > +namespace {; >; > The anonymous namespace can't be named, so no names introduced in an; > anonymous namespace can be referenced from outside the namespace. The; > exception is that on closing an anonymous namespace, it is automatically; > opened into the enclosing namespace. The typical use is to make things; > file-local.; >; > —; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/3973#discussion_r207567962>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AJzExuxprnaVF62eonAgCjSmqAERvBJiks5uNGLtgaJpZM4VbZpP>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-410321049:508,clear,clear,508,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410321049,2,['clear'],['clear']
Usability,"The default options are all false. If left all false, the user gets an clear error saying that they must include at least one entry field. This forces users to think about what they actually need to import, as it can make a big difference on, say, UKBB until we have better tech. I've updated the docs and tests accordingly. @cseed suggested that we remove BGEN v1.1 support if nobody is reliant on it anymore. I've asked on Slack. So I didn't add more complexity to support these options for BGEN v1.1. Rather this PR requires GT and GP set to true if any file is 1.1 (as explained in docs and error message). If nobody minds, we can rip out BGEN 1.1 and update the docs simultaneously in a subsequent PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2930:71,clear,clear,71,https://hail.is,https://github.com/hail-is/hail/pull/2930,1,['clear'],['clear']
Usability,"The doc wasn't very clear about where information lived. I had imagined that the pools and the JobPrivateInstanceManager (JPIM) owned the information. Nit: the doc doesn't say the instance monitor monitors instances, it just monitors and handles *events*. Let me be explicit: I think the doc is wrong about the monitor doing health checking because that requires it to track the instances, which I just said should be owned by the pools and the JPIM. That didn't occur to me when we were writing the doc, my apologies. I still think the monitor should:; - route events to the right pool or to the JPIM, and; - aggregate summaries up for the web UI. ---. Let me try to be more specific in my critique:. I think of the system as three layers: the top most is the driver, the middle layer is the monitor, and the bottom layer is the pool or JobPrivateInstanceManager (JPIM). I don't want control flow to go down, up, and back down again. If that happens, then we can't reason about our system as separate layers, we necessarily have to think about the middle and bottom layer together. Very specifically, this flow worries me: (instance pool) create_instance -> (instance monitor) add_instance -> adjust_for_add_instance -> (instance pool) adjust_for_add_instance. We move from low to mid *back to low*. I want information to flow in one direction: either its downward information or its upward information. ---. I'm guessing you're also concerned about code organization / code duplication. I'm not that worried about this. The JPIM and the Pool are similar things and we might inevitably produce some duplication. That's OK with me. To be honest, I think a few stand-alone functions that both of them use will eliminate any code duplication. Both pools and the JPIM will have a `name_instances` and `instance_by_last_updated`. If the duplication gets hard to manage, we might pack that up into another class like InstanceCollection. I realize this means we have several monitoring loops. I'm not very w",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9772#issuecomment-738515358:20,clear,clear,20,https://hail.is,https://github.com/hail-is/hail/pull/9772#issuecomment-738515358,2,['clear'],['clear']
Usability,"The docs on the new `export` method are pretty clear:; ```pycon; >>> mt.GT.export('gt.tsv'); >>> with open('gt.tsv', 'r') as f:; ... for line in f:; ... print(line, end=''); locus	alleles	0	1	2	3; 1:1	[""A"",""C""]	0/1	1/1	0/1	0/1; 1:2	[""A"",""C""]	1/1	0/1	1/1	1/1; 1:3	[""A"",""C""]	0/1	0/0	0/0	0/0; 1:4	[""A"",""C""]	1/1	1/1	0/0	1/1; ```. I also changed all the vds extensions to mt, added a new; dataset that is small enough to print the entire matrix,; and fixed a bug in `make install-editable`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6841:47,clear,clear,47,https://hail.is,https://github.com/hail-is/hail/pull/6841,1,['clear'],['clear']
Usability,"The high-level problem: . The Hail Query Service is redeployed with each commit to `main`. Each deployment has a new JAR file; whose ABI is backwards-incompatible. The high-level solution:. Hail Batch Workers can load the JAR for a given Hail version on-demand. Although not a long-term; solution, we currently start a fresh JVM for each job. As a result, we can simply start the JVM with; the correct JAR on its classpath. We cache jars on the local filesystem. I had to abandon the old approach for two reasons:. 1. Multiple JVMs race to download the JAR. In the new approach, the python worker process uses a; lock to ensure at most one coroutine is downloading a given version of a JAR at the same time. 2. The JVM includes assumes that a child ClassLoader does not redefine a class from the parent; ClassLoader. That's why ClassLoaders always prefer to load a class from the parent ClassLoader's; classes. When we decide to re-use JVMs or use a single multi-threaded JVM, we'll need to ensure the top-level; ClassLoader *does not have Hail on its classpath*. I looked briefly at this approach and found it; more work than the current approach. ---. My apologies for eliminating JVMProcess in this PR. It's an unrelated change which facilitated my; understanding of worker.py. I essentially inlined JVMProcess into JVMJob and eliminated any duplicative; code. ---. After making this change I restored the tests. Some tests had bitrotted. In the process of fixing; those tests, I found a few other bugs. Fixing these lower-level bugs unlocked a number of new; tests. One test (which was added since the service tests were removed) had to be marked as failing. Some; Hail operations rely on writing to the local file system. Implementing that properly in the Query; Worker will take some thought. Here are the bugs I fixed:. 1. Correct the error message raised when tests are run in a non-main thread (we look for this; message and start an event loop for Hail's async code because asyncio refuses t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10314:363,simpl,simply,363,https://hail.is,https://github.com/hail-is/hail/pull/10314,1,['simpl'],['simply']
Usability,"The high-level problem:. The Hail Query Service is redeployed with each commit to `main`. Each deployment has a new JAR file; whose ABI is backwards-incompatible. The high-level solution:. Hail Batch Workers can load the JAR for a given Hail version on-demand. Although not a long-term; solution, we currently start a fresh JVM for each job. As a result, we can simply start the JVM with; the correct JAR on its classpath. We cache jars on the local filesystem. I had to abandon the old approach for two reasons:. 1. Multiple JVMs race to download the JAR. In the new approach, the python worker process uses a; lock to ensure at most one coroutine is downloading a given version of a JAR at the same time. 2. The JVM assumes that a child ClassLoader does not redefine a class from the parent; ClassLoader. That's why ClassLoaders always prefer to load a class from the parent ClassLoader's; classes. When we decide to re-use JVMs or use a single multi-threaded JVM, we'll need to ensure the top-level; ClassLoader *does not have Hail on its classpath*. I looked briefly at this approach and found it; more work than the current approach. ---. My apologies for eliminating JVMProcess in this PR. It's an unrelated change which facilitated my; understanding worker.py. I essentially inlined JVMProcess into JVMJob and eliminated any duplicative; code. ---. After making this change I restored the tests. Some tests had bitrotted. In the process of fixing; those tests, I found a few other bugs. Fixing these lower-level bugs unlocked a number of new; tests. A couple tests (which were added since the service tests were removed) had to be marked as; failing. Here are the bugs I fixed:. 1. Correct the error message raised when tests are run in a non-main thread (we look for this; message and start an event loop for Hail's async code because asyncio refuses to start an event; loop in a non-main thread). 2. Use a `SafeRow` to copy the globals data out of a Region and into durable, GC'ed objects. 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10390:362,simpl,simply,362,https://hail.is,https://github.com/hail-is/hail/pull/10390,1,['simpl'],['simply']
Usability,"The idea is to allow the execution on both `SparkBackend` and `ServiceBackend` without code changes, simply switching to the Query service by setting the environment variables `HAIL_QUERY_BACKEND`, `HAIL_BILLING_PROJECT`, and `HAIL_BUCKET`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10189:101,simpl,simply,101,https://hail.is,https://github.com/hail-is/hail/pull/10189,1,['simpl'],['simply']
Usability,"The issue it's solving: allows the dropdown be the requested 75% width of the table. In order to have this you need to set width on the parent of the table, and allow the table to stretch. Hard part is not having it stretch too much when it's empty. Easy alternative is to have the dropdown fixed width. For the double scroll: for very narrow views, I don't think you should see that anymore, unless the table is wider than 1024px. ; * For very wide views, if we set max-width: 100% on the parent, you can have a slightly nicer UX than would have had previously, in that the table is scrollable (so 1 scroll bar), but the search bar is no longer off screen (ex below). But now parent is full width. To solve this can add a media query for narrow views. I found another issue, this time in Safari, will PR. Or can revert, up to you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7786#issuecomment-580067553:528,UX,UX,528,https://hail.is,https://github.com/hail-is/hail/pull/7786#issuecomment-580067553,2,['UX'],['UX']
Usability,"The latest changes adopt the ""happy medium"" of having at all times either 0 or 1 NativeModule; objects corresponding to each lib, and a worker may get a shared ptr to what was constructed as; a master NativeModule. . In either case, the constructor is responsible for checking that lib already exists, or populating; it if it didn't exist. The big_mutex is held during constructors, in a way which a) protects the; module_table, and b) makes the transition from ""no lib file"" to ""complete and immutable lib file""; appear atomic, whether that occurs by invoking the makefile, or by writing binary data. Consequently, the makefile is simplified to just build $(MODULE).so without worrying about; atomicity, and the perl rename goes away. The loading is now done eagerly in the worker constructor, but still lazily for master-constructed; NativeModule's, since the most common lifecycle for a master is to construct it, do getKey, getBinary,; then throw it away without needing to load it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4211#issuecomment-417031457:632,simpl,simplified,632,https://hail.is,https://github.com/hail-is/hail/pull/4211#issuecomment-417031457,2,['simpl'],['simplified']
Usability,The latest changes to CI introduced a bug where an old build status; can be reported to GitHub because we do not always clear the; intended_github_status when we change the build_state. This PR; fixes that.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8410:120,clear,clear,120,https://hail.is,https://github.com/hail-is/hail/pull/8410,1,['clear'],['clear']
Usability,"The main goal of this PR was to remove some of the vector/scalar logic from the BlockMatrixMap2 node, and to support the scalar operations on BlockMatrixMap. I basically accomplished this by taking the cases that are matched on in BlockMatrixMap2 and lifting them into the Simplify rules. The only endpoint that I believe I needed to cover was the BlockMatrix.pyExecute() one; all the others will go through the usual CompileAndEvaluate. There's another part of the PR that fixes the variable bindings, which are currently hard-coded and unchecked. I needed this to construct the right expressions for the IR expressions, so I changed it to handle variable bindings with the rest of our IR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7566:273,Simpl,Simplify,273,https://hail.is,https://github.com/hail-is/hail/pull/7566,1,['Simpl'],['Simplify']
Usability,The most trivial loop is the loop which does not recur. I added a simple test and fixed Requiredness to handle this case.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12796:66,simpl,simple,66,https://hail.is,https://github.com/hail-is/hail/pull/12796,1,['simpl'],['simple']
Usability,"The new generic lines coerce code could produce a partitioner with unsafe values. Those unsafe values ended up in the Compile cache, which become invalid when owning region was cleared. This fixes the memory errors I was seeing when running with the local backend. It is possible it will fix (some?) of the errors you were investigating, @johnc1231.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8987:177,clear,cleared,177,https://hail.is,https://github.com/hail-is/hail/pull/8987,1,['clear'],['cleared']
Usability,The old error message for matmul was impossible to read. This is much clearer.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10298:70,clear,clearer,70,https://hail.is,https://github.com/hail-is/hail/pull/10298,1,['clear'],['clearer']
Usability,"The old query plan is here:; ```; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+-------------------------------+---------+---------------------------------------------+------+----------+-----------------------------------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+-------------------------------+---------+---------------------------------------------+------+----------+-----------------------------------------------------------+; | 1 | SIMPLE | billing_project_users | NULL | index | PRIMARY | PRIMARY | 204 | NULL | 3201 | 10.00 | Using where; Using index; Using temporary; Using filesort |; | 1 | SIMPLE | batches | NULL | ref | PRIMARY,batches_deleted,batches_token,batches_user_state,batches_time_completed,batches_billing_project_state | batches_billing_project_state | 102 | batch.billing_project_users.billing_project | 519 | 25.00 | Using where |; | 1 | SIMPLE | batches_n_jobs_in_complete_states | NULL | eq_ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 1 | 100.00 | NULL |; | 1 | SIMPLE | batches_cancelled | NULL | eq_ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 1 | 100.00 | Using index |; | 1 | SIMPLE | aggregated_batch_resources | NULL | ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 44 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 102 | batch.aggregated_batch_resources.resource | 1 | 100.00 | NULL |; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12049:870,SIMPL,SIMPLE,870,https://hail.is,https://github.com/hail-is/hail/pull/12049,1,['SIMPL'],['SIMPLE']
Usability,"The original UI redesign was intended to make it easier to navigate and focus on important information. I received very positive feedback on some aspects like this, for example having the different job steps in separate tabs. There was also feedback though that there was a lot of dead space. This is an attempt to find a good middle ground where the UI is not overwhelmingly cluttered but is more compact and makes better use of screen real estate",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14587:129,feedback,feedback,129,https://hail.is,https://github.com/hail-is/hail/pull/14587,2,['feedback'],['feedback']
Usability,"The original goal of this PR was avoiding `Try` when we are not using the restartability provided by semantic hashing because I strongly suspect it is related to the loss of stacktraces in exceptions. Unrelatedly, we realized the semantic hash PR changed the semantics of Query-on-Spark even when semantic hash is disabled: previously we would abort RDD writing on the first exception. In Hail 0.2.123 through 0.2.126, the semantics were changed to only crash *after* we already ran every other partition. Two bad scenarios of which I can think:. 1. Suppose the first partition fails due to OOM. We now waste time/money on the rest of the partitions even though we cannot possibly get a valid output. 2. Suppose every partition hits a permission error. Users should get that feedback after paying for O(1) partitions run, not O(N). I created two Backend paths: the normal `parallelizeAndComputeWithIndex` with its pre-0.2.123 semantics as well as `parallelizeAndComputeWithIndexReturnAllErrors` which, as the name says, returns errors instead of raising them. While making this change, I think I found two other bugs in the ""return all errors"" path, only one of which I addressed in this PR:. 1. I'm pretty sure semantic-hash-enabled QoB batch submission is broken because it uses the logical partition ids as job indices. Suppose there are 10,000 partitions, but we only need to compute 1, 100, and 1543. 0.2.126 would try to submit a batch of size 3 but whose job indices are 1, 100, and 1543. 2. Likewise, the Query-on-Spark path returns an invalid `SparkTaskContext.partitionId` which, at best, produces confusing partition filenames. I only fixed the former because it was simple to fix. I wasn't exactly sure what to do about the latter. We should fix that separately because the changes in this PR need to urgently land in the next release to avoid unexpected cost when one partition fails.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14085:775,feedback,feedback,775,https://hail.is,https://github.com/hail-is/hail/pull/14085,2,"['feedback', 'simpl']","['feedback', 'simple']"
Usability,The other issue is I'm getting a small negative value for the first time point on CPU. Not sure how to fix that. Maybe we just ignore it for now? Or revert back to the simpler code where we omit the first timepoint? Although I don't know how to represent NaN in binary data if we keep the first memory timepoint.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11368#issuecomment-1058213280:168,simpl,simpler,168,https://hail.is,https://github.com/hail-is/hail/pull/11368#issuecomment-1058213280,2,['simpl'],['simpler']
Usability,"The other option to fix this was to make `job_record_to_dict` have an extra layer of getopt everywhere, so I thought this was simpler.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7522:126,simpl,simpler,126,https://hail.is,https://github.com/hail-is/hail/pull/7522,1,['simpl'],['simpler']
Usability,"The previous implementation, while seeming to be well-abstracted at; first, actually had a rather devious property of creating agg states; for multiple classes multiple times. I'm still working on figuring out; *exactly* the place where our assumptions broke down, but this change; definitely fixes the problem, and simplifies the implementation by; directly using IR, instead of other compiled functions. This problem was a symptom of a larger issue, which is that the; ownership semantics of the current aggregator system is way too complex; to be coding against regularly. This all will go away when lowering is; complete, in favor of the *much* simpler set of IR nodes that are used; in lowering. We may need to address this problem sooner, though. CHANGELOG: Fixed memory leak affecting `Table.annotate` with scans, `hl.experimental.densify`, and `Table.group_by` / `aggregate`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9028:316,simpl,simplifies,316,https://hail.is,https://github.com/hail-is/hail/pull/9028,2,['simpl'],"['simpler', 'simplifies']"
Usability,"The problem I saw was this:. ToStream's invariant is that its children must be TIterable. Given this invariant, in boundary it is not safe to call ToArray on streamified when streamified.isInstanceOf[TStream] and node.typ.isInstanceOf[TArray], because this will miss cases (potentially) when node is a different TIterable, and likewise it is not safe to call ToArray on streamified when node.typ.isInstanceOf[TIterable], because we may inadvertently cast a non-array TIterable to TArray, and thereby break boundary's type invariance. So everywhere that we add a ToStream, we need to perform a check on the child: if it's a non-TArray TIterable, return it, else wrap in ToArray, unless we can be sure we never perform said wrap on a TIterable when streamify is called from boundary. . In the latest commit, I simplified the toStream code, and improved the type check to check not TContainer, but (TIterable && !TStream). This is more precise that checking TContainer alone. That being said I haven't created a convincing test yet (though it's trivially easy to make *a* test: pass a ToStream wrapping a node with typ TDict to boundary, with the old check on boundary, and a TIterable check-before-wrap-in-ToStream in the base case of streamify). However, I don't think we can avoid the condition you don't like in `boundary` without changing ToStream's child-type invariant to TArray.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-586553403:808,simpl,simplified,808,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-586553403,2,['simpl'],['simplified']
Usability,"The problem is that the `InsertFields` simplify rule was ignoring the `fieldOrder`, and thus potentially changing the type.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11340:39,simpl,simplify,39,https://hail.is,https://github.com/hail-is/hail/pull/11340,1,['simpl'],['simplify']
Usability,The project is at a point where it would be clearer to separate the dev stuff from the user stuff.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4477:44,clear,clearer,44,https://hail.is,https://github.com/hail-is/hail/issues/4477,1,['clear'],['clearer']
Usability,"The query in the scheduler was running incredibly slowly. So slowly, I didn't have the patience to let it finish. . ```; mysql> EXPLAIN; -> SELECT job_id, batch_id, spec, cores_mcpu,; -> ((jobs.cancelled OR batches.cancelled) AND NOT always_run) AS cancel,; -> userdata, user; -> FROM jobs; -> INNER JOIN batches ON batches.id = jobs.batch_id; -> WHERE jobs.state = 'Ready' AND batches.closed; -> LIMIT 50;; +----+-------------+---------+------+--------------------+---------+---------+-------------------+------+-------------+; | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |; +----+-------------+---------+------+--------------------+---------+---------+-------------------+------+-------------+; | 1 | SIMPLE | batches | ALL | PRIMARY | NULL | NULL | NULL | 31 | Using where |; | 1 | SIMPLE | jobs | ref | PRIMARY,jobs_state | PRIMARY | 8 | batch2.batches.id | 84 | Using where |; +----+-------------+---------+------+--------------------+---------+---------+-------------------+------+-------------+; 2 rows in set (0.01 sec); ```. This is because the query was querying closed batches, and then joining against jobs and using a where condition to find ready jobs. This is an insane execution plan and I still can't believe MySQL is choosing it by default. To fix this, I changed the inner join to a straight join: https://dev.mysql.com/doc/refman/5.6/en/join.html. Straight join is a MySQL extension that always scans the left table first. This leads to the correct execution plan which runs instantly:. ```; mysql> EXPLAIN; -> SELECT job_id, batch_id, spec, cores_mcpu,; -> ((jobs.cancelled OR batches.cancelled) AND NOT always_run) AS cancel,; -> userdata, user; -> FROM jobs; -> STRAIGHT_JOIN batches ON batches.id = jobs.batch_id; -> WHERE jobs.state = 'Ready' AND batches.closed; -> LIMIT 50;; +----+-------------+---------+--------+--------------------+------------+---------+----------------------+-------+-----------------------+; | id | select_ty",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7634:746,SIMPL,SIMPLE,746,https://hail.is,https://github.com/hail-is/hail/pull/7634,2,['SIMPL'],['SIMPLE']
Usability,The representation docs seem much clearer than the expr docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1669:34,clear,clearer,34,https://hail.is,https://github.com/hail-is/hail/pull/1669,1,['clear'],['clearer']
Usability,"The resulting rules are more succinct and correctly rely on file-system modification dependencies. - No use of `SPARK_HOME` and `PYTHONPATH`, and limited use of `PYSPARK_SUBMIT_ARGS`. Python tests now rely on the python package directly which handles correctly handles dependencies like `pyspark`. - There are also some phony targets for convenience: `jar`, `zip`, `pip-install`, `docs`, and `docs-no-test`. - Fix configuration of Spark version for the python package. The version is written by make into `python/spark_version` and read by `python/setup.py`. Many of the tests pass against 2.3.0, but there's some floating point value changes. - add breezeVersions for all currently released Spark versions greater than 2.2.0. - For developers, require python package `py` version 1.7.0 or later to allow `pytest` to test an installed package while loading the doctest expressions from the source code. (We could also determine where hail was installed and pass that path to pytest instead of `python/src`, but using the environment variable `PY_IGNORE_IMPORTMISMATCH` seems simple and safe enough). ---. ### Explainers. #### env_var.mk. This is a Makefile that is intended to be `include`d by other Makefiles. It defines a [multi-line variable](https://www.gnu.org/software/make/manual/html_node/Multi_002dLine.html) that [takes arguments](https://www.gnu.org/software/make/manual/html_node/Call-Function.html#Call-Function) (known in any reasonable language as a ""function""). It is intended to be used like this:. ```; VERSION = 30; $(eval $(call ENV_VAR,VERSION)). build: env/VERSION; build:; ... $(VERSION) ...; ```. Each time this Makefile is executed, at Makefile parse-time, `make` evaluates the `ifneq` to compare the current value of the variable to the previously used value (if any). If they differ, a phony (ergo always needs to be rebuilt) target is dynamically generated. That target will force a execution of any dependent targets, in the example above, it will force `build` to be exec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5130:2411,simpl,simple,2411,https://hail.is,https://github.com/hail-is/hail/pull/5130,1,['simpl'],['simple']
Usability,"The root issue here was that sometimes exc.args[0] was a string and sometimes it was a dict. When it was a string the `in` condition worked fine. When it was a dict, it was looking at the keys of the dict and not finding the error message (which is buried under a few layers). The code was unnecessarily complex. I reworked the yaml printer to be simpler and work for any multiline string. I removed the regular expression that was used to discover the worker batch when the worker jobs were in a different batch from the driver jobs. I remove all specialized debugging information in favor of the general `debug_info` methods on `Batch` and `ServiceBackend`. I also have two clear error cases: if the driver does not write its output file, then something went horribly wrong. We dump all the debug info. If we do not receive valid JSON from the driver, again, something went horribly wrong. We dump all the debug info. The only remaining exceptional case is an error purposely serialized by the QoB driver to us (with or without an error id). In particular, note that we now completely ignore the number of failing or successful jobs. That doesn't matter. If the driver sends us an output file, we use the data found there. If the driver does not send us an output file or sends us an output file without valid JSON, we dump as much debug info as possible. cc: @tpoterba for visibility on your end; cc: @iris-garden because you're in this space (albeit, the bug you're fixing is in the QoB *driver* whereas this is the *client* [nb: *client* is the Python code which starts a batch with a *driver*. A *driver* adds zero or more *worker* jobs to its batch. You're addressing an issue with how the *driver* handles errors from the *workers*. This PR simplifies the logic for how the *client* handles errors from the *driver*.]).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12470:347,simpl,simpler,347,https://hail.is,https://github.com/hail-is/hail/pull/12470,3,"['clear', 'simpl']","['clear', 'simpler', 'simplifies']"
Usability,"The simpler version is slower, but in the python test, not by a large amount (previous version was, in this test 23.8s or so, although Scala benches may show a larger difference). {""config"": {""cores"": 1, ""version"": ""0.2.28-7888aeb97570"", ""timestamp"": ""2019-12-04 02:07:13.182303"", ""system"": ""darwin""}, ""benchmarks"": [{""name"": ""make_ndarray_bench"", ""failed"": false, ""timed_out"": false, ""times"": [28.613776744999996, 28.361242108, 28.481231283]}]}. So 20% slower. I would prefer to use longs, because it doesn't feel right to me to leave performance on the table, however I'm ok with this tradeoff if you find it aligns with your goals better. ; - Regarding longs, to deal with alignment: right now we assume we're int aligned. To read longs, could we read the first 4 bytes as an int, then switch to longs, then do bits for the remaining length. Should be as terse. edit: I propose to put the unstaged version for a later time, but can do now as well.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7646#issuecomment-561510056:4,simpl,simpler,4,https://hail.is,https://github.com/hail-is/hail/pull/7646#issuecomment-561510056,2,['simpl'],['simpler']
Usability,"The site container polls regularly for new releases of hail and pulls the docs for the latest release. But we deploy site regularly enough that we can just include the latest release docs in the site build. Eventually, a deploy to PyPi should trigger a deploy of the site but this gets us part of the way there and simplifies things considerably.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9943:315,simpl,simplifies,315,https://hail.is,https://github.com/hail-is/hail/pull/9943,1,['simpl'],['simplifies']
Usability,"The slight increase in complexity is worth it for the code improvement.; We now will clearly support early truncation when possible (and can; enable the inner join benchmark to go through whole stage codegen),; and will propagate requiredness correctly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10758:85,clear,clearly,85,https://hail.is,https://github.com/hail-is/hail/pull/10758,1,['clear'],['clearly']
Usability,"There are a few small cosmetic changes in here that were a result of an updated pylint, but I put those in a separate commit to hopefully make that less confusing. There are a few follow-ups after this that I want to tackle; - simplifying the images for testing query (Dockerfile.hail-build, Dockerfile.hail-base, Dockerfile.hail-run). I think these are the only things that use `base_image` so we might be able to collapse a bunch of these; - updating to python 3.8 to avoid accidentally installing that in some of our images; - trying to produce eStargz images so that buildkit can lazily pull the base image when building new images. I hope that can bring some image build times down even further by not having to localize the installed pip dependencies when making changes to our python code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12578#issuecomment-1458470548:227,simpl,simplifying,227,https://hail.is,https://github.com/hail-is/hail/pull/12578#issuecomment-1458470548,2,['simpl'],['simplifying']
Usability,"There are some tiny formatting issues and typos, but the main thing is to add an short examples section in docs that makes clear what this is useful for. I'd put one example for INFO field and one for FORMAT field. For other commands for format, like:; https://hail.is/hail/hail.VariantDataset.html#hail.VariantDataset.pca",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1373#issuecomment-279790111:123,clear,clear,123,https://hail.is,https://github.com/hail-is/hail/pull/1373#issuecomment-279790111,2,['clear'],['clear']
Usability,"There is a [known issue](https://github.com/moby/moby/issues/41792) with the official Docker deb. If you uninstall docker and re-install it later, it might fail to start. The root cause is the `docker.socket` `systemd` unit failing to start because there are ""insufficient file descriptors available"". I think this is confusing verbiage. The socket's name must be `/var/run/docker.sock`. Clearly, if that filename is already in use, we cannot create a new socket at that filename. One of Google's [""Dataproc components""](https://cloud.google.com/dataproc/docs/concepts/components/overview) is Docker. I believe Google installed and then uninstalled docker in this image, thus leaving it in the broken state. For evidence of that:. <details>; <summary> find docker on a worker node of a *non-Hail* Dataproc cluster</summary>. ```; sudo find / -iname '*docker*'; ```. ```; /opt/conda/miniconda3/pkgs/dbus-1.13.6-h5008d03_3/info/recipe/patches/0004-disable-fd-limit-tests-not-supported-in-docker.patch; /opt/conda/miniconda3/pkgs/nbclassic-0.5.6-pyhb4ecaf3_1/site-packages/nbclassic/static/components/codemirror/mode/dockerfile; /opt/conda/miniconda3/pkgs/nbclassic-0.5.6-pyhb4ecaf3_1/site-packages/nbclassic/static/components/codemirror/mode/dockerfile/dockerfile.js; /opt/conda/miniconda3/pkgs/notebook-6.2.0-py38h578d9bd_0/lib/python3.8/site-packages/notebook/static/components/codemirror/mode/dockerfile; /opt/conda/miniconda3/pkgs/notebook-6.2.0-py38h578d9bd_0/lib/python3.8/site-packages/notebook/static/components/codemirror/mode/dockerfile/dockerfile.js; /opt/conda/miniconda3/lib/python3.8/site-packages/nbclassic/static/components/codemirror/mode/dockerfile; /opt/conda/miniconda3/lib/python3.8/site-packages/nbclassic/static/components/codemirror/mode/dockerfile/dockerfile.js; /opt/conda/miniconda3/lib/python3.8/site-packages/notebook/static/components/codemirror/mode/dockerfile; /opt/conda/miniconda3/lib/python3.8/site-packages/notebook/static/components/codemirror/mode/dockerfile/docker",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936#issuecomment-1709120751:388,Clear,Clearly,388,https://hail.is,https://github.com/hail-is/hail/issues/12936#issuecomment-1709120751,1,['Clear'],['Clearly']
Usability,"There is occasional use of this in other projects, e.g., gnomad_methods (`SimpleRichProgressBar` in this case). Do you consider these classes to be part of the API? Was it intended to rename these without any compatibility shim, e.g., having the old names as aliases for a while?. It's not the end of the world and gnomad_methods has already updated accordingly. It does however mean that older gnomad_methods is only compatible with hail ≤ 0.2.125 and newer gnomad_methods is only compatible with hail ≥ 0.2.126, which is an otherwise unnecessary lock-step restriction. ETA: gnomad_methods have now updated by removing the (apparently unused) progress bar reference, so now newer gnomad_methods is compatible with hail both ≤ 0.2.125 and ≥ 0.2.126 again. So this is no longer a significant problem for gnomad_methods, but remains FYI.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13832#issuecomment-1788106993:74,Simpl,SimpleRichProgressBar,74,https://hail.is,https://github.com/hail-is/hail/pull/13832#issuecomment-1788106993,3,"['Simpl', 'progress bar']","['SimpleRichProgressBar', 'progress bar']"
Usability,There is room to simplify rules,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5506:17,simpl,simplify,17,https://hail.is,https://github.com/hail-is/hail/issues/5506,1,['simpl'],['simplify']
Usability,"There may also be a way of handling the intended effect using alpha blending, but this works and is a simple fix.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8964#issuecomment-644687247:102,simpl,simple,102,https://hail.is,https://github.com/hail-is/hail/pull/8964#issuecomment-644687247,2,['simpl'],['simple']
Usability,"There was a logic error in constructFromIndicesUnsafe, if a missing value was pushed, pushing a present value with the same index would not clear the missing bit.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13263:140,clear,clear,140,https://hail.is,https://github.com/hail-is/hail/pull/13263,1,['clear'],['clear']
Usability,"There was some real bad capture/broadcast issues in VCFsReader. I made the following changes:. - import_vcfs requires the signature of all files to be the same,; - compute the type once from the first file,; - verify the types agree when parallelizing over files computing the partitions,; - always broadcast the header lines (which can be large). This reduced the DAGScheduler RDD broadcast by about 4x (6MB => 1.4MB) on a simple 10-input pipeline of import_vcfs/transform_one/combine/write_multi.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5507:424,simpl,simple,424,https://hail.is,https://github.com/hail-is/hail/pull/5507,1,['simpl'],['simple']
Usability,"There were two sources of deadlocks:. 1. The attempt resources were not inserted in the same order in the aggregated_*_resources tabes between the two triggers `attempt_resources_after_insert` and `attempts_after_update`. One had jobs -> batches -> billing projects and the other had billing_projects -> batches -> jobs. We also were inserting the resources in a different order in the two triggers. I solved the ordering issue by making sure we `INSERT MANY` the resources in alphabetical order. 2. Once I fixed (1), then the next set of errors were in `add_attempt`. We were locking the `instances_free_cores_mcpu` table only if the attempt didn't already exist. This was causing cryptic deadlock errors like this:. ```; ------------------------; LATEST DETECTED DEADLOCK; ------------------------; 2022-06-23 18:08:12 0x7f1807665700; *** (1) TRANSACTION:; TRANSACTION 1215034153, ACTIVE 0 sec starting index read; mysql tables in use 1, locked 1; LOCK WAIT 21 lock struct(s), heap size 1136, 12 row lock(s), undo log entries 5; MySQL thread id 962402, OS thread handle 139741222766336, query id 6809292838 10.32.5.50 jigold updating; UPDATE instances_free_cores_mcpu; SET free_cores_mcpu = free_cores_mcpu + cur_cores_mcpu; WHERE instances_free_cores_mcpu.name = in_instance_name; *** (1) WAITING FOR THIS LOCK TO BE GRANTED:; RECORD LOCKS space id 1578686 page no 3 n bits 72 index PRIMARY of table `jigold`.`instances_free_cores_mcpu` trx id 1215034153 lock_mode X locks rec but not gap waiting; Record lock, heap no 3 PHYSICAL RECORD: n_fields 4; compact format; info bits 0; 0: len 30; hex 62617463682d776f726b65722d6a69676f6c642d7374616e646172642d62; asc batch-worker-jigold-standard-b; (total 34 bytes);; 1: len 6; hex 0000486bf32c; asc Hk ,;;; 2: len 7; hex 600001287513cb; asc ` (u ;;; 3: len 4; hex 80002de6; asc - ;;. *** (2) TRANSACTION:; TRANSACTION 1215034156, ACTIVE 0 sec inserting; mysql tables in use 6, locked 6; 22 lock struct(s), heap size 1136, 13 row lock(s), undo log entries",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11959:1011,undo,undo,1011,https://hail.is,https://github.com/hail-is/hail/pull/11959,1,['undo'],['undo']
Usability,"There's a few things happening here:. ### Node pool updates through terraform; I extended the node pool update documentation with how to deal with terraform-managed node pools. This is what I did on Azure and worked fine. The only real change in terraform other than changing the machine type is making the node pool name configurable to adhere to the naming guidelines and allow us to do a rolling migration. ### Updated the kubernetes and azurerm providers; I updated the azurerm provider without thinking much about it and even though it's a minor version had some breaking changes that after a half-successful `apply` made it hard to downgrade. So I decided just to appease the breaking change and leave us at the new version, which is what all the `blob_properties` changes are for. They are in no way related to the node pools. ### Troubleshooting; I added a section for a bug that I've seen a couple of times (and encountered again today) but never documented how I got around it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11636:359,guid,guidelines,359,https://hail.is,https://github.com/hail-is/hail/pull/11636,1,['guid'],['guidelines']
Usability,There's a kind of unrelated thing: Fix reading of configuration information to not ignore a hailctl configuration value of `''` . The big change is to introduce 3 progress bar systems:; 1. SimpleRichProgressBar. One progress bar active at a time.; 2. RichProgressBar. More than one progress bar active at a time.; 3. BatchProgressBar. Same as RichProgressBar but with default columns good for monitoring 1 or more Hail Batch batches.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12346:163,progress bar,progress bar,163,https://hail.is,https://github.com/hail-is/hail/pull/12346,4,"['Simpl', 'progress bar']","['SimpleRichProgressBar', 'progress bar']"
Usability,"There's more work to be done here. This adds a new route to the batch UI for getting a certain job group within a batch. It then, instead of listing all jobs, only lists the jobs that belong directly to the currently viewed job group and also shows the child job groups of the current job group. When picking up this PR I would make sure to go through the Batch development tutorial to make sure you are familiar with dev deploying. Then, read [this](https://github.com/hail-is/hail/blob/main/dev-docs/development-process.md#alternatives-to-dev-deploy) to learn about all the ways you can avoid dev deploying 😄 . If you are only making tweaks in the HTML templates, you don't need to keep deploying for every little change. Instead, run. ```bash; make devserver SERVICE=batch; ```. in your terminal and you'll get a local server that proxies the Batch that your `hail` installation is pointed to. You can then make changes to HTML and refresh your browser to see the results. Note that this is just rendering the HTML locally, and will have any effect on what's deployed, meaning you can't use it for python changes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14600#issuecomment-2239854998:556,learn,learn,556,https://hail.is,https://github.com/hail-is/hail/pull/14600#issuecomment-2239854998,2,['learn'],['learn']
Usability,"These are doc corrections/improvements I'd made in #3825 but then removed from #3833, except for the name changes that would break interface. I'd like to get feedback on those at check-in.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3875:158,feedback,feedback,158,https://hail.is,https://github.com/hail-is/hail/pull/3875,1,['feedback'],['feedback']
Usability,"These are good thoughts. I agree that a visually clean format will make the guides easier for people to use. I like the idea of hiding the explanation underneath a clickable thing. I'd be hesitant to completely remove the explanatory text, because I think people will be more likely to use the how-to guides than to go through an entire tutorial, but making it optional is a good middle-ground. I can experiment on one of the files, before I do them all, so we can settle on a good format.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4089#issuecomment-411940112:76,guid,guides,76,https://hail.is,https://github.com/hail-is/hail/pull/4089#issuecomment-411940112,4,['guid'],['guides']
Usability,"These examples suggest to me that the main problem is loss of type specificity in the substituted type. As for digging through the fields of `TVariant`, I personally am not bothered by `vt.gr.inXPar _`. I don't see any simple way to preserve the fact that `vt` will be a `TVariant`. I'll modify it to the approach you suggested.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2226#issuecomment-334178886:219,simpl,simple,219,https://hail.is,https://github.com/hail-is/hail/pull/2226#issuecomment-334178886,2,['simpl'],['simple']
Usability,These upgrades are simple and do not represent major version upgrades.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10830:19,simpl,simple,19,https://hail.is,https://github.com/hail-is/hail/pull/10830,1,['simpl'],['simple']
Usability,"Things aren't really consistent, so there's no clear pattern to follow. I'm happy to mimic python set/list functionality",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1491#issuecomment-284746931:47,clear,clear,47,https://hail.is,https://github.com/hail-is/hail/pull/1491#issuecomment-284746931,2,['clear'],['clear']
Usability,Things to simplify when renaming fields is free,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5202:10,simpl,simplify,10,https://hail.is,https://github.com/hail-is/hail/issues/5202,2,['simpl'],['simplify']
Usability,"This PR Python-izes all but the LocalLDPrune step of `ld_prune` while adding modular functionality for window indices that also simplifies computing big banded correlation (where the band is in terms of position, centimorgans, or any other non-decreasing value per contig). I later plan to simplify computing correlation, but basically:; ```; ld_matrix = ... BlockMatrix stuff starting from mt ...; starts, stops = hl.locus_windows(mt.rows(), radius=1e6); banded_ld_matrix = ld_matrix.sparsify_row_intervals(starts, stops); ```; Or if centimorgan coordinates are a row field (via annotation or import from plink format):; ```; ht = mt.rows(); starts, stops = hl.locus_windows(ht, radius=1e6, value_expr=ht.centimorgans); ```. Changes:; - added `array_windows` to methods/misc, with docs and test.; - added `locus_windows` to methods/genetics, with docs and test.; - reworked `ld_prune` to use `locus_windows` and `sparsify_row_intervals`, moved squaring op from expression language to block matrix `r2_bm`, moved arg checks from scala to python.; - then deleted `UpperIndexBounds`, `UpperIndexBoundsSuite`, `BlockMatrix.filteredEntriesTable` and tests.; - improved `test_ld_prune` and modified `ldprune.vcf` to make it much smaller and span three chromosomes instead of one for better testing; - allowed `sparsify_row_intervals` to accept ndarrays so user need not convert output of `locus_windows` (which should naturally be an ndarray) with `[int(s) for s in starts]`. If the arg checking or py4j communication become a bottleneck, we can add passage through file similar to what we do for arrays of doubles.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3715:128,simpl,simplifies,128,https://hail.is,https://github.com/hail-is/hail/pull/3715,2,['simpl'],"['simplifies', 'simplify']"
Usability,"This PR adds stream nodes `StreamMultiMerge` and `StreamZipJoin`, which will be used to implement `TableUnion` and `TableMultiWayZipJoin`. The two nodes were so similar, both in implementation and in interface, that I thought bundling them into one PR would actually make it *easier* to review, but I can split them up if you disagree. The implementations of both nodes use tournament trees, a very simple data structure ideal for this problem. Think of it as a priority queue specialized to holding exactly `k` elements, so when you pop the top element, you must immediately replace it with a new value. A tournament tree is just what it sounds like. It is a complete binary tree with `k` leaves. Conceptually, the leaves hold the current `k` elements (the heads of each of the `k` input streams), while each internal node records the result of the comparison between the ""winners"" of the two subtrees, where in this case the winner is the least element. Thus we can find the smallest of all `k` elements by looking at the root node. If we remove the smallest element, and replace it with the next value from that stream, we change the value in the corresponding leaf node, then we just need to replay the comparisons at all internal nodes on the path to the root. Note that to replay a comparison, we only need to know what element *lost* at this node previously. It must have lost to the previous overall winner, the element we just replaced. Using that observation, we only need to store the `k` current values in the `k` leaves, and in each of the `k-1` internal nodes we store the index of the element which lost the comparison at that node. That just leaves the overall winner, which we can store in a separate variable. Note that each element besides the overall winner loses exactly one ""match"", so the internal nodes store a permutation of the indices 0 to (k-1), minus the overall winner. This is a so-called ""loser tree"". In the implementation, I store the `k` leaves in a `Array[Long]`, w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9033:399,simpl,simple,399,https://hail.is,https://github.com/hail-is/hail/pull/9033,1,['simpl'],['simple']
Usability,"This PR adds support for Azure SAS tokens in QoB. A SAS token is basically a blob storage URI with a short-lived credential to access that resource appended as a URL query string. In such a scenario where the FS receives a blob URI with a SAS token, that token should be used instead of the latent credentials on the system. Most of the changes to the `AzureStorageFS.scala` are to parse out a SAS token from blob names. This change brings with it a couple caveats. Unfortunately it is not possible to truly disambiguate a SAS token from a glob pattern, or even just a normal blob filename. So we take what is probably a safe assumption and look to see if there exists a query-parameter style key-value pair after the last `?` in the blob name. If this is the case, we treat everything after the last `?` as a SAS token. If this condition is not satsified, we say there is no SAS token and treat the whole path as the blob name. This logic already exists in python, but I'm open to alternatives. Introducing SAS tokens also breaks the way globbing is currently implemented, where it is deemed safe to iteratively append components to the end of a blob URI string. I added an abstract type member to `FS` and instead of a `String` have `globWithPrefix` accept that associated URL type that can properly handle path updates. I'm unclear on the best way to do this w.r.t. the type system, and wasn't quite sure what to put as the associated type for `RouterFS`, which ideally would accept a union of the URL types for the filesystems that it wraps, so some guidance on that would be great if you have any.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13178:1554,guid,guidance,1554,https://hail.is,https://github.com/hail-is/hail/pull/13178,1,['guid'],['guidance']
Usability,"This PR attempts to make CI more useful as a developer feedback tool. Developers need to know the success/failure state of their PR ASAP. It is better to know that state for an old tip sha pair than to know nothing. It is better still to know that state for a more recent sha pair. It is best to know that state for the tip sha pair. We aim to test a PR's tip source sha (perhaps against an out of date target sha). ---. Our *target state* for remembering batches is:; - one is complete and the other is in-progress; the complete one is for an out-of-date tip sha pair, or ; - only one batch is in-progress or complete; it's for the tip sha pair. We forget an in-progress batch for a PR only if:; - a batch for a more recent sha pair is complete, or; - a more recent, but not tip, source sha build is also in progress. As is the case for our services, at any time we may not be in our target state. For CI, if we are not in our target state, `_refresh` and `_heal` are intended to move us towards the desired state. `_refresh` incorporates new GitHub information. `_heal` incorporates new batch state and perturbs batch as necessary. cc: services crew: @akotlar, @jigold . EDIT:. I've gone round and round with my thoughts on what the right idea here is. I would appreciate some discussion around what we should aim for.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6007:55,feedback,feedback,55,https://hail.is,https://github.com/hail-is/hail/pull/6007,1,['feedback'],['feedback']
Usability,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9554:20,simpl,simplify,20,https://hail.is,https://github.com/hail-is/hail/pull/9554,2,['simpl'],"['simplified', 'simplify']"
Usability,"This PR begins the implementation of checkpointing and restoring of jobs in Batch. Currently, a container is checkpointed after 10 seconds and before running a container (using crun run) the worker container checks if it should restore a job based on a checkpoint in Google storage. Currently, the kinds of Jobs that can be checkpointed/restored are: jobs that do simple operations and only print to stdout, jobs that redirect their output to local files. Changelist:; - Add copy method to RouterAsyncFS; - Add checkpointable flag to containers (make DockerJob containers checkpointable and JVMJob containers not checkpointable); - Create checkpoint method which pauses a container, checkpoints it, copies the checkpoint directory and upper directory of the overlay into Google storage, and then resumes the container; - Add logic in _run_container to try copying checkpoint directory and upper directory from cloud storage and then running `crun restore` if the job is checkpointable",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11888:364,simpl,simple,364,https://hail.is,https://github.com/hail-is/hail/pull/11888,3,"['pause', 'resume', 'simpl']","['pauses', 'resumes', 'simple']"
Usability,"This PR begins to implement the infrastructure needed for reproducible randomness. The main components are:; * An implementation of the Threefish block cipher, reduced to 20 rounds as in Threefry [1], but keeping the tweak from Threefish (really just the first 64 bits, the second 64 bits are always 0). The specification for Threefish can be found in [2].; * An implementation of the `jdistlib.RandomEngine` interface using Threefish, so that we can continue using the `jdistlib` implementations of sampling from various distributions.; * This has some improvements over the standard Java RNG implementations of random floating point numbers, and of random integers from a specified interval. See comments in the code for details.; * The beginnings of a new type `(S/T)RNGState`. This implements a splittable RNG interface, similarly to [3], but instead of the cascade construction, we use a modification of PMAC [4] to build a psuedo-random function from a blockcipher. This allows us to reorder the processing of blocks of the input, in particular moving computation to compile time as much as possible.; * A simple test suite for the new RNG using a chi-square test. [1] ""Parallel random numbers: as easy as 1, 2, 3"", http://www.thesalmons.org/john/random123/papers/random123sc11.pdf; [2] ""The Skein Hash Function Family"", https://www.schneier.com/wp-content/uploads/2015/01/skein.pdf; [3] ""Splittable pseudorandom number generators using cryptographic hashing"", https://publications.lib.chalmers.se/records/fulltext/183348/local_183348.pdf; [4] ""Efficient Instantiations of Tweakable Blockciphers and Refinements to Modes OCB and PMAC"", https://www.cs.ucdavis.edu/~rogaway/papers/offsets.pdf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11605:1112,simpl,simple,1112,https://hail.is,https://github.com/hail-is/hail/pull/11605,1,['simpl'],['simple']
Usability,"This PR changes the way loop memory management works. . Previously, memory used while in the loop was allocated in one region, with no cleanup happening between loops. A long running loop that did a lot of allocation could therefore easily cause hail to run out of memory. This PR fixes that by creating two regions for each loop. Every iteration, we emit everything in region 1, copy the state that is necessary to region 2, then clear region 1. Then we swap the regions and repeat this until the loop terminates.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10233:431,clear,clear,431,https://hail.is,https://github.com/hail-is/hail/pull/10233,1,['clear'],['clear']
Usability,"This PR drastically simplifies the hail/elasticsearch story. We no longer require any special custom built JAR from google cloud (was necessary because there was a time when Spark 3 compatible ES wasn't on Maven). Also allow ES version 7 or 8 when on Spark 3, and don't require that it's Spark 3.1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11410:20,simpl,simplifies,20,https://hail.is,https://github.com/hail-is/hail/pull/11410,1,['simpl'],['simplifies']
Usability,"This PR enables calling QR decomposition via LAPACK. It's passing all the tests, and I've made some initial cleanup passes, but there's probably more that could be done to simplify this. . I referenced the numpy QR implementation when doing this, it may be helpful to understand the goal outside of the dealing with all the overhead of reading staged code: https://github.com/numpy/numpy/blob/0aeab48b9e914d1dc7041b7e3f3b7e575ffcbbed/numpy/linalg/linalg.py",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7682:172,simpl,simplify,172,https://hail.is,https://github.com/hail-is/hail/pull/7682,1,['simpl'],['simplify']
Usability,"This PR generates documentation for all current ndarray functionality. Wondering if to coincide with this we should also remove the `_` from `hl._nd`. I mostly had it there so people wouldn't poke at undocumented functionality, but this seems to work ok now. . Resolves #7531",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7688:200,undo,undocumented,200,https://hail.is,https://github.com/hail-is/hail/pull/7688,1,['undo'],['undocumented']
Usability,"This PR implements the beginning of the EmitCode and CodeBuilder change discussed here: https://dev.hail.is/t/on-the-subject-of-emittriplet/183/7. The codegen rule for ArrayRef is now the delightfully clear and concise:. ```; EmitCode.fromI(mb) { cb =>; emit(a).toI(cb).flatMap(cb) { (ac) =>; emit(i).toI(cb).flatMap(cb) { (ic) =>; val av = ac.asIndexable.memoize(cb, ""aref_a""); val iv = cb.memoize(ic.tcode[Int], ""aref_i""). cb.ifx(iv < 0 || iv >= av.loadLength(), {; cb._fatal(errorTransformer(; const(""array index out of bounds: index=""); .concat(iv.toS); .concat("", length=""); .concat(av.loadLength().toS))); }); av.loadElement(cb, iv); }; }; }; ```. Summary of changes:. Introduce CodeBuilder. CodeBuilder allows for the imperative, sequential construction of code. The idea is that it is the imperative analog of Code[Unit]. In this analogy, a function returning Code[Unit] becomes a function that takes a CodeBuilder, alternatively, a Code[Unit] can become a CodeLabel: the place to jump to run a given computation. In addition to CodeBuilder, I have a imperative implementation of EmitCode that is similar to the proposal in the dev post: IEmitCode. Under the above analog, the proposal in the dev post would become:. ```; trait IEmitCode {; def apply(missing: (CodeBuilder) => Unit, present: (CodeBuilder, PValue) => Unit): Unit; }; ```. However, I took the additional step of ""defunctionalizing"" this picture by using labels instead of functions of code, giving:. ```; case class IEmitCode(Lmissing: CodeLabel, Lpresent: CodeLabel, pc: PCode) {; ...; }; ```. In this model, the emit function will become: `Emit.emit(cb: CodeBuilder, ...): IEmitCode`. The discipline is after calling `emit`, the contents of the code builder, when executed, will jump to one of `Lmissing` or `Lpresent` (labels which are not defined yet) and the consumer can define those labels, and use the expression `pc` in the code after the `Lpresent` label only. Because obviously I haven't converted everything to the i",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8245#issuecomment-600899413:201,clear,clear,201,https://hail.is,https://github.com/hail-is/hail/pull/8245#issuecomment-600899413,2,['clear'],['clear']
Usability,"This PR includes the PDF of the Hail Tables cheatsheet. I'll add the powerpoint file as well once someone has approved the pdf so that others can change in the future. If github is just complaining that it's a binary file and doesn't show the preview, click the ""..."" on the right hand side of the filename bar thing and click ""view file"". Any feedback is welcome. . Fixes #5388 (though we should make a new issue for adding a matrix table cheat sheet). Assigned to Tim, but also put Gopal on it since he's been thinking about tutorials",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7544:344,feedback,feedback,344,https://hail.is,https://github.com/hail-is/hail/pull/7544,1,['feedback'],['feedback']
Usability,"This PR introduces a generic pretty-printing package, which for now is only used in `ir.Pretty`. The primary motivation was to separate format specification from rendering, to simplify the formatting code, and make it easier to add multiple formatting options, including forms with line number references. Some nice properties of the new pretty-printer:; * Generic. Should be able to be used for all pretty-printing in hail scala code. This simplifies the codebase by making client pretty-printers easy to understand and modify, without getting bogged down in low-level details.; * Composable. Formatting specifications are trivially combinable, without needing to manually track context like the current indentation level, max line length, etc.; * Stack safe. Uses constant stack space.; * Uses constant heap space. Only keeps in memory text which might print in the current line, if it fits. (The pretty printer writes to a `java.io.Writer`, and I'm ignoring any heap space used by the writer.); * Lazy. If the number of lines to print is capped, doesn't scan more of the tree than is needed to print those lines.; * Produces more readable output, printing nodes on a single line where possible. As we work to increase visibility into the compiler, I think this will be very helpful. A formatted document is represented by the `Doc` type. This defines a `render` method, which takes three parameters to control the output:; * `width`: the maximum length of a line, including indentation; * `ribbonLength`: the maximum length of a line, not including indentation (too many characters on a line is hard to read, regardless of indentation); * `maxLines`: the maximum number of lines to print. There are only a few `Doc` constructors, which suffice to define all methods in the richer api contained in the `prettyPrint` package object.; * `Text(t: String)`; * `Line(ifFlat: String)`; * `Indent(i: Int, body: Doc)`; * `Concat(it: Iterable[Doc])`; * `Group(body: Doc)`. Ignoring `Group` for the moment, th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9652:176,simpl,simplify,176,https://hail.is,https://github.com/hail-is/hail/pull/9652,2,['simpl'],"['simplifies', 'simplify']"
Usability,"This PR introduces a second region `eltRegion` into the `emitStream` environment, and plumbs it through everywhere it is needed. One complication is that the `eltRegion` for a stream bound in the environment (e.g. in a `StreamMap` over a `Stream[Stream[A]]`) must be set by the consumer of the stream, so the `PCanonicalStreamCode` stored in the environment needs to be a function `Code[Region] => SizedStream`. For the most part, this PR leaves the `eltRegion`s unused. In the new semantics, explained below, it is still correct for a producer to only use the `outerRegion`, and for a consumer to pass the same region for both `outerRegion` and `eltRegion`. This lets us migrate to the new memory management one node at a time. When I talk about correctness, I mean that: no pointer is used after the region it points into has been freed; and, every region which is created is eventually freed. When reasoning about correctness, I consider `r.clear()` equivalent to `r.invalidate(); r.getNewRegion()`. As a demonstration of how this should work, this PR does convert `EmitStream.{toArray, write}` to use `eltRegion` correctly, which are used in the consumer nodes `ToArray`, `ArraySort`, `ToSet`, `ToDict`, and `GroupByKey`. Going forward, the plan is to convert the rest of the consumer and producer nodes, before converting the transformer nodes (which both consume and produce streams), as correctness can only be tested on pipelines in which all nodes have been converted. ### Semantics. A stream producer is passed two regions from its consumer: `outerRegion` and `eltRegion`. The node being emitted does not own either region, so may not free/clear them. The only thing a producer may do with either region is to put data in them, by writing directly to them or by giving/sharing ownership of a producer-owned region to them. Consumers' contract:; * The lifetime of `outerRegion` must contain the lifetime of the producer stream, i.e. `outerRegion` must be valid before the producer's `setup0` ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9106:944,clear,clear,944,https://hail.is,https://github.com/hail-is/hail/pull/9106,1,['clear'],['clear']
Usability,"This PR is a first step towards full debug information in generated bytecode. It lays the foundation in lir, and uses it to add line numbers to generated exceptions, which then show up in the stack trace. The line numbers are computed by taking the stack trace in `Code._fatal`, and finding the most recent line in `Emit.scala`, if any. Sometimes this will be less useful, e.g. exceptions thrown in aggregators, but it's a step. The design of the source location tracking in lir is very simple: every instruction has an associated line number, and `lir.Emit` watches for when the line numbers of the current and previous instruction are different, and emits the start of a new line number interval. This design might be slightly wasteful of memory, if we expect groups of several consecutive instructions to come from the same source line, but it's probably fine, and makes preserving the source location information through lir transformations trivial. In any case, I expect it to be easy to change in the future if necessary.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9499:487,simpl,simple,487,https://hail.is,https://github.com/hail-is/hail/pull/9499,1,['simpl'],['simple']
Usability,"This PR is a step towards a general picture for generating debugging information in bytecode. The general picture is to write a sequence of files, each corresponding to a certain point in the compile pipeline, where each line in each file includes a line number pointing to the line in the previous file from which this line was derived. (We may eventually want richer source information than just a single line number, like a range or list of ranges.) The top of each file has the file name of the previous printout, which is the target of all line numbers in the file. We could in the future also print a list of transformations that were applied to get from the previous printed state to this one. The idea to implement this picture is simple. Each IR node stores a line number in a mutable variable. When we want to generate a printed checkpoint, we walk the IR, printing a representation of each node, including the stored line number, and then overwriting the node's line number with the current line count of the file being written to. Some work will be required to preserve this source information in all IR transformations. This PR implements this idea in lir only. If the `HAIL_WRITE_IR_FILES` environment variable is set, it is hardcoded to print the lir after the first `SimplifyControl` (because before that is very hard to read), and after method splitting right before emitting bytecode. It also prints out the class files themselves. Longer term we'll want to be able to control which points in the compilation get printed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9521:739,simpl,simple,739,https://hail.is,https://github.com/hail-is/hail/pull/9521,2,"['Simpl', 'simpl']","['SimplifyControl', 'simple']"
Usability,"This PR is needed for atomic batch creation where the job_id is 0 to n_jobs and is not unique across batches. - Job now has a compound key in the database (batch_id, job_id); - Job.id on the server side is `(batch_id, job_id)`; - Batch on the client side has been modified to not require the attributes since Job now needs a reference to the batch.; - Changed some routes to be '/batches/{batch_id}/jobs/{job_id}/...`; - Changed the appropriate places in ci2 and pipeline that use the job status interface; - Changed the create_job interface for parents to take the Job objects and not the id. I think this is clearer and will allow me to check the batch of the Job is the correct batch in the future.; - deleted creating batch from a file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6183:610,clear,clearer,610,https://hail.is,https://github.com/hail-is/hail/pull/6183,1,['clear'],['clearer']
Usability,"This PR is not ready to be merged, but I want feedback.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3470:46,feedback,feedback,46,https://hail.is,https://github.com/hail-is/hail/pull/3470,1,['feedback'],['feedback']
Usability,This PR lowers `TableParallelize` and beefs up the tests for parallelize a bit. If you see a simpler formulation of the math to compute `start` and `length` let me know.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8596:93,simpl,simpler,93,https://hail.is,https://github.com/hail-is/hail/pull/8596,1,['simpl'],['simpler']
Usability,"This PR makes the following changes:; * Add a `separateRegions` flag to `PStream`.; * Add a `separateRegions` flag to the stream producer nodes `MakeStream`, `StreamRange`, and `ToStream`.; * Propogate `separateRegions` through all stream nodes in `InferPType`. The intended semantics is that if a stream's type has the `separateRegions` flag set, its consumer must pass it a region which gets cleared every element. If the flag is not set, there is no requirement; depending on context, the consumer may put every element in the same region, but is also allowed to use separate regions for each element. For example, in a zip, the elements of the zipped stream are put in separate regions iff at least one child stream requires separate regions; in that case, all children will get emitted with separate regions, whether they requested it or not. In this PR, the `separateRegions` flags are left unused. Eventually, stream consumers will inspect the flag on their child streams' types, and use that information to construct the appropriate `StagedRegion` to pass to `emitStream`. In implementing that, I did some refactoring of the `StagedRegion` design, which I separated out into a follow-up PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9388:394,clear,cleared,394,https://hail.is,https://github.com/hail-is/hail/pull/9388,1,['clear'],['cleared']
Usability,"This PR prepares the way to remove `UnpartitionedRVD` and `RVD`, but stops before doing so to keep things simple. The changes are probably easiest to understand one commit at a time, because it actually worked out quite cleanly. I'll describe each commit, to make review easier:; * **remove `TableValue.enforceOrderingRVD`** - I could have removed `enforceOrderingRVD` earlier, as soon as tables were always sorted by key. This also loosens the `TableValue` invariant: Before, we required that if `key=None` then the `rvd` is an `UnpartitionedRVD`, but it was okay to have `key=Some(..)` and an `UnpartitionedRVD`. Then, once all tables were sorted by key, I strengthened it to `key=None` if and only if `rvd` is an `UnpartitionedRVD`. Now, I'm weakening it in the other direction, to allow `key=None` with `rvd` an `OrderedRVD`, possibly with some non-empty key. This is consistent with the rule that the `rvd` must always have a stronger/longer key than the `TableType`.; * **small tweaks** - Now I start working through the `TableIR` nodes, rewriting them to remove explicit uses of `UnpartitionedRVD`. The general plan is to sandwich the rvd logic between `toOrderedRVD` and `toOldStyleRVD`. The first takes an `UnpartitionedRVD` to an `OrderedRVD` with empty key (and leaves `OrderedRVD`s alone), and the second takes an `OrderedRVD` to an `UnpartitionedRVD` if its key was empty, and leaves it alone otherwise. Once they're all rewritten this way, I redefine `toOldStyleRVD` to always return `OrderedRVD`, and `UnpartitionedRVD` is no longer used.; * **remove `TableUnkey`** - With `UnpartitionedRVD` going away, `TableUnkey` is no longer necessary, it's equivalent to keying by an empty key.; * **small tweaks** - these next two rewrite more `TableIR` nodes; * **Merge master** - the big one; * **tweak MatrixColsTable** - 1) Optimize `coerce` by checking if the requested key is empty, avoiding a scan in that case. 2) Optimize `sortedColsValue` by checking if the column key is empty, avoidin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4319:106,simpl,simple,106,https://hail.is,https://github.com/hail-is/hail/pull/4319,1,['simpl'],['simple']
Usability,This PR refactors the aioclient to merge the functionality of Batch and BatchBuilder into just a single Batch object. The reason for making this change is to make adding job groups simpler. I will follow up with a change to Jobs after this merges. I apologize for the number of line changes. Most are just renaming `bb -> b` in the tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13458:181,simpl,simpler,181,https://hail.is,https://github.com/hail-is/hail/pull/13458,1,['simpl'],['simpler']
Usability,"This PR removes the `as_array` parameter on `pca` and `hwe_normalized_pca`. The scores and loadings tables are constructed to always have a field of array type, mirroring the eigenvalues array. This simplifies the interface and makes pipeline (and PC indexing) behavior more predictable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3280:199,simpl,simplifies,199,https://hail.is,https://github.com/hail-is/hail/pull/3280,1,['simpl'],['simplifies']
Usability,"This PR should fail because the gsa key is not in the test namespace -- I think we should have a second user account for testing. Still to do is to expose all of the user key infrastructure in the batch `Makefile` and `test-locally` in pipeline and ci. At some point, we should consolidate the `google_storage.py` file so not duplicating with `ci`. . But first I wanted to get feedback. @danking @cseed @akotlar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5866:377,feedback,feedback,377,https://hail.is,https://github.com/hail-is/hail/pull/5866,1,['feedback'],['feedback']
Usability,"This PR switches the `NDArrayEmitter` to emit column major data by default. However, it still allows things like the result of `MakeNDArray` to come back as row major. This simplifies code that calls BLAS considerably, since we no longer have to manually flip to column major and then flip back. . There's still unnecessary copying going on, just less. `emitNDArrayStandardStrides` is not a very smart method, always copies the data even if it's already in the right format. At some point a smarter version of this should check if the ndarray exists in memory with the proper striding already.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8555:173,simpl,simplifies,173,https://hail.is,https://github.com/hail-is/hail/pull/8555,1,['simpl'],['simplifies']
Usability,"This PR teaches gear/database.py to respect four more MySQL configuration parameters: `ssl-mode`, `ssl-ca`, `ssl-cert`, `ssl-key`. In particular, we can now turn TLS on or off and rotate keys by simply changing secrets and restarting the services. Since all sql-config secrets (except those in my namespace) currently have no certs, no keys, and no ssl parameters, after this PR merges all services will still use plaintext communications to the database. After this PR merges, I will update the root secret as well as all the service secrets (e.g. sql-auth-user-config) to have a shared client cert/key and our sql database's cert. Moreover I will set `ssl-mode` to `VERIFY_CA` which means (in our world, at least) verify the server's certificate but not the hostname (we use IPs to connect to our sql server) and present your own certificate for verification. Then I will restart all the services. Then I will ban plaintext connections to the database. Then I will PR a change that raises errors if we try to start a service with plaintext connections or unverified connections. I also:; - updated `create_database.py` so that it will propagate these TLS settings, if present, to created secrets, and; - updated CI to use `gear/database.py` and standard sql-config locations. All these parameters are defined by MySQL. We only support three options for [`ssl-mode`](https://dev.mysql.com/doc/refman/5.7/en/connection-options.html#option_general_ssl-mode), the remainder are either unnecessary or not supported (e.g. we have no hostnames so `VERIFY_IDENTITY` is irrelevant).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8433:195,simpl,simply,195,https://hail.is,https://github.com/hail-is/hail/pull/8433,1,['simpl'],['simply']
Usability,"This PR:. - Introduces `NDArrayReindex`, which allows the use of the `transpose` on hail `NDArrayExpressions`. ; - Introduces `NDArrayMap2`, which allows operations like elementwise +, -, /, *, etc. This has full broadcasting support to match numpys. ; - Fixes `NDArrayShape`, which was not properly implemented. The only reason `NDArrayShape` seemed to work was because calling `NDArrayShape` directly on a `MakeNDArray` or on a `NDArrayMap1` was always simplified away to just return the tuple. ; - Removed the Simplify rule that transformed `NDArrayShape(MakeNDArray(..., shape))` to `shape`, since that was resulting in a type change, as `NDArrayShape` always returns a required tuple and `shape` was not a required tuple.; - Changes `ndarrays_eq` in the tests to just go through `eval` instead of a write then read, since write and read don't exist yet. . Things I'm not happy with:; - The rule for emitting `NDArrayReindex` is written twice, since depending on the situation one or the other is computationally cheaper. Seems like there should be a version of `NDArrayEmitter` that allows us to use an already existing array as the data. . Might add a few more tests, but code is here for review.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7069:455,simpl,simplified,455,https://hail.is,https://github.com/hail-is/hail/pull/7069,2,"['Simpl', 'simpl']","['Simplify', 'simplified']"
Usability,"This PR:. 1. Refactors `ResultOp` to just take an index and return whatever agg result is at that index. No more returning a suffix of the total aggregator tuple based on a starting index. This is necessary for me to effectively implement my Fold aggregator, which will be included in a subsequent PR. ; 2. Pushes `EmitType` through aggregators, uses them as the basis for analyzing the requiredness of aggregator results.; 3. Changes `_storeResult` on aggregators to instead just be `_result`, which directly returns an `IEmitCode`. No reason that `ResultOp` had to be so wound up in `PType`s, and for the most part this made the code simpler.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10894:636,simpl,simpler,636,https://hail.is,https://github.com/hail-is/hail/pull/10894,1,['simpl'],['simpler']
Usability,"This PR:. 1. Refactors `listify` to return pandas dataframes, and every geom to take in pandas dataframes. This significantly simplifies the code and should also speed things up.; 2. Refactors the `apply_to_fig` method of most of the geoms to rely on a specification dict and then just loop over that. This simplifies adding a new argument / aesthethic. In the future, it may be best to just make all of the geoms take `**kwargs` so that arguments added to that dict will immediately be used for plotting, as right now I have to add something to `geom_bar`, `GeomBar.__init__`, and that dictionary for it to start showing up in plots. ; 3. Adds `identity` as a bar position, which means to plot bars on top of each other. This is useful along with the `alpha` argument added to bars and histograms, which sets transparency of points.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11317:126,simpl,simplifies,126,https://hail.is,https://github.com/hail-is/hail/pull/11317,2,['simpl'],['simplifies']
Usability,This Region will get cleared by consumers. I introduced the zip primitive which is a safer way to; zip two RVDs because it does not rely on the user correctly; clearing the regions used by the left and right hand sides; of the zip. cc: @cseed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3400:21,clear,cleared,21,https://hail.is,https://github.com/hail-is/hail/pull/3400,2,['clear'],"['cleared', 'clearing']"
Usability,"This adds `SpillingCollectIterator` which avoids holding more than 1000 aggregation results in memory at one time. We could do something that listens for GC events and spills data if there's high memory pressure. That seems a bit error prone and hard. How should I pipe the size limit down to TableMapRows? I decided to make it a HailContext `flag` which means its not very user-visible, but Laurent can set it for now. In C++ we can design a system that is aware of its memory usage and adjusts memory allocated to scans accordingly. Spilling ten local files and then reading them in is probably in the noise of timings. 🎉. ---. ### Implementation Notes. I had to add two new file operations to the `RichHadoopConfiguration` because I need seekable file input streams. I don't like the names. I'm not sure what to do here. Hadoop really screws us with the seek-ability on compressed streams. The implementation is rather simple, it just maintains an array of the per-partition results. The index of the array corresponds to the partition index. The sparsity of that array is controlled by how often we spill. For an operation with a huge number of partitions that are often spilled (e.g. large number of partitions, each with a lot of data), we may want to use a `Map` instead of an `Array`. The use of `ObjectOutputStream` without a try-catch-finally block is non-standard. I was having trouble seeking to individual classes when I used one ObjectOutputStream to output each partition's array. There were these ""bad header"" messages. This seems to work. I don't close the OOS because I'm going to re-use the underlying output stream on the next partition. We use O(n_spills) files. ---. ### Timings. Master 0.2.14-4da055db5a7b; ```; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.45 s, sys: 333 ms, total: 1.78 s; Wall time: 24.6 s; In [3]: %%time ; ...: ;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6333:922,simpl,simple,922,https://hail.is,https://github.com/hail-is/hail/pull/6333,1,['simpl'],['simple']
Usability,"This adds `partitionKeys` which partitions the keys into partitions containing as-near-to-equal-as-possible number of records. The partitions are represented by an array, `pb`, of keys of length `nPartitions + 1`. The partitions are taken to include records with keys in; ```; [pb(0), pb(1)); [pb(1), pb(2)); ...; [pb(nPartitions-1), pb(nPartitions)]; ```; Note that the last partition is inclusive of both end-points. I have two simple examples of the partitioning behavior at the top of `LSMSuite`. In these cases, the number of elements is so small that the LSM perfectly stored the distribution, so there is no approximation. `LSMSuite` also contains tests that use enough keys so as to force the LSM to not keep them all. When the LSM has more than 10,000 keys, it starts sampling. It flips a coin that is true with probability `10,000 / n_keys_seen`. As we see more keys, the probability that the next seen key is kept decreases. If we decide to keep a key, we uniformly randomly choose a key to evict. The above is not entirely true. In reality, we keep 9998 keys in an array and separately keep the greatest and the least. Those are the true greatest seen key and the true least seen key. The probabilities above are adjusted accordingly. If the sample of keys is unbiased, then we expect the partitions chosen to be roughly equal in number of records. ---. The TestNG changes are already in another PR, I'll rebase when that lands. I separately fixed a bug in KeyedCodecSpec wherein it incorrectly assumed the Key and Value types were the same. I also fixed a bug in that the LSM used non-thread-local regions. Regions are not thread safe and the Indeed LSM implementation uses many threads. In order to track every addition to the LSM, I made the Indeed LSM object private and made the Hail LSM class have the necessary methods.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8803:430,simpl,simple,430,https://hail.is,https://github.com/hail-is/hail/pull/8803,1,['simpl'],['simple']
Usability,"This adds `test_storage_uri` and `batch_logs_storage_uri` fields in the global config. In GCP, this meant just copying existing GCS bucket names and prepending `gs://`, which I've done in the terraform and manually in default. For azure, in the terraform I add two storage accounts, `batch` and `ci`, with `logs` and `test` containers, respectively. This felt like an intuitive consolidation of containers under storage accounts that would make permissioning cleaner. E.g. the batch service principal has access to the entire batch storage account, but only to the `test` container in the ci storage account. However, I've not thought about it deeper than that so it might be worth some looking into. Luckily this decision has no impact on application code. There's still more to be done in a follow-up PR to replace instances of `hail_test_gcs_bucket_name` with `test_storage_uri`, but I think this takes care of the batch deployment's dependency on GCS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11014:368,intuit,intuitive,368,https://hail.is,https://github.com/hail-is/hail/pull/11014,1,['intuit'],['intuitive']
Usability,"This adds roles to the auth service. They are not used yet, but they are stored in the database and I created a simple UI for adding them. I tested with this dev deploy. FYI @danking @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9672:112,simpl,simple,112,https://hail.is,https://github.com/hail-is/hail/pull/9672,1,['simpl'],['simple']
Usability,This adds simple unit tests to the CI functionality that generates the configs for `gateway` and `internal-gateway`. It also adds a developer-only endpoint to CI for easier inspection of what configs CI is currently generating in production. These configs do not contain any sensitive information.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14524:10,simpl,simple,10,https://hail.is,https://github.com/hail-is/hail/pull/14524,1,['simpl'],['simple']
Usability,"This adds the Google Cloud Monitoring and Prometheus datasources to the grafana configuration. I had done this initially by hand in the UI but this is the first step toward reproducible monitoring, and I'll eventually follow up with dashboards as code. The one ""change"" I made is I exposed the prometheus port sitting behind nginx so that grafana can talk directly to prometheus. Currently, there's an nginx sitting in front of prometheus so that the prometheus UI can be exposed at prometheus.hail.is with https and dev authentication. This hasn't changed. Currently though, grafana is piggybacking on this flow by forwarding the user's session (which I set up in the UI), but I couldn't figure out an easy way to set that in the config and it seemed unnecessarily complicated. I ended up going the simpler route of just letting grafana talk to prometheus directly and not go through nginx. The 9090 endpoint is not reachable outside of the cluster. I considered namespacing the prometheus domain (`{{ default_ns.name }}` instead of `default`), but I pretty much never find it useful to spin up my own prometheus. In the rare case I run my own grafana I just point it to the data from default.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10627:800,simpl,simpler,800,https://hail.is,https://github.com/hail-is/hail/pull/10627,1,['simpl'],['simpler']
Usability,"This adds the k8s config necessary to host the [guide browser](https://hub.docker.com/r/gneak123/guide_browser/tags) in our k8s cluster. You can see it running in dev [here](https://internal.hail.is/dgoldste/guide-analysis/). There's not much special here, a deployment with the browser app and an envoy sidecar to handle TLS. Once this merges and the `ssl-config-guide-analysis` is created in `default` I can `make -C guide deploy NAMESPACE=default` and then recreate the certs to pick up the new subdomain, after which it should be live. Resolves #14067",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14078:48,guid,guide,48,https://hail.is,https://github.com/hail-is/hail/pull/14078,4,['guid'],"['guide', 'guide-analysis']"
Usability,"This assert is here because the buffer we use in the FS is a Java array and can't be longer than MAX_INT, but clearly the position in the blob can be more than that. This currently breaks range reads into indexes on data that's more than 2GiB.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12164:110,clear,clearly,110,https://hail.is,https://github.com/hail-is/hail/pull/12164,1,['clear'],['clearly']
Usability,"This basically implements the collect-and-broadcast strategy that we use for the current BlockMatrix.execute. I think it might be good to eventually be able to lift scalar broadcasts out as a relational let in a simplify pass instead of in the lowering, but in the meantime I've implemented it in the lowerer also.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9140:212,simpl,simplify,212,https://hail.is,https://github.com/hail-is/hail/pull/9140,1,['simpl'],['simplify']
Usability,"This certificate is valid for a server whose DNS name; is `example.com`. If ""hostname checking"" is enabled (web browsers always; enable it), then the client will reject the certificate if the hostname used; to open the socket does not match the certificate.; - `-addext subjectAltName = ...`. This specifies additional acceptable hostnames; for the aformentioned hostname check. #### Trust. An X.509 Certificate only proves that the principal has a private key. On the; world wide web, ownership of a particular domain, e.g. `example.com`, is; guaranteed by a Certificate Authority (CA). A Certificate Authority (like; letsencypt or VeriSign) digitally signs the certificate of a user that has; proven they own the domain name mentioned in the certificate (see above; discussion of `CN` and `subjectAltName`). Web browsers have a file of the ""root""; certificates of the public Certificate Authorities. They establish a ""chain of; trust"" from a root certificate to the server's certificate. Our system is simpler. We have no root certificate. Each principal has a; certificate which is given to all the principals to which it might; communicate. ### Encryption. TLS has many encryption schemes. I will focus on encryption using a *symmetric*; key because asymmetric schemes do not enable *forward secrecy* [2]. Under; forward secret schemes, the two parties share a private key unknown to all; adversaries. TLS 1.3 makes forward secrecy mandatory. I intend to eventually; require all our services to refuse to speak anything other than TLS 1.3. The shared private key is used to encrypt and decrypt messages sent over a; socket. This poses a problem: how do two parties who have never met each other; agree on a private key without revealing the key to the public? This is a; classic cryptography problem called [key; exchange](https://en.wikipedia.org/wiki/Key_exchange). The classic solution to; this problem is [Diffie-Hellman key; exchange](https://en.wikipedia.org/wiki/Diffie–Hellman_key_exchange",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:4869,simpl,simpler,4869,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['simpl'],['simpler']
Usability,"This change achieves the effect you desire. What I additionally need from this PR is a mental model of why this change works. This change specifies a pixel ratio of two when the device's physical:css pixel ratio is one, but uses the device's pixel ratio otherwise. This breaks my conceptual model. It's important for us all to share compatible models of what the code does so that we all are able to manipulate the code in the future. I think there's a few moving pieces and if we can get a handle on them all, we'll all agree on what the right fix is. AFAICT, three js is built on WebGL. The MDN recommends not using a WebGL `lineWidth` other than one because of inconsistent (or lack of) support for line widths other than one. You observe that `pixelRatio` affects the visual behavior, at least in Safari, when the lineWidth is set to 0.25. In particular, when the pixel ratio is set to `2` and the lineWidth is set to `0.25`, the lines appear thinner. If the pixel ratio is higher than the device pixel ratio, something must be interpolating to device pixels. It seems to me that relying on this interpolation behavior will lead to code that is more difficult to understand and manipulate. If the intention is to make the lines less striking, can we apply an alpha filter instead? Is there another simple & consistent-across-platforms solution?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8964#issuecomment-645569518:1302,simpl,simple,1302,https://hail.is,https://github.com/hail-is/hail/pull/8964#issuecomment-645569518,2,['simpl'],['simple']
Usability,This change allows batchces which fit in one bunch to be created in one; request instead of three. I found this saved a few hundred milliseconds; for batches with 1 job. This path is already well tested because most; of our test batches fit in one job. To be clear: all the savings here is from avoiding two round-trips to front-end.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11044:259,clear,clear,259,https://hail.is,https://github.com/hail-is/hail/pull/11044,1,['clear'],['clear']
Usability,"This change combines cloud auth logic that was previously duplicated; between the various `FS` implementations and the `BatchClient`. . The main refactoring is to make the interface between the `ServiceBackend` more; high-level and leave json serialisation to the `BatchClient`. To do this, I've; added a bunch of case classes that resemble the python objects the batch service ; expects (or a subset of the data). To simplify the interface, I've split batch; creation from job submission (update). For QoB, the python client creates the ; batch before handing control to the query driver; batch creation is necessary; for testing only. This change has low security impact as there are minor changes to the creation; and scoping of service account credentials. Note that for each `FS`, credentials; are scoped to the default storage oauth2 scopes for each service.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14684:418,simpl,simplify,418,https://hail.is,https://github.com/hail-is/hail/pull/14684,1,['simpl'],['simplify']
Usability,"This change exists as part of larger refactoring work. Herein, I've exchanged; hard-coded contextual strings passed to `ExecutionTimer.time` with implict; contexts, drawing inspiration from scalatest. These contexts are now supplied after entering functions like `Compile` and; `Emit` instead of before (see `ExecuteContext.time`). By sprinking calls to ; `time` throughout the codebase after entering functions, we obtain a nice trace; of the timings with `sourcecode.Enclosing`, minus the previous verbosity. See [1] for more information about what pre-built macros are available. We can; always build our own later. See comments in [pull request id] for example output.; Note that `ExectionTimer.time` still accepts a string to support uses like; `Optimise` and `LoweringPass` where those contexts are provided already.; It is also exception-safe now. This change exposed many similarities between the implementations of query; execution across all three backends. I've stopped short of full unification; which is a greater work, I've instead simplified and moved duplicated result; encoding into the various backend api implementations. More interesting changes are to `ExecuteContext`, which now supports; - `time`, as discussed above; - `local`, a generalisation for temporarily overriding properties of an ; `ExecuteContext` (inspired by [2]). While I've long wanted this for testing,; we were doing some questionable things when reporting timings back to python,; for which locally overriding the `timer` of a `ctx` has been very useful.; We also follow this pattern for local regions. [1] https://github.com/com-lihaoyi/sourcecode; [2] https://hackage.haskell.org/package/mtl-2.3.1/docs/Control-Monad-Reader.html#v:local",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14679:1046,simpl,simplified,1046,https://hail.is,https://github.com/hail-is/hail/pull/14679,1,['simpl'],['simplified']
Usability,"This change fixes a huge problem caused by these lines of code and context:. https://github.com/hail-is/hail/pull/6605/files#diff-1278c1788239002cc63ccb82cbef8d76L190. The problem is that in our generated code, every literal is decoded *each time any literal is referenced*. This is **extremely** expensive! . In this change, we instead decode the literals once with the function is constructed from the partition index (used with randomness), by adding a new region argument which the literals are decoded into. This region must live as long as the RegionValues returned by any invocation of the function. The primary error mode I might expect is that we use the wrong region to generate the function, causing use-after-free errors. These are well-covered by tests, since I had a few of these bugs and fixed them due to test failures. The region we *shouldn't* be using is `ctx.region`, which refers to `RVDContext.region`, the per-row region that is cleared after each record. `ctx.r` (the global execution context region) and `ctx.freshRegion` (a partition-owned global region, generally named `globalRegion` or `partRegion`) are safe.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6605#issuecomment-510677139:952,clear,cleared,952,https://hail.is,https://github.com/hail-is/hail/pull/6605#issuecomment-510677139,2,['clear'],['cleared']
Usability,"This change grew out of https://github.com/hail-is/hail/pull/13674.; The idea is simple - we shouldn't be appending code after control statements as such statements are redundant. That idea opened pandora's box, but now we're not generating and dropping dead code anymore. Main changes that rose form fixing fallout from adding assert in `Block.append`:; - Implement basic control-flow structures (if, while, for, switch) in `CodeBuilderLike` and remove the older implementations from `Code`.; - main difference is these are built from sequencing `Code` operations rather than being defined from LIR; - allows for a higher-level implementation that I think is simpler to read.; - Use the type-system to prevent foot-guns like `cb.ifx(cond, label.goto)`. Other changes:; - rename `ifx`, `forLoop` and `whileLoop` to just `if_`, `for_` and `while_`, respectively.; - Implement loops in-terms of one-another to remove code duplication.; - Fix logic for when to write IRs as some default value behaviour was broken when `HAIL_WRITE_IR_FILES` was set in tests",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13752:81,simpl,simple,81,https://hail.is,https://github.com/hail-is/hail/pull/13752,2,['simpl'],"['simple', 'simpler']"
Usability,"This change integrates the C++ code of libhail with the python code as; a python native extension exposed as _hail. It is extremely minimal for; now, containing only small wrappers for the C++ versions of hail virtual; types as python classes/objects. It is completely unused and introduces; python build time dependencies of a C++20 compiler and CMake. The LLVM dependencies should be optional for now as they add a lot to; the binary size without adding any functionality. They will still get; built if they are found. In the future, it may be easier or more desireable to maintain the _hail; module sources as Cython rather than C++, however, for both learning's; sake and ease of compilation, the module is pure C++.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10505:655,learn,learning,655,https://hail.is,https://github.com/hail-is/hail/pull/10505,1,['learn'],['learning']
Usability,"This change is split out from a larger refactoring effort on the various Backend; implementations. The goals of this effort are to provide query-level; configuration to the backend that's currently tied to the lifetime of a backend,; reduce code duplication and reduce state duplication. In this change, I'm removing blockmatrix persist/unpersist from the `Backend`; interface by adding `BlockMatrixCache: mutable.Map[String, BlockMatrix]` to; `ExecuteContext`. The various reader/writer implementations simply fetch the ; block matrix from this cache. For the spark backend, this is backed by a cache; whose lifetime is tied to the spark backend. Since block matrices are not; supported in the local and service backends, the cache is an empty map. Note that block matrix persist is broken in python (#14689)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14690:504,simpl,simply,504,https://hail.is,https://github.com/hail-is/hail/pull/14690,1,['simpl'],['simply']
Usability,"This change simplifies aspects of the annotation db's implementation as well as adding new features such as annotating a Table or using a custom JSON configuration file. The Annotation DB will remain experimental until we iron out the JSON configuration file's structure and we're confident in the deploy process. - Allow custom URL or JSON for configuration (enabling testing and local development).; - Support Tables.; - Restructure the annotation db JSON to reduce duplication. It now maps from dataset name to dataset metadata and dataset versions.; - Simplify JS logic based on new JSON structure.; - Check-in and implement versioned deployment of the annotation db configuration JSON.; - Add a JS file to the website that defines `hail_version` and `hail_pip_version`.; - Add `key_properties` which currently supports two properties `gene` and `unique`. Gene keyed datasets require using the `gencode` dataset to crosswalk from locus to gene before joining.; - Rudimentary test of key properties functionality. Foundational Changes Outside Annotation DB:; - Define `__pip_version__` in `hail`.; - Teach `StructExpression` and `TupleExpression` how to slice by integers, facilitating the construction of structs of a prefix of fields.; - Make `ttuple` a mapping from integers to the tuple elements.; - Implement `Table._maybe_flexindex_table_by_expr` which, given a indexer expression, finds a prefix of the expression that can index the indexee, if such an expression exists. Unrelated changes:; - Clarify Makefile error echos with `ERROR:`. ---. ## flexindex. The primary use case for this is a dataset which is `locus, allele` keyed and needs to index into a `locus` keyed or `interval<locus>` keyed dataset. Hail's normal join logic will return a key mismatch error:. ```python; import hail as hl; t = hl.utils.range_table(10); t2 = t.key_by(x=t.idx, y=t.idx); t.index(t2.key); ```; ```; Traceback (most recent call last):; File ""<ipython-input-6-3ddc90774dfe>"", line 1, in <module>; t.index(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7178:12,simpl,simplifies,12,https://hail.is,https://github.com/hail-is/hail/pull/7178,2,"['Simpl', 'simpl']","['Simplify', 'simplifies']"
Usability,"This change simplifies the logic to create the various globals when computing linear regression, cuts the size of the IR in half, and makes the code faster in the process. Benchmark times for linear_regression_rows_nd on my laptop:. Before this PR: [37.80013062, 37.84073734200001, 38.025162351999995]; After this PR: [31.85279850500001, 33.12659071399999, 31.33206254000001]. So about 15% faster, but still not fast enough. Regular linear regression is 22 seconds on my laptop.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10075:12,simpl,simplifies,12,https://hail.is,https://github.com/hail-is/hail/pull/10075,1,['simpl'],['simplifies']
Usability,"This commit changes the tracking of Joins on Python expressions; in two ways:. First, joins are switched from being tracked explicitly; on Expression to being a part of the expr AST. Second, broadcasts are split off as a separate AST node, which; lets us make them significantly simpler. It also made it easy; to collapse all broadcasts for a given MT/Table operation into; one MapGlobals IR, instead of one per broadcast variable. In the future, all the metadata on Expression should be tracked; on AST (type, aggregations, indices). This is a first incremental; step in getting there.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3573:279,simpl,simpler,279,https://hail.is,https://github.com/hail-is/hail/pull/3573,1,['simpl'],['simpler']
Usability,This creates redundant bindings that interfere with our ability to apply certain simplification rules.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7720:81,simpl,simplification,81,https://hail.is,https://github.com/hail-is/hail/pull/7720,1,['simpl'],['simplification']
Usability,"This currently is exposed in `read_table` and `read_matrix_table` as; undocumented optional parameters `_intervals` and `_filter_intervals`; which takes a list of python `Interval`s that are used either as; a filter or a repartition. This adds an `IndexedRVDSpec` as the primary container format for; indexed data, and increments the file version to 1.1.0. One index file is written per partition. For matrix tables, the offset; to a particular key for the entries is stored in the `entries_offset`; field of the annotation that an index may contain. We use the new; `IndexSpec` to retrive the appropriate offset from the index so that we; can seek to the proper offset in the partition. When writing data with a blocked spec (like the default) we use virtual; index offsets similar to tabix. The high 48 bits are used to indicate; the file offset to the start of a block, and the low 16 bits are used to; indicate the offset from the start of the (possibly decompressed) block. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6266:70,undo,undocumented,70,https://hail.is,https://github.com/hail-is/hail/pull/6266,1,['undo'],['undocumented']
Usability,This diff is pretty inscrutable but this entire PR is just a reorganization to better make use of terraform modules. The only things that are not shifting code into different modules and invoking those modules are:. - Made the default AKS node pool the nonpreemptible pool instead of having two custom pools in addition to default; - Added subscription/resource group level roles to be added to the service_principal module which removed a fair amount of repetitive role blocks.; - The azure module directly invokes Kubernetes resources instead of managing two separate states (one for azure and one for k8s). This simplifies the process to one `terraform apply` instead of two and removes the need for the janky copying of outputs to inputs that happened in bootstrap.sh. Sorry for the nearly 1k line PR but I think maintaining this terraform is going to be easier going forward and better to be done atomically.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11175:615,simpl,simplifies,615,https://hail.is,https://github.com/hail-is/hail/pull/11175,1,['simpl'],['simplifies']
Usability,"This doc introduces the entire Hail project to new software engineers. This is a response to; Carolin's and Daniel's critiques of our on-boarding documentation. I think there's a lot more to say, but I think it's time for some feedback before I continue. The other things I want to document:; - How we use git? Including practical examples.; - What does genetic data look like?; - What is a GWAS?; - What is PCA as applied to genetics?; - A Tour of Hail Query (in the spirit of Soustroup's a Tour of C++).; - A Bibliography of Hail Team's recommended books.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10020:227,feedback,feedback,227,https://hail.is,https://github.com/hail-is/hail/pull/10020,1,['feedback'],['feedback']
Usability,"This does, what I believe to be the minimum necessary to get Tabix reading working in a standard VCF reader.; ; * Add GenericLines readTabix; * Harmonize import_gvcfs arguments and MatrixVCFReader parameters, as such, it is now possible to directly override the sample ids.; * Remove the undocumented (and until this change, dead) _partitions argument to import_vcf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12375:288,undo,undocumented,288,https://hail.is,https://github.com/hail-is/hail/pull/12375,1,['undo'],['undocumented']
Usability,"This doesn't necessarily fix the problem, but I think they are good changes in the direction of what we know. It passed test_{batch, pipeline} on the first try, so that's a good sign. What I did:. 1. Lock down Job state transitions. Now only set_state and _mark_job_task_complete change _state, and they log identically. Explicitly enumerate the valid state transitions are check them in each function. Slightly clarified the transitions around Pending. Now Pending can only go to Ready. 2. If a state update fails (the Python object is stale), throw JobStateWriteFailure. If we have a stale picture, we clearly don't want to be doing anything else. 3. Handle a few more cases in update_job_with_pod: a pod without a job or a job that shouldn't have one, and a cancellable pod that hasn't been cancelled yet.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6618#issuecomment-510731707:604,clear,clearly,604,https://hail.is,https://github.com/hail-is/hail/pull/6618#issuecomment-510731707,2,['clear'],['clearly']
Usability,"This fixes a bug in joins where:; * The join key is a prefix of the left key; * Values of the join key in the left table span multiple partitions. For example, say the left table is `{[(0, 0), (0, 1)], [(0, 2), (1, 0)]}`, where the two lists of tuples are the two partitions, and the key is the entire tuple, and the join key is just the first field. Then in the old code; ```; val loweredLeft = lower(left).strictify(); val leftKeyToRightKeyMap = left.typ.keyType.fieldNames.zip(right.typ.keyType.fieldNames).toMap; val newRightPartitioner = loweredLeft.partitioner.coarsen(commonKeyLength); .rename(leftKeyToRightKeyMap); val loweredRight = lower(right).repartitionNoShuffle(newRightPartitioner); ```; the left partitioner is coarsened to `[(0), (0)], [(0), (1)]` in the third line, and the `repartitionNoShuffle` in the fourth line fails because rows with key `(0)` are split across both partitions. One possible fix would be to strictify the coarsened partitioner, which in this case would force the left table to one partition. But this seems dangerous performance-wise. Instead, this PR makes the lowered behavior match the old behavior, which is to ""repartition"" the right to the invalid partitioner `[(0), (0)], [(0), (1)]`, meaning rows with key `(0)` get duplicated into both partitions. This is exactly the intended semantics of `alignAndZipPartitions` as described in the code:; > The partitioner of the result will be the left partitioner. Each partition will be computed by 'joiner', with corresponding partition of 'this' as first iterator, and with all rows of 'that' whose 'joinKey' might match something in partition as the second iterator. This behavior is implemented with a flag `allowDuplication` on `repartitionNoShuffle`. This simply omits the assertion on the new partitioner that guarantees each incoming row ends up in at most one result partition.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11556:1751,simpl,simply,1751,https://hail.is,https://github.com/hail-is/hail/pull/11556,1,['simpl'],['simply']
Usability,"This fixes one mistake (right join does not set fields in the right table to missing), and makes the join table to be more precise. Keys are arrays of columns/fields of the table. They need to be present (they must be of same length and type for a join to be performed). The values are what are considered. The description also doesn't give a clear idea that left/right join is really about returning all rows from left/right table, and then joining the right/left table's fields depending on matches.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8467:343,clear,clear,343,https://hail.is,https://github.com/hail-is/hail/pull/8467,1,['clear'],['clear']
Usability,"This flips the pca algorithm, so that we're locally collecting a Krylov space basis on the column side (presumably the smaller side). This leads to a few simplifications, and allows for an optimization in the `compute_loadings=False` case. Once we have a complete TSQR implementation, we can optimize the `compute_loadings=True` case as well. With that, there should be no memory limitation to the number of rows (no local value is O(rows)).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10264:154,simpl,simplifications,154,https://hail.is,https://github.com/hail-is/hail/pull/10264,1,['simpl'],['simplifications']
Usability,This function permits developers to preserve ordering; when flatMaping a function which produces elements; montonically related to the source element. This change depends on PR #706. Merging that commit will simplify this diff.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/696:208,simpl,simplify,208,https://hail.is,https://github.com/hail-is/hail/pull/696,1,['simpl'],['simplify']
Usability,This has diverged significantly and contains parts of some changes to handling hailgenetics images that was handled in separate PRs. Closing in favor of #12446 which is much simpler.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11797#issuecomment-1314533333:174,simpl,simpler,174,https://hail.is,https://github.com/hail-is/hail/pull/11797#issuecomment-1314533333,2,['simpl'],['simpler']
Usability,"This implements my proposal to simplify aggregators here: http://dev.hail.is/t/proposal-for-aggregators/93/3. Builds on: https://github.com/hail-is/hail/pull/3552. I still need to finish converting some tests from ExtractAggregatorSuite (they are currently commented out). Old-style aggregators (filter, map, flatMap) are expanded at toIR conversion time to ApplyAggOp and SeqOp. ApplyAggOp returns the result of the aggregation. ApplyAggOp's first argument, which must be of type TVoid, is the expression to run for each element being aggregated over. SeqOp merges a computed value into the RegionValueAggregator. I added a AggSignature that holds the AggOp, type being aggregated over and the RegionValueAggregator constructor argument types. This is stored by the ApplyAggOp and the SeqOp. @tpoterba I believe TAggregable is no longer used in the IR code and can go away when the AST gets ripped out. @danking I added some IR testing logic to TestUtils. Namely, `eval` evaluates an IR with environments, args and/or aggregations with a single call (and verifies that the interpret with and without optimization and compiler all agree). There are also functions for asserting the result of aggregations, for example:. ```; val aggSig = AggSignature(Sum(), TFloat64(), FastSeq()); assertEvalsTo(ApplyAggOp(; SeqOp(ApplyBinaryPrimOp(Multiply(), Ref(""a"", TFloat64()), Ref(""b"", TFloat64())), I32(0), aggSig),; FastSeq(), aggSig),; (FastIndexedSeq(Row(1.0, 10.0), Row(10.0, 10.0), Row(null, 10.0)), TStruct(""a"" -> TFloat64(), ""b"" -> TFloat64())),; 110.0); ```. The line:. > (FastIndexedSeq(Row(1.0, 10.0), ...), TStruct(""a"" -> TFloat64(), ""b"" -> TFloat64())),. is the IndexedSeq of values to aggregate over, along with their signature. The struct type is used to build the scope in which aggregators are evaluated. (A little noisy because of the aggregator syntax. It's noisier than I'd like it to be.). This nicely paves the way for aggregators with multi-argument seqOps (like takeBy) that were previou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3570:31,simpl,simplify,31,https://hail.is,https://github.com/hail-is/hail/pull/3570,1,['simpl'],['simplify']
Usability,This is a great simplification. I'm on board,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13372#issuecomment-1673712560:16,simpl,simplification,16,https://hail.is,https://github.com/hail-is/hail/pull/13372#issuecomment-1673712560,2,['simpl'],['simplification']
Usability,"This is a lot simpler, I'll try to run this tomorrow morning.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1803234894:14,simpl,simpler,14,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1803234894,2,['simpl'],['simpler']
Usability,"This is a name to IP address and port service. GKE exposes pod IPs onto our VDC; network. As such, regular Google Cloud VMs can access pods by IP. GKE cannot; expose our services as IPs on our VDC because the way services load balance; traffic is more complex than DNS can handle. We acknowledge and accept the; limitations of client-side load balancing. In particular, if there are not many; clients and clients re-use address-port-pairs traffic will likely be; unbalanced. This is not a problem for the planned Shuffle service because the; clients are intended to be numerous (consider all the workers in a Query or; Batch pipeline). The big change is that deploy config now has an `addresses` function which will; return a list of address-port pairs. Deploy config also now has `address` which; randomly chooses one of the address-port pairs. I have included a simple test. Please review both code and overall design, considering how it fits in the wider system.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9129:864,simpl,simple,864,https://hail.is,https://github.com/hail-is/hail/pull/9129,1,['simpl'],['simple']
Usability,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10090:591,simpl,simpler,591,https://hail.is,https://github.com/hail-is/hail/pull/10090,1,['simpl'],['simpler']
Usability,"This is a pretty simple change, though the diff is a little bizarre. I don't want running a ukbb server to be a requirement of running a hail instance. Since the ukbb app is a special case in the way we deploy apps in k8s, we would render the gateway configuration server blocks with the logic:. - For each service, if it's not ukbb, render it the usual way; - Render the ukbb block. This is a very simple change to instead make the logic. - For each service, if it's ukbb render it the ukbb way, else render it the usual way. Together with the separation of the ukbb terraform into its own module in #10842, it should be easier to deploy hail without the ukbb app and simplify the bootstrap process. This is currently running in hail-vdc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10845:17,simpl,simple,17,https://hail.is,https://github.com/hail-is/hail/pull/10845,3,['simpl'],"['simple', 'simplify']"
Usability,"This is a simple refactor, that moves `Stream[A]` to a top-level class. Some of my wip depends on this, so it will be helpful to get it merged. This should also simplify merging `Stream` with the PType infrastructure, where `Stream` should become a `PCode`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8547:10,simpl,simple,10,https://hail.is,https://github.com/hail-is/hail/pull/8547,2,['simpl'],"['simple', 'simplify']"
Usability,"This is a simple refactoring of `lir.Emit` to directly use the core visitor based interface of ASM, rather than the higher level `tree` interface. This should have a small performance benefit, as we aren't building the in-memory tree representation only to immediately walk it with a visitor. But I also find this version of `Emit` slightly cleaner. For reference, you can find the documentation for ASM 5.1 [here](https://javadoc.io/doc/org.ow2.asm/asm/5.1/index.html).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9511:10,simpl,simple,10,https://hail.is,https://github.com/hail-is/hail/pull/9511,1,['simpl'],['simple']
Usability,"This is a simple tidying refactoring to hide the `children` array from consumers of `BaseIR`. My main motivation is to make it easier to explore other ir data structure designs, and to migrate to a new design in the future, e.g. to allow for in-place mutation without requiring large-scale changes to every compiler pass, and to simplify how we encode binding structure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13214:10,simpl,simple,10,https://hail.is,https://github.com/hail-is/hail/pull/13214,2,['simpl'],"['simple', 'simplify']"
Usability,"This is a simplified implementation of `Process.communicate`. We feed lines into the log one-by-one; until we reach the end of both stdout and stderr. When both stdout and stderr have been closed by; the child process, we wait for the process to exit. At any point in time, the most recent log is; available to us.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10259:10,simpl,simplified,10,https://hail.is,https://github.com/hail-is/hail/pull/10259,1,['simpl'],['simplified']
Usability,"This is an improvement, but I think we should reconsider the batch state. Thinking out loud: The batch and CI UIs have slightly different displays. If you're running, have had a failed job, but also been cancelled, what should your state be? I think we either need columns in the batch display for open/closed, cancelled, complete and the simple state (open, running, cancelled, failure, success ... where the latter 3 mean complete), or display compound states like ""running failure cancelled"".",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7897:339,simpl,simple,339,https://hail.is,https://github.com/hail-is/hail/pull/7897,1,['simpl'],['simple']
Usability,"This is an initial revision intended for feedback, there is much left to do; ### TODOs; - [x] Implement Read from index, notably for two operations, filter and repartition.; - [ ] Write matrix table indices; - There needs to be some work done on figuring out how to index both the rows and entries, especially when reading the entries as a table. Indices support an arbitrary `Annotation` payload that could be used. One thought I had for handling this is changing Indices rather than requiring a `offset: Long` and an `Annotation` changing them so that they only take some `Annotation`. Then the `TableSpec` or `MatrixTableSpec` would have a list of indices that would describe what needs to be pulled out of the `Annotation` in order to get the key's offset. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6095:41,feedback,feedback,41,https://hail.is,https://github.com/hail-is/hail/pull/6095,1,['feedback'],['feedback']
Usability,"This is at a place where people could look. Currently plan is to implement storeShallow on every PType separately (could keep all in PType for convenience initially). Majority of functionality: https://github.com/hail-is/hail/pull/7639/files#diff-2cba834adc6803ff8b274f8634bb46c0R394; ; # TODO:. - [x] Implement deep copy; - [ ] Implement for things that are not PCanonicalArray or PArrayBackedContainer; - [ ] Non-staged version; - [ ] More tests. cc @patrick-schultz, @catoverdrive, @danking for feedback",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7639#issuecomment-568135072:498,feedback,feedback,498,https://hail.is,https://github.com/hail-is/hail/pull/7639#issuecomment-568135072,2,['feedback'],['feedback']
Usability,"This is caused by domain-by-domain CSRF tokens introduced in [#14180](https://github.com/hail-is/hail/issues/14180). An unfortunate side effect is that the tokens available on non-auth pages are no longer able to validate requests to the auth/logout API. Given the lack of apparent noise about this bug in our issues and zulip I suspect that this is not a common path for users, and that a fix along the lines of ""require add one button click to go to the User page first before logging out is acceptable"". On the other hand, the risk of a user clicking on the broken Logout button and believing themselves to be logged out when seeing a `401: Unauthorized` page (but actually still having logged-in state in their browser) raises this in my mind to a security bug rather than just a UX bug or an unfortunate user experience. Therefore my proposal is:; 1. To fix the bug as soon as possible; 2. Accept an additional redirect in a user flow which is rarely exercised; 3. To make the smallest number of potentially risky changes to the underlying security architecture; 4. Therefore: Remove the broken ""log out"" link in page headers and replace with a Log out button on the auth[...]/users page which is guaranteed to have the correct CSRF token in state.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14635#issuecomment-2253086187:784,UX,UX,784,https://hail.is,https://github.com/hail-is/hail/issues/14635#issuecomment-2253086187,4,"['UX', 'user experience']","['UX', 'user experience']"
Usability,"This is caused by the circularity in the import chain. Imports need to be a directed acyclic graph. The simplest fix seems to be to define `schedule_job` in `pool.py`, the only place it is used.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9832#issuecomment-758162781:104,simpl,simplest,104,https://hail.is,https://github.com/hail-is/hail/pull/9832#issuecomment-758162781,2,['simpl'],['simplest']
Usability,"This is currently just dead code, although it could conceivably be useful in the future; I want to remove this for now as it's pretty simple to add back in at a later date (follows the pattern of Serialize/Deserialize Aggs pretty much exactly) and makes for less code to keep refactoring as we optimize the aggregator stuff.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6813:134,simpl,simple,134,https://hail.is,https://github.com/hail-is/hail/pull/6813,1,['simpl'],['simple']
Usability,"This is going to cause problems down the line. Here's an example where inappropriate use of parentheses does something unexpected:; ```python; In [39]: x = functions.capture(5). In [40]: eval_expr((3 < x) & x > 5); Out[40]: True. In [41]: eval_expr((3 < x) & (x > 5)); Out[41]: False; ```; I'm actually not sure what the order of operations is in [40], but it's clearly wrong.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2640:362,clear,clearly,362,https://hail.is,https://github.com/hail-is/hail/issues/2640,1,['clear'],['clearly']
Usability,"This is indeed tricky, but I think there are other options here. For example, we could expand the spec so that a job specifies *either* a job_id or update_relative_job_id, and same for parents. This way the relative vs absolute job id is baked into the schema of the spec, and not inferred from the sign of the job id. Though similar in concept, I think that would be much less confusing. However,. > We can simplify things if we require all updates make two requests to the server to (1) get the start id and establish the update and then (2) submit new jobs with all absolute job IDs. I'd like to try this first. I feel like if we get a really solid API and it has a couple of superfluous requests in some edge cases, we will be able to come up with good performance shortcuts that don't muddle the normal path. Since the Query Driver currently lives the full life of the batch and is likely to stay that way for a while, it will satisfy these conditions without making any extra requests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12010#issuecomment-1215951685:408,simpl,simplify,408,https://hail.is,https://github.com/hail-is/hail/pull/12010#issuecomment-1215951685,2,['simpl'],['simplify']
Usability,"This is more clear to me, thanks Tim! Would it be worth explaining why it's called as `hail.init()` vs say `hail.context.init()` or `HailContext()`? Knowing the chain of custody makes this indirection feel less magical to me. ```python; // Instantiates the HailContext class, unless called with dempotent == True; // Calls def __init__ ; // Imported in hail/__init__.py for use as hail.init() ; ```. Also, wondering if it makes sense to uses/benefits of treating as singleton, though that may be for a different pr.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4987#issuecomment-448319952:13,clear,clear,13,https://hail.is,https://github.com/hail-is/hail/pull/4987#issuecomment-448319952,2,['clear'],['clear']
Usability,"This is mostly done, though I'll give it another pass tomorrow to see if I catch any problems and to remove some unneeded text file exports and imports. I also want to create one script at the end of tutorial that can be easily copy and pasted and runs the whole tutorial. Just wanted to post it so people could start looking at it and give feedback.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1288:341,feedback,feedback,341,https://hail.is,https://github.com/hail-is/hail/pull/1288,1,['feedback'],['feedback']
Usability,"This is not because we forgot to unfreeze CI, we just have simply never added the dockerhub images to azure automatically. The couple that are there now (only 107 and 112) must have been uploaded manually. Because there are some build.yaml steps that run on deploy that are specific to the broad GCP instance (like maybe making a release), non-hail-vdc instances don't run the whole build.yaml pipeline on deploy, but a subset that are specified through terraform (this is how AUS and MS could decide to only deploy a subset of our services e.g. not monitoring. We somewhat recently added a step (separate from the `deploy` step) called `mirror_hailgenetics_images` that was entirely intended so that other hail deployments (including ourselves on Azure!) could pick up the images that we released to dockerhub. I never added that steps to the Azure CI's config. I have done that now. Somehow I had foreseen this incident happening and when it actually did any prior on it disappeared from my brain entirely.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13050#issuecomment-1572657390:59,simpl,simply,59,https://hail.is,https://github.com/hail-is/hail/issues/13050#issuecomment-1572657390,2,['simpl'],['simply']
Usability,"This is now the first PR in the deduping resource ids stack. I decided that we should directly write the new ""deduped_resource_id"" value rather than in a trigger to make things simpler to reason about later when dropping unused columns. The implication of this is this PR must now be fully deployed before #12757. We need to announce this on Zulip once this PR merges.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12786:177,simpl,simpler,177,https://hail.is,https://github.com/hail-is/hail/pull/12786,1,['simpl'],['simpler']
Usability,"This is on the radar, so I vote for closing this issue. We're using issues for bugs, and this seems more in the realm of a feature request / usability improvement.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9226#issuecomment-672877232:141,usab,usability,141,https://hail.is,https://github.com/hail-is/hail/issues/9226#issuecomment-672877232,2,['usab'],['usability']
Usability,"This is runIfRequested deployment that simply has hail; and ipython installed. It facilitates developmnent of; services that interact with Hail Query (i.e. the Shuffler). I do this silly thing with a tar file because:; - I do not know the hail version (which is included in the wheel filename), so; - I am unable to copy it out with a variable name, and; - python refuses to install a wheel that does not have the version in the filename. I added `make update-hail-repl` to `hail/Makefile` which updates the hail wheel on the hail-repo without changing the pod or rebuilding the image. If the pod is restarted you lose your version, but the risk is worth the immense benefit of 5s deploys.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8194:39,simpl,simply,39,https://hail.is,https://github.com/hail-is/hail/pull/8194,1,['simpl'],['simply']
Usability,"This is super cool! I am a big fan of the idea and the overall approach, particularly when it comes to setting up the tmp bucket and getting the permissions on it correct. Here's my high level thoughts. Sorry for the wall of text but I found these a little hard to articulate. ### Regarding number of prompts. I think this is my primary concern. There's a lot of great automation here, but it's a lot right off the bat. I think what this is aiming to do is make it quick and simple to start running batches and every time someone has to stop and ask someone a question as to how they should respond to some prompt that process gets longer and more complicated. I think it's worth considering what the first batch people should run might be and design for a minimal first experience. IMO, a temp bucket is an absolutely crucial piece of configuration before you can do anything interesting and configuring a temp bucket is something that `hailctl` can easily be very opinionated about. Container registry… I feel like there's harder questions there, and you can run a lot of cool batches before having to worry about provisioning your own. It's also not actually a part of the hailctl config (unless something has changed recently) so it feels a little unusual in this flow. I still think that it is helpful to set people up with an AR and keep them from footguns, but maybe that can go in a separate command that the initial init command points to once you're done? Something along the lines of ""if you get to the point where you need to upload custom container images, you can use hailctl to set up a registry""?. Another thing that gives me a little pause is the wording around google projects. I get that you need one to create a bucket, but I think we should just make sure to steer clear of the implication that you are ""selecting a GCP project to use for Hail Batch"", because that implies some link or ownership that isn't there. But I think there's a quick fix here: for a given resource that we",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1648633012:475,simpl,simple,475,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1648633012,2,['simpl'],['simple']
Usability,"This is the initial version of the ATGU intranet service. Currently, it has a curated list of resources which can be created, viewed, edited and deleted. Resources can have attachments, which I store on Google storage. I used the async Google Storage client and it worked very nicely with aiohttp. Right now this developers only. I may give access to the admins to start curating resources. I'll follow up with roles and add roles for atgu-viewer and atgu-editor that I'll use in the service. I think the code is mostly straightforward, but a few remarks:. This is built on Bootstrap. It doesn't share the the styling with web common (which I probably want to convert). On the resources page, for client side search I use fuse.js: https://fusejs.io/ (so fast). For a rich text box (the resource content), I use quill.js: https://quilljs.com/. Quill doesn't allow you to post its contents in a form, so I use a JS event handler to populate a hidden input with the contents on submission. I tested it with dev deploy. I suggest you do the same before reviewing to get a sense of what's here. Feedback on the UI welcome.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9684:1090,Feedback,Feedback,1090,https://hail.is,https://github.com/hail-is/hail/pull/9684,1,['Feedback'],['Feedback']
Usability,"This is very nice! I didn't know some of things about the 0.1 days. I agree with John's comments, though I think it's worth making explicit whether a given Tour of Hail Query is for Scientists or Software Engineers. I think you're proposing the latter? Also, a stylistic nitpick but I find bullet-delimited sentences quite difficult to read, and think it might be clearer to drop the ands and commas at the end of the bullets.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10020#issuecomment-776811671:364,clear,clearer,364,https://hail.is,https://github.com/hail-is/hail/pull/10020#issuecomment-776811671,2,['clear'],['clearer']
Usability,"This issue could have been an RFC, but that felt too heavy. I can move this to a formal RFC if desired, but otherwise feedback and/or questions welcome in the discussion here. # Idea; For any key type, create an encoding to variable-length byte arrays, which preserves the key ordering. That way, algorithms and data structures which use key comparisons can be written monomorphically, with `memcmp` as the only comparison function needed. Idea inspired by [Fast and Memory Efficient Multi-Column Sorts in Apache Arrow Rust](https://arrow.apache.org/blog/2022/11/07/multi-column-sorts-in-arrow-rust-part-2/) blog post. But while they've optimized for vectorized encoding (which we currently can't do), I've preferred simplicity and smaller encodings. # Design; Type encoders can emit three kinds of output to a byte array buffer:; - byte - simply add a byte to the result, first padding an incomplete byte if necessary; - bit - add a bit to the result, possibly leaving an incomplete byte. We must know statically how many bits are used in the byte.; - pad - add `0`s to pad the last incomplete byte. This is safe (prefix-free) because the number of used bits is a (statically known) constant. We use this to ensure the number of used bits is known statically.; 	; Types:; - missingness; - treat as a type constructor `optional<T>`, i.e. base types don't encode missingness. Emits a single bit in the encoding. Can invert this bit to control whether missing values come first or last in the ordering. If missing, nothing is emitted after.; - sort-order; - treat reversing the default ordering as a type constructor `reverse<T>`; - simply inverts the encoding bitwise; - primitive types; - same as in datafusion, encoding has same size as original type; - signed integers - flip the sign bit; - floating point numbers - if sign bit is set, invert all bits, otherwise only flip the sign bit; - arrays; - before each element and after last element, emit continuation bit (0 if no more elements); - pad be",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14396:118,feedback,feedback,118,https://hail.is,https://github.com/hail-is/hail/issues/14396,3,"['feedback', 'simpl']","['feedback', 'simplicity', 'simply']"
Usability,"This larger benchmark shows clearer separation between the old pc-relate approach and the current one. this branch (which include's master's improvements); ```; 2020-01-27 13:16:20,975: INFO: [1/1] Running pc_relate_big...; 2020-01-27 13:18:12,886: INFO: burn in: 111.90s; 2020-01-27 13:19:56,255: INFO: run 1: 103.35s; 2020-01-27 13:21:46,801: INFO: run 2: 110.54s; 2020-01-27 13:23:39,147: INFO: run 3: 112.37s; {""config"": {""cores"": 1, ""version"": ""0.2.31-68d448411ab5"", ""timestamp"": ""2020-01-27 13:23:39.157122"", ""system"": ""darwin""}, ""benchmarks"": [{""name"": ""pc_relate_big"", ""failed"": false, ""timed_out"": false, ""times"": [103.35172498200001, 110.53654034999997, 112.369625832]}]}; ```; before improvements `becbbc6d2` (run against this branch's new benchmark); ```; 2020-01-27 13:25:15,789: INFO: [1/1] Running pc_relate_big...; 2020-01-27 13:27:25,725: INFO: burn in: 129.92s; 2020-01-27 13:29:44,260: INFO: run 1: 138.48s; 2020-01-27 13:31:49,675: INFO: run 2: 125.40s; 2020-01-27 13:33:59,580: INFO: run 3: 129.86s; ```. cc: @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7975:28,clear,clearer,28,https://hail.is,https://github.com/hail-is/hail/pull/7975,1,['clear'],['clearer']
Usability,"This lets RVB copy values of a different type. To do this, I needed to; delete all the logic in RVB and move it to PType. This also was an; opportunity to slightly simplify the existing copy code. I realize this may be a challenge to review. Happy to walk through any part as necessary.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8099:164,simpl,simplify,164,https://hail.is,https://github.com/hail-is/hail/pull/8099,1,['simpl'],['simplify']
Usability,"This looks like good start. A few comments:; - I prefer using MySQL over auth0 mainly because it simplifies our eventual backup/restore story. If you think that's simpler overall, great. I don't see how integrating our db with their service does anything for us.; - I assume you're planning to pull the user data from MySQL during the login flow and add it to cookie? I think @danking @jigold and I are interested in nailing down the format for the cookie and seeing an example.; - I agree with @danking we should have an internal id field that's an integer. I think we should use that everywhere, and just use the auth0 id to look up the user record during login. So the integer id would be the primary key and the auth0 id would be unique with a secondary index.; - You need to get the GCP service account key and store it in a secret.; - The GCP service account needs permissions on the bucket. It should be bucket writer.; - Name ""user_secrets"" seems overly specific (buckets and service accounts are not secrets). ""user_data""?; - Please don't give the database a public IP.; - From a usability perspective, for user-visible names I have to say I really dislike long uuids and like the k8s-style short random string at the end. For k8s resource, you get this for free with the `generate_name` argument. For other stuff, long-term, this will potentially require retry logic to make it robust.; - I don't like this create table logic (FYI @danking @jigold). Most database users should not have permissions to create databases. There should be a k8s secret with the database root and a secret for each specific database application that only has access to that database.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5618#issuecomment-473583731:97,simpl,simplifies,97,https://hail.is,https://github.com/hail-is/hail/pull/5618#issuecomment-473583731,6,"['simpl', 'usab']","['simpler', 'simplifies', 'usability']"
Usability,"This makes Hail Batch usable from a VM that's run under a service account, without requiring a JSON key. #assign services",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10647:22,usab,usable,22,https://hail.is,https://github.com/hail-is/hail/pull/10647,1,['usab'],['usable']
Usability,This makes the interaction with other infrastructure a bit simpler.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9951:59,simpl,simpler,59,https://hail.is,https://github.com/hail-is/hail/pull/9951,1,['simpl'],['simpler']
Usability,"This might be an overcorrection, but as it is we are not scheduling more than 30j/s with the database at max capacity. With 3 replicas of internal-gateway this will let 30rps reach the batch driver. This should give us a clear indication of whether rate limiting more aggressively will help with the database currently being overloaded. See [this thread](https://hail.zulipchat.com/#narrow/stream/300487-Hail-Batch-Dev/topic/trying.20to.20mark.20batch.200.20complete/near/423839864) for more details.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14374:221,clear,clear,221,https://hail.is,https://github.com/hail-is/hail/pull/14374,1,['clear'],['clear']
Usability,"This more or less follows the same strategy as the python splitting. Instead of each job figuring out which split it owns, I create 5 separate testng.xml files in `build_hail`. Each job reads one of those files. testng.xml has a pretty simple XML format and you can explicitly list the classes of interest. I noticed that hail java tests were up to 15 minutes which was really cramping my PR merging style. With this, some of the splits are a minute or two. I think we suffer a bit from programmatically generated tests since I'm splitting at the granularity of classes rather than methods, or, even better, generated methods.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9139#issuecomment-663248573:236,simpl,simple,236,https://hail.is,https://github.com/hail-is/hail/pull/9139#issuecomment-663248573,2,['simpl'],['simple']
Usability,This need substantial work. I will create a new PR which revamps import_matrix_table to be simpler and to correctly handle glob patterns.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12299#issuecomment-1304287294:91,simpl,simpler,91,https://hail.is,https://github.com/hail-is/hail/pull/12299#issuecomment-1304287294,2,['simpl'],['simpler']
Usability,"This needs tests as well as I think I need to fix indexing (so I don't blow memory on the full genome), but I wanted to share what I've been up to with y'all. Also, caitlin can use this branch to run an analysis if it comes to that. I would also appreciate some feedback on the approach. It would be much more ideal to just make joins of variant tables against BGENs smarter, but I think the infrastructure necessary for that is big. cc: @cseed. List of changes:. - added `_variants_per_file` limits the loaded variants to variants at the given array of indexes (0-indexed, same order as on disk). - ~added `row_fields` which prevents reading and allocation of LID and RSID (also improved python-type-checking for `row_fields` and `entry_fields`)~ Moved to #3779 and #3778. - ~fixed table-table joins to _not_ always coerce (thus computing partition keys of) the right-hand table~ Moved to #3723 . - ~added a check that prevents globals and sample annotations copying when they're not used in the body of a MatrixMapCols~ Moved to #3751. - ~fixed a bug in `IndexBTree` wherein if the number of elements was a multiple of 1024, an unnecessary 1024 elements were added to the end of the index file (which I believe breaks the reading process which expects the number of bytes to correspond to the size of the tree)~ Moved to #3750. - ~added `IndexBTree2` which is just an in-memory list of the variant start positions. This is a fair bit of data. Chromosome 1 has about 250 million bases, so in the worst case this is 250 * 8 million bytes = 2 GB. It occurs to me that this is actually way to much data to load on the master node in general (since I just try to open the indexes for every file). I should switch this to a disk-based index.~ Made it disk-based, called it `OnDiskBTreeIndexToValue` #3794. - each hadoop `FileSplit` now contains a possibly null (indicating no filter) list of variants (by index) to keep, in practice this should be quite small. - ~I changed several asserts to `if`'s with ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3727:262,feedback,feedback,262,https://hail.is,https://github.com/hail-is/hail/pull/3727,1,['feedback'],['feedback']
Usability,"This opens the possibility for compiler differences to fail builds for our users. The CI server should simply set CXX and CC to clang and rebuild hail. Moreover, we need to ensure the hail build system passes these variables all the way down to `libsimdpp`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1327:103,simpl,simply,103,https://hail.is,https://github.com/hail-is/hail/issues/1327,1,['simpl'],['simply']
Usability,"This proposal mounts to programming with explicit continuations. It doesn't increase the expressiveness of the loop construct that I can see. Our users are reluctant enough to learn functional programming, I think continuations is one step too far for the user interface. Internally, I don't care as much, although personally I would prefer to code up my solution. @catoverdrive's doing the work, so I'll let them decide. > As a side note, @iitalics stream emitter. Ah, I thought @catoverdrive was referring to IR level streams.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7614#issuecomment-559099522:176,learn,learn,176,https://hail.is,https://github.com/hail-is/hail/pull/7614#issuecomment-559099522,2,['learn'],['learn']
Usability,This provides useful feedback we can use to understand why `test_file_in_current_dir` keeps failing.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14151:21,feedback,feedback,21,https://hail.is,https://github.com/hail-is/hail/pull/14151,1,['feedback'],['feedback']
Usability,This removes support for parallel composable vcf export. I believe this; to be okay however as parallel composable export is undocumented and was; added for one specific internal project and may no longer be needed.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11656:125,undo,undocumented,125,https://hail.is,https://github.com/hail-is/hail/pull/11656,1,['undo'],['undocumented']
Usability,"This revamps the `batch.front_end` web pages to be a bit less cluttered and more usable. I brought in tailwindcss instead of using our existing sass. I mainly find it easier to work with but am fine porting it to sass if anyone feels strongly against changing css tools. In order to avoid overhauling all our HTML in one PR, I added a flag to the jinja context `use_tailwind` that is currently only on for the `batch` service. `layout.html` then uses this flag to determine which CSS and header it should use. If this gets to a state we're happy to merge, it should be a lot less work to bring over auth and CI and delete that flag.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14562:81,usab,usable,81,https://hail.is,https://github.com/hail-is/hail/pull/14562,1,['usab'],['usable']
Usability,"This seems very simple, I'm just not sure how to modify the job creation to do what we want it to. https://github.com/hail-is/hail/blob/86f21400e3f2ac127f084f15ab72594a6add6f15/hail/python/hailtop/batch/backend.py#L799-L807",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13816#issuecomment-1775716804:16,simpl,simple,16,https://hail.is,https://github.com/hail-is/hail/issues/13816#issuecomment-1775716804,2,['simpl'],['simple']
Usability,"This sends a literal tab character to grep, taking advantage of Bash ANSI-C style quoting (see https://tldp.org/LDP/Bash-Beginners-Guide/html/sect_03_03.html)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9632:131,Guid,Guide,131,https://hail.is,https://github.com/hail-is/hail/pull/9632,1,['Guid'],['Guide']
Usability,This should be just a simple refactoring in anticipation of having bunches for job groups as well.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13448:22,simpl,simple,22,https://hail.is,https://github.com/hail-is/hail/pull/13448,1,['simpl'],['simple']
Usability,"This should fix the test_copy failures. The problem was, we were sending a mutable byte iterator for data when inserting a new object. If that insert read some of the data, failed, and was retried, the data that was read was lost and the retry started where the failed insert left off. To retry writes, you need to keep around the data you've sent to resend in case of failure. So you don't have to keep around an unbounded amount of data, Google Storage supports resumable uploads: https://cloud.google.com/storage/docs/resumable-uploads. This allows us to send data in chunks, and release the data after Google reports back that the data has been committed. `StorageClient.insert_object`, when the upload type is resumable (the default), takes an additional argument `bufsize`. This is the amount the amount that the writer will buffer for retries, and the size of the chunks sent to GCS. I kept around the simpler media upload type since I actually want to use it in copy (copy doesn't need to buffer because it can retry by rereading the file being copied from). This code was actually kind of hard to organize. It would be better if the code immediately wrote any incoming data instead of just buffering it until we hit the chunk size, but I didn't find a manageable way to write that. Suggestions welcome, tho it would be good to get this fix in because of the test failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10023:909,simpl,simpler,909,https://hail.is,https://github.com/hail-is/hail/pull/10023,1,['simpl'],['simpler']
Usability,This should now be cleared to merge. I might need to go dismiss all of these alerts on `main` once that merges the first time. Let's leave it on for a bit and assess how much of a headache it is.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12269#issuecomment-1272065133:19,clear,cleared,19,https://hail.is,https://github.com/hail-is/hail/pull/12269#issuecomment-1272065133,2,['clear'],['cleared']
Usability,This should put the issue of non-responsive cancels to rest.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7913:33,responsiv,responsive,33,https://hail.is,https://github.com/hail-is/hail/pull/7913,1,['responsiv'],['responsive']
Usability,This simplifies many of our methods with a `using` primitive for handling `Closeable` objects.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2103:5,simpl,simplifies,5,https://hail.is,https://github.com/hail-is/hail/pull/2103,1,['simpl'],['simplifies']
Usability,This simplifies the code and means that region bookeeping for the prune; queue is unnecessary.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12076:5,simpl,simplifies,5,https://hail.is,https://github.com/hail-is/hail/pull/12076,1,['simpl'],['simplifies']
Usability,"This simply adds the wrapping structure + header from app.hail.is. Includes no scss from app.hail.is. That will be the next PR unless you want it here. We should also decide whether we want a home page (the smoothly-rising Hail that Arcturus liked), i.e whether this will be extended with a link to batch, or not (we discussed the option at our last meeting). cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5429:5,simpl,simply,5,https://hail.is,https://github.com/hail-is/hail/pull/5429,1,['simpl'],['simply']
Usability,"This slows the exponential growth in sleeps dramatically. Enough that the tests don't sometimes wait 30 seconds to learn that a batch is finished. On my laptop, the tests just finished in less than three minutes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5604:115,learn,learn,115,https://hail.is,https://github.com/hail-is/hail/pull/5604,1,['learn'],['learn']
Usability,"This test failure has occurred a few times. It's usually been resolved by simply re-running the test without any source code changes. There are at least four recent examples, all on different feature branches: . - [2017-02-21 11:10 UTC](https://ci.hail.is/viewLog.html?buildId=6489&tab=buildResultsDiv&buildTypeId=HailSourceCode_HailCi#); - [2017-02-15 21:51 UTC](https://ci.hail.is/viewLog.html?buildId=5446#2135525582_186_5446_problem); - [2017-02-15 18:45 UTC](https://ci.hail.is/viewLog.html?buildId=5333#1163765489_186_5333_problem); - [2017-02-13 22:42 UTC](https://ci.hail.is/viewLog.html?buildId=4934&tab=buildResultsDiv&buildTypeId=HailSourceCode_HailCi). ```; [11:19:14][:testHail] ======================================================================; [11:19:14][:testHail] ERROR: test_dataset (hail.tests.ContextTests); [11:19:14][:testHail] ----------------------------------------------------------------------; [11:19:14][:testHail] Traceback (most recent call last):; [11:19:14][:testHail] File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/tests.py"", line 233, in test_dataset; [11:19:14][:testHail] vds_assoc = vds_assoc.lmmreg(vds_kinship, 'sa.pheno', ['sa.cov1', 'sa.cov2']); [11:19:14][:testHail] File ""<decorator-gen-89>"", line 2, in lmmreg; [11:19:14][:testHail] File ""/home/ec2-user/BuildAgent/work/c38e75e72b769a7c/python/hail/java.py"", line 93, in handle_py4j; [11:19:14][:testHail] raise FatalError(msg); [11:19:14][:testHail] FatalError: lmmreg: failed to fit delta: REML realized at delta upper search boundary e^10 = 22026.465794806718, indicating negligible genetic component of variance. Standard linear regression may be more appropriate.; ```. These are the [offending lines](https://github.com/hail-is/hail/blob/master/python/hail/tests.py#L222-L233):. ```; vds_assoc = (hc.import_vcf(test_resources + '/sample.vcf'); .split_multi(); .variant_qc(); .annotate_samples_expr(; 'sa.culprit = gs.filter(g => v == Variant(""20"", 13753124, ""A"", ""C"")).map(g =",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1416:74,simpl,simply,74,https://hail.is,https://github.com/hail-is/hail/issues/1416,1,['simpl'],['simply']
Usability,This uses an undocumented feature. It can wait for a little while.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6629#issuecomment-511021715:13,undo,undocumented,13,https://hail.is,https://github.com/hail-is/hail/pull/6629#issuecomment-511021715,2,['undo'],['undocumented']
Usability,"This was a good one :). I haven’t measured the performance difference, but clearly the bug defeated the purpose of using a union-find data structure in the first place, which was to reduce the complexity of `unify` from quadratic to linear. While I was here, I made a separate simplification. Now that the sets are being unioned as intended, each set contains exactly one block that doesn’t start with a `GotoX`, and that block is the final target of all blocks in the set. That observation allows a simplification when computing the `rootFinalTarget` map.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9475:75,clear,clearly,75,https://hail.is,https://github.com/hail-is/hail/pull/9475,3,"['clear', 'simpl']","['clearly', 'simplification']"
Usability,This was based on feedback Cotton gave me in the Counter PR. I couldn't figure out how to get a nicer count of the number of elements for `result`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3821:18,feedback,feedback,18,https://hail.is,https://github.com/hail-is/hail/pull/3821,1,['feedback'],['feedback']
Usability,"This was to simplify the bytecode generated for unsafe memory access calls vs Scala objects. If there was an improvement, it was smaller than the benchmark measurement noise. Also added some object+offset variants.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2184:12,simpl,simplify,12,https://hail.is,https://github.com/hail-is/hail/pull/2184,1,['simpl'],['simplify']
Usability,"This will fail until #7376 lands and allows the test to create an empty matrix table. - document `sep`; - add two tests for importing empty matrix tables, one with a header and one without; - include the offending lines in error messages when files have different numbers of columns; - consistently use `String.split(separator, 0)` instead of using two different approaches which yield inconsistent results.; - simplify `parseHeader` and generalize to empty files; - improve error message when a row field found in the file does not match one of the row fields specified by `row_fields` (a dictionary from row field name to type). NB: A no-header empty file implies no columns in the MT. We print a warning to this effect when we discover an empty file. Resolves #7242",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7378:411,simpl,simplify,411,https://hail.is,https://github.com/hail-is/hail/pull/7378,1,['simpl'],['simplify']
Usability,"Though running: `pprint(dict(os.environ.items()))`, yielded:. ```; {'CLICOLOR': '1',; 'GIT_PAGER': 'cat',; 'HOME': '/root',; 'INVOCATION_ID': '0faec80a970f4cf29ce69112519fe641',; 'JOURNAL_STREAM': '8:38888',; 'JPY_PARENT_PID': '5858',; 'LANG': 'en_US.UTF-8',; 'LOGNAME': 'root',; 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline',; 'PAGER': 'cat',; 'PATH': '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',; 'SHELL': '/bin/sh',; 'SPARKMONITOR_KERNEL_PORT': '38853',; 'TERM': 'xterm-color',; 'USER': 'root'}; ```. which does not include the environment variable you added saying to use the new thing, though that's clearly present in `init_notebook.py`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7087#issuecomment-532865823:634,clear,clearly,634,https://hail.is,https://github.com/hail-is/hail/pull/7087#issuecomment-532865823,2,['clear'],['clearly']
Usability,"Tim would you prefer RVD.unify to be separate from RVD.union, such that the caller controls upcast? Interface seems much simpler if RVD.union calls RVD.unify, but may result in unify being called too many times (if the caller unifies rvds, and doesn't realize that they also transitively call RVD.unify because some function the caller directly calls calls RVD.union)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8132#issuecomment-589323266:121,simpl,simpler,121,https://hail.is,https://github.com/hail-is/hail/pull/8132#issuecomment-589323266,2,['simpl'],['simpler']
Usability,"Tim, bug in the test fixed...but I'm not entirely clear why it should have caused an issue yet. In PBaseStruct.copyFromType, I was calling srcFieldType.storeShallowAtOffset instead of dstFieldType.storeShallowAtOffset, in a case where srcFieldType was +PCArray and dstFieldType was PCArray, aka:. ```scala; srcFieldType: +PCArray[+PInt32], dstFieldType: PCArray[PInt32]; ```. Where the invocation is:. ```scala; srcFieldType.storeShallowAtOffset(; this.fieldOffset(dstStructAddress, dstField.index),; dstFieldType.copyFromType(...); ```. The storeShallowAtOffset function on PCArray is stateless and identical between required and non-required PCArray instantiations:. ```scala; def storeShallowAtOffset(dstAddress: Code[Long], valueAddress: Code[Long]): Code[Unit] =; Region.storeAddress(dstAddress, valueAddress); ```. I don't have a clear idea why this issue occurred. Also, clearly not easily triggered, required PStruct(""bar"" -> PArray(PInt32(true),false) dest and PStruct(""bar"" -> PArray(PInt32(true),true) source, having the ""bar"" field be a primitive wouldn't do it (we had those tests)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7958#issuecomment-578204878:50,clear,clear,50,https://hail.is,https://github.com/hail-is/hail/pull/7958#issuecomment-578204878,6,['clear'],"['clear', 'clearly']"
Usability,"Tim, if you're willing would like to keep this open (or make another issue), to track progress on Patrick/your proposal. Patrick walked me through it, and I like it. The proposal I had, although clearly not explained well, is similar in nature, and for educational reasons, would like to talk to you about it, to see pro's/cons (maybe next week?). Patrick's proposal diagram attached. I would like to implement this once this becomes a priority. ![IMG_6021](https://user-images.githubusercontent.com/5543229/72645429-a610d580-3941-11ea-8086-85fe1f8618a4.png)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7826#issuecomment-575791483:195,clear,clearly,195,https://hail.is,https://github.com/hail-is/hail/issues/7826#issuecomment-575791483,2,['clear'],['clearly']
Usability,"Timing is not clear, gonna try an LRU cache. I will close until I have time to work on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3450#issuecomment-385008102:14,clear,clear,14,https://hail.is,https://github.com/hail-is/hail/pull/3450#issuecomment-385008102,2,['clear'],['clear']
Usability,"To be abundantly clear: this is strictly a rename. Originally I had some changes in Python, but I've backed them out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13594#issuecomment-1710921838:17,clear,clear,17,https://hail.is,https://github.com/hail-is/hail/pull/13594#issuecomment-1710921838,2,['clear'],['clear']
Usability,"To be clear `.select_globals()` fixes the problem, but...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3639#issuecomment-391115483:6,clear,clear,6,https://hail.is,https://github.com/hail-is/hail/issues/3639#issuecomment-391115483,2,['clear'],['clear']
Usability,To be clear this is a straight copy-paste job.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14314#issuecomment-1949442248:6,clear,clear,6,https://hail.is,https://github.com/hail-is/hail/pull/14314#issuecomment-1949442248,2,['clear'],['clear']
Usability,To be clear this is just the *visual* output. The data is fine.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13512#issuecomment-1773467913:6,clear,clear,6,https://hail.is,https://github.com/hail-is/hail/issues/13512#issuecomment-1773467913,2,['clear'],['clear']
Usability,"To be clear, I'm approving the Python code, and the fact that it runs to completion (will check for correctness shortly). Someone else might want to look over the Scala code changes)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3211#issuecomment-376013809:6,clear,clear,6,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376013809,2,['clear'],['clear']
Usability,"To be clear, I'm working on *aiohttp* project, not *Sanic*.; Regarding TechEmpower -- I did not investigate.; Maybe the problem is trivial, maybe it is fixed on master. ; IIRC Sanic has a partial Flow-Control/HTTP-Pipelining implementation now but I'm not 100% sure.; I have many points to apply my spare time, Sanic problems are not in my TOP-10 personal list. I hope you understand my position.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5242#issuecomment-461451746:6,clear,clear,6,https://hail.is,https://github.com/hail-is/hail/pull/5242#issuecomment-461451746,2,['clear'],['clear']
Usability,"To be clear, all this does is encode in the types what we already guarantee: if version X returns `{'foo': int}`, then all future versions of the server must *at least* return a dict containing the `'foo'` key with an integer. If those servers start returning `{'bar': int}`, that would break all the old clients (and violate the types that we wrote in those clients).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13500#issuecomment-1693583847:6,clear,clear,6,https://hail.is,https://github.com/hail-is/hail/pull/13500#issuecomment-1693583847,2,['clear'],['clear']
Usability,"To be clear, not the link you provided, what the page (https://internal.hail.is/dking/site/index.html) pulls.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8923#issuecomment-639057471:6,clear,clear,6,https://hail.is,https://github.com/hail-is/hail/pull/8923#issuecomment-639057471,2,['clear'],['clear']
Usability,"To be clear, the bug was that if the rdd of IndexedRows backing the IndexedRowMatrix omitted some rows (as a way of indicating that they contained only 0's), that omitted row would not get written to TSV file. This has been corrected, and a test was created for it by making the test data in the Suite more interesting and adding an assertion.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1679:6,clear,clear,6,https://hail.is,https://github.com/hail-is/hail/pull/1679,1,['clear'],['clear']
Usability,"To do this add an intermidiate abstract PartitionWriter,; SimplePartitionWriter, and extend it with TextTablePartitionWriter. SimplePartitionWriter manages the output stream for its subclasses. The; subclasses need to implement consumeElement, and optionally preConsume; and postConsume. TextTablePartitionWriter handles the delimiter delimited writing per; element item and the line delimited writing per element of the stream.; It will also optionally write the header if ExportType.PARALLEL_HEADER_IN_SHARD; has been requested. TextTableFinalizer is the 'MetadataWriter' (name change pending), for; TextTableWriter. That's where the header is written for; PARALLEL_SEPARATE_HEADER and CONCATENATED, and files are merged for; CONCATENATED. There are currently a few idosyncracies that don't replicate bug-for-bug; compatibility with the non-lowered version. 1. We avoid the use of fs.copyMerge, as such, we don't check for the; existence of the _SUCCESS file (even though we create it).; 2. ExportType.PARALLEL_COMPOSABLE is unsupported.; 3. We rely on the temporary file cleaner to clean up the files; created for CONCATENATED export, rather than deleting them; explicitly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11323:58,Simpl,SimplePartitionWriter,58,https://hail.is,https://github.com/hail-is/hail/pull/11323,2,['Simpl'],['SimplePartitionWriter']
Usability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; First of all, thank you for making such a highly integrated tool. . I learned that this tool could be run in two modes, on Cloud and locally. Well, I happen to have an HPC server that I can work on, so I'd love to use the tool locally. However, many annotation tools require many annotation data that need to be prepared in advance, and no one has seen the exact format of them. Plus, the annotation data sometimes is stored on a google cloud bucket that is requester paid so I don't have a chance to take a peek at them. Therefore, even I try to fill my configuration file, the annotation data needed cannot be prepared unless I have a template of them. . Pls, consider adding a feature like, if we want to run an annotation job locally, let us download package containing all the necessary annotation data in there. So we can set up the configuration file on our own and run the job on a local HPC server. Much appreciated!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9059:363,learn,learned,363,https://hail.is,https://github.com/hail-is/hail/issues/9059,1,['learn'],['learned']
Usability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. Sorry for the awful formatting!! I'm not familiar with how to properly format for GitHub, and clearly some of my code got picked up as formatting.... . EDIT: Fixed the formatting :). ### Hail version: 0.2 / devel. ### What you did: ; ```; import. hail as hl. def flip_text(base):; """"""; :param StringExpression base: Expression of a single base; :return: StringExpression of flipped base; :rtype: StringExpression; """"""; return hl.cond(base == 'A', 'T',; hl.cond(base == 'T', 'A',; hl.cond(base == 'C', 'G',; hl.cond(base == 'G', 'C', base)))). # load ldpred sumstats file; sumstats = hl.import_table('gs://ukbb_prs/sumstats/UKB_SCZ_LDPred.txt', delimiter='\s+', impute=True). # create locus and alleles columns and key by locus; sumstats = (sumstats.annotate(locus=hl.parse_locus(sumstats.chrom[6:] + "":"" + hl.str(sumstats.pos)),; alleles=[sumstats.nt1,sumstats.nt2]); .key_by('locus'); .order_by('locus')). # repartition sumstats to save time; sumstats = sumstats.repartition(100). # write the sumstats table; sumstats.write('gs://ukbb_prs/sumstats/UKB_SCZ_LDPred.kt', overwrite=True). # read the sumstats table; sumstats = hl.read_table('gs://ukbb_prs/sumstats/UKB_SCZ_LDPred.kt'). # remove leading zeros from contigs; contigs = {'0{}'.format(x):str(x) for x in range(1, 10)}. # import variants; variants = hl.methods.import_bgen('gs://fc-7d5088b4-7673-45b5-95c2-17ae00a04183/imputed/ukb_imp_chr{22}_v3.bgen',; [],; sample_file='gs://phenotype_31063/ukb31063.imputed_v3.autosomes.sample',; contig_recoding=contigs). # merge sumstats on bgen matrixtable; variants = variants.annotate_rows(ss = sumstats[variants.locus]). # handle strand/allele flips; variants = variants.annotate_rows(beta = hl.case(); .when(((variants.alleles[0] == variants.ss.nt1) &; (variants.al",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508:329,clear,clearly,329,https://hail.is,https://github.com/hail-is/hail/issues/3508,1,['clear'],['clearly']
Usability,"Took a look, and not clear why this is an issue. They seem to track different information, with WatchedBranch relating to one branch/sha combination and PR relating to two (with also a sha for the PR itself). Also Code doesn't appear to define a concrete `code` implementation, at least as of now. If you can help me understand the issue, I'll attempt to address tonight.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6142#issuecomment-497841118:21,clear,clear,21,https://hail.is,https://github.com/hail-is/hail/issues/6142#issuecomment-497841118,2,['clear'],['clear']
Usability,"Travis test processes sometimes die with a gradle exit code 137, internet research suggests that this is because Travis is issuing a SIGKILL to the process for using too many resources. No clear fix.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/118:189,clear,clear,189,https://hail.is,https://github.com/hail-is/hail/issues/118,1,['clear'],['clear']
Usability,"Trying to make it more ergonomic to simply do `python3 -m pytest batch/test/test_batch.py::test_job` (now works without any extra environment variables or configuration). This involved the following changes:; - Deleted of some env vars that are no longer used / can be easily consolidated into existing ones; - Gave defaults to those testing env variables for which there are reasonable defaults. E.g. `DOCKER_ROOT_IMAGE` and `HAIL_GENETICS_HAIL_IMAGE`.; - Pushed other environment variables for which there are not reasonable defaults into the tests that need them. If you run a test that requires `HAIL_CLOUD`, you'll still get an error that that env variable is unset and you should set it. But, if you just want to run a single test that doesn't need `HAIL_CLOUD` it won't get in the way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12862:36,simpl,simply,36,https://hail.is,https://github.com/hail-is/hail/pull/12862,1,['simpl'],['simply']
Usability,"Turns out pandas dataframes have an `.attrs` field to store ""globals"". So now I group by discrete values and collect them as globals, and I get one pandas dataframe per group of discrete values. This makes things a bit less complicated I think. . As part of this change, I now create scales based on looking at all the collected data, not just one particular geom's data. This is more correct for things like continuous color, where if I have one geom that has points in color range 0 - .5, and another geom that has points in color range .5-1, there should be a continuous color gradient between 0 and 1, not two separate ones from 0 - .5 and .5 - 1. . This will also allow me to support things like `scale_color_hue`, which is the default R way of picking discrete colors by choosing evenly spaced points on a color wheel. I can't pick evenly spaced points if I don't know how many discrete values of `color` I have across all geoms. Summary of actual code changes:. 1. Don't flatten out grouped data. Stats use `group_by` to group by discrete aesthetics, but prior to this PR they would just forget that grouping information and flatten out the data, only to redetermine the grouping information later. This prevents that entirely by storing the per group information in a dataframes `attrs`. ; 2. Update geoms to reflect they are getting data in this form. This simplifies away the need to have a specified `take_one` boolean for each aesthetic a geom supports that said whether it's a per data point or per group field.; 3. Replace `Scale.transform_local_data` with `Scale.create_local_transformer`. This takes in all the data and returns a lambda to map over the data. This is part of the ""scales looking at all collect data"" change mentioned above.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11380:1366,simpl,simplifies,1366,https://hail.is,https://github.com/hail-is/hail/pull/11380,1,['simpl'],['simplifies']
Usability,"Turns out we never used the generality provided by `ContextRDD`. This forces the context type to be `RVDContext`, and the context factory `mkc` to be `RVDContext.default`, both of which were the only values ever actually used. This change will simplify further work migrating region management to the new model.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8283:244,simpl,simplify,244,https://hail.is,https://github.com/hail-is/hail/pull/8283,1,['simpl'],['simplify']
Usability,"Two different tests: first running N linregs as separate aggregations, and the second running N linregs inside an array_agg. I suspect you're right that the first one is running into some kind of method size limit in the jit. Time 1 is master, Time 2 is this branch. ```python; @benchmark; def table_aggregate_linregN():; ht = hl.read_table(resource('many_ints_table.ht')); ht.aggregate(hl.tuple([hl.agg.linreg(ht[f'i{i%5}'],; [ht[f'i{(i+1)%5}'], ht[f'i{(i+2)%5}']]); for i in range(N)])); ```. ```quote; Name Ratio Time 1 Time 2; ---- ----- ------ ------; table_aggregate_linreg20 101.2% 11.622 11.765; table_aggregate_linreg21 98.0% 11.964 11.730; table_aggregate_linreg22 22.2% 54.272 12.068; table_aggregate_linreg23 99.9% 54.989 54.939; table_aggregate_linreg24 101.7% 54.753 55.661; table_aggregate_linreg25 102.7% 55.902 57.422; ----------------------; Geometric mean: 78.3%; Simple mean: 87.6%; Median: 100.6%; ```. ```python; @benchmark; def table_aggregate_linregN():; ht = hl.read_table(resource('many_ints_table.ht')); ht.aggregate(hl.agg.array_agg(lambda i: hl.agg.linreg(ht.i0 + i, [ht.i1, ht.i2]),; hl.range(N))); ```. ```quote; Name Ratio Time 1 Time 2; ---- ----- ------ ------; table_aggregate_linreg22 79.1% 10.609 8.389; table_aggregate_linreg23 79.0% 11.006 8.695; table_aggregate_linreg21 78.6% 10.559 8.295; table_aggregate_linreg25 77.2% 11.579 8.937; table_aggregate_linreg24 76.3% 11.520 8.793; table_aggregate_linreg20 75.7% 10.792 8.173; ----------------------; Geometric mean: 77.6%; Simple mean: 77.6%; Median: 77.9%; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7134#issuecomment-540058423:883,Simpl,Simple,883,https://hail.is,https://github.com/hail-is/hail/pull/7134#issuecomment-540058423,2,['Simpl'],['Simple']
Usability,Two high-level comments:; - Here is the default documentation:. https://ci.hail.is/repository/download/HailSourceCode_HailCi/846:id/docs/index.html#exportaggregate. Some documentation of the output format and maybe and example or two (with and without `--by-matrix`) would be awesome.; - We need at least some testing. I think a simple aggregation on a small file that you verify by hand would be sufficient. I'll look over the code and let you know if I have additional comments.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/837#issuecomment-249244766:329,simpl,simple,329,https://hail.is,https://github.com/hail-is/hail/pull/837#issuecomment-249244766,2,['simpl'],['simple']
Usability,"Two small comments:; - make it clear the name/description tables are describing the scope of the corresponding expression. We might need to do this elsewhere in the documentation, too.; - I'd write `aIndices[newIndex] = oldIndex` just to make it clear you're talking about the indices, and not the alleles.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/551#issuecomment-240494452:31,clear,clear,31,https://hail.is,https://github.com/hail-is/hail/issues/551#issuecomment-240494452,4,['clear'],['clear']
Usability,"Unfortunately, Google changed the way to connect to Spark UI, and now makes you either go through the YARN UI or use the Spark history page. This PR changes our Spark UI commands in `hailctl dataproc connect` to use the spark history page instead, since that works. The regular `spark-ui` command will show you running jobs, the `spark-history` command will show you finished jobs. I don't know what ui1 and ui2 were, but they're no longer usable so I removed them.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6760:440,usab,usable,440,https://hail.is,https://github.com/hail-is/hail/pull/6760,1,['usab'],['usable']
Usability,Update contributing guidelines,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9752:20,guid,guidelines,20,https://hail.is,https://github.com/hail-is/hail/pull/9752,2,['guid'],['guidelines']
Usability,Update style-guide.txt,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1738:13,guid,guide,13,https://hail.is,https://github.com/hail-is/hail/pull/1738,2,['guid'],['guide']
Usability,Update summarize in response to Laura's feedback. Also add a helper method to compute the 'real' GT from Local GT and Local Alleles.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5299:40,feedback,feedback,40,https://hail.is,https://github.com/hail-is/hail/pull/5299,1,['feedback'],['feedback']
Usability,Updated style guide.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/562:14,guid,guide,14,https://hail.is,https://github.com/hail-is/hail/pull/562,2,['guid'],['guide']
Usability,"Use Sanic + ujson instead of Flask + flask.json, cache more, and fix missing favicon in HTML templates. Sanic should be 3+x faster than Flask, and ujson ~2-3x faster than the standard json lib. I also optimize away the unnecessary re-generation of user_data (via get_users()) and json equivalent for /json. This is deployed currently on scorecard.hail.is, and improves performance by ~20%, even for 1 single connection, and for that simple workload (response time from ~50ms to ~40ms). Besides performance ( https://fgimian.github.io/blog/2018/06/05/python-api-framework-benchmarks/ ) Sanic also builds in a production-oriented web server, so need for WSGI or aWSGI, Gunicorn, etc. Can easily run multiple workers if desired. ```python; app.run(host='0.0.0.0', port=5000, workers=4); ```. This serves as a demonstration or migration to faster web frameworks, and in particular to uvloop-based asyncio implementations.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5242:433,simpl,simple,433,https://hail.is,https://github.com/hail-is/hail/pull/5242,1,['simpl'],['simple']
Usability,"Use ToArray(StreamRange(...)) instead; added tstream (undocumented), StreamRange to Python. This is the first step in: https://dev.hail.is/t/cleaning-up-titerable-hierarchy/181/2. Next I will make the Array* operations Stream-only. Then I can rip out TStreamable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8145:54,undo,undocumented,54,https://hail.is,https://github.com/hail-is/hail/pull/8145,1,['undo'],['undocumented']
Usability,Use set_message in CI and Batch to give users feedback after performing POST operations. I added set_message while working on notebook. Any message set will show up at the top of the next page loaded styled according to the message type.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7160:46,feedback,feedback,46,https://hail.is,https://github.com/hail-is/hail/pull/7160,1,['feedback'],['feedback']
Usability,Use to fix TableHead(TableOrderBy) rule in Simplify,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6234:43,Simpl,Simplify,43,https://hail.is,https://github.com/hail-is/hail/issues/6234,1,['Simpl'],['Simplify']
Usability,"Use web_common in ci, batch and scorecard for common design (e.g. header) and styling. The styling is clearly not ideal, this is intended to be a work in progress. Hand-deployed to checked batch and scorecard UI are still workable. Not easy to do with CI. Converted scorecard to aiohttp and gidgethub. Will remove dependencies in separate PR so I don't want to wait for all the images to rebuild. Can't quite get rid of Flask yet as it is used in callback tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7064:102,clear,clearly,102,https://hail.is,https://github.com/hail-is/hail/pull/7064,1,['clear'],['clearly']
Usability,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9380:1494,simpl,simply,1494,https://hail.is,https://github.com/hail-is/hail/pull/9380,2,"['learn', 'simpl']","['learning-paths', 'simply']"
Usability,"Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:1296: >>> hl.eval(d.key_set()) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:1312: >>> hl.eval(d.keys()) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:1329: >>> hl.eval(d.map_values(lambda x: x * 10)) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:1366: >>> hl.eval(d.values()) # doctest: +NOTEST; Binary file /Users/dking/projects/hail/hail/python/hail/expr/expressions/__pycache__/typed_expressions.cpython-37.pyc matches; Binary file /Users/dking/projects/hail/hail/python/hail/__pycache__/table.cpython-37.pyc matches; Binary file /Users/dking/projects/hail/hail/python/hail/__pycache__/matrixtable.cpython-37.pyc matches; /Users/dking/projects/hail/hail/python/hail/docs/guides/basics.rst:95: >>> mt.describe() # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/guides/basics.rst:141: >>> ht.describe() # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/guides/basics.rst:164: >>> mt.s.describe() # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:21: >>> hl.eval(x) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:24: >>> hl.eval(x) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:27: >>> hl.eval(hl.rand_unif(0, 1)) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:30: >>> hl.eval(hl.rand_unif(0, 1)) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:33: >>> hl.eval(hl.array([x, x, x])) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:42: >>> hl.eval(hl.array([a, b, c])) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4817#issuecomment-506359198:9157,guid,guides,9157,https://hail.is,https://github.com/hail-is/hail/issues/4817#issuecomment-506359198,2,['guid'],['guides']
Usability,"Uses the existent Region.setMemory function, and checks requiredeness before setting/clearing missing bits.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7822:85,clear,clearing,85,https://hail.is,https://github.com/hail-is/hail/pull/7822,1,['clear'],['clearing']
Usability,"Using index expressions to represent abstract transformations on tensors. E.g. broadcasts from scalars and vectors to matrices would be represented by. ```; O(i, j) <- A(); O(i, j) <- A(i); O(i, j) <- A(j); ```; where A is the input tensor and O is the output tensor. Similarly, transpose and identity look like. ```; O(i, j) <- A(j, i); O(i, j) <- A(i, j); ```. Since the `O(i,j)` is the same in all of these, we only need to look at the ""in"" index expressions for broadcasts to distinguish what operation needs to be performed. There's also a Simplify rule to cut out identity broadcasts. ## Workaround; This method of index expressions treats scalars and vectors as 0-dimensional and 1-dimensional tensors, respectively. As such, their shapes in the IR are 0 and 1-dimensional. However, BlockMatrix (Py API and Scala backend) assumes that all BlockMatrices are 2-dimensional, with the potential to have dimensions of length 1. To satisfy the current user API while maintaining a tensor-like mindset in the IR, the BlockMatrixType now has a `isRowVector` flag to help the front-end BlockMatrix discern whether a 1-tensor IR should be treated as a row or column vector. As BlockMatrix generalizes to n-tensors this flag can be removed. The IR should not rely on this flag for any execution logic.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5338:545,Simpl,Simplify,545,https://hail.is,https://github.com/hail-is/hail/pull/5338,1,['Simpl'],['Simplify']
Usability,Verify Field index is the index within the TStruct.; field => column in keytable. This was an old rename but looks like; some things got missed.; Simplify KT.select interface in Scala (and mathc Python).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2187:146,Simpl,Simplify,146,https://hail.is,https://github.com/hail-is/hail/pull/2187,1,['Simpl'],['Simplify']
Usability,"WIP solution. We need to fetch resources for job groups that have completed but have not been cancelled. ; The `job_groups` table describes if job group has been cancelled. Simply joining the job groups to `job_group_inst_coll_cancellable_resources` is prohibitively expensive due to explodes. My approach is to query for finished non-cancelled job groups from a last (batch, job) id then process records iteratively:. ```python; sql = """"""\; WITH T AS ( ; SELECT G.batch_id, G.job_group_id; FROM job_groups AS G ; INNER JOIN job_group_self_and_ancestors AS D; ON G.batch_id = D.batch_id; AND G.job_group_id = D.job_group_id; LEFT JOIN job_groups_cancelled AS C ; ON C.id = G.batch_id; AND C.job_group_id = D.ancestor_id ; WHERE G.batch_id >= ?; AND G.job_group_id > ?; AND G.time_completed IS NOT NULL; AND C.id IS NULL; ORDER BY G.batch_id ASC, G.job_group_id ASC; LIMIT 1000; ); SELECT group_resources.batch_id; , group_resources.update_id; , group_resources.job_group_id; , group_resources.inst_coll; , SUM(group_resources.n_creating_cancellable_jobs) AS n_creating_cancellable_jobs; , SUM(group_resources.n_ready_cancellable_jobs) AS n_ready_cancellable_jobs; , SUM(group_resources.n_running_cancellable_jobs) AS n_running_cancellable_jobs; , SUM(group_resources.ready_cancellable_cores_mcpu) AS ready_cancellable_cores_mcpu; , SUM(group_resources.running_cancellable_cores_mcpu) AS running_cancellable_cores_mcpu; , COUNT(*) as `count`; FROM job_group_inst_coll_cancellable_resources AS group_resources; INNER JOIN T USING (batch_id, job_group_id); GROUP BY group_resources.batch_id; , group_resources.update_id; , group_resources.job_group_id; , group_resources.inst_coll;; "". last_batch_id = 0; last_job_group_id = -1. while True:; rows = db.execute(sql, [last_batch_id, last_job_group_id]); ; if not rows:; break. for r in rows:; if r.count > 1:; delete records from job_group_inst_coll_cancellable_resources where token > 0; update record with accumulated result in r; ; last_batch_id = r.bat",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14623#issuecomment-2253530481:173,Simpl,Simply,173,https://hail.is,https://github.com/hail-is/hail/issues/14623#issuecomment-2253530481,1,['Simpl'],['Simply']
Usability,Waiting for guidance from htsjdk team on how to replace the deprecated method `Allele.acceptableAlleleBases`. https://github.com/samtools/htsjdk/issues/1623,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229#issuecomment-1266123134:12,guid,guidance,12,https://hail.is,https://github.com/hail-is/hail/pull/12229#issuecomment-1266123134,2,['guid'],['guidance']
Usability,"Was hitting a very annoying bug because `PCanonicalNDArray` didn't explicitly override the default. Creators of new `PType`s should not have to magically know that this method exists and override it. It should not have a default implementation. . I had to specify that `PCanonicalNDArray` does have pointers, and that `PVoid` and `PPrimitive` don't. I said `false` for `PCanonicalStream` too, but that was less clear. `false` is the value it was inheriting previously, but idk if you can even `deepCopy` a stream. If you can, then maybe it should recur to the `elementType`? You'd know best Patrick.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9242:411,clear,clear,411,https://hail.is,https://github.com/hail-is/hail/pull/9242,1,['clear'],['clear']
Usability,We added `simpleAssert`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/39#issuecomment-235158444:10,simpl,simpleAssert,10,https://hail.is,https://github.com/hail-is/hail/issues/39#issuecomment-235158444,2,['simpl'],['simpleAssert']
Usability,We could add a warning to the docs to make it even clearer.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3912#issuecomment-403844335:51,clear,clearer,51,https://hail.is,https://github.com/hail-is/hail/pull/3912#issuecomment-403844335,2,['clear'],['clearer']
Usability,"We do not have a strategy for folds on arbitrary types, but for primitive types the answer is clear: represent the value as a JVM primitive. The Python syntax should mirror [functools.reduce](https://docs.python.org/3/library/functools.html#functools.reduce):. ```python; hl.agg.reduce(lambda acc, x: hl.bit_or(acc, x), t.bit_string, 0L); ```. The implementation should not box the primitive values.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7173:94,clear,clear,94,https://hail.is,https://github.com/hail-is/hail/issues/7173,1,['clear'],['clear']
Usability,"We don't have clear issues now, but an open question about what these differences are, and whether they're user-facing. cc @johnc1231",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7419:14,clear,clear,14,https://hail.is,https://github.com/hail-is/hail/issues/7419,1,['clear'],['clear']
Usability,"We have chosen to prototype a new hail query compiler and runtime using; the LLVM project's MLIR framework for query compilation infrastructure.; This creates a simple project skeleton that will serve as a jumping off; point for the work. The README should be enough to get it built. There; is an implementation of the opt tool for investigating IRs, and; a completely empty dialect. I chose to rewrite this rather than copy over [hail-is/mlir-hail] as; breaking API changes from LLVM/MLIR 14 to 15 made it very difficult to; update that repo. The difficulties in updating LLVM versions may prove; to be a source of pain going forward, as this will be a pretty deep; dependency of the system. [hail-is/mlir-hail]: https://github.com/hail-is/mlir-hail",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12070:161,simpl,simple,161,https://hail.is,https://github.com/hail-is/hail/pull/12070,1,['simpl'],['simple']
Usability,"We need to re-simplify after LiftLiterals, since it's generating:. ```; GetField; SelectFields; Ref global; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4483:14,simpl,simplify,14,https://hail.is,https://github.com/hail-is/hail/issues/4483,1,['simpl'],['simplify']
Usability,"We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the driver was killed by the system.; Let's focus on the driver machines. In Run A, we used an n1-highmem-8 which is advertised to have 52GiB (53248 MiB). In Run B, we used an n1-highmem-16 which is advertised to have 104GiB (106,496 MiB). hailctl sets the JVM max heap size to 80% of the advertised RAM, so 42598 MiB (see ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:1264,clear,clear,1264,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449,2,['clear'],['clear']
Usability,"We run this query to get fair share values per user:. ```; SELECT user, CAST(COALESCE(SUM(n_cancelled_running_jobs), 0) AS SIGNED) AS n_cancelled_running_jobs; FROM user_inst_coll_resources; GROUP BY user; HAVING n_cancelled_running_jobs > 0;; ```. This query will return 0 even though there could be attempts still running. Plus these queries only look at running batches. ```; async for batch in self.db.select_and_fetchall(; '''; SELECT id; FROM batches; WHERE user = %s AND `state` = 'running' AND cancelled = 1;; ''',; (user,),; timer_description=f'in cancel_cancelled_running_jobs: get {user} cancelled batches'):; async for record in self.db.select_and_fetchall(; '''; SELECT jobs.job_id, attempts.attempt_id, attempts.instance_name; FROM jobs FORCE INDEX(jobs_batch_id_state_always_run_cancelled); STRAIGHT_JOIN attempts; ON attempts.batch_id = jobs.batch_id AND attempts.job_id = jobs.job_id; WHERE jobs.batch_id = %s AND state = 'Running' AND always_run = 0 AND cancelled = 0; LIMIT %s;; ''',; (batch['id'], remaining.value),; timer_description=f'in cancel_cancelled_running_jobs: get {user} batch {batch[""id""]} running cancelled jobs'):; record['batch_id'] = batch['id']; yield record; ``` . I'll think about whether I can combine these queries over the attempts. However, it seemed clearer to me to look for two different things as the other queries are optimized by looking at the batch and job state where the orphaned query doesn't care about fair share or the batch / job state..",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10071#issuecomment-783583573:1294,clear,clearer,1294,https://hail.is,https://github.com/hail-is/hail/pull/10071#issuecomment-783583573,2,['clear'],['clearer']
Usability,"We seem to be running into spark/yarn scheduling limitations causing stages to often fail with a large number of partitions. Here, we implement a very simple chunking strategy to run spark jobs with a limited number of partitions at a time. The maximum parallelism is controlled by a new `spark_max_stage_parallelism` feature flag, which defaults to MAXINT until we can figure out a good default. Also, this change corrects a small error in logic for partition indices for call caching. The `resultHandler` argument of [`runJob`] is called with the job's partition index, not the index of the partition within the RDD. So we need to index into the `partitions` sequence when populating the results buffer. CHANGELOG: Add 'spark_max_stage_parallelism' flag to allow users to run pipelines with a large number of partitions in chunks. By default, hail still attempts to run all partitions in a stage at once. . [`runJob`]: https://spark.apache.org/docs/latest/api/scala/org/apache/spark/SparkContext.html#runJob[T,U](rdd:org.apache.spark.rdd.RDD[T],func:(org.apache.spark.TaskContext,Iterator[T])=%3EU,partitions:Seq[Int],resultHandler:(Int,U)=%3EUnit)(implicitevidence$11:scala.reflect.ClassTag[U]):Unit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14590:151,simpl,simple,151,https://hail.is,https://github.com/hail-is/hail/pull/14590,1,['simpl'],['simple']
Usability,"We should discuss the struct ordering in person. I think there are orderings that can be defined on the space of all tuples (since the names don't matter) of arbitrary lengths, which are very helpful in working with changing keys and partition keys. In principle, it should be easy to repartition an OrderedRVD with a longer partition key to a partitioner with a shorter partition key, but currently that doesn't look simple to do. I tried to lay the groundwork here to make that trivial.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3159#issuecomment-373723920:418,simpl,simple,418,https://hail.is,https://github.com/hail-is/hail/pull/3159#issuecomment-373723920,2,['simpl'],['simple']
Usability,"We use feature flags to communicate requester pays information to the service backend.; In this change, I've made the local backend do the same to make a future refactoring simpler.; I intend to follow up this change that'll split config from feature flags.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14407#issuecomment-1998508308:173,simpl,simpler,173,https://hail.is,https://github.com/hail-is/hail/pull/14407#issuecomment-1998508308,2,['simpl'],['simpler']
Usability,"We want all allocations of `Region` to be controlled with a `using` or within a `RVDContext` (which will be appropriately closed). When we have achieved this, we can move the `Region` off-heap which provides a number of benefits including the use of raw-pointers in our Hail Object Representation as well as allocation free communication with other languages. This PR makes `LoadVCF` and `HailContext.readRows` use the regions in the `RVDContext`. Note that the _consumer_ is responsible for clearing the region when they're done with the current values. This is why `writePartitions` now includes `ctx.clear()`. Moreover, _producers_ must _not_ clear the region. These changes are tested by our whole infrastructure, but in particular, `is.hail.annotations.AnnotationsSuite.testReadWrite` exercises a lot of this. NB: We no longer clear the region between each read of a row. This means we could blow memory if we don't clear in the consumer. The other consumers are: aggregations, collects, shuffles, and joins. The tests pass though, so I guess I'm not too concerned for now. Once this is merged, I'll follow swiftly with uses of the RVDContext's region else where in our infrastructure. cc: @cseed . ---. I also included a couple miscellaneous small clean ups like unifying `RVD.rdd` and adding a use of `Region.scoped` in `HailContext`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3392:492,clear,clearing,492,https://hail.is,https://github.com/hail-is/hail/pull/3392,5,['clear'],"['clear', 'clearing']"
Usability,"We want to track Hail's performance with every release for a number of reasons, including but not limited to: ; - Measure how we are doing in delivering value to scientists; - Measure the effect of changes, test our intuition and learn how to improve the product. ; - Compare our solution with others; - Catch unexpected regressions. As of the time of writing, benchmarks are run rarely and have rotted somewhat. There's a bit of work required to get them going again. There's also some work in getting them running in CI and capturing the results. Very roughly, I think work can broken down as follows:; - [ ] get benchmarks passing; - [ ] organise trials with learnings from https://www.zora.uzh.ch/id/eprint/170445/1/emse_smb_cloud.pdf; - [x] run bechmarks in ci on deploy and store the results somewhere appropriate, fail if there's something really awful ; - [ ] visualise results on some appropriate cadance for trends. Might be nice to have a graphic on our github page. . I think many of these can be done in parallel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14221:216,intuit,intuition,216,https://hail.is,https://github.com/hail-is/hail/issues/14221,3,"['intuit', 'learn']","['intuition', 'learn', 'learnings']"
Usability,"We'll talk more about this during our meeting. This provides a skeleton for an LSM tree. Your first job will be to implement the interface using just C++'s `std::map`, an ordered key-value mapping. I implemented a simple command line interface that accepts a key-value language:. - `p k v`, put the value `v` at the key `k` (overwriting any value that currently exists); - `g k`, print the value associated with key `k`; if there is no value print an empty line; - `r l r`, print, on one line, all the key-value pairs between `l` (inclusive) and `r` (exclusive); - `d k`, remove any value associated with the key `k`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9740:214,simpl,simple,214,https://hail.is,https://github.com/hail-is/hail/pull/9740,1,['simpl'],['simple']
Usability,We'll test this when we add keytable random gens. For now I think this is a clear fix,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1972#issuecomment-316468753:76,clear,clear,76,https://hail.is,https://github.com/hail-is/hail/pull/1972#issuecomment-316468753,2,['clear'],['clear']
Usability,"We've had to do a redeploy of our hail batch instance on Azure. This PR resolves/clarifies two issues we encountered. 1) Storage Account Name Uniqueness. Due to Azure's restrictions on storage account naming (mainly that names must be globally unique) the redeploy did not succeed. This is because the resource group name (we chose to reuse hail) is possible under a new subscription, but the generated storage account names were therefore identical to our previous stack. I've added in an argument called `storage_account_suffix` to account for this issue. It can be set to any arbitrary string that complies with Azure's storage account naming scheme in order to avoid naming conflicts in the future. While the option remains to simply choose a novel resource group name this is not enforced by Azure and anyone deploying a stack similarly named to someone else would not know until the `terraform apply` stage that the name would not work. 2) Mysql Flexible Server Zones. The only other issue is that the zone argument for the mysql flexible server is no longer always valid depending on your compute region. We needed to comment it out for a successful deploy in Australia East. The comment that has been added we hope will be helpful for others in future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13058:731,simpl,simply,731,https://hail.is,https://github.com/hail-is/hail/pull/13058,1,['simpl'],['simply']
Usability,"We've run into this on Hail Batch 0.2.108. Binaries unfortunately sometimes produce binary output in logs (through `stdout` or `stderr`), e.g. `tabix` does that when it encounters the wrong input format. It appears that Hail Batch doesn't display _any_ log in such circumstances. That makes debugging the underlying issue really hard. For some reason, this seems to specifically happen with the byte value of 128. A simple way to reproduce this is to run the following commands in a batch:. ```python; job.command(""echo 'hi there :)'""); job.command(""echo -n -e '\\x80'""); ```. This will result in a `ERROR: could not find log file`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12614:416,simpl,simple,416,https://hail.is,https://github.com/hail-is/hail/issues/12614,1,['simpl'],['simple']
Usability,"Website is an aiohttp application which templates docs pages and normal pages. This opens the path; towards unifying the visual appearance of hail.is, the docs, and the services. I simplified documentation generation at the cost of building the docs twice per commit. A new step,; `make_pip_versioned_docs` builds the pip version of the docs without testing them. `make_docs`; continues to work as it did before. The website uses the docs from `make_pip_versioned_docs`. The; GCS docs location is now completely unused. Website has four key folders:. - `website/website/pages/`: Jinja2 templated HTML pages. Served at `/`. - `website/website/docs/`: Hail & Batch docs pages, all HTML pages are templated with Jinja2.; Served at `/docs`. - `website/website/templates/`: Jinaj2 templates that are used in pages or in docs. - `website/website/static/`: Non-templated files. Served at `/static`. The website can be developed locally in or outside of Docker:; ```; make -C website run; ```; or; ```; make -C website rundocker; ```. ---. I had to rename site to website due to a Python package conflict. I also deleted two unused css; files. I also removed PLINK from hail_run_image because it was slowing down my iteration speed; and was a long-term FIXME anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10056:181,simpl,simplified,181,https://hail.is,https://github.com/hail-is/hail/pull/10056,1,['simpl'],['simplified']
Usability,"Well, fraction reads supporting that alternate allele (`1-Ref` for the bi-allelic case, but not necessarily for the multi-allelic) - but that's possibly a separate discussion. GQ histogram I think is a simple application here. For each variant, a histogram of GQs - I think `gs.hist()` is the right idea though yes (this is an idea, does not exist yet, right?)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/509#issuecomment-237703639:202,simpl,simple,202,https://hail.is,https://github.com/hail-is/hail/issues/509#issuecomment-237703639,2,['simpl'],['simple']
Usability,"What do you mean specifically? Code-wise? If you're asking how I feel about the code, I think the change is clear now, but it's a bit verbose. I think it was more readable without all of the `_mcpu` extensions, but was also more confusing that way. . I had an idea that I tried to implement earlier where we had a class `Cores` that internally represented the cores as mCPU but then printed everything in CPU when referenced. That could have worked but I had to be careful with how I overrode all of the mathematical operations. I thought this was overkill for the problem so I abandoned it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7241#issuecomment-541195142:108,clear,clear,108,https://hail.is,https://github.com/hail-is/hail/pull/7241#issuecomment-541195142,2,['clear'],['clear']
Usability,"What do you think about simplifying the name to `annotation`? I think that's just as clear as `annotationFromRG`, especially as the RG is optional.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3062#issuecomment-370081471:24,simpl,simplifying,24,https://hail.is,https://github.com/hail-is/hail/pull/3062#issuecomment-370081471,4,"['clear', 'simpl']","['clear', 'simplifying']"
Usability,What do you think of setting the auto increment to 0 for the region id? I think that will make the bit shift operations clearer and less vulnerable to mistakes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1277915822:120,clear,clearer,120,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1277915822,2,['clear'],['clearer']
Usability,"What kind of feedback would you like? At a high-level, I think constructing these URLs and embedding links like this into the PR page is a great idea. Love how little code it takes to do this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13744#issuecomment-1739576643:13,feedback,feedback,13,https://hail.is,https://github.com/hail-is/hail/pull/13744#issuecomment-1739576643,2,['feedback'],['feedback']
Usability,What should we do about testing Cassandra? We need an `annotatevariants cass` as well I think. This stuff looks good though (awesome that it can be so simple!),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/282#issuecomment-208341414:151,simpl,simple,151,https://hail.is,https://github.com/hail-is/hail/pull/282#issuecomment-208341414,2,['simpl'],['simple']
Usability,"When I run copy inside a batch job to copy some files, it's really annoying to get no feedback at all.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11776#issuecomment-1101494934:86,feedback,feedback,86,https://hail.is,https://github.com/hail-is/hail/pull/11776#issuecomment-1101494934,2,['feedback'],['feedback']
Usability,"When regions are off-heap, we can allow the globals to live in a separate, longer-lived Region that is not cleared until the whole partition is finished. For now, we pay the memory cost. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3399:107,clear,cleared,107,https://hail.is,https://github.com/hail-is/hail/pull/3399,1,['clear'],['cleared']
Usability,"When using this command `filtervariants -c /user/xiaoli/LCR-hs37d5.interval_list --remove`, I got this error message: ; `hail: filtervariants: caught exception: scala.MatchError: [Ljava.lang.String;@56d822dc (of class [Ljava.lang.String;)`. The input file is formatted:; 1 1 10000; 1 10016 10464; 1 10656 10784; 1 28576 28603; 1 30852 30959; 1 31712 31733; 1 33440 33464; 1 33504 33541. It might be because that it cannot take tab delimited file with only three columns. At least we need a clear warning message.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/319:490,clear,clear,490,https://hail.is,https://github.com/hail-is/hail/issues/319,1,['clear'],['clear']
Usability,"When workers shut down, we get warning logs about unclosed client sessions, as seen in #14261. While it can be difficult to derive the source of the client session, I think it's the one held by the `GCPWorkerAPI`. I've added an exit stack and added the session's close method to it. I also made a small change to `Worker`. I find it can be difficult to determine whether or not a particular class should close a client session because it's not always clear who owns it. Without a clear way to communicate this in python, I think we should just never transfer ownership of a `ClientSession` and always assume that if an object's constructor takes a client session, it should be assumed a borrow and not close the session when the object is closed. As such, I moved the call to `client_session()` into the `Worker` constructor so it's clear that the worker owns the session.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14418:451,clear,clear,451,https://hail.is,https://github.com/hail-is/hail/pull/14418,3,['clear'],['clear']
Usability,"While trying to fix some weird errors, I realized this was more complicated than necessary and, I; think, broken. In the new implementation, a BatchPoolFuture is a thin wrapper around an asyncio.Future. Instead of; tracking the value and any exceptions manually, the BatchPoolFuture relies on asyncio.Future. I think the diff is not very helpful, just look at the new, simpler implementation. I also forgot to close the ServiceBackend, I now do that in the cleanup method that happens after all future complete.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10322:369,simpl,simpler,369,https://hail.is,https://github.com/hail-is/hail/pull/10322,1,['simpl'],['simpler']
Usability,"While we're making breaking changes to the `hailctl` interface... there is a beta feature to start/stop Dataproc clusters. Once this is released, it could create some confusion that `hailctl dataproc start` runs `gcloud dataproc clusters create` instead of `gcloud dataproc clusters start`. Likewise for `hailctl dataproc stop` and `gcloud dataproc clusters delete`. Should we rename `hailctl dataproc` start/stop to create/delete?. https://cloud.google.com/dataproc/docs/guides/dataproc-start-stop",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842#issuecomment-767171070:472,guid,guides,472,https://hail.is,https://github.com/hail-is/hail/pull/9842#issuecomment-767171070,2,['guid'],['guides']
Usability,"Whoa, it worked. I included one change that might have warranted re-review. I was getting errors becomes some Jobs, on which delete had been called, were still being used. I tracked it down to a recent cancel => delete change in `PR.update_from_completed_batch_job`. If look at that function, it is clear delete is not OK because in several cases the build object keep a handle to the job. I reverted it, and now clear all the fields of Job when it is deleted. https://github.com/hail-is/hail/pull/5655/files#diff-433f83d97fa8a526a3f8cff52590e422R479; https://github.com/hail-is/hail/pull/5655/files#diff-0c1f876ad25335b076837f768f727566R59",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5655#issuecomment-475474180:299,clear,clear,299,https://hail.is,https://github.com/hail-is/hail/pull/5655#issuecomment-475474180,4,['clear'],['clear']
Usability,"Whoops, sorry for not getting back to this! Basically, I'd like to see a test of just the heap structure exercised in a large number of ways (basically doing a compare + insert in all sorts of different configurations). You're kind of doing this with the large TakeBy test, but I'd prefer to see a simpler test with many, many more inserts being done and tested for correctness. This is basically to flush out any edge cases that you wouldn't be hitting with a more basic/structured test that wouldn't reach the correct internal state to trigger it. . I've found that creating a simple test structure that mimics the desired end result and using the random generator to generate comparison tests (with the count set pretty high) is generally a pretty good way of sanity checking and flushing these bugs out, rather than writing specific test cases---usually if I've written a test for a specific case, I won't have missed it when coding, and if I've missed an edge case when coding, I won't think to test it. I think I'm pushing on this extra hard because the generated code is at a level of complexity where I can look at it and say ""yeah, this looks generally right"" but I'm not sure that I trust myself, as the reviewer, to guarantee that it's accounted for every single insert configuration correctly, if that makes sense.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6942#issuecomment-530961530:298,simpl,simpler,298,https://hail.is,https://github.com/hail-is/hail/pull/6942#issuecomment-530961530,4,['simpl'],"['simple', 'simpler']"
Usability,"With natives, it clearly isn't dominated by the matrix multiply and I get something comparable to master: ~33 (master) vs ~36 (this branch, plus some fixes I will suggest in comments) on an example I cooked up (10K variants already mostly independent, a bad case for ld_prune).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3335#issuecomment-385311049:17,clear,clearly,17,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385311049,2,['clear'],['clearly']
Usability,"With the binding changes I can't even find the regression code. We're totally swamped by the compiler. After the JIT is warm, the compiler is ~3s. The regression code is probably equally as fast as scikit learn on this tiny example.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12793#issuecomment-1477072386:205,learn,learn,205,https://hail.is,https://github.com/hail-is/hail/pull/12793#issuecomment-1477072386,2,['learn'],['learn']
Usability,"With the new rng splitting design, each ApplySeeded node directly gets a unique fixed-length ID (similar to the seed currently), which gets combined into the RNGState immediately before generating random numbers. That allows us to simplify the SRNGState type. Abstractly, each `rand` result is the hash of a bitstring with one block corresponding to the static ID---which gets encrypted using the `staticTweak` tweak---and any number of blocks corresponding to the accumulated dynamic splits---which get encrypted using the block counter as tweak (except for the last block in normal PMAC fashion).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11668:231,simpl,simplify,231,https://hail.is,https://github.com/hail-is/hail/pull/11668,1,['simpl'],['simplify']
Usability,"Working backwards, we need to not return a 500 on error. We could return a BadRequest error code with the message 'invalid spec' and then handle the MJC database call on the driver. I chose instead to have the worker to post job complete so we get the error message with the stack trace showing up in the UI as having the normal job flow seemed cleaner to me last week then special casing `schedule_job` on the driver. `post job complete` needs a job object to get the status to send back to the driver. However, a `Job` has two concrete implementations and we don't know which the bad job is because we can't get the spec. Furthermore, the `Job` class does a lot of work based on the spec right now. So I thought it was clearer to just create a new class that had the status, but nothing else. After writing this out, it's probably better to have the driver MJC upon error rather than from the worker. The code below would be more complicated. We'd have to get the traceback / error message from the response from the worker. ```python3; try:; await client_session.post(; f'http://{instance.ip_address}:5000/api/v1alpha/batches/jobs/create',; json=body,; timeout=aiohttp.ClientTimeout(total=2),; ); await instance.mark_healthy(); except aiohttp.ClientResponseError as e:; await instance.mark_healthy(); if e.status == 403:; log.info(f'attempt already exists for job {id} on {instance}, aborting'); if e.status == 503:; log.info(f'job {id} cannot be scheduled because {instance} is shutting down, aborting'); raise e; except Exception:; await instance.incr_failed_request_count(); raise; ```. And the error handling would look something like this:. ```python3; try:; body = await job_config(app, record, attempt_id); except Exception:; log.exception('while making job config'); status = {; 'version': STATUS_FORMAT_VERSION,; 'worker': None,; 'batch_id': batch_id,; 'job_id': job_id,; 'attempt_id': attempt_id,; 'user': record['user'],; 'state': 'error',; 'error': traceback.format_exc(),; 'container_s",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11391#issuecomment-1048213078:721,clear,clearer,721,https://hail.is,https://github.com/hail-is/hail/pull/11391#issuecomment-1048213078,2,['clear'],['clearer']
Usability,Working on it! #12848 will be merged soon and #12849 will be reopened subsequently. The next steps after the billing tables are fully populated are not clear to me and we might want to discuss after stand up once the other two are merged.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13656#issuecomment-1737882692:152,clear,clear,152,https://hail.is,https://github.com/hail-is/hail/issues/13656#issuecomment-1737882692,2,['clear'],['clear']
Usability,"Would it be useful to give people repr() feedback on lazy operations? Like ""scheduling x"" and ""executing x""? cc @tpoterba. Would be a separate PR, but related issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7828#issuecomment-572726743:41,feedback,feedback,41,https://hail.is,https://github.com/hail-is/hail/issues/7828#issuecomment-572726743,2,['feedback'],['feedback']
Usability,"Writing the ATGU presentation made clear that we need consistent branding. I am; going with ""Hail Query-on-Batch"" and the ""Batch backend"".",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11685:35,clear,clear,35,https://hail.is,https://github.com/hail-is/hail/pull/11685,1,['clear'],['clear']
Usability,"YAML has an arbitrary extension mechanism. pyYAML defines a python extension that lets you create arbitrary python objets. This is clearly a huge security vulnerability. Apparently, pyYAML, by default, enables this extension (rather than just parsing vanilla YAML, 🤦‍♀️). `safe_load` loads vanilla YAML without the gaping security hole. I was getting warnings about this when testing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5825:131,clear,clearly,131,https://hail.is,https://github.com/hail-is/hail/pull/5825,1,['clear'],['clearly']
Usability,Ya I really need to set up running clusters locally. It's a frustrating feedback loop for a single cluster test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5686#issuecomment-477170521:72,feedback,feedback,72,https://hail.is,https://github.com/hail-is/hail/pull/5686#issuecomment-477170521,2,['feedback'],['feedback']
Usability,Ya the progress bars I mentioned were the file upload summary and the batch submission. I can try to make a quiet mode so it can cleanly print just the json. My intention was not to wait it in `submit.py` but to print out a json and then use `hailctl batch wait`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12471#issuecomment-1324152841:7,progress bar,progress bars,7,https://hail.is,https://github.com/hail-is/hail/pull/12471#issuecomment-1324152841,2,['progress bar'],['progress bars']
Usability,"Ya you're right, I was over-optimizing trying to share credentials between jobs of the same user. Just kept it as 1:1 jobs to credentials and it got a lot simpler. I changed the key to the job id because using the name of the identity would cause collisions between jobs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14125#issuecomment-1881179738:155,simpl,simpler,155,https://hail.is,https://github.com/hail-is/hail/pull/14125#issuecomment-1881179738,2,['simpl'],['simpler']
Usability,"Yeah, I misjudged, clearly the determinism issue. I cached for my test case.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4096#issuecomment-410890171:19,clear,clearly,19,https://hail.is,https://github.com/hail-is/hail/issues/4096#issuecomment-410890171,2,['clear'],['clearly']
Usability,"Yeah, I think I agree that we have a unique UUID. What I'm more skeptical of is: what if we throw an exception in a `write`? Do we clean up all the open resources? If not, that could totally leave a writer open that will conflict when we retry (even if we retried on a different VM!). ---. `retryTransientErrors` expects partition code to be safe to execute twice, but otherwise it's quite simple:. ```scala; def retryTransientErrors[T](f: => T): T = {; var delay = 0.1; var errors = 0; while (true) {; try {; return f; } catch {; case e: Exception =>; errors += 1; if (errors == 1 && isRetryOnceError(e)); return f; if (!isTransientError(e)); throw e; if (errors % 10 == 0); log.warn(s""encountered $errors transient errors, most recent one was $e""); }; delay = sleepAndBackoff(delay); }. throw new AssertionError(""unreachable""); }; ```; and this is the call site:; ```scala; val htc = new ServiceTaskContext(i); var result: Array[Byte] = null; var userError: HailException = null; try {; retryTransientErrors {; result = f(context, htc, theHailClassLoader, fs); }; } catch {; case err: HailException => userError = err; }; htc.close(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1531592331:390,simpl,simple,390,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1531592331,2,['simpl'],['simple']
Usability,"Yeah, OK, this isn't great. Do you have exac sites file snippet you're using somewhere? I clearly need to start doing more systematic benchmarking.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2089#issuecomment-321580378:90,clear,clearly,90,https://hail.is,https://github.com/hail-is/hail/pull/2089#issuecomment-321580378,2,['clear'],['clearly']
Usability,"Yeah, code-wise. I wanted to see how you felt my suggestion(s) were playing out. I agree with you. Having seen the code, I think I still like this best since it is the least confusing (clearest?) A `Cores` class if we used it consistently is an interesting option, although I also like that everyone knows how integers work and there's no conceptual overhead.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7241#issuecomment-541225212:185,clear,clearest,185,https://hail.is,https://github.com/hail-is/hail/pull/7241#issuecomment-541225212,2,['clear'],['clearest']
Usability,"Yeah, this was broken in a recent update to the gcloud libraries. For now, following the command to do:; ```; gcloud config set dataproc/region VALUE; ```; will generate the best user experience. We'll fix this for the next version though.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8078#issuecomment-584868077:179,user experience,user experience,179,https://hail.is,https://github.com/hail-is/hail/issues/8078#issuecomment-584868077,2,['user experience'],['user experience']
Usability,"Yes, absolutely! I was confused between filename and method name when I first added them. I think things are clear in my head now -- but maybe some more explanations about what is required to add a method to experimental (beyond adding the method code) would be neat!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4052#issuecomment-409731138:109,clear,clear,109,https://hail.is,https://github.com/hail-is/hail/pull/4052#issuecomment-409731138,2,['clear'],['clear']
Usability,"Yes, definitely! I'll assign you as a reviewer, though I'd like to also do a quick design review with Cotton to make sure I'm not doing anything crazy. I don't think there are any major redesigns I have in mind, barring feedback from review. I think I'll make it possible to control the default split size using a flag / env var, but other than that it works and seems to improve performance.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10512#issuecomment-852084745:220,feedback,feedback,220,https://hail.is,https://github.com/hail-is/hail/pull/10512#issuecomment-852084745,2,['feedback'],['feedback']
Usability,"Yet Another Terraform Refactoring PR, this creates two simple modules:; - A gcs_bucket module to remove the redundancy of resources that we have across the batch-logs, query and test bucket; - A ukbb module which sets up the ukbb k8s resources. While this technically would allow us to reuse this, say in azure, it's more an attempt to tease it apart from the google-specific infrastructure so that we wouldn't have to. In short, it would be nice to organize things such that deploying hail with or without the ukbb site is as simple as choosing to include or omit a terraform module.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10842:55,simpl,simple,55,https://hail.is,https://github.com/hail-is/hail/pull/10842,2,['simpl'],['simple']
Usability,You will use the principal components space that you learned from the unrelated samples. You can project the withheld samples by summing over all variants and multiplying the variant loadings by the withheld samples' GTs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3490#issuecomment-1284296019:53,learn,learned,53,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-1284296019,2,['learn'],['learned']
Usability,You're also removing Interval.point_type (just to be clear what the breaking changes are).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5152#issuecomment-454915985:53,clear,clear,53,https://hail.is,https://github.com/hail-is/hail/pull/5152#issuecomment-454915985,2,['clear'],['clear']
Usability,"You're right, they don't. @tpoterba Let's make this clear in the documentation. Although it is on the roadmap, it is not easy to support nested aggregators in full generality (what amounts to subqueries in SQL). I propose adding a `oneHot(x, arr)` where `x: Whatever`, `arr: Array[Whatever]` and `oneHot` returns the one hot encoding of `x` with respect to the ordered values in `arr` as an `Array[Int]` (and missing if `x` is not in `arr`). Then, using Tim's new changes that support aggregating over arrays (https://github.com/broadinstitute/hail/pull/584, still being reviewed but very close), you can write the above example as:. ```; annotateglobal expr -c 'global.pops = [""AFR"", ""NFE""]'; annotateglobals expr -c 'global.pop_counts = samples.sum(oneHot(sa.meta_test.POP, global.pops))'; ```. Reasonable?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/549#issuecomment-240003377:52,clear,clear,52,https://hail.is,https://github.com/hail-is/hail/issues/549#issuecomment-240003377,2,['clear'],['clear']
Usability,Yup! Mitja and I have been talking and sharing code on this issue. But clearly there is some work to be done for this functionality to be integrated naturally in Hail. And obviously the phasing stuff would be neat :),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/104#issuecomment-279858875:71,clear,clearly,71,https://hail.is,https://github.com/hail-is/hail/issues/104#issuecomment-279858875,2,['clear'],['clearly']
Usability,[auth/batch] Simplify deployment.yaml templating,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11993:13,Simpl,Simplify,13,https://hail.is,https://github.com/hail-is/hail/pull/11993,1,['Simpl'],['Simplify']
Usability,[auth] Simplify and unify use of userinfo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9715:7,Simpl,Simplify,7,https://hail.is,https://github.com/hail-is/hail/pull/9715,1,['Simpl'],['Simplify']
Usability,[batch] Fix UI to make user errors clear,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10329:35,clear,clear,35,https://hail.is,https://github.com/hail-is/hail/pull/10329,2,['clear'],['clear']
Usability,[batch] Job progress bar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10687:12,progress bar,progress bar,12,https://hail.is,https://github.com/hail-is/hail/pull/10687,2,['progress bar'],['progress bar']
Usability,[batch] Make error messages clearer in the UI and formatted correctly,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10545:28,clear,clearer,28,https://hail.is,https://github.com/hail-is/hail/pull/10545,2,['clear'],['clearer']
Usability,[batch] Omit setup progress bars on small batch submission,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12554:19,progress bar,progress bars,19,https://hail.is,https://github.com/hail-is/hail/pull/12554,2,['progress bar'],['progress bars']
Usability,[batch] Progress bar for jobs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10799:8,Progress bar,Progress bar,8,https://hail.is,https://github.com/hail-is/hail/pull/10799,2,['Progress bar'],['Progress bar']
Usability,[batch] Simplify cloudfuse credential handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12962:8,Simpl,Simplify,8,https://hail.is,https://github.com/hail-is/hail/pull/12962,1,['Simpl'],['Simplify']
Usability,[batch] Simplify iptables rules for worker network namespaces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11250:8,Simpl,Simplify,8,https://hail.is,https://github.com/hail-is/hail/pull/11250,1,['Simpl'],['Simplify']
Usability,[batch] Undo trigger change to ignore updates for format_version < 3,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11995:8,Undo,Undo,8,https://hail.is,https://github.com/hail-is/hail/pull/11995,1,['Undo'],['Undo']
Usability,[batch] Usability fixes to resource usage plots in the UI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12617:8,Usab,Usability,8,https://hail.is,https://github.com/hail-is/hail/pull/12617,1,['Usab'],['Usability']
Usability,[batch] disable bunch submission progress bar when fewer than 100,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13668:33,progress bar,progress bar,33,https://hail.is,https://github.com/hail-is/hail/pull/13668,4,['progress bar'],['progress bar']
Usability,[batch] insertion progress bars,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7876:18,progress bar,progress bars,18,https://hail.is,https://github.com/hail-is/hail/pull/7876,2,['progress bar'],['progress bars']
Usability,"[batch] it is not simple and straightforward to write a Python script that uses Python jobs which need: Hail, a set of local Python files, and third party dependencies.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13161:18,simpl,simple,18,https://hail.is,https://github.com/hail-is/hail/issues/13161,2,['simpl'],['simple']
Usability,[batch] maybe simplify jobs_after_update,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13372:14,simpl,simplify,14,https://hail.is,https://github.com/hail-is/hail/pull/13372,2,['simpl'],['simplify']
Usability,[batch] miscellaneous usability improvements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6557:22,usab,usability,22,https://hail.is,https://github.com/hail-is/hail/pull/6557,2,['usab'],['usability']
Usability,[batch] reproduce Ben's non-responsive worker issue and convert to a test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13992:28,responsiv,responsive,28,https://hail.is,https://github.com/hail-is/hail/issues/13992,2,['responsiv'],['responsive']
Usability,[batch] simple & understandable metrics,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12253:8,simpl,simple,8,https://hail.is,https://github.com/hail-is/hail/pull/12253,2,['simpl'],['simple']
Usability,[batch] simplify batch api.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5797:8,simpl,simplify,8,https://hail.is,https://github.com/hail-is/hail/pull/5797,2,['simpl'],['simplify']
Usability,[batch]Progress bar that tracks job status,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10060:7,Progress bar,Progress bar,7,https://hail.is,https://github.com/hail-is/hail/pull/10060,1,['Progress bar'],['Progress bar']
Usability,[batch][dag14] Add simple UI for batch,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4823:19,simpl,simple,19,https://hail.is,https://github.com/hail-is/hail/pull/4823,2,['simpl'],['simple']
Usability,[batch]progress bar color change,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11661:7,progress bar,progress bar,7,https://hail.is,https://github.com/hail-is/hail/pull/11661,2,['progress bar'],['progress bar']
Usability,[benchmark] Add argument to filter simple patterns,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6528:35,simpl,simple,35,https://hail.is,https://github.com/hail-is/hail/pull/6528,2,['simpl'],['simple']
Usability,[benchmark] Add simple range_table write benchmarks,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6529:16,simpl,simple,16,https://hail.is,https://github.com/hail-is/hail/pull/6529,2,['simpl'],['simple']
Usability,[c++] Scala's Region.clear() should clear underlying region instead of asking for a new one,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5968:21,clear,clear,21,https://hail.is,https://github.com/hail-is/hail/pull/5968,4,['clear'],['clear']
Usability,[c++] simplify deforesting for NDArrayReindex,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6135:6,simpl,simplify,6,https://hail.is,https://github.com/hail-is/hail/pull/6135,2,['simpl'],['simplify']
Usability,[ci] simplify local tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5803:5,simpl,simplify,5,https://hail.is,https://github.com/hail-is/hail/pull/5803,2,['simpl'],['simplify']
Usability,[combiner] update combiner format in response to feedback,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5495:49,feedback,feedback,49,https://hail.is,https://github.com/hail-is/hail/pull/5495,2,['feedback'],['feedback']
Usability,[compiler] Add `If` and `MakeStruct` Simplifications,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14231:37,Simpl,Simplifications,37,https://hail.is,https://github.com/hail-is/hail/pull/14231,1,['Simpl'],['Simplifications']
Usability,[compiler] Add simplify rule to push maps inside flat maps,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10525:15,simpl,simplify,15,https://hail.is,https://github.com/hail-is/hail/pull/10525,2,['simpl'],['simplify']
Usability,[compiler] PruneDeadFields simplification,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14455:27,simpl,simplification,27,https://hail.is,https://github.com/hail-is/hail/pull/14455,2,['simpl'],['simplification']
Usability,[compiler] Simplify SRNGState,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11668:11,Simpl,Simplify,11,https://hail.is,https://github.com/hail-is/hail/pull/11668,1,['Simpl'],['Simplify']
Usability,[compiler] add simple copy propagation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11004:15,simpl,simple,15,https://hail.is,https://github.com/hail-is/hail/pull/11004,2,['simpl'],['simple']
Usability,[compiler] extend + fix simplifier for integral types,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12754:24,simpl,simplifier,24,https://hail.is,https://github.com/hail-is/hail/pull/12754,2,['simpl'],['simplifier']
Usability,[compiler] simplify NormalizeNames,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14514:11,simpl,simplify,11,https://hail.is,https://github.com/hail-is/hail/pull/14514,2,['simpl'],['simplify']
Usability,[compiler] simplify PruneDeadFields,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14509:11,simpl,simplify,11,https://hail.is,https://github.com/hail-is/hail/pull/14509,2,['simpl'],['simplify']
Usability,[copy] make --verbose show a progress bar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11776:29,progress bar,progress bar,29,https://hail.is,https://github.com/hail-is/hail/pull/11776,2,['progress bar'],['progress bar']
Usability,[copy] teach aiotools.copy about tqdm progress bars,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10937:38,progress bar,progress bars,38,https://hail.is,https://github.com/hail-is/hail/pull/10937,2,['progress bar'],['progress bars']
Usability,[dev-docs] Add rudimentary tool guide,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10499:32,guid,guide,32,https://hail.is,https://github.com/hail-is/hail/pull/10499,2,['guid'],['guide']
Usability,[devbin] Add simple function for switching hail GCP projects,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10846:13,simpl,simple,13,https://hail.is,https://github.com/hail-is/hail/pull/10846,2,['simpl'],['simple']
Usability,"[docs] move Expressions, simplify",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6744:25,simpl,simplify,25,https://hail.is,https://github.com/hail-is/hail/pull/6744,2,['simpl'],['simplify']
Usability,[fs] Dont clear the buffer when seeking within bounds,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12061:10,clear,clear,10,https://hail.is,https://github.com/hail-is/hail/pull/12061,2,['clear'],['clear']
Usability,[fs] improve copy tool progress bars,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13832:23,progress bar,progress bars,23,https://hail.is,https://github.com/hail-is/hail/pull/13832,2,['progress bar'],['progress bars']
Usability,[gear] simplify database retry logic,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14369:7,simpl,simplify,7,https://hail.is,https://github.com/hail-is/hail/pull/14369,2,['simpl'],['simplify']
Usability,[guide-analysis] Host guide browser in hail-vdc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14078:1,guid,guide-analysis,1,https://hail.is,https://github.com/hail-is/hail/pull/14078,4,['guid'],"['guide', 'guide-analysis']"
Usability,"[hail/ptypes] simplify clearMissingBits, setAllMissing",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7822:14,simpl,simplify,14,https://hail.is,https://github.com/hail-is/hail/pull/7822,4,"['clear', 'simpl']","['clearMissingBits', 'simplify']"
Usability,[hail] Add TableAggregate simplify rules,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7141:26,simpl,simplify,26,https://hail.is,https://github.com/hail-is/hail/pull/7141,2,['simpl'],['simplify']
Usability,[hail] Add simplify rule to invert order_by and collect,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7175:11,simpl,simplify,11,https://hail.is,https://github.com/hail-is/hail/pull/7175,2,['simpl'],['simplify']
Usability,[hail] Add simplify rules for TableDistinct,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6227:11,simpl,simplify,11,https://hail.is,https://github.com/hail-is/hail/pull/6227,2,['simpl'],['simplify']
Usability,[hail] Clear trailing missing bits on encoded arrays as well,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7934:7,Clear,Clear,7,https://hail.is,https://github.com/hail-is/hail/pull/7934,1,['Clear'],['Clear']
Usability,[hail] Disable currently-invalid simplify rule,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7515:33,simpl,simplify,33,https://hail.is,https://github.com/hail-is/hail/pull/7515,2,['simpl'],['simplify']
Usability,[hail] Fix overflow caused by TableCount(TableUnion) simplification.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6958:53,simpl,simplification,53,https://hail.is,https://github.com/hail-is/hail/pull/6958,2,['simpl'],['simplification']
Usability,[hail] Fix simplify rewrite of ArrayLen(TableCollect),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7539:11,simpl,simplify,11,https://hail.is,https://github.com/hail-is/hail/pull/7539,2,['simpl'],['simplify']
Usability,[hail] Fix simplify rule with TableHead(MatrixColsTable),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6167:11,simpl,simplify,11,https://hail.is,https://github.com/hail-is/hail/pull/6167,2,['simpl'],['simplify']
Usability,[hail] Improve simplification of nested struct insertions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7082:15,simpl,simplification,15,https://hail.is,https://github.com/hail-is/hail/pull/7082,2,['simpl'],['simplification']
Usability,"[hail] Introduce ptypes to BGEN, refactor pruning logic to be simpler",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6576:62,simpl,simpler,62,https://hail.is,https://github.com/hail-is/hail/pull/6576,2,['simpl'],['simpler']
Usability,[hail] Simplify BGEN row count,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6895:7,Simpl,Simplify,7,https://hail.is,https://github.com/hail-is/hail/pull/6895,1,['Simpl'],['Simplify']
Usability,[hail] Simplify TableCount(CastMatrixToTable) appropriately,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6237:7,Simpl,Simplify,7,https://hail.is,https://github.com/hail-is/hail/pull/6237,1,['Simpl'],['Simplify']
Usability,[hail] Simplify buffer spec parsing code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7260:7,Simpl,Simplify,7,https://hail.is,https://github.com/hail-is/hail/pull/7260,1,['Simpl'],['Simplify']
Usability,[hail] Simplify nested insert fields,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6456:7,Simpl,Simplify,7,https://hail.is,https://github.com/hail-is/hail/pull/6456,1,['Simpl'],['Simplify']
Usability,[hail] Simplify nested struct inserts broken by lets,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7096:7,Simpl,Simplify,7,https://hail.is,https://github.com/hail-is/hail/pull/7096,1,['Simpl'],['Simplify']
Usability,"[hail] clean up BlockMatrixMap IRs, delegate optimization of broadcasting for scalars to Simplify pass",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7566:89,Simpl,Simplify,89,https://hail.is,https://github.com/hail-is/hail/pull/7566,1,['Simpl'],['Simplify']
Usability,[hail] simplify region value fromBytes code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7259:7,simpl,simplify,7,https://hail.is,https://github.com/hail-is/hail/pull/7259,2,['simpl'],['simplify']
Usability,[hail] write undocumented function for passing expr to sparsify_row_intervals,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8120:13,undo,undocumented,13,https://hail.is,https://github.com/hail-is/hail/pull/8120,2,['undo'],['undocumented']
Usability,[hailtop.batch] simplify BPE implementation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10322:16,simpl,simplify,16,https://hail.is,https://github.com/hail-is/hail/pull/10322,2,['simpl'],['simplify']
Usability,[hailtop.utils] Add Batch monitor and custom multi-state progress bar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14100:57,progress bar,progress bar,57,https://hail.is,https://github.com/hail-is/hail/pull/14100,2,['progress bar'],['progress bar']
Usability,[hailtop][batch] unify & simplify docker transient error handling,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11943:25,simpl,simplify,25,https://hail.is,https://github.com/hail-is/hail/pull/11943,2,['simpl'],['simplify']
Usability,[jvm-fs] simplify use of URLs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13650:9,simpl,simplify,9,https://hail.is,https://github.com/hail-is/hail/pull/13650,2,['simpl'],['simplify']
Usability,[libhail] Add simple testing infrastructure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10231:14,simpl,simple,14,https://hail.is,https://github.com/hail-is/hail/pull/10231,2,['simpl'],['simple']
Usability,[memory] add simple read-only cache,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9349:13,simpl,simple,13,https://hail.is,https://github.com/hail-is/hail/pull/9349,2,['simpl'],['simple']
Usability,[notebook] fix some simple problems,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6834:20,simpl,simple,20,https://hail.is,https://github.com/hail-is/hail/pull/6834,2,['simpl'],['simple']
Usability,[query Start undoing value misuse related to ndarrays,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9708:13,undo,undoing,13,https://hail.is,https://github.com/hail-is/hail/pull/9708,2,['undo'],['undoing']
Usability,[query service] usability,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8585:16,usab,usability,16,https://hail.is,https://github.com/hail-is/hail/pull/8585,2,['usab'],['usability']
Usability,[query/compiler] Update simple dependencies,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10830:24,simpl,simple,24,https://hail.is,https://github.com/hail-is/hail/pull/10830,2,['simpl'],['simple']
Usability,[query/lir] assert postcondition of SimplifyControl,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9486:36,Simpl,SimplifyControl,36,https://hail.is,https://github.com/hail-is/hail/pull/9486,1,['Simpl'],['SimplifyControl']
Usability,[query/lir] simplify Classx.asBytes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9491:12,simpl,simplify,12,https://hail.is,https://github.com/hail-is/hail/pull/9491,2,['simpl'],['simplify']
Usability,[query/ptypes] simplify isOfType,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8261:15,simpl,simplify,15,https://hail.is,https://github.com/hail-is/hail/pull/8261,2,['simpl'],['simplify']
Usability,[query/service] simplify ServiceBackend by abstracting over ExecuteContext,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11646:16,simpl,simplify,16,https://hail.is,https://github.com/hail-is/hail/pull/11646,2,['simpl'],['simplify']
Usability,[query/service] use error id to raise user-friendly errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11624:38,user-friendly,user-friendly,38,https://hail.is,https://github.com/hail-is/hail/pull/11624,2,['user-friendly'],['user-friendly']
Usability,[query] Add simplify rule for repartition(range),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9158:12,simpl,simplify,12,https://hail.is,https://github.com/hail-is/hail/pull/9158,2,['simpl'],['simplify']
Usability,[query] Added simplify rules for nested ndarray maps and for ndarray shape,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10433:14,simpl,simplify,14,https://hail.is,https://github.com/hail-is/hail/pull/10433,2,['simpl'],['simplify']
Usability,[query] ArraySlice simplify,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10759:19,simpl,simplify,19,https://hail.is,https://github.com/hail-is/hail/pull/10759,2,['simpl'],['simplify']
Usability,[query] ArraySlice simplify rules,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10755:19,simpl,simplify,19,https://hail.is,https://github.com/hail-is/hail/pull/10755,2,['simpl'],['simplify']
Usability,[query] Begin simplifying EmitCode constructors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10009:14,simpl,simplifying,14,https://hail.is,https://github.com/hail-is/hail/pull/10009,2,['simpl'],['simplifying']
Usability,[query] Clear TableKeyByAndAggregate context region in SeqOp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11312:8,Clear,Clear,8,https://hail.is,https://github.com/hail-is/hail/pull/11312,1,['Clear'],['Clear']
Usability,[query] Clear the bdist build cache before building the wheel,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12008:8,Clear,Clear,8,https://hail.is,https://github.com/hail-is/hail/pull/12008,1,['Clear'],['Clear']
Usability,[query] Drastically simplify binding-based computation/rewrite code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9247:20,simpl,simplify,20,https://hail.is,https://github.com/hail-is/hail/pull/9247,2,['simpl'],['simplify']
Usability,[query] Fix FilterIntervals simplify rule,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12179:28,simpl,simplify,28,https://hail.is,https://github.com/hail-is/hail/pull/12179,2,['simpl'],['simplify']
Usability,[query] Fix insert fields simplify bug,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11198:26,simpl,simplify,26,https://hail.is,https://github.com/hail-is/hail/pull/11198,2,['simpl'],['simplify']
Usability,[query] Fix simplify rule for nested TableFilterIntervals,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9114:12,simpl,simplify,12,https://hail.is,https://github.com/hail-is/hail/pull/9114,2,['simpl'],['simplify']
Usability,[query] Fix simplify rules related to interval filter pushdown,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9179:12,simpl,simplify,12,https://hail.is,https://github.com/hail-is/hail/pull/9179,2,['simpl'],['simplify']
Usability,[query] Fixed BlockMatrixToValueApply simplify rule,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10481:38,simpl,simplify,38,https://hail.is,https://github.com/hail-is/hail/pull/10481,2,['simpl'],['simplify']
Usability,[query] Fixed simplify InsertFields bug and added appropriate test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11340:14,simpl,simplify,14,https://hail.is,https://github.com/hail-is/hail/pull/11340,2,['simpl'],['simplify']
Usability,[query] NDArray Reshape Simplification,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9874:24,Simpl,Simplification,24,https://hail.is,https://github.com/hail-is/hail/pull/9874,1,['Simpl'],['Simplification']
Usability,[query] Simplify Elasticsearch Dependencies,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11410:8,Simpl,Simplify,8,https://hail.is,https://github.com/hail-is/hail/pull/11410,1,['Simpl'],['Simplify']
Usability,[query] Simplify HailTaskContext logic,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10301:8,Simpl,Simplify,8,https://hail.is,https://github.com/hail-is/hail/pull/10301,1,['Simpl'],['Simplify']
Usability,[query] Simplify and clarify aggregator memory ownership,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9253:8,Simpl,Simplify,8,https://hail.is,https://github.com/hail-is/hail/pull/9253,1,['Simpl'],['Simplify']
Usability,[query] Simplify and improve EmitCode store code.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10338:8,Simpl,Simplify,8,https://hail.is,https://github.com/hail-is/hail/pull/10338,1,['Simpl'],['Simplify']
Usability,"[query] The VDS docs need to be crystal clear about ""dense"" and ""sparse""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14009:40,clear,clear,40,https://hail.is,https://github.com/hail-is/hail/issues/14009,2,['clear'],['clear']
Usability,[query] Unify CloudCredentials and Simplify BatchClient,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14684:35,Simpl,Simplify,35,https://hail.is,https://github.com/hail-is/hail/pull/14684,1,['Simpl'],['Simplify']
Usability,[query] add simplification for TableFilterIntervals with empty intervals,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11693:12,simpl,simplification,12,https://hail.is,https://github.com/hail-is/hail/pull/11693,2,['simpl'],['simplification']
Usability,[query] always allow simplify to repartition,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13218:21,simpl,simplify,21,https://hail.is,https://github.com/hail-is/hail/pull/13218,2,['simpl'],['simplify']
Usability,[query] fix performance bug in lir.SimplifyControl,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9475:35,Simpl,SimplifyControl,35,https://hail.is,https://github.com/hail-is/hail/pull/9475,1,['Simpl'],['SimplifyControl']
Usability,[query] hl.pc_relate should more clearly indicate and provide better defaults for calculating PC scores,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14008:33,clear,clearly,33,https://hail.is,https://github.com/hail-is/hail/issues/14008,2,['clear'],['clearly']
Usability,[query] import_table: simplify code and improve speed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11782:22,simpl,simplify,22,https://hail.is,https://github.com/hail-is/hail/pull/11782,2,['simpl'],['simplify']
Usability,[query] pca simplification/optimization,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10264:12,simpl,simplification,12,https://hail.is,https://github.com/hail-is/hail/pull/10264,2,['simpl'],['simplification']
Usability,[query] simplify fs interface,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8388:8,simpl,simplify,8,https://hail.is,https://github.com/hail-is/hail/pull/8388,2,['simpl'],['simplify']
Usability,[query] simplify ndarray coiterate interface,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10622:8,simpl,simplify,8,https://hail.is,https://github.com/hail-is/hail/pull/10622,2,['simpl'],['simplify']
Usability,[query] simplify strange stdev formula,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10132:8,simpl,simplify,8,https://hail.is,https://github.com/hail-is/hail/pull/10132,2,['simpl'],['simplify']
Usability,[query][bugfix] clear region in rvd.countPerPartition,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9009:16,clear,clear,16,https://hail.is,https://github.com/hail-is/hail/pull/9009,2,['clear'],['clear']
Usability,[query][qob] simplify QoB error handling and fix flaky test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12470:13,simpl,simplify,13,https://hail.is,https://github.com/hail-is/hail/pull/12470,2,['simpl'],['simplify']
Usability,[shuffler] Refactor/simplify codegen interfaces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10421:20,simpl,simplify,20,https://hail.is,https://github.com/hail-is/hail/pull/10421,2,['simpl'],['simplify']
Usability,[stacked] implement a simple left join right distinct on a partition's worth of data?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4998:22,simpl,simple,22,https://hail.is,https://github.com/hail-is/hail/pull/4998,2,['simpl'],['simple']
Usability,[tls] Simplify TLS use and enable TLS for address,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9554:6,Simpl,Simplify,6,https://hail.is,https://github.com/hail-is/hail/pull/9554,1,['Simpl'],['Simplify']
Usability,"[uv](https://github.com/astral-sh/uv) is a new package resolver by the same folks who make `ruff`. It's boasted for being really fast, which honestly it is, but mostly it's appealing to me because they support generating lockfiles for alternative platforms and python versions than the system you run it on, which allows us to delete all this dockerizing `pip-compile` in order to generate lockfiles for linux. It's a really green project, so I'm open to pushback on incorporating it, but it seemed like a worthwhile simplification. I also quite like that it allows for additional strategies in generating lockfiles. By default, it behaves as would be expected, where it locks packages to the highest version within the acceptable bounds. But you can also configure it to generate the *lowest* acceptable pins, so we could actually verify whether the lower bounds that we have in our requirements files are actually acceptable or not.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14503:517,simpl,simplification,517,https://hail.is,https://github.com/hail-is/hail/pull/14503,1,['simpl'],['simplification']
Usability,[vcf-combiner] Usability improvements to vcf combiner,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8378:15,Usab,Usability,15,https://hail.is,https://github.com/hail-is/hail/pull/8378,1,['Usab'],['Usability']
Usability,[website] Simplify service and deployment discrepancy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12431:10,Simpl,Simplify,10,https://hail.is,https://github.com/hail-is/hail/pull/12431,1,['Simpl'],['Simplify']
Usability,[website] add a link to the community feedback survey to website,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13986:38,feedback,feedback,38,https://hail.is,https://github.com/hail-is/hail/pull/13986,2,['feedback'],['feedback']
Usability,[wip] perform simple CSE during python IR serialization,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6688:14,simpl,simple,14,https://hail.is,https://github.com/hail-is/hail/pull/6688,2,['simpl'],['simple']
Usability,[www/docs] remove undocumented methods,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7292:18,undo,undocumented,18,https://hail.is,https://github.com/hail-is/hail/issues/7292,2,['undo'],['undocumented']
Usability,"[www/docs] simplify section rule, enable scrollto functions",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7288:11,simpl,simplify,11,https://hail.is,https://github.com/hail-is/hail/pull/7288,2,['simpl'],['simplify']
Usability,[www] simplify templates,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8455:6,simpl,simplify,6,https://hail.is,https://github.com/hail-is/hail/pull/8455,2,['simpl'],['simplify']
Usability,"_From @cseed on September 1, 2015 15:48_. Need general strategy for error reporting. We can't use asserts for input data validation (e.g., reading tsv files, command line flags, etc.) Need to generate good error messages with feedback about line numbers, etc. _Copied from original issue: cseed/hail#42_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/33:226,feedback,feedback,226,https://hail.is,https://github.com/hail-is/hail/issues/33,1,['feedback'],['feedback']
Usability,"_From @jbloom22 on October 14, 2015 1:23_. Cotton, I haven't implemented good testing yet, but would appreciate some initial feedback on the code as I take a break to write up the math. I've done some comparison with R and it checks out so far. It runs on the command line, but you'll need to create a covariate file from your PCs. _Copied from original issue: cseed/hail/pull/81_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/50:125,feedback,feedback,125,https://hail.is,https://github.com/hail-is/hail/issues/50,1,['feedback'],['feedback']
Usability,"_From @jbloom22 on September 29, 2015 17:15_. In computing statistics like sample and variant qc, we should not treat X/Y like the autosomes. A simple solution is to only compute on the autosome, but we should discuss with the community how to make the tools more powerful via sex awareness. for example, we could split all stats by sex, or just sex chromosome stats by sex, ... _Copied from original issue: cseed/hail#64_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/44:144,simpl,simple,144,https://hail.is,https://github.com/hail-is/hail/issues/44,1,['simpl'],['simple']
Usability,"`IEmitCode.consume`, with signature `consume[T](cb: EmitCodeBuilder, ifMissing: => Unit, ifPresent: (A) => T): T`, is wrong: it exports a value that is only defined in the present branch to be used after the two branches have joined. The only use of this manually guarded the exported value by a bit remembering which branch was taken, but this is better handled by memoizing the `IEmitCode` in an `EmitValue`. Almost every other use of `consume` could be more simply expressed using `handle`, and moreover almost every use of `handle` could be more simply expressed using a method `get` which simply throws an exception if the missing branch is taken. For those few cases where one really does want to consume an `IEmitCode` to a `Code` or `PCode`, with definitions given for each branch, I added `consumeCode` and `consumePCode`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9447:461,simpl,simply,461,https://hail.is,https://github.com/hail-is/hail/pull/9447,3,['simpl'],['simply']
Usability,"`OnDiskBTreeIndexToValue` can index the elements at the base of a BTree. The BGen BTree is a BTree on the byte-offsets of variants in the BGen file. In a following PR, I will use this class to filter the BGen file to a subset of variants, specified by their index. This kind of filtering happens at the level of bytes, it permits me to avoid decoding/decompressing any variants I don't need. Ideally, the index would also include the variant keys themselves. That would be a really nice extension of this work and would enable a more natural file-level filtering user experience. Aside: `IndexBTree` could use some TLC. I'm sort of making the minimal changes to get Caitlin cooking. Last night, I slipped into a rewrite and it's just too big a task to get right before Friday because I don't have any documentation of precisely what our btree file format is.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3794:563,user experience,user experience,563,https://hail.is,https://github.com/hail-is/hail/pull/3794,1,['user experience'],['user experience']
Usability,"`Table._select` got way too complicated (mostly my fault) when key changing moved from `TableMapRows` to `TableKeyBy`. Making `_select` a simple wrapper around `TableMapRows`, and moving the key logic to `key_by`, made both way simpler. I then realized the `key_by` code could be even simpler by adding some rules to the optimizer to clean up the case where all new keys are existing fields. I actually think some things had gotten broken in the old `_select` (performance wise). In particular, in `split_multi`, in the `split_rows` function with `rekey=false`, I think it's supposed to extend the key from `['locus']` to `['locus', 'alleles']`, but that wasn't happening. I changed `key_by` to no longer accept `key_by(None)` or `key_by([])`, both of which should now be `key_by()`, which is more consistent with the rest of our interface, but is a breaking change. Is it worth the disruption? Should I add a warning? Or just continue to accept both?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4455:138,simpl,simple,138,https://hail.is,https://github.com/hail-is/hail/pull/4455,3,['simpl'],"['simple', 'simpler']"
Usability,`TableCollect(TableOrderBy(...))` has a simplify rule that uses a local sort,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7144#issuecomment-570306267:40,simpl,simplify,40,https://hail.is,https://github.com/hail-is/hail/issues/7144#issuecomment-570306267,2,['simpl'],['simplify']
Usability,"`[0, 0.toFloat][0].toInt` results in a ClassCastException. We should fix the type promotion method, and should also replace the `makeLong` and `makeDouble` methods on TNumeric with a `conv: NumericConversion[_]` to simplify things and be consistent. @khernyo has claimed this!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/759:215,simpl,simplify,215,https://hail.is,https://github.com/hail-is/hail/issues/759,1,['simpl'],['simplify']
Usability,"```. dspr calls to the corresponding BLAS Level 2 command, which updates A to A + x.t \* x in place:; http://www.netlib.org/lapack/explore-html/d7/d15/group__double__blas__level2_ga22adb497a4f41eabc6a8dcac6f326183.html#ga22adb497a4f41eabc6a8dcac6f326183. Down the line we might also consider using BLAS level 3 dsyrk on each partition, which updates A to A + B.t \* B:; http://www.netlib.org/lapack/explore-html/d1/d54/group__double__blas__level3_gae0ba56279ae3fa27c75fefbc4cc73ddf.html#gae0ba56279ae3fa27c75fefbc4cc73ddf. @cseed The ArrayIndex exception on profile225k in the current master is concerning, and may be related to serialization. Here is the full stack trace:. ```; hail: grm: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 3.0 failed 1 times, most recent failure: Lost task 5.0 in stage 3.0 (TID 45, localhost): java.lang.ArrayIndexOutOfBoundsException: 1048578; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:345); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:47); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:804); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:570); at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:194); at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:147); at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:185); at org.apache.spark.util.collection.ExternalAppendOnlyMap.spill(ExternalAppendOnlyMap.scala:206); at org.apache.spark.util.collection.ExternalAppendOnlyMap.spill(ExternalAppendOnlyMap.scala:55); at org.apache.spark.util.collection.Spillable$class.maybeSpill(Spillable.scala:93); at org.apache.spark.util.collection.ExternalAppendOnlyMap.maybeSpill(ExternalAppendOnlyMap.scala:55); at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:158); at org",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/801#issuecomment-247861703:2320,clear,clear,2320,https://hail.is,https://github.com/hail-is/hail/pull/801#issuecomment-247861703,2,['clear'],['clear']
Usability,"```; +----+-------------+-----------------------+------------+------+-------------------------------------------------------+-----------------------------------------------+---------+-----------------------------+-------+----------+-----------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+-----------------------+------------+------+-------------------------------------------------------+-----------------------------------------------+---------+-----------------------------+-------+----------+-----------------------------+; | 1 | SIMPLE | billing_projects | NULL | ALL | billing_project_status | NULL | NULL | NULL | 30733 | 66.67 | Using where; Using filesort |; | 1 | SIMPLE | billing_project_users | NULL | ref | PRIMARY,billing_project_users_billing_project_user_cs | billing_project_users_billing_project_user_cs | 302 | batch.billing_projects.name | 1 | 100.00 | Using index |; +----+-------------+-----------------------+------------+------+-------------------------------------------------------+-----------------------------------------------+---------+-----------------------------+-------+----------+-----------------------------+; ```. versus. ```; +----+-------------+-----------------------+------------+-------+-------------------------------------------------------+-----------------------------------------------+---------+-----------------------------+-------+----------+------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+-----------------------+------------+-------+-------------------------------------------------------+-----------------------------------------------+---------+-----------------------------+-------+----------+------------------------------+; | 1 | PRIMARY | billing_projects | NULL | ALL | billing_project_status | NULL | NULL | NULL",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12652:643,SIMPL,SIMPLE,643,https://hail.is,https://github.com/hail-is/hail/pull/12652,2,['SIMPL'],['SIMPLE']
Usability,"`clear ""import"" graph: javautils > types > utils > expr` . Sounds good to me.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5152#issuecomment-456802543:1,clear,clear,1,https://hail.is,https://github.com/hail-is/hail/pull/5152#issuecomment-456802543,2,['clear'],['clear']
Usability,`copyFrom` method was simply wrong. Also needed to fix memory management; in `result` function. Fixes #8240,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8273:22,simpl,simply,22,https://hail.is,https://github.com/hail-is/hail/pull/8273,1,['simpl'],['simply']
Usability,"`curlylint` doesn't like logical blocks that produce incomplete html tags. This is the only instance in our codebase where we do that though. In either path of the if/else block we produce an open `a` tag and then close it out outside of the block. I reorganized it to avoid this and think it's actually more clear, and that creating open tags like this is a footgun to avoid since it's super easy not to close them (which we have had a lot).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10412:309,clear,clear,309,https://hail.is,https://github.com/hail-is/hail/pull/10412,1,['clear'],['clear']
Usability,"`hail` was hanging after all commands completed when running kudu commands against the quickstart. From the thread dump, it looked like it was spinning in the kudu client. Shutting down the kudu context seemed to fix the problem. See any problems with this patch? Also, I removed latest. It didn't seem to be used. ```; diff --git a/src/main/scala/org/kududb/spark/KuduContext.scala b/src/main/scala/org/kududb/spark/KuduContext.scala; index c48dcd4..71be7d2 100644; --- a/src/main/scala/org/kududb/spark/KuduContext.scala; +++ b/src/main/scala/org/kududb/spark/KuduContext.scala; @@ -41,8 +41,6 @@ class KuduContext(@transient sc: SparkContext,. val broadcastedKuduMaster = sc.broadcast(kuduMaster). - LatestKuduContextCache.latest = this; -; /**; * A simple enrichment of the traditional Spark RDD foreachPartition.; * This function differs from the original in that it offers the; @@ -169,10 +167,6 @@ class KuduContext(@transient sc: SparkContext,; def fakeClassTag[T]: ClassTag[T] = ClassTag.AnyRef.asInstanceOf[ClassTag[T]]; }. -object LatestKuduContextCache {; - var latest:KuduContext = null; -}; -; object KuduClientCache {; var kuduClient: KuduClient = null; var asyncKuduClient: AsyncKuduClient = null; @@ -195,4 +189,14 @@ object KuduClientCache {; asyncKuduClient; }. + def close() {; + if (kuduClient != null) {; + kuduClient.close(); + kuduClient = null; + }; + if (asyncKuduClient != null) {; + asyncKuduClient.close(); + asyncKuduClient = null; + }; + }; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/242#issuecomment-220667612:753,simpl,simple,753,https://hail.is,https://github.com/hail-is/hail/pull/242#issuecomment-220667612,2,['simpl'],['simple']
Usability,`hailctl dataproc modify`'s `--update-hail-version` and `--wheel` arguments cannot be used together. Using argparse's [mutually exclusive group](https://docs.python.org/3/library/argparse.html#mutual-exclusion) to enforce that makes the usage/help text clearer. ```; usage: hailctl dataproc modify [-h] [--num-workers NUM_WORKERS]; [--num-preemptible-workers NUM_PREEMPTIBLE_WORKERS]; [--graceful-decommission-timeout GRACEFUL_DECOMMISSION_TIMEOUT]; [--max-idle MAX_IDLE] [--dry-run] [--zone ZONE]; [--update-hail-version | --wheel WHEEL]; name; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8918:253,clear,clearer,253,https://hail.is,https://github.com/hail-is/hail/pull/8918,1,['clear'],['clearer']
Usability,"`hailctl` allows the user to define a `network` for a new dataproc cluster, but not a `subnet`. The `network` flag in `gcloud` only works for `auto` and `legacy` project networks. If a Google Project has a custom network, the `subnet` must be supplied manually. This PR adds that functionality to `hailctl`. Its a very simple passthrough, so not much effort was required.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13129:319,simpl,simple,319,https://hail.is,https://github.com/hail-is/hail/pull/13129,1,['simpl'],['simple']
Usability,"`hl.balding_nichols_model` generates a MatrixTable representing a genetic dataset randomly drawn according to the Balding Nichols model.; ```; In [5]: hl.balding_nichols_model(2,3,3).show() ; 2019-08-15 10:38:05 Hail: INFO: balding_nichols_model: generating genotypes for 2 populations, 3 samples, and 3 variants...; +---------------+------------+------+------+------+; | locus | alleles | 0.GT | 1.GT | 2.GT |; +---------------+------------+------+------+------+; | locus<GRCh37> | array<str> | call | call | call |; +---------------+------------+------+------+------+; | 1:1 | [""A"",""C""] | 0/0 | 0/0 | 0/1 |; | 1:2 | [""A"",""C""] | 1/1 | 1/1 | 1/1 |; | 1:3 | [""A"",""C""] | 1/1 | 0/1 | 0/0 |; +---------------+------------+------+------+------+. ```; These MatrixTables are useful both as examples and test datasets for genetics-related Hail code. Unfortunately, the loci are chosen sequentially starting with chromosome 1, position 1. This region of chromosome 1 is in the telomere. Many genetic annotations contain no information in this region. As a result, `hl.balding_nichols_model` is not useful when demonstrating the annotation database or third-party genetic annotations. We want to enhance `hl.balding_nichols_model` to select variants (loci-allele-array pairs) that are likely to appear in real genetic datasets. One very simple model would be to draw variants according to their alternate/minor allele frequency in the gnomAD or 1000 Genomes datasets. An additional improvement would be to generate chromosomes roughly proportionally to their true sizes. These changes should not significantly slow down the method. We may want to include a small dataset of allele frequencies with Hail for use when the requested number of variants is small, only loading the full gnomAD or 1000 Genomes allele frequencies when the requested number of variants is in the millions or tens of millions. This functionality should be enabled and disabled by a parameter to `hl.balding_nichols_model`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6880:1328,simpl,simple,1328,https://hail.is,https://github.com/hail-is/hail/issues/6880,1,['simpl'],['simple']
Usability,"`inHemiX` depends on sex. How about `inXPar` and `inXNonPar`, so that Non clearly just refers to Par? This reads as ""in the X pseudo-autosomal region"" or ""in the X non-pseudo-autosomal-region""",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/499#issuecomment-235665809:74,clear,clearly,74,https://hail.is,https://github.com/hail-is/hail/pull/499#issuecomment-235665809,2,['clear'],['clearly']
Usability,"`java.nio` avoids unnecessary copies. We suspect we may see a 2-3x improvement in Zstd decoding speed by passing it `ByteBuffer` instead of `Array[Byte]`. We also suspect there may be pervasive (but minor) improvements to Hail's I/O infrastructure. We should start with the egregious examples. Consider `AzureStorageFS.createNoCompression`'s [`OutputStream`](https://github.com/hail-is/hail/blob/main/hail/src/main/scala/is/hail/io/fs/AzureStorageFS.scala#L332-L342):; ```scala; val os: PositionedOutputStream = new FSPositionedOutputStream(4 * 1024 * 1024) {; private[this] val client: BlockBlobClient = blockBlobClient; private[this] val blobOutputStream = client.getBlobOutputStream(true). override def flush(): Unit = {; bb.flip(). if (bb.limit() > 0) {; blobOutputStream.write(bb.array(), 0, bb.limit()); }. bb.clear(); }; // ...; }; ```. Notice how we already have a `ByteBuffer` but we convert it to an array and send that to the OutputStream. Instead, we could just use the [`ByteChannel` methods of `BlockBlobClient`](https://learn.microsoft.com/en-us/java/api/com.azure.storage.blob.specialized.blockblobclient?view=azure-java-stable#com-azure-storage-blob-specialized-blockblobclient-openseekablebytechannelwrite(com-azure-storage-blob-options-blockblobseekablebytechannelwriteoptions)). The [read case also supports a channel](https://learn.microsoft.com/en-us/java/api/com.azure.storage.blob.specialized.blobclientbase?view=azure-java-stable#com-azure-storage-blob-specialized-blobclientbase-openseekablebytechannelread(com-azure-storage-blob-options-blobseekablebytechannelreadoptions-com-azure-core-util-context)). The next, more complicated problem, is the InputBuffer and OutputBuffer interfaces. These assume their sources/sinks are `java.io.InputStream` and `java.io.OutputStream`. Moreover, they too rely on and expose `Array[Byte]` interfaces (e.g. `readBytesArray` and the implementation of `StreamInputBuffer.readBytes`). Let's start with InputBuffer and the decoders and use de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13840:816,clear,clear,816,https://hail.is,https://github.com/hail-is/hail/issues/13840,2,"['clear', 'learn']","['clear', 'learn']"
Usability,"`order_by` supports sort fields. Eventually `order_by` will use the shuffler. To support this `CodeOrdering` needs to support sort fields. I didn't actually add any tests. The Shuffler will eventually land and use this to do non-standard orderings. There's a lot of noise due to threading SortField's everywhere, but the implementation of `CodeOrdering.reverse` and `PType.codeOrdering` are actually quite simple. I also cleaned the code that I touched by abstracting over lt, lteq, gt, gteq.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7257:406,simpl,simple,406,https://hail.is,https://github.com/hail-is/hail/pull/7257,1,['simpl'],['simple']
Usability,`orjson` 3.9.15 fixed the rare segfault that we saw in `3.9.11`. Besides just updating to latest patch and minor versions:. - Removed a redundant requirement of `orjson` in `gear/requirements.txt` -- it inherits `orjson` from hailtop; - Bokeh `3.4` made a breaking change w.r.t. the `circle` method on figures. I have restricted the bounds for `bokeh` to avoid this breaking change but will follow up with a PR that changes our usage of bokeh to follow the deprecation/upgrade advice and undo the bounds restriction,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14471:488,undo,undo,488,https://hail.is,https://github.com/hail-is/hail/pull/14471,1,['undo'],['undo']
Usability,"`switch` can either be used with `Code[T]`s or `JoinPoint[Unit]`s. The former resemble's Java's `switch` by executing the code in the matched case. The latter in some cases generates less bytecode; it simply jumps to the join point for the matched case. ```scala; Code.switch[T](target: Code[Int], dflt: Code[T], cases: Seq[Code[T]]): Code[T]; JoinPoint.switch(target: Code[Int], dflt: JoinPoint[Unit], cases: Seq[JoinPoint[Unit]]): Code[Ctrl]; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7207:201,simpl,simply,201,https://hail.is,https://github.com/hail-is/hail/pull/7207,1,['simpl'],['simply']
Usability,"`test_rectangles_to_numpy` shouldn't pass on local, that's one of the weird ones where we don't understand why it's passing, it's clearly unlowered. In fact, in this PR I added the `fail_local` annotation to it. I'll try what you suggested.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11637#issuecomment-1078198872:130,clear,clearly,130,https://hail.is,https://github.com/hail-is/hail/pull/11637#issuecomment-1078198872,2,['clear'],['clearly']
Usability,"`tls.py` has many different functions with long names. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I push",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9862:303,simpl,simplified,303,https://hail.is,https://github.com/hail-is/hail/pull/9862,1,['simpl'],['simplified']
Usability,"`write_pipeline_outputs` returns a list for resource groups (which kills the command run). simplest fix is to change the last line in that function to:; ```; return [x for ext, rf in r._resources.items() for x in write_pipeline_outputs(rf, dest + '.' + ext)]; ```; A `yield` type function might be more elegant, but sounds like you might be tearing this up a little bit anyway, so I leave that to you.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5868:91,simpl,simplest,91,https://hail.is,https://github.com/hail-is/hail/issues/5868,1,['simpl'],['simplest']
Usability,"a few things happening here, most of which was me trying to not have to explicitly list dependencies in the shadowJar/shadowTestJar tasks:; - upgraded gradle to 5.0 and some plugins to be compatible; - split compile dependencies into ""bundled"" and ""unbundled"" to more explicitly separate the things we want in the jars and dependencies that we don't want bundled/are currently depending on the spark installation for. I did it this way because the shadowJar `exclude` filter does not let you exclude transitive dependencies, and I just wanted to exclude the entire spark/scala dependency tree.; - there was a problem where trying to run the tests kept giving me the ""Could not find or load main class org.testng.TestNG"" error, despite the class clearly being findable from the classpath I was providing. I added some excludes per this:; https://stackoverflow.com/questions/51455197/gradle-fatjar-could-not-find-or-load-main-class; (although I believe this is no longer strictly necessary after excluding all the transitive spark dependencies)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6248:745,clear,clearly,745,https://hail.is,https://github.com/hail-is/hail/pull/6248,1,['clear'],['clearly']
Usability,"a homogenous set of named values of type `T`.; 1. an `array<T>` and a `dict<str, int>`, the values are stored in the array and the names are stored in a separate dictionary mapping names to their indices; 2. a `dict<str, T>`, the name-value pairs are stored as dictionary key-value pairs; 3. a `struct{name1: T, name2: T, ... nameN: T}`, the name-value pairs are stored as field name, field string pairs. The third option is the most space efficient: the type stores the field names and there is no bookkeeping overhead per-set-of-named-values. The first two options repeat the field names for each occurrence (in particular, consider a Table field or MatrixTable entry-indexed field). The first two options needlessly encode the length (which is statically known). The third option is the most access-time-efficient: the offset of any named-value is known at hail compile time. The first two options require a logarithmic search of hail's dictionary tree representation. The third option is more user-friendly for accessing: `x.name`. The first is the least user-friendly: `x[indices[""name""]]`. The first and third options are the most cache-friendly for homogenous operations. The first uses `ArrayExpression.map`, so code size is `O(CODE)`. The third option's code size is `O(CODE * #VALUES)` because structs have no `map`-like primitive. The third option is also not user-friendly for homogenous operations (the user must repeat the code for each name-value pair). The third is the most self-documenting option. The number of fields and their names are visible in `ds.describe()`. The first is the next best because the dictionary is likely a global field that can be viewed with `x.indices.show()`. ---. ## Phase 1; Implement a new virtual type `tstaticdict<T, name1, name2, ..., nameN>` who's physical type is `PStruct` with N fields. These changes span Scala and Python. Implement `map` and `__getitem__` on `StaticDictExpression`s. `map` is implemented by code duplication. ## Phase 2; Implem",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6881:1031,user-friendly,user-friendly,1031,https://hail.is,https://github.com/hail-is/hail/issues/6881,1,['user-friendly'],['user-friendly']
Usability,"a simpler solution which was attractive because the microservices are looking more and more like services and less like web servers (even more so moving all the rendering to the front end with the web app, the legacy version of scorecard using jinja is not the representative case). Did you look at aiohttp?; > * From the code:; > > Global variables that are modified ...; > ; > ; > I don't want to have to think about shared state and locking. I want a shared-nothing architecture in the microservices where the only globals are true constants and threads communication by sending immutable data through queues.; > * Finally, a meta-comment. I started reviewing this when it was just ujson, I did a bit of research about json packages to understand your choices and when I came back, the PR had expanded with all the async stuff. I would have approved the ujson stuff. The async stuff could have been a separate PR. Nobody wants to review a moving target, so the scope of a change should be roughly frozen when you assign a PR and additional changes should be minimized and restricted to that scope. You're welcome to have an open PR with no reviewer if you're still fleshing out the scope, of course. Thanks!. In response:. 1) aiohttp is an option, but appears to be generally considered slow on a per-response basis (published benchmarks, haven't had a chance to try it), even potentially slower than flask. It seems wrong to choose something slower if there are are reasonable alternatives.; 2) The globals were a feature of the initial implementation (the GitHub cache). It felt outside of the scope of my PR to change that to some queue solution. Meta comment. Ok. I didn't think it had been looked at, and expanded what it did pretty quickly, as I realized that ujson wasn't helping much. I can make a ujson-specific pr, but my goal was to test async library implementations in a simple applications, since we need a long term strategy for python web stuff that isn't Flask (or not just Flask)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5242#issuecomment-461191051:2115,simpl,simple,2115,https://hail.is,https://github.com/hail-is/hail/pull/5242#issuecomment-461191051,2,['simpl'],['simple']
Usability,"a931de0"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""42.0.2""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,509,454,616,584,479,509,509,509,509,589,509,691,399,479,399,539,479,479,616,616,489,519],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14329:13056,Learn,Learn,13056,https://hail.is,https://github.com/hail-is/hail/pull/14329,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,ableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Missing Range header in response; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/aou_tmp/o?name=tmp/hail/icullIwHC8dQXtq8JU2uDW/aggregate_intermediates/-ntpjdAQ9sKaR8lK26cV0p5790a4d87-9035-41ae-afc6-326f710d9a89&uploadType=resumable&upload_id=ADPycdtl5JSqwvftT4W190_-ueC032I_oZcwLAlVVMFkqp06W4eY8b-XMwf8DeT7If9I7uIgmI_PLCuFsExsT0aEh2b4FrHtAiUktumQbvgl1U0icw; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ADPycdtl5JSqwvftT4W190_-ueC032I_oZcwLAlVVMFkqp06W4eY8b-XMwf8DeT7If9I7uIgmI_PLCuFsExsT0aEh2b4FrHtAiUktumQbvgl1U0icw; 	| ; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:185) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:117) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:98) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionQueryTask.call(JsonResumableSessionQueryTask.java:100) ~[gs:__hail-query-ger0g_jars_13536,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13721:5299,Resume,Resume,5299,https://hail.is,https://github.com/hail-is/hail/issues/13721,1,['Resume'],['Resume']
Usability,ables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.exp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:7741,Simpl,Simplify,7741,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"accept a prefix with a complete file path:; <code>IOUtil.createTempDir(&quot;path/to/my/tempdir/prefix&quot;, &quot;&quot;)</code>. The new implementation will now throw in that case. You can use <code>Files.createTemporaryDirectory(path, prefix)</code> for those use cases instead.</p>; <p>4a4024a97 Fix temporary directory hijacking or temporary directory information disclosure (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1621"">#1621</a>); 9fd0ecf21 Disable codecov until we can fix the uploader (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1622"">#1622</a>); 347c0ac57 Fix EdgeReadIterator (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1616"">#1616</a>); d15a5bacb Added ULTIMA and ELEMENT as valid value for RG-PL according to SAM spec. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1619"">#1619</a>)</p>; <h2>3.0.0</h2>; <p>Htsjdk 3.0.0: Revenge of the Simple Allele</p>; <p>This is the first htsjdk with a major version increase in a long time. We bumped it to indicate there are some breaking changes that will potentially require downstream code changes. Notably, <code>Allele</code> became an interface instead of a concrete class. <code>SimpleAllele</code> may be used as a replacement if you have classes which previously subclassed allele.</p>; <p>New Plugin Infrastructure:; 6a60de7c2 Move API marker annotations into new annotation package. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1558"">#1558</a>); 7ac95d5f7 Plugin framework and interfaces for versioned file format codecs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1525"">#1525</a>); d40fe5412 Beta implementation of Bundles. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1546"">#1546</a>)</p>; <p>CRAM; 489c4192d Support CRAM reference regions. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1605"">#1605</a>); 22aec678",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12310:2286,Simpl,Simple,2286,https://hail.is,https://github.com/hail-is/hail/pull/12310,1,['Simpl'],['Simple']
Usability,add ability to get and clear sub-regions by index,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6499:23,clear,clear,23,https://hail.is,https://github.com/hail-is/hail/pull/6499,2,['clear'],['clear']
Usability,add clears to restrictToPKInterval,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3572:4,clear,clears,4,https://hail.is,https://github.com/hail-is/hail/pull/3572,2,['clear'],['clears']
Usability,add command reference to doc style guide,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/647:35,guid,guide,35,https://hail.is,https://github.com/hail-is/hail/pull/647,2,['guid'],['guide']
Usability,add how-to guides to documentation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4089:11,guid,guides,11,https://hail.is,https://github.com/hail-is/hail/pull/4089,2,['guid'],['guides']
Usability,add missing clear in sampleqc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3589:12,clear,clear,12,https://hail.is,https://github.com/hail-is/hail/pull/3589,2,['clear'],['clear']
Usability,add repartitionableness logic to Simplify,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4165:33,Simpl,Simplify,33,https://hail.is,https://github.com/hail-is/hail/pull/4165,1,['Simpl'],['Simplify']
Usability,add simplification rule for positive array index,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5359:4,simpl,simplification,4,https://hail.is,https://github.com/hail-is/hail/pull/5359,2,['simpl'],['simplification']
Usability,added a new benchmark:; ```; wm2b0-b9b:hail wang$ hail-bench compare old.json new.json --metric median; Name Ratio Time 1 Time 2; ---- ----- ------ ------; group_by_take_rekey 23.5% 23.902 5.612; ----------------------; Geometric mean: 23.5%; Simple mean: 23.5%; Median: 23.5%; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7194#issuecomment-538159223:243,Simpl,Simple,243,https://hail.is,https://github.com/hail-is/hail/pull/7194#issuecomment-538159223,1,['Simpl'],['Simple']
Usability,added disjoint interval. Happy to go over the code with you if you want -- it's pretty simple right now!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6109#issuecomment-492688221:87,simpl,simple,87,https://hail.is,https://github.com/hail-is/hail/pull/6109#issuecomment-492688221,2,['simpl'],['simple']
Usability,added flatten union simplify rule,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3432:20,simpl,simplify,20,https://hail.is,https://github.com/hail-is/hail/pull/3432,1,['simpl'],['simplify']
Usability,"addressed your comment (good catch). I commented out a simplify rule that is currently invalid, but will be possible to introduce soon.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7141#issuecomment-536620808:55,simpl,simplify,55,https://hail.is,https://github.com/hail-is/hail/pull/7141#issuecomment-536620808,2,['simpl'],['simplify']
Usability,"adds a notion of sparsity to BlockMatrixType; I've lifted all of the necessary logic except for Map/Map2, which needs #8072 to implement in a sensical way. I had originally implemented this as a dense boolean matrix, which makes a lot of transformations simpler, but for really large (and very sparse) block matrices, you end up needing ~GB of space just to store the sparsity matrix, which is pretty untenable. This version basically preserves the structure of the version on GridPartitioner, except that we're storing the unlinearized form of the block index.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8071:254,simpl,simpler,254,https://hail.is,https://github.com/hail-is/hail/pull/8071,1,['simpl'],['simpler']
Usability,"adings"", version='2.1', reference_genome='GRCh38'). File ~/.local/lib/python3.8/site-packages/hail/experimental/datasets.py:115, in load_dataset(name, version, reference_genome, region, cloud); 107 raise ValueError(f'Region {repr(region)} not available for dataset'; 108 f' {repr(name)} on cloud platform {repr(cloud)}.\n'; 109 f'Available regions: {regions}.'); 111 path = [dataset['url'][cloud][region]; 112 for dataset in datasets[name]['versions']; 113 if all([dataset['version'] == version,; 114 dataset['reference_genome'] == reference_genome])]; --> 115 assert len(path) == 1; 116 path = path[0]; 117 if path.startswith('s3://'):. AssertionError: ; ```. I'm a new Hail user and don't have the full context here, but it seems like there are at least three problems:. 1. An assert failed in production code, which indicates either the presence of a bug or an incorrect use of assert (e.g. using assert to check for value errors).; 2. The assert has no corresponding error message, so the user learns that something has gone wrong but can't easily tell what.; 3. The assert is bare. Bare asserts can get optimized out of code in ways that are difficult to foresee in advance, and are generally deprecated in favor of the `if error_condition: raise AssertionError(...)` pattern (see: https://discuss.python.org/t/stop-ignoring-asserts-when-running-in-optimized-mode/13132). **The Big Picture**. The bare assert pattern is used over 3k times in Hail. To be fair, many of these usages occur in test directories, where they're fine. But they also occur in application code, and often in the dangerous form `assert(expr1, expr2)` which will never fail (because a tuple with two falsy elements is truthy in python). These asserts are never actually getting checked. . Fixing all of them would be a heavy lift. One compromise solution might be to add a bare assert rule to the linter (e.g. https://pypi.org/project/flake8-assert-msg/). This would prevent the introduction of further bare asserts to the ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12952:1329,learn,learns,1329,https://hail.is,https://github.com/hail-is/hail/issues/12952,1,['learn'],['learns']
Usability,"ailing bits, `emitBit(b: Value[Boolean], trailingBits: Int)`, and `pad()`. Note that this interface forces the caller to track the statically known number of trailing bits. Illustrated using scala-like psuedocode. I pretend conditional and loop statements are virtualized to work on staged values, in which case they generate runtime code. This is straightforward to translate to our `CodeBuilder` interface. ```scala; // top level method, emit a required value of any type; // always leaves 0 trailing bits; emit(value: SValue, trailingBits: Int) {; // dispatch on type; }. // leaves `trailingBits + 1` trailing bits; emitMissingness(present: Value[Boolean], trailingBits: Int) {; if (missingFirst) emitBit(present, trailingBits); else emitBit(~present, trailingBits); }. // leaves 0 trailing bits; emitInt(value: Value[Int], _: Int) {; pad(); // flip the sign bit; emitInt(value ^ (1 << 31)); }. // leaves 0 trailing bits; emitArray(value: SIndexable, _: Int) {; // for simplicity, don't try to pack continuation and missing; // bits of first element with preceding bits; pad(); for ((i, elt) <- value.enumerate) { // runtime loop; emitBit(true, 0) // continuation bit; if (value.eltsRequired) { // static if; emit(elt, 1); } else {; emitMissingness(elt.present, 1); emit(elt.get, 2); }; }; emitBit(false, 0) // continuation bit; pad() ; }. // leaves 0 trailing bits; emitStruct(value: SBaseStruct, _trailingBits: Int) {; var trailingBits = _trailingBits; for (field <- value) { // static loop; if (field.required) { // static if; emit(field, trailingBits); } else {; emitMissingness(field.present, trailingBits); emit(field, trailingBits + 1); }; trailingBits = 0; }; }. emitKeyStruct(value: SBaseStruct, length: Value[Int], sign: Value[Int], _trailingBits: Int) {; var trailingBits = _trailingBits; for ((field, i) <- value.enumerate) { // static loop; if (i < length) { // runtime if; emitBit(false, trailingBits); emitBit(true, trailingBits + 1) // continuation bits; if (field.required) { // st",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14396:4514,simpl,simplicity,4514,https://hail.is,https://github.com/hail-is/hail/issues/14396,1,['simpl'],['simplicity']
Usability,"aken for CompileAndEvaluate -- Optimize -- ForwardRelationalLets : 6.605ms, total 363.564ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- PruneDeadFields : 29.964ms, total 394.795ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize : 371.542ms, total 395.164ms(); 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- LowerMatrixToTable -- Verify : 3.975ms, total 407.299ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- LowerMatrixToTable -- LoweringTransformation : 77.664ms, total 485.244ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- LowerMatrixToTable -- Verify : 1.780ms, total 487.281ms, tagged coverage 0.0; ...; ...; ...; 2019-11-06 18:44:11 root: INFO: Timer: aggregate:; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'Verify' (8): 8.109ms; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'ConvertToSafeValue' (2): 12.828ms; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'InitializeCompiledFunction' (2): 14.536ms; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'ForwardRelationalLets' (7): 20.388ms; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'FoldConstants' (7): 21.650ms; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'RunCompiledFunction' (2): 44.571ms; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'ExtractIntervalFilters' (7): 70.933ms; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'LoweringTransformation' (3): 79.703ms; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'Simplify' (7): 135.960ms; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'ForwardLets' (7): 200.163ms; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'Compile' (2): 269.978ms; 2019-11-06 18:44:11 root: INFO: Time taken for tag 'PruneDeadFields' (7): 274.850ms; 2019-11-06 18:44:11 root: INFO: Fraction covered by a tagged leaf: 13.383s (7.9%); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7476:4208,Simpl,Simplify,4208,https://hail.is,https://github.com/hail-is/hail/pull/7476,1,['Simpl'],['Simplify']
Usability,"also, a note on the comment - Konrad, Cotton, and I discussed a simple function ""write_expr"" in the experimental module that uses a dummy table and writes in globals.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5044#issuecomment-452252677:64,simpl,simple,64,https://hail.is,https://github.com/hail-is/hail/pull/5044#issuecomment-452252677,2,['simpl'],['simple']
Usability,"ambda, is defined as the sum of the squares of the means of each component normal random variable. Although the non-central chi-squared distribution has a closed form implementation (indeed, Hail implements this CDF: `hl.pchisqtail`), the generalized chi-squared distribution does not have a closed form. There are at least four distinct algorithms for evaluating the CDF. To my knowledge, the oldest one is by Robert Davies:. Davies, Robert. ""The distribution of a linear combination of chi-squared; random variables."" Applied Statistics 29 323-333. 1980. The [original publication](http://www.robertnz.net/pdf/lc_chisq.pdf) includes a Fortran implementation in the publication. Davies' [website](http://www.robertnz.net/QF.htm) also includes a C version. Hail includes a copy of the C version as `davies.cpp`. I suspect this code contains undefined behavior. Moreover, it is not supported on Apple M1 machines because we don't ship binaries for that platform. It seemed to me that the simplest solution is to port this algorithm to Scala. This PR is that port. I tested against the 39 test cases provided Davies with the source code. I also added some doctests based on the CDF plots from Wikipedia. The same 39 test cases are tested in Scala and in Python. I am open to suggestions for the name. `pgenchisq` seems to strike a balance between clarity and brevity. I believe this is the first CDF which can fail to converge. I included some relevant debugging information. I think we should standardize on a schema, but I need more examples before I am certain of the right standard. I am open to critique of `GeneralizedChiSquaredDistribution.scala` but I will strongly argue against significant refactoring. I worry that we will subtly break this algorithm. I directly reached out to Robert Davies to clarify the licensing of this algorithm. It appears to have been released at least under both GPL2 and MIT by unaffiliated third parties (who, really, have no right to apply a license to it). Do no",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12605:1778,simpl,simplest,1778,https://hail.is,https://github.com/hail-is/hail/pull/12605,1,['simpl'],['simplest']
Usability,"ambda:; ```; hl.loop(; lambda sum, ret, i, x:; hl.cond(i < 10, sum(i + 1, x + i), ret(x)),; 0, 0); ```. The second difference is in the typing. In this PR, the `hl.recur` expression is given the type of the entire loop. I would add a single new type `Bottom`, and give all expressions which jump (both the recur and the break expressions) the type `Bottom`. `Bottom` is the empty type, so there can be no closed expressions of type `Bottom`. In the type checker, `Bottom` is only allowed to appear in tail positions, and for `If`, we keep the rule that both branches must have the same type, so either both branches are `Bottom` or neither are. This keeps the semantics simple: an if statement either makes a value or it jumps away, there's no confusing mix. One nice property of this setup is that if an expression has a non-bottom type, then it is guaranteed not to jump away from itself (it may jump internally), so it is safe to method-wrap. This also make codegen very simple, and @iitalics has already implemented it! See `JoinPoint` and `JoinPoint.CallCC`. In the IR, I don't think this requires much change. If we're already adding a continuation context (as mentioned above), then `TailLoop` just needs to bind both a recur and a break continuation, where recur takes the loop variable types, and break takes the loop result type. Then `Recur` can be replaced by a `Jump` node which calls (jumps to) a continuation in context. There's also a middle ground where we make break continuations explicit in the IR, but we want to keep the scheme-like interface in python. Then the pass @cseed described for inferring where the loop exits are would just go in python instead of the emitter. > Using the stream interface seems wrong to me also. When I mentioned this, I was thinking we could reuse the region management logic from the stream emitter for loops, but I've since changed my mind. I think loops will have hard region management no matter what. > What's the type of the stream the loop t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7614#issuecomment-559072407:2293,simpl,simple,2293,https://hail.is,https://github.com/hail-is/hail/pull/7614#issuecomment-559072407,2,['simpl'],['simple']
Usability,andlerContext.java:336); 	io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267); 	; 	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100); 	at org.apache.spark.SparkContext.cancelAllJobs(SparkContext.scala:2209); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at sparklyr.Invoke.invoke(invoke.scala:139); 	at sparklyr.StreamHandler.handleMethodCall(stream.scala:123); 	at sparklyr.StreamHandler.read(stream.scala:66); 	at sparklyr.BackendHandler.channelRead0(handler.scala:51); 	at sparklyr.BackendHandler.channelRead0(handler.scala:4); 	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267); 	at io.netty.channel.Abstra,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:10953,Simpl,SimpleChannelInboundHandler,10953,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['Simpl'],['SimpleChannelInboundHandler']
Usability,"apparently gather runs things in the background even if; you do not await the gather task, which is different from; other awaitables (which simply do nothing), the result was; that batch nondeterministically succeeds, depending on; whether the tasks execute in the order of the program or not.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6846:140,simpl,simply,140,https://hail.is,https://github.com/hail-is/hail/pull/6846,1,['simpl'],['simply']
Usability,"ar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Widget>*` or `unique_ptr<Widget>&` is an in-out parameter, where the function needs to be able to point the pointer somewhere else.; * A const pointer or reference to a unique_ptr should never be used. Just pass a raw pointer or reference. Essentially the same rubric should be used for shared_ptr, replacing ""take ownership"" with ""share ownership"". If a function is simply using a value and isn't concerned with its lifetime management, it should be taking a raw pointer or reference, not a shared_ptr. It should be completely agnostic what method the caller is using to manage the lifetime of the object. Herb Sutter gives his typical thorough analysis of this question [here](https://herbsutter.com/2013/06/05/gotw-91-solution-smart-pointer-parameters/). > I would be fine with that extra learning curve and complexity if unique_ptr solved a difficult; problem. But - by definition! - it doesn't. It only works for the easy case where you have one; pointer to each object. The invariant that unique_ptr is designed to keep isn't that there is only one pointer to each object. There can be any number of aliases, changing over time, but at any time exactly one must be a unique_ptr, which documents which alias is the ""owner"". The design of and idioms around unique_ptr ensure that all non-owning aliases have lifetimes which are nested inside the lifetime of the owning pointer, and that ownership can be passed around unam",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:2365,simpl,simply,2365,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638,2,['simpl'],['simply']
Usability,assuming I haven't messed something up:; ```; wm2b0-b9b:hail wang$ hail-bench compare old.json new.json --metric median; Name Ratio Time 1 Time 2; ---- ----- ------ ------; group_by_collect_per_row 10.0% 38.441 3.852; ----------------------; Geometric mean: 10.0%; Simple mean: 10.0%; Median: 10.0%; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7195#issuecomment-538148467:265,Simpl,Simple,265,https://hail.is,https://github.com/hail-is/hail/pull/7195#issuecomment-538148467,1,['Simpl'],['Simple']
Usability,at is.hail.expr.ir.FreeVariables$$anonfun$is$hail$expr$ir$FreeVariables$$compute$1$1.apply(FreeVariables.scala:27); at is.hail.expr.ir.FreeVariables$$anonfun$is$hail$expr$ir$FreeVariables$$compute$1$1.apply(FreeVariables.scala:24); at scala.collection.Iterator$$anon$11.next(Iterator.scala:410); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.fold(TraversableOnce.scala:212); at scala.collection.AbstractIterator.fold(Iterator.scala:1334); at is.hail.expr.ir.FreeVariables$.is$hail$expr$ir$FreeVariables$$compute$1(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$.apply(FreeVariables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collec,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:6883,Simpl,Simplify,6883,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,at least something simple.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4960:19,simpl,simple,19,https://hail.is,https://github.com/hail-is/hail/issues/4960,1,['simpl'],['simple']
Usability,"ata and a hash function can cause this integer map to exceed its size limitations at a load factor of 5%. Even a 20x increase in footprint puts us at 400 million. Each element of that array has 6 entries, so we're at 1.2 billion. That definitely feels like the danger zone. Maybe there's more variants than Danfeng expects, maybe there's more overhead than we've accounted for. The GATK folks have been chasing down the fix. Kryo [released 4.0.0](https://github.com/EsotericSoftware/kryo/issues/431) which should fix this issue. Spark [upgraded to Kryo 4.0.0](https://github.com/apache/spark/pull/22179) on September 8th of 2018. (resolving [Spark-20389](https://issues.apache.org/jira/browse/SPARK-20389)). This change made it to 2.4.0, but it was not back ported to other versions of Spark. GATK [references a temporary fix via JVM options](; https://github.com/broadinstitute/gatk/issues/1524#issuecomment-189368808), which apparently forces the JVM to use an alternative hash function with better behavior in this specific case:; ```; spark.executor.extraJavaOptions -XX:hashCode=0; spark.driver.extraJavaOptions -XX:hashCode=0; ```; A [generally interesting blog post on Java's hashCode](https://srvaroa.github.io/jvm/java/openjdk/biased-locking/2017/01/30/hashCode.html), which I haven't fully read, claims that the JVM previously defaulted to a PRNG draw for an object's hash code. In JDK 8 it uses some function of the current thread state. It appears this old strategy is preserved as JVM hashCode parameter value 0 and is less likely to trigger the bad behavior in Kryo. This `-XX:hashCode` option is undocumented [1](https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html), [2](https://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html) 🤷‍♀️. Another suggested Kryo option is to disable reference tracking. This would cause duplicate objects in the object graph to be serialized twice:; ```java; Kryo kryo = new Kryo();; kryo.setReferences(false);; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5564:2201,undo,undocumented,2201,https://hail.is,https://github.com/hail-is/hail/issues/5564,1,['undo'],['undocumented']
Usability,"ate. Each principal has a; certificate which is given to all the principals to which it might; communicate. ### Encryption. TLS has many encryption schemes. I will focus on encryption using a *symmetric*; key because asymmetric schemes do not enable *forward secrecy* [2]. Under; forward secret schemes, the two parties share a private key unknown to all; adversaries. TLS 1.3 makes forward secrecy mandatory. I intend to eventually; require all our services to refuse to speak anything other than TLS 1.3. The shared private key is used to encrypt and decrypt messages sent over a; socket. This poses a problem: how do two parties who have never met each other; agree on a private key without revealing the key to the public? This is a; classic cryptography problem called [key; exchange](https://en.wikipedia.org/wiki/Key_exchange). The classic solution to; this problem is [Diffie-Hellman key; exchange](https://en.wikipedia.org/wiki/Diffie–Hellman_key_exchange). The; Wikipedia article has ""General overview"" which is quite clear. In addition to a key, the parties must agree on a cipher. There are many old,; insecure ciphers available. In the future I intend all our servers to refuse to; use insecure ciphers. Mozilla; [has a list of secure cipher suites](https://wiki.mozilla.org/Security/Server_Side_TLS#Recommended_configurations). ## New Hail Concepts. Every principal in our system has a secret: `ssl-config-NAME`. These secrets are; automatically created for a particular namespace by `tls/create_certs.py`. Who; trusts who (i.e. who is allowed to talk to whom) is defined by; `tls/config.yaml`. For example, `site` is defined in `config.yaml` as follows:. ```; - name: site; domain: site; kind: nginx; incoming:; - admin-pod; - router; ```. A principal named ""site"" exists. Site's domain names are `site`,; `site.NAMESPACE`, `site.NAMESPACE.svc.cluster.local`. Site's configuration files; should be in NGINX configuration file format. Site accepts incoming requests; from the principals",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:5930,clear,clear,5930,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['clear'],['clear']
Usability,"ately once per run. I ran; this three times using a commit very similar to `main` [1]. All three runs failed:. 1. In run 1, three partitions had this error.; 2. In run 2, one partition had a different error (#13721 to be exact).; 3. In run 3, two partitions had this error. After my fix [2] for this issues bug, the #13721 bug became super common! I saw it 50 times in my first run:; ```; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Missing Range header in response; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/aou_tmp/o?name=tmp/hail/icullIwHC8dQXtq8JU2uDW/aggregate_intermediates/-ntpjdAQ9sKaR8lK26cV0p5790a4d87-9035-41ae-afc6-326f710d9a89&uploadType=resumable&upload_id=ADPycdtl5JSqwvftT4W190_-ueC032I_oZcwLAlVVMFkqp06W4eY8b-XMwf8DeT7If9I7uIgmI_PLCuFsExsT0aEh2b4FrHtAiUktumQbvgl1U0icw; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ADPycdtl5JSqwvftT4W190_-ueC032I_oZcwLAlVVMFkqp06W4eY8b-XMwf8DeT7If9I7uIgmI_PLCuFsExsT0aEh2b4FrHtAiUktumQbvgl1U0icw; 	| ; ```. Luckily, that one is actually trivial to fix, we just need to [update to the latest GCS client; library](https://github.com/hail-is/hail/issues/13721#issuecomment-1737924344). # Test Code. ```python3; import hail as hl; import gnomad.utils.sparse_mt. tmp_dir = 'gs://danking/tmp/'; vds_file = 'gs://neale-bge/bge-wave-1.vds'; out = 'gs://danking/foo.vcf.bgz'. vds = hl.vds.read_vds(vds_file); mt = hl.vds.to_dense_mt(vds); t = gnomad.utils.sparse_mt.default_compute_info(mt); t = t.annotate(info=t.info.drop('AS_SB_TABLE')); t = t.annotate(info = t.info.drop(; 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; )); t = t.drop('AS_lowqual'). hl.methods.export_vcf(dataset = t, output = out, tabix = True). ```. # Failing Batch (in my namespace). https://internal.hail.is/dking/batch/batches/8?q=state%3Dbad. # Footnotes. [1] I was using `de009fdb89`, which I pushe",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13409#issuecomment-1737926184:1073,Resume,Resume,1073,https://hail.is,https://github.com/hail-is/hail/issues/13409#issuecomment-1737926184,1,['Resume'],['Resume']
Usability,atrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10633,Simpl,Simplify,10633,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyValue']"
Usability,"aving fundamental error against the OpenAPIv3 schema. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108859"">kubernetes/kubernetes#108859</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Support for gRPC probes is now in beta. GRPCContainerProbe feature gate is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108522"">kubernetes/kubernetes#108522</a>, <a href=""https://github.com/SergeyKanzhelev""><code>@​SergeyKanzhelev</code></a>)</li>; <li>Suspend job to GA. The feature gate <code>SuspendJob</code> is locked and will be removed in 1.26. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108129"">kubernetes/kubernetes#108129</a>, <a href=""https://github.com/ahg-g""><code>@​ahg-g</code></a>)</li>; <li>The AnyVolumeDataSource feature is now beta, and the feature gate is enabled by default. In order to provide user feedback on PVCs with data sources, deployers must install the VolumePopulators CRD and the data-source-validator controller. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108736"">kubernetes/kubernetes#108736</a>, <a href=""https://github.com/bswartz""><code>@​bswartz</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/9ecc1143a8f7b34264b48dea12edd4d66230476f""><code>9ecc114</code></a> [chore] update version</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/ae5fd81a0fbea7d7fdac8d418876acaa288bcc0f""><code>ae5fd81</code></a> fix: config reader handles bool types (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/218"">#218</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/7bbb327cee0d4ed908a5deb28aaf5a9ccc1f4602""><code>7bbb327</code></a> [chore] update version</li>; <li><a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:13597,feedback,feedback,13597,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['feedback'],['feedback']
Usability,"azing-fast-python-networking. In short, one of the creators of asyncio discusses uvloop performance relative to other libraries. They key is:. ""However, the performance bottleneck in aiohttp turned out to be its HTTP parser, which is so slow, that it matters very little how fast the underlying I/O library is."". <img width=""1001"" alt=""screen shot 2019-02-06 at 7 29 00 pm"" src=""https://user-images.githubusercontent.com/5543229/52382977-77a62d00-2a45-11e9-8c04-b8142586eb5c.png"">. <img width=""936"" alt=""screen shot 2019-02-06 at 7 29 19 pm"" src=""https://user-images.githubusercontent.com/5543229/52382985-812f9500-2a45-11e9-9155-97c00ef9784b.png"">. As an aside I've spent some time reading about this over the last ~month, and besides relatively consistent messaging about the messiness of Python's ecosystem, performance and user experience are deeply important to me, so when I read things like:. ""I don’t think performance matter. I think asgi does not matter in 2018 in general. Usability and complexity matters. Python is not very good choice for high performance system in any case...For me high performance python is a fantasy, but i don’t do aiohttp/python anymore. In the end it is up to @asvetlov"". from one of the creators of aiohttp, I'm not encouraged about the long-term health of the project. https://github.com/aio-libs/aiohttp/issues/2902. In the second branch related to this pull request, linked above, I chose Starlette, and it is a thin abstraction, nearly identical performance, over Uvicorn + httptools, which were both written by Yury Selivanov, the asyncio person I mention above. Starlette and Uvicorn are currently the fastest options, (Sanic isn't tested), by a relatively large margin, on Techempower's benchmarks. If there is a reference standard benchmark of http library performance, Techempower is it: https://www.techempower.com/benchmarks/#section=data-r17 . Starlette is something like base Go performance (though 1/5-1/10th the performance of Go's fasthttp libra",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5242#issuecomment-461259030:1631,Usab,Usability,1631,https://hail.is,https://github.com/hail-is/hail/pull/5242#issuecomment-461259030,1,['Usab'],['Usability']
Usability,"b.com/kubernetes/kubernetes/pull/53947. Batch: `kube_event_loop` is always involved. Always:; ```log; Traceback (most recent call last):; File ""/usr/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 384, in _make_request; six.raise_from(e, None); File ""<string>"", line 2, in raise_from; File ""/usr/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 380, in _make_request; httplib_response = conn.getresponse(); File ""/usr/lib/python3.6/http/client.py"", line 1331, in getresponse; response.begin(); File ""/usr/lib/python3.6/http/client.py"", line 297, in begin; version, status, reason = self._read_status(); File ""/usr/lib/python3.6/http/client.py"", line 258, in _read_status; line = str(self.fp.readline(_MAXLINE + 1), ""iso-8859-1""); File ""/usr/lib/python3.6/socket.py"", line 586, in readinto; return self._sock.recv_into(b); socket.timeout: timed out; ```. Seems that the simplest issue may be to increase `read_timeout` past 120 seconds, although depending on the causes of this issue, that may not eliminate the problem, and of course leaves a long delay, which may be unacceptable for the use-case. As for why read takes so long: not 100% sure yet, setting up batch and CI is still incomplete, and I have not triggered this error myself. My guess is that Kubernetes takes too long to generate the response, either due to garbage collection, or simply because the requested information takes N > 120 seconds to return. That would be a very long time for any reasonable response, so either the resource isn't ready and it waits, or there are network connectivity issues. If network issues, not sure what solutions are. If I were on AWS, I would think about using a larger instance, with a higher-bandwidth NIC.; * Possible connection: https://github.com/arangodb/arangodb/issues/7813 ; * Possible solution: Reduce work Kubernetes must do to return response. #### 2nd set of errors:; ```log; # Batch; ERROR	| 2018-12-18 21:25:00,095 	| server.py 	| run_forever:447 | run_forever:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4984#issuecomment-450444389:1094,simpl,simplest,1094,https://hail.is,https://github.com/hail-is/hail/issues/4984#issuecomment-450444389,2,['simpl'],['simplest']
Usability,"bandedBlocks is used to write those blocks intersecting a band around diagonal, and rectangularBlocks (or a subsequent improvement leveraging symmetry) will be used to write out all blocks overlapping a set of pre-specified LD blocks. . In Python I've exposed the blocks_to_keep option on BlockMatrix write and added BlockMatrix.write_banded along with a simple interface check. I'm not yet sure how I want to expose rectangular blocks on the Python side. I also fixed a GridPartitioner bug to properly catch overflow, replacing; ```; assert(numPartitions >= nBlockRows && numPartitions >= nBlockCols); ```; with; ```; require(nBlockRows.toLong * nBlockCols <= Int.MaxValue); ```. For the record, I compared `rectangularBlocks` as written to the following alternate implementation under a variety of contexts and found the included version to be faster even with a large number of partitions and a small number of rectangles:; ```; def rectangularBlocks(rectangles: Array[Array[Long]]): Array[Int] = {; val blocks = rectangles.par.aggregate(Set[Int]())( { case (b, r) =>; assert(r.length == 4); b ++ rectangularBlocks(r(0), r(1), r(2), r(3)) },; _ ++ _); .toArray; ; scala.util.Sorting.quickSort(blocks); ; blocks; }; ```; Using `par` for parallel aggregate above does speed things up for large numbers of large rectangles, but the included implementation is still faster with good scaling by design.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2890:355,simpl,simple,355,https://hail.is,https://github.com/hail-is/hail/pull/2890,1,['simpl'],['simple']
Usability,"based on #4061, and part of a broader move toward the four types of documentation . 1. Tutorials; 2. Reference/API ; 3. Explanation; 4. How-To Guides. This just moves some stuff around between sections 1 and 3. I'll put the beginning of the How-To Guides in a separate PR. . - change layout of tutorials landing page so that clicking on the tutorial title in the sidebar brings you to the actual tutorial; - delete Types tutorial and Missingness tutorial, which weren't really tutorials, and move some of their information to the Types and Missingness sections of Section III.; - break the ""Overview"" page into smaller subpages, and rename it to Hailpedia. This is section III of the documentation, but I don't like 'Explanation' or 'Overview' as a title. Other suggestions welcome.; - a few other edits to add additional explantation to some of the jupyter tutorials",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4064:143,Guid,Guides,143,https://hail.is,https://github.com/hail-is/hail/pull/4064,2,['Guid'],['Guides']
Usability,"basically, it now looks at the partitioner for the MatrixValues of its children when it executes, and only shuffles if rvds are non-disjoint. It removes empty rvds and separates children into non-disjoint piles, shuffles those independently, and then concatenates them together in sorted order. (I'm not sure how this behaves relative to the old behavior (coerce everything together) when we have multiple shuffles that need to happen, but at least filtering out empty RVDs helps a lot in e.g. the split-multi case where none of the variants need to be moved.). I think the (a?) better optimization would be to add smarter partitioning so that we're adjusting partition bounds and not really shuffling under most circumstances, but I thought I'd PR this first since at least there's a warning in python about unioning non-disjoint datasets (where this will avoid the scan). I also added tests for MatrixUnionRows and pulled out one of the simplify rules; TableUnion does an unsorted union (I'm not sure this is actually correct behavior now if the tables have keys) and pulling the union outside of a MatrixRowsTable can cause the ordering to be wrong.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4043:939,simpl,simplify,939,https://hail.is,https://github.com/hail-is/hail/pull/4043,1,['simpl'],['simplify']
Usability,"bility and complexity matters. Python is not very good choice for high performance system in any case...For me high performance python is a fantasy, but i don’t do aiohttp/python anymore. In the end it is up to @asvetlov"". from one of the creators of aiohttp, I'm not encouraged about the long-term health of the project. https://github.com/aio-libs/aiohttp/issues/2902. In the second branch related to this pull request, linked above, I chose Starlette, and it is a thin abstraction, nearly identical performance, over Uvicorn + httptools, which were both written by Yury Selivanov, the asyncio person I mention above. Starlette and Uvicorn are currently the fastest options, (Sanic isn't tested), by a relatively large margin, on Techempower's benchmarks. If there is a reference standard benchmark of http library performance, Techempower is it: https://www.techempower.com/benchmarks/#section=data-r17 . Starlette is something like base Go performance (though 1/5-1/10th the performance of Go's fasthttp library for simple responses, and much closer for anything involving database calls). Sanic also uses httptools and uvloop, but has more stuff.. so yeah maybe a bit slower than Starlette, or not, but the diff will probably be small. Regarding the benchmark you linked, it is benchmarking the power of sleep. There is something deeply wrong with their results. Sanic has 1800 timeouts, vs 200 for aiohttp, and 3x the connection errors. Fine, so Sanic is super slow. But look at their non-db tests. Sanic is >2x as fast, 0 timeouts. They aren't using anything Sanic specific to query the database, and both use the same event loop. Adding asyncio Postgres to two programs that fundamentally differ mainly in how the handle http requests and responses, shows the one that is faster at http requests/responses (Sanic) becoming much slower, and in fact reversing its relationship to Aiohttp. This is strange to say the least. I was really curious about this, so I ran the bench. First, I upgraded ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5242#issuecomment-461259030:2654,simpl,simple,2654,https://hail.is,https://github.com/hail-is/hail/pull/5242#issuecomment-461259030,2,['simpl'],['simple']
Usability,"bstract method `def partition(ctxRef: Ref): IR`. This makes defining a new `TableStage` a bit heavy syntactically, and means we can't inspect the type of the partition IR without apply the function to something. This PR replaces the abstract method with two fields `ctxRefName: String` and `partitionIR: IR`. It defines a method `def partition(ctx: IR): IR` using these, which is more ergonomic to use because the context isn't forced to be a `Ref`. * With the type of the partition result accessible, this PR requires that type to be a `TStream<TStruct>`. Without this requirement, there is no clear connection between the partitioner and the rest of the `TableStage`. The only violation of this requirement was mapping to some other type right before collecting; this use is accommodated by a `mapCollect` method which combines the steps. * The binding structure of `TableStage` has been slightly reorganized. The `letBindings`, which are used on the master, and the `broadcastVals` which are used on the driver (previously, they had to also be usable on master), have been teased apart. In the new structure:; * `letBindings` are as before: a sequence of bindings which are evaluated in sequence on the master, whose bindings are visible in the `contexts` expression and in the `broadcastVals`; * `broadcastVals` are now a separate sequence of bindings, which are evaluated on the master in parallel (each broadcast binding sees only the `letBindings`, no previous `broadcastVals`), and whose bindings are visible only in the `partitionIR`; * `globals` is now required to be a `Ref`, which is defined in `letBindings` and redefined in `broadcastVals`, so that the `Ref` is valid in later `letBindings`, in `contexts`, as well as in the `partitionIR`. This does mean that `globals` is always broadcast, even when it's just an empty struct. But since we're generating a `CollectDistributedArray` which always broadcasts a struct, adding a nested required empty struct shouldn't have any overhead. I ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8917:1231,usab,usable,1231,https://hail.is,https://github.com/hail-is/hail/pull/8917,1,['usab'],['usable']
Usability,bstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267); 	; 	The currently active SparkContext was created at:; 	; 	org.apache.spark.SparkContext.getOrCreate(SparkContext.scala); 	sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	java.lang.reflect.Method.invoke(Method.java:498); 	sparklyr.Invoke.invoke(invoke.scala:139); 	sparklyr.StreamHandler.handleMethodCall(stream.scala:123); 	sparklyr.StreamHandler.read(stream.scala:66); 	sparklyr.BackendHandler.channelRead0(handler.scala:51); 	sparklyr.BackendHandler.channelRead0(handler.scala:4); 	io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267); 	; 	at org.apache.spark.SparkContext.assertNotStopped(,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:9214,Simpl,SimpleChannelInboundHandler,9214,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['Simpl'],['SimpleChannelInboundHandler']
Usability,bstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.fold(TraversableOnce.scala:212); at scala.collection.AbstractIterator.fold(Iterator.scala:1334); at is.hail.expr.ir.FreeVariables$.is$hail$expr$ir$FreeVariables$$compute$1(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$.apply(FreeVariables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:7232,Simpl,Simplify,7232,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyMatrix']"
Usability,"but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzYWE2MzZiYi00NmJmLTQ3MjgtOGVjMC0yMDg0OWE4NzgyZGMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjNhYTYzNmJiLTQ2YmYtNDcyOC04ZWMwLTIwODQ5YTg3ODJkYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3aa636bb-46bf-4728-8ec0-20849a8782dc"",""prPublicId"":""3aa636bb-46bf-4728-8ec0-20849a8782dc"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[566],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13444:3279,Learn,Learn,3279,https://hail.is,https://github.com/hail-is/hail/pull/13444,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,cala.collection.AbstractIterator.fold(Iterator.scala:1334); at is.hail.expr.ir.FreeVariables$.is$hail$expr$ir$FreeVariables$$compute$1(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$.apply(FreeVariables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:7529,Simpl,Simplify,7529,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,cala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:7780,Simpl,Simplify,7780,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyMatrix']"
Usability,"can return in two possible ways:; - `Missing` - the stream is actually entirely missing; this usually happens if one of the parameters to a stream is missing (e.g. `ArrayRange(0, NA, 1) = NA`); - `State(s0)` - the stream has started; its initial state is `s0`. `step` can return in three possible ways as well:; - `EOS` - we've reached the End Of Stream, there are no more elements left.; - `Skip(s1)` - this iteration didn't produce an element, you must try stepping again with state `s1` (see ""design notes"").; - `Yield(elt, s1)` - the stream computed an element `elt`; the following stream state will be `s1`. **Design Notes**. - The `Skip` return is very useful for simplifying the implementation of `ArrayFilter`. There is basically no nice way to implement filter otherwise without introducing some significant code duplication.; - ~~The stream ""parameter"", as well as the `Empty` return, are not very useful for the basic streams in this PR. However, they simplify the implementation of `ArrayFlatMap` (aka ""composing"" two parameterized streams).~~ NOTE (to Patrick): I decided to abandon the ""empty"" return idea in favor of just providing ""default states"" that always yield empty streams. **Implementation Notes**. - The implementation makes great use of Scala's type system. Most of the streams are implemented first in a very type aware manner, where it is easy to reason about the types of data flowing in and out, before being instantiated with EmitTriplets and Envs which don't hold very much type information. For instance, we have the following helper for `map`:; ```scala; Parameterized[P, A].map(f: A => B): Parameterized[P, B]; ```; The emitter instantiates P = `Any`, A = `EmitTriplet`, B = `EmitTriplet` :/. - Complex streams will have non trivial control flow and jumps. Therefore `init` and `step` both take `JoinPointBuilder`s and return `Code[Ctrl]`, to indicate that they may create join points and do jumps. - I've utilized a cute continuation passing style trick in multiple",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7228:2000,simpl,simplify,2000,https://hail.is,https://github.com/hail-is/hail/pull/7228,1,['simpl'],['simplify']
Usability,can't find docs on VCF genotypes format assumptions. Not clear what makes them reset to missing.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3472:57,clear,clear,57,https://hail.is,https://github.com/hail-is/hail/issues/3472,2,['clear'],['clear']
Usability,"cated. I think it's worth considering what the first batch people should run might be and design for a minimal first experience. IMO, a temp bucket is an absolutely crucial piece of configuration before you can do anything interesting and configuring a temp bucket is something that `hailctl` can easily be very opinionated about. Container registry… I feel like there's harder questions there, and you can run a lot of cool batches before having to worry about provisioning your own. It's also not actually a part of the hailctl config (unless something has changed recently) so it feels a little unusual in this flow. I still think that it is helpful to set people up with an AR and keep them from footguns, but maybe that can go in a separate command that the initial init command points to once you're done? Something along the lines of ""if you get to the point where you need to upload custom container images, you can use hailctl to set up a registry""?. Another thing that gives me a little pause is the wording around google projects. I get that you need one to create a bucket, but I think we should just make sure to steer clear of the implication that you are ""selecting a GCP project to use for Hail Batch"", because that implies some link or ownership that isn't there. But I think there's a quick fix here: for a given resource that we *are* creating for hail use, like the temp bucket, ask for the name first and then ask which project it should be created in, using the projects listed in gcloud as choices with the option to write in your own. ### Regarding number of checks; I think it'd be good to avoid warnings when possible. From looking at this I see a pattern of; 1. Ask a leading question; 2. Emit a warning if the user selects the alternative option instead of the suggested option. I think I would prefer instead to ask a leading question and in the prompt explain why the alternative option might be undesirable. Then when they make a decision just move on. On a broader not",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1648633012:1651,pause,pause,1651,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1648633012,2,['pause'],['pause']
Usability,"cause is that newer versions of autodoc include, [as an experimental addition](https://www.sphinx-doc.org/en/2.0/usage/extensions/autodoc.html#generating-documents-from-type-annotations), sphinx-autodoc-typehints. This addition (which we use in batch) only works when a class is documented using its true name (i.e. where it is defined, not re-exported). A quick fix is to [disable this functionality](https://www.sphinx-doc.org/en/2.0/usage/extensions/autodoc.html#confval-autodoc_typehints):; ```; autodoc_typehints = 'none'; ```. - autodoc issue about this https://github.com/agronholm/sphinx-autodoc-typehints/issues/38; - another autodoc issue with a fix for the particular use case https://github.com/agronholm/sphinx-autodoc-typehints/issues/124; - root sphinx issue wrt fully qualified names versus the documented name: https://github.com/sphinx-doc/sphinx/issues/4826. The autodoc-typehints maintainer seems to have gotten stuck when trying to fix this. It appears that someone went and figured out enough of Sphinx to [fix this](https://git-cral.univ-lyon1.fr/MUSE/mpdaf/blob/23d52ba059fe76df5e1655542b17a28a7137cf20/doc/ext/smart_resolver.py). When a doc string is processed, they record a mapping from the documented name to the fully-resolved name. The code that catches missing references and fixes them is kinda big and complicated. I'm uncomfortable dropping it into our project. There's some good documentation about how autodoc_typehints works at [scanpydocs' docs](https://icb-scanpydoc.readthedocs-hosted.com/en/latest/scanpydoc.elegant_typehints.html). This [flying sheep](https://github.com/flying-sheep) seems pretty competent. I think they fixed it for scanpydocs [here](https://github.com/theislab/scanpydoc/pull/19/files) but it's a rather complex looking solution. It's frankly pretty shocking that such a simple operation (have a mapping from all the names of an object to its documented name) results in a two years of back and forth that still hasn't reached a solution.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9403#issuecomment-703776111:1842,simpl,simple,1842,https://hail.is,https://github.com/hail-is/hail/pull/9403#issuecomment-703776111,2,['simpl'],['simple']
Usability,"cc @cseed @jigold @tpoterba. This replaces the python AST with directly-generated IR nodes. I tried to make minimal changes to how the AST/IR interfaced with expressions and tables/matrixtables, since this PR is already super big. The main changes I had to make were to the aggregator interface---`_agg_func` and the current aggregable map/filter/flatmap stuff now mimics the scala `toIR` logic. The other functions that get lifted out specially in `toIR`--mostly lambda functions--also got rewritten directly in python. (I also implemented `agg.map`, `agg.flatmap`, and `functions.fold` to do this, but left them undocumented since I didn't want to put a bunch of documentation in this PR. I'll follow up with documentation separately.). I also added some tests to test_expr that were getting caught in the doctests but didn't have other corresponding python tests. On the Scala side, I rewrote the IR parser to allow `Ref`s to be typeless if the type could be looked up in a corresponding map from the Table or MatrixTable, and to allow ApplyComparisonOps to not pass the type. The other changes are mostly changing the Table/MatrixTable methods to parse IR strings directly. The old AST methods have been left and renamed if the tests still needed them; was planning on moving to TestUtils in a separate PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3940:614,undo,undocumented,614,https://hail.is,https://github.com/hail-is/hail/pull/3940,1,['undo'],['undocumented']
Usability,"cc @iris-garden: You might find this discussion interesting. > Is it kosher to use write_output on the individual items within a ResourceGroup like this?. Yes, that is fine. > The resulting code is IMHO overall less clear than the original version in which the resource group models the relationship between all three filenames. The resource group was intended for sets of files that should be **localized** together. The primary motivation was for PLINK files with `.bed, .bim, and .fam` extensions. This is not quite your use case. > If Hail Batch is a well-rounded orthogonal API, then that code ought to work too. It's a fair criticism that the ResourceGroup API isn't very flexible. We can think about ways to improve it. It's unclear from your code what exactly you want to have happen. Do you want to be able to declare not to localize the tsv only file? In this toy example, a string path is assumed to be `ResourceGroupFile(path, localize=True)`. ```python3; j = b.new_job(…). j.declare_resource_group(counts={; 'tsv': ResourceGroupFile('{root}.counts.tsv', localize=False),; 'tsv.gz': '{root}.counts.tsv.gz',; 'tsv.gz.tbi': '{root}.counts.tsv.gz.tbi',; }). j.command(f""""""; gatk SubCommand … --output {j.tsv_counts}; bgzip {j.tsv_counts}; gatk IndexFeatureFile --input {j.counts['tsv.gz']}; """"""). b.write_output(j.counts, output_dir_path); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13191#issuecomment-1599590271:216,clear,clear,216,https://hail.is,https://github.com/hail-is/hail/issues/13191#issuecomment-1599590271,2,['clear'],['clear']
Usability,"cc @tpoterba . Isn't actually called yet, and no tests. Would like feedback on direction, then will add those pieces. . A few issues, starting from top:. 1) RelationalRef. Parser.scala `type_expr` can output a TUnion, but no PUnion exists. Current plan is to add one and the corresponding canonical type; 2) More to come.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6594:67,feedback,feedback,67,https://hail.is,https://github.com/hail-is/hail/pull/6594,1,['feedback'],['feedback']
Usability,"cc: @cseed . This seems much simpler and saves a per-element allocation, but I'm not entirely sure I understand how `saveAsSequenceFile` differs from `saveAsHadoopFile`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2265:29,simpl,simpler,29,https://hail.is,https://github.com/hail-is/hail/pull/2265,1,['simpl'],['simpler']
Usability,"cc: @cseed @konradjk . This PCRelate should handle larger data sizes than the previous one by avoiding shuffles. It avoids the shuffle by writing the vds to a temporary directory in block matrix form. It then loads this BlockMatrix directly. Form that point forward, the PCRelate algorithm is just non-shuffling linear algebra (however: matrix multiplication will require each node to communicate with approximately `n+m` other nodes). I'm vaguely uncomfortable with two things:. 1. I've added some hail expr lang to mean impute missing values. This is written in python. As such, correctly mean imputing is not tested by our test system any more. The mean imputation is pretty simple, so maybe we should just verify my code is right?. 2. I noticed that at some earlier point PCA was moved outside of Java as well. This also makes me uncomfortable for the same reason. Moving the tests into python is a fair lift because, AFAIK, we don't have as robust test infrastructure over there. I'm torn between the desire to get this out for @konradjk and the desire to follow our normal testing standards. ---. I've played a bit with this locally, but have not tried it on a large cluster. @konradjk, I would be very interested in how this performs on a large dataset, if you would be so kind. Please don't try this until the CI tests and doc builds pass on this PR though. I haven't run the tests locally, so I'm not certain it passes them :P",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2821:678,simpl,simple,678,https://hail.is,https://github.com/hail-is/hail/pull/2821,1,['simpl'],['simple']
Usability,"cc: @cseed, @tpoterba . Old PR: https://github.com/hail-is/hail/pull/4576. Still using the subfolder rather than subdomain, but it spins and has a management console. Currently both the user password and admin password are generated on start up and written to the log. It's running right now in k8s, as long as site doesn't get updated you can access it at https://hail.is/notebook . You can find the passwords in the log files. As you can see I played with some CSS. I'm open to suggestion there, clearly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4588:498,clear,clearly,498,https://hail.is,https://github.com/hail-is/hail/pull/4588,1,['clear'],['clearly']
Usability,"cc: @daniel-goldstein is it possible to make the error more clear? The CI test job is a bit hard to read. Maybe the last line of the output should be something like ""XXXX file is out of date, run YYYY""",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11840#issuecomment-1325464620:60,clear,clear,60,https://hail.is,https://github.com/hail-is/hail/pull/11840#issuecomment-1325464620,2,['clear'],['clear']
Usability,cc: @jigold some changes to memory to simplify it and address some weird behavior. sent over to Daniel since I feel like I've been hitting you with a bunch of PRs lately 😉 !,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11202#issuecomment-1006964286:38,simpl,simplify,38,https://hail.is,https://github.com/hail-is/hail/pull/11202#issuecomment-1006964286,2,['simpl'],['simplify']
Usability,"cc: @tpoterba . Some greek yogurt to cool off that spicy meatball. Large filters, or filters with large globals will clutter up the region unnecessarily. This fix adds clears to the two matrix row filters and the table filter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3587:168,clear,clears,168,https://hail.is,https://github.com/hail-is/hail/pull/3587,1,['clear'],['clears']
Usability,"cc: @tpoterba @patrick-schultz @catoverdrive . We are not allowed to clear a region we do not own. Someone should test this doesn't blow memory on a severe filter in the cloud. ---. Prevent segfaults when joining two tables using `t1.join(t2)`. This syntax does a ""product join"", i.e., a normal join. The `t2[t1.key]` syntax takes only one matching element from `t2` for each element in `t1`. When performing a ""product join"", hail keeps a side-buffer of region values from the right-hand-side table. This side buffer *must not be cleared* by down stream operations (it is owned by the join node). Unfortunately, hail's filter method was incorrectly clearing regions it might not own. This bug only appeared as a segfault when `t1.join(t2)` was followed by a filter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5421:69,clear,clear,69,https://hail.is,https://github.com/hail-is/hail/pull/5421,3,['clear'],"['clear', 'cleared', 'clearing']"
Usability,"ccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.base/java.lang.Thread.run(Thread.java:834). 2022-05-14 12:09:11 SparkContext: INFO: Invoking stop() from shutdown hook; 2022-05-14 12:09:11 AbstractConnector: INFO: Stopped Spark@15a2644a{HTTP/1.1, (http/1.1)}{0.0.0.0:4044}; 2022-05-14 12:09:11 SparkUI: INFO: Stopped Spark web UI at http://10.40.3.21:4044; 2022-05-14 12:09:11 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!; 2022-05-14 12:09:11 MemoryStore: INFO: MemoryStore cleared; 2022-05-14 12:09:11 BlockManager: INFO: BlockManager stopped; 2022-05-14 12:09:11 BlockManagerMaster: INFO: BlockManagerMaster stopped; 2022-05-14 12:09:11 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!; 2022-05-14 12:09:11 SparkContext: INFO: Successfully stopped SparkContext; 2022-05-14 12:09:11 ShutdownHookManager: INFO: Shutdown hook called; 2022-05-14 12:09:11 ShutdownHookManager: INFO: Deleting directory /tmp/spark-51f10d40-8377-4f52-a8ce-27e5f2970d9c; 2022-05-14 12:09:11 ShutdownHookManager: INFO: Deleting directory /tmp/spark-acc398f9-392d-44b1-8f70-05573dad7cda; 2022-05-14 12:09:11 ShutdownHookManager: INFO: Deleting directory /tmp/spark-acc398f9-392d-44b1-8f70-05573dad7cda/pyspark-aab08516-4526-40da-8556-7b50184b10eb`. prs weights and genome data for GRCh38 are in use",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:9234,clear,cleared,9234,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['clear'],['cleared']
Usability,"cda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""8f2f7ae4-0cec-47e6-822f-e81b1067da22"",""prPublicId"":""8f2f7ae4-0cec-47e6-822f-e81b1067da22"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""numpy"",""from"":""1.21.3"",""to"":""1.22.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-NUMPY-2321964"",""SNYK-PYTHON-NUMPY-2321966"",""SNYK-PYTHON-NUMPY-2321970"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,null,null,null,509,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13871:6717,Learn,Learn,6717,https://hail.is,https://github.com/hail-is/hail/pull/13871,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"cda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f06f3836-ea3a-4143-ba99-12b7ad33753d"",""prPublicId"":""f06f3836-ea3a-4143-ba99-12b7ad33753d"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.2""},{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622"",""SNYK-PYTHON-AIOHTTP-6209406"",""SNYK-PYTHON-AIOHTTP-6209407"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,531,null,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Limitation of a Pathname to a Restricted Directory (&#x27;Path Traversal&#x27;)](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14259:7287,Learn,Learn,7287,https://hail.is,https://github.com/hail-is/hail/pull/14259,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ch is annoying. Anyway now when someone asks how to count the mutations in each gene by consequence type we can point them to the `counter` docs. ---. Adding a dataset caused a bunch of docs failure that lead me to change how we do doctesting. The changes are summarized below.; - ignore `python/.eggs`; - make `PARALLELISM` configurable in `Makefile`; - fix `make pytest` (it referenced a non-extant target); - add `make doctest` (this and `pytest` use setup.py to replicate the environment the user would have after installation, I prefer this approach because I need not manually install any dependencies, setup.py handles that, it also configures spark correctly without environment variables); - harmonize `doctest` and `pytest` parameters in `build.gradle` and `Makefile`; - clean up import order in `conftest.py` to match pylint's desired ordering; - use a `temple.TemporaryDirectory` for all doctest and test output, which is automatically cleaned up (if you want to interrogate it you can `ctrl-z` a running doctest); this allows us to not copy the entire python directory into a build directory before running pytest; - *important:* re-generate all input datasets on every run of the tests. Previously, there was a file `doctest_write_data.py` which you were supposed to run when you changed the datasets, but if Hail changes then the random datasets generated by `doctest_write_data.py` might change. This means when I came along to add a new dataset, I had to address all the test failures introduced since the last time `doctest_write_data.py`'s results were checked in. (the doctests still only take about 2 minutes); - I fixed several latent doc bugs caused by the aforementioned situation; - I changed ""Using Variants as Covariates"" in `guides/genetics.rst` because it seemed complicated and was broken by the aforementioned situation; - I removed `NOTEST` which was a custom pytest annotation that duplicates the functionality of `SKIP` (I changed all `NOTEST` annotations to `SKIP`)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6856:2284,guid,guides,2284,https://hail.is,https://github.com/hail-is/hail/pull/6856,1,['guid'],['guides']
Usability,"changed the signature of the `deepCopy` functions that take source and destination parameters, replacing the source parameter with a ""value"" parameter. this way you can pass in primitive values to `deepCopy` and it will call `storePrimitive`. the reasoning for this is that most applications of `deepCopy` want this behavior, previously having to match over the type to determine if its a primitive. now they can just call `deepCopy` with any PType. @patrick-schultz suggested this change in #6858, so if this gets merged i can simplify some of the logic in that PR as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6906:528,simpl,simplify,528,https://hail.is,https://github.com/hail-is/hail/pull/6906,1,['simpl'],['simplify']
Usability,"ches.id DESC; -> LIMIT 51;; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+---------+---------+-------------------------------------------+---------+----------+----------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+---------+---------+-------------------------------------------+---------+----------+----------------------------------+; | 1 | SIMPLE | batches | NULL | range | PRIMARY,batches_deleted,batches_token,batches_user_state,batches_time_completed,batches_billing_project_state | PRIMARY | 8 | NULL | 1348998 | 5.00 | Using where; Backward index scan |; | 1 | SIMPLE | batches_n_jobs_in_complete_states | NULL | eq_ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 1 | 100.00 | NULL |; | 1 | SIMPLE | batches_cancelled | NULL | eq_ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 1 | 100.00 | Using index |; | 1 | SIMPLE | aggregated_batch_resources | NULL | ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 61 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 302 | batch.aggregated_batch_resources.resource | 1 | 100.00 | NULL |; | 1 | SIMPLE | billing_project_users | NULL | eq_ref | PRIMARY | PRIMARY | 604 | batch.batches.billing_project,const | 1 | 100.00 | Using index |; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+---------+---------+-------------------------------------------+---------+----------+----------------------------------+; 6 rows in set, 1 warning (0.01 sec); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12057#issuecomment-1196612910:2049,SIMPL,SIMPLE,2049,https://hail.is,https://github.com/hail-is/hail/pull/12057#issuecomment-1196612910,5,['SIMPL'],['SIMPLE']
Usability,"ches.id; -> LEFT JOIN aggregated_job_resources; -> ON jobs.batch_id = aggregated_job_resources.batch_id AND; -> jobs.job_id = aggregated_job_resources.job_id; -> LEFT JOIN resources; -> ON aggregated_job_resources.resource = resources.resource; -> INNER JOIN job_attributes; -> ON jobs.batch_id = job_attributes.batch_id AND; -> jobs.job_id = job_attributes.job_id AND; -> job_attributes.`key` = 'name'; -> WHERE (jobs.batch_id = 14327) AND; -> (jobs.batch_id, jobs.job_id) IN (SELECT batch_id, job_id FROM job_attributes WHERE `key` = 'pheno' AND `value` = '50'); -> GROUP BY jobs.batch_id, jobs.job_id; -> ORDER BY jobs.batch_id, jobs.job_id ASC; -> LIMIT 50;; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | 1 | SIMPLE | batches | NULL | const | PRIMARY | PRIMARY | 8 | const | 1 | 100.00 | Using temporary; Using filesort |; | 1 | SIMPLE | job_attributes | NULL | ref | PRIMARY,job_attributes_key_value | job_attributes_key_value | 1081 | const,const,const | 3057 | 100.00 | Using where |; | 1 | SIMPLE | jobs | NULL | eq_ref | PRIMARY,jobs_batch_id_state_always_run_cancelled | PRIMARY | 12 | const,batch.job_attributes.job_id | 1 | 100.00 | NULL |; | 1 | SIMPLE | job_attributes | NULL | eq_ref | PRIMARY,job_attributes_key_value | PRIMARY | 314 | const,batch.job_attributes.job_id,const | 1 | 100.00 | NULL |; | 1 | SIMPLE | aggregated_job_resources | NULL | ref | PRIMARY | PRIMARY | 12 | const,batch.job_attributes.jo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9870:1503,SIMPL,SIMPLE,1503,https://hail.is,https://github.com/hail-is/hail/pull/9870,1,['SIMPL'],['SIMPLE']
Usability,"cies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.6""},{""name"":""pyjwt"",""from"":""1.7.1"",""to"":""2.4.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""rsa"",""from"":""4.5"",""to"":""4.7""}],""packageManager"":""pip"",""projectPublicId"":""e7c92c7b-5282-49ea-940f-7a5797e2a45a"",""projectUrl"":""https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-PYJWT-2840625"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-RSA-1038401""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[],""priorityScoreList"":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14134:10798,Learn,Learn,10798,https://hail.is,https://github.com/hail-is/hail/pull/14134,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ck the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4MmVlNzU5Ny0wZmFhLTQ1NmUtOTA3Ny0zOTM4ODRjNzJmNGMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjgyZWU3NTk3LTBmYWEtNDU2ZS05MDc3LTM5Mzg4NGM3MmY0YyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""82ee7597-0faa-456e-9077-393884c72f4c"",""prPublicId"":""82ee7597-0faa-456e-9077-393884c72f4c"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.2"",""to"":""41.0.3""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[471,551,471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13370:4242,Learn,Learn,4242,https://hail.is,https://github.com/hail-is/hail/pull/13370,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ck the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxOGJjNGZiYS05ZTMwLTRmNWItYTE4Yy0wOGNmNDVmZDExMTciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE4YmM0ZmJhLTllMzAtNGY1Yi1hMThjLTA4Y2Y0NWZkMTExNyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""18bc4fba-9e30-4f5b-a18c-08cf45fd1117"",""prPublicId"":""18bc4fba-9e30-4f5b-a18c-08cf45fd1117"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.2"",""to"":""41.0.3""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[471,551,471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13366:4250,Learn,Learn,4250,https://hail.is,https://github.com/hail-is/hail/pull/13366,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,clear in block matrix write,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3555:0,clear,clear,0,https://hail.is,https://github.com/hail-is/hail/pull/3555,2,['clear'],['clear']
Usability,closing this because i ripped some stuff out prematurely and i'm not sure it's actually clearer to have this as a separate PR,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3939#issuecomment-406155895:88,clear,clearer,88,https://hail.is,https://github.com/hail-is/hail/pull/3939#issuecomment-406155895,2,['clear'],['clearer']
Usability,"code>ssm-sap</code>: [<code>botocore</code>] AWS Systems Manager for SAP provides simplified operations and management of SAP applications such as SAP HANA. With this release, SAP customers and partners can automate and simplify their SAP system administration tasks such as backup/restore of SAP HANA.</li>; <li>api-change:<code>stepfunctions</code>: [<code>botocore</code>] Update stepfunctions client to latest version</li>; <li>api-change:<code>transfer</code>: [<code>botocore</code>] Adds a NONE encryption algorithm type to AS2 connectors, providing support for skipping encryption of the AS2 message body when a HTTPS URL is also specified.</li>; </ul>; <h1>1.26.12</h1>; <ul>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Adds a new value (WEB_COMPUTE) to the Platform enum that allows customers to create Amplify Apps with Server-Side Rendering support.</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow simplifies the preparation and cataloging of SaaS data into the AWS Glue Data Catalog where your data can be discovered and accessed by AWS analytics and ML services. AppFlow now also supports data field partitioning and file size optimization to improve query performance and reduce cost.</li>; <li>api-change:<code>appsync</code>: [<code>botocore</code>] This release introduces the APPSYNC_JS runtime, and adds support for JavaScript in AppSync functions and AppSync pipeline resolvers.</li>; <li>api-change:<code>dms</code>: [<code>botocore</code>] Adds support for Internet Protocol Version 6 (IPv6) on DMS Replication Instances</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/boto/boto3/commit/f38ce50a317baf6715870b2706100d43b80b0c73""><code>f38ce50</code></a> Merge branch 'release-1.26.16'</li>; <li><a href=""https://github.com/boto/boto3/commit/33d7d6f020510890b93edf49de3f81c0ba208cb3""><code>33d7d6f</code></a> Bump",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12502:5940,simpl,simplifies,5940,https://hail.is,https://github.com/hail-is/hail/pull/12502,1,['simpl'],['simplifies']
Usability,"code>ssm-sap</code>: [<code>botocore</code>] AWS Systems Manager for SAP provides simplified operations and management of SAP applications such as SAP HANA. With this release, SAP customers and partners can automate and simplify their SAP system administration tasks such as backup/restore of SAP HANA.</li>; <li>api-change:<code>stepfunctions</code>: [<code>botocore</code>] Update stepfunctions client to latest version</li>; <li>api-change:<code>transfer</code>: [<code>botocore</code>] Adds a NONE encryption algorithm type to AS2 connectors, providing support for skipping encryption of the AS2 message body when a HTTPS URL is also specified.</li>; </ul>; <h1>1.26.12</h1>; <ul>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Adds a new value (WEB_COMPUTE) to the Platform enum that allows customers to create Amplify Apps with Server-Side Rendering support.</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow simplifies the preparation and cataloging of SaaS data into the AWS Glue Data Catalog where your data can be discovered and accessed by AWS analytics and ML services. AppFlow now also supports data field partitioning and file size optimization to improve query performance and reduce cost.</li>; <li>api-change:<code>appsync</code>: [<code>botocore</code>] This release introduces the APPSYNC_JS runtime, and adds support for JavaScript in AppSync functions and AppSync pipeline resolvers.</li>; <li>api-change:<code>dms</code>: [<code>botocore</code>] Adds support for Internet Protocol Version 6 (IPv6) on DMS Replication Instances</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] This release adds a new optional parameter &quot;privateIpAddress&quot; for the CreateNatGateway API. PrivateIPAddress will allow customers to select a custom Private IPv4 address instead of having it be auto-assigned.</li>; <li>api-change:<code>elbv2</code>: [<code>botocore</code>] Update elbv2 client to latest version</li>; <li>api-change:<code",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:5469,simpl,simplifies,5469,https://hail.is,https://github.com/hail-is/hail/pull/12498,1,['simpl'],['simplifies']
Usability,"commit/95df758d6753005226556177e68a3e9c630c789b"">95df758</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.24 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2158"">#2158</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4f5682a4f6d6d5372a2d382ae3e47dace490ca0d"">4f5682a</a>)</li>; </ul>; <h2>v2.26.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.25.0...v2.26.0"">2.26.0</a> (2023-08-03)</h2>; <h3>Features</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/java-storage/blob/main/CHANGELOG.md"">com.google.cloud:google-cloud-storage's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.26.1...v2.27.0"">2.27.0</a> (2023-09-12)</h2>; <h3>Features</h3>; <ul>; <li>Add new JournalingBlobWriteSessionConfig usable with gRPC transport (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2194"">#2194</a>) (<a href=""https://github.com/googleapis/java-storage/commit/8880d94c3d1a737dd4492cf66a16ba5e08633a70"">8880d94</a>)</li>; <li>Follow-up CLI Improvements (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2184"">#2184</a>) (<a href=""https://github.com/googleapis/java-storage/commit/d9859768081ea6f872097851d3e318b5bad384d9"">d985976</a>)</li>; <li>Initial CLI for SSB integration and Workload 1 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2166"">#2166</a>) (<a href=""https://github.com/googleapis/java-storage/commit/a349735e7fe108e623a330afec0c8cd608ebeef9"">a349735</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>A resumable session without a Range header should be interpreted as 0 length (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2182"">#2182</a>) (<a href=""https://github.com/googleapis/java-stora",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13624:6482,usab,usable,6482,https://hail.is,https://github.com/hail-is/hail/pull/13624,1,['usab'],['usable']
Usability,"create separate and complete style guides for python, scala, and c++",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3224:35,guid,guides,35,https://hail.is,https://github.com/hail-is/hail/issues/3224,2,['guid'],['guides']
Usability,"crossposting from a message I sent to the variants team. ---. #### executive summary. Excess JVM memory use is almost certainly not the issue. I've taken a close look at the import_gvs.py loop and the related Hail Python code. No obvious accumulation of RAM use. AFAICT, the oomkiller keeps killing the pipelines. We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the drive",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:967,simpl,simple,967,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449,2,['simpl'],['simple']
Usability,"ct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxMDU5YWVmMS00ZGY4LTQ2YjktYWYwNS02MWQzYTI2NjE5NWQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjEwNTlhZWYxLTRkZjgtNDZiOS1hZjA1LTYxZDNhMjY2MTk1ZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""1059aef1-4df8-46b9-af05-61d3a266195d"",""prPublicId"":""1059aef1-4df8-46b9-af05-61d3a266195d"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown""],""priorityScoreList"":[null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13436:3168,Learn,Learn,3168,https://hail.is,https://github.com/hail-is/hail/pull/13436,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkNGViNWEyYS04NmZjLTRhZDQtYmM5MC1mZDViZWU4Mjg3YWUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImQ0ZWI1YTJhLTg2ZmMtNGFkNC1iYzkwLWZkNWJlZTgyODdhZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""d4eb5a2a-86fc-4ad4-bc90-fd5bee8287ae"",""prPublicId"":""d4eb5a2a-86fc-4ad4-bc90-fd5bee8287ae"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.3"",""to"":""41.0.4""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5914629""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[611],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13701:3381,Learn,Learn,3381,https://hail.is,https://github.com/hail-is/hail/pull/13701,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmOTk4OWJlMC0yOWQ3LTQyYTctYTAzMC04NzljMTRmOGE2N2YiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImY5OTg5YmUwLTI5ZDctNDJhNy1hMDMwLTg3OWMxNGY4YTY3ZiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f9989be0-29d7-42a7-a030-879c14f8a67f"",""prPublicId"":""f9989be0-29d7-42a7-a030-879c14f8a67f"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.3"",""to"":""41.0.4""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5914629""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[611],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13700:3373,Learn,Learn,3373,https://hail.is,https://github.com/hail-is/hail/pull/13700,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ctest: +NOTEST; docs/functions/random.rst:33: >>> hl.eval(hl.array([x, x, x])) # doctest: +NOTEST; docs/functions/random.rst:42: >>> hl.eval(hl.array([a, b, c])) # doctest: +NOTEST; docs/functions/random.rst:50: >>> table.show() # doctest: +NOTEST; docs/functions/random.rst:72: >>> hl.eval(hl.rand_unif(0, 1, seed=0)) # doctest: +NOTEST; docs/functions/random.rst:75: >>> hl.eval(hl.rand_unif(0, 1, seed=0)) # doctest: +NOTEST; docs/functions/random.rst:82: >>> table.x.collect() # doctest: +NOTEST; docs/functions/random.rst:90: >>> table.x.collect() # doctest: +NOTEST; docs/functions/random.rst:98: >>> table.x.collect() # doctest: +NOTEST; docs/functions/random.rst:110: >>> hl.eval(hl.array([hl.rand_unif(0, 1), hl.rand_unif(0, 1)])) # doctest: +NOTEST; docs/functions/random.rst:114: >>> hl.eval(hl.array([hl.rand_unif(0, 1), hl.rand_unif(0, 1)])) # doctest: +NOTEST; docs/guides/basics.rst:95: >>> mt.describe() # doctest: +NOTEST; docs/guides/basics.rst:141: >>> ht.describe() # doctest: +NOTEST; docs/guides/basics.rst:164: >>> mt.s.describe() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:68: >>> mt # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:71: >>> mt.locus # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:83: >>> mt.DP.describe() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:107: >>> mt.describe() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:266: >>> mt_new.replicate_num.show() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:299: >>> mt.aggregate_entries(hl.agg.mean(mt.GQ)) # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:307: >>> mt.aggregate_entries((agg.stats(mt.DP), agg.stats(mt.GQ))) # doctest: +NOTEST; docs/hailpedia/table.rst:63: >>> ht.describe() # doctest: +NOTEST; docs/hailpedia/table.rst:102: >>> ht # doctest: +NOTEST; docs/hailpedia/table.rst:105: >>> ht.ID # doctest: +NOTEST; experimental/import_gtf.py:56: >>> ht.describe() # doctest: +NOTEST; expr/aggregators/aggregators.py:365: >>> table1.aggregate(agg.counter(table1.S",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4817#issuecomment-451506878:1328,guid,guides,1328,https://hail.is,https://github.com/hail-is/hail/issues/4817#issuecomment-451506878,2,['guid'],['guides']
Usability,"currently just for the rows of MatrixTable, but I'd appreciate some feedback on what I've got so far. I think I'm probably just going to make all the interface changes on this branch/in this PR so they're all in one place before they go in?. from:; http://dev.hail.is/t/proposed-changes-to-the-python-select-annotate-drop-interface-for-keys/88",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3297:68,feedback,feedback,68,https://hail.is,https://github.com/hail-is/hail/pull/3297,1,['feedback'],['feedback']
Usability,"d dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2NWVkZTk2ZC0xYjZkLTQ1ZjktOTU3OC00NzdjMWNmNDhiZmQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjY1ZWRlOTZkLTFiNmQtNDVmOS05NTc4LTQ3N2MxY2Y0OGJmZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""65ede96d-1b6d-45f9-9578-477c1cf48bfd"",""prPublicId"":""65ede96d-1b6d-45f9-9578-477c1cf48bfd"",""dependencies"":[{""name"":""msal"",""from"":""1.24.0"",""to"":""1.24.1""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-MSAL-5904284""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[661],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Neutralization of Special Elements in Data Query Logic](https://learn.snyk.io/lesson/nosql-injection-attack/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13754:3446,Learn,Learn,3446,https://hail.is,https://github.com/hail-is/hail/pull/13754,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"d dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhYjlhNGM2ZS0xOTg1LTRmYTctYjg0OC0zOTNmOWE3MGJkMWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFiOWE0YzZlLTE5ODUtNGZhNy1iODQ4LTM5M2Y5YTcwYmQxYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ab9a4c6e-1985-4fa7-b848-393f9a70bd1a"",""prPublicId"":""ab9a4c6e-1985-4fa7-b848-393f9a70bd1a"",""dependencies"":[{""name"":""msal"",""from"":""1.24.0"",""to"":""1.24.1""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-MSAL-5904284""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[661],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Neutralization of Special Elements in Data Query Logic](https://learn.snyk.io/lesson/nosql-injection-attack/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13753:3438,Learn,Learn,3438,https://hail.is,https://github.com/hail-is/hail/pull/13753,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"d within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNTZiOGU3Ni1mMTk3LTQ0MmMtOGVlMC04MjFhMDk5YzM3YTAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU1NmI4ZTc2LWYxOTctNDQyYy04ZWUwLTgyMWEwOTljMzdhMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e56b8e76-f197-442c-8ee0-821a099c37a0"",""prPublicId"":""e56b8e76-f197-442c-8ee0-821a099c37a0"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.2""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5537286""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[556],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Open Redirect](https://learn.snyk.io/lessons/open-redirect/python/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13072:3031,Learn,Learn,3031,https://hail.is,https://github.com/hail-is/hail/pull/13072,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"d, @jigold, @danking . Adds a `users.user_data` table reader. Upon login the user's `user_data` entry is read, stored in a `user` cookie, as a hmac/sha256-signed jwt. The secret key is the `'/notebook-secrets/secret-key'`. In order to avoid duplicating user data storage, I use the `user` cookie in place of `session['user']`, and to handle this wrote a decorator to decode the token and store it in Flask.g (for the duration of the request). The claims included:. ```python; {; 'id': [int],; 'auth0_id': [str],; 'name': [str],; 'email': [str],; 'picture': [str],; 'ksa_name': [str],; 'gsa_name': [str],; 'bucket_name': [str],; }; ```. An example cookie; ```python; { ; 'auth0_id': 'google-oauth2|000000000000000',; 'bucket_name': 'user-f2khk67pq8a9pc38wnbjigarg',; 'email': 'akotlar@broadinstitute.org',; 'gsa_name': 'projects/hail-vdc/serviceAccounts/user-f2khk67pq8a9pc38wnbjigarg@hail-vdc.iam.gserviceaccount.com',; 'id': 1,; 'ksa_name': 'user-4c4pr',; 'name': 'Alex Kotlar',; 'picture': 'https://lh4.googleusercontent.com/-QIkmrfGTN1M/AAAAAAAAAAI/AAAAAAAAAAA/ACHi3reUAvw1lwovp2ozAIThEN72j-qzeQ/mo/photo.jpg'; }; ```. Here 'id' means `users.user_data.id`. To parse the cookie in your applications:; ```python; SECRET_KEY = read_string('/notebook-secrets/secret-key'). def jwt_decode(token):; if token is None:; return None. try:; payload = jwt.decode(token, SECRET_KEY, algorithms=['HS256']); except jwt.exceptions.InvalidTokenError as e:; log.exception(e); payload = None. return payload. def jwt_encode(payload):; return jwt.encode(payload, SECRET_KEY, algorithm='HS256'). def get_domain(host):; parts = host.split('.'); p_len = len(parts). return f""{parts[p_len - 2]}.{parts[p_len - 1]}""; ```. And to use this (in Flask...aiohttp will be similar): `user = jwt_decode(request.cookies.get('user'))`. The cookie is scoped to hail.is (or whatever the lowest level domain happens to be if you're locally testing). I think this is a mostly straightforward implementation, but happy to take feedback.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5633:1999,feedback,feedback,1999,https://hail.is,https://github.com/hail-is/hail/pull/5633,1,['feedback'],['feedback']
Usability,dHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.140ms self 0.140ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.026ms self 0.026ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 0.154ms self 0.069ms children 0.085ms %children 55.31%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#appl,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:171593,Simpl,Simplify,171593,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,dHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.187ms self 0.187ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.031ms self 0.031ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 0.346ms self 0.121ms children 0.225ms %children 65.07%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#appl,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:28276,Simpl,Simplify,28276,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,"dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * **#14691** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14691?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14690** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14690?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14686** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14747](https://github.com/hail-is/hail/pull/14747) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @ehigham and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14692#issuecomment-2358958754:3726,Learn,Learn,3726,https://hail.is,https://github.com/hail-is/hail/pull/14692#issuecomment-2358958754,1,['Learn'],['Learn']
Usability,"dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14691** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14691?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * **#14690** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14690?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14686** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14747](https://github.com/hail-is/hail/pull/14747) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @ehigham and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14691#issuecomment-2357221524:3726,Learn,Learn,3726,https://hail.is,https://github.com/hail-is/hail/pull/14691#issuecomment-2357221524,1,['Learn'],['Learn']
Usability,"dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14691** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14691?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14690** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14690?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * **#14686** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14747](https://github.com/hail-is/hail/pull/14747) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @ehigham and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14690#issuecomment-2356990835:3726,Learn,Learn,3726,https://hail.is,https://github.com/hail-is/hail/pull/14690#issuecomment-2356990835,1,['Learn'],['Learn']
Usability,"dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14691** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14691?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14690** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14690?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14686** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14747](https://github.com/hail-is/hail/pull/14747) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @ehigham and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14686#issuecomment-2354274670:3726,Learn,Learn,3726,https://hail.is,https://github.com/hail-is/hail/pull/14686#issuecomment-2354274670,1,['Learn'],['Learn']
Usability,"docs/functions/random.rst:30: >>> hl.eval(hl.rand_unif(0, 1)) # doctest: +NOTEST; docs/functions/random.rst:33: >>> hl.eval(hl.array([x, x, x])) # doctest: +NOTEST; docs/functions/random.rst:42: >>> hl.eval(hl.array([a, b, c])) # doctest: +NOTEST; docs/functions/random.rst:50: >>> table.show() # doctest: +NOTEST; docs/functions/random.rst:72: >>> hl.eval(hl.rand_unif(0, 1, seed=0)) # doctest: +NOTEST; docs/functions/random.rst:75: >>> hl.eval(hl.rand_unif(0, 1, seed=0)) # doctest: +NOTEST; docs/functions/random.rst:82: >>> table.x.collect() # doctest: +NOTEST; docs/functions/random.rst:90: >>> table.x.collect() # doctest: +NOTEST; docs/functions/random.rst:98: >>> table.x.collect() # doctest: +NOTEST; docs/functions/random.rst:110: >>> hl.eval(hl.array([hl.rand_unif(0, 1), hl.rand_unif(0, 1)])) # doctest: +NOTEST; docs/functions/random.rst:114: >>> hl.eval(hl.array([hl.rand_unif(0, 1), hl.rand_unif(0, 1)])) # doctest: +NOTEST; docs/guides/basics.rst:95: >>> mt.describe() # doctest: +NOTEST; docs/guides/basics.rst:141: >>> ht.describe() # doctest: +NOTEST; docs/guides/basics.rst:164: >>> mt.s.describe() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:68: >>> mt # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:71: >>> mt.locus # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:83: >>> mt.DP.describe() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:107: >>> mt.describe() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:266: >>> mt_new.replicate_num.show() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:299: >>> mt.aggregate_entries(hl.agg.mean(mt.GQ)) # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:307: >>> mt.aggregate_entries((agg.stats(mt.DP), agg.stats(mt.GQ))) # doctest: +NOTEST; docs/hailpedia/table.rst:63: >>> ht.describe() # doctest: +NOTEST; docs/hailpedia/table.rst:102: >>> ht # doctest: +NOTEST; docs/hailpedia/table.rst:105: >>> ht.ID # doctest: +NOTEST; experimental/import_gtf.py:56: >>> ht.describe() # doctest: +NOTEST; expr/aggrega",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4817#issuecomment-451506878:1262,guid,guides,1262,https://hail.is,https://github.com/hail-is/hail/issues/4817#issuecomment-451506878,2,['guid'],['guides']
Usability,"doop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-408f188; Error summary: EsHadoopIllegalArgumentException: Spark SQL types are not handled through basic RDD saveToEs() calls; typically this is a mistake(as the SQL schema will be ignored). Use 'org.elasticsearch.spark.sql' package instead; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [ffc9fb0b99f64080b674ab7a07962df9] entered state [ERROR] while waiting for [DONE].; ```. Ideally it would get exported as nested objects: https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html#_using_literal_nested_literal_fields_for_arrays_of_objects. with elasticsearch mapping:; ```; u'vep': {'type': 'nested', 'properties': {u'category': {'type': 'keyword'}, u'major_consequence': {'type': 'keyword'}, u'gene_id': {'type': 'keyword'}, u'major_consequence_rank': {'type': 'integer'}, u'gene_symbol': {'type': 'keyword'}, u'transcript_id': {'type': 'keyword'}, u'hgvs': {'type': 'keyword'}, u'protein_id': {'type': 'keyword'}}}, ; ```. I thought about switching to saveJsonToEs here: ; https://github.com/hail-is/hail/blob/0.1/src/main/scala/is/hail/io/ElasticsearchConnector.scala#L33; but not sure how to auto-convert to json before exporting; https://www.elastic.co/guide/en/elasticsearch/hadoop/6.x/spark.html#spark-streaming-write-json",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:11551,guid,guide,11551,https://hail.is,https://github.com/hail-is/hail/issues/4250,2,['guid'],['guide']
Usability,"e -- ExtractIntervalFilters : 21.579ms, total 51.305ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- Simplify : 38.711ms, total 90.246ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ForwardLets : 58.138ms, total 148.873ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ForwardRelationalLets : 4.892ms, total 154.106ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- PruneDeadFields : 70.932ms, total 225.284ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- FoldConstants : 2.673ms, total 228.575ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ExtractIntervalFilters : 6.413ms, total 235.357ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- Simplify : 4.736ms, total 240.359ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ForwardLets : 38.152ms, total 278.793ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ForwardRelationalLets : 3.185ms, total 282.285ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- PruneDeadFields : 25.086ms, total 307.692ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- FoldConstants : 1.938ms, total 310.139ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ExtractIntervalFilters : 13.601ms, total 324.665ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- Simplify : 4.231ms, total 329.178ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: IN",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7476:1445,Simpl,Simplify,1445,https://hail.is,https://github.com/hail-is/hail/pull/7476,1,['Simpl'],['Simplify']
Usability,"e the only reason that we currently require a zone be provided either in gcloud configuration or on the command line is to maintain backwards compatibility. `cloudtools` and earlier versions of `hailctl` had a default value for the `--zone` option of `hailctl dataproc start` (I think it was `us-central1-b`). > I stripped all gcloud pass through args from hailctl dataproc modify. There aren't any left. Invoking modify now looks like:; > ; > ```; > hailctl dataproc modify my-cluster \; > --extra-glcoud-update-args='---num-workers=2 --num-secondary-workers=100'; > ```; >; > The extra in the option name sounds a little weird since they are the only options (and the command isn't run if they aren't specified), but I'm leaving it for consistency for now. I moved the help text from the removed options into the help for the modify command itself. The output of modify --help is included below. I have mixed feelings on this one. On the one hand, `--extra-gcloud-update-args` sounds like it is extra arguments for a `gcloud update` command, which isn't a thing. On the other hand, `--extra-gcloud-dataproc-clusters-update-args` is an awfully long argument name. > I plan to leave the --async option to stop, although it is pass through. > Then there is --files for submit. This is passed through, but --py-files is needed (it is not passed through, but modified). Do I leave --files? I'm currently inclined to. Agreed. I support having the most frequently used parameters as `hailctl` parameters, even if they are only simple pass throughs. My original comment about minimizing the number of simple pass through parameters was mainly directed toward `hailctl dataproc start`, which has several options than can be specified separately for master node, worker nodes, and secondary worker nodes. I wanted to avoid cases where, for example, `--worker-boot-disk-size` was a `hailctl` option, but `--secondary-worker-boot-disk-size` had to be specified after a `--` or with `--extra-gcloud-start-args`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842#issuecomment-767168393:3155,simpl,simple,3155,https://hail.is,https://github.com/hail-is/hail/pull/9842#issuecomment-767168393,4,['simpl'],['simple']
Usability,"e want, but there isn’t really an equivalent for samples since hl.sample_qc and hl.vds.sample_qc take MTs and return HTs rather than taking expressions and returning aggregation expressions. Would the Hail team have the bandwidth in the next couple weeks to put in a modification to the hl.vds.sample_qc to make it function similar to the hl.agg.call_stats ?. My thoughts on it:. It's a reasonable ask. You'll have four parts (first three are aggregators): rmt_sq, vmt_sq, ac_and_atype, and combine. The user must ensure the same filters, groups, etc. are applied to each aggregator. If you group, you'll need to ensure the right grouped AC is passed around. It might look like this on the variant matrix table. The reference stuff looks similar.; ```python3; vmt = vmt.annotate_entries(GT=hl.vds.lgt_to_gt(vmt.LGT, vmt.LA)); vmt = vmt.annotate_rows(ac_atype=hl.agg.group_by(foo, ac_and_atype(vmt.GT, vmt.alleles))); vmt = vmt.annotate_cols(; qc=hl.agg.group_by(; foo,; vmt_sample_qc(; global_gt=vmt.GT,; gq=vmt.GQ,; ac=ac_atype[foo].ac,; atype=ac_atype[foo].atype,; dp=vmt.DP); ); ); ```; The atype needn't really be grouped. That should maybe be its own aggregator and then you can use stats directly to get a valid AC. I sketched this here: https://github.com/hail-is/hail/compare/main...danking:hail:agg-sample-qc but there are probably bugs in that. This issue is complete when we merge a PR that:; 1. Exposes one or more aggregators which compute all the statistics from `hl.vds.sample_qc` on the component matrix tables of a VDS: the variant data and the reference data.; 2. Exposes a combination function which combines reference and variant stats to produce `bases_over_dp_threshold` and `bases_over_gq_threshold`.; 3. Includes extensive tests comparing these aggregators to the original `hl.vds.sample_qc`.; 4. Includes clear documentation *with several examples* of how to use these new aggregators and the combination function. ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14264:2134,clear,clear,2134,https://hail.is,https://github.com/hail-is/hail/issues/14264,1,['clear'],['clear']
Usability,"e"",""from"":""0.8.4"",""to"":""2.0.3""},{""name"":""nbconvert"",""from"":""5.6.1"",""to"":""6.3.0b0""},{""name"":""notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,624,531,604,589,726,434,589,449,696,589,479,519,509,711,701,586,586,384,494],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:11922,Learn,Learn,11922,https://hail.is,https://github.com/hail-is/hail/pull/13717,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"e(RDD.scala:362); at org.apache.spark.rdd.RDD.mapPartitions(RDD.scala:793); at is.hail.sparkextras.ContextRDD.cmapPartitions(ContextRDD.scala:351); at is.hail.HailContext.readRows(HailContext.scala:629); at is.hail.rvd.AbstractRVDSpec.read(AbstractRVDSpec.scala:151); at is.hail.variant.RVDComponentSpec.read(MatrixTable.scala:98); at is.hail.expr.ir.TableRead.execute(TableIR.scala:78); at is.hail.expr.ir.TableHead.execute(TableIR.scala:325); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:56); at is.hail.table.Table.x$3$lzycompute(Table.scala:216); at is.hail.table.Table.x$3(Table.scala:216); at is.hail.table.Table.value$lzycompute(Table.scala:216); at is.hail.table.Table.value(Table.scala:216); at is.hail.table.Table.rdd$lzycompute(Table.scala:220); at is.hail.table.Table.rdd(Table.scala:220); at is.hail.table.Table.collect(Table.scala:538); at is.hail.table.Table.showString(Table.scala:582); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:564); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:282); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:238); at java.base/java.lang.Thread.run(Thread.java:844). The problem here is that the message gives zero information on why the python hail code failed. Please implement a version checker; run the java binary and query its version, and if it's not compatible, raise a python exception with a clear message about which java version is installed and needs to be installed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4896:4814,clear,clear,4814,https://hail.is,https://github.com/hail-is/hail/issues/4896,1,['clear'],['clear']
Usability,"e.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14691** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14691?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14690** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14690?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14686** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14747](https://github.com/hail-is/hail/pull/14747) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @ehigham and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14693#issuecomment-2362149504:3726,Learn,Learn,3726,https://hail.is,https://github.com/hail-is/hail/pull/14693#issuecomment-2362149504,6,['Learn'],['Learn']
Usability,"eaking <code>method_name</code> in; <code>DeprecatedList</code>.</li>; </ul>; <h1>v4.10.1</h1>; <h1>v2.1.3</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python/importlib_metadata/commit/516f2a78061d27a3baff53ce4b08f95b638f60d3""><code>516f2a7</code></a> Fix reference in docs build.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/c8d7285af792d6851227212d4261ce7ae180a87c""><code>c8d7285</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/391"">#391</a> from python/ghpython-93259/from-name-arg-validation-s...</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/91b71494226a95251134c4fe6ea65a1dd25f495c""><code>91b7149</code></a> Update changelog</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/c96dc1e77f032315bfc78f0c1d13c9a61fb68c3f""><code>c96dc1e</code></a> Merge branch 'main' into ghpython-93259/from-name-arg-validation-simple</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/f52757d0c8a9a555d0591a86b334a17028e2ead9""><code>f52757d</code></a> In Distribution.from_name, re-use discover.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/344a6ffc612eec611592e7686264ced72f64da5a""><code>344a6ff</code></a> Refactor Distribution.from_name to avoid return in loop and unnecessary None ...</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/eb19c647519c754dd93b42a0c421101af73cf7a4""><code>eb19c64</code></a> In Distribution.from_name, require a non-empty string. Fixes <a href=""https://github-redirect.dependabot.com/python/cpython/issues/9"">python/cpython#9</a>...</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/d3fe031dbad4590896829f18ecbd8d9d8a132f53""><code>d3fe031</code></a> Add comment about the compatibility factor.</li>; <li><a href=""https://github.com/python/impor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12000:3060,simpl,simple,3060,https://hail.is,https://github.com/hail-is/hail/pull/12000,1,['simpl'],['simple']
Usability,"eam()</code> to continue yielding bytes if buffered decompressed data; was still available to be read even if the underlying socket is closed. This prevents; a compressed response from being truncated. (<code>[#3009](https://github.com/urllib3/urllib3/issues/3009) &lt;https://github.com/urllib3/urllib3/issues/3009&gt;</code>__)</li>; </ul>; <h1>2.0.1 (2023-04-30)</h1>; <ul>; <li>Fixed a socket leak when fingerprint or hostname verifications fail. (<code>[#2991](https://github.com/urllib3/urllib3/issues/2991) &lt;https://github.com/urllib3/urllib3/issues/2991&gt;</code>__)</li>; <li>Fixed an error when <code>HTTPResponse.read(0)</code> was the first <code>read</code> call or when the internal response body buffer was otherwise empty. (<code>[#2998](https://github.com/urllib3/urllib3/issues/2998) &lt;https://github.com/urllib3/urllib3/issues/2998&gt;</code>__)</li>; </ul>; <h1>2.0.0 (2023-04-26)</h1>; <p>Read the <code>v2.0 migration guide &lt;https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html&gt;</code>__ for help upgrading to the latest version of urllib3.</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/262e3e332209ee93ff70e2b13502c8f20c105ac8""><code>262e3e3</code></a> Release 2.0.6</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/644124ecd0b6e417c527191f866daa05a5a2056d""><code>644124e</code></a> Merge pull request from GHSA-v845-jxx5-vc9f</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/740380c59ca2a7c2dceca19e5dba99f6b7060e62""><code>740380c</code></a> Bump cryptography from 41.0.3 to 41.0.4 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3131"">#3131</a>)</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/d9f85a749488188c286cd50606d159874db94d5f""><code>d9f85a7</code></a> Release 2.0.5</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/d41f4122966f7f4f5f92001ad518",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:11620,guid,guide,11620,https://hail.is,https://github.com/hail-is/hail/pull/13768,2,['guid'],['guide']
Usability,"eating') OR jobs.attempt_id != attempts.attempt_id); -> AND instances.`state` = 'active'; -> ORDER BY attempts.start_time ASC; -> LIMIT 300\G;. *************************** 1. row ***************************; id: 1; select_type: SIMPLE; table: instances; partitions: NULL; type: ALL; possible_keys: PRIMARY; key: NULL; key_len: NULL; ref: NULL; rows: 1150201; filtered: 10.00; Extra: Using where; Using temporary; Using filesort; *************************** 2. row ***************************; id: 1; select_type: SIMPLE; table: attempts; partitions: NULL; type: ref; possible_keys: PRIMARY,attempts_instance_name; key: attempts_instance_name; key_len: 303; ref: batch.instances.name; rows: 91; filtered: 9.00; Extra: Using where; *************************** 3. row ***************************; id: 1; select_type: SIMPLE; table: jobs; partitions: NULL; type: eq_ref; possible_keys: PRIMARY,jobs_batch_id_state_always_run_cancelled,jobs_batch_id_state_always_run_inst_coll_cancelled,jobs_batch_id_update_id,jobs_batch_id_always_run_n_regions_regions_bits_rep_job_id,jobs_batch_id_ic_state_ar_n_regions_bits_rep_job_id,jobs_batch_id_job_group_id,jobs_batch_id_ic_state_ar_n_regions_bits_rep_job_group_id; key: PRIMARY; key_len: 12; ref: batch.attempts.batch_id,batch.attempts.job_id; rows: 1; filtered: 98.10; Extra: Using where; 3 rows in set, 1 warning (0.00 sec); ```. This is not great:; ```; rows: 1150201; filtered: 10.00; Extra: Using where; Using temporary; Using filesort; ```; what we want to see is a low number of rows, a high percent filtered, and something like `Extra: Using where; Using index;`. 3. We can then verify that this finding aligns with our current understanding of the database schema where there is no index on `instances.state`: ; https://github.com/hail-is/hail/blob/1f3a0503926b65f479dce6d5eb105236632f8d07/batch/sql/estimated-current.sql#L113-L138. ### Remaining questions; 1. Why do we need to join against the instances table to find orphaned attempts? Can we not?; 2.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14460:2536,SIMPL,SIMPLE,2536,https://hail.is,https://github.com/hail-is/hail/issues/14460,1,['SIMPL'],['SIMPLE']
Usability,"ebook/react/issues/13525); 2. There should alway be one and only one non-leaf node in the component tree. Leaf siblings are allowed; note that this requires that there is only one root node as well. ```jsx; export default () => <div>OK</div>; export default () => (<div>OK</div><span>Not OK</span>); ```. To get around this, wrap in a ""<Fragment>"", an html element, or array. Basically, react wants a top level / root object. https://reactjs.org/docs/fragments.html, https://pawelgrzybek.com/return-multiple-elements-from-a-component-with-react-16/. ```jsx; import { Fragment } from 'react';. const good = () => [<div>OK</div><span>GOOD!</span>];; const good2 = () => <Fragment><div>OK</div><span>GOOD!</span></Fragment>;; const good3 = () => <span><div>OK</div><span>GOOD!</span></span>;; ```. #### JSX naming conventions; 1. Lowercase components are just built-in html elements. i.e `<span>` is a an HTML `<span>` on output.; 2. Uppercase components are javascript functions. This makes composing components really simple. ```jsx; const CoolComponent = () => <span>Hello World</span>;. export default () => <CoolComponent>;; ```. You can pass state to these user-defined components, much like you would in HTML, using attributes. These attributes can have arbitrary names, except they must start with a lowercase letter, and follow camel-case convention. These attributes are called `props`. ```jsx; const CoolComponent = (props) => <span>Hello {props.name}!</span>;. export default () => <CoolComponent name=""Alex"">; #mounts <span>Hello Alex!</span> in DOM; ```. #### PureComponent / shallow watch; React's reconciler is triggered whenever this.setState is called, resulting in a walk down the descendent nodes, based on either the presence of that state variable as a ""prop"" (i.e `<MyComponent name={this.state.name}/>`), or its use directly within the component (i.e `{this.state.name === 'Alex' ? <div>Do stuff</div> : <div>Do other stuff</div>). To give the reconciler less work to do, when acc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:8472,simpl,simple,8472,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['simpl'],['simple']
Usability,"ef7a4f</code></a> Merge pull request from GHSA-44cc-43rp-5947</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/0a7510114b56a0c5da8f7d251e69a67aafb87ef2""><code>0a75101</code></a> Fix CI: lint</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/dda0033cd49449572d077bbecd33b18d8d05f48a""><code>dda0033</code></a> Merge pull request from GHSA-4m77-cmpx-vjc4</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/0708330843fd087134a239d2ad6005b1d543e246""><code>0708330</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15612"">#15612</a>: Fixes focus indicator on input checkbox for Firefox (<a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15653"">#15653</a>)</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/edb23ebb12977675ef2a003f526e2f2e751930f3""><code>edb23eb</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15640"">#15640</a>: Fix link to yarn docs in extension migration guide (<a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15644"">#15644</a>)</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/40e8e47123453e65f19c0d5eb2b6bc7bc8d5d49a""><code>40e8e47</code></a> [ci skip] Publish 4.0.10</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/b9bc3002b1ab89b9a1c4d2a3007c43275d11e0df""><code>b9bc300</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15386"">#15386</a>: Improve scrolling to heading (<a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15565"">#15565</a>)</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/3ce03317159234accec1987a890dffa10aef6ebd""><code>3ce0331</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15499"">#15499</a>: Adopt ruff format (<a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15564"">#15564</a>)</li>; <li><a href=""https://github.co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14184:14085,guid,guide,14085,https://hail.is,https://github.com/hail-is/hail/pull/14184,1,['guid'],['guide']
Usability,"ement; TL;DR: `npm`; ```sh; npm init # creates a package.json file, which tracks dependencies; npm install next react react-dom # install 3 packages and save them to the dependencies property; ```. #### package.json; The file that tracks dependencies, and their semantic versioning numbers. Shape:; ```json; {; ""name"": ""hail-web-client"",; ""version"": ""0.2.0"",; ""scripts"": {; ""dev"": ""next"",; ""build"": ""next build"",; ""start"": ""NODE_ENV=production SSL=true next start""; },; ""author"": ""Hail Team"",; ""license"": ""MIT"",; ""dependencies"": {; ""next"": ""^7.0.2-canary.50"",; ""react"": ""^16.7.0"",; ""react-dom"": ""^16.7.0""; },; ""devDependencies"": {; }; }; ```; * Scripts are thing that can be run by typing, in shell `npm run`. Ex: `npm run dev`. ### Async, Await, Promises and callback (WIP); Javascript is async-first. This is most obvious in Node.js, which is the most popular library for server-side JS.; * [How event loop works](https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/); <img width=""765"" alt=""screen shot 2019-01-18 at 11 20 51 am"" src=""https://user-images.githubusercontent.com/5543229/51399094-1f999c00-1b13-11e9-8dfb-da8aa20807b0.png"">. * The event loop call stack: https://www.youtube.com/watch?v=8aGhZQkoFbQ. At a high level, a function that defines a callback will return immediately. The callback is pushed on to the event-loop stack, and on each tick, is checked to determine whether it has returned or not. Blocking operations within the callbacks will block the event loop. This is how CPU viruses, like blockchain manage to slow down web pages that are hijacked to include some mining script: hashing something 30 million times, takes a long time, and JS cannot do anything besides waiting for those operations to finish in a synchronous fashion. Luckily, asynchronous functions are the norm in the JS ecosystem, such that both in the browser, and nodejs, IO functions are (mostly?) asynchronous.; * For NodeJS: Transparently to the user, blocking operations (IO) are executed ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:3204,guid,guides,3204,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['guid'],['guides']
Usability,"emory parameters, but once we have some user feedback I'd like to consider re-implementing computeGramianLargeN to use BLAS3 outer product on blocks of (fewer than m) rows of the n x m matrix rather than inner product on all pairs of columns, which I think will boost speed and make it reasonable to kill the smallN routine entirely (the current largeN case benefits from dot product of sparse vectors when using hard calls, but that also goes away when we move to generic 0.2 and rip out the hardcall/dosage complexity). Then it will be natural for maxSize to control the number of rows in a block. - Added accuracy and iterations parameters to allow users to tune Davies, with R settings for Davies (1e-6, 10k) as default. This allows users to re-run groups with tiny p-values if desired to obtain greater accuracy. The R package runs additional p-value routines that may be faster when the p-value is very small, will keep in mind should this become an issue. - In remark above the Skat class, I've added an overview of how math in paper corresponds to implementation. - Simplified and re-organized the Skat class to cut down on the number and complexity of passed parameters and make the meaning of the code more transparent with respect to the overview. Killed the SkatModel class. - Fixed an oversight whereby the largeN route was never called by logistic. - Fixed a bug whereby a weight of null was passed to DoubleNumericConversion.to and then Option rather than the other way around to prevent null match exception. - Modified R test code to use Adjustment=False to avoid the small-sample adjustment made in the logistic case when running using than 2000 samples. I could then reduce the Balding-Nichols example from 2001 and 500 samples and run logistic on the smaller test set as well. - Further cleaned up the tests, and added a test of the size column and maxSize parameter. - More descriptive error message should Cholesky or inversion fail in logistic case. - Updated docs accordingly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2248:1669,Simpl,Simplified,1669,https://hail.is,https://github.com/hail-is/hail/pull/2248,1,['Simpl'],['Simplified']
Usability,"encounter the error mentioned above. This code works:. ```python; import hail as hl. hail_table = 'gs://gcp-public-data--gnomad/release/3.1.1/ht/genomes/gnomad.genomes.v3.1.1.sites.ht'; chain_file = 'gs://hail-common/references/grch38_to_grch37.over.chain.gz'; ht = hl.read_table(hail_table).head(10_000). GRCh37 = hl.get_reference('GRCh37'); GRCh38 = hl.get_reference('GRCh38'); GRCh38.add_liftover(chain_file, GRCh37). hl.eval(hl.liftover(hl.locus('chr1', 1034245, 'GRCh38'), 'GRCh37')); # Locus(contig=1, position=969625, reference_genome=GRCh37); ```. However, when trying to lift over the entire table it fails:; ```; ht = ht.annotate(; locus_GRCh37 = hl.liftover(ht.locus, 'GRCh37'); ); ht.show(); ```. I got the same error when trying to lift over an older gnomAD version (2.1) from GRCh37 to GRCh38, which used to work according to my best knowledge. Also, this way of lifting over a hail table is following the recommended process on the documentation [here](https://hail.is/docs/0.2/guides/genetics.html?highlight=prs#liftover-variants-from-one-coordinate-system-to-another). I'm quite confident there must be something I'm doing wrong, but now I'm stuck, any help would be highly welcome. Thanks!. The code is running on a Google Cloud Dataproc cluster, Python 3.8, hail version: `'0.2.71-f3a54b530979'`. Error stack:; ```python; --------------------------------------------------------------------------- / 1]; FatalError Traceback (most recent call last); /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 700 type_pprinters=self.type_printers,; 701 deferred_pprinters=self.deferred_printers); --> 702 printer.pretty(obj); 703 printer.flush(); 704 return stream.getvalue(). /opt/conda/miniconda3/lib/python3.8/site-packages/IPython/lib/pretty.py in pretty(self, obj); 392 if cls is not object \; 393 and callable(cls.__dict__.get('__repr__')):; --> 394 return _repr_pprint(obj, self, cycle); 395; 396 return _default_pprint(obj, self, c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:1057,guid,guides,1057,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['guid'],['guides']
Usability,end.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ExtractIntervalFilters.apply total 0.004ms self 0.004ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.063ms self 0.063ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.010ms self 0.010ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 0.102ms self 0.032ms children 0.070ms %children 68.44%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply/is.hail.expr.ir.NormalizeNames.apply total 0.063ms self 0.063ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.i,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:216023,Simpl,Simplify,216023,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,end.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ExtractIntervalFilters.apply total 0.004ms self 0.004ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.070ms self 0.070ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.010ms self 0.010ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 0.108ms self 0.034ms children 0.074ms %children 68.32%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply/is.hail.expr.ir.NormalizeNames.apply total 0.067ms self 0.067ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.i,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:200050,Simpl,Simplify,200050,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,end.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ExtractIntervalFilters.apply total 0.005ms self 0.005ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.064ms self 0.064ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.011ms self 0.011ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 0.101ms self 0.033ms children 0.068ms %children 67.31%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply/is.hail.expr.ir.NormalizeNames.apply total 0.061ms self 0.061ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.i,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:208002,Simpl,Simplify,208002,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,end.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ExtractIntervalFilters.apply total 0.005ms self 0.005ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.072ms self 0.072ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.011ms self 0.011ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 0.102ms self 0.035ms children 0.067ms %children 66.15%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply/is.hail.expr.ir.NormalizeNames.apply total 0.060ms self 0.060ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.i,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:195398,Simpl,Simplify,195398,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,"endabot.com/dateutil/dateutil/issues/1025"">#1025</a>)</li>; <li>Changed some relative links in the exercise documentation to refer to the; document locations in the input tree, rather than the generated HTML files in; the HTML output tree (which presumably will not exist in non-HTML output; formats). (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1078"">#1078</a>).</li>; </ul>; <h2>Misc</h2>; <ul>; <li>Moved <code>test_imports.py</code>, <code>test_internals.py</code> and <code>test_utils.py</code> to; pytest. Reported and fixed by <a href=""https://github.com/jpurviance""><code>@​jpurviance</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/978"">#978</a>)</li>; <li>Added project_urls for documentation and source. Patch by <a href=""https://github.com/andriyor""><code>@​andriyor</code></a> (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/975"">#975</a>).</li>; <li>Simplified handling of bytes and bytearray in <code>_parser._timelex</code>. Reported; and fixed by <a href=""https://github.com/frenzymadness""><code>@​frenzymadness</code></a> (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1060"">#1060</a>).</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/dateutil/dateutil/commit/6b035517571e63b6a63a493740c5506ec1e5da44""><code>6b03551</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1143"">#1143</a> from mariocj89/pu/2.8.2</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/cf44dd0c66827070cf9dd7b30f126b3ab2e110b5""><code>cf44dd0</code></a> Manual cleanup for 2.8.2 NEWS</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/561167183d4cad190059975e5c0826e3587d3c97""><code>5611671</code></a> Automatic generation of NEWS entries for 2.8.2</li>; <li><a href=""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:8560,Simpl,Simplified,8560,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['Simpl'],['Simplified']
Usability,"endabot.com/dateutil/dateutil/issues/1025"">#1025</a>)</li>; <li>Changed some relative links in the exercise documentation to refer to the; document locations in the input tree, rather than the generated HTML files in; the HTML output tree (which presumably will not exist in non-HTML output; formats). (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1078"">#1078</a>).</li>; </ul>; <h2>Misc</h2>; <ul>; <li>Moved <code>test_imports.py</code>, <code>test_internals.py</code> and <code>test_utils.py</code> to; pytest. Reported and fixed by <a href=""https://github.com/jpurviance""><code>@​jpurviance</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/978"">#978</a>)</li>; <li>Added project_urls for documentation and source. Patch by <a href=""https://github.com/andriyor""><code>@​andriyor</code></a> (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/975"">#975</a>).</li>; <li>Simplified handling of bytes and bytearray in <code>_parser._timelex</code>. Reported</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/dateutil/dateutil/blob/master/NEWS"">python-dateutil's changelog</a>.</em></p>; <blockquote>; <h1>Version 2.8.2 (2021-07-08)</h1>; <h2>Data updates</h2>; <ul>; <li>Updated tzdata version to 2021a. (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1128"">#1128</a>)</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Fixed a bug in the parser where non-<code>ValueError</code> exceptions would be raised; during exception handling; this would happen, for example, if an; <code>IllegalMonthError</code> was raised in <code>dateutil</code> code. Fixed by Mark Bailey.; (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/981"">#981</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:4239,Simpl,Simplified,4239,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['Simpl'],['Simplified']
Usability,"ent.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhZGQ5ZWQxOC00MjJhLTRkZWUtYWI4Yy01MTkyYmQ4ZmYxMzIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFkZDllZDE4LTQyMmEtNGRlZS1hYjhjLTUxOTJiZDhmZjEzMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""add9ed18-422a-4dee-ab8c-5192bd8ff132"",""prPublicId"":""add9ed18-422a-4dee-ab8c-5192bd8ff132"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""protobuf"",""from"":""3.17.3"",""to"":""3.18.3""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""rsa"",""from"":""4.5"",""to"":""4.7""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-PROTOBUF-3031740"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-RSA-1038401"",""SNYK-PYTHON-SETUPTOOLS-3180412""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,null,null,509],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13975:5033,Learn,Learn,5033,https://hail.is,https://github.com/hail-is/hail/pull/13975,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ents, except they expose `getInitialProps`, described above. Each page file must export 1 default component:. ```js; #Page file; import React from 'react';. const index = () => <div>Hello World</div>; export default index;; ```. There is nothing else to do to get routing to work, a quite nice solution. ### JS pragma; 1. `this` is different than in most (every?) other language. scope of this is bound to caller, not object containing the method; * Solution: use arrow functions. ```js; class Something {; constructor() {; this.bar = 'foo';; } ; //Do; onSubmit = () => {; console.log(this.bar) //prints foo; }. // Don't; onSubmitBad() {; console.log(this.bar) //may be undefined; }; }. const barrer = new Something();; console.info(""good"", barrer.onSubmit());; console.info(""bad"", barrer.onSubmitBad());; ```. # Tips . ### Client-side routing; Wrap a normal anchor tag in `<Link ></Link>`; ex:; ```jsx; <Link href='/path/to/page'><a>Page Name</a></Link>; ```. This simply adds the client-side routing logic, and passes the href to <a href=. . ### Prefetching; One of the neat things about Next is how easy it makes prefetching pages. This allows perceived page loading times on the order of 5ms, even when the page requires very complex state (say a GraphQL or series of REST calls with large responses). ```jsx; <Link href='/expensive-page' prefetch><a>Expensive Page</a></Link>; ```; ### Make your app do ONLY server-side routing; Meaning every time you click on a link in your page, you hit the server, just like the first visited page. . Simply use `<a>` directly. ### Caching and sidecar requests; Broadly, there are three strategies: browser caching, server caching, and service-worker caching. In this project we will likely use all three. Server caching is an excellent strategy for pages that serve only public data. In this strategy we pre-generate the static html, serve that, and invalidate the cache once in a while. An example of this can be found in https://github.com/hail-is/hail/pul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:13554,simpl,simply,13554,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['simpl'],['simply']
Usability,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1M2U3Mjk0MS01YmVjLTQ2MjYtYTY2Ny0wNzIxYjUwNjZlZjYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjUzZTcyOTQxLTViZWMtNDYyNi1hNjY3LTA3MjFiNTA2NmVmNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""53e72941-5bec-4626-a667-0721b5066ef6"",""prPublicId"":""53e72941-5bec-4626-a667-0721b5066ef6"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14043:3987,Learn,Learn,3987,https://hail.is,https://github.com/hail-is/hail/pull/14043,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3M2M5M2ZlNi0yOWM3LTQ4MWMtYTBiYy1lMzFkYzc3N2QyODEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjczYzkzZmU2LTI5YzctNDgxYy1hMGJjLWUzMWRjNzc3ZDI4MSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""73c93fe6-29c7-481c-a0bc-e31dc777d281"",""prPublicId"":""73c93fe6-29c7-481c-a0bc-e31dc777d281"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14041:3872,Learn,Learn,3872,https://hail.is,https://github.com/hail-is/hail/pull/14041,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4ZmFmZmYwNi1jOTI2LTQ5NjEtOTI4MC1iNGI0OTczNTg2MWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjhmYWZmZjA2LWM5MjYtNDk2MS05MjgwLWI0YjQ5NzM1ODYxYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""8fafff06-c926-4961-9280-b4b49735861c"",""prPublicId"":""8fafff06-c926-4961-9280-b4b49735861c"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14038:3880,Learn,Learn,3880,https://hail.is,https://github.com/hail-is/hail/pull/14038,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5NGM3N2YwYy0xN2JkLTRkMzQtYmJhOS1iNzBiNmVhMDllMjYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijk0Yzc3ZjBjLTE3YmQtNGQzNC1iYmE5LWI3MGI2ZWEwOWUyNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""94c77f0c-17bd-4d34-bba9-b70b6ea09e26"",""prPublicId"":""94c77f0c-17bd-4d34-bba9-b70b6ea09e26"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""0ba777e1-bc27-41cc-aefa-0ed1a253829e"",""projectUrl"":""https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14039:3807,Learn,Learn,3807,https://hail.is,https://github.com/hail-is/hail/pull/14039,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxZjc1YjVmNi00MjFkLTQyN2YtYTk3OC0yNTBhNTgyNTI4YmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjFmNzViNWY2LTQyMWQtNDI3Zi1hOTc4LTI1MGE1ODI1MjhiZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""1f75b5f6-421d-427f-a978-250a582528be"",""prPublicId"":""1f75b5f6-421d-427f-a978-250a582528be"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""cbac91bd-aa95-4900-9a06-97404b268d6e"",""projectUrl"":""https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14035:3801,Learn,Learn,3801,https://hail.is,https://github.com/hail-is/hail/pull/14035,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzMjkzZGUwOS01NmJjLTRkNWEtYWNkZC1iMzdlMDBkMzkwOTgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjMyOTNkZTA5LTU2YmMtNGQ1YS1hY2RkLWIzN2UwMGQzOTA5OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3293de09-56bc-4d5a-acdd-b37e00d39098"",""prPublicId"":""3293de09-56bc-4d5a-acdd-b37e00d39098"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14034:3755,Learn,Learn,3755,https://hail.is,https://github.com/hail-is/hail/pull/14034,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzODVlZjFmNi0zYjJhLTRjZTEtOTA5MS0xMWM1YzU3NDY0OTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjM4NWVmMWY2LTNiMmEtNGNlMS05MDkxLTExYzVjNTc0NjQ5MiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""385ef1f6-3b2a-4ce1-9091-11c5c5746492"",""prPublicId"":""385ef1f6-3b2a-4ce1-9091-11c5c5746492"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""92d13c88-936f-40d3-b692-29e637c1a00c"",""projectUrl"":""https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14044:3732,Learn,Learn,3732,https://hail.is,https://github.com/hail-is/hail/pull/14044,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhNGNiNTQzMi0zM2VmLTQ3ZmQtYmYzMy1lZGU2YzJlNDJiOTAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImE0Y2I1NDMyLTMzZWYtNDdmZC1iZjMzLWVkZTZjMmU0MmI5MCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""a4cb5432-33ef-47fd-bf33-ede6c2e42b90"",""prPublicId"":""a4cb5432-33ef-47fd-bf33-ede6c2e42b90"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14042:4008,Learn,Learn,4008,https://hail.is,https://github.com/hail-is/hail/pull/14042,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNDEzMjhlZS0zNDg5LTQ3NDItYTc3YS01ZDZhNTQ1ZWE2ZjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU0MTMyOGVlLTM0ODktNDc0Mi1hNzdhLTVkNmE1NDVlYTZmMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e41328ee-3489-4742-a77a-5d6a545ea6f2"",""prPublicId"":""e41328ee-3489-4742-a77a-5d6a545ea6f2"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""fdd23464-9a67-49b8-8d9c-08502282c5fb"",""projectUrl"":""https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14037:3741,Learn,Learn,3741,https://hail.is,https://github.com/hail-is/hail/pull/14037,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"equire_sphinx</code> now allows the version; requirement to be specified as <code>(major, minor)</code>.</li>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/11011"">#11011</a>: Allow configuring a line-length limit for object signatures, via; :confval:<code>maximum_signature_line_length</code> and the domain-specific variants.; If the length of the signature (in characters) is greater than the configured; limit, each parameter in the signature will be split to its own logical line.; This behaviour may also be controlled by options on object description; directives, for example :rst:dir:<code>py:function:single-line-parameter-list</code>.; Patch by Thomas Louf, Adam Turner, and Jean-François B.</li>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/10983"">#10983</a>: Support for multiline copyright statements in the footer block.; Patch by Stefanie Molin</li>; <li><code>sphinx.util.display.status_iterator</code> now clears the current line; with ANSI control codes, rather than overprinting with space characters.</li>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/11431"">#11431</a>: linkcheck: Treat SSL failures as broken links.; Patch by Bénédikt Tran</li>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/11157"">#11157</a>: Keep the <code>translated</code> attribute on translated nodes.</li>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/11451"">#11451</a>: Improve the traceback displayed when using :option:<code>sphinx-build -T</code>; in parallel builds. Patch by Bénédikt Tran</li>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/11324"">#11324</a>: linkcheck: Use session-basd HTTP requests.</li>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/11438"">#11438</a>: Add support for the :rst:dir:<code>py:class</code> and :rst:dir:<code>py:function</code>; directives for PEP 695 (generic classes and functions declarations) and; PEP 696 (default ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13295:3116,clear,clears,3116,https://hail.is,https://github.com/hail-is/hail/pull/13295,1,['clear'],['clears']
Usability,"er of rows and the billing is within $0.001 per job with the old way and new way of computing the billing. The tolerance of $0.001 was empirically determined. At a threshold of $0.0001, 33/30,000,000 attempts failed. I think this is good enough as there's always going to be rounding errors. I did not do an explicit audit in the code to make sure the other aggregated_*_resources tables did not change. I spot checked this was correct in my test database. To do the complete audit during the actual migration would take more time. I made sure all the inserts were idempotent. Please double check this. The inserts use a temporary table with an isolation level of read committed. The reason for this is because `INSERT INTO ... SELECT` locks the next gap lock if the isolation level is not read committed. Maybe what I did is overkill and it's no longer a problem with the new burn in period. https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html I'd be interested to hear @danking feedback on what the best query here is to allow parallelism. There are ~30 million attempts that need to be processed for hail-vdc (~60% of the attempts). This will add ~20Gi to the existing database. I use 4 cores to get this migration to be ~3 hours, so we will want to **upgrade the database to 8 cores** while this migration is running. The inserting takes about 2 hours and the audit is 45 minutes or so. For the Australians, I think this script should be a no-op because I believe they started their instance after the billing changes went in around May/June 2020. The main thing to look out for is whether I got the interval queries correct! For example:. ```python3; where_cond = 'WHERE (attempts.batch_id > %s OR ' \; '(attempts.batch_id = %s AND attempts.job_id > %s) OR ' \; '(attempts.batch_id = %s AND attempts.job_id = %s AND attempts.attempt_id >= %s)) ' \; 'AND (attempts.batch_id < %s OR ' \; '(attempts.batch_id = %s AND attempts.job_id < %s) OR ' \; '(attempts.batch_id = %s AND attempts.job",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990:2742,feedback,feedback,2742,https://hail.is,https://github.com/hail-is/hail/pull/11990,1,['feedback'],['feedback']
Usability,"er.max=1g,spark:spark.driver.extraJavaOptions=-Xss4M,spark:spark.executor.extraJavaOptions=-Xss4M,hdfs:dfs.replication=1,dataproc:dataproc.logging.stackdriver.enable=false,dataproc:dataproc.monitoring.stackdriver.enable=false,spark:spark.driver.memory=41g', '--initialization-actions=gs://hail-common/hailctl/dataproc/0.2.18/init_notebook.py,gs://gnomad-public/tools/inits/master-init.sh', '--metadata=^|||^WHEEL=gs://hail-common/hailctl/dataproc/0.2.18/hail-0.2.18-py3-none-any.whl|||PKGS=aiohttp|bokeh>1.1,<1.3|decorator<5|gcsfs==0.2.1|hurry.filesize==0.9|ipykernel<5|nest_asyncio|numpy<2|pandas>0.22,<0.24|parsimonious<0.9|PyJWT|python-json-logger==0.1.11|requests>=2.21.0,<2.21.1|scipy>1.2,<1.4|tabulate==0.8.3|slackclient==2.0.0|websocket-client|sklearn|tabulate|statsmodels|scikit-learn|hdbscan|matplotlib', '--master-machine-type=n1-highmem-8', '--master-boot-disk-size=100GB', '--num-master-local-ssds=0', '--num-preemptible-workers=0', '--num-worker-local-ssds=0', '--num-workers=2', '--preemptible-worker-boot-disk-size=40GB', '--worker-boot-disk-size=40', '--worker-machine-type=n1-standard-8', '--zone=us-central1-b', '--initialization-action-timeout=20m', '--labels=creator=weisburd_broadinstitute_org', '--max-idle=12h']' returned non-zero exit status 1.; ```. Then looking at the error log; ```; $ gsutil cat gs://dataproc-d919bddb-bde3-4138-bbe1-e068dfa1e550-us/google-cloud-dataproc-metainfo/3ec45dcc-d901-4777-930c-23046e64a97d/bw2-m/dataproc-initialization-script-0_output; pip packages are ['setuptools', 'mkl<2020', 'ipywidgets<8', 'jupyter_console<5', 'nbconvert<6', 'notebook<6', 'qtconsole<5', 'jupyter', 'tornado<6', 'lxml<5', 'google-cloud==0.32.0', 'ipython<7', 'jgscm<0.2', 'jupyter-spark', 'aiohttp', 'bokeh>1.1,<1.3', 'decorator<5', 'gcsfs==0.2.1', 'hurry.filesize==0.9', 'ipykernel<5', 'nest_asyncio', 'numpy<2', 'pandas>0.22,<0.24', 'parsimonious<0.9', 'PyJWT', 'python-json-logger==0.1.11', 'requests>=2.21.0,<2.21.1', 'scipy>1.2,<1.4', 'tabulate==0.8.3', 'slackclien",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6634:4332,learn,learn,4332,https://hail.is,https://github.com/hail-is/hail/issues/6634,1,['learn'],['learn']
Usability,"erToDiskThenUpload BlobWriteSessionConfig (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2139"">#2139</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4dad2d5c3a81eda7190ad4f95316471e7fa30f66"">4dad2d5</a>)</li>; <li>Introduce new BlobWriteSession (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2123"">#2123</a>) (<a href=""https://github.com/googleapis/java-storage/commit/e0191b518e50a49fae0691894b50f0c5f33fc6af"">e0191b5</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/java-storage/commit/cc6503155201c0aae6d79517a91712c834689ce5""><code>cc65031</code></a> chore(main): release 2.27.0 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2167"">#2167</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/8880d94c3d1a737dd4492cf66a16ba5e08633a70""><code>8880d94</code></a> feat: add new JournalingBlobWriteSessionConfig usable with gRPC transport (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2"">#2</a>...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/1fa49db2810f6ffbd46755b4eb1f5efdcf980edb""><code>1fa49db</code></a> deps: update dependency com.google.apis:google-api-services-storage to v1-rev...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/5e76f1963db18c9d081133755b5572e186cd1b34""><code>5e76f19</code></a> chore: Update the Java code generator (gapic-generator-java) to 2.25.0 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2198"">#2198</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/26552f4b78f77d90df4e3dfb829c3f9c092fc817""><code>26552f4</code></a> deps: update dependency com.google.cloud:google-cloud-shared-dependencies to ...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/bffb397730d39f4c1c9f8fa80e316a26c39534ce""><code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13624:13003,usab,usable,13003,https://hail.is,https://github.com/hail-is/hail/pull/13624,1,['usab'],['usable']
Usability,"er_cols((mt.s == 'V33335') | (mt.s == 'NWD157935')); mt = mt.annotate_rows(__n = hl.agg.count_where(hl.is_defined(mt.GT))); mt = mt.filter_rows(mt.__n > 0). print(; mt.count()). def show_mt(mt):; entry_fields = ['GT']; if 'END' in mt.entry:; entry_fields.append('END'); (mt.select_rows(); .select_entries(*entry_fields); ._localize_entries('__entries', '__cols'); .show()). show_mt(mt). mt = hl.experimental.densify(mt); show_mt(mt). mt.describe(); ```. which produces sparse and dense samples:. ```; +----------------+-------------------------------------+; | locus | __entries |; +----------------+-------------------------------------+; | locus<GRCh38> | array<struct{GT: call, END: int32}> |; +----------------+-------------------------------------+; | chr22:10510746 | [NA,(0/0,10510769)] |; | chr22:10510770 | [NA,(1/1,NA)] |; | chr22:10510771 | [NA,(0/0,10510891)] |; | chr22:10511207 | [NA,(0/0,10511390)] |; | chr22:10511272 | [(0/0,10511390),NA] |; | chr22:10511391 | [NA,(1/1,NA)] |; | chr22:10511392 | [(0/0,10511393),(0/0,10511477)] |; | chr22:10511397 | [(0/0,10511403),NA] |; | chr22:10511406 | [(0/0,10511418),NA] |; | chr22:10511420 | [(0/0,10511420),NA] |; +----------------+-------------------------------------+; showing top 10 rows. +----------------+-------------------------+; | locus | __entries |; +----------------+-------------------------+; | locus<GRCh38> | array<struct{GT: call}> |; +----------------+-------------------------+; | chr22:10510746 | [NA,(0/0)] |; | chr22:10510770 | [NA,(1/1)] |; | chr22:10510771 | [NA,(0/0)] |; | chr22:10511207 | [NA,(0/0)] |; | chr22:10511272 | [(0/0),(0/0)] |; | chr22:10511391 | [NA,(1/1)] |; | chr22:10511392 | [(0/0),(0/0)] |; | chr22:10511397 | [(0/0),(0/0)] |; | chr22:10511406 | [(0/0),(0/0)] |; | chr22:10511420 | [(0/0),(0/0)] |; +----------------+-------------------------+; ```. Thanks to @tpoterba for the totally sick `array_agg`. It's crazy how simple this was. (Unfortunately, it won't be so simple to make it go fast.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5281:2354,simpl,simple,2354,https://hail.is,https://github.com/hail-is/hail/pull/5281,2,['simpl'],['simple']
Usability,"ery helpful. A formatted document is represented by the `Doc` type. This defines a `render` method, which takes three parameters to control the output:; * `width`: the maximum length of a line, including indentation; * `ribbonLength`: the maximum length of a line, not including indentation (too many characters on a line is hard to read, regardless of indentation); * `maxLines`: the maximum number of lines to print. There are only a few `Doc` constructors, which suffice to define all methods in the richer api contained in the `prettyPrint` package object.; * `Text(t: String)`; * `Line(ifFlat: String)`; * `Indent(i: Int, body: Doc)`; * `Concat(it: Iterable[Doc])`; * `Group(body: Doc)`. Ignoring `Group` for the moment, the first four constructors define formatted documents with only one possible layout, regardless of `width` or `ribbonLength`. `Text` simply prints the string `t`; `Line` prints a newline, followed by the current level of indentation (`ifFlat` is explained when we discuss `Group`); `Indent` increases the indentation of all `Line`s contained in `body` by `i`; and `Concat` simply prints all documents in `it` sequentially. `Group` is the sole source of alternatives which `render` must choose between. `Group(body)` can be rendered in one of two ways:; * replace all `Line`s contained in `body` (including in nested `Group`s) by their `ifFlat` alternative (almost always either "" "" or """"), or, if that would cause the line to exceed `width`; * print `body` normally, as described in the previous paragraph, allowing nested `Group`s to print either flat or normally. This pretty-printer DSL has become fairly standard, with some common enhancements that I don't think we need. It was first described in [A prettier printer](https://homepages.inf.ed.ac.uk/wadler/papers/prettier/prettier.pdf) by Wadler (though my implementation is completely different). This achieves stack safety by `Concat` taking an `Iterable`, so each contained `Doc` can be produced on demand. `render` ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9652:2133,simpl,simply,2133,https://hail.is,https://github.com/hail-is/hail/pull/9652,2,['simpl'],['simply']
Usability,"es into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugging seemed very unpleasant and slow. [It was also a masterful achievement in ; job-security-through-obscurity, because no-one in management was going to mess with the; two people who wrote it - until the whole project got canned]. ... and in the time I was there, the Endeca/Oracle stuff wasn't distributed, which could be another; place where the generate-LLVM-IR needs some kind of extra glue for distributing compiled code,; whereas the conventional DLL's are trivial to ship around. Not claiming that part of it is difficult,; just that it didn't happen at Oracle until long after I left. In contrast, at PhysicsSpeed it was fairly smooth to implement nice abstractions (dense-join-table,; hash-join-table, tuple-with-order) as template classes which could be tested and debugged; in a standalone environment, and then have simpler codegen using those abstractions. At least,; that's a good way to get a lot of functionality with modest effort - and it doesn't preclude migrating; towards a more complex codegen later. It's nice to be able to have templates as low-runtime-cost; abstractions, but you don't have to use them if you don't want to. In short, most of the usual arguments about the benefits of HLL's apply. Plus the larger pool of; potential hires w/ C++ experience compared to the pool of people w/ lower-level/LLVM/IR/compiler-; internals expertise, and the possibility of very occasionally picking up useful fragments of open-source code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:3137,simpl,simpler,3137,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385,2,['simpl'],['simpler']
Usability,"es of join. Some of the join methods take `OrderingView` arguments. An `OrderingView` is a small abstraction on top of an `Ordering` which can take one element `a`, copy data (such as key-fields) from `a` if necessary, then later (after `a` might have been destroyed or mutated) compare `a` to other elements using the copied data. The potentially producting (non-distinct assuming) join methods also take a buffer argument, which is anything that can make a copy of an iterator and then iterate over the copy multiple times. To avoid allocating tuples in the output iterators of the join methods, I made `Muple`, which is just a mutable tuple. I turned the existing `JoinedRegionValue` into an alias of `Muple[RegionValue, RegionValue]`. All of this core `FlipbookIterator` and `StagingIterator` behavior has no dependencies on anything else in Hail, so I want to thoroughly test everything at this level, and treat it like a small external iterator library living inside the repo. As such, I think this level should be quite stable going forwards. At the higher level, I lifted all the join methods on `FlipbookIterator` to `OrderedRVIterator`, which is a `Iterator[RegionValue]` together with an `OrderedRVDType`. I think `OrderedRVIterator` should be replaced by something better soon: see future work below. I've replaced the old implementations of `innerJoinDistinct`, `leftJoinDistinct`, and `orderedZipJoin` using the new infrastructure (see OrderedRDD2.scala), which I think is a good example of the kind of simplifications possible. The existing JoinSuite tests also serve as a secondary test of the new code. In future PRs, I intend to:. * Implement all the join varieties on `OrderedRVD` using the `FlipbookIterator` joins defined here.; * Update other uses of `Iterator` to use the `FlipbookIterator` infrastructure, if doing so improves the code (and I expect it will, or I've done something wrong); * Beef up the `FlipbookIterator` test suite. I could do that for this PR if requested.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3016:5104,simpl,simplifications,5104,https://hail.is,https://github.com/hail-is/hail/pull/3016,1,['simpl'],['simplifications']
Usability,"es the source) and the somewhat bizarre terminology and syntax; used to express that in C++. I agree that move semantics takes getting used to, but I think it is much too integrated into modern C++ to ignore, going far beyond unique_ptr. Writing interfaces that take advantage of move semantics requires understanding rvalue-references in more detail, but for users of those move-enabled interfaces I think the guidelines are easy to teach: a variable will only be modified by moving if it is explicitly tagged with a `std::move`, so all you have to remember is ""after a `std::move(foo)`, the variable `foo` may only be assigned to or deleted."". > And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). Keeping in mind the model that letting a function/class `foo` hold a `unique_ptr<Widget>` means explicitly ""`foo` owns this Widget, and is responsible for deleting it or passing ownership somewhere else"", these questions have pretty clear answers. * If a function `bar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Widget>*` or `unique_ptr<Widget>&` is an in-out parameter, where the function needs to be able to point the pointer somewhere else.; * A const pointer or reference to a unique_ptr should never be used. Just pass a raw pointer or reference. Essentially the same rubric should be used ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:1391,clear,clear,1391,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638,2,['clear'],['clear']
Usability,es$.is$hail$expr$ir$FreeVariables$$compute$1(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$.apply(FreeVariables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:7619,Simpl,Simplify,7619,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlYjc2ODRiYy00Njg4LTQ4ODktOTQyOS0xY2M4M2JhNzJmMDAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImViNzY4NGJjLTQ2ODgtNDg4OS05NDI5LTFjYzgzYmE3MmYwMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""eb7684bc-4688-4889-9429-1cc83ba72f00"",""prPublicId"":""eb7684bc-4688-4889-9429-1cc83ba72f00"",""dependencies"":[{""name"":""orjson"",""from"":""3.9.7"",""to"":""3.9.15""}],""packageManager"":""pip"",""projectPublicId"":""0ba777e1-bc27-41cc-aefa-0ed1a253829e"",""projectUrl"":""https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-ORJSON-6276643""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title""],""priorityScoreList"":[null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Relative Path Traversal](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14355:2899,Learn,Learn,2899,https://hail.is,https://github.com/hail-is/hail/pull/14355,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,expr$ir$FreeVariables$$compute$1(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$.apply(FreeVariables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.exp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:7635,Simpl,Simplify,7635,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"expr.ir.CompileAndEvaluate._apply/Optimize: relationalLowerer, after LowerMatrixToTable/Transform/ExtractIntervalFilters, iteration: 0 total 0.016ms self 0.016ms children 0.000ms %children 0.00%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/Optimize: relationalLowerer, after LowerMatrixToTable/Transform/NormalizeNames, iteration: 0 total 0.363ms self 0.004ms children 0.358ms %children 98.82%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/Optimize: relationalLowerer, after LowerMatrixToTable/Transform/NormalizeNames, iteration: 0/is.hail.expr.ir.NormalizeNames.apply total 0.358ms self 0.358ms children 0.000ms %children 0.00%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/Optimize: relationalLowerer, after LowerMatrixToTable/Transform/Simplify, iteration: 0 total 0.077ms self 0.077ms children 0.000ms %children 0.00%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/Optimize: relationalLowerer, after LowerMatrixToTable/Transform/ForwardLets, iteration: 0 total 0.659ms self 0.292ms children 0.367ms %children 55.66%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/Optimize: relationalLowerer, after LowerMatrixToTable/Transform/ForwardLets, iteration: 0/is.hail.expr.ir.NormalizeNames.apply total 0.367ms self 0.367ms children 0.000ms %children 0.00%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/Optimize: relationalLowerer, after LowerMatrixToTable/Transform/is.hail.expr.ir.TypeCheck.apply total 0.127ms self 0.127ms children 0.000ms %c",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14679#issuecomment-2341990966:12317,Simpl,Simplify,12317,https://hail.is,https://github.com/hail-is/hail/pull/14679#issuecomment-2341990966,2,['Simpl'],['Simplify']
Usability,ext.java:343); 	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267); 	; 	The currently active SparkContext was created at:; 	; 	org.apache.spark.SparkContext.getOrCreate(SparkContext.scala); 	sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	java.lang.reflect.Method.invoke(Method.java:498); 	sparklyr.Invoke.invoke(invoke.scala:139); 	sparklyr.StreamHandler.handleMethodCall(stream.scala:123); 	sparklyr.StreamHandler.read(stream.scala:66); 	sparklyr.BackendHandler.channelRead0(handler.scala:51); 	sparklyr.BackendHandler.channelRead0(handler.scala:4); 	io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267); 	; 	at org.apache.sp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:9174,Simpl,SimpleChannelInboundHandler,9174,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['Simpl'],['SimpleChannelInboundHandler']
Usability,"extmanager</code> were one-shot,; as discovered by Alex Pizarro.</li>; <li><code>decorator.decorator</code> was not passing the kwsyntax argument.</li>; </ul>; <h2>5.0.9 (2021-05-16)</h2>; <p>Fixed a test breaking PyPy. Restored support for Sphinx.</p>; <h2>5.0.8 (2021-05-15)</h2>; <p>Made the decorator module more robust when decorating builtin functions; lacking dunder attributes, like <code>dict.__setitem__</code>.</p>; <h2>5.0.7 (2021-04-14)</h2>; <p>The decorator module was not passing correctly the defaults inside the; <code>*args</code> tuple, thanks to Dan Shult for the fix. Also fixed some mispellings; in the documentation and integrated codespell in the CI, thanks to; Christian Clauss.</p>; <h2>5.0.6 (2021-04-08)</h2>; <p>The decorator module was not copying the <strong>module</strong> attribute anymore.; Thanks to Nikolay Markov for the notice.</p>; <h2>5.0.5 (2021-04-04)</h2>; <p>Dropped support for Python &lt; 3.5 with a substantial simplification of; the code base (now building a decorator does not require calling &quot;exec&quot;).; Added a way to mimic functools.wraps-generated decorators.; Ported the Continuous Integration from Travis to GitHub.</p>; <h2>4.4.2 (2020-02-29)</h2>; <p>Sylvan Mosberger (<a href=""https://github.com/Infinisil"">https://github.com/Infinisil</a>) contributed a patch to; some doctests that were breaking on NixOS.; John Vandenberg (<a href=""https://github.com/jayvdb"">https://github.com/jayvdb</a>) made a case for removing the usage</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/micheles/decorator/commit/ad013a2c1ad7969963acf3dea948632be387f5a0""><code>ad013a2</code></a> Updated changelog and bumped version to 5.1.1</li>; <li><a href=""https://github.com/micheles/decorator/commit/5a2023203948ff297cc2e482aa66f84d75d1d1f8""><code>5a20232</code></a> Fixed implementation of decorator_apply</li>; <li><a href=""https://github.c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11490:1974,simpl,simplification,1974,https://hail.is,https://github.com/hail-is/hail/pull/11490,1,['simpl'],['simplification']
Usability,"extmanager</code> were one-shot,; as discovered by Alex Pizarro.</li>; <li><code>decorator.decorator</code> was not passing the kwsyntax argument.</li>; </ul>; <h2>5.0.9 (2021-05-16)</h2>; <p>Fixed a test breaking PyPy. Restored support for Sphinx.</p>; <h2>5.0.8 (2021-05-15)</h2>; <p>Made the decorator module more robust when decorating builtin functions; lacking dunder attributes, like <code>dict.__setitem__</code>.</p>; <h2>5.0.7 (2021-04-14)</h2>; <p>The decorator module was not passing correctly the defaults inside the; <code>*args</code> tuple, thanks to Dan Shult for the fix. Also fixed some mispellings; in the documentation and integrated codespell in the CI, thanks to; Christian Clauss.</p>; <h2>5.0.6 (2021-04-08)</h2>; <p>The decorator module was not copying the <strong>module</strong> attribute anymore.; Thanks to Nikolay Markov for the notice.</p>; <h2>5.0.5 (2021-04-04)</h2>; <p>Dropped support for Python &lt; 3.5 with a substantial simplification of; the code base (now building a decorator does not require calling &quot;exec&quot;).; Added a way to mimic functools.wraps-generated decorators.; Ported the Continuous Integration from Travis to GitHub.</p>; <h2>4.4.2 (2020-02-29)</h2>; <p>Sylvan Mosberger (<a href=""https://github.com/Infinisil"">https://github.com/Infinisil</a>) contributed a patch to; some doctests that were breaking on NixOS.; John Vandenberg (<a href=""https://github.com/jayvdb"">https://github.com/jayvdb</a>) made a case for removing the usage</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/micheles/decorator/commits/5.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=decorator&package-manager=pip&previous-version=4.4.0&new-version=5.1.1)](https://docs.github.com/en/github/managing-security-v",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11799:1943,simpl,simplification,1943,https://hail.is,https://github.com/hail-is/hail/pull/11799,1,['simpl'],['simplification']
Usability,feedback on generic VEP,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2460:0,feedback,feedback,0,https://hail.is,https://github.com/hail-is/hail/pull/2460,2,['feedback'],['feedback']
Usability,"fields 4; compact format; info bits 0; 0: len 30; hex 62617463682d776f726b65722d64676f6c647374652d7374616e64617264; asc batch-worker-dgoldste-standard; (total 36 bytes);; 1: len 6; hex 00000025f0ee; asc % ;;; 2: len 7; hex 01000000a90a9b; asc ;;; 3: len 4; hex 80000fa0; asc ;;. *** (1) WAITING FOR THIS LOCK TO BE GRANTED:; RECORD LOCKS space id 376 page no 8 n bits 408 index PRIMARY of table `dgoldste-batch`.`aggregated_billing_project_user_resources_v3` trx id 2486515 lock_mode X locks rec but not gap waiting; Record lock, heap no 228 PHYSICAL RECORD: n_fields 7; compact format; info bits 0; 0: len 4; hex 74657374; asc test;;; 1: len 8; hex 64676f6c64737465; asc dgoldste;;; 2: len 4; hex 80000009; asc ;;; 3: len 4; hex 80000034; asc 4;;; 4: len 6; hex 00000025f0cd; asc % ;;; 5: len 7; hex 810000021b01cd; asc ;;; 6: len 8; hex 80000000001b09e0; asc ;;. *** (2) TRANSACTION:; TRANSACTION 2486477, ACTIVE 0 sec starting index read; mysql tables in use 27, locked 27; LOCK WAIT 47 lock struct(s), heap size 8312, 215 row lock(s), undo log entries 211; MySQL thread id 682, OS thread handle 140330866251520, query id 4746389 10.32.3.39 dgoldste-batch-user executing; INSERT INTO aggregated_job_group_resources_v3 (batch_id, job_group_id, resource_id, token, `usage`); SELECT attempt_resources.batch_id,; job_group_self_and_ancestors.ancestor_id,; attempt_resources.deduped_resource_id,; NAME_CONST('rand_token',189),; NAME_CONST('msec_diff_rollup',1671) * quantity; FROM attempt_resources; LEFT JOIN jobs ON attempt_resources.batch_id = jobs.batch_id AND attempt_resources.job_id = jobs.job_id; LEFT JOIN job_group_self_and_ancestors ON jobs.batch_id = job_group_self_and_ancestors.batch_id AND jobs.job_group_id = job_group_self_and_ancestors.job_group_id; WHERE attempt_resources.batch_id = NEW.batch_id AND attempt_resources.job_id = NEW.job_id AND attempt_resources.attempt_id = NEW.attempt_id; FOR UPDATE; ON DUPLICATE KEY UPDATE `usage` = aggregated_job_group_resources_v3.`usage` + NAM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14380:2881,undo,undo,2881,https://hail.is,https://github.com/hail-is/hail/issues/14380,1,['undo'],['undo']
Usability,fix not clearing per item,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3509:8,clear,clearing,8,https://hail.is,https://github.com/hail-is/hail/pull/3509,2,['clear'],['clearing']
Usability,"fixes #13407. CHANGELOG: Resolves #13407 in which uses of `union_rows` could reduce parallelism to one partition resulting in severely degraded performance. TableUnion was always collapsing to a single partition when the key was empty. This adds a special case handling, which just concatenates partitions. The body of the resulting TableStage is a little hacky: it does a StreamMultiMerge, but where exactly one input stream is non-empty. I think that should have fine performance, and I didn’t see any simpler ways to do it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13414:504,simpl,simpler,504,https://hail.is,https://github.com/hail-is/hail/pull/13414,1,['simpl'],['simpler']
Usability,flesh out SparkBackend and add some simple tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5127:36,simpl,simple,36,https://hail.is,https://github.com/hail-is/hail/pull/5127,2,['simpl'],['simple']
Usability,"fy JS logic based on new JSON structure.; - Check-in and implement versioned deployment of the annotation db configuration JSON.; - Add a JS file to the website that defines `hail_version` and `hail_pip_version`.; - Add `key_properties` which currently supports two properties `gene` and `unique`. Gene keyed datasets require using the `gencode` dataset to crosswalk from locus to gene before joining.; - Rudimentary test of key properties functionality. Foundational Changes Outside Annotation DB:; - Define `__pip_version__` in `hail`.; - Teach `StructExpression` and `TupleExpression` how to slice by integers, facilitating the construction of structs of a prefix of fields.; - Make `ttuple` a mapping from integers to the tuple elements.; - Implement `Table._maybe_flexindex_table_by_expr` which, given a indexer expression, finds a prefix of the expression that can index the indexee, if such an expression exists. Unrelated changes:; - Clarify Makefile error echos with `ERROR:`. ---. ## flexindex. The primary use case for this is a dataset which is `locus, allele` keyed and needs to index into a `locus` keyed or `interval<locus>` keyed dataset. Hail's normal join logic will return a key mismatch error:. ```python; import hail as hl; t = hl.utils.range_table(10); t2 = t.key_by(x=t.idx, y=t.idx); t.index(t2.key); ```; ```; Traceback (most recent call last):; File ""<ipython-input-6-3ddc90774dfe>"", line 1, in <module>; t.index(t2.key); File ""/usr/local/lib/python3.7/site-packages/hail/table.py"", line 1536, in index; raise ExpressionException(f""Key type mismatch: cannot index table with given expressions:\n""; ExpressionException: Key type mismatch: cannot index table with given expressions:; Table key: int32; Index Expressions: int32, int32; ```. This new, private, method facilitates the annotation db which users expect to automatically find a compatible prefix of the key to use as an indexer. ---. Dice came up @chrisvittal, but I'm curious to hear @tpoterba 's feedback as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7178:2545,feedback,feedback,2545,https://hail.is,https://github.com/hail-is/hail/pull/7178,1,['feedback'],['feedback']
Usability,"gatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745). 2019-01-22 13:12:06 YarnClientSchedulerBackend: INFO: Interrupting monitor thread; 2019-01-22 13:12:06 YarnClientSchedulerBackend: INFO: Shutting down all executors; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Asking each executor to shut down; 2019-01-22 13:12:06 SchedulerExtensionServices: INFO: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-22 13:12:06 YarnClientSchedulerBackend: INFO: Stopped; 2019-01-22 13:12:06 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!; 2019-01-22 13:12:06 MemoryStore: INFO: MemoryStore cleared; 2019-01-22 13:12:06 BlockManager: INFO: BlockManager stopped; 2019-01-22 13:12:06 BlockManagerMaster: INFO: BlockManagerMaster stopped; 2019-01-22 13:12:06 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!; 2019-01-22 13:12:06 TransportResponseHandler: ERROR: Still have 1 requests outstanding when connection from /192.168.18.203:44844 is closed; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnSchedulerEndpoint: WARN: Attempted to get executor loss reason for executor id 14 at RPC address 192.168.18.189:50356, but got no response. Marking as slave lost.; java.io.IOException: Connection from /192.168.18.203:44844 closed; at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:146); at org.apache.spark.network.server.TransportChannelHandler.channelInactive(Transpo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:209969,clear,cleared,209969,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['clear'],['cleared']
Usability,"ge:. ```; Traceback (most recent call last):; File ""…/borkscript.py"", line 8, in <module>; my_job, my_output = make_job(batch); File ""…/site-packages/hailtop/batch/job.py"", line 125, in __getitem__; return self._get_resource(item); File ""…/site-packages/hailtop/batch/job.py"", line 118, in _get_resource; r = self._batch._new_job_resource_file(self, value=item); File ""…/site-packages/hailtop/batch/batch.py"", line 405, in _new_job_resource_file; jrf = _resource.JobResourceFile(value, source); File ""…/site-packages/hailtop/batch/resource.py"", line 128, in __init__; super().__init__(value); File ""…/site-packages/hailtop/batch/resource.py"", line 48, in __init__; assert value is None or isinstance(value, str); AssertionError; ```. Of course, in a 400-line script it took a long while to figure out what the traceback that seemed to have little to do with any dubious code of ours was trying to tell us, and to notice that the actual problem was the `return` 200 lines away!. The problem is that these classes define `__getitem__()` so their resources can be accessed as if via a dict. The assignment into multiple variables causes Python to try to interpret the RHS as something iterable, and as `__getitem__` is defined, it will use `__getitem__(0)`, `__getitem__(1)`,... to implement that iteration. These classes are not really iterable, so define a no-op `__iter__()` to prevent this. With this, we get:. ```; Traceback (most recent call last):; File ""…/borkscript.py"", line 8, in <module>; my_job, my_output = make_job(batch); File ""…/site-packages/hailtop/batch/job.py"", line 127, in __iter__; raise TypeError(f'{type(self).__name__!r} object is not iterable'); TypeError: 'BashJob' object is not iterable; ```. Which, while still not pointing directly at the problem, is much clearer. Especially for ResourceGroup, it may be worth defining iteration for these classes in future. But at the moment `__getitem__`-based iteration fails, so this ensures it fails with a clear TypeError message.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14390:2118,clear,clearer,2118,https://hail.is,https://github.com/hail-is/hail/pull/14390,2,['clear'],"['clear', 'clearer']"
Usability,"github.com/grantjenks/python-sortedcontainers/commit/a1f52d6713dd2c2713a881d4f4d86ed68ff71cab""><code>a1f52d6</code></a> Bump version to 2.4.0</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/2678a78b6dacbe2352bff7876a26759d84971dac""><code>2678a78</code></a> Implement SortedDict methods: <strong>or</strong>, <strong>ror</strong>, and <strong>ior</strong> (<a href=""https://github-redirect.dependabot.com/grantjenks/python-sortedcontainers/issues/171"">#171</a>)</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/9887989b21fc21fe572e0b4c30a3f3aa1eabbdca""><code>9887989</code></a> Bump version to 2.3.0</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/da6d0d034822f66966e4a84a3a1e2f37cc83e3b0""><code>da6d0d0</code></a> Remove unneeded &quot;update order&quot; consistency test</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/e85d8659733cb3e28d539a28db0fdd71672ab2e4""><code>e85d865</code></a> Simplify &quot;update order&quot; consistency test</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/7dc426c95a0c329d5514e6198d92080f1ffc1e5e""><code>7dc426c</code></a> Fix update() ordering to be more consistent with add() ordering (<a href=""https://github-redirect.dependabot.com/grantjenks/python-sortedcontainers/issues/159"">#159</a>)</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/13d30bc654eb9e6be092282ca502967fcb7f0113""><code>13d30bc</code></a> Bump version to 2.2.2</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/4997d0e849f2275d1931772a5432163ecc20e0b0""><code>4997d0e</code></a> Refactor small slice optimization in SortedList.<strong>getitem</strong></li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/6ee5d57fc8d691fbab4972b853a60348d0f922ef""><code>6ee5d57</code></a> improve SortedList.<strong>getitem</strong>() performance for small slices</li>; <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11476:2312,Simpl,Simplify,2312,https://hail.is,https://github.com/hail-is/hail/pull/11476,1,['Simpl'],['Simplify']
Usability,"give each loop a name so that `Recur` unambiguously refers to a loop defined in the surrounding scope, mostly treating `Recur` as something of a function reference.; * The code generation is rather inconsistent, since the `Recur` node technically has the same type as the return type of the function, but the code generated needs to be a jump node with no actual value (which makes the generated EmitTriplet look a lot like it has type TVoid!); * @patrick-schultz proposed a similar design, but with two additional types to make the difference between the type of the `Recur` concept and the actual return type more explicit. I have not yet implemented it because I think it might make this python interface more difficult to support, and I rather like its simplicity.; * @patrick-schultz and I were talking about rewriting loops in the stream interface.; * We can only emit calls to recur in the same method that the original loop is defined in, because we are using jumps to implement them. This means we need to know that we are not going to wrap any calls that contain `Recur` in a method. I don't believe there are any cases where we wrap `If` conditions or `Let` bodies in methods, so this is fine for now, but we're not enforcing it in any way. I believe that the iteration for the stream codegen stuff will always be in the same method, so we wouldn't have to deal with this specially there.; * I've implemented a pretty simple version of here, as part of the `Streamify` pass. I believe it should handle all the valid tail-recursive cases, but I don't think we want to use it right now since it'll always allocate (as opposed to not allocating if all state is primitive). We could potentially revisit this once we can allow stream elements like this to basically store their elements in primitive fields, if that prevents allocation. You can take a look here: https://github.com/catoverdrive/hail/compare/loops...catoverdrive:loops-as-stream?expand=1. cc @cseed @patrick-schultz @chrisvittal",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7614:2802,simpl,simple,2802,https://hail.is,https://github.com/hail-is/hail/pull/7614,1,['simpl'],['simple']
Usability,gnomAD is also exhausting memory (exit code 137) on their frequencies generating pipeline. They’re still exhausting memory after eliminating fork-joins in their pipeline. They were unintentionally invoking densification four times. We’ll need to sort out why even the simple frequencies blows memory.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13584#issuecomment-1712493167:268,simpl,simple,268,https://hail.is,https://github.com/hail-is/hail/issues/13584#issuecomment-1712493167,2,['simpl'],['simple']
Usability,"h.batches.id | 1 | 100.00 | Using index |; | 1 | SIMPLE | aggregated_batch_resources | NULL | ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 44 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 102 | batch.aggregated_batch_resources.resource | 1 | 100.00 | NULL |; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+-------------------------------+---------+---------------------------------------------+------+----------+-----------------------------------------------------------+; ```. New plan; ```; +----+-------------+-----------------------------------+------------+--------+-----------------+-----------------+---------+-------------------------------------------+--------+----------+----------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+-----------------------------------+------------+--------+-----------------+-----------------+---------+-------------------------------------------+--------+----------+----------------------------------+; | 1 | SIMPLE | batches | NULL | ref | batches_deleted | batches_deleted | 1 | const | 493389 | 33.33 | Using where; Backward index scan |; | 1 | SIMPLE | batches_n_jobs_in_complete_states | NULL | eq_ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 1 | 100.00 | NULL |; | 1 | SIMPLE | batches_cancelled | NULL | eq_ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 1 | 100.00 | Using index |; | 1 | SIMPLE | billing_project_users | NULL | eq_ref | PRIMARY | PRIMARY | 204 | batch.batches.billing_project,const | 1 | 100.00 | Using index |; | 1 | SIMPLE | aggregated_batch_resources | NULL | ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 44 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 102 | batch.aggregated_batch_resour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12049:2747,SIMPL,SIMPLE,2747,https://hail.is,https://github.com/hail-is/hail/pull/12049,1,['SIMPL'],['SIMPLE']
Usability,"hail currently only supports v5.4. The current version v6.3.2 (https://www.elastic.co/downloads/elasticsearch) has some nice new features such as field aliases.; The main breaking change from v5.x is that ""mapping_types"" have been removed, so the ; kt.export_elasticsearch `mapping_type` arg isn't needed anymore (https://www.elastic.co/guide/en/elasticsearch/reference/6.0/breaking-changes-6.0.html). ### Hail version:; 0.1, 0.2. ### What you did:. kt.export_elasticsearch. ### What went wrong (all error messages here, including the full java stack trace):; ```; Traceback (most recent call last):; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/load_clinvar_to_es_pipeline.py"", line 112, in <module>; export_globals_to_index_meta=True,; File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 142, in export_vds_to_elasticsearch; verbose=verbose); File ""/hail-elasticsearch-pipelines/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; kt.export_elasticsearch(self._host, int(self._port), index_name, index_type_name, block_size, config=elasticsearch_config); File ""<decorator-gen-143>"", line 2, in export_elasticsearch; File ""/hail/build/distributions/hail-python.zip/hail/java.py"", line 121, in handle_py4j; hail.java.FatalError: EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 20050, localhost): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot detect ES version - typically this happens if the network/Elasticsearch cluster is not accessible or when targeting a WAN/Cloud instance without the proper setting 'es.nodes.wan.only'; 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:247); 	at org.elasticsearch.hadoop.rest.RestService.createWri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:337,guid,guide,337,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['guid'],['guide']
Usability,"hailctl dataproc start \; 	--max-idle 12h \; 	--init gs://gnomad-public/tools/inits/master-init.sh \; 	--packages slackclient==2.0.0,websocket-client,sklearn,tabulate,statsmodels,scikit-learn,hdbscan,matplotlib bw2. Fails with the following error:; ```; gcloud beta dataproc clusters create \; bw2 \; --image-version=1.4-debian9 \; --properties=spark:spark.driver.maxResultSize=0,spark:spark.task.maxFailures=20,spark:spark.kryoserializer.buffer.max=1g,spark:spark.driver.extraJavaOptions=-Xss4M,spark:spark.executor.extraJavaOptions=-Xss4M,hdfs:dfs.replication=1,dataproc:dataproc.logging.stackdriver.enable=false,dataproc:dataproc.monitoring.stackdriver.enable=false,spark:spark.driver.memory=41g \; --initialization-actions=gs://hail-common/hailctl/dataproc/0.2.18/init_notebook.py,gs://gnomad-public/tools/inits/master-init.sh \; --metadata=^|||^WHEEL=gs://hail-common/hailctl/dataproc/0.2.18/hail-0.2.18-py3-none-any.whl|||PKGS=aiohttp|bokeh>1.1,<1.3|decorator<5|gcsfs==0.2.1|hurry.filesize==0.9|ipykernel<5|nest_asyncio|numpy<2|pandas>0.22,<0.24|parsimonious<0.9|PyJWT|python-json-logger==0.1.11|requests>=2.21.0,<2.21.1|scipy>1.2,<1.4|tabulate==0.8.3|slackclient==2.0.0|websocket-client|sklearn|tabulate|statsmodels|scikit-learn|hdbscan|matplotlib \; --master-machine-type=n1-highmem-8 \; --master-boot-disk-size=100GB \; --num-master-local-ssds=0 \; --num-preemptible-workers=0 \; --num-worker-local-ssds=0 \; --num-workers=2 \; --preemptible-worker-boot-disk-size=40GB \; --worker-boot-disk-size=40 \; --worker-machine-type=n1-standard-8 \; --zone=us-central1-b \; --initialization-action-timeout=20m \; --labels=creator=weisburd_broadinstitute_org \; --max-idle=12h; Starting cluster 'bw2'...; Waiting on operation [projects/seqr-project/regions/global/operations/46f1d37d-798a-3fc0-8f70-eac304448a08].; Waiting for cluster creation operation...; WARNING: For PD-Standard without local SSDs, we strongly recommend provisioning 1TB or larger to ensure consistently high I/O performance. See h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6634:186,learn,learn,186,https://hail.is,https://github.com/hail-is/hail/issues/6634,1,['learn'],['learn']
Usability,"he binding structure of `TableStage` has been slightly reorganized. The `letBindings`, which are used on the master, and the `broadcastVals` which are used on the driver (previously, they had to also be usable on master), have been teased apart. In the new structure:; * `letBindings` are as before: a sequence of bindings which are evaluated in sequence on the master, whose bindings are visible in the `contexts` expression and in the `broadcastVals`; * `broadcastVals` are now a separate sequence of bindings, which are evaluated on the master in parallel (each broadcast binding sees only the `letBindings`, no previous `broadcastVals`), and whose bindings are visible only in the `partitionIR`; * `globals` is now required to be a `Ref`, which is defined in `letBindings` and redefined in `broadcastVals`, so that the `Ref` is valid in later `letBindings`, in `contexts`, as well as in the `partitionIR`. This does mean that `globals` is always broadcast, even when it's just an empty struct. But since we're generating a `CollectDistributedArray` which always broadcasts a struct, adding a nested required empty struct shouldn't have any overhead. I think this more layered organization has a clearer semantics than before, where `broadcastVals` were a subset of the `letBindings`, and `globals` was an arbitrary IR in the `broadcastVals` scope. It's also closer to the structure of the resulting `CollectDistributedArray`. I tried to pull `letBindings` out of `TableStage`, letting them be built up imperatively in the lowering pass, similar to what we do in `LowerMatrixIR`. I had it mostly working, but was blocked by `localSort`, which compiles and executes an intermediate `TableStage`. This needs to be able to compile only those bindings needed in that intermediate stage, and to throw out those used bindings, neither of which is easy when the bindings are accumulated in a single list throughout the lowering pass. @catoverdrive Would appreciate if you could take a quick look as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8917:2227,clear,clearer,2227,https://hail.is,https://github.com/hail-is/hail/pull/8917,1,['clear'],['clearer']
Usability,"he location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references these third-party classes:; ```; import breeze.linalg.DenseMatrix; import breeze.linalg._; import breeze.linalg.{*, diag, DenseMatrix => BDM, D",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:1121,learn,learn,1121,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741,2,['learn'],['learn']
Usability,"he results of each benchmark are outputted as json lines (`.jsonl`) to the file specified by the `--output` pytest arg or stdout. The folder structure should be familiar, resembling our `test/` directory.; I believe this is flexible enough to add `hailtop` benchmarks should we so wish:; ```; pytest.ini - hoisted from `test/` to include benchmark marks; benchmark/; - conftest.py for custom pytest command line args ; - hail/; - confest.py for custom plugin that runs hail benchmarks; - benchmark_*.py hail query benchmark code; - tools/; - shared utilites, including the `@benchmark`; ```; Supporting pytest fixtures required writing a custom plugin to run benchmarks, as using off-the-shelf; solutions like `pytest-benchmark` would forbid method level fixtures like `tmp_path` etc.; The plugin is designed to run ""macro-benchmarks"" (ie long-running tests) and fully supports pytest parameterisation.; For each benchmark, the plugin initialises hail and then repeats (for a number of iterations defined by the pytest mark); acquiring fixtures, timing invocation and tearing-down fixtures, finally stopping hail. It is therefore unsuitable for; microbenchmarks, for which we currenly have none in python. If we add them we'd need to tweak this so support them.; Perhaps an inner loop or something. The process of submitting benchmarks to batch is greatly simplified as the old `Makefile` infrastructure for ; building wheels and docker images etc has been replaced with the script `benchmark_in_batch.py`.; Benchmark images are now based off the `hail-dev` image built in CI (or via the `hail-dev-image` make target). ; Furthermore, you can control the number of ""replicate"" jobs created for each benchmark at the benchmark level using; the `@benchmark(batch_jobs=N)` decotator. Limitations/shortcomings:; - Output is currently jsonl only. Some more human friendly output might be nice on a per iteration basis.; - Old `benchmark-hail` utilities are broken. I'll restore these in subsequent changes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14565:2111,simpl,simplified,2111,https://hail.is,https://github.com/hail-is/hail/pull/14565,1,['simpl'],['simplified']
Usability,"hink for Stanley Center stuff we; should use GCP auth. > I'm getting proxy timeouts. We need an ready endpoint and something on the; > client side to poll and redirect. Actually, awesome if it doesn't poll but; > uses, say, websockets, and the server watches the pod for a notification for; > k8s (or does this and also polls, which seems to be our standard pattern). The proxy timeouts might be because I shut the whole thing down? But yeah, I; also saw timeouts if a pod can't be scheduled right away. > Should we have an auto-scaling non-preemptible pool and schedule these there?. We already have such a pool, and these pods do not tolerate the preemptible; taint, so they are forced to get scheduled on non-preemptibles. > If we do that, to optimize startup time, we should have imagePullPolicy: Never; > and then pull the image on startup and push it on update. I think `imagePullPolicy: Never` is a bad idea. If there's a bug where the image; is not present, then we get stuck. I think we should rely on k8s to pull the 5GB; jupyter image in a reasonable time period. If we cannot rely on that, we just; start up N nodes before the tutorial, ssh to each and pull the image. If; somehow the image disappears, `imagePullPolicy: IfNotPresent` ensures we just; experience a delay rather than complete interruption. > When do you reap jupyter pods? jupyterhub has a simple management console that; > lets you shut down notebooks. I just run `make clean-jobs`, but we could add a delete endpoint and a little; web page. > I don't think you can do this dynamically using headers. Blueprints seem to be; > the answer in Flask:; > https://stackoverflow.com/questions/18967441/add-a-prefix-to-all-flask-routes/18969161#18969161. ah, cool. > Is there a reason you didn't make it a subdomain? I thought we decided we; > preferred that. I thought it would take less time to get a subdirectory working than figure out; how to add a new domain and a cert and deal with DNS. Long term a subdomain makes sense.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576#issuecomment-431185878:2177,simpl,simple,2177,https://hail.is,https://github.com/hail-is/hail/pull/4576#issuecomment-431185878,2,['simpl'],['simple']
Usability,"his PR just contains the most simple streams (`ArrayRange`, `MakeArray`, `ArrayMap`, `ArrayFilter`). I'd like to get comments on it before merging my other stream implementations. So far I have all of the other streams implemented, except for `ReadPartition` and `If` (it turns out that `If` is tricky). **Interface**. `init` can return in two possible ways:; - `Missing` - the stream is actually entirely missing; this usually happens if one of the parameters to a stream is missing (e.g. `ArrayRange(0, NA, 1) = NA`); - `State(s0)` - the stream has started; its initial state is `s0`. `step` can return in three possible ways as well:; - `EOS` - we've reached the End Of Stream, there are no more elements left.; - `Skip(s1)` - this iteration didn't produce an element, you must try stepping again with state `s1` (see ""design notes"").; - `Yield(elt, s1)` - the stream computed an element `elt`; the following stream state will be `s1`. **Design Notes**. - The `Skip` return is very useful for simplifying the implementation of `ArrayFilter`. There is basically no nice way to implement filter otherwise without introducing some significant code duplication.; - ~~The stream ""parameter"", as well as the `Empty` return, are not very useful for the basic streams in this PR. However, they simplify the implementation of `ArrayFlatMap` (aka ""composing"" two parameterized streams).~~ NOTE (to Patrick): I decided to abandon the ""empty"" return idea in favor of just providing ""default states"" that always yield empty streams. **Implementation Notes**. - The implementation makes great use of Scala's type system. Most of the streams are implemented first in a very type aware manner, where it is easy to reason about the types of data flowing in and out, before being instantiated with EmitTriplets and Envs which don't hold very much type information. For instance, we have the following helper for `map`:; ```scala; Parameterized[P, A].map(f: A => B): Parameterized[P, B]; ```; The emitter instantiate",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7228:1707,simpl,simplifying,1707,https://hail.is,https://github.com/hail-is/hail/pull/7228,1,['simpl'],['simplifying']
Usability,"his because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxZDhjNDI0MS1hOTllLTQwZDktOTM5Yy0zZWMzM2NkNTI0ZjkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjFkOGM0MjQxLWE5OWUtNDBkOS05MzljLTNlYzMzY2Q1MjRmOSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""1d8c4241-a99e-40d9-939c-3ec33cd524f9"",""prPublicId"":""1d8c4241-a99e-40d9-939c-3ec33cd524f9"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.2""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6149518"",""SNYK-PYTHON-CRYPTOGRAPHY-6157248""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581,581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use of a Broken or Risky Cryptographic Algorithm](https://learn.snyk.io/lesson/insecure-hash/?loc&#x3D;fix-pr); 🦉 [Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14230:3944,Learn,Learn,3944,https://hail.is,https://github.com/hail-is/hail/pull/14230,3,"['Learn', 'learn']","['Learn', 'learn']"
Usability,hl.plot.pdf is undocumented,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8215:15,undo,undocumented,15,https://hail.is,https://github.com/hail-is/hail/issues/8215,2,['undo'],['undocumented']
Usability,"https://github.com/hail-is/hail/files/12231481/data2.tar.gz. Simplest repro I have. One row in chr8... two rows in ch5... ; ```; In [2]: import hail as hl; ...: y = hl.read_table(""chr8_51749536.ht""); ...: x = hl.read_table('ch5_and_ch8.ht'); ...: print(y.annotate(gene=x[y.locus].gene).collect()); ```. TableIR:; ```; (TableCollect; (TableOrderBy (Alocus Aalleles); (TableMapRows; (TableLeftJoinRightDistinct __uid_3; (TableRead; Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}; False (TableNativeReader chr8_51749536.ht )); (TableRead; Table{global:Struct{},key:[locus],row:Struct{locus:Locus(GRCh38),gene:String}}; False (TableNativeReader ch5_and_ch8.ht ))); (InsertFields; (SelectFields (locus alleles) (Ref row)); None; (gene; (GetField gene (GetField __uid_3 (Ref row)))))))); ```; [hail-20230801-1154-0.2.120-be655bbda3cb.log](https://github.com/hail-is/hail/files/12231617/hail-20230801-1154-0.2.120-be655bbda3cb.log)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13339#issuecomment-1660613347:61,Simpl,Simplest,61,https://hail.is,https://github.com/hail-is/hail/issues/13339#issuecomment-1660613347,1,['Simpl'],['Simplest']
Usability,https://github.com/hail-is/jgscm/pull/3 will resolve this. `jgscm` sequentially issues API calls for each folder or file in a directory. Each call takes about a second so this quickly kills the UX.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8587:194,UX,UX,194,https://hail.is,https://github.com/hail-is/hail/issues/8587,1,['UX'],['UX']
Usability,"https://github.com/kjd/idna) from 3.6 to 3.7.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/kjd/idna/releases"">idna's releases</a>.</em></p>; <blockquote>; <h2>v3.7</h2>; <h2>What's Changed</h2>; <ul>; <li>Fix issue where specially crafted inputs to encode() could take exceptionally long amount of time to process. [CVE-2024-3651]</li>; </ul>; <p>Thanks to Guido Vranken for reporting the issue.</p>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/kjd/idna/compare/v3.6...v3.7"">https://github.com/kjd/idna/compare/v3.6...v3.7</a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/kjd/idna/blob/master/HISTORY.rst"">idna's changelog</a>.</em></p>; <blockquote>; <p>3.7 (2024-04-11); ++++++++++++++++</p>; <ul>; <li>Fix issue where specially crafted inputs to encode() could; take exceptionally long amount of time to process. [CVE-2024-3651]</li>; </ul>; <p>Thanks to Guido Vranken for reporting the issue.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/kjd/idna/commit/1d365e17e10d72d0b7876316fc7b9ca0eebdd38d""><code>1d365e1</code></a> Release v3.7</li>; <li><a href=""https://github.com/kjd/idna/commit/c1b3154939907fab67c5754346afaebe165ce8e6""><code>c1b3154</code></a> Merge pull request <a href=""https://redirect.github.com/kjd/idna/issues/172"">#172</a> from kjd/optimize-contextj</li>; <li><a href=""https://github.com/kjd/idna/commit/0394ec76ff022813e770ba1fd89658790ea35623""><code>0394ec7</code></a> Merge branch 'master' into optimize-contextj</li>; <li><a href=""https://github.com/kjd/idna/commit/cd58a23173d2b0a40b95ee680baf3e59e8d33966""><code>cd58a23</code></a> Merge pull request <a href=""https://redirect.github.com/kjd/idna/issues/152"">#152</a> from elliotwutingfeng/dev</li>; <li><a href=""https://github.com/kjd/idna/commit/5beb28b9dd77912c0dd656d8b0fdba3eb80222e7""><code>5beb28b</code></a> ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14464:1016,Guid,Guido,1016,https://hail.is,https://github.com/hail-is/hail/pull/14464,7,['Guid'],['Guido']
Usability,https://hail.is/docs/0.2/guides/genetics.html#filter-loci-by-a-list-of-locus-intervals,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5254:25,guid,guides,25,https://hail.is,https://github.com/hail-is/hail/issues/5254,1,['guid'],['guides']
Usability,https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/simple.20job.20timings.20from.20batch.20perspective/near/366227291,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13181:70,simpl,simple,70,https://hail.is,https://github.com/hail-is/hail/pull/13181,1,['simpl'],['simple']
Usability,"i went through and manually fixed everything that `--unsafe-fixes` had initially addressed (after undoing the unsafe fixes, obv), and i broke all my changes up into separate commits based on which linter rule they were addressing",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14150#issuecomment-1894479704:98,undo,undoing,98,https://hail.is,https://github.com/hail-is/hail/pull/14150#issuecomment-1894479704,2,['undo'],['undoing']
Usability,"i>; <li>api-change:<code>connect</code>: [<code>botocore</code>] Added AllowedAccessControlTags and TagRestrictedResource for Tag Based Access Control on Amazon Connect Webpage</li>; <li>api-change:<code>dynamodb</code>: [<code>botocore</code>] Updated minor fixes for DynamoDB documentation.</li>; <li>api-change:<code>dynamodbstreams</code>: [<code>botocore</code>] Update dynamodbstreams client to latest version</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] This release adds support for copying an Amazon Machine Image's tags when copying an AMI.</li>; <li>api-change:<code>glue</code>: [<code>botocore</code>] AWSGlue Crawler - Adding support for Table and Column level Comments with database level datatypes for JDBC based crawler.</li>; <li>api-change:<code>iot-roborunner</code>: [<code>botocore</code>] AWS IoT RoboRunner is a new service that makes it easy to build applications that help multi-vendor robots work together seamlessly. See the IoT RoboRunner developer guide for more details on getting started. <a href=""https://docs.aws.amazon.com/iotroborunner/latest/dev/iotroborunner-welcome.html"">https://docs.aws.amazon.com/iotroborunner/latest/dev/iotroborunner-welcome.html</a></li>; <li>api-change:<code>quicksight</code>: [<code>botocore</code>] This release adds the following: 1) Asset management for centralized assets governance 2) QuickSight Q now supports public embedding 3) New Termination protection flag to mitigate accidental deletes 4) Athena data sources now accept a custom IAM role 5) QuickSight supports connectivity to Databricks</li>; <li>api-change:<code>sagemaker</code>: [<code>botocore</code>] Added DisableProfiler flag as a new field in ProfilerConfig</li>; <li>api-change:<code>servicecatalog</code>: [<code>botocore</code>] This release 1. adds support for Principal Name Sharing with Service Catalog portfolio sharing. 2. Introduces repo sourced products which are created and managed with existing SC APIs. These products are synced to",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:3405,guid,guide,3405,https://hail.is,https://github.com/hail-is/hail/pull/12498,2,['guid'],['guide']
Usability,"i>; <li>api-change:<code>logs</code>: [<code>botocore</code>] Updates to support CloudWatch Logs data protection and CloudWatch cross-account observability</li>; <li>api-change:<code>mgn</code>: [<code>botocore</code>] This release adds support for Application and Wave management. We also now support custom post-launch actions.</li>; <li>api-change:<code>oam</code>: [<code>botocore</code>] Amazon CloudWatch Observability Access Manager is a new service that allows configuration of the CloudWatch cross-account observability feature.</li>; <li>api-change:<code>organizations</code>: [<code>botocore</code>] This release introduces delegated administrator for AWS Organizations, a new feature to help you delegate the management of your Organizations policies, enabling you to govern your AWS organization in a decentralized way. You can now allow member accounts to manage Organizations policies.</li>; <li>api-change:<code>rds</code>: [<code>botocore</code>] This release enables new Aurora and RDS feature called Blue/Green Deployments that makes updates to databases safer, simpler and faster.</li>; <li>api-change:<code>textract</code>: [<code>botocore</code>] This release adds support for classifying and splitting lending documents by type, and extracting information by using the Analyze Lending APIs. This release also includes support for summarized information of the processed lending document package, in addition to per document results.</li>; <li>api-change:<code>transcribe</code>: [<code>botocore</code>] This release adds support for 'inputType' for post-call and real-time (streaming) Call Analytics within Amazon Transcribe.</li>; </ul>; <h1>1.26.16</h1>; <ul>; <li>api-change:<code>grafana</code>: [<code>botocore</code>] This release includes support for configuring a Grafana workspace to connect to a datasource within a VPC as well as new APIs for configuring Grafana settings.</li>; <li>api-change:<code>rbin</code>: [<code>botocore</code>] This release adds support for",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:3507,simpl,simpler,3507,https://hail.is,https://github.com/hail-is/hail/pull/12507,1,['simpl'],['simpler']
Usability,"icate is signed by the same root certificate. I think using a root cert is quite secure (a big improvement over our current situation!). However, I endeavored in this PR to additionally prevent, for example, a compromised `notebook` from masquerading as `batch`. I agree that additionally verifying that the certificate came from a single root certificate (that we, perhaps, destroy after everything is signed) would additionally prevent a malicious user from inserting their certificates into the trusted certificates list. AFAICT, python's `ssl` module has no support for this verification strategy. We could probably build an SSLContext shim that contained two SSLContexts one with a root cert and one with the trusted certs and require certification verification to pass both. Seems easy to get wrong, so I'm inclined to not take this path. ### trusted cert lists. Yeah, it felt a little silly to duplicate the cert in each secret. However, this seems like the simplest approach if I require each principal to only trust a subset of incoming/outgoing principals. If I had one secret per principal, then I have to modify build.yaml or deployment.yamls if I modify the trust sets. That seemed error prone. If I had one secret with all the certs, then when a service starts up it has to select the trusted ones and only insert those into its certificate store. This seems OK, but a little harder to inspect. Duplicating a cert for each trust list to which it belongs occupies what seems like a good spot to me from a developer ergonomics perspective:; - O(trusts) modifications necessary to update/revoke the cert; - O(1) configuration to load a trust list; - no pod-start-time configuration; - the trust list is on the container's file system, so its easy to inspect. Small point: I don't pin the incoming certs yet due to the mTLS challenges. ### create on each deploy. Only creating certs if they don't exist is an easy change. Seems fine, though leaves unresolved how to rotate the certs. I guess",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243:1664,simpl,simplest,1664,https://hail.is,https://github.com/hail-is/hail/pull/8561#issuecomment-617428243,2,['simpl'],['simplest']
Usability,"ies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YjUwZjkzNy0zZjY4LTRkZjItYjliMC0zZjRiYzUyNmIwNWIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdiNTBmOTM3LTNmNjgtNGRmMi1iOWIwLTNmNGJjNTI2YjA1YiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7b50f937-3f68-4df2-b9b0-3f4bc526b05b"",""prPublicId"":""7b50f937-3f68-4df2-b9b0-3f4bc526b05b"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14244:4188,Learn,Learn,4188,https://hail.is,https://github.com/hail-is/hail/pull/14244,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,ildren 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ExtractIntervalFilters.apply total 0.005ms self 0.005ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.086ms self 0.086ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.011ms self 0.011ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 0.123ms self 0.054ms children 0.068ms %children 55.59%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply/is.hail.expr.ir.NormalizeNames.apply total 0.061ms self 0.061ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.O,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:188662,Simpl,Simplify,188662,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,ildren 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ExtractIntervalFilters.apply total 0.006ms self 0.006ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.095ms self 0.095ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.014ms self 0.014ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 0.114ms self 0.048ms children 0.067ms %children 58.31%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply/is.hail.expr.ir.NormalizeNames.apply total 0.060ms self 0.060ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.O,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:181637,Simpl,Simplify,181637,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,ildren 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ExtractIntervalFilters.apply total 0.012ms self 0.012ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.173ms self 0.173ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.025ms self 0.025ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 0.315ms self 0.116ms children 0.199ms %children 63.18%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply/is.hail.expr.ir.NormalizeNames.apply total 0.153ms self 0.153ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.O,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:15372,Simpl,Simplify,15372,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,ildren 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ExtractIntervalFilters.apply total 0.014ms self 0.014ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.179ms self 0.179ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.028ms self 0.028ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 0.328ms self 0.115ms children 0.213ms %children 64.89%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply/is.hail.expr.ir.NormalizeNames.apply total 0.164ms self 0.164ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.O,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:8388,Simpl,Simplify,8388,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,ildren 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ExtractIntervalFilters.apply total 0.506ms self 0.506ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.500ms self 0.500ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 7.523ms self 7.523ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 4.611ms self 3.590ms children 1.020ms %children 22.13%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply/is.hail.expr.ir.NormalizeNames.apply total 0.442ms self 0.442ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.O,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:4097,Simpl,Simplify,4097,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,"in 7.2 seconds; > ...; > The 20 seconds is: clone from github.com, git-merge; > The 7.2 seconds is: download from GCS, untar; > Just ran the test in the cloud using the google cloud sdk image started by k run, 3.7 seconds; > The download is super fast, like a second; > the untar is about the same in both contexts, 1.2 seconds; > But the download drops from 4.7 to ~1.5. Chris pointed out I should skip going to disk and pipe into tar, I have not timed that yet. I was seeing fetch being more like 8 minutes to my repository. My repository is significantly larger than Alex's. I could delete some old branches to address this. ---. > for inputs/outputs, I wonder if we should have a flag that indicates it is an archive and do the archive/extract automatically (like you've done here but more generally), and stop using cp -r. I almost went down this route. It would save a couple lines of tar/untar in runImage steps. I felt the savings wasn't worth the effort of implementing it. In the buildImage case (what this PR addressed), I think it's worth it to keep images small. > for downstream steps that only need a small part of the repo, is it better to copy out different pieces (archived or no) rather than copy the whole thing and extra the parts you need?. I haven't investigated this. I agree, there exists an inflection point where the size of data overcomes GCS latency and GCS-throughput / tar-decompress is the bottleneck. There's something to be said for tar'ing everything except for `.git`, but I didn't carefully check which steps need it and which steps do not. ---. In conclusion, I'd say this PR is necessary for #7534, and #7534 is a big quality of life improvement for those of us with large repos running tests on images that are deep on the critical path (the shuffler test is behind 3 images and build hail, which also clones the repo, so for my repo I wait at least 2 minutes before I even have a chance to get feedback; with this PR and #7534 I should wait like 45 seconds?).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7626#issuecomment-560442927:2295,feedback,feedback,2295,https://hail.is,https://github.com/hail-is/hail/pull/7626#issuecomment-560442927,2,['feedback'],['feedback']
Usability,"ing.google.com/sre/books/; - Distributed Systems Observability https://www.oreilly.com/library/view/distributed-systems-observability/9781492033431/; - ""Learning to Build Distributed Systems"" http://brooker.co.za/blog/2019/04/03/learning.html; - Increment's On-Call issue https://increment.com/on-call/; # SWE; - ""Designing Data-Intensive Systems"" by Kleppman https://www.amazon.com/gp/product/1449373321/; # SEC; - ""The Confused Deputy"" http://zoo.cs.yale.edu/classes/cs422/2010/bib/hardy88confused.pdf; - ""Blueprint fo a science of cybersecurity"" http://www.cs.cornell.edu/fbs/publications/SoS.blueprint.pdf; - ""Macaroons: Cookies with Contextual Caveats for Decentralized Authorization in the Cloud"" https://ai.google/research/pubs/pub41892; - ""Native Client: A Sandbox for Portable, Untrusted x86 Native Code"" https://ai.google/research/pubs/pub34913; - What is CSRF https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF); - What is XSS https://www.owasp.org/index.php/Cross-site_Scripting_(XSS); ## Containers; - gVisor Architecture Guide https://gvisor.dev/docs/architecture_guide/; - ""cgroups"" https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt; - ""cgroups v2"" https://github.com/torvalds/linux/blob/master/Documentation/admin-guide/cgroup-v2.rst; - ""Docker Security"" https://docs.docker.com/engine/security/security/; - ""On the security of containers"" https://medium.com/@ewindisch/on-the-security-of-containers-2c60ffe25a9e; - ""User namespaces might not be enough"" https://medium.com/@ewindisch/linux-user-namespaces-might-not-be-secure-enough-a-k-a-subverting-posix-capabilities-f1c4ae19cad; - ""OS-level virtualization"" https://en.wikipedia.org/wiki/OS-level_virtualisation; - ""Sandbox (computer security)"" https://en.wikipedia.org/wiki/Sandbox_(computer_security); - ""Making Containers More Isolated: An Overview of Sandboxed Container Technologies"" https://unit42.paloaltonetworks.com/making-containers-more-isolated-an-overview-of-sandboxed-container-technologies/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6720:1091,Guid,Guide,1091,https://hail.is,https://github.com/hail-is/hail/issues/6720,2,"['Guid', 'guid']","['Guide', 'guide']"
Usability,"ing; sent through the tunneled connection to the destination server. Users who rely on; defining their proxy credentials in the URL are <em>strongly</em> encouraged to upgrade; to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy; credentials once the change has been fully deployed.</p>; <p>Users who do not use a proxy or do not supply their proxy credentials through; the user information portion of their proxy URL are not subject to this; vulnerability.</p>; <p>Full details can be read in our <a href=""https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q"">Github Security Advisory</a>; and <a href=""https://nvd.nist.gov/vuln/detail/CVE-2023-32681"">CVE-2023-32681</a>.</p>; </li>; </ul>; <h2>2.30.0 (2023-05-03)</h2>; <p><strong>Dependencies</strong></p>; <ul>; <li>; <p>⚠️ Added support for urllib3 2.0. ⚠️</p>; <p>This may contain minor breaking changes so we advise careful testing and; reviewing <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html</a>; prior to upgrading.</p>; <p>Users who wish to stay on urllib3 1.x can pin to <code>urllib3&lt;2</code>.</p>; </li>; </ul>; <h2>2.29.0 (2023-04-26)</h2>; <p><strong>Improvements</strong></p>; <ul>; <li>Requests now defers chunked requests to the urllib3 implementation to improve; standardization. (<a href=""https://redirect.github.com/psf/requests/issues/6226"">#6226</a>)</li>; <li>Requests relaxes header component requirements to support bytes/str subclasses. (<a href=""https://redirect.github.com/psf/requests/issues/6356"">#6356</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/psf/requests/commit/147c8511ddbfa5e8f71bbf5c18ede0c4ceb3bba4""><code>147c851</code></a> v2.31.0</li>; <li><a href=""https://github.com/psf/requests/commit/74ea7cf7a6a27a4eeb2ae24e162bcc942a6706d5""><code>74ea7cf</code></a> Merge pull request from GHSA-j8r2-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:4530,guid,guide,4530,https://hail.is,https://github.com/hail-is/hail/pull/13091,6,['guid'],['guide']
Usability,ingleThreadEventExecutor.java:131); 	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144); 	at java.lang.Thread.run(Thread.java:748); 	Error: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.; 	This stopped SparkContext was created at:; 	; 	org.apache.spark.SparkContext.getOrCreate(SparkContext.scala); 	sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	java.lang.reflect.Method.invoke(Method.java:498); 	sparklyr.Invoke.invoke(invoke.scala:139); 	sparklyr.StreamHandler.handleMethodCall(stream.scala:123); 	sparklyr.StreamHandler.read(stream.scala:66); 	sparklyr.BackendHandler.channelRead0(handler.scala:51); 	sparklyr.BackendHandler.channelRead0(handler.scala:4); 	io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267); 	; 	The currently active SparkContext was created at:;,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:7536,Simpl,SimpleChannelInboundHandler,7536,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['Simpl'],['SimpleChannelInboundHandler']
Usability,"internet are not free. We should track every egressing byte and assign the cost of that byte to the job which produced it. I believe there are two ways to trigger substantial egress:; 1. The main container opens a network connection and bytes are sent to the other IP from the container. ; 2. An output file whose destination is a different cloud provider. I think this is currently impossible due to lack of permissions, but we should either explicitly prohibit this or ensure our solution encompasses it. In particular, I am concerned OpenID could be used to grant permission for a GCP identity to write to S3 or ABS. . Pulling an image shouldn’t trigger substantial egress. In the first case, there are three kinds of possible egress:; 1. Egress to the Public Internet.; 2. Egress to a VM in a different Google region.; 3. Egress to a Google Service in a different Google region (e.g. uploading to a bucket in a different region). I believe (2) and (3) are charged equivalently. (1) is simply Internet egress pricing. In (3), I’m not sure who pays the egress from a VM to a bucket in a different region. I assume the VM owner. In all three cases, the destination’s location matters. For public Internet egress, we can use GeoIP to determine the region of the planet. I’m not sure if we can determine the region of (2) and (3). If we can’t, we should either prevent such traffic or we should charge the maximum egress. A final caveat is that we use Premium Networking. As a result, our traffic can use Google’s internal backbone. It’s not clear to me if this means that a packet from us-central to a public IP in Australia incurs just Internet egress or that *and* a region-to-region egress to pay for the use of GCP’s internal global backbone. The priority of various considerations:; 1. Top priority within this issue is to track and recover costs. Even if this means charging a flat fee across all possible kinds of egress. Even if that fee is substantially higher than the real cost to us.; 2. S",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13428:1058,simpl,simply,1058,https://hail.is,https://github.com/hail-is/hail/issues/13428,1,['simpl'],['simply']
Usability,"ion generated [here](https://github.com/hail-is/hail/blob/8bd9b7b2224b77372a72f02f2b13806267892a35/hail/src/main/scala/is/hail/types/encoded/EBaseStruct.scala#L107). I2B is an instruction that truncates an integer to a byte, and it is used in various places in code generation but primarily encoding missing bits in arrays and structs. . I2B loads a byte to the stack, not a boolean. TypeInfos are mostly non-structural since they rarely influence the bytecode generated. Here is an exception, and that's where the method splitter comes in. Method splitting exists in the Hail compiler because not only does the JVM have limits on how large methods can be, but also the JIT compiler handles small methods much more effectively than large methods (and so splitting a large method into two small ones can make an order of magnitude or more in performance difference). We have three forms of method splitting in the Hail Query compiler. The first is a heuristic and greedy IR-level method splitter that generates new methods every X IR nodes, simply based on node count. However, the size of code generated by each IR can vary widely (`I32` vs `LowerBoundOnOrderedCollection` for instance), and so we have two other kinds of splitting that operate on the LIR level. The first is region splitting, which is used to split large blocks of LIR. In order to insert a split, any variables on the stack are stored in local variables before the split and loaded from those locals after the split. The second is method splitting, which is used to split large single methods. A single-exit group of blocks can be split into a separate method, and we have some machinery for replacing control flow instructions (which I will not go into here, for they are not relevant now), as well as handling local variables that are used across a method split. These shared Local variables are replaced by fields on a ""spills"" class which is allocated any time a split method is called. Spilled local `store`s are rewritten as ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11328:1760,simpl,simply,1760,https://hail.is,https://github.com/hail-is/hail/pull/11328,1,['simpl'],['simply']
Usability,"ionpool.py"", line 380, in _make_request; httplib_response = conn.getresponse(); File ""/usr/lib/python3.6/http/client.py"", line 1331, in getresponse; response.begin(); File ""/usr/lib/python3.6/http/client.py"", line 297, in begin; version, status, reason = self._read_status(); File ""/usr/lib/python3.6/http/client.py"", line 258, in _read_status; line = str(self.fp.readline(_MAXLINE + 1), ""iso-8859-1""); File ""/usr/lib/python3.6/socket.py"", line 586, in readinto; return self._sock.recv_into(b); socket.timeout: timed out; ```. Seems that the simplest issue may be to increase `read_timeout` past 120 seconds, although depending on the causes of this issue, that may not eliminate the problem, and of course leaves a long delay, which may be unacceptable for the use-case. As for why read takes so long: not 100% sure yet, setting up batch and CI is still incomplete, and I have not triggered this error myself. My guess is that Kubernetes takes too long to generate the response, either due to garbage collection, or simply because the requested information takes N > 120 seconds to return. That would be a very long time for any reasonable response, so either the resource isn't ready and it waits, or there are network connectivity issues. If network issues, not sure what solutions are. If I were on AWS, I would think about using a larger instance, with a higher-bandwidth NIC.; * Possible connection: https://github.com/arangodb/arangodb/issues/7813 ; * Possible solution: Reduce work Kubernetes must do to return response. #### 2nd set of errors:; ```log; # Batch; ERROR	| 2018-12-18 21:25:00,095 	| server.py 	| run_forever:447 | run_forever: target kube_event_loop threw exception; Traceback (most recent call last):; File ""/usr/lib/python3.6/site-packages/urllib3/response.py"", line 601, in _update_chunk_length; self.chunk_left = int(line, 16); ValueError: invalid literal for int() with base 16: b''. # CI; ERROR	| 2018-12-18 21:25:22,041 	| app.py 	| log_exception:1761 | Exception on /re",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4984#issuecomment-450444389:1569,simpl,simply,1569,https://hail.is,https://github.com/hail-is/hail/issues/4984#issuecomment-450444389,2,['simpl'],['simply']
Usability,"irect.github.com/urllib3/urllib3/issues/3051"">#3051</a></li>; </ul>; <h2>2.0.2</h2>; <ul>; <li>Fixed <code>HTTPResponse.stream()</code> to continue yielding bytes if buffered decompressed data was still available to be read even if the underlying socket is closed. This prevents a compressed response from being truncated. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3009"">urllib3/urllib3#3009</a>)</li>; </ul>; <h2>2.0.1</h2>; <ul>; <li>Fixed a socket leak when fingerprint or hostname verifications fail. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2991"">#2991</a>)</li>; <li>Fixed an error when <code>HTTPResponse.read(0)</code> was the first <code>read</code> call or when the internal response body buffer was otherwise empty. (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2998"">#2998</a>)</li>; </ul>; <h2>2.0.0</h2>; <p>Read the <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">v2.0 migration guide</a> for help upgrading to the latest version of urllib3.</p>; <h1>Removed</h1>; <ul>; <li>Removed support for Python 2.7, 3.5, and 3.6 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/883"">#883</a>, <a href=""https://redirect.github.com/urllib3/urllib3/issues/2336"">#2336</a>).</li>; <li>Removed fallback on certificate <code>commonName</code> in <code>match_hostname()</code> function. This behavior was deprecated in May 2000 in RFC 2818. Instead only <code>subjectAltName</code> is used to verify the hostname by default. To enable verifying the hostname against <code>commonName</code> use <code>SSLContext.hostname_checks_common_name = True</code> (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2113"">#2113</a>).</li>; <li>Removed support for Python with an <code>ssl</code> module compiled with LibreSSL, CiscoSSL, wolfSSL, and all other OpenSSL alternatives. Python is moving to require OpenSSL with PEP 644 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/2168"">#2168</a>).<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:3347,guid,guide,3347,https://hail.is,https://github.com/hail-is/hail/pull/13768,3,['guid'],['guide']
Usability,"irements.txt --output-file=/tmp/tmp.aWUFJ1BMnP; ../check_pip_requirements.sh: line 13: pip-compile: command not found; ```. While I do have pip-compile installed. ```sh ; pip-compile --help; Usage: pip-compile [OPTIONS] [SRC_FILES]... Compiles requirements.txt from requirements.in, pyproject.toml, setup.cfg,; or setup.py specs. Options:; ```. Note that `make clean` did not solve the issue. see logs attached. ### Version. 0.2.120. ### Relevant log output. ```shell; BUILD SUCCESSFUL in 2m 46s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; /usr/lib64/python3.8/distutils/dist.py:274: UserWarning: Unknown distribution option: 'long_description_content_type'; warnings.warn(msg); installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.120.dist-info/WHEEL; creating 'dist/hail-0.2.120-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/__init__.py'; adding 'hail/backend/backend.py'; adding 'hail/backend/hail-all-spark.jar'; adding 'hail/backend/local_backend.py'; adding 'hail/backend/py4j_backend.py'; adding 'hail/backend/service_backend.py'; adding 'hail/backend/spark_backend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13445:1391,Clear,Clear,1391,https://hail.is,https://github.com/hail-is/hail/issues/13445,1,['Clear'],['Clear']
Usability,is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10699,Simpl,Simplify,10699,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"issues/3217"">#3217</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Black now uses the presence of debug f-strings to detect target version (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3215"">#3215</a>)</li>; <li>Fix misdetection of project root and verbose logging of sources in cases involving <code>--stdin-filename</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3216"">#3216</a>)</li>; <li>Immediate <code>.gitignore</code> files in source directories given on the command line are now also respected, previously only <code>.gitignore</code> files in the project root and automatically discovered directories were respected (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3237"">#3237</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Recommend using BlackConnect in IntelliJ IDEs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3150"">#3150</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Vim plugin: prefix messages with <code>Black: </code> so it's clear they come from Black (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3194"">#3194</a>)</li>; <li>Docker: changed to a /opt/venv installation + added to PATH to be available to non-root users (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3202"">#3202</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Change from deprecated <code>asyncio.get_event_loop()</code> to create our event loop which removes DeprecationWarning (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3164"">#3164</a>)</li>; <li>Remove logging from internal <code>blib2to3</code> library since it regularly emits error logs about failed caching that can and should be ignored (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3193"">#3193</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Type comments are now included in the AST equivalence check consistently so accidental deletion raises an error. Though type comments can't",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:3843,clear,clear,3843,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['clear'],['clear']
Usability,"istune/commit/979d6d3bfc7d6159f38deb8e751611e4205033f6""><code>979d6d3</code></a> Fix * parsing, <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/312"">#312</a></li>; <li><a href=""https://github.com/lepture/mistune/commit/f857f048ebb2f6f2bb7ab97dcb7a159172a20649""><code>f857f04</code></a> Trigger GitHub dependency graph</li>; <li><a href=""https://github.com/lepture/mistune/commit/3f422f1e84edae0f39756c45be453ecde534b755""><code>3f422f1</code></a> Version bump 2.0.3</li>; <li><a href=""https://github.com/lepture/mistune/commit/a6d43215132fe4f3d93f8d7e90ba83b16a0838b2""><code>a6d4321</code></a> Fix asteris emphasis regex CVE-2022-34749</li>; <li><a href=""https://github.com/lepture/mistune/commit/5638e460459cb59ceb20e4ce4716c802d4d73c53""><code>5638e46</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/307"">#307</a> from jieter/patch-1</li>; <li><a href=""https://github.com/lepture/mistune/commit/0eba47196a81453bafe1f2492748a87475063dff""><code>0eba471</code></a> Fix typo in guide.rst</li>; <li><a href=""https://github.com/lepture/mistune/commit/61e9337884e20f9f8fdc0b7788d319afdd259729""><code>61e9337</code></a> Fix table plugin</li>; <li><a href=""https://github.com/lepture/mistune/commit/76dec68c4514c2612ef9263b49c6ec7f4d77bd14""><code>76dec68</code></a> Add documentation for renderer heading when TOC enabled</li>; <li>Additional commits viewable in <a href=""https://github.com/lepture/mistune/compare/v0.8.4...v2.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mistune&package-manager=pip&previous-version=0.8.4&new-version=2.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12066:3460,guid,guide,3460,https://hail.is,https://github.com/hail-is/hail/pull/12066,2,['guid'],['guide']
Usability,"it('\\.')[0],; length=ht.interval.end.position - ht.interval.start.position + 1); coding_regions = ht.filter(ht.feature == 'CDS').select('gene_id', 'transcript_id', 'transcript_type', 'length', 'level'); transcripts = coding_regions.group_by('transcript_id', 'transcript_type', 'gene_id',; transcript_level=coding_regions.level).aggregate(; cds_length=hl.agg.sum(coding_regions.length),; num_coding_exons=hl.agg.count(); ).key_by('transcript_id'); ```; Afterwards:; ```; transcripts.count() # fails with error below; transcripts.persist().count() # succeeds; ```; on current master (d33e2d1c19b2); ```; Py4JJavaError: An error occurred while calling z:is.hail.expr.ir.Interpret.interpretPyIR.; : java.util.NoSuchElementException: key not found: interval; 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.MapLike$class.apply(MapLike.scala:141); 	at scala.collection.AbstractMap.apply(Map.scala:59); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.rvd.RVDType.<init>(RVDType.scala:23); 	at is.hail.expr.types.TableType.<init>(TableType.scala:16); 	at is.hail.expr.types.TableType.copy(TableType.scala:15); 	at is.hail.expr.ir.TableMapRows.<init>(TableIR.scala:592); 	at is.hail.expr.ir.Simplify$$anonfun$tableRules$1.applyOrElse(Simplify.scala:394); 	at is.hail.expr.ir.Simplify$$anonfun$tableRules$1.applyOrElse(Simplify.scala:251); 	at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); 	at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4799:1954,Simpl,Simplify,1954,https://hail.is,https://github.com/hail-is/hail/issues/4799,4,['Simpl'],['Simplify']
Usability,"ithub&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""5da7ca75-f161-4f7a-ae7f-c92bb747eca9"",""prPublicId"":""5da7ca75-f161-4f7a-ae7f-c92bb747eca9"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""},{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,531,null,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14074:6561,Learn,Learn,6561,https://hail.is,https://github.com/hail-is/hail/pull/14074,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ittle unusual in this flow. I still think that it is helpful to set people up with an AR and keep them from footguns, but maybe that can go in a separate command that the initial init command points to once you're done? Something along the lines of ""if you get to the point where you need to upload custom container images, you can use hailctl to set up a registry""?. Another thing that gives me a little pause is the wording around google projects. I get that you need one to create a bucket, but I think we should just make sure to steer clear of the implication that you are ""selecting a GCP project to use for Hail Batch"", because that implies some link or ownership that isn't there. But I think there's a quick fix here: for a given resource that we *are* creating for hail use, like the temp bucket, ask for the name first and then ask which project it should be created in, using the projects listed in gcloud as choices with the option to write in your own. ### Regarding number of checks; I think it'd be good to avoid warnings when possible. From looking at this I see a pattern of; 1. Ask a leading question; 2. Emit a warning if the user selects the alternative option instead of the suggested option. I think I would prefer instead to ask a leading question and in the prompt explain why the alternative option might be undesirable. Then when they make a decision just move on. On a broader note, I think we should focus on having good documentation and linking to it over having perfectly thorough ; explanations in the CLI. At some point in an interactive setup if it gets longwinded I start spamming enter, but if it was quick and at the end it said something to the effect of: ""Your current configuration could result in excess cloud cost. See the documentation <here> about common pitfalls and how to avoid them"", I might decide to read through that FAQ with a more discerning eye. This is just my opinion though, I would be curious to see if other folks disagree regarding the UX.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1648633012:3243,UX,UX,3243,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1648633012,2,['UX'],['UX']
Usability,"ix a number of minor annotation issues in <code>protocols.Validator</code></li>; </ul>; <h1>v4.13.0</h1>; <ul>; <li>Add support for creating validator classes whose metaschema uses a different; dialect than its schemas. In other words, they may use draft2020-12 to define; which schemas are valid, but the schemas themselves use draft7 (or a custom; dialect, etc.) to define which <em>instances</em> are valid. Doing this is likely; not something most users, even metaschema authors, may need, but occasionally; will be useful for advanced use cases.</li>; </ul>; <h1>v4.12.1</h1>; <ul>; <li>Fix some stray comments in the README.</li>; </ul>; <h1>v4.12.0</h1>; <ul>; <li>Warn at runtime when subclassing validator classes. Doing so was not; intended to be public API, though it seems some downstream libraries; do so. A future version will make this an error, as it is brittle and; better served by composing validator objects instead. Feel free to reach; out if there are any cases where changing existing code seems difficult; and I can try to provide guidance.</li>; </ul>; <h1>v4.11.0</h1>; <ul>; <li>Make the rendered README in PyPI simpler and fancier. Thanks Hynek (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/983"">#983</a>)!</li>; </ul>; <h1>v4.10.3</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/420fc6bd9a3ecc4cd637ece97cb4b482b4d0d37e""><code>420fc6b</code></a> Minor verbiage tweak for protocols.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/8ce8250897e1b2e9b1fea6825965dbc876ec1f4d""><code>8ce8250</code></a> Don't show type checker functions in TypeChecker reprs.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/6533d32cad0a65847979297c66f96f1dfbf1d68c""><code>6533d32</code></a> Tweak the colorscheme for code blocks in docs.</li>; <li><a hre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12163:5965,guid,guidance,5965,https://hail.is,https://github.com/hail-is/hail/pull/12163,1,['guid'],['guidance']
Usability,"k.readthedocs.io/en/latest/the_black_code_style/index.html#stability-policy"">new stability policy</a>.</p>; <h3>Highlights</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2740"">#2740</a>)</li>; <li>Introduce the <code>--preview</code> flag (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2752"">#2752</a>)</li>; </ul>; <h3>Style</h3>; <ul>; <li>Deprecate <code>--experimental-string-processing</code> and move the functionality under <code>--preview</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2789"">#2789</a>)</li>; <li>For stubs, one blank line between class attributes and methods is now kept if there's at least one pre-existing blank line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2736"">#2736</a>)</li>; <li>Black now normalizes string prefix order (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2297"">#2297</a>)</li>; <li>Remove spaces around power operators if both operands are simple (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2726"">#2726</a>)</li>; <li>Work around bug that causes unstable formatting in some cases in the presence of the magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2807"">#2807</a>)</li>; <li>Use parentheses for attribute access on decimal float and int literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Don't add whitespace for attribute access on hexadecimal, binary, octal, and complex literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Treat blank lines in stubs the same inside top-level if statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2820"">#2820</a>)</li>; <li>Fix unstable formatting with semicolons and arithmetic expressions (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2817"">#2817</a>)</li>; <l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:1422,simpl,simple,1422,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['simpl'],['simple']
Usability,"l of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZTZiMDk2ZC0xYzc5LTQ2ZjctYjY5Ni0yNjFlM2QzYzU2ZmMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdlNmIwOTZkLTFjNzktNDZmNy1iNjk2LTI2MWUzZDNjNTZmYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7e6b096d-1c79-46f7-b696-261e3d3c56fc"",""prPublicId"":""7e6b096d-1c79-46f7-b696-261e3d3c56fc"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""b7c31419-ec34-40f1-8bc6-ad8303fb329b"",""projectUrl"":""https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14036:3595,Learn,Learn,3595,https://hail.is,https://github.com/hail-is/hail/pull/14036,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"l of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiOGQwNmE2Yi00MTg0LTRhMzAtOGMxYi0wYzNhZDVkZDk2OTQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI4ZDA2YTZiLTQxODQtNGEzMC04YzFiLTBjM2FkNWRkOTY5NCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b8d06a6b-4184-4a30-8c1b-0c3ad5dd9694"",""prPublicId"":""b8d06a6b-4184-4a30-8c1b-0c3ad5dd9694"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""}],""packageManager"":""pip"",""projectPublicId"":""e7c92c7b-5282-49ea-940f-7a5797e2a45a"",""projectUrl"":""https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[663,663],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14045:3597,Learn,Learn,3597,https://hail.is,https://github.com/hail-is/hail/pull/14045,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"l, React days at worst. Also, by not buying into a full framework, we achieve modularity: If we end up finding React too slow, even with [planned 2019 improvements](https://reactjs.org/blog/2018/11/27/react-16-roadmap.html), there are plenty of others view layers we can migrate to, without gutting our entire app. Next makes this somewhat trickier, but since it's mostly a light wrapper around Webpack, there is essentially no Next-specific code (just a bit in pages/_app.js and pages/_document.js). Migrating from Next won't be an issue, we would just lose some of the tooling benefits. 8. Typescript: static typing, syntax more familiar to OO-language devs (interfaces, types, classes). 9. Really amazing debug, tooling. React debug tools natively included in Chrome for instance. First class support for JSX (React-wrapped HTML) in popular IDE's, most obviously Visual Studio Code. ## Tech TL;DR; Mainly React. React should take about a day to learn well enough to make contributions. Guide: https://reactjs.org/docs/introducing-jsx.html. ```jsx; # Renders Hello World; # Biggest annoyance (may go away in 2019) is that ""class"" is not a valid tag (reserved by React); export default function SomePage() {; const name = 'Alex'. # Renders ""Hello Alex""; return (; <div className='some-class'> Hello {name} </div>; ); }; ```. ## Challenges; 1. Auth ; Authentication is tricky, but not for any reason specific to React, Next, Node. Server-side rendered apps tie the web app to the resource server; as such it's easier to hide sensitive information. . Mobile and desktop apps have dealt with this for 2 decades. We should build a robust infrastructure, and not one that requires server-rendered web pages for security. Currently it seems Auth0 may not be the best choice: it does not interface for us with third-party API's; requires us to either insecurely store 3rd party access tokens (with at least 1 extra round trip), or altogether proxy all third-party requests through our own resource server..",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:5648,Guid,Guide,5648,https://hail.is,https://github.com/hail-is/hail/pull/4931,1,['Guid'],['Guide']
Usability,la:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$v,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:9380,Simpl,Simplify,9380,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,la:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10348,Simpl,Simplify,10348,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,la:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hai,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10578,Simpl,Simplify,10578,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,la:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:9465,Simpl,Simplify,9465,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,la:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10433,Simpl,Simplify,10433,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,la:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8497,Simpl,Simplify,8497,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,la:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$v,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8412,Simpl,Simplify,8412,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,la:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8587,Simpl,Simplify,8587,https://hail.is,https://github.com/hail-is/hail/issues/8338,2,['Simpl'],['Simplify']
Usability,la:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10523,Simpl,Simplify,10523,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"lar rules apply to column keys and other operations where sensible. When promoting a BlockMatrix to a KeyedBlockMatrix, the keys are set to None. A BlockMatrix can be promoted to a KeyedBlockMatrix even if it's dimensions exceed Int.MaxValue; the simple rule is that you can't set keys on a dimension that is too large. This is convenient if you have a matrix where one dimension is huge but you still want keys on the other dimension. Checking keys helps ensure correctness, and I think the ability to set/drop keys on keyed matrices should be useful for linear algebra where a matrix operand comes un-keyed or you don't care about the keys on that operand. This key persistence is also natural when thinking about operations that add (unkeyed) scalars or vectors to keyed matrices (We'd later add optionally-keyed vectors as well, where keys are checked in vector addition, matrix/vector mult, vectorAddToEveryRow, etc). Keys are stored and checked on master, so for large dimensions users may want to rekey with simpler keys, via a map on the python side or with just indices. For simplicity, and since there's basically no additional overhead using an unkeyed KeyedBlockMatrix versus its underlying BlockMatrix, I think we should consider only having (optionally) keyed matrices exposed on the Python side (so a Python BlockMatrix is a Scala KeyedBlockMatrix, and you can do linear algebra numpy-style by just having no keys set). I plan to add writeKeyedBlockMatrix to MatrixTable in next step, with parameters to on whether to retain the keys (e.g., key_rows = true). On the Python side, this could then replace write_block_matrix rather than being in addition to it. Later, LocalMatrix and RowMatrix would follow the same pattern of optionally keyed versions in Scala, with a common Matrix and KeyedMatrix abstraction. And in Python users would just have Matrix backed by KeyedMatrix on the Scala side. PS. In the filters, I switched to names keepRows and keepCols in KeyedBlockMatrix instead o",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2718:1366,simpl,simpler,1366,https://hail.is,https://github.com/hail-is/hail/pull/2718,1,['simpl'],['simpler']
Usability,"latest/dev/iotroborunner-welcome.html</a></li>; <li>api-change:<code>quicksight</code>: [<code>botocore</code>] This release adds the following: 1) Asset management for centralized assets governance 2) QuickSight Q now supports public embedding 3) New Termination protection flag to mitigate accidental deletes 4) Athena data sources now accept a custom IAM role 5) QuickSight supports connectivity to Databricks</li>; <li>api-change:<code>sagemaker</code>: [<code>botocore</code>] Added DisableProfiler flag as a new field in ProfilerConfig</li>; <li>api-change:<code>servicecatalog</code>: [<code>botocore</code>] This release 1. adds support for Principal Name Sharing with Service Catalog portfolio sharing. 2. Introduces repo sourced products which are created and managed with existing SC APIs. These products are synced to external repos and auto create new product versions based on changes in the repo.</li>; <li>api-change:<code>ssm-sap</code>: [<code>botocore</code>] AWS Systems Manager for SAP provides simplified operations and management of SAP applications such as SAP HANA. With this release, SAP customers and partners can automate and simplify their SAP system administration tasks such as backup/restore of SAP HANA.</li>; <li>api-change:<code>stepfunctions</code>: [<code>botocore</code>] Update stepfunctions client to latest version</li>; <li>api-change:<code>transfer</code>: [<code>botocore</code>] Adds a NONE encryption algorithm type to AS2 connectors, providing support for skipping encryption of the AS2 message body when a HTTPS URL is also specified.</li>; </ul>; <h1>1.26.12</h1>; <ul>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Adds a new value (WEB_COMPUTE) to the Platform enum that allows customers to create Amplify Apps with Server-Side Rendering support.</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow simplifies the preparation and cataloging of SaaS data into the AWS Glue Data Catalog where your data can be dis",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:4596,simpl,simplified,4596,https://hail.is,https://github.com/hail-is/hail/pull/12498,2,['simpl'],['simplified']
Usability,"ld be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5Nzc0NDQwMi1iNzEyLTQ5NjMtYWQ0Zi01YjFhZWZmOTcwZDciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijk3NzQ0NDAyLWI3MTItNDk2My1hZDRmLTViMWFlZmY5NzBkNyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""97744402-b712-4963-ad4f-5b1aeff970d7"",""prPublicId"":""97744402-b712-4963-ad4f-5b1aeff970d7"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.2"",""to"":""41.0.3""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471,551,471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13365:4022,Learn,Learn,4022,https://hail.is,https://github.com/hail-is/hail/pull/13365,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ld implement convenience methods for building while/for loops if we decide it's worth it. > Giving each loop a name seems natural. Apart from the wrapping issue (the greatest existential threat our generation faces) I don't see any problem calling an outer loop from an inner loop. Also agree. This will require either adding another context of loops/continuations in the environment (valid places to jump to, and their argument types), or keeping them in the normal value context by adding a new continuation type. > Is Patrick's proposal for extra types written up anywhere?. My proposal has two main differences. In; ```; hl.loop(; lambda i, x:; hl.cond(i < 10, hl.recur(i + 1, x + i), x),; 0, 0); ```; the point that jumps back to the top of the loop is explicit, but the point that jumps out of the loop is not. I suggested making this something like; ```; hl.loop(; lambda i, x:; hl.cond(i < 10, hl.recur(i + 1, x + i), hl.break(x)),; 0, 0); ```; or, if we're giving names to loops, it might be simpler to pass the break and recur functions to the lambda:; ```; hl.loop(; lambda sum, ret, i, x:; hl.cond(i < 10, sum(i + 1, x + i), ret(x)),; 0, 0); ```. The second difference is in the typing. In this PR, the `hl.recur` expression is given the type of the entire loop. I would add a single new type `Bottom`, and give all expressions which jump (both the recur and the break expressions) the type `Bottom`. `Bottom` is the empty type, so there can be no closed expressions of type `Bottom`. In the type checker, `Bottom` is only allowed to appear in tail positions, and for `If`, we keep the rule that both branches must have the same type, so either both branches are `Bottom` or neither are. This keeps the semantics simple: an if statement either makes a value or it jumps away, there's no confusing mix. One nice property of this setup is that if an expression has a non-bottom type, then it is guaranteed not to jump away from itself (it may jump internally), so it is safe to method-wrap.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7614#issuecomment-559072407:1265,simpl,simpler,1265,https://hail.is,https://github.com/hail-is/hail/pull/7614#issuecomment-559072407,2,['simpl'],['simpler']
Usability,"leOnce$class.toArray(TraversableOnce.scala:285); at scala.collection.AbstractTraversable.toArray(Traversable.scala:104); at is.hail.utils.richUtils.RichIterable.toFastIndexedSeq(RichIterable.scala:83); at is.hail.table.Table.keyBy(Table.scala:419); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748); ```; Pipeline's a lot of steps but fairly simple:; ```; keys = ('transcript', 'gene', 'canonical'); po_ht = po_ht.repartition(n_partitions).persist(). # Getting classic LoF annotations (no LOFTEE); classic_lof_annotations = hl.literal({'stop_gained', 'splice_donor_variant', 'splice_acceptor_variant'}); lof_ht_classic = po_ht.filter(classic_lof_annotations.contains(po_ht.annotation) &; ((po_ht.modifier == 'HC') | (po_ht.modifier == 'LC'))); lof_ht_classic = collapse_lof_ht(lof_ht_classic, keys); lof_ht_classic = lof_ht_classic.rename({x: f'{x}_classic' for x in list(lof_ht_classic.row_value)}). # Getting classic LoF annotations (with LOFTEE); lof_ht_classic_hc = po_ht.filter(classic_lof_annotations.contains(po_ht.annotation) & (po_ht.modifier == 'HC')); lof_ht_classic_hc = collapse_lof_ht(lof_ht_classic_hc, keys); lof_ht_classic_hc = lof_ht_classic_hc.rename({x: f'{x}_classic_hc' for x in list(lof_ht_classic_hc.row_value)}). # Getting all LoF annotations (LOFTEE HC + new splice variants); lof_ht = po_ht.filter(po_ht.modifier == 'HC'); po",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4314:1326,simpl,simple,1326,https://hail.is,https://github.com/hail-is/hail/issues/4314,1,['simpl'],['simple']
Usability,leOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.fold(TraversableOnce.scala:212); at scala.collection.AbstractIterator.fold(Iterator.scala:1334); at is.hail.expr.ir.FreeVariables$.is$hail$expr$ir$FreeVariables$$compute$1(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$.apply(FreeVariables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChi,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:7338,Simpl,Simplify,7338,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyMatrix']"
Usability,lifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.is$hail$expr$ir$Optimize$$runOpt$1(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply$mcV$sp(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.apply(Optimize.scala:20); at is.hail.expr.ir.lowering.LoweringPipeline.apply(L,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:11680,Simpl,Simplify,11680,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"ll available jobs; * By querying Batch api, or Kubernetes directly; 4d: Receive current status of 1 job; 4e: Authentication; 4f: Polish (longest step): make interacting with batch achievable within perceived 16ms.; * goal: subscribe to events in web socket; * may want to save user job state in a Hail-controlled database (possible to use Firebase or Mongo, may prefer relational db, maybe Postgres or MySQL).; 4other: Figure out state question (sufficient to use Kubernetes); 5. Basic notebook interface.; 6. Connect websocket logic (non-GraphQL); 7. Authenticate web socket via Oauth2; 8. Incorporate GraphQL subscriptions (first: GitHub API); 9. Write tests; 10. Mock GraphQL endpoints; 11. Integrate web and api server bits into CI (maybe should be prioritized earlier...I prefer to get draft of major functions done first; am new to writing tests for React/Node). ## Near-term goals (<= 6 mo); 1. Upload, download; 2. Launch clusters, pay for them; 3. ?. ## Longer-term goals; 1. Much simpler interface to Hail. I would like steps that can be performed without programming to be done so. I would prefer fasta->variant filtering to be done as in Bystro (at least from the interface standpoint), i.e without opening up a notebook. Common analyses pipelines should also be possible without any interaction with a python notebook: GWAS, rare-variant (SKAT) analyses have, it seems, relatively few permutations. Those should be behind UI primitives. At each stage of a ; 2. Social network bits: users should be able to share job state with other users (requested by Bystro users on 22q consortium project) at the least.; 3. Record job state using something like Merkle tree. Checkout state. Aka ""blockchain""; 4. Cooperative analysis: provide system for people to validate analyses; ; Basic idea: . 1) People donate computational resources for ad-hoc heterogenous clusters. ; 2) People donate intellectual capital. Re-run analyses without the full available code. See if they can replicate (not p-valu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:8088,simpl,simpler,8088,https://hail.is,https://github.com/hail-is/hail/pull/4931,1,['simpl'],['simpler']
Usability,"llel Plot example with output_backend=&quot;webgl&quot; not working</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11713"">#11713</a> [component: docs] Documentation builds are failing in CI</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11644"">#11644</a> [component: bokehjs] Actually fix clipping in SVG <code>&lt;text&gt;</code> nodes</li>; </ul>; </li>; <li>; <p>tasks:</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11617"">#11617</a> [component: docs] Update Team link in footer</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11658"">#11658</a> [component: build] Support &quot;pip install&quot; from sdist</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11618"">#11618</a> [component: tests] Reduce Tornado imports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11628"">#11628</a> [component: docs] Correct path in dev guide server instructions</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11652"">#11652</a> [component: build] Update bokehjs' dependencies</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11668"">#11668</a> [component: docs] Add information about mathjax bundle</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11681"">#11681</a> [NO SQUASH] Batch of 3.0 -&gt; 2.4 backports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11712"">#11712</a> [component: tests] Upgrade baselines to Chrome 94</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11722"">#11722</a> [component: tests] Update visual baselines on MacOS</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11724"">#11724</a> [NO SQUASH] More 3.0 -&gt; 2.4 backports</li>; </ul>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11540:5696,guid,guide,5696,https://hail.is,https://github.com/hail-is/hail/pull/11540,1,['guid'],['guide']
Usability,"long it takes `gcloud storage ls`. There are two improvements:. 1. Use `bounded_gather2`. The use of a semaphore in `bounded_gather2`, which is missing from `bounded_gather`, allows it to be used recursively. In particular, suppose we had a semaphore of; 50. The outer `bounded_gather2` might need 20 slots to run its 20 paths in parallel. That leaves 30 slots of parallelism left over for its children. By passing the semaphore down, we let our children optimistically use some of that excess parallelism. 2. If we happen to have the `StatResult` for a particular object, we should never again look it up. In particular, getting the `StatResult` for every file in a directory can be done in O(1) requests. Getting the `StatResult` for each of those files individually (using their full paths) is necessarily O(N). If there was at least one glob and also there are no `suffix_components`, then we can use the `StatResult`s that we learned when checking the glog pattern. The latter point is perhaps a bit more clear with examples:. 1. `gs://foo/bar/baz`. Since there are no globs, we can make exactly one API request to list `gs://foo/bar/baz`. 2. `gs://foo/b*r/baz`. In this case, we must make one API request to list `gs://foo/`. This gives us a list of paths under that prefix. We check each path for conformance to the glob pattern `gs://foo/b*r`. For any path that matches, we must then list `<the matching path>/baz` which may itself be a directory containing files. Overall we make O(1) API requests to do the glob and then O(K) API requests to get the final `StatResult`s, where K is the number of paths matching the glob pattern. 3. `gs://foo/bar/b*z`. In this case, we must make one API request to list `gs://foo/bar/`. In `main`, we then throw away the `StatResult`s we got from that API request! Now we have to make O(K) requests to recover those `StatResult`s for all K paths that match the glob pattern. This PR just caches the `StatResult`s of the most recent globbing. If there is no s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13253:1138,clear,clear,1138,https://hail.is,https://github.com/hail-is/hail/pull/13253,1,['clear'],['clear']
Usability,"looks like the differences between `--unsafe-fixes` and my manual edits based on the feedback the linter gave were:; * `assert <boolean value> == True` becomes `assert <boolean value> is True`, not `assert <boolean value>`; * `if <value> == foo or <value> == bar` becomes `if <value> in (foo, bar)`, not `if <value> in {foo, bar}`; * `<unused variable> = foo` becomes `foo` instead of being deleted outright. those seem fine, though i think the manual version of the latter two is better in the cases where i had added it, as i only used sets for hashable types and deleted things that didn't have side effects, afaik",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355:85,feedback,feedback,85,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355,2,['feedback'],['feedback']
Usability,ly/is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.566ms self 0.566ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.445ms self 0.445ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 2.252ms self 0.765ms children 1.487ms %children 66.02%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowerin,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:121639,Simpl,Simplify,121639,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,ly/is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.609ms self 0.609ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.195ms self 0.195ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 1.409ms self 0.648ms children 0.762ms %children 54.04%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowerin,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:137357,Simpl,Simplify,137357,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,ly/is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.NormalizeNames.apply total 0.655ms self 0.655ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.Simplify.apply total 0.184ms self 0.184ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.EvalRelationalLetsPass/is.hail.expr.ir.lowering.EvalRelationalLets.apply/is.hail.expr.ir.lowering.EvalRelationalLets.apply execute/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.Compile.apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowering.OptimizePass/is.hail.expr.ir.Optimize.apply/is.hail.expr.ir.ForwardLets.apply total 2.228ms self 1.353ms children 0.875ms %children 39.29%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply/is.hail.expr.ir.lowerin,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:153144,Simpl,Simplify,153144,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['Simpl'],['Simplify']
Usability,"m>Sourced from <a href=""https://github.com/python/importlib_resources/blob/main/CHANGES.rst"">importlib-resources's changelog</a>.</em></p>; <blockquote>; <h1>v5.9.0</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_resources/issues/228"">#228</a>: <code>as_file</code> now also supports a <code>Traversable</code>; representing a directory and (when needed) renders the; full tree to a temporary directory.</li>; </ul>; <h1>v5.8.1</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_resources/issues/253"">#253</a>: In <code>MultiplexedPath</code>, restore expectation that; a compound path with a non-existent directory does not; raise an exception.</li>; </ul>; <h1>v5.8.0</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_resources/issues/250"">#250</a>: Now <code>Traversable.joinpath</code> provides a concrete; implementation, replacing the implementation in <code>.simple</code>; and converging with the behavior in <code>MultiplexedPath</code>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python/importlib_resources/commit/31102947fd9babef636d3b82c2a5d58883f9c1f5""><code>3110294</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python/importlib_resources/issues/255"">#255</a> from python/feature/228-directory-of-resources</li>; <li><a href=""https://github.com/python/importlib_resources/commit/bac6e8e3e6c681d923e1ec78b6f670cee0883ea3""><code>bac6e8e</code></a> Extract function for _is_present_dir.</li>; <li><a href=""https://github.com/python/importlib_resources/commit/9afeb056dfabf8c8cc497cddbabe9ebcd70ff82d""><code>9afeb05</code></a> Merge branch 'main' into feature/228-directory-of-resources</li>; <li><a href=""https://github.com/python/importlib_resources/commit/b8da8446d72b6dbaa34a8fa0f6d0dae238bf00f6""><code>b8da844</code></a> Merge pull request <a href=""https://github-redirect.dependabot.c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12141:1103,simpl,simple,1103,https://hail.is,https://github.com/hail-is/hail/pull/12141,1,['simpl'],['simple']
Usability,more improvements (though less simple) to come.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6980#issuecomment-527418968:31,simpl,simple,31,https://hail.is,https://github.com/hail-is/hail/pull/6980#issuecomment-527418968,2,['simpl'],['simple']
Usability,"more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YTljMjVmNy0wMTBmLTQxNmItYjc0OS1jNzFkY2I4YjY5YjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdhOWMyNWY3LTAxMGYtNDE2Yi1iNzQ5LWM3MWRjYjhiNjliOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7a9c25f7-010f-416b-b749-c71dcb8b69b8"",""prPublicId"":""7a9c25f7-010f-416b-b749-c71dcb8b69b8"",""dependencies"":[{""name"":""orjson"",""from"":""3.9.7"",""to"":""3.9.15""}],""packageManager"":""pip"",""projectPublicId"":""e7c92c7b-5282-49ea-940f-7a5797e2a45a"",""projectUrl"":""https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-ORJSON-6276643""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[661],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Relative Path Traversal](https://learn.snyk.io/lesson/directory-traversal/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14361:3127,Learn,Learn,3127,https://hail.is,https://github.com/hail-is/hail/pull/14361,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,mplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.exp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8709,Simpl,Simplify,8709,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,mplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$si,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:9677,Simpl,Simplify,9677,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,mplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.colle,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8815,Simpl,Simplify,8815,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,mplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$sim,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:9783,Simpl,Simplify,9783,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,mplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.is$hail$expr$ir$Optimize$$runOpt$1(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply$mcV$sp(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.apply(Optimize.scala:20); at is.hail.expr.ir.lowering.LoweringPip,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:11664,Simpl,Simplify,11664,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"my strategy here was just to undo everything added in [this commit](https://github.com/hail-is/hail/commit/12e0f497db0f3e5453f870495e48e44191b315f4), except the version upgrades, so i'm not sure if there are some changes i'm making here that are unnecessary or produce weird results as far as what all ends up in the jar or anything. from running `jar -tf` on the jar produced by the current `main` and the one produced by the commit prior to the one i'm partially reverting, it looked like the updates to the config only added things to the jar, rather than removing any, so hopefully that should be fine",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13759#issuecomment-1743654792:29,undo,undo,29,https://hail.is,https://github.com/hail-is/hail/pull/13759#issuecomment-1743654792,2,['undo'],['undo']
Usability,"nats are now not types and align more with the ReferenceGenome structure, making for better function signatures. There's a `NatBase` with `Nat` and `NatVariable` as extending classes. For `NatVariable`, instances mutate a single class variable `_nat`. Type variables behave similarly using using a map of name -> box, but I didn't really see the point of ever needing more than one `nat` variable in the same context. Either way it seems a little weird so glad to take feedback.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5737#issuecomment-479528708:469,feedback,feedback,469,https://hail.is,https://github.com/hail-is/hail/pull/5737#issuecomment-479528708,2,['feedback'],['feedback']
Usability,"ncy, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMjJhZDMzNS1kYzBkLTQxZWYtYmRjYi03ZTFkODQwNWJhYTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAyMmFkMzM1LWRjMGQtNDFlZi1iZGNiLTdlMWQ4NDA1YmFhNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""022ad335-dc0d-41ef-bdcb-7e1d8405baa6"",""prPublicId"":""022ad335-dc0d-41ef-bdcb-7e1d8405baa6"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.1"",""to"":""41.0.2""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5777683""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[763],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13247:3192,Learn,Learn,3192,https://hail.is,https://github.com/hail-is/hail/pull/13247,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"nd a `dict<str, int>`, the values are stored in the array and the names are stored in a separate dictionary mapping names to their indices; 2. a `dict<str, T>`, the name-value pairs are stored as dictionary key-value pairs; 3. a `struct{name1: T, name2: T, ... nameN: T}`, the name-value pairs are stored as field name, field string pairs. The third option is the most space efficient: the type stores the field names and there is no bookkeeping overhead per-set-of-named-values. The first two options repeat the field names for each occurrence (in particular, consider a Table field or MatrixTable entry-indexed field). The first two options needlessly encode the length (which is statically known). The third option is the most access-time-efficient: the offset of any named-value is known at hail compile time. The first two options require a logarithmic search of hail's dictionary tree representation. The third option is more user-friendly for accessing: `x.name`. The first is the least user-friendly: `x[indices[""name""]]`. The first and third options are the most cache-friendly for homogenous operations. The first uses `ArrayExpression.map`, so code size is `O(CODE)`. The third option's code size is `O(CODE * #VALUES)` because structs have no `map`-like primitive. The third option is also not user-friendly for homogenous operations (the user must repeat the code for each name-value pair). The third is the most self-documenting option. The number of fields and their names are visible in `ds.describe()`. The first is the next best because the dictionary is likely a global field that can be viewed with `x.indices.show()`. ---. ## Phase 1; Implement a new virtual type `tstaticdict<T, name1, name2, ..., nameN>` who's physical type is `PStruct` with N fields. These changes span Scala and Python. Implement `map` and `__getitem__` on `StaticDictExpression`s. `map` is implemented by code duplication. ## Phase 2; Implement a new physical type that implements homogenous operations wit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6881:1093,user-friendly,user-friendly,1093,https://hail.is,https://github.com/hail-is/hail/issues/6881,1,['user-friendly'],['user-friendly']
Usability,"ne direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhYmU2OWI5ZC1kMzViLTQ1Y2ItYWY2NS04ZDEwN2YxZWMzZmMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImFiZTY5YjlkLWQzNWItNDVjYi1hZjY1LThkMTA3ZjFlYzNmYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""abe69b9d-d35b-45cb-af65-8d107f1ec3fc"",""prPublicId"":""abe69b9d-d35b-45cb-af65-8d107f1ec3fc"",""dependencies"":[{""name"":""cryptography"",""from"":""40.0.2"",""to"":""41.0.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5663682""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lessons/redos/javascript/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13139:3162,Learn,Learn,3162,https://hail.is,https://github.com/hail-is/hail/pull/13139,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ne direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiYWUwMDM5My05NGUzLTRhNjYtYTE5Ni0xMjUwZDg0ZGZiZDgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImJhZTAwMzkzLTk0ZTMtNGE2Ni1hMTk2LTEyNTBkODRkZmJkOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""bae00393-94e3-4a66-a196-1250d84dfbd8"",""prPublicId"":""bae00393-94e3-4a66-a196-1250d84dfbd8"",""dependencies"":[{""name"":""cryptography"",""from"":""42.0.2"",""to"":""42.0.4""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6261585""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14343:3154,Learn,Learn,3154,https://hail.is,https://github.com/hail-is/hail/pull/14343,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ne direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjOTM3MTIxYy1lZTM3LTQ2ZmMtYTcxMC04MWY4YzdhZmUyN2IiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImM5MzcxMjFjLWVlMzctNDZmYy1hNzEwLTgxZjhjN2FmZTI3YiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""c937121c-ee37-46fc-a710-81f8c7afe27b"",""prPublicId"":""c937121c-ee37-46fc-a710-81f8c7afe27b"",""dependencies"":[{""name"":""cryptography"",""from"":""40.0.2"",""to"":""41.0.0""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5663682""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lessons/redos/javascript/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13136:3153,Learn,Learn,3153,https://hail.is,https://github.com/hail-is/hail/pull/13136,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ne direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmZWM3ZmQ2Ny0xZmE0LTRlNzEtODQ4Ni1hMDk5YThmYWM3NzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZlYzdmZDY3LTFmYTQtNGU3MS04NDg2LWEwOTlhOGZhYzc3OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""fec7fd67-1fa4-4e71-8486-a099a8fac778"",""prPublicId"":""fec7fd67-1fa4-4e71-8486-a099a8fac778"",""dependencies"":[{""name"":""cryptography"",""from"":""40.0.2"",""to"":""41.0.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5663682""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lessons/redos/javascript/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13138:3078,Learn,Learn,3078,https://hail.is,https://github.com/hail-is/hail/pull/13138,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"nformation. Nit: the doc doesn't say the instance monitor monitors instances, it just monitors and handles *events*. Let me be explicit: I think the doc is wrong about the monitor doing health checking because that requires it to track the instances, which I just said should be owned by the pools and the JPIM. That didn't occur to me when we were writing the doc, my apologies. I still think the monitor should:; - route events to the right pool or to the JPIM, and; - aggregate summaries up for the web UI. ---. Let me try to be more specific in my critique:. I think of the system as three layers: the top most is the driver, the middle layer is the monitor, and the bottom layer is the pool or JobPrivateInstanceManager (JPIM). I don't want control flow to go down, up, and back down again. If that happens, then we can't reason about our system as separate layers, we necessarily have to think about the middle and bottom layer together. Very specifically, this flow worries me: (instance pool) create_instance -> (instance monitor) add_instance -> adjust_for_add_instance -> (instance pool) adjust_for_add_instance. We move from low to mid *back to low*. I want information to flow in one direction: either its downward information or its upward information. ---. I'm guessing you're also concerned about code organization / code duplication. I'm not that worried about this. The JPIM and the Pool are similar things and we might inevitably produce some duplication. That's OK with me. To be honest, I think a few stand-alone functions that both of them use will eliminate any code duplication. Both pools and the JPIM will have a `name_instances` and `instance_by_last_updated`. If the duplication gets hard to manage, we might pack that up into another class like InstanceCollection. I realize this means we have several monitoring loops. I'm not very worried about that. I think it's fine and it helps simplify the architecture. It avoids entangling the monitor with the pools and the JPIM.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9772#issuecomment-738515358:2051,simpl,simplify,2051,https://hail.is,https://github.com/hail-is/hail/pull/9772#issuecomment-738515358,2,['simpl'],['simplify']
Usability,non$11.next(Iterator.scala:410); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.fold(TraversableOnce.scala:212); at scala.collection.AbstractIterator.fold(Iterator.scala:1334); at is.hail.expr.ir.FreeVariables$.is$hail$expr$ir$FreeVariables$$compute$1(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$.apply(FreeVariables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mu,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:7139,Simpl,Simplify,7139,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"none-any.whl"" which is different from old value ""gs://hail-30-day/hailctl/dataproc/edmund-dev/0.2.129-827516e474c3/hail-0.2.129-py3-none-any.whl""; mkdir -p env; printf ""gs://hail-common/hailctl/dataproc/0.2.129/hail-0.2.129-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in init_notebook.py vep-GRCh37.sh vep-GRCh38.sh; do \; echo "" $FILE: gs://hail-common/hailctl/dataproc/0.2.129/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-common/hailctl/dataproc/0.2.129/hail-0.2.129-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; gcloud storage cp python/hailtop/hailctl/dataproc/resources/init_notebook.py python/hailtop/hailctl/dataproc/resources/vep-GRCh37.sh python/hailtop/hailctl/dataproc/resources/vep-GRCh38.sh build/deploy/dist/hail-0.2.129-py3-none-any.whl gs://hail-common/hailctl/dataproc/0.2.129; gcloud storage objects update -r gs://hail-common/hailctl/dataproc/0.2.129 --add-acl-grant=entity=AllUsers,role=READER; gcloud storage objects update ""gs://hail-common/hailctl/dataproc/0.2.129/*"" --temporary-hold; ```. Note the following:; - mill is not invoked; - deploy.yaml is re-made with the correct uris; - the wheel is built",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14453#issuecomment-2045927145:1815,Clear,Clear,1815,https://hail.is,https://github.com/hail-is/hail/pull/14453#issuecomment-2045927145,1,['Clear'],['Clear']
Usability,"nt (PContainer and inheritors) and loadField (PBaseStruct and inheritors) have region-taking parameterizations, but these methods are always wrappers for non-region parameterization (e.g loadElement(region, offset, idx) = loadElement(offset, idx)), which makes sense since our ""offsets"" are now memory addresses in these cases (can be read without knowledge of the region that allocated that memory). I believe historically these were really offsets into a region, requiring that region to load it. I believe the remaining use case, now that these offsets are absolute, is to allow for off-heap allocation. This seems slightly odd for a load operation/getter, but I am probably not seeing the intention. Thanks!. daniel king: The history is correct. daniel king: You may want a load to do allocation if you're loading from a lazy datastructure, like a lazily decoded BGEN genotype row. Alex Kotlar: ok, thanks Dan, will keep that parameterization as is. daniel king: You should check-in with Tim though, not clear that load is the place to do this. Tim Poterba: Yep, agree with Dan here. This was the reason I pushed back on your pr to remove the region args in December. Patrick Schultz: How would a lazily decoded datastructure work? Would it mutate to record the fact that some lazy value has already been computed? Or would it recompute every time that value is accessed?. Patrick Schultz: We probably want the former for performance, but we should figure out what the memory management for that looks like. Patrick Schultz: It might be that the lazy datastructure should really own the region(s) it uses for on-demand computation, rather than getting them from its callers. Tim Poterba: hmmm, you're right. Passing the region on load is not sufficient -- that region needs to be the owning region for the original data. Alex Kotlar: Would we want to associate an instance of a PType with a single region?. Patrick Schultz: I think we have most of the infrastructure needed to have a hail type hol",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7826:1496,clear,clear,1496,https://hail.is,https://github.com/hail-is/hail/issues/7826,1,['clear'],['clear']
Usability,"o.txt&quot;</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/91babb941e07a1f45636bdcb75675f13ce1503a2""><code>91babb9</code></a> Update Api docs for credentialed requests (<a href=""https://github-redirect.dependabot.com/corydolphin/flask-cors/issues/221"">#221</a>)</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/522d98936f3995480fe3132b55415d74298d6790""><code>522d989</code></a> Release version 3.0.9 (<a href=""https://github-redirect.dependabot.com/corydolphin/flask-cors/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/67c4b2cc98ae87cf1fa7df4f97fd81b40c79b895""><code>67c4b2c</code></a> Fix request path normalization (<a href=""https://github-redirect.dependabot.com/corydolphin/flask-cors/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/5c6e05e996f10be1df1f2ad178560e54a2f82f1b""><code>5c6e05e</code></a> docs: Fix simple typo, garaunteed -&gt; guaranteed</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/566aef21accd0a15cf127a41edbe14a40c80728c""><code>566aef2</code></a> Fixed over-indentation</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/8a4e6e7057924d124a39ec08f446345bc19e4c5b""><code>8a4e6e7</code></a> Update changelog to give proper kudos to <a href=""https://github.com/juanmaneo""><code>@​juanmaneo</code></a> and <a href=""https://github.com/jdevera""><code>@​jdevera</code></a></li>; <li>See full diff in <a href=""https://github.com/corydolphin/flask-cors/compare/3.0.8...3.0.9"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flask-cors&package-manager=pip&previous-version=3.0.8&new-version=3.0.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10464:2319,simpl,simple,2319,https://hail.is,https://github.com/hail-is/hail/pull/10464,1,['simpl'],['simple']
Usability,"o/en/stable/the_black_code_style/index.html#stability-policy"">stability policy</a>.</p>; <h3>Highlights</h3>; <ul>; <li><strong>Remove Python 2 support</strong> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2740"">#2740</a>)</li>; <li>Introduce the <code>--preview</code> flag (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2752"">#2752</a>)</li>; </ul>; <h3>Style</h3>; <ul>; <li>Deprecate <code>--experimental-string-processing</code> and move the functionality under; <code>--preview</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2789"">#2789</a>)</li>; <li>For stubs, one blank line between class attributes and methods is now kept if there's; at least one pre-existing blank line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2736"">#2736</a>)</li>; <li>Black now normalizes string prefix order (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2297"">#2297</a>)</li>; <li>Remove spaces around power operators if both operands are simple (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2726"">#2726</a>)</li>; <li>Work around bug that causes unstable formatting in some cases in the presence of the; magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2807"">#2807</a>)</li>; <li>Use parentheses for attribute access on decimal float and int literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Don't add whitespace for attribute access on hexadecimal, binary, octal, and complex; literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Treat blank lines in stubs the same inside top-level <code>if</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2820"">#2820</a>)</li>; <li>Fix unstable formatting with semicolons and arithmetic expressions (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2817"">#281",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:8423,simpl,simple,8423,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['simpl'],['simple']
Usability,"ok, let me know when I can try again. I’m now importing another large WES study, hope doesn’t have the same problem.; cheers,. > On Apr 16, 2016, at 5:08 PM, cseed notifications@github.com wrote:; > ; > I think this is due to HDFS filling up. Possibly related to the fact Tim was creating a copy of ExAC. I will retry the job once we clear up some space.; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly or view it on GitHub https://github.com/broadinstitute/hail/issues/301#issuecomment-210901646",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/301#issuecomment-210901896:334,clear,clear,334,https://hail.is,https://github.com/hail-is/hail/issues/301#issuecomment-210901896,2,['clear'],['clear']
Usability,"ollow-redirects/follow-redirects/commit/8b347cbcef7c7b72a6e9be20f5710c17d6163c22""><code>8b347cb</code></a> Drop Cookie header across domains.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/6f5029ae1a0fdab4dc25f6379a5ee303c2319070""><code>6f5029a</code></a> Release version 1.14.6 of the npm package.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/af706bee57de954414c0bde0a9f33e62beea3e52""><code>af706be</code></a> Ignore null headers.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/d01ab7a5c5df3617c7a40a03de7af6427fdfac55""><code>d01ab7a</code></a> Release version 1.14.5 of the npm package.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/40052ea8aa13559becee5795715c1d45b1f0eb76""><code>40052ea</code></a> Make compatible with Node 17.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/86f7572f9365dadc39f85916259b58973819617f""><code>86f7572</code></a> Fix: clear internal timer on request abort to avoid leakage</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/2e1eaf0218c5315a2ab27f53964d0535d4dafb51""><code>2e1eaf0</code></a> Keep Authorization header on subdomain redirects.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/2ad9e82b6277ae2104f7770e9ff1186cc6da29d4""><code>2ad9e82</code></a> Carry over Host header on relative redirects (<a href=""https://github-redirect.dependabot.com/follow-redirects/follow-redirects/issues/172"">#172</a>)</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/77e2a581e1d1811674b7b74745a9c20a5b939488""><code>77e2a58</code></a> Release version 1.14.4 of the npm package.</li>; <li>Additional commits viewable in <a href=""https://github.com/follow-redirects/follow-redirects/compare/v1.14.1...v1.14.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11283:1384,clear,clear,1384,https://hail.is,https://github.com/hail-is/hail/pull/11283,2,['clear'],['clear']
Usability,"om/Azure/azure-sdk-for-python/issues/23659"">#23659</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/68dda72cab22a13014012c6b88137684180e941b""><code>68dda72</code></a> add app service api 2017 backward compatibility support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23626"">#23626</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/1b23cab27114193fa8c19bfd47627093052d8212""><code>1b23cab</code></a> remove validate_authority (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23625"">#23625</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/a6a41458f5d15d47fe508629056b7c90185d4060""><code>a6a4145</code></a> refresh async oob (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23551"">#23551</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/95139f477dcda4de7f6fab56c17e7081f035595d""><code>95139f4</code></a> address arch board review feedback (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23539"">#23539</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/c344afe25cd36875d0fc0c7e4c03a942d2c19bf7""><code>c344afe</code></a> Add Azure Account extension version requirement to Identity README (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23518"">#23518</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/075e68abfb5d4ebe596c8e97fce0327cd0c1f6c2""><code>075e68a</code></a> check content (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23496"">#23496</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/a82e1ea612a3d3e9542812b04930fc8d797fce51""><code>a82e1ea</code></a> expose async client assertion (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23474"">#23474</a>)</li>; <li>A",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11752:3942,feedback,feedback,3942,https://hail.is,https://github.com/hail-is/hail/pull/11752,1,['feedback'],['feedback']
Usability,"om/pytest-dev/pytest-html/issues/244"">#244</a>) <a href=""https://github.com/lzhu666""><code>@​lzhu666</code></a></li>; <li>Trigger sorting for initial sort column (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/248"">#248</a>) <a href=""https://github.com/wanam""><code>@​wanam</code></a></li>; <li>Close opened resource. (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/235"">#235</a>) <a href=""https://github.com/krzysztof-pawlik-gat""><code>@​krzysztof-pawlik-gat</code></a></li>; <li>Keep sort preference for previously sorted columns (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/220"">#220</a>) <a href=""https://github.com/wanam""><code>@​wanam</code></a></li>; <li>Fix assets file naming to work across both *nix and windows (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/223"">#223</a>) <a href=""https://github.com/BeyondEvil""><code>@​BeyondEvil</code></a></li>; <li>Remove unused and undocumented markers (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/224"">#224</a>) <a href=""https://github.com/BeyondEvil""><code>@​BeyondEvil</code></a></li>; <li>Append a line break after captured log sections (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/217"">#217</a>) <a href=""https://github.com/borntyping""><code>@​borntyping</code></a></li>; <li>Handle when report title is stored as an environment variable (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/203"">#203</a>) <a href=""https://github.com/BeyondEvil""><code>@​BeyondEvil</code></a></li>; <li>Removed extraneous space from anchor tag (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/192"">#192</a>) <a href=""https://github.com/chardbury""><code>@​chardbury</code></a></li>; <li>Stop filtering out falsy environment values (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/18",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:6758,undo,undocumented,6758,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['undo'],['undocumented']
Usability,"omment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14692** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14692?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14691** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14691?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14690** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14690?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14686** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @ehigham and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14683#issuecomment-2359375453:1773,Learn,Learn,1773,https://hail.is,https://github.com/hail-is/hail/pull/14683#issuecomment-2359375453,2,['Learn'],['Learn']
Usability,"on; defining their proxy credentials in the URL are <em>strongly</em> encouraged to upgrade; to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy; credentials once the change has been fully deployed.</p>; <p>Users who do not use a proxy or do not supply their proxy credentials through; the user information portion of their proxy URL are not subject to this; vulnerability.</p>; <p>Full details can be read in our <a href=""https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q"">Github Security Advisory</a>; and <a href=""https://nvd.nist.gov/vuln/detail/CVE-2023-32681"">CVE-2023-32681</a>.</p>; </li>; </ul>; <h2>v2.30.0</h2>; <h2>2.30.0 (2023-05-03)</h2>; <p><strong>Dependencies</strong></p>; <ul>; <li>; <p>⚠️ Added support for urllib3 2.0. ⚠️</p>; <p>This may contain minor breaking changes so we advise careful testing and; reviewing <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html</a>; prior to upgrading.</p>; <p>Users who wish to stay on urllib3 1.x can pin to <code>urllib3&lt;2</code>.</p>; </li>; </ul>; <h2>v2.29.0</h2>; <h2>2.29.0 (2023-04-26)</h2>; <p><strong>Improvements</strong></p>; <ul>; <li>Requests now defers chunked requests to the urllib3 implementation to improve; standardization. (<a href=""https://redirect.github.com/psf/requests/issues/6226"">#6226</a>)</li>; <li>Requests relaxes header component requirements to support bytes/str subclasses. (<a href=""https://redirect.github.com/psf/requests/issues/6356"">#6356</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/blob/main/HISTORY.md"">requests's changelog</a>.</em></p>; <blockquote>; <h2>2.31.0 (2023-05-22)</h2>; <p><strong>Security</strong></p>; <ul>; <li>; <p>Versions of Requests between v2.3.0 and v2.30.0 are vulnerable to potential; forwarding of <code>Proxy-Authorization</code> he",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:2043,guid,guide,2043,https://hail.is,https://github.com/hail-is/hail/pull/13091,6,['guid'],['guide']
Usability,"one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyOTUzNDFmZi1lMjQ4LTRiOTItYTY1Yy1kYjJiZWQ3ZDQxMGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI5NTM0MWZmLWUyNDgtNGI5Mi1hNjVjLWRiMmJlZDdkNDEwZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""295341ff-e248-4b92-a65c-db2bed7d410d"",""prPublicId"":""295341ff-e248-4b92-a65c-db2bed7d410d"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.2""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5537286""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[556],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Open Redirect](https://learn.snyk.io/lessons/open-redirect/python/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13066:3276,Learn,Learn,3276,https://hail.is,https://github.com/hail-is/hail/pull/13066,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"one sec, need to remove the clearMissingBits function",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7831#issuecomment-572767655:28,clear,clearMissingBits,28,https://hail.is,https://github.com/hail-is/hail/pull/7831#issuecomment-572767655,2,['clear'],['clearMissingBits']
Usability,"one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the driver was killed by the system.; Let's focus on the driver machines. In Run A, we used an n1-highmem-8 which is advertised to have 52GiB (53248 MiB). In Run B, we used an n1-highmem-16 which is advertised to have 104GiB (106,496 MiB). hailctl sets the JVM max heap size to 80% of the advertised RAM, so 42598 MiB (see hailctl's --master-memory-fraction). In Run A (the only run for which we have syslogs), based on the driver's syslog, before Spark starts, the system has already allocated 8500 MiB to Linux/Google/Dataproc daemons. Moreover, the actual RAM of the system (as reported by the earlyoom daemon) is 52223 MiB (51 GiB, 1GiB less than Google advertises for n1-highmem-8). Assuming these daemons never release their memory, all our user code must fit in 43723 MiB. Since the JVM's max heap is 42598 MiB, Python",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:1822,clear,clear,1822,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449,2,['clear'],['clear']
Usability,"optimal order. This is advantageous for a couple of reasons:; - We want to list newer batches first; - For this query, the `batches` table has more applicables indexes; - We want the variable to order by to be in the primary key of the first; table so we can read the index in reverse. Before and after timings, collected by running the query 5 times, then using; profiles gathered by MySQL.; ```; +-------+---------------------------------------------------*; | query | description | ; +-------+---------------------------------------------------+; | 0 | All batches accessible to user `ci` |; | 1 | All batches accessible to user `ci` owned by `ci` |; +-------+---------------------------------------------------*. +-------+--------+--------------------------------------------------------+------------+------------+; | query | branch | timings | mean | stdev | ; +-------+--------+--------------------------------------------------------+------------+------------+; | 0 | main | 0.05894400,0.05207850,0.07067875,0.06281800,0.060250 | 0.06095385 | 0.00602255 |; | 1 | main | 14.1106150,12.2619323,13.8442850,12.0749633,14.0297822 | 13.2643156 | 0.90087263 |; +-------+--------+--------------------------------------------------------+------------+------------+; | 0 | PR | 0.04717375,0.04974350,0.04312150,0.04070850,0.04193650 | 0.04453675 | 0.00339069 |; | 1 | PR | 0.04423925,0.03967550,0.03935425,0.04056875,0.05286850 | 0.04334125 | 0.00507140 |; +-------+--------+--------------------------------------------------------+------------+------------+; ```. I'm hopeful that this won't introduce regressions for most use cases. While I; haven't benchmarked other queries, the MySQL client does feel more responsive; for a wider array of users. One notable exception is for the user `dking` who ; owns 3.7x more batches than has access to, of which all have been deleted. I; don't think this is a common enough use case to make this query even more; complicated than it already is. Resolves #14599",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14649:2844,responsiv,responsive,2844,https://hail.is,https://github.com/hail-is/hail/pull/14649,1,['responsiv'],['responsive']
Usability,or.fold(Iterator.scala:1334); at is.hail.expr.ir.FreeVariables$.is$hail$expr$ir$FreeVariables$$compute$1(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$.apply(FreeVariables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:5,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:7555,Simpl,Simplify,7555,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyMatrix']"
Usability,"orcing the global uniqueness of names as a basic invariant of the IR (typecheck could also check this invariant); * keep a string in the `Name`, but no longer require it to be unique. Instead it's just a suggestion for how to show the name in printouts, adding a uniqueifying suffix as needed. With `NormalizeNames` gone, this would let us preserve meaningful variable names further in the lowering pipeline.; * possibly keep other state in the `Name`, for example to allow a more efficient implementation of environments, similar to the `mark` state on `BaseIR`. This is obviously a large change, but there are only a few conceptual pieces (appologies for not managing to separate these out):; * attempt to minimize the number of locations in which the `Name` constructor is called, to make future refactorings easier; * add `freshName()`, which just wraps `genUID()`, returning a `Name`; * convert IR construction to use the convenience methods in `ir.package`, which take scala lambdas to represent blocks with bound variables, instead of manually creating new variable names; * replace uses of the magic constant variable names (`row`, `va`, `sa`, `g`, `global`) with constants (`TableIR.{rowName, globalName}`, `MatrixIR.{rowName, colName, entryName, globalName}`); * the above changes modified the names we use for bound variables in many places. That shouldn't matter, but it cought a couple bugs where it did.; * `NormalizeNames` optionally allows the IR to contain free variables. But it didn't do anything to ensure the newly generated variable names are distinct from any contained free variables. Thus it was possible to rename a bound variable to mistakenly capture a contained free variable. I've fixed that.; * `SimplifySuite` compared simplified IR with the pre-constructed expected IR, carefully controlling the `genUID` global state to make simplify generate exactly the names expected. I've replaced that by just comparing with the expected IR using a alpha-equivalence comparison.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14547:2300,Simpl,SimplifySuite,2300,https://hail.is,https://github.com/hail-is/hail/pull/14547,3,"['Simpl', 'simpl']","['SimplifySuite', 'simplified', 'simplify']"
Usability,"ormation: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMjFkYTE5Ny1lMDgzLTRiNzEtODc1Yi0xZmY0MjNhZWZmOWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMyMWRhMTk3LWUwODMtNGI3MS04NzViLTFmZjQyM2FlZmY5YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""c21da197-e083-4b71-875b-1ff423aeff9a"",""prPublicId"":""c21da197-e083-4b71-875b-1ff423aeff9a"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.2""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6149518"",""SNYK-PYTHON-CRYPTOGRAPHY-6157248"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[509,581,451],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use of a Broken or Risky Cryptographic Algorithm](https://learn.snyk.io/lesson/insecure-hash/?loc&#x3D;fix-pr); 🦉 [Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14236:4055,Learn,Learn,4055,https://hail.is,https://github.com/hail-is/hail/pull/14236,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ort](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""514b5ede-26fa-4106-8310-c2ceed7c08a9"",""prPublicId"":""514b5ede-26fa-4106-8310-c2ceed7c08a9"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""40.5.0"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14365:6616,Learn,Learn,6616,https://hail.is,https://github.com/hail-is/hail/pull/14365,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ort](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""bc93468d-68e9-4fac-a335-f87261706f48"",""prPublicId"":""bc93468d-68e9-4fac-a335-f87261706f48"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,null,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14211:6546,Learn,Learn,6546,https://hail.is,https://github.com/hail-is/hail/pull/14211,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ot all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyMTAxMzNhYS03MjA2LTRmMzQtYTQ2OC1iYjY5YWJmYTUzZjEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjIxMDEzM2FhLTcyMDYtNGYzNC1hNDY4LWJiNjlhYmZhNTNmMSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""210133aa-7206-4f34-a468-bb69abfa53f1"",""prPublicId"":""210133aa-7206-4f34-a468-bb69abfa53f1"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.0""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[479,616],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14200:3565,Learn,Learn,3565,https://hail.is,https://github.com/hail-is/hail/pull/14200,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1NDMwZTFmMi0wNDZjLTQwNDctYmI3Mi1hZmJkZmM1MDViNGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjU0MzBlMWYyLTA0NmMtNDA0Ny1iYjcyLWFmYmRmYzUwNWI0YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""5430e1f2-046c-4047-bb72-afbdfc505b4a"",""prPublicId"":""5430e1f2-046c-4047-bb72-afbdfc505b4a"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13304:3183,Learn,Learn,3183,https://hail.is,https://github.com/hail-is/hail/pull/13304,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3Mzc3ZjFlZS1kMjJjLTQ0MDAtYmE1Yy04NGNkYWZmZWJmYzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjczNzdmMWVlLWQyMmMtNDQwMC1iYTVjLTg0Y2RhZmZlYmZjOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7377f1ee-d22c-4400-ba5c-84cdaffebfc8"",""prPublicId"":""7377f1ee-d22c-4400-ba5c-84cdaffebfc8"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13305:3166,Learn,Learn,3166,https://hail.is,https://github.com/hail-is/hail/pull/13305,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMDQ5NzlhMC1iYWM3LTRiMjEtYmE0ZS02OWU5YjAzMTE5ZjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMwNDk3OWEwLWJhYzctNGIyMS1iYTRlLTY5ZTliMDMxMTlmMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""c04979a0-bac7-4b21-ba4e-69e9b03119f0"",""prPublicId"":""c04979a0-bac7-4b21-ba4e-69e9b03119f0"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""7fad328c-8d01-4768-8813-73d6c644e2d4"",""projectUrl"":""https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13309:3168,Learn,Learn,3168,https://hail.is,https://github.com/hail-is/hail/pull/13309,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkY2E2ZDI1ZC1hZGM3LTRiNTctYWU3Zi0yNjExOTYzNTY5MmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImRjYTZkMjVkLWFkYzctNGI1Ny1hZTdmLTI2MTE5NjM1NjkyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""dca6d25d-adc7-4b57-ae7f-26119635692e"",""prPublicId"":""dca6d25d-adc7-4b57-ae7f-26119635692e"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13294:3175,Learn,Learn,3175,https://hail.is,https://github.com/hail-is/hail/pull/13294,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjNiYjk0OC04YjdmLTQ5MzUtYTRkMi05ZWJmNjg4NjZlMmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyM2JiOTQ4LThiN2YtNDkzNS1hNGQyLTllYmY2ODg2NmUyZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e23bb948-8b7f-4935-a4d2-9ebf68866e2e"",""prPublicId"":""e23bb948-8b7f-4935-a4d2-9ebf68866e2e"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13316:3179,Learn,Learn,3179,https://hail.is,https://github.com/hail-is/hail/pull/13316,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"pendency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmYWJiOGYzZi1mMDFjLTQxMjktODJjNC1kZjQzMjRmZTU4YTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZhYmI4ZjNmLWYwMWMtNDEyOS04MmM0LWRmNDMyNGZlNThhMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""fabb8f3f-f01c-4129-82c4-df4324fe58a2"",""prPublicId"":""fabb8f3f-f01c-4129-82c4-df4324fe58a2"",""dependencies"":[{""name"":""certifi"",""from"":""2023.5.7"",""to"":""2023.7.22""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-5805047""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[471],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13296:3168,Learn,Learn,3168,https://hail.is,https://github.com/hail-is/hail/pull/13296,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,plify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:5,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8523,Simpl,Simplify,8523,https://hail.is,https://github.com/hail-is/hail/issues/8338,6,"['Simpl', 'simpl']","['Simplify', 'simplifyMatrix']"
Usability,plify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anon,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10459,Simpl,Simplify,10459,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyMatrix']"
Usability,"populate the `aggregated_*_resources_by_date` tables.; 5. In 10-way parallelism (maxes out a 4 core database), randomly populate the tables for each chunk.; 6. From the last offset (original first running batch id), we sequentially process attempts in groups of 100. We take note of where we are at with tracking any updates to the attempts table (`attempts_time_msecs_diff`), populate the `aggregated_*_resources_by_date` tables, and then do a final catchup step where we apply any updates from `attempts_time_msecs_diff` for any attempts that we have already processed.; 7. Once we have reached the ""end"" of the attempts table, we lock all tables of interest especially the `attempts` table, and do one last final processing step before we add the new triggers that will auto-populate the `aggregated_*_resources_by_date` tables.; 8. Then we perform an audit and make sure things look correct. (I might need to change or eliminate the billing_project audit query because there are 5 batches with ~20 jobs that aren't perfectly tracked when we did the original switch over to the new billing tables).; 9. If there are any failures, we revert the triggers back to the original state. Also to note, is the new table for billing_projects is keyed by (billing_project, user) which will make queries much faster so they don't have to scan the batches aggregated resources table. I ran the migration successfully on a full test database and the audit was clean for jobs and batches except for the 5 batches that were running right when we started populating the original aggregated billing tables. . I'd like to gather all feedback and then will run the migration one more time to do a final test. Note, that most of the queries in the migration are not tested. The key thing to double check is the triggers will continue to insert data into the old tables and we get the end points correct (start is inclusive and end is exclusive) as unlike the previous migration, this set of updates is NOT idempotent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11996:2607,feedback,feedback,2607,https://hail.is,https://github.com/hail-is/hail/pull/11996,1,['feedback'],['feedback']
Usability,"port for creating validator classes whose metaschema uses a different; dialect than its schemas. In other words, they may use draft2020-12 to define; which schemas are valid, but the schemas themselves use draft7 (or a custom; dialect, etc.) to define which <em>instances</em> are valid. Doing this is likely; not something most users, even metaschema authors, may need, but occasionally; will be useful for advanced use cases.</li>; </ul>; <h1>v4.12.1</h1>; <ul>; <li>Fix some stray comments in the README.</li>; </ul>; <h1>v4.12.0</h1>; <ul>; <li>Warn at runtime when subclassing validator classes. Doing so was not; intended to be public API, though it seems some downstream libraries; do so. A future version will make this an error, as it is brittle and; better served by composing validator objects instead. Feel free to reach; out if there are any cases where changing existing code seems difficult; and I can try to provide guidance.</li>; </ul>; <h1>v4.11.0</h1>; <ul>; <li>Make the rendered README in PyPI simpler and fancier. Thanks Hynek (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/983"">#983</a>)!</li>; </ul>; <h1>v4.10.3</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/420fc6bd9a3ecc4cd637ece97cb4b482b4d0d37e""><code>420fc6b</code></a> Minor verbiage tweak for protocols.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/8ce8250897e1b2e9b1fea6825965dbc876ec1f4d""><code>8ce8250</code></a> Don't show type checker functions in TypeChecker reprs.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/6533d32cad0a65847979297c66f96f1dfbf1d68c""><code>6533d32</code></a> Tweak the colorscheme for code blocks in docs.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/792311dc26b5b6aec3b82930969f7eb2588a9fcd""><code>792311d</code></a>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12163:6049,simpl,simpler,6049,https://hail.is,https://github.com/hail-is/hail/pull/12163,1,['simpl'],['simpler']
Usability,pply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.is$hail$expr$ir$Optimize$$runOpt$1(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply$mcV$sp(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.exp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:11559,Simpl,Simplify,11559,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyValue']"
Usability,prefer IR over ApplyIR for simple functions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4499:27,simpl,simple,27,https://hail.is,https://github.com/hail-is/hail/pull/4499,2,['simpl'],['simple']
Usability,pret$$anonfun$apply$1.apply(Interpret.scala:599); 	at is.hail.expr.ir.Interpret$$anonfun$apply$1.apply(Interpret.scala:599); 	at scala.Option.getOrElse(Option.scala:121); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:599); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:49); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:24); 	at is.hail.table.Table.count(Table.scala:257); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at sparklyr.Invoke.invoke(invoke.scala:139); 	at sparklyr.StreamHandler.handleMethodCall(stream.scala:123); 	at sparklyr.StreamHandler.read(stream.scala:66); 	at sparklyr.BackendHandler.channelRead0(handler.scala:51); 	at sparklyr.BackendHandler.channelRead0(handler.scala:4); 	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:4295,Simpl,SimpleChannelInboundHandler,4295,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['Simpl'],['SimpleChannelInboundHandler']
Usability,"project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlZjJlMTU4YS01YTI0LTQ2NjgtYjY2My1iMmYzYmNmZjM3NmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImVmMmUxNThhLTVhMjQtNDY2OC1iNjYzLWIyZjNiY2ZmMzc2ZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ef2e158a-5a24-4668-b663-b2f3bcff376e"",""prPublicId"":""ef2e158a-5a24-4668-b663-b2f3bcff376e"",""dependencies"":[{""name"":""numpy"",""from"":""1.21.3"",""to"":""1.22.2""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-NUMPY-2321964"",""SNYK-PYTHON-NUMPY-2321966"",""SNYK-PYTHON-NUMPY-2321970""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown""],""priorityScoreList"":[null,null,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lessons/null-dereference/cpp/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lessons/redos/javascript/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12895:3677,Learn,Learn,3677,https://hail.is,https://github.com/hail-is/hail/pull/12895,3,"['Learn', 'learn']","['Learn', 'learn']"
Usability,prometheus was on a crash loop in Azure because it was failing to `mmap` a 0-byte file that the previous pod had created before getting shut down. Turns out this bug was fixed in a more recent version of prometheus so a simple upgrade fixed the issue. This is the most recent release.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11607:220,simpl,simple,220,https://hail.is,https://github.com/hail-is/hail/pull/11607,1,['simpl'],['simple']
Usability,"py<2', 'pandas>0.22,<0.24', 'parsimonious<0.9', 'PyJWT', 'python-json-logger==0.1.11', 'requests>=2.21.0,<2.21.1', 'scipy>1.2,<1.4', 'tabulate==0.8.3', 'slackclient==2.0.0', 'websocket-client', 'sklearn', 'tabulate', 'statsmodels', 'scikit-learn', 'hdbscan', 'matplotlib']; b""Double requirement given: tabulate (already in tabulate==0.8.3, name='tabulate')\nYou are using pip version 10.0.1, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\n""; Traceback (most recent call last):; File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 16, in safe_call; sp.check_output(args, stderr=sp.STDOUT); File ""/opt/conda/default/lib/python3.6/subprocess.py"", line 336, in check_output; **kwargs).stdout; File ""/opt/conda/default/lib/python3.6/subprocess.py"", line 418, in run; output=stdout, stderr=stderr); subprocess.CalledProcessError: Command '('pip', 'install', 'setuptools', 'mkl<2020', 'ipywidgets<8', 'jupyter_console<5', 'nbconvert<6', 'notebook<6', 'qtconsole<5', 'jupyter', 'tornado<6', 'lxml<5', 'google-cloud==0.32.0', 'ipython<7', 'jgscm<0.2', 'jupyter-spark', 'aiohttp', 'bokeh>1.1,<1.3', 'decorator<5', 'gcsfs==0.2.1', 'hurry.filesize==0.9', 'ipykernel<5', 'nest_asyncio', 'numpy<2', 'pandas>0.22,<0.24', 'parsimonious<0.9', 'PyJWT', 'python-json-logger==0.1.11', 'requests>=2.21.0,<2.21.1', 'scipy>1.2,<1.4', 'tabulate==0.8.3', 'slackclient==2.0.0', 'websocket-client', 'sklearn', 'tabulate', 'statsmodels', 'scikit-learn', 'hdbscan', 'matplotlib')' returned non-zero exit status 1. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 66, in <module>; safe_call(*command); File ""/etc/google-dataproc/startup-scripts/dataproc-initialization-script-0"", line 18, in safe_call; print(e.output).decode(); AttributeError: 'NoneType' object has no attribute 'decode'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6634:6898,learn,learn,6898,https://hail.is,https://github.com/hail-is/hail/issues/6634,1,['learn'],['learn']
Usability,python version doesn't give as much feedback,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1123:36,feedback,feedback,36,https://hail.is,https://github.com/hail-is/hail/issues/1123,2,['feedback'],['feedback']
Usability,"python/hail/expr/expressions/typed_expressions.py:934: >>> hl.eval(s1.add(10)) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:1296: >>> hl.eval(d.key_set()) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:1312: >>> hl.eval(d.keys()) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:1329: >>> hl.eval(d.map_values(lambda x: x * 10)) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:1366: >>> hl.eval(d.values()) # doctest: +NOTEST; Binary file /Users/dking/projects/hail/hail/python/hail/expr/expressions/__pycache__/typed_expressions.cpython-37.pyc matches; Binary file /Users/dking/projects/hail/hail/python/hail/__pycache__/table.cpython-37.pyc matches; Binary file /Users/dking/projects/hail/hail/python/hail/__pycache__/matrixtable.cpython-37.pyc matches; /Users/dking/projects/hail/hail/python/hail/docs/guides/basics.rst:95: >>> mt.describe() # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/guides/basics.rst:141: >>> ht.describe() # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/guides/basics.rst:164: >>> mt.s.describe() # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:21: >>> hl.eval(x) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:24: >>> hl.eval(x) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:27: >>> hl.eval(hl.rand_unif(0, 1)) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:30: >>> hl.eval(hl.rand_unif(0, 1)) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:33: >>> hl.eval(hl.array([x, x, x])) # doctest: +NOTEST; /Users/dking/projects/hail/hail/python/hail/docs/functions/random.rst:42: >>> hl.eval(hl.array([a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4817#issuecomment-506359198:9048,guid,guides,9048,https://hail.is,https://github.com/hail-is/hail/issues/4817#issuecomment-506359198,2,['guid'],['guides']
Usability,"r both `outerRegion` and `eltRegion`. This lets us migrate to the new memory management one node at a time. When I talk about correctness, I mean that: no pointer is used after the region it points into has been freed; and, every region which is created is eventually freed. When reasoning about correctness, I consider `r.clear()` equivalent to `r.invalidate(); r.getNewRegion()`. As a demonstration of how this should work, this PR does convert `EmitStream.{toArray, write}` to use `eltRegion` correctly, which are used in the consumer nodes `ToArray`, `ArraySort`, `ToSet`, `ToDict`, and `GroupByKey`. Going forward, the plan is to convert the rest of the consumer and producer nodes, before converting the transformer nodes (which both consume and produce streams), as correctness can only be tested on pipelines in which all nodes have been converted. ### Semantics. A stream producer is passed two regions from its consumer: `outerRegion` and `eltRegion`. The node being emitted does not own either region, so may not free/clear them. The only thing a producer may do with either region is to put data in them, by writing directly to them or by giving/sharing ownership of a producer-owned region to them. Consumers' contract:; * The lifetime of `outerRegion` must contain the lifetime of the producer stream, i.e. `outerRegion` must be valid before the producer's `setup0` is called, and must still be valid when the producer's `close0` is called. Thus a producer may use `outerRegion` to store state that persists between elements, or it may use a region it owns itself.; * When the producer's `pull` is called, `eltRegion` must be valid (it does not need to be valid for setup/close). Producers' contract:; * When the consumer's `push` is called, the pushed value must be owned by either `outerRegion` or `eltRegion` (really `eltRegion`; using `outerRegion` is correct but unnecessarily extends the lifetime of the value). This can be accomplished by writing directly to the consumer's region",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9106:1650,clear,clear,1650,https://hail.is,https://github.com/hail-is/hail/pull/9106,1,['clear'],['clear']
Usability,"r, there is a [GCS connector](https://www.hdfgroup.org/solutions/cloud-amazon-s3-storage-hdf5-connector/). It's not an object store, but there's also support for [Hadoop HDFS](https://www.hdfgroup.org/solutions/hadoop-hdfs-hdf5-connector/). There's also [the Virtual Object Layer](https://docs.hdfgroup.org/hdf5/develop/_h5_v_l__u_g.html) which appears to be a file system abstraction that would permit storing HDF5 ""files"" in multiple objects which plays well with cloud object store scaling. We should prioritize an importer because no one has asked for HDF5 export nor is it clear that the HDF5 client libraries make it easy to write a single HDF5 ""file"" from a cluster of cores separated by a network. An importer would look something like `MatrixVCFReader`. It will need to use an HDF5 Java client library. An HDF5 client API is described [here](https://docs.hdfgroup.org/hdf5/develop/_h_d_f5_l_i_b.html) but they don't link to any JARs or maven repositories. This [support thread from 2022](https://forum.hdfgroup.org/t/how-to-get-started-wih-hdf5-java/10346/14) appears to ultimately conclude that [netcdf-java](https://forum.hdfgroup.org/t/how-to-get-started-wih-hdf5-java/10346/24) supports reading HDF5 files. Including netcdf-java in a gradle or maven project is described [here](https://docs.unidata.ucar.edu/netcdf-java/current/userguide/using_netcdf_java_artifacts.html). It is not entirely clear how to use netcdf-java to access objects in Google Cloud Storage or Azure Blob Storage. There's an [open issue to support S3](https://github.com/Unidata/netcdf-java/issues/111). ---. OK, so, this is roughly what I'd do:. Driver side:; 1. Get the schema, cook up a corresponding Hail type.; 2. Choose a partitioning of the index space. Worker side:; 1. Read the same slice of each field/column based on the partition information.; 2. Construct a Hail SType/PType. See `GVCFPartitionReader` for an example. That class is misnamed, it's just a VCF partition reader, its not specific to GVCFs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14311#issuecomment-1955112694:1792,clear,clear,1792,https://hail.is,https://github.com/hail-is/hail/issues/14311#issuecomment-1955112694,2,['clear'],['clear']
Usability,"r. I think this is currently impossible due to lack of permissions, but we should either explicitly prohibit this or ensure our solution encompasses it. In particular, I am concerned OpenID could be used to grant permission for a GCP identity to write to S3 or ABS. . Pulling an image shouldn’t trigger substantial egress. In the first case, there are three kinds of possible egress:; 1. Egress to the Public Internet.; 2. Egress to a VM in a different Google region.; 3. Egress to a Google Service in a different Google region (e.g. uploading to a bucket in a different region). I believe (2) and (3) are charged equivalently. (1) is simply Internet egress pricing. In (3), I’m not sure who pays the egress from a VM to a bucket in a different region. I assume the VM owner. In all three cases, the destination’s location matters. For public Internet egress, we can use GeoIP to determine the region of the planet. I’m not sure if we can determine the region of (2) and (3). If we can’t, we should either prevent such traffic or we should charge the maximum egress. A final caveat is that we use Premium Networking. As a result, our traffic can use Google’s internal backbone. It’s not clear to me if this means that a packet from us-central to a public IP in Australia incurs just Internet egress or that *and* a region-to-region egress to pay for the use of GCP’s internal global backbone. The priority of various considerations:; 1. Top priority within this issue is to track and recover costs. Even if this means charging a flat fee across all possible kinds of egress. Even if that fee is substantially higher than the real cost to us.; 2. Second priority is to surface this information to the user. Simply providing, in the job page, the usage and cost of each resource for this job.; 3. Fine grained egress so that users can actually intentionally use it at cost or near cost to, for example, move data between clouds or regions. . ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13428:1610,clear,clear,1610,https://hail.is,https://github.com/hail-is/hail/issues/13428,2,"['Simpl', 'clear']","['Simply', 'clear']"
Usability,"r. Users who rely on; defining their proxy credentials in the URL are <em>strongly</em> encouraged to upgrade; to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy; credentials once the change has been fully deployed.</p>; <p>Users who do not use a proxy or do not supply their proxy credentials through; the user information portion of their proxy URL are not subject to this; vulnerability.</p>; <p>Full details can be read in our <a href=""https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q"">Github Security Advisory</a>; and <a href=""https://nvd.nist.gov/vuln/detail/CVE-2023-32681"">CVE-2023-32681</a>.</p>; </li>; </ul>; <h2>2.30.0 (2023-05-03)</h2>; <p><strong>Dependencies</strong></p>; <ul>; <li>; <p>⚠️ Added support for urllib3 2.0. ⚠️</p>; <p>This may contain minor breaking changes so we advise careful testing and; reviewing <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html</a>; prior to upgrading.</p>; <p>Users who wish to stay on urllib3 1.x can pin to <code>urllib3&lt;2</code>.</p>; </li>; </ul>; <h2>2.29.0 (2023-04-26)</h2>; <p><strong>Improvements</strong></p>; <ul>; <li>Requests now defers chunked requests to the urllib3 implementation to improve; standardization. (<a href=""https://redirect.github.com/psf/requests/issues/6226"">#6226</a>)</li>; <li>Requests relaxes header component requirements to support bytes/str subclasses. (<a href=""https://redirect.github.com/psf/requests/issues/6356"">#6356</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/psf/requests/commit/147c8511ddbfa5e8f71bbf5c18ede0c4ceb3bba4""><code>147c851</code></a> v2.31.0</li>; <li><a href=""https://github.com/psf/requests/commit/74ea7cf7a6a27a4eeb2ae24e162bcc942a6706d5""><code>74ea7cf</code></a> Merge pull request from GHSA-j8r2-6x86-q33q</li>; <li><a href=""https://github.com/psf/requests/commi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:4596,guid,guide,4596,https://hail.is,https://github.com/hail-is/hail/pull/13091,6,['guid'],['guide']
Usability,r.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8642,Simpl,Simplify,8642,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyMatrix']"
Usability,r.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:9610,Simpl,Simplify,9610,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyMatrix']"
Usability,r.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8748,Simpl,Simplify,8748,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyMatrix']"
Usability,r.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:9716,Simpl,Simplify,9716,https://hail.is,https://github.com/hail-is/hail/issues/8338,3,"['Simpl', 'simpl']","['Simplify', 'simplifyMatrix']"
Usability,r.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.is$hail$expr$ir$Optimize$$runOpt$1(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply$mcV$sp(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.apply(Optimize.scala:20); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:16); at is.hail.expr.ir.CompileAn,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:11735,Simpl,Simplify,11735,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,r.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.is$hail$expr$ir$Optimize$$runOpt$1(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply$mcV$sp(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:11520,Simpl,Simplify,11520,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"r.buffer.max=1g,spark:spark.driver.extraJavaOptions=-Xss4M,spark:spark.executor.extraJavaOptions=-Xss4M,hdfs:dfs.replication=1,dataproc:dataproc.logging.stackdriver.enable=false,dataproc:dataproc.monitoring.stackdriver.enable=false,spark:spark.driver.memory=41g \; --initialization-actions=gs://hail-common/hailctl/dataproc/0.2.18/init_notebook.py,gs://gnomad-public/tools/inits/master-init.sh \; --metadata=^|||^WHEEL=gs://hail-common/hailctl/dataproc/0.2.18/hail-0.2.18-py3-none-any.whl|||PKGS=aiohttp|bokeh>1.1,<1.3|decorator<5|gcsfs==0.2.1|hurry.filesize==0.9|ipykernel<5|nest_asyncio|numpy<2|pandas>0.22,<0.24|parsimonious<0.9|PyJWT|python-json-logger==0.1.11|requests>=2.21.0,<2.21.1|scipy>1.2,<1.4|tabulate==0.8.3|slackclient==2.0.0|websocket-client|sklearn|tabulate|statsmodels|scikit-learn|hdbscan|matplotlib \; --master-machine-type=n1-highmem-8 \; --master-boot-disk-size=100GB \; --num-master-local-ssds=0 \; --num-preemptible-workers=0 \; --num-worker-local-ssds=0 \; --num-workers=2 \; --preemptible-worker-boot-disk-size=40GB \; --worker-boot-disk-size=40 \; --worker-machine-type=n1-standard-8 \; --zone=us-central1-b \; --initialization-action-timeout=20m \; --labels=creator=weisburd_broadinstitute_org \; --max-idle=12h; Starting cluster 'bw2'...; Waiting on operation [projects/seqr-project/regions/global/operations/46f1d37d-798a-3fc0-8f70-eac304448a08].; Waiting for cluster creation operation...; WARNING: For PD-Standard without local SSDs, we strongly recommend provisioning 1TB or larger to ensure consistently high I/O performance. See https://cloud.google.com/compute/docs/disks/performance for information on disk I/O performance.; Waiting for cluster creation operation...done.; ERROR: (gcloud.beta.dataproc.clusters.create) Operation [projects/seqr-project/regions/global/operations/46f1d37d-798a-3fc0-8f70-eac304448a08] failed: Initialization action failed. Failed action 'gs://hail-common/hailctl/dataproc/0.2.18/init_notebook.py', see output in: gs://dataproc-d919bdd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6634:1230,learn,learn,1230,https://hail.is,https://github.com/hail-is/hail/issues/6634,1,['learn'],['learn']
Usability,r.functions.qnorm:1: WARNING: py:meth reference target not found: pnorm; /Users/dking/projects/hail/hail/python/hail/expr/functions.py:docstring of hail.expr.functions.qpois:1: WARNING: py:meth reference target not found: ppois; /Users/dking/projects/hail/hail/python/hail/expr/functions.py:docstring of hail.expr.functions.qpois:15: WARNING: py:meth reference target not found: ppois; /Users/dking/projects/hail/hail/python/hail/genetics/pedigree.py:docstring of hail.genetics.pedigree.Pedigree.filter_to:: WARNING: py:class reference target not found: list of str; /Users/dking/projects/hail/hail/python/hail/genetics/pedigree.py:docstring of hail.genetics.pedigree.Pedigree.write:14: WARNING: py:meth reference target not found: hail.KeyTable.import_fam; /Users/dking/projects/hail/hail/python/hail/genetics/reference_genome.py:docstring of hail.genetics.reference_genome.ReferenceGenome.write:10: WARNING: py:meth reference target not found: hail.ReferenceGenome.read; /Users/dking/projects/hail/hail/python/hail/docs/guides/api.rst:19: WARNING: py:func reference target not found: Table.show; /Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:docstring of hail.expr.expressions.typed_expressions.CallExpression.one_hot_alleles:25: WARNING: py:obj reference target not found: tint32; /Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:docstring of hail.expr.expressions.typed_expressions.IntervalExpression.overlaps:11: WARNING: py:data reference target not found: tinterval; /Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:docstring of hail.expr.expressions.typed_expressions.NDArrayExpression.T:5: WARNING: py:func reference target not found: transpose; /Users/dking/projects/hail/hail/python/hail/expr/expressions/typed_expressions.py:docstring of hail.expr.expressions.typed_expressions.NDArrayNumericExpression.T:5: WARNING: py:func reference target not found: transpose; /Users/dking/projects/,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9403#issuecomment-685996666:11578,guid,guides,11578,https://hail.is,https://github.com/hail-is/hail/pull/9403#issuecomment-685996666,2,['guid'],['guides']
Usability,raversableOnce$class.fold(TraversableOnce.scala:212); at scala.collection.AbstractIterator.fold(Iterator.scala:1334); at is.hail.expr.ir.FreeVariables$.is$hail$expr$ir$FreeVariables$$compute$1(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$.apply(FreeVariables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30);,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:7470,Simpl,Simplify,7470,https://hail.is,https://github.com/hail-is/hail/issues/8338,2,['Simpl'],['Simplify']
Usability,"re than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1ZTRkMTU3Zi04YTdjLTRhNzctYTZlNC00YTdmNGU4Y2I0YzkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjVlNGQxNTdmLThhN2MtNGE3Ny1hNmU0LTRhN2Y0ZThjYjRjOSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""5e4d157f-8a7c-4a77-a6e4-4a7f4e8cb4c9"",""prPublicId"":""5e4d157f-8a7c-4a77-a6e4-4a7f4e8cb4c9"",""dependencies"":[{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.2""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-TORNADO-5537286""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[384],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13323:3244,Learn,Learn,3244,https://hail.is,https://github.com/hail-is/hail/pull/13323,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"rect dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2ZWQ3MzlmOS1mZjc4LTQzYzgtYWQwOC05MThjNmRhMWNlOTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjZlZDczOWY5LWZmNzgtNDNjOC1hZDA4LTkxOGM2ZGExY2U5NiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""6ed739f9-ff78-43c8-ad08-918c6da1ce96"",""prPublicId"":""6ed739f9-ff78-43c8-ad08-918c6da1ce96"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.4"",""to"":""3.8.5""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-5798483""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[658],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13284:3151,Learn,Learn,3151,https://hail.is,https://github.com/hail-is/hail/pull/13284,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"rect dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4YTljZTU5Zi0yOTY3LTQ2MTQtOGE5YS1iY2M5YjU1ZWZkZGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjhhOWNlNTlmLTI5NjctNDYxNC04YTlhLWJjYzliNTVlZmRkZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""8a9ce59f-2967-4614-8a9a-bcc9b55efddd"",""prPublicId"":""8a9ce59f-2967-4614-8a9a-bcc9b55efddd"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.4"",""to"":""3.8.5""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-5798483""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[658],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13282:3166,Learn,Learn,3166,https://hail.is,https://github.com/hail-is/hail/pull/13282,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"rect dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjZmU2NDEwYi1jYjQ3LTQ2YzgtOTYwYy1kOWRlY2UxMjI5ZTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImNmZTY0MTBiLWNiNDctNDZjOC05NjBjLWQ5ZGVjZTEyMjllMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""cfe6410b-cb47-46c8-960c-d9dece1229e2"",""prPublicId"":""cfe6410b-cb47-46c8-960c-d9dece1229e2"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.4"",""to"":""3.8.5""}],""packageManager"":""pip"",""projectPublicId"":""b7c31419-ec34-40f1-8bc6-ad8303fb329b"",""projectUrl"":""https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-5798483""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[658],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13286:3157,Learn,Learn,3157,https://hail.is,https://github.com/hail-is/hail/pull/13286,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"rect dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjk5ZmU1Ni0wNGI1LTQ3MzEtYmUzYS03M2ZmYzgxZTZjYjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyOTlmZTU2LTA0YjUtNDczMS1iZTNhLTczZmZjODFlNmNiOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e299fe56-04b5-4731-be3a-73ffc81e6cb8"",""prPublicId"":""e299fe56-04b5-4731-be3a-73ffc81e6cb8"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.4"",""to"":""3.8.5""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-5798483""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[658],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13283:3158,Learn,Learn,3158,https://hail.is,https://github.com/hail-is/hail/pull/13283,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"rect dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmZmEwNjUyZi1hMzc2LTQ0NmQtYWJjNC04NmJhMzUwNmY3MzMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZmYTA2NTJmLWEzNzYtNDQ2ZC1hYmM0LTg2YmEzNTA2ZjczMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ffa0652f-a376-446d-abc4-86ba3506f733"",""prPublicId"":""ffa0652f-a376-446d-abc4-86ba3506f733"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.4"",""to"":""3.8.5""}],""packageManager"":""pip"",""projectPublicId"":""cbac91bd-aa95-4900-9a06-97404b268d6e"",""projectUrl"":""https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-5798483""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[658],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13285:3152,Learn,Learn,3152,https://hail.is,https://github.com/hail-is/hail/pull/13285,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"rect.dependabot.com/googleapis/python-logging/issues/434"">#434</a>) (<a href=""https://www.github.com/googleapis/python-logging/commit/5055919f70c82b38de6d1fa7f1df6006865a857b"">5055919</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-logging/commit/10727ef3c8cca7e20484e58e6afdc79e81a4d4c9""><code>10727ef</code></a> chore(main): release 3.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/473"">#473</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/d86be6cf83c3f3b91c4fc0b2e0666b0ca1d7e248""><code>d86be6c</code></a> chore(deps): update dependency google-cloud-storage to v2.1.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/469"">#469</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/8a67b73cdfcb9da545671be6cf59c724360b1544""><code>8a67b73</code></a> docs: update usage guide for v3.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/456"">#456</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/e0c5fc02160ae87faf4ba5c2b62be86de6b02cf3""><code>e0c5fc0</code></a> feat: trace improvements (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/450"">#450</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/97e32b67603553fe350b6327455fc9f80b8aa6ce""><code>97e32b6</code></a> fix: allow reading logs from non-project paths (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/444"">#444</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/a760e02371a55d6262e42de9e0222fffa2c7192b""><code>a760e02</code></a> feat: add json_fields extras argument for adding to jsonPayload (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/447"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:11824,guid,guide,11824,https://hail.is,https://github.com/hail-is/hail/pull/11574,1,['guid'],['guide']
Usability,remove learn more,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8851:7,learn,learn,7,https://hail.is,https://github.com/hail-is/hail/pull/8851,2,['learn'],['learn']
Usability,removed action and simplified rrm and grm,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3944:19,simpl,simplified,19,https://hail.is,https://github.com/hail-is/hail/pull/3944,2,['simpl'],['simplified']
Usability,ret.scala:599); 	at is.hail.expr.ir.Interpret$$anonfun$apply$1.apply(Interpret.scala:599); 	at scala.Option.getOrElse(Option.scala:121); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:599); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:49); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:24); 	at is.hail.table.Table.count(Table.scala:257); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at sparklyr.Invoke.invoke(invoke.scala:139); 	at sparklyr.StreamHandler.handleMethodCall(stream.scala:123); 	at sparklyr.StreamHandler.read(stream.scala:66); 	at sparklyr.BackendHandler.channelRead0(handler.scala:51); 	at sparklyr.BackendHandler.channelRead0(handler.scala:4); 	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267); 	at io.netty.channel.Abstra,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:4335,Simpl,SimpleChannelInboundHandler,4335,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['Simpl'],['SimpleChannelInboundHandler']
Usability,"rom v1 to v2.3.2 <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/50"">#50</a>, <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/56"">#56</a>.; Thanks to Dependabot.; o Update actions/setup-java from v1.4.0 to v1.4.1 <a href=""https://github-redirect.dependabot.com/apache/commons-codec/issues/57"">#57</a>.; Thanks to Dependabot.</p>; <p>For complete information on Apache Commons Codec, including instructions on how; to submit bug reports, patches, or suggestions for improvement, see the; Apache Commons Codec website:</p>; <p><a href=""https://commons.apache.org/proper/commons-codec/"">https://commons.apache.org/proper/commons-codec/</a></p>; <p>Download page: <a href=""https://commons.apache.org/proper/commons-codec/download_codec.cgi"">https://commons.apache.org/proper/commons-codec/download_codec.cgi</a></p>; <hr />; <pre><code> Apache Commons Codec 1.14 RELEASE NOTES; December 30 2019; </code></pre>; <p>The Apache Commons Codec package contains simple encoder and decoders for; various formats such as Base64 and Hexadecimal. In addition to these; widely used encoders and decoders, the codec package also maintains a</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/apache/commons-codec/commit/c89d2af770f05457fbefa5fb4713c888bf177fb2""><code>c89d2af</code></a> Prepare for 1.15 release</li>; <li><a href=""https://github.com/apache/commons-codec/commit/ba81ed5dc06661d931a4bb8f7abaa51ee5300396""><code>ba81ed5</code></a> Use gav=true for the maven central redirect</li>; <li><a href=""https://github.com/apache/commons-codec/commit/cb629f03516e21ba7daeb4dd9a7b5fe3c76fc841""><code>cb629f0</code></a> Update maven central badge</li>; <li><a href=""https://github.com/apache/commons-codec/commit/b8090b34914ef456a1262292b554c7a5e1e623e8""><code>b8090b3</code></a> Fix coverage badge to use the 'master' branch not the default 'trunk'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12385:2525,simpl,simple,2525,https://hail.is,https://github.com/hail-is/hail/pull/12385,1,['simpl'],['simple']
Usability,"ry. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol defines both a scheme for the *encryption of messages* and for; the *authentication of parties*. The protocol defines authentication as; optional. In practice, at least one party presents authentication. For example,; public web servers authenticate themselves to clients but clients do not; reciprocate. ### Authentication; #### X.509 Certificates. TLS uses X.509 Certificates for authentication. X.509 is a rather complicated; standard. X.509 Certificates can be serialized in a variety of ways. We use the; Privacy-enhanced Electronic Mail (PEM) file format for serialization. PEM is; really simple. A file may contain multiple base64-encoded blobs each with a; header and footer of the form:. ```; -----BEGIN LABEL-----; ...; -----END LABEL-----; ```. where `LABEL` describes the data. We only use two labels: `CERTIFICATE` and; `PRIVATE KEY`. An X.509 Certificate is an unforgeable proof of identity. It usually is paired; with a private key that was used to digitally sign the certificate. In the; security literature, an authenticatable entity is usually called a; *principal*. Each principal should have a unique private key. In our system the; principals are both our services (e.g. `batch`, `batch-driver`) and any; non-serving clients (e.g. `test-batch`, `admin-pod`). A key and certificate are; generated ad nihilum by `openssl req -new`:. ```; openssl req -new \; -x509; -keyout key_file; -out cert_file; -newkey rsa:4096; -nodes; -subj /CN=example.com; -addext subjectAltName = DNS:www.example.com,DNS:foo.com; ```. The first three arguments are self-explanatory. I explain the",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:2593,simpl,simple,2593,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['simpl'],['simple']
Usability,"s explicit, but the point that jumps out of the loop is not. I suggested making this something like; ```; hl.loop(; lambda i, x:; hl.cond(i < 10, hl.recur(i + 1, x + i), hl.break(x)),; 0, 0); ```; or, if we're giving names to loops, it might be simpler to pass the break and recur functions to the lambda:; ```; hl.loop(; lambda sum, ret, i, x:; hl.cond(i < 10, sum(i + 1, x + i), ret(x)),; 0, 0); ```. The second difference is in the typing. In this PR, the `hl.recur` expression is given the type of the entire loop. I would add a single new type `Bottom`, and give all expressions which jump (both the recur and the break expressions) the type `Bottom`. `Bottom` is the empty type, so there can be no closed expressions of type `Bottom`. In the type checker, `Bottom` is only allowed to appear in tail positions, and for `If`, we keep the rule that both branches must have the same type, so either both branches are `Bottom` or neither are. This keeps the semantics simple: an if statement either makes a value or it jumps away, there's no confusing mix. One nice property of this setup is that if an expression has a non-bottom type, then it is guaranteed not to jump away from itself (it may jump internally), so it is safe to method-wrap. This also make codegen very simple, and @iitalics has already implemented it! See `JoinPoint` and `JoinPoint.CallCC`. In the IR, I don't think this requires much change. If we're already adding a continuation context (as mentioned above), then `TailLoop` just needs to bind both a recur and a break continuation, where recur takes the loop variable types, and break takes the loop result type. Then `Recur` can be replaced by a `Jump` node which calls (jumps to) a continuation in context. There's also a middle ground where we make break continuations explicit in the IR, but we want to keep the scheme-like interface in python. Then the pass @cseed described for inferring where the loop exits are would just go in python instead of the emitter. > Using",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7614#issuecomment-559072407:1989,simpl,simple,1989,https://hail.is,https://github.com/hail-is/hail/pull/7614#issuecomment-559072407,2,['simpl'],['simple']
Usability,"s no comparison: Angular takes months to know well, React days at worst. Also, by not buying into a full framework, we achieve modularity: If we end up finding React too slow, even with [planned 2019 improvements](https://reactjs.org/blog/2018/11/27/react-16-roadmap.html), there are plenty of others view layers we can migrate to, without gutting our entire app. Next makes this somewhat trickier, but since it's mostly a light wrapper around Webpack, there is essentially no Next-specific code (just a bit in pages/_app.js and pages/_document.js). Migrating from Next won't be an issue, we would just lose some of the tooling benefits. 8. Typescript: static typing, syntax more familiar to OO-language devs (interfaces, types, classes). 9. Really amazing debug, tooling. React debug tools natively included in Chrome for instance. First class support for JSX (React-wrapped HTML) in popular IDE's, most obviously Visual Studio Code. ## Tech TL;DR; Mainly React. React should take about a day to learn well enough to make contributions. Guide: https://reactjs.org/docs/introducing-jsx.html. ```jsx; # Renders Hello World; # Biggest annoyance (may go away in 2019) is that ""class"" is not a valid tag (reserved by React); export default function SomePage() {; const name = 'Alex'. # Renders ""Hello Alex""; return (; <div className='some-class'> Hello {name} </div>; ); }; ```. ## Challenges; 1. Auth ; Authentication is tricky, but not for any reason specific to React, Next, Node. Server-side rendered apps tie the web app to the resource server; as such it's easier to hide sensitive information. . Mobile and desktop apps have dealt with this for 2 decades. We should build a robust infrastructure, and not one that requires server-rendered web pages for security. Currently it seems Auth0 may not be the best choice: it does not interface for us with third-party API's; requires us to either insecurely store 3rd party access tokens (with at least 1 extra round trip), or altogether proxy all third",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:5607,learn,learn,5607,https://hail.is,https://github.com/hail-is/hail/pull/4931,1,['learn'],['learn']
Usability,"s"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.4.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12358:1223,guid,guide,1223,https://hail.is,https://github.com/hail-is/hail/pull/12358,1,['guid'],['guide']
Usability,"s"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.6.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90029a6933bd3a60""><code>da4f3c3</code></a> [DOCS] Add 8.5.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elast",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:1222,guid,guide,1222,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['guid'],['guide']
Usability,"s"">elasticsearch-spark-20_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.6.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html</a></p>; <h2>Elasticsearch Hadoop 8.6.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:1222,guid,guide,1222,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['guid'],['guide']
Usability,"s"">elasticsearch-spark-30_2.12's releases</a>.</em></p>; <blockquote>; <h2>Elasticsearch Hadoop 8.4.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:1222,guid,guide,1222,https://hail.is,https://github.com/hail-is/hail/pull/12319,1,['guid'],['guide']
Usability,"s). [//]: # (snyk:metadata:{""prId"":""4c874ad7-563f-49cd-9773-8b9f1095e36c"",""prPublicId"":""4c874ad7-563f-49cd-9773-8b9f1095e36c"",""dependencies"":[{""name"":""certifi"",""from"":""2021.10.8"",""to"":""2023.7.22""},{""name"":""cryptography"",""from"":""3.3.2"",""to"":""41.0.6""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-CRYPTOGRAPHY-3172287"",""SNYK-PYTHON-CRYPTOGRAPHY-3314966"",""SNYK-PYTHON-CRYPTOGRAPHY-3315324"",""SNYK-PYTHON-CRYPTOGRAPHY-3315328"",""SNYK-PYTHON-CRYPTOGRAPHY-3315331"",""SNYK-PYTHON-CRYPTOGRAPHY-3315452"",""SNYK-PYTHON-CRYPTOGRAPHY-3315972"",""SNYK-PYTHON-CRYPTOGRAPHY-3315975"",""SNYK-PYTHON-CRYPTOGRAPHY-3316038"",""SNYK-PYTHON-CRYPTOGRAPHY-3316211"",""SNYK-PYTHON-CRYPTOGRAPHY-5663682"",""SNYK-PYTHON-CRYPTOGRAPHY-5777683"",""SNYK-PYTHON-CRYPTOGRAPHY-5813745"",""SNYK-PYTHON-CRYPTOGRAPHY-5813746"",""SNYK-PYTHON-CRYPTOGRAPHY-5813750"",""SNYK-PYTHON-CRYPTOGRAPHY-5914629"",""SNYK-PYTHON-CRYPTOGRAPHY-6036192"",""SNYK-PYTHON-CRYPTOGRAPHY-6092044"",""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[554,704,509,454,616,584,479,509,509,509,509,589,509,691,399,479,399,539,479,616,519],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use After Free](https://learn.snyk.io/lesson/use-after-free/?loc&#x3D;fix-pr); 🦉 [Access of Resource Using Incompatible Type (&#x27;Type Confusion&#x27;)](https://learn.snyk.io/lesson/type-confusion/?loc&#x3D;fix-pr); 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:11808,Learn,Learn,11808,https://hail.is,https://github.com/hail-is/hail/pull/14148,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,s.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Sim,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10594,Simpl,Simplify,10594,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,s.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.exp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8603,Simpl,Simplify,8603,https://hail.is,https://github.com/hail-is/hail/issues/8338,2,['Simpl'],['Simplify']
Usability,s.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10539,Simpl,Simplify,10539,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"s/random.rst:27: >>> hl.eval(hl.rand_unif(0, 1)) # doctest: +NOTEST; docs/functions/random.rst:30: >>> hl.eval(hl.rand_unif(0, 1)) # doctest: +NOTEST; docs/functions/random.rst:33: >>> hl.eval(hl.array([x, x, x])) # doctest: +NOTEST; docs/functions/random.rst:42: >>> hl.eval(hl.array([a, b, c])) # doctest: +NOTEST; docs/functions/random.rst:50: >>> table.show() # doctest: +NOTEST; docs/functions/random.rst:72: >>> hl.eval(hl.rand_unif(0, 1, seed=0)) # doctest: +NOTEST; docs/functions/random.rst:75: >>> hl.eval(hl.rand_unif(0, 1, seed=0)) # doctest: +NOTEST; docs/functions/random.rst:82: >>> table.x.collect() # doctest: +NOTEST; docs/functions/random.rst:90: >>> table.x.collect() # doctest: +NOTEST; docs/functions/random.rst:98: >>> table.x.collect() # doctest: +NOTEST; docs/functions/random.rst:110: >>> hl.eval(hl.array([hl.rand_unif(0, 1), hl.rand_unif(0, 1)])) # doctest: +NOTEST; docs/functions/random.rst:114: >>> hl.eval(hl.array([hl.rand_unif(0, 1), hl.rand_unif(0, 1)])) # doctest: +NOTEST; docs/guides/basics.rst:95: >>> mt.describe() # doctest: +NOTEST; docs/guides/basics.rst:141: >>> ht.describe() # doctest: +NOTEST; docs/guides/basics.rst:164: >>> mt.s.describe() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:68: >>> mt # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:71: >>> mt.locus # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:83: >>> mt.DP.describe() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:107: >>> mt.describe() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:266: >>> mt_new.replicate_num.show() # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:299: >>> mt.aggregate_entries(hl.agg.mean(mt.GQ)) # doctest: +NOTEST; docs/hailpedia/matrix_table.rst:307: >>> mt.aggregate_entries((agg.stats(mt.DP), agg.stats(mt.GQ))) # doctest: +NOTEST; docs/hailpedia/table.rst:63: >>> ht.describe() # doctest: +NOTEST; docs/hailpedia/table.rst:102: >>> ht # doctest: +NOTEST; docs/hailpedia/table.rst:105: >>> ht.ID # doctest: +NOTEST; experimental",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4817#issuecomment-451506878:1197,guid,guides,1197,https://hail.is,https://github.com/hail-is/hail/issues/4817#issuecomment-451506878,2,['guid'],['guides']
Usability,"s://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""12691d21-0395-41b3-80d2-f212830f66ea"",""prPublicId"":""12691d21-0395-41b3-80d2-f212830f66ea"",""dependencies"":[{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.7.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""},{""name"":""urllib3"",""from"":""1.26.17"",""to"":""1.26.18""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-URLLIB3-6002459""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[531,null,null,509,384,494,496],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13873:5967,Learn,Learn,5967,https://hail.is,https://github.com/hail-is/hail/pull/13873,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"se `test-database-instance` to create a `sql-test-instance-admin-config` that inherits the credentials from the production `database-server-config`, and then copies that within the test namespace to `database-server-config`. In this change, since we are creating the server ourselves, we can just replace these with a step that creates a `database-server-config` from scratch, and then uses that for the DB pod. Overall making these changes really gave me the heebie jeebies that the test and dev namespaces have all these credentials to the CloudSQL server. I'm glad this gets rid of that. ### Accessing the database server; We use the DB pod's service DNS name as the `host` so inside Kubernetes this Just Works. The one caveat is the CI pipeline in which we run migrations in batch jobs. Those jobs need a way to reach the DB pod. I achieve this with a NodePort and then use the job's K8s credentials to resolve the node and port that the DB is on. The code I've added to do this resolution feels a bit janky, wouldn't mind some feedback on that. In terms of security, if a user job was able to somehow resolve the address of a test db, they would still not have the credentials to access it, and this is currently also the case with the production database. Nevertheless, this does raise an action item that we should only allow traffic to the k8s and DB subnets for `network=private` jobs, but I think we should make that a separate PR. ### Database creation; In order to test this properly in a dev deploy, I needed to make some changes to `create_database.py`. In main, dev deploys can't create databases. I think they should be able to, and those operations should just be idempotent. When allowing dev deploys to create databases, I hit the `ALTER USER` lines in `create_database.py` which lock out any already-deployed application, which feels silly. Instead, I create the mysql user and create the corresponding secret iff the mysql username does not already exist. ### create_initial_acco",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13030:1447,feedback,feedback,1447,https://hail.is,https://github.com/hail-is/hail/pull/13030,1,['feedback'],['feedback']
Usability,see: https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Shuffle.20issues. Not clear exactly what's wrong but switching from the cartesian join syntax to the dict join syntax resolves the issue.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5707:103,clear,clear,103,https://hail.is,https://github.com/hail-is/hail/issues/5707,1,['clear'],['clear']
Usability,"service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10100:1281,simpl,simplify,1281,https://hail.is,https://github.com/hail-is/hail/pull/10100,1,['simpl'],['simplify']
Usability,"shed to avoid using code generation abstractions (in this case, just factoring code into smaller functions), because they generate worse code.). The method is pretty simple. SNDArray shapes are now arrays of `SizeValue`, which is a sum type with cases `SizeValueDyn(Value[Long])` and `SizeValueStatic(Long)`. I don't think static sizes occur very often, but it was a simple addition. `SizeValue`s can be compared statically with `==`, or at runtime with `ceq`: the former is true only if we can prove statically that the two sizes must be equal, while the latter emits code to check equality at runtime, using static knowledge to elide dynamic checks where possible. The way we encode static knowledge that two sizes are equal is by using the same local variable to store both. The primary interface to introduce that static knowledge (other than using the same set of sizes to construct multiple SNDArrays), is the method `coerceToShape(cb: CodeBuilder, newShape: Seq[SizeValue]): SNDArrayValue`, which emits code to dynamically assert that `this.shape` agrees with `newShape`, then returns `this` with shape replaced by `newShape`. Thus, `a.coerceToShape(cb, newShape).shape == newShape` will always be true, preserving the static knowledge about the shape of `a`. As a simple example, `gemm` verifies its inputs with (simplifying to the case with no transposes); ```; val Seq(m, n) = C.shapes; val k = A.shapes(1); A.assertHasShape(cb, FastIndexedSeq(m, k), errMsg); B.assertHasShape(cb, FastIndexedSeq(k, n), errMsg); ```; If we call this with; ```; val m, n, k = \\ compute expected dim sizes. \\ emit dynamic size checks once; val A_ = A.coerceToShape(cb, IndexedSeq(m, k)); val B_ = B.coerceToShape(cb, IndexedSeq(k, n)); val C_ = C.coerceToShape(cb, IndexedSeq(m, n)). \\ this generates no new dynamic shape checks; SNDArray.gemm(cb, A, B, C); ```; then we can emit one set of runtime shape assertions, and further calls to methods with shape preconditions generate no new runtime assertions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10783:1575,simpl,simple,1575,https://hail.is,https://github.com/hail-is/hail/pull/10783,2,['simpl'],"['simple', 'simplifying']"
Usability,"simpler:; ```; In [12]: import hail as hl; ...: ; ...: t1kg = hl.utils.range_matrix_table(1,1); ...: t1kg = t1kg.key_rows_by(locus=hl.locus(hl.str(t1kg.row_idx), t1kg.row_idx), alleles=['A','T']); ...: t1kg = hl.split_multi(t1kg); ...: t1kg._force_count_rows(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4527#issuecomment-429050886:0,simpl,simpler,0,https://hail.is,https://github.com/hail-is/hail/issues/4527#issuecomment-429050886,2,['simpl'],['simpler']
Usability,"simpler:; ```; In [16]: import hail as hl; ...: ; ...: t1kg = hl.utils.range_matrix_table(1,1); ...: t1kg = t1kg.key_rows_by(locus=hl.locus(hl.str(t1kg.row_idx+1), t1kg.row_idx+1), alleles=['A','T']); ...: t1kg.write('/tmp/foo.mt', overwrite=True); 2018-10-11 13:42:55 Hail: INFO: Coerced sorted dataset; 2018-10-11 13:42:55 Hail: INFO: wrote 1 items in 1 partitions to /tmp/foo.mt; ^[[A; In [17]: import hail as hl; ...: ; ...: t1kg = hl.read_matrix_table('/tmp/foo.mt'); ...: t1kg = hl.split_multi(t1kg); ...: t1kg._force_count_rows(); ```; error:; ```; FatalError: HailException: optimization changed type!; before: Matrix{global:Struct{},col_key:[col_idx],col:Struct{col_idx:Int32},row_key:[[locus,alleles]],row:Struct{row_idx:Int32,locus:Locus(GRCh37),alleles:Array[String],a_index:Int32,was_split:Boolean,old_locus:Locus(GRCh37),old_alleles:Array[String]},entry:Struct{}}; after: Matrix{global:Struct{},col_key:[col_idx],col:Struct{col_idx:Int32},row_key:[[locus,alleles]],row:Struct{row_idx:Int32,locus:Locus(GRCh37),alleles:Array[String],a_index:Int32,was_split:Boolean,old_locus:Locus(GRCh37),old_alleles:Array[String]},entry:Struct{}}; ```; describe:; ```; In [18]: import hail as hl; ...: ; ...: t1kg = hl.read_matrix_table('/tmp/foo.mt').describe(); ...: ; ----------------------------------------; Global fields:; None; ----------------------------------------; Column fields:; 'col_idx': int32 ; ----------------------------------------; Row fields:; 'row_idx': int32 ; 'locus': locus<GRCh37> ; 'alleles': array<str> ; ----------------------------------------; Entry fields:; None; ----------------------------------------; Column key: ['col_idx']; Row key: ['locus', 'alleles']; ----------------------------------------; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4527#issuecomment-429051397:0,simpl,simpler,0,https://hail.is,https://github.com/hail-is/hail/issues/4527#issuecomment-429051397,2,['simpl'],['simpler']
Usability,simplified IRM toHailBlockMatrix,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2542:0,simpl,simplified,0,https://hail.is,https://github.com/hail-is/hail/pull/2542,2,['simpl'],['simplified']
Usability,simplified compiler interface,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3157:0,simpl,simplified,0,https://hail.is,https://github.com/hail-is/hail/pull/3157,2,['simpl'],['simplified']
Usability,simplified python normalization logic in pca,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2529:0,simpl,simplified,0,https://hail.is,https://github.com/hail-is/hail/pull/2529,2,['simpl'],['simplified']
Usability,simplify aggregators,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3570:0,simpl,simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/3570,2,['simpl'],['simplify']
Usability,simplify error handling logic,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1888:0,simpl,simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/1888,2,['simpl'],['simplify']
Usability,simplify index.html,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6047:0,simpl,simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/6047,2,['simpl'],['simplify']
Usability,simplify scalar types in expression language,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/614:0,simpl,simplify,0,https://hail.is,https://github.com/hail-is/hail/issues/614,2,['simpl'],['simplify']
Usability,simplify type checking of entry_fields,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3778:0,simpl,simplify,0,https://hail.is,https://github.com/hail-is/hail/pull/3778,2,['simpl'],['simplify']
Usability,"so I can remove the computeEigenvalues option and just always return them, but I'm less clear on the loadings. @tpoterba are you suggesting that I can remove the computeLoadings option because the computation is lazy? Does passing the KeyTable object through to python count as ""using"", though?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2454#issuecomment-348580540:88,clear,clear,88,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348580540,2,['clear'],['clear']
Usability,"sorry, I think I wasn't clear -- you can put them in globals when doing `mt.localize_entries` by passing both the `entries_field_name` and `columns_array_field_name` params.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9121#issuecomment-662700219:24,clear,clear,24,https://hail.is,https://github.com/hail-is/hail/issues/9121#issuecomment-662700219,2,['clear'],['clear']
Usability,"sorry, wasn't clear. I don't think it's trivial to figure out what a no-args checkpoint should do, but it IS trivial to make that change back-compatibly when we do.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5528#issuecomment-469468966:14,clear,clear,14,https://hail.is,https://github.com/hail-is/hail/pull/5528#issuecomment-469468966,2,['clear'],['clear']
Usability,"specific Hail Query functionality, let's mirror that structure. Let's move REGENIE and any non-Python dependencies of it into `hailtop/batch/genetics/regenie`. Sure. > How is the Dockerfile meant to be used? As written it doesn't appear that it would work because there doesn't exist any regenie source code to COPY in. It's meant to create a Regenie docker image that we could use. It's a copy of the regenie c++ repo's dockerfile, with the removal of the ENTRYPOINT /usr/local/bin/regenie, so that I could issue a command that included an executable, which is convenient to give me the ability to check that intermediate files are actually created (wc, ls) by batch, and because that seems more idiomatic for batch. I don't think there is a published regenie image, but docker hub is down so can't double check. . You're right, I shouldn't have deleted the bulk of the repo, kept as is. Didn't want to deal with submodules. > I've made some other in-line comments in the python file. It's not clear to me how all those other files are related to the python files and I'm a bit uncomfortable adding a whole directory with a LICENSE file, especially when not all the files in the directory fall under that license (e.g. the regenie py file) and moreover the license makes claims about things linking to BGEN, which none of our code here does. The license is only contained within the folder with the licensed files. In a previous conversation with Nate/Cotton, if we use any open-source software, best to keep those files segregated, alongside their license (license must be kept alongside the code, easier to see the demarcation if in a separate folder). > We have some BGEN files for testing in the Hail src/test/resources. I already have an example provided. The example folder contains the config for that, and the regenie folder contains the example. We need an example that has a known result, and regenie's c++ repo conveniently provides that. This is what the regenie/regenie folder contains.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9194#issuecomment-668357987:1323,clear,clear,1323,https://hail.is,https://github.com/hail-is/hail/pull/9194#issuecomment-668357987,2,['clear'],['clear']
Usability,"sses that backslash and newline to the shell. In Make 3.81, the `\` was also required but the newline and backslash *are not passed* to the shell. In other words: in 3.81, backslash-newline is always replaced with a space and in 4.0, backslash-newline is replaced with a space *except on recipe lines in which case it is necessary to indicate the recipe continues but it is also passed literally to the shell*. The docs page you linked directly addresses our use case and suggests we put the command inside of a make variable (thus triggering normal backslash-newline rules rather than the special recipe line rules). > Sometimes you want to split a long line inside of single quotes, but you don’t want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1080,simpl,simple,1080,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324,2,['simpl'],['simple']
Usability,"stacked on #7446. This is the first step toward broad integration of the timer throughout the compiler. This gives us output like:; ```; 2019-11-06 18:44:11 root: INFO: Timer: all timings:; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- FoldConstants : 5.811ms, total 29.474ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ExtractIntervalFilters : 21.579ms, total 51.305ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- Simplify : 38.711ms, total 90.246ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ForwardLets : 58.138ms, total 148.873ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ForwardRelationalLets : 4.892ms, total 154.106ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- PruneDeadFields : 70.932ms, total 225.284ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- FoldConstants : 2.673ms, total 228.575ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ExtractIntervalFilters : 6.413ms, total 235.357ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- Simplify : 4.736ms, total 240.359ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ForwardLets : 38.152ms, total 278.793ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- ForwardRelationalLets : 3.185ms, total 282.285ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAndEvaluate -- Optimize -- PruneDeadFields : 25.086ms, total 307.692ms, tagged coverage 0.0; 2019-11-06 18:44:11 root: INFO: Time taken for CompileAn",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7476:567,Simpl,Simplify,567,https://hail.is,https://github.com/hail-is/hail/pull/7476,1,['Simpl'],['Simplify']
Usability,"stacked on 3 other ci2 PRs. - add heal logic; - add job log endpoint; - some simplifications: PRs have a watched branch target (which has a sha) and a source sha, but don't need the source branch. Got rid of FQSHA.; - Ran by hand, seems to work. Will add tests back once build is actually doing something non-trivial.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5814:77,simpl,simplifications,77,https://hail.is,https://github.com/hail-is/hail/pull/5814,1,['simpl'],['simplifications']
Usability,stacked on: https://github.com/hail-is/hail/pull/5812 (which should hopefully go in soon?). simplified aioclient (added HTTP verb helper methods); changed cancel and close to PATCH endpoints; client side Batch object carries attributes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5826:92,simpl,simplified,92,https://hail.is,https://github.com/hail-is/hail/pull/5826,1,['simpl'],['simplified']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a7873eb46985d849286ab89fa0a51f8b5374e02e""><code>a7873eb</code></a> Update index.adoc (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2000"">#2000</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2002"">#2002</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/9f44fe66d0ff82f18a13a38cae6abf3f72183a94""><code>9f44fe6</code></a> Bump to version 8.4.3</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/c9e3b114b98bb0e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:4078,guid,guide,4078,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a7873eb46985d849286ab89fa0a51f8b5374e02e""><code>a7873eb</code></a> Update index.adoc (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2000"">#2000</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2002"">#2002</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/9f44fe66d0ff82f18a13a38cae6abf3f72183a94""><code>9f44fe6</code></a> Bump to version 8.4.3</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/c9e3b114b98bb0e340555311c82e2d9f32c880b6""><code>c9e3b11</code></a> [DOCS] Add 8.4.2 release n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:4156,guid,guide,4156,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a7873eb46985d849286ab89fa0a51f8b5374e02e""><code>a7873eb</code></a> Update index.adoc (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2000"">#2000</a>) (<a href=""https://github-red",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:3752,guid,guide,3752,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a7873eb46985d849286ab89fa0a51f8b5374e02e""><code>a7873eb</code></a> Update index.adoc (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2000"">#2000</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2002"">#2002</a>)</li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:3830,guid,guide,3830,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:3426,guid,guide,3426,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html</a></p>; <h2>Elasticsearch Hadoop 8.1.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/ela",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:3504,guid,guide,3504,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:3100,guid,guide,3100,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html</a></p>; <h2>Elasticsearch Hadoop 8.2.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:3178,guid,guide,3178,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:2774,guid,guide,2774,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html</a></p>; <h2>Elasticsearch Hadoop 8.2.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:2852,guid,guide,2852,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:2448,guid,guide,2448,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html</a></p>; <h2>Elasticsearch Hadoop 8.2.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:2526,guid,guide,2526,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:2122,guid,guide,2122,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html</a></p>; <h2>Elasticsearch Hadoop 8.2.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/eshadoop-8.2.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.2/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:2200,guid,guide,2200,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:1796,guid,guide,1796,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html</a></p>; <h2>Elasticsearch Hadoop 8.3.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:1874,guid,guide,1874,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:1470,guid,guide,1470,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.3.html</a></p>; <h2>Elasticsearch Hadoop 8.4.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.2.html</a></p>; <h2>Elasticsearch Hadoop 8.4.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.1.html</a></p>; <h2>Elasticsearch Hadoop 8.4.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.4/eshadoop-8.4.0.html</a></p>; <h2>Elasticsearch Hadoop 8.3.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.3.html</a></p>; <h2>Elasticsearch Hadoop 8.3.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.2.html</a></p>; <h2>Elasticsearch Hadoop 8.3.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/eshadoop-8.3.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.3/esh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:1548,guid,guide,1548,https://hail.is,https://github.com/hail-is/hail/pull/12319,2,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90029a6933bd3a60""><code>da4f3c3</code></a> [DOCS] Add 8.5.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2045"">#2045</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2050"">#2050</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/79d592abdce1cd90845d153afab8b66069e2a172""><code>79d592a</code></a> [DOCS] Add 8.5.2 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2042"">#2042</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2049"">#2049</a>)</li>; <li><a href=""https://github.com/elastic/elasticsea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:1796,guid,guide,1796,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/e665cd918aa8d0ba7806b92e16881edb96180d48""><code>e665cd9</code></a> Update Spark to 3.2.3 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2056"">#2056</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2057"">#2057</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/07380b0e17c7d908d50d59fc69ac2953adfa5a0d""><code>07380b0</code></a> Use DRA repository for build-tools dependencies</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/77bce30bfefb39c39bd34a6f147b17fb0df4701c""><code>77bce30</code></a> Bump to version 8.6.1</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/92ac2d5e61b7b8c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:2122,guid,guide,2122,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90029a6933bd3a60""><code>da4f3c3</code></a> [DOCS] Add 8.5.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2045"">#2045</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2050"">#2050</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/79d592abdce1cd90845d153afab8b66069e2a172""><code>79d592a</code></a> [DOCS] Add 8.5.2 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2042"">#2042</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2049"">#2049</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/712f518822ff281abdd6f83c2e0ea97857dbf6ba""><code>712f518</cod",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:1874,guid,guide,1874,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/e665cd918aa8d0ba7806b92e16881edb96180d48""><code>e665cd9</code></a> Update Spark to 3.2.3 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2056"">#2056</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2057"">#2057</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/07380b0e17c7d908d50d59fc69ac2953adfa5a0d""><code>07380b0</code></a> Use DRA repository for build-tools dependencies</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/77bce30bfefb39c39bd34a6f147b17fb0df4701c""><code>77bce30</code></a> Bump to version 8.6.1</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/92ac2d5e61b7b8cc16b6a9f29ad1454497f604ba""><code>92ac2d5</code></a> [DOCS] Add 8.6.0 release n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:2200,guid,guide,2200,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90029a6933bd3a60""><code>da4f3c3</code></a> [DOCS] Add 8.5.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2045"">#2045</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2050"">#2050</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/79d592abdce1cd90845d153afab8b660",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:1470,guid,guide,1470,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/e665cd918aa8d0ba7806b92e16881edb96180d48""><code>e665cd9</code></a> Update Spark to 3.2.3 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2056"">#2056</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2057"">#2057</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/07380b0e17c7d908d50d59fc69ac2953adfa5a0d""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:1796,guid,guide,1796,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90029a6933bd3a60""><code>da4f3c3</code></a> [DOCS] Add 8.5.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2045"">#2045</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2050"">#2050</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/79d592abdce1cd90845d153afab8b66069e2a172""><code>79d592a</code></a> [DOCS] Add 8.5.2 release notes (<a href=""ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:1548,guid,guide,1548,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/e665cd918aa8d0ba7806b92e16881edb96180d48""><code>e665cd9</code></a> Update Spark to 3.2.3 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2056"">#2056</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2057"">#2057</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/07380b0e17c7d908d50d59fc69ac2953adfa5a0d""><code>07380b0</code></a> Use DRA repository for build-tools dependencies</li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:1874,guid,guide,1874,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html</a></p>; <h2>Elasticsearch Hadoop 8.6.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/e665cd918aa8d0ba7806b92e16881edb96180d48""><code>e665cd9</code></a> Update Spark to",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:1470,guid,guide,1470,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['guid'],['guide']
Usability,"stic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.1.html</a></p>; <h2>Elasticsearch Hadoop 8.6.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.6/eshadoop-8.6.0.html</a></p>; <h2>Elasticsearch Hadoop 8.5.3</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.3.html</a></p>; <h2>Elasticsearch Hadoop 8.5.2</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/e665cd918aa8d0ba7806b92e16881edb96180d48""><code>e665cd9</code></a> Update Spark to 3.2.3 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:1548,guid,guide,1548,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['guid'],['guide']
Usability,style guide is very out of date,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3067:6,guid,guide,6,https://hail.is,https://github.com/hail-is/hail/issues/3067,2,['guid'],['guide']
Usability,"sure, seems clearer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12213#issuecomment-1254048690:12,clear,clearer,12,https://hail.is,https://github.com/hail-is/hail/pull/12213#issuecomment-1254048690,2,['clear'],['clearer']
Usability,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0MmRjMDIwMC02MDI1LTQ1M2QtYWUxNC00NDRlZjM5MmU4NTciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjQyZGMwMjAwLTYwMjUtNDUzZC1hZTE0LTQ0NGVmMzkyZTg1NyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""42dc0200-6025-453d-ae14-444ef392e857"",""prPublicId"":""42dc0200-6025-453d-ae14-444ef392e857"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.17"",""to"":""1.26.18""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-6002459""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[496],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13854:3444,Learn,Learn,3444,https://hail.is,https://github.com/hail-is/hail/pull/13854,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3OWQ3MTdiYy05MThjLTRlMjctOGQ2OC0xNTNhNWIxZGFmM2YiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijc5ZDcxN2JjLTkxOGMtNGUyNy04ZDY4LTE1M2E1YjFkYWYzZiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""79d717bc-918c-4e27-8d68-153a5b1daf3f"",""prPublicId"":""79d717bc-918c-4e27-8d68-153a5b1daf3f"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.17"",""to"":""1.26.18""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-6002459""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[496],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13850:3442,Learn,Learn,3442,https://hail.is,https://github.com/hail-is/hail/pull/13850,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4MmZhNTRjZC0yOGI4LTQ3OTUtYWFjNy02MDE0NjY3NjMwNTUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjgyZmE1NGNkLTI4YjgtNDc5NS1hYWM3LTYwMTQ2Njc2MzA1NSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""82fa54cd-28b8-4795-aac7-601466763055"",""prPublicId"":""82fa54cd-28b8-4795-aac7-601466763055"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.16"",""to"":""1.26.17""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-5926907""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13771:3360,Learn,Learn,3360,https://hail.is,https://github.com/hail-is/hail/pull/13771,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxNGQyZDIxMi00ZjI4LTQ0OGEtYWRkNS02NThkNDEwNzQxZDYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE0ZDJkMjEyLTRmMjgtNDQ4YS1hZGQ1LTY1OGQ0MTA3NDFkNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""14d2d212-4f28-448a-add5-658d410741d6"",""prPublicId"":""14d2d212-4f28-448a-add5-658d410741d6"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.17"",""to"":""1.26.18""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-6002459""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[496],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13847:3360,Learn,Learn,3360,https://hail.is,https://github.com/hail-is/hail/pull/13847,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxOGU4YzI4Yi1kYWQ0LTQ5ZDUtOTExNi04NjFkYTdkODk5OTYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE4ZThjMjhiLWRhZDQtNDlkNS05MTE2LTg2MWRhN2Q4OTk5NiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""18e8c28b-dad4-49d5-9116-861da7d89996"",""prPublicId"":""18e8c28b-dad4-49d5-9116-861da7d89996"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.16"",""to"":""1.26.17""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-5926907""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13773:3444,Learn,Learn,3444,https://hail.is,https://github.com/hail-is/hail/pull/13773,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiNzM0YmY4Ni1mNzQyLTQyMjMtOWVlYS1lNGU3ZjNmMTVlYWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3MzRiZjg2LWY3NDItNDIyMy05ZWVhLWU0ZTdmM2YxNWVhYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b734bf86-f742-4223-9eea-e4e7f3f15eac"",""prPublicId"":""b734bf86-f742-4223-9eea-e4e7f3f15eac"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.16"",""to"":""1.26.17""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-5926907""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13772:3374,Learn,Learn,3374,https://hail.is,https://github.com/hail-is/hail/pull/13772,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiODhmOTA3Ny02ZjlmLTRiZjEtYjFiYy0yZjNkNTE1MDEwYWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI4OGY5MDc3LTZmOWYtNGJmMS1iMWJjLTJmM2Q1MTUwMTBhYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b88f9077-6f9f-4bf1-b1bc-2f3d515010aa"",""prPublicId"":""b88f9077-6f9f-4bf1-b1bc-2f3d515010aa"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.16"",""to"":""1.26.17""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-5926907""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13783:3436,Learn,Learn,3436,https://hail.is,https://github.com/hail-is/hail/pull/13783,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"t all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmNDI4YzVjNi05NmZmLTQ1ZTMtYjY4ZC0zYzU5NjY3MjA3MGUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImY0MjhjNWM2LTk2ZmYtNDVlMy1iNjhkLTNjNTk2NjcyMDcwZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""f428c5c6-96ff-45e3-b68d-3c596672070e"",""prPublicId"":""f428c5c6-96ff-45e3-b68d-3c596672070e"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.17"",""to"":""1.26.18""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-6002459""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[496],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13851:3436,Learn,Learn,3436,https://hail.is,https://github.com/hail-is/hail/pull/13851,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"t array *must* be the JAR URL and the SHA-1 is confusing. Instead, there are now two keys in a JVM process specification:; 1. `jar_spec`, which may be either `{""type"": ""jar_url"", ""value"": ""gs://..../abc123....jar""}` or `{""type"":""git_revision"", ""value"": ""abc123...""}`.; 2. `argv`, an opaque list of strings which are passed, by the JVMEntryway, along with a few more args, to `is.hail.backend.service.Main`. The `Main` class dispatches to either `ServiceBackendSocketAPI2` or the `Worker` based on the first element of `argv`. Each class expects different contents in `argv` that suits its needs. Second, I completely eliminated the HAIL_SHA/revision from the Worker and Hail Query Java code. This was only ever used as unique name for the JAR. Instead, I just use the full JAR URL as a unique name for the JAR. If you need to defeat the cache, just create a new git commit before running `make -C query ipython`. If defeating the cache becomes a common problem, we can add a ""reload_jar"" parameter or similar to the job spec. Third, I renamed `push-jar` in `query/Makefile` to `upload-query-jar` to mirror the build.yaml step. Fourth, I embraced the use of `NAMEPSACE` in `query/Makefile` instead of relying on the minor hack that our laptop usernames match our namespace names. This does mean you need to always specify NAMESPACE when uploading a jar. Finally, a pleasant outcome of this change is the elimination of a bunch of conditional build.yaml logic in the service backend tests!. I think this will simplify the use of Hail Query by Australia et al. because I've isolated the use of hail-specific data to `query/Makefile`. If there's a way to access the relevant global-config variables from `query/Makefile`, I can also fix the `query/Makefile` to be deployment-independent. cc: @lgruen @illusional @tpoterba . [1] For our default namespace deployment, `gs://hail-query/jars/{GIT_REVISION}.jar`. In general, `{HAIL_QUERY_STORAGE_URI}{HAIL_QUERY_ACCEPTABLE_JAR_SUBFOLDER}/{GIT_REVISION}.jar`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11645:2942,simpl,simplify,2942,https://hail.is,https://github.com/hail-is/hail/pull/11645,1,['simpl'],['simplify']
Usability,"t dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzNTM4YWIwOC03Yzk4LTRjMDUtOTQ0Ny0yMjYwYjliNjhmY2IiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjM1MzhhYjA4LTdjOTgtNGMwNS05NDQ3LTIyNjBiOWI2OGZjYiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3538ab08-7c98-4c05-9447-2260b9b68fcb"",""prPublicId"":""3538ab08-7c98-4c05-9447-2260b9b68fcb"",""dependencies"":[{""name"":""pillow"",""from"":""9.5.0"",""to"":""10.0.1""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-PILLOW-5918878""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown""],""priorityScoreList"":[null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13708:3292,Learn,Learn,3292,https://hail.is,https://github.com/hail-is/hail/pull/13708,4,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"t for centralized assets governance 2) QuickSight Q now supports public embedding 3) New Termination protection flag to mitigate accidental deletes 4) Athena data sources now accept a custom IAM role 5) QuickSight supports connectivity to Databricks</li>; <li>api-change:<code>sagemaker</code>: [<code>botocore</code>] Added DisableProfiler flag as a new field in ProfilerConfig</li>; <li>api-change:<code>servicecatalog</code>: [<code>botocore</code>] This release 1. adds support for Principal Name Sharing with Service Catalog portfolio sharing. 2. Introduces repo sourced products which are created and managed with existing SC APIs. These products are synced to external repos and auto create new product versions based on changes in the repo.</li>; <li>api-change:<code>ssm-sap</code>: [<code>botocore</code>] AWS Systems Manager for SAP provides simplified operations and management of SAP applications such as SAP HANA. With this release, SAP customers and partners can automate and simplify their SAP system administration tasks such as backup/restore of SAP HANA.</li>; <li>api-change:<code>stepfunctions</code>: [<code>botocore</code>] Update stepfunctions client to latest version</li>; <li>api-change:<code>transfer</code>: [<code>botocore</code>] Adds a NONE encryption algorithm type to AS2 connectors, providing support for skipping encryption of the AS2 message body when a HTTPS URL is also specified.</li>; </ul>; <h1>1.26.12</h1>; <ul>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Adds a new value (WEB_COMPUTE) to the Platform enum that allows customers to create Amplify Apps with Server-Side Rendering support.</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow simplifies the preparation and cataloging of SaaS data into the AWS Glue Data Catalog where your data can be discovered and accessed by AWS analytics and ML services. AppFlow now also supports data field partitioning and file size optimization to improve query performance a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:4734,simpl,simplify,4734,https://hail.is,https://github.com/hail-is/hail/pull/12498,2,['simpl'],['simplify']
Usability,"t of this is that the `allowAllocations` bit is no longer hereditary. A `ChildStagedRegion` can be converted into a `ParentStagedRegion`, and hence another generation of children can be created, but now doing so requires explicitly specifying `allowAllocations` for the new generation. In emit, this happens at stream consumers, where the allocation strategy will be read off the PType of the stream. The full hierarchy is now:; * `StagedRegion` - The root class is the type for passing around unowned regions. Besides writing into the region, the method `asRoot` allows converting to a `RootStagedRegion` by specifying `allowAllocations`; * `ParentStagedRegion` - for passing around un-owned regions which allow creating child regions. Has a `allowSubregions` flag which encodes whether child regions are actually separate run-time regions.; * `ChildStagedRegion` - un-owned regions which know their parent, allowing methods like `copyToParent` and `createSiblingRegion`; * `OwnedStagedRegion` - owned regions are always children; adds methods like `free`, `clear`, `giveToParent`; * The concrete classes `RealOwnedStagedRegion` and `DummyOwnedStagedRegion`. These encode whether the parent region is real or dummy. They are intended to be private to the `StagedRegion` implementation. ### Update. At first, I restricted methods like `copyTo` and `giveTo` to copy/move to either a parent or sibling region. That is easy to verify correctness, but turned out to be too restrictive. I had been assuming an invariant that the `elementRegion` of a stream is always a direct child of the `outerRegion`. But this invariant is violated by some nested stream nodes like `StreamFlatMap` and `StreamGroupBy`. Take `StreamFlatMap`: the `outerRegion` of the inner stream should be the `eltRegion` of the outer stream, which is created and owned by the FlatMap code. But the `eltRegion` of the final flatMapped stream is passed in from the consumer, so is not a child of the inner stream's `outerRegion`. It is a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9401:2410,clear,clear,2410,https://hail.is,https://github.com/hail-is/hail/pull/9401,1,['clear'],['clear']
Usability,t.fireChannelRead(AbstractChannelHandlerContext.java:336); 	io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267); 	; 	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100); 	at org.apache.spark.SparkContext.cancelAllJobs(SparkContext.scala:2209); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at sparklyr.Invoke.invoke(invoke.scala:139); 	at sparklyr.StreamHandler.handleMethodCall(stream.scala:123); 	at sparklyr.StreamHandler.read(stream.scala:66); 	at sparklyr.BackendHandler.channelRead0(handler.scala:51); 	at sparklyr.BackendHandler.channelRead0(handler.scala:4); 	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:10913,Simpl,SimpleChannelInboundHandler,10913,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['Simpl'],['SimpleChannelInboundHandler']
Usability,"t/chardet/commit/57abbca866a41758f7c26e1bb26a0126e28575c2""><code>57abbca</code></a> Rebased and cleaned up version of UTF-16/32 BE/LE PR (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/206"">#206</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/eca9558cf7569c1f7689bd66e5aaf965a56e903c""><code>eca9558</code></a> Fix missing black formatting</li>; <li><a href=""https://github.com/chardet/chardet/commit/f1f9d4280e11fb3a9b2d9eaf1827dac9263cb1cb""><code>f1f9d42</code></a> slight increase in performance (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/252"">#252</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/f9ef56cfd6c9b24b9c865eae6dc2285c67ffb75c""><code>f9ef56c</code></a> Use Python-3 super() syntax in Latin1Prober (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/240"">#240</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/c5e5d5a8f1b6e135a8bffd8d60b2f726bb168339""><code>c5e5d5a</code></a> Simple maintenance improvements (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/244"">#244</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/49b8341f507bed68f7d3ff7138bb97047a0e04f0""><code>49b8341</code></a> Configure setuptools using the declarative syntax in setup.cfg (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/239"">#239</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/5c73bfcdf819251d1a1d0de672e34480ebafbe1f""><code>5c73bfc</code></a> Run all pre-commit hooks on pull requests (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/236"">#236</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/chardet/chardet/compare/4.0.0...5.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=chardet&package-manager=pip&previous-version=4.0.0&new-v",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12107:4747,Simpl,Simple,4747,https://hail.is,https://github.com/hail-is/hail/pull/12107,1,['Simpl'],['Simple']
Usability,"tHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14751** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14751?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14747** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14686](https://github.com/hail-is/hail/pull/14686) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @grohli and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14747#issuecomment-2438734907:1740,Learn,Learn,1740,https://hail.is,https://github.com/hail-is/hail/pull/14747#issuecomment-2438734907,1,['Learn'],['Learn']
Usability,"tHub because a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14751?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14751** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14751?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * **#14747** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14686](https://github.com/hail-is/hail/pull/14686) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @grohli and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14751#issuecomment-2457987492:1740,Learn,Learn,1740,https://hail.is,https://github.com/hail-is/hail/pull/14751#issuecomment-2457987492,1,['Learn'],['Learn']
Usability,take a look and tell me if this helps simplify this trigger,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13372#issuecomment-1670091762:38,simpl,simplify,38,https://hail.is,https://github.com/hail-is/hail/pull/13372#issuecomment-1670091762,2,['simpl'],['simplify']
Usability,"tation of `ArrayFilter`. There is basically no nice way to implement filter otherwise without introducing some significant code duplication.; - ~~The stream ""parameter"", as well as the `Empty` return, are not very useful for the basic streams in this PR. However, they simplify the implementation of `ArrayFlatMap` (aka ""composing"" two parameterized streams).~~ NOTE (to Patrick): I decided to abandon the ""empty"" return idea in favor of just providing ""default states"" that always yield empty streams. **Implementation Notes**. - The implementation makes great use of Scala's type system. Most of the streams are implemented first in a very type aware manner, where it is easy to reason about the types of data flowing in and out, before being instantiated with EmitTriplets and Envs which don't hold very much type information. For instance, we have the following helper for `map`:; ```scala; Parameterized[P, A].map(f: A => B): Parameterized[P, B]; ```; The emitter instantiates P = `Any`, A = `EmitTriplet`, B = `EmitTriplet` :/. - Complex streams will have non trivial control flow and jumps. Therefore `init` and `step` both take `JoinPointBuilder`s and return `Code[Ctrl]`, to indicate that they may create join points and do jumps. - I've utilized a cute continuation passing style trick in multiple functions. Instead of `init` ""returning"" `Missing`/`Start(s0)` (which is impossible, since these are compile time data structures; they won't exist during JVM runtime), init takes a continuation `k: Init[S] => Code[Ctrl]`, which it must call with one of these values. To use `init`, you can simply provide a pattern matching lambda, which closely resembles the syntax you would normally use to pattern match on a returned value, e.g. (from `contMap`):; ```scala; self.init(mb, jb, param) {; case Missing => k(Missing); case Start(s) => Code(setup, k(Start(s))); }; ```; This technique actually cleans up the implementation significantly, especially moving forward to more complicated streams.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7228:3330,simpl,simply,3330,https://hail.is,https://github.com/hail-is/hail/pull/7228,1,['simpl'],['simply']
Usability,"tch_id, jobs.job_id) IN (SELECT batch_id, job_id FROM job_attributes WHERE `key` = 'pheno' AND `value` = '50'); -> GROUP BY jobs.batch_id, jobs.job_id; -> ORDER BY jobs.batch_id, jobs.job_id ASC; -> LIMIT 50;; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | 1 | SIMPLE | batches | NULL | const | PRIMARY | PRIMARY | 8 | const | 1 | 100.00 | Using temporary; Using filesort |; | 1 | SIMPLE | job_attributes | NULL | ref | PRIMARY,job_attributes_key_value | job_attributes_key_value | 1081 | const,const,const | 3057 | 100.00 | Using where |; | 1 | SIMPLE | jobs | NULL | eq_ref | PRIMARY,jobs_batch_id_state_always_run_cancelled | PRIMARY | 12 | const,batch.job_attributes.job_id | 1 | 100.00 | NULL |; | 1 | SIMPLE | job_attributes | NULL | eq_ref | PRIMARY,job_attributes_key_value | PRIMARY | 314 | const,batch.job_attributes.job_id,const | 1 | 100.00 | NULL |; | 1 | SIMPLE | aggregated_job_resources | NULL | ref | PRIMARY | PRIMARY | 12 | const,batch.job_attributes.job_id | 5 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 302 | batch.aggregated_job_resources.resource | 1 | 100.00 | NULL |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; 6 rows in set, 1 warning (0.01 sec); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9870:1623,SIMPL,SIMPLE,1623,https://hail.is,https://github.com/hail-is/hail/pull/9870,5,['SIMPL'],['SIMPLE']
Usability,"te(); r.getNewRegion()`. As a demonstration of how this should work, this PR does convert `EmitStream.{toArray, write}` to use `eltRegion` correctly, which are used in the consumer nodes `ToArray`, `ArraySort`, `ToSet`, `ToDict`, and `GroupByKey`. Going forward, the plan is to convert the rest of the consumer and producer nodes, before converting the transformer nodes (which both consume and produce streams), as correctness can only be tested on pipelines in which all nodes have been converted. ### Semantics. A stream producer is passed two regions from its consumer: `outerRegion` and `eltRegion`. The node being emitted does not own either region, so may not free/clear them. The only thing a producer may do with either region is to put data in them, by writing directly to them or by giving/sharing ownership of a producer-owned region to them. Consumers' contract:; * The lifetime of `outerRegion` must contain the lifetime of the producer stream, i.e. `outerRegion` must be valid before the producer's `setup0` is called, and must still be valid when the producer's `close0` is called. Thus a producer may use `outerRegion` to store state that persists between elements, or it may use a region it owns itself.; * When the producer's `pull` is called, `eltRegion` must be valid (it does not need to be valid for setup/close). Producers' contract:; * When the consumer's `push` is called, the pushed value must be owned by either `outerRegion` or `eltRegion` (really `eltRegion`; using `outerRegion` is correct but unnecessarily extends the lifetime of the value). This can be accomplished by writing directly to the consumer's region, or by giving/sharing ownership of a producer-owned region to it. Thus the consumer may assume the pushed value is valid until it frees/clears `eltRegion`. If the consumer needs the value to live longer, it must deep-copy the value to another region. These allow us to reason about (and, in principle, to prove) the correctness of each node independently.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9106:2759,clear,clears,2759,https://hail.is,https://github.com/hail-is/hail/pull/9106,1,['clear'],['clears']
Usability,"ted dependencies (we have a lot!). See [here](https://mill-build.com/mill/Intro_to_Mill.html) and [here](https://mill-build.com/mill/Builtin_Commands.html) for more details. ## IntelliJ setup. To import from scratch:; * delete any `.idea` directories in the hail root, or `hail/` subdirectory (you could try skipping this, but you're on your own); * in the `hail/` subdirectory, you can also delete `.classpath`, `.gradle`, `.project`, `.settings/`, `build/` (we still use this for a few things, but most of it is dead gradle output, and it's safe to delete it all and start clean), `build.gradle`, `gradle/`, `gradlew`, `gradlew.bat`, `pgradle`, `settings.gradle`; * run `mill mill.bsp.BSP/install` to generate the `.bsp` config directory (bsp is the Build Server Protocol); * In IntelliJ, go to File->Open, and choose the hail root directory; * When the project is open, go to File->Project Structure; * in the Project pane, set an sdk (8 or 11), and set the language level to 8; * in the Modules pane, delete the existing root module, click the plus sign -> Import Module, choose the `hail/` subdirectory, and choose ""Import module from external model"" and `BSP`; * you should see a progress bar at the bottom as it imports the project; * when it's done, quit and reopen IntelliJ. There should now be a bsp icon (two bars with two arrows between them) on the right, where the gradle elephant used to be. Just like before, sometimes you'll need to click the ""reload"" icon in there if things get wonky.; * if it says ""scalafmt configuration detected"", go ahead and enable the formatter. ## Metals setup. * delete any `.metals` directories; * open the hail repo in VSCode (even if you won't use VSCode, this seems to be the best way to get metals set up initially); * it should ask you to import a Mill build; * when that finishes, at the bottom it should say it's connected to a Bloop build server. In general, I think using Mill as the BSP directly will work best, but I don't have much experience t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14147:4240,progress bar,progress bar,4240,https://hail.is,https://github.com/hail-is/hail/pull/14147,1,['progress bar'],['progress bar']
Usability,"ted dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxNjVmNDVkMi00ZDM3LTRmNzAtOGU1OC00OGIxOGJhNmVlOTgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE2NWY0NWQyLTRkMzctNGY3MC04ZTU4LTQ4YjE4YmE2ZWU5OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""165f45d2-4d37-4f70-8e58-48b18ba6ee98"",""prPublicId"":""165f45d2-4d37-4f70-8e58-48b18ba6ee98"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[479,616],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14203:3858,Learn,Learn,3858,https://hail.is,https://github.com/hail-is/hail/pull/14203,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ted dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkYWIzNjU3Mi1hNTUwLTQwY2EtYThjZi0zN2ZjODljOWI1OGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImRhYjM2NTcyLWE1NTAtNDBjYS1hOGNmLTM3ZmM4OWM5YjU4YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""dab36572-a550-40ca-a8cf-37fc89c9b58a"",""prPublicId"":""dab36572-a550-40ca-a8cf-37fc89c9b58a"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6050294"",""SNYK-PYTHON-CRYPTOGRAPHY-6126975""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[265,402],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14201:3808,Learn,Learn,3808,https://hail.is,https://github.com/hail-is/hail/pull/14201,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"ted, involved `@overload`, and did not seem to help me reason about that function. I presumed the root cause was that the Resource class had an insufficient interface. Here is how I understand what that function was trying to achieve: We need to track the set of resources that are produced by, produced-by-and-later-consumed, and consumed by a job:. 1. ""Produced by"" corresponds to `Job._valid`.; 2. ""Produced-by-and-later-consumed"" corresponds to `Job._internal_outputs` and `Job._external_outputs`.; 3. ""Consumed by"" corresponds to `Job._inputs`. There is also `Job._mentioned` which I do not fully understand but which does not use `_add_resource_to_set`. There is an important distinction between the latter two and the first kind of resource set. The latter two must be what I am now calling `SingleResource`s. These are actual single files that need to be uploaded or downloaded. In contrast the ""produced by"" set (and, I think `Job._mentioned`) might include `ResourceGroup`s which are composite: one or more `SingleResource`s that must be transmitted as a group. For example, a VCF file and its TBI index file must always be transmitted as a group, even if a job only references one of those two files. That's the essential functionality of a `ResourceGroup`. I introduced three operations to `Resource` which I think make this system simpler:. 1. `get_resource_group`: if a `Resource` is a group or a member thereof, return it. 2. `component_resources`: if a `Resource` is composite, return the components, otherwise just return the resource itself. 3. `bonded_resources`: the minimum set of resources that must be transmitted if this resource is transmitted. In particular, a member of a resource group returns itself and the other resources in the group. A resource group just returns its components. We can now add a type annotation which requires (2) and (3) to be sets of `SingleResource`. In; particular, (2) and (3) are concrete files that can be copied as opposed to groups thereof.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14319:1652,simpl,simpler,1652,https://hail.is,https://github.com/hail-is/hail/pull/14319,1,['simpl'],['simpler']
Usability,"tely crucial piece of configuration before you can do anything interesting and configuring a temp bucket is something that `hailctl` can easily be very opinionated about. Container registry… I feel like there's harder questions there, and you can run a lot of cool batches before having to worry about provisioning your own. It's also not actually a part of the hailctl config (unless something has changed recently) so it feels a little unusual in this flow. I still think that it is helpful to set people up with an AR and keep them from footguns, but maybe that can go in a separate command that the initial init command points to once you're done? Something along the lines of ""if you get to the point where you need to upload custom container images, you can use hailctl to set up a registry""?. Another thing that gives me a little pause is the wording around google projects. I get that you need one to create a bucket, but I think we should just make sure to steer clear of the implication that you are ""selecting a GCP project to use for Hail Batch"", because that implies some link or ownership that isn't there. But I think there's a quick fix here: for a given resource that we *are* creating for hail use, like the temp bucket, ask for the name first and then ask which project it should be created in, using the projects listed in gcloud as choices with the option to write in your own. ### Regarding number of checks; I think it'd be good to avoid warnings when possible. From looking at this I see a pattern of; 1. Ask a leading question; 2. Emit a warning if the user selects the alternative option instead of the suggested option. I think I would prefer instead to ask a leading question and in the prompt explain why the alternative option might be undesirable. Then when they make a decision just move on. On a broader note, I think we should focus on having good documentation and linking to it over having perfectly thorough ; explanations in the CLI. At some point in an interacti",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1648633012:1786,clear,clear,1786,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1648633012,2,['clear'],['clear']
Usability,"than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0M2ViODJhZS04ZDkwLTRjZWUtYjIzMS01ZDMyYmZiZWM4OWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjQzZWI4MmFlLThkOTAtNGNlZS1iMjMxLTVkMzJiZmJlYzg5YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""43eb82ae-8d90-4cee-b231-5d32bfbec89a"",""prPublicId"":""43eb82ae-8d90-4cee-b231-5d32bfbec89a"",""dependencies"":[{""name"":""jinja2"",""from"":""3.1.2"",""to"":""3.1.3""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JINJA2-6150717""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[556],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14136:3407,Learn,Learn,3407,https://hail.is,https://github.com/hail-is/hail/pull/14136,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlOTc1OTMyYy1kNmNhLTQ0NTUtYmU4ZC04NzY1ZGY0MTZjMWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU5NzU5MzJjLWQ2Y2EtNDQ1NS1iZThkLTg3NjVkZjQxNmMxYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e975932c-d6ca-4455-be8d-8765df416c1c"",""prPublicId"":""e975932c-d6ca-4455-be8d-8765df416c1c"",""dependencies"":[{""name"":""jinja2"",""from"":""3.1.2"",""to"":""3.1.3""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JINJA2-6150717""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[556],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14141:3725,Learn,Learn,3725,https://hail.is,https://github.com/hail-is/hail/pull/14141,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlYTQ5ODFkZC02M2FmLTQ4YzYtYTIwMC05NjkyZjg2ZTlhNjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImVhNDk4MWRkLTYzYWYtNDhjNi1hMjAwLTk2OTJmODZlOWE2MiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ea4981dd-63af-48c6-a200-9692f86e9a62"",""prPublicId"":""ea4981dd-63af-48c6-a200-9692f86e9a62"",""dependencies"":[{""name"":""jinja2"",""from"":""3.1.2"",""to"":""3.1.3""}],""packageManager"":""pip"",""projectPublicId"":""b7c31419-ec34-40f1-8bc6-ad8303fb329b"",""projectUrl"":""https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-JINJA2-6150717""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[556],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Cross-site Scripting (XSS)](https://learn.snyk.io/lesson/xss/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14140:3281,Learn,Learn,3281,https://hail.is,https://github.com/hail-is/hail/pull/14140,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"that one is simple:; ```; def get_old_mu_data() -> hl.Table:; old_mu_data = hl.import_table('gs://gnomad-resources/constraint/source/fordist_1KG_mutation_rate_table.txt',; delimiter=' ', impute=True); return old_mu_data.transmute(context=old_mu_data['from'], ref=old_mu_data['from'][1],; alt=old_mu_data.to[1]).key_by('context', 'ref', 'alt'); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4314#issuecomment-420405426:12,simpl,simple,12,https://hail.is,https://github.com/hail-is/hail/issues/4314#issuecomment-420405426,2,['simpl'],['simple']
Usability,"the current structure is easier to follow:. 1. Fit the null model.; 2. If wald, assume the beta for the genotypes is zero and use the rest of the parameters from the null model fit to compute the score (i.e. the gradient of the likelihood). Recall calculus: gradient near zero => value near the maximum. Return: this is the test.; 3. Otherwise, fit the full model starting at the null fit parameters.; 4. Test the ""goodness"" of this new & full fit. ---. Poisson regression is similar but with a different likelihood function and gradient thereof. Notice that I `key_cols_by()` to indicate to Hail that the order of the cols is irrelevant (the result is a locus-keyed table after all). This is necessary at least until #12753 merges. I think it's generally a good idea though: it indicates to Hail that the ordering of the columns is irrelevant, which is potentially useful information for the optimizer!. ---. Both logistic and Poisson regression can benefit from BLAS3 by running at least the score test for multiple variants at once. ---. I'll attach an image in the comments, but I spend ~6 seconds compiling this trivial model and ~140ms testing it. ```python3; import hail as hl; mt = hl.utils.range_matrix_table(1, 3); mt = mt.annotate_entries(x=hl.literal([1, 3, 10, 5])); ht = hl.poisson_regression_rows(; 'wald', y=hl.literal([0, 1, 1, 0])[mt.col_idx], x=mt.x[mt.col_idx], covariates=[1], max_iterations=2); ht.collect(); ```. I grabbed some [sample code from; scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PoissonRegressor.html) for Poisson regression (doing a score test rather than a wald test) and timed it. It takes ~8ms. So we're 3 orders of magnitude including the compiler, and ~1.2 orders of magnitude off without the compiler. Digging in a bit:; - ~65ms for class loading.; - ~15ms for region allocation.; - ~20ms various little spots. Leaving about 40ms strictly executing generated code That's about 5x which is starting to feel reasonable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12793:2487,learn,learn,2487,https://hail.is,https://github.com/hail-is/hail/pull/12793,2,['learn'],['learn']
Usability,"the error in #4529 was:; ```; ERROR: Create cluster failed!; ERROR: gcloud crashed (AttributeError): 'Operation' object has no attribute 'details'. If you would like to report this issue, please run the following command:; gcloud feedback. To check gcloud for common problems, please run the following command:; gcloud info --run-diagnostics; Traceback (most recent call last):; File ""/home/hail/.conda/envs/hail/bin/cluster"", line 11, in <module>; sys.exit(main()); File ""/home/hail/.conda/envs/hail/lib/python3.6/site-packages/cloudtools/__main__.py"", line 76, in main; start.main(args); File ""/home/hail/.conda/envs/hail/lib/python3.6/site-packages/cloudtools/start.py"", line 237, in main; check_call(cmd); File ""/home/hail/.conda/envs/hail/lib/python3.6/subprocess.py"", line 291, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['gcloud', 'beta', 'dataproc', 'clusters', 'create', 'ci-test-nhxn5owt', '--image-version=1.2-deb9', '--metadata=MINICONDA_VERSION=4.4.10,JAR=gs://hail-ci-0-1/temp/ba8134f0f121a49ea96d7dd30ea3be330802cfef/784ab2796878cd2f825c554e80d29d304f21d0f4/hail.jar,ZIP=gs://hail-ci-0-1/temp/ba8134f0f121a49ea96d7dd30ea3be330802cfef/784ab2796878cd2f825c554e80d29d304f21d0f4/hail.zip', '--properties=spark:spark.driver.memory=41g,spark:spark.driver.maxResultSize=0,spark:spark.task.maxFailures=20,spark:spark.kryoserializer.buffer.max=1g,spark:spark.driver.extraJavaOptions=-Xss4M,spark:spark.executor.extraJavaOptions=-Xss4M,hdfs:dfs.replication=1', '--initialization-actions=gs://dataproc-initialization-actions/conda/bootstrap-conda.sh,gs://hail-common/cloudtools/init_notebook1.py,gs://hail-common/vep/vep/vep85-loftee-init-docker.sh', '--master-machine-type=n1-highmem-8', '--master-boot-disk-size=100GB', '--num-master-local-ssds=0', '--num-preemptible-workers=0', '--num-worker-local-ssds=0', '--num-workers=2', '--preemptible-worker-boot-disk-size=40GB', '--worker-boot-disk-size=40', '--worker-machine-type=n1-highmem-8', '--",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4530#issuecomment-431996515:230,feedback,feedback,230,https://hail.is,https://github.com/hail-is/hail/issues/4530#issuecomment-431996515,2,['feedback'],['feedback']
Usability,the getting_started docs now point to using conda envs with the environment.yml. Thanks for the feedback @verdurin!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2978#issuecomment-378608438:96,feedback,feedback,96,https://hail.is,https://github.com/hail-is/hail/issues/2978#issuecomment-378608438,2,['feedback'],['feedback']
Usability,"the local_path_uri function simply prepends 'file://' to the path provided. This leads to an odd situation were a relative path is transformed into 'file://relative/path/to/log', which parses as:. SCHEME: file; HOST : relative; PATH : path/to/log. To fix this, compute the real path of the log file and use that as the path for the local_path_uri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13340:28,simpl,simply,28,https://hail.is,https://github.com/hail-is/hail/pull/13340,1,['simpl'],['simply']
Usability,"the number of used bits is a (statically known) constant. We use this to ensure the number of used bits is known statically.; 	; Types:; - missingness; - treat as a type constructor `optional<T>`, i.e. base types don't encode missingness. Emits a single bit in the encoding. Can invert this bit to control whether missing values come first or last in the ordering. If missing, nothing is emitted after.; - sort-order; - treat reversing the default ordering as a type constructor `reverse<T>`; - simply inverts the encoding bitwise; - primitive types; - same as in datafusion, encoding has same size as original type; - signed integers - flip the sign bit; - floating point numbers - if sign bit is set, invert all bits, otherwise only flip the sign bit; - arrays; - before each element and after last element, emit continuation bit (0 if no more elements); - pad before each element. This prevents a variable number of missing bits packing into a byte; - strings and byte-arrays; - simply use null-terminated strings (being careful to do this in a unicode-safe way); - structs; - simply concatenate element encodings. safe because codes are prefix-free; - key structs; - support variable length ""interval endpoints""; - e.g. for a key type `struct<t1, t2>`, the interval `[{a}, {a, b})` contains all keys with first field `a` and second field less than `b`. We break it into two ""interval endpoints"", `({a}, -1)` and `({a, b}, -1)`, which consist of a struct value which is a prefix of the key struct type, and a ""sign"". In this case, both endpoints ""lean left"".; - needed for working with partitioners at runtime; - like an array with fixed but heterogenous types and a max length; - before each element and after last element, emit two continuation bits; - `00` - end of key, leans left (less than all longer keys with this prefix); - `01` - continue, or after last key field of actual key value (not interval endpoint); - unambiguous because key value can't terminate early, and can't continue past",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14396:2118,simpl,simply,2118,https://hail.is,https://github.com/hail-is/hail/issues/14396,2,['simpl'],['simply']
Usability,the other way was clearly backwards,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3033:18,clear,clearly,18,https://hail.is,https://github.com/hail-is/hail/pull/3033,1,['clear'],['clearly']
Usability,"the same, a few changes were made to how options are handled. We first introduce a bit of terminology. In a shell command invocation like `$ cmd a -o c`, `a`, `-o` and `c` are called parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842:1102,undo,undo,1102,https://hail.is,https://github.com/hail-is/hail/pull/9842,1,['undo'],['undo']
Usability,"the script may be clearer and easier to extend if written in python, too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5910#issuecomment-484684296:18,clear,clearer,18,https://hail.is,https://github.com/hail-is/hail/pull/5910#issuecomment-484684296,2,['clear'],['clearer']
Usability,"the tunneled connection to the destination server. Users who rely on; defining their proxy credentials in the URL are <em>strongly</em> encouraged to upgrade; to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy; credentials once the change has been fully deployed.</p>; <p>Users who do not use a proxy or do not supply their proxy credentials through; the user information portion of their proxy URL are not subject to this; vulnerability.</p>; <p>Full details can be read in our <a href=""https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q"">Github Security Advisory</a>; and <a href=""https://nvd.nist.gov/vuln/detail/CVE-2023-32681"">CVE-2023-32681</a>.</p>; </li>; </ul>; <h2>v2.30.0</h2>; <h2>2.30.0 (2023-05-03)</h2>; <p><strong>Dependencies</strong></p>; <ul>; <li>; <p>⚠️ Added support for urllib3 2.0. ⚠️</p>; <p>This may contain minor breaking changes so we advise careful testing and; reviewing <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html</a>; prior to upgrading.</p>; <p>Users who wish to stay on urllib3 1.x can pin to <code>urllib3&lt;2</code>.</p>; </li>; </ul>; <h2>v2.29.0</h2>; <h2>2.29.0 (2023-04-26)</h2>; <p><strong>Improvements</strong></p>; <ul>; <li>Requests now defers chunked requests to the urllib3 implementation to improve; standardization. (<a href=""https://redirect.github.com/psf/requests/issues/6226"">#6226</a>)</li>; <li>Requests relaxes header component requirements to support bytes/str subclasses. (<a href=""https://redirect.github.com/psf/requests/issues/6356"">#6356</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/blob/main/HISTORY.md"">requests's changelog</a>.</em></p>; <blockquote>; <h2>2.31.0 (2023-05-22)</h2>; <p><strong>Security</strong></p>; <ul>; <li>; <p>Versions of Requests between v2.3.0 and v2.30.0 are vulnerab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:1977,guid,guide,1977,https://hail.is,https://github.com/hail-is/hail/pull/13091,6,['guid'],['guide']
Usability,"this by explaining the query against the DB:; ```; > kssh admin-pod; > mysql; mysql> use batch;; mysql> EXPLAIN SELECT attempts.*; -> FROM attempts; -> INNER JOIN jobs ON attempts.batch_id = jobs.batch_id AND attempts.job_id = jobs.job_id; -> LEFT JOIN instances ON attempts.instance_name = instances.name; -> WHERE attempts.start_time IS NOT NULL; -> AND attempts.end_time IS NULL; -> AND ((jobs.state != 'Running' AND jobs.state != 'Creating') OR jobs.attempt_id != attempts.attempt_id); -> AND instances.`state` = 'active'; -> ORDER BY attempts.start_time ASC; -> LIMIT 300\G;. *************************** 1. row ***************************; id: 1; select_type: SIMPLE; table: instances; partitions: NULL; type: ALL; possible_keys: PRIMARY; key: NULL; key_len: NULL; ref: NULL; rows: 1150201; filtered: 10.00; Extra: Using where; Using temporary; Using filesort; *************************** 2. row ***************************; id: 1; select_type: SIMPLE; table: attempts; partitions: NULL; type: ref; possible_keys: PRIMARY,attempts_instance_name; key: attempts_instance_name; key_len: 303; ref: batch.instances.name; rows: 91; filtered: 9.00; Extra: Using where; *************************** 3. row ***************************; id: 1; select_type: SIMPLE; table: jobs; partitions: NULL; type: eq_ref; possible_keys: PRIMARY,jobs_batch_id_state_always_run_cancelled,jobs_batch_id_state_always_run_inst_coll_cancelled,jobs_batch_id_update_id,jobs_batch_id_always_run_n_regions_regions_bits_rep_job_id,jobs_batch_id_ic_state_ar_n_regions_bits_rep_job_id,jobs_batch_id_job_group_id,jobs_batch_id_ic_state_ar_n_regions_bits_rep_job_group_id; key: PRIMARY; key_len: 12; ref: batch.attempts.batch_id,batch.attempts.job_id; rows: 1; filtered: 98.10; Extra: Using where; 3 rows in set, 1 warning (0.00 sec); ```. This is not great:; ```; rows: 1150201; filtered: 10.00; Extra: Using where; Using temporary; Using filesort; ```; what we want to see is a low number of rows, a high percent filtered, and somet",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14460:2235,SIMPL,SIMPLE,2235,https://hail.is,https://github.com/hail-is/hail/issues/14460,1,['SIMPL'],['SIMPLE']
Usability,tils$RichHadoopConfiguration$$using$extension(RichHadoopConfiguration.scala:226); 	at is.hail.utils.richUtils.RichHadoopConfiguration$.readFile$extension(RichHadoopConfiguration.scala:251); 	at is.hail.variant.VariantSampleMatrix$.readFileMetadata(VariantSampleMatrix.scala:72); 	at is.hail.variant.VariantSampleMatrix$.read(VariantSampleMatrix.scala:51); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:434); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:433); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.HailContext.readAll(HailContext.scala:433); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:497); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: devel-41347fd; Error summary: HailException: corrupt or outdated VDS: invalid metadata; Recreate VDS with current version of Hail.; Detailed exception:; No usable value for sample_schema; Did not find value which can be converted into java.lang.String; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2173:2800,usab,usable,2800,https://hail.is,https://github.com/hail-is/hail/pull/2173,1,['usab'],['usable']
Usability,"tm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""49ddea8a-962c-4889-b800-3d64b82a0b38"",""prPublicId"":""49ddea8a-962c-4889-b800-3d64b82a0b38"",""dependencies"":[{""name"":""aiohttp"",""from"":""3.8.6"",""to"":""3.9.0""},{""name"":""ipython"",""from"":""7.34.0"",""to"":""8.10.0""},{""name"":""jupyter-server"",""from"":""1.24.0"",""to"":""2.11.2""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""tornado"",""from"":""6.2"",""to"":""6.3.3""}],""packageManager"":""pip"",""projectPublicId"":""fa47fca0-549b-41a3-8bf7-bcda4ca9a617"",""projectUrl"":""https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-AIOHTTP-6091621"",""SNYK-PYTHON-AIOHTTP-6091622"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERSERVER-5862881"",""SNYK-PYTHON-JUPYTERSERVER-5862882"",""SNYK-PYTHON-JUPYTERSERVER-6099119"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-TORNADO-6041512""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[591,591,531,444,429,501,509,384,494,539],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Improper Input Validation](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Access Control Bypass](https://learn.snyk.io/lesson/broken-access-control/?loc&#x3D;fix-pr); 🦉 [Open Redirect](https://learn.snyk.io/lesson/open-redirect/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:7394,Learn,Learn,7394,https://hail.is,https://github.com/hail-is/hail/pull/14109,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"to be clear, the comment on default is a conversation starter, not a change request",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8164#issuecomment-591670074:6,clear,clear,6,https://hail.is,https://github.com/hail-is/hail/pull/8164#issuecomment-591670074,2,['clear'],['clear']
Usability,"to be clear, there is an option to display row fields, but it defaults to `False`. There's a lot of visual noise if you show both.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5677#issuecomment-476797101:6,clear,clear,6,https://hail.is,https://github.com/hail-is/hail/pull/5677#issuecomment-476797101,2,['clear'],['clear']
Usability,"tp://dev.hail.is/t/proposal-for-aggregators/93/3. Builds on: https://github.com/hail-is/hail/pull/3552. I still need to finish converting some tests from ExtractAggregatorSuite (they are currently commented out). Old-style aggregators (filter, map, flatMap) are expanded at toIR conversion time to ApplyAggOp and SeqOp. ApplyAggOp returns the result of the aggregation. ApplyAggOp's first argument, which must be of type TVoid, is the expression to run for each element being aggregated over. SeqOp merges a computed value into the RegionValueAggregator. I added a AggSignature that holds the AggOp, type being aggregated over and the RegionValueAggregator constructor argument types. This is stored by the ApplyAggOp and the SeqOp. @tpoterba I believe TAggregable is no longer used in the IR code and can go away when the AST gets ripped out. @danking I added some IR testing logic to TestUtils. Namely, `eval` evaluates an IR with environments, args and/or aggregations with a single call (and verifies that the interpret with and without optimization and compiler all agree). There are also functions for asserting the result of aggregations, for example:. ```; val aggSig = AggSignature(Sum(), TFloat64(), FastSeq()); assertEvalsTo(ApplyAggOp(; SeqOp(ApplyBinaryPrimOp(Multiply(), Ref(""a"", TFloat64()), Ref(""b"", TFloat64())), I32(0), aggSig),; FastSeq(), aggSig),; (FastIndexedSeq(Row(1.0, 10.0), Row(10.0, 10.0), Row(null, 10.0)), TStruct(""a"" -> TFloat64(), ""b"" -> TFloat64())),; 110.0); ```. The line:. > (FastIndexedSeq(Row(1.0, 10.0), ...), TStruct(""a"" -> TFloat64(), ""b"" -> TFloat64())),. is the IndexedSeq of values to aggregate over, along with their signature. The struct type is used to build the scope in which aggregators are evaluated. (A little noisy because of the aggregator syntax. It's noisier than I'd like it to be.). This nicely paves the way for aggregators with multi-argument seqOps (like takeBy) that were previously handled by lambdas and we didn't have a clear plan for.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3570:2045,clear,clear,2045,https://hail.is,https://github.com/hail-is/hail/pull/3570,1,['clear'],['clear']
Usability,"tps://github.com/search?q=repo%3Ajupyterlab%2Fjupyterlab+involves%3Awelcome+updated%3A2024-01-19..2024-01-30&amp;type=Issues""><code>@​welcome</code></a></p>; <!-- raw HTML omitted -->; <h2>4.0.11</h2>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/compare/v4.0.10...0708330843fd087134a239d2ad6005b1d543e246"">Full Changelog</a>)</p>; <h3>Security fixes</h3>; <ul>; <li>Potential authentication and CSRF tokens leak in JupyterLab (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-44cc-43rp-5947"">GHSA-44cc-43rp-5947</a>)</li>; <li>SXSS in Markdown Preview (<a href=""https://github.com/jupyterlab/jupyterlab/security/advisories/GHSA-4m77-cmpx-vjc4"">GHSA-4m77-cmpx-vjc4</a>)</li>; </ul>; <h3>Bugs fixed</h3>; <ul>; <li>Fixes focus indicator on input checkbox for Firefox <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15612"">#15612</a> (<a href=""https://github.com/alden-ilao""><code>@​alden-ilao</code></a>)</li>; </ul>; <h3>Documentation improvements</h3>; <ul>; <li>Fix link to yarn docs in extension migration guide <a href=""https://redirect.github.com/jupyterlab/jupyterlab/pull/15640"">#15640</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyterlab/jupyterlab/graphs/contributors?from=2023-12-29&amp;to=2024-01-19&amp;type=c"">GitHub contributors page for this release</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/e7a1af706875c8ab183101ff68b38e836181028c""><code>e7a1af7</code></a> [ci skip] Publish 4.0.12</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/69079ec413cbe6d173f0a667c15802b76423ece5""><code>69079ec</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15710"">#15710</a>: Removes Python 3.0, Notebook 5 mentions from cont",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:10920,guid,guide,10920,https://hail.is,https://github.com/hail-is/hail/pull/14218,1,['guid'],['guide']
Usability,turn back on progress bar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3142:13,progress bar,progress bar,13,https://hail.is,https://github.com/hail-is/hail/issues/3142,2,['progress bar'],['progress bar']
Usability,"ugh, this PR is quite mislabeled. This was meant to be the secondary indexing stub -- the last commit here -- but was stacked on the keyed_intersection stuff (which has merged to main in another PR) and I didn't fix up the title. I'll rebase to make this clearer as an example for us to poke at indexing for seqr, and make the warning fix in another PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12539#issuecomment-1349720433:255,clear,clearer,255,https://hail.is,https://github.com/hail-is/hail/pull/12539#issuecomment-1349720433,2,['clear'],['clearer']
Usability,"ugh. just to be clear, this is just removing the `:`s right? (to force converting to tables most of the time). but you are planning on keeping `[]` generally (maybe as shorthand if you suggest generally using `index_*`)?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4383#issuecomment-423410409:16,clear,clear,16,https://hail.is,https://github.com/hail-is/hail/pull/4383#issuecomment-423410409,2,['clear'],['clear']
Usability,"ummary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/13989b5b1253e26f3f3ee24013a3013fea1bdf73""><code>13989b5</code></a> [Storage] Fix ranged download for client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25522"">#25522</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e90af4374bfd7c139737ad2888fcd269b3023520""><code>e90af43</code></a> DataLake funny dependency (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25129"">#25129</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/cbec3383039ffeb46760268d1a8f81cf1b4d2219""><code>cbec338</code></a> [AutoRelease] t2-storagecache-2022-07-06-35884(Do not merge) (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25089"">#25089</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/dc7c5a16d39df8a8d4b838a7240e58f64fc824f2""><code>dc7c5a1</code></a> [Storage] API View Feedback For STG84 GA (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25085"">#25085</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/9f66f6bce7d777b34c03dc9a633148acd0c4f238""><code>9f66f6b</code></a> [Storage] Revert removing aiohttp dependency for storage.blob.aio (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25084"">#25084</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e40d3e1d985cee13a2e0d070fb8e04958905f468""><code>e40d3e1</code></a> [storage.blob] Remove aiohttp as dependency for storage.blob.aio (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24965"">#24965</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/7915719f211cc1217dfca6f3973a2b1f04c2e3f5""><code>7915719</code></a> [Storage] Prepare for STG83 GA release (<a href=""https://github-redirect.dependabot.com/Az",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:2524,Feedback,Feedback,2524,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['Feedback'],['Feedback']
Usability,update: took 160s on profile225 (2.0GB as .vcf.gz). The size input to LD Prune (after filtering and split-multi) is 700MB (as mt). 1KG is 16MB as an mt. There's clearly a lot of overhead for small datasets.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5078#issuecomment-452419381:161,clear,clearly,161,https://hail.is,https://github.com/hail-is/hail/pull/5078#issuecomment-452419381,2,['clear'],['clearly']
Usability,updated style guide,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1395:14,guid,guide,14,https://hail.is,https://github.com/hail-is/hail/pull/1395,2,['guid'],['guide']
Usability,"urlparse isn't really what we want for breaking down a blob storage URL. There are special characters that delimit different parts of a typical URL that don't translate to a blob. Specifically, if a blob name contains a `?` (which is totally valid if albeit horrendous), `parsed.path` will terminate before the `?` and drop the rest because it views those as query params. We really just want everything after the container to be the blob name, so we do a bit more manual work in the name of simplicity. Dan already handled this in the Google async fs but this was never changed in the azure implementation. They now resemble each other more closely.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11851:492,simpl,simplicity,492,https://hail.is,https://github.com/hail-is/hail/pull/11851,1,['simpl'],['simplicity']
Usability,"use a downstack PR is open. Once all requirements are satisfied, merge this PR as a stack <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14533?utm_source=stack-comment-downstack-mergeability-warning"" >on Graphite</a>.</b>; > <a href=""https://graphite.dev/docs/merge-pull-requests"">Learn more</a>. * **#14533** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14533?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * **#14509** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14509?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14514** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14514?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14554](https://github.com/hail-is/hail/pull/14554) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14554?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14517** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14517?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14533#issuecomment-2098889324:1740,Learn,Learn,1740,https://hail.is,https://github.com/hail-is/hail/pull/14533#issuecomment-2098889324,1,['Learn'],['Learn']
Usability,"using the; generalized cross-validation (GCV) criterion to find the tradeoff between; smoothness and proximity to data points.</li>; <li><code>scipy.stats</code> has three new distributions, two new hypothesis tests, three; new sample statistics, a class for greater control over calculations; involving covariance matrices, and many other enhancements.</li>; </ul>; <h1>New features</h1>; <h1><code>scipy.datasets</code> introduction</h1>; <ul>; <li>A new dedicated <code>datasets</code> submodule has been added. The submodules; is meant for datasets that are relevant to other SciPy submodules ands; content (tutorials, examples, tests), as well as contain a curated; set of datasets that are of wider interest. As of this release, all; the datasets from <code>scipy.misc</code> have been added to <code>scipy.datasets</code>; (and deprecated in <code>scipy.misc</code>).</li>; <li>The submodule is based on <a href=""https://www.fatiando.org/pooch/latest/"">Pooch</a>; (a new optional dependency for SciPy), a Python package to simplify fetching; data files. This move will, in a subsequent release, facilitate SciPy; to trim down the sdist/wheel sizes, by decoupling the data files and; moving them out of the SciPy repository, hosting them externally and</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/scipy/scipy/commit/dde50595862a4f9cede24b5d1c86935c30f1f88a""><code>dde5059</code></a> REL: 1.10.0 final [wheel build]</li>; <li><a href=""https://github.com/scipy/scipy/commit/7856f281b016c585b82d03723c4494bcdbdcd4a5""><code>7856f28</code></a> Merge pull request <a href=""https://redirect.github.com/scipy/scipy/issues/17696"">#17696</a> from tylerjereddy/treddy_110_final_prep</li>; <li><a href=""https://github.com/scipy/scipy/commit/205b6243c6d075d05695e7ac6d007e0f03bfbf42""><code>205b624</code></a> DOC: add missing author</li>; <li><a href=""https://github.com/scipy/scipy/c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13227:2590,simpl,simplify,2590,https://hail.is,https://github.com/hail-is/hail/pull/13227,1,['simpl'],['simplify']
Usability,"utor driver, partition 0, PROCESS_LOCAL, 4777 bytes); 2018-10-09 14:46:43 Executor: INFO: Running task 0.0 in stage 5.0 (TID 5); 2018-10-09 14:46:43 BlockManager: INFO: Found block rdd_9_0 locally; 2018-10-09 14:46:43 CodeGenerator: INFO: Code generated in 19.341759 ms; 2018-10-09 14:46:43 CodeGenerator: INFO: Code generated in 10.738625 ms; 2018-10-09 14:46:43 SparkContext: INFO: Invoking stop() from shutdown hook; 2018-10-09 14:46:43 AbstractConnector: INFO: Stopped Spark@31b6843e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2018-10-09 14:46:43 SparkUI: INFO: Stopped Spark web UI at http://10.32.119.167:4040; 2018-10-09 14:46:43 DAGScheduler: INFO: Job 3 failed: fold at RVD.scala:361, took 0.107081 s; 2018-10-09 14:46:43 DAGScheduler: INFO: ResultStage 5 (fold at RVD.scala:361) failed in 0.097 s due to Stage cancelled because SparkContext was shut down; 2018-10-09 14:46:43 LiveListenerBus: ERROR: SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@58127452); 2018-10-09 14:46:43 LiveListenerBus: ERROR: SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(3,1539121603334,JobFailed(org.apache.spark.SparkException: Job 3 cancelled because SparkContext was shut down)); 2018-10-09 14:46:43 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!; 2018-10-09 14:46:43 MemoryStore: INFO: MemoryStore cleared; 2018-10-09 14:46:43 BlockManager: INFO: BlockManager stopped; 2018-10-09 14:46:43 BlockManagerMaster: INFO: BlockManagerMaster stopped; 2018-10-09 14:46:43 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!; 2018-10-09 14:46:43 SparkContext: INFO: Successfully stopped SparkContext; 2018-10-09 14:46:43 ShutdownHookManager: INFO: Shutdown hook called; 2018-10-09 14:46:43 ShutdownHookManager: INFO: Deleting directory /private/var/folders/w4/9k0my8pd6113d61pq05fvqlr0000gn/T/spark-02128b51-f37e-4798-84bb-d3e3819e51be; ```; </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:49349,clear,cleared,49349,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['clear'],['cleared']
Usability,"v oauth2 key. Alternatively, we should create a separate login flow doesn't use oauth2 but uses production credentials.; - and interactively tested notebook2 creating notebooks (but haven't tested the config of the notebooks themselves). Summary of changes:; - auth service that handles login/logout flow via Google OAuth2 and user verification via /userdata endpoint. Web sessions are stored in the aiohttp_session cookie (encrypted), command line sessions are stored in tokens file: tokens.json. Token files potentially contain tokens for multiple namespaces (e.g. default and cseed in the example workflow above).; - sessions are now started in the database, table `users.sessions`, which have session_id (32 random bytes, base64-encoded), user_id, creation time and max_age (for expiry); - I write notebook2 to use our async stack; - added a notion of ""deploy config"" that has three parts: location (one of external, k8s or gce), default_namespace (the default namespace to find services), and service_namespace (of overrides for specific services ... so e.g. you can use the default auth with batch in cseed). deploy_config main function is to construct URLs to contact services.; - JWTs and the jwt secret key are gone.; - Simplified configuration/data file handling by enforcing consistent defaults. File paths should be determined by the location, which is loaded from HAIL_DEPLOY_CONFIG_FILE. If that isn't set, I look in ~/.hail/deploy_config.json, and if that doesn't exist, use external/default. All other configuration files are determined by the location: the tokens file is in ~/.hail/tokens.json for external, in /user-tokens/tokens.json for k8s, etc. What remains:; - what a `hailctl dev config` to set the (local) deploy config for switching between default and dev namespaces.; - salt session IDs in the database; - dev oauth2 key; - add `dev deploy` service override option so we can use production/default auth with services deployed in dev namespaces. These are all pretty easy.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6892#issuecomment-527970251:1972,Simpl,Simplified,1972,https://hail.is,https://github.com/hail-is/hail/pull/6892#issuecomment-527970251,1,['Simpl'],['Simplified']
Usability,"ved the code). - `.strip()` the GitHub token in case there are newlines. - print the SHA being deployed in the log statement. - add `hail-ci-build.sh` to CI, which just invokes `make test-in-cluster`(which in turn runs `test-in-cluster.sh`. - `test-in-cluster.sh` copies the secrets for testing to the expected locations and exposes the pod in which it is running with an internal service, recent changes to `site` [redirect sub URLs of ci.test.is to services named using this scheme](https://github.com/hail-is/hail/blob/master/site/hail.nginx.conf#L38-L41). GitHub uses these URLs to send updates to the CI under test about the watched repositories. - `test-locally.sh` now installs `../batch` into the currently running `pip` before testing (NB: if you edit batch and run the tests without committing the changes you've made to batch, this will pass tests but fail when pushed to a PR!). - `test-locally.sh` activates the `hail-ci` conda environment itself because it was not being propagated from the `Makefile`. I don't know why, but this is a simple fix. - `test-locally.sh` starts the ci after the repository is created. CI will print error messages if a watched repository doesn't exist. - `test/test-ci.py` now uses access tokens for all interaction with GitHub, previously it relied on the latent privileges that I and Cotton had in our environments. - `test/test-ci.py` uses a temporary, but not automatically deleted, directory when the environment variable `IN_CLUSTER` is set to `true` (to which it is set by `test-in-cluster.sh`). I noticed that, when running in a batch job pod, if an error occurred, `pytest` failed to print any error information and instead failed because the current working directory no longer existed. I found very little information on Google about this. It seems safe to not clean up temporary directories created in the batch job pod because pods are ephemeral. cc: @cseed. Assigning to @tpoterba since he has the most context on this stuff other than Cotton.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4474:1517,simpl,simple,1517,https://hail.is,https://github.com/hail-is/hail/pull/4474,1,['simpl'],['simple']
Usability,"vert data to/from JSON and to/from the JVM (by way of this ""encoded"" representation which is a binary one). The details of that are not super important to this PR, but you might take a peek to understand the change. The main issue here is that in Python, you can't write:; ```; {[1]}; ```; Because sets must contain ""hashable"" data. Python lists are not hashable because they're mutable. This is transitively a problem. For example, the following also fails with the same error because the list inside the tuple is mutable thus the tuple is not (safely) hashable.; ```; {(""tuples"", ""are"", ""immutable"", [""lists"", ""are"", ""not""])}; ```. Hail's internal language is fully immutable, so every type can be placed inside a set (or used as the keys of a dict). When we convert from Hail's internal representation to Python, we cannot use mutable types in hashable positions. Unfortunately, we also need to maintain backwards compatibility with the way the code currently works. You can see this pretty clearly in the difference between `hl.agg.collect` and `hl.agg.collect_as_set`:; ```; t = hl.utils.range_table(1); t = t.annotate(ls = [1, 2, 3]); collected_ls = t.aggregate(hl.agg.collect(t.ls)); collected_as_set_ls = t.aggregate(hl.agg.collect_as_set(t.ls)); ```; `collected_ls` should be `[[1, 2, 3]]` whereas `collected_as_set_ls` necessarily uses hashable types: `{frozenlist([1, 2, 3])}`. Things are particularly subtle with dictionaries whose keys must always be hashable and whose values need only be hashable if the dictionary itself must be hashable. For example:; ```; t = hl.utils.range_table(1); # we're trying to create {[""hello""]: [""goodbye""]}, but that; # would fail because a python dictionary can't have a list; # as a key; t = t.annotate(x = hl.dict([([""hello""], [""goodbye""])])); in_list = t.aggregate(hl.agg.collect(t.x)); in_set = t.aggregate(hl.agg.collect_as_set(t.x)); ```; `in_list` will be `[{frozenlist([""hello""]): [""goodbye""]}]` (because we should be backwards compatible with th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12265:1433,clear,clearly,1433,https://hail.is,https://github.com/hail-is/hail/pull/12265,1,['clear'],['clearly']
Usability,"w Intersphinx role :rst:role:<code>external</code> for explict; lookup in the external projects, without resolving to the local project.</li>; </ul>; <h2>Bugs fixed</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9866"">#9866</a>: autodoc: doccomment for the imported class was ignored</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/88f9647a223c77a29153683b49bc29852ed80721""><code>88f9647</code></a> Bump to 4.4.0 final</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/fc428ad324ef38402f1e93b38c61cd6348980ed2""><code>fc428ad</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9822"">#9822</a> from jakobandersen/intersphinx_role</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/5d595ec0c4294f45f3138c4c581b84c39cae5e29""><code>5d595ec</code></a> intersphinx role, simplify role_name check</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/6ee0ecbe40ab8a3251538409cf35ffcc04765bfa""><code>6ee0ecb</code></a> intersphinx role, simplify role name matching</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/3bf8bcd6e151a78b0dd003a3e76ff4c65566b6e6""><code>3bf8bcd</code></a> intersphinx role, update docs</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/c11b109d591a74f87de071ec4782ac3ab782ea38""><code>c11b109</code></a> intersphinx role: :external+inv:<strong>: instead of :external:inv+</strong>:</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/9589a2bc0531598cdd69f260f2f2c2dbc5852d6e""><code>9589a2b</code></a> intersphinx role, remove redundant method</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/941db550f02d76ee2b93300584ac85dc599d21e6""><code>941db55</code></a> intersphinx role, fix flake8 warnings</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11522:5873,simpl,simplify,5873,https://hail.is,https://github.com/hail-is/hail/pull/11522,2,['simpl'],['simplify']
Usability,"we're thinking that GitHub issues should just be bug reports / problems with a clear fix that can be addressed with a maximum of a few commits. Feature requests should be in the forum, development discuss in in dev.hail.is or Zulip dev channel.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8009#issuecomment-613667435:79,clear,clear,79,https://hail.is,https://github.com/hail-is/hail/issues/8009#issuecomment-613667435,2,['clear'],['clear']
Usability,"web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. There are two pieces. `nav-top.html`; contains the nav bar HTML elements. `nav-bottom.html` contains the JavaScript; code that hooks the search bar up to Algolia and sets the active page in the; navigation. I believe JavaScript which modifies the HTML DOM is traditionally; placed at the bottom of the `body` tag so that it is executed *after* the HTML; DOM is mostly rendered. That's why the navigation/search bar is split across two; files. I also load the `prism.js` source code highlighter at the end of the; body. All of the non-docs pages are defined by html files in `pages`. Each one of; these is a Jinja2 template which derives from the base template. `make render`; converts every template in `pages` into a real HTML file in `www`. Check out; 404.html for a simple example. Once I had the site in working order, I turned my eyes to the docs. I converted; `docs/_templates/layout.html`, the base template for our docs, into a template; which derives from `site/templates/base.html`. That ensures everyone is using; the same CSS, the same navigation/search bar, same icon set, etc. Convincing; Sphinx to work like this was actually really easy because Sphinx already uses; Jinja2 templates! I just added site's templates folder to the Sphinx; `templates_path`. I eliminated a few conditionals that are only relevant if your docs are also; rendered on RTD's server, which ours are not. Finally, in order to experiment quickly with this, I changed site's Makefile to; add some rules that keep the automatically render the site and docs in response; to file edits.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9597:2770,simpl,simple,2770,https://hail.is,https://github.com/hail-is/hail/pull/9597,1,['simpl'],['simple']
Usability,what if you do a simpler benchmark: `filter_genotypes('g.gq > 20')`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1292#issuecomment-275122784:17,simpl,simpler,17,https://hail.is,https://github.com/hail-is/hail/pull/1292#issuecomment-275122784,2,['simpl'],['simpler']
Usability,"when plotting graphs</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11801"">#11801</a> [component: bokehjs] [BUG] Log axis figures don't render if they're not visible at start</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11807"">#11807</a> [component: bokehjs] Work around issues with initialization-time change discovery</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11808"">#11808</a> Don't unnecessarily update node/edge renderers in graphs</li>; </ul>; </li>; <li>; <p>tasks:</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11613"">#11613</a> [component: docs] Cache-bust custom.css for docs</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11791"">#11791</a> [component: docs] Update issue template to use new GH forms</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11761"">#11761</a> [component: docs] Clarify use of color in first steps guide</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11762"">#11762</a> [component: docs] Replace slash with backslash for PS commands</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11767"">#11767</a> [component: bokehjs] Upgrade jquery-ui to resolve security concerns</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11781"">#11781</a> [component: examples] fix transform jitter example</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11786"">#11786</a> bokeh 2.4.2 backports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11790"">#11790</a> [component: build] Bryanv/pin sphinx 42</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11797"">#11797</a> Add OS to bokeh info</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11805"">#11805</a> More 3.0 -&gt; 2.4.2 backports</li>; <li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11540:1717,guid,guide,1717,https://hail.is,https://github.com/hail-is/hail/pull/11540,1,['guid'],['guide']
Usability,whoops this clearly broke batch somehow,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13053#issuecomment-1548722663:12,clear,clearly,12,https://hail.is,https://github.com/hail-is/hail/pull/13053#issuecomment-1548722663,2,['clear'],['clearly']
Usability,will add this to the style guide when I update it,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3065#issuecomment-370182016:27,guid,guide,27,https://hail.is,https://github.com/hail-is/hail/pull/3065#issuecomment-370182016,2,['guid'],['guide']
Usability,"wip. A few remaining tests fail. Includes a number of fixes to InferPType, InferType. Plan is to get this working before optimize, since that is the simple case, and then move to pre-simplify",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063:149,simpl,simple,149,https://hail.is,https://github.com/hail-is/hail/pull/8063,2,['simpl'],"['simple', 'simplify']"
Usability,"with the new mypy update, mypy complains if we don't use the type stubs for our dependencies. This is fixed in main (we add the type stubs) but not in the previously released pip hail, because well it's already released. One option is we decide we don't like this requirement and disable that for mypy (though I do enjoy having the type hints). The problem remains that we lint the released version with the `setup.cfg` on main, so this will fail if we ever tighten our linting. It's not clear to me why we want to lint already-released hail",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11502#issuecomment-1061947409:488,clear,clear,488,https://hail.is,https://github.com/hail-is/hail/pull/11502#issuecomment-1061947409,2,['clear'],['clear']
Usability,"writing a simple command such as read and write produces different type of error, but all related to memory issues. ; The most explicit error is: . ```; error='Cannot allocate memory' (errno=12); # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 7376207872 bytes for committing reserved memory.; ```. But also get this issue in other occasions:. ```; ExecutorLostFailure (executor 2265 exited caused by one of the running tasks) Reason: Container marked as failed: container_1481808189977_0001_01_002296 on host: gnomadpsychk-sw-wpt8.c.wgspd-147615.internal. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1481808189977_0001_01_002296; Exit code: 50; Stack trace: ExitCodeException exitCode=50:; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582); 	at org.apache.hadoop.util.Shell.run(Shell.java:479); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Container exited with a non-zero exit code 50. Driver stacktrace:; ```. Log for this last error is here: https://storage.googleapis.com/wgspd_urv/hailNEW.log. I tried different projects and get the same error, both with pyhail and native hail. I don't see the same error when running on cray.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186:10,simpl,simple,10,https://hail.is,https://github.com/hail-is/hail/issues/1186,1,['simpl'],['simple']
Usability,xpr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.is$hail$expr$ir$Optimize$$runOpt$1(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply$mcV$sp(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply(Optimize.scala:21); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.apply(Optimize.scala:20,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:11625,Simpl,Simplify,11625,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Simpl'],['Simplify']
Usability,"y keyed by locus, and removed the MatrixKeyRowsBy in combine_gvcfs. To goal here is to avoid re-buidling an re-broadcasting the partitioner once for each gVCF. We'll need to re-key at the very end. I'm not so familiar with the end of the joint calling pipeline. @chrisvittal can you take care of that?. Second, I don't repartition in TableMultiWayZipJoin if the partitioners all match (which they should in in the joint calling pipeline). For that to work right, I need allowedOverlap == 0 (or to verify the partitions are in fact disjoint). Turns out allowedOverlap wasn't being propagated in various places. I fixed that. @patrick-schultz can you look at the RVDPartitioner changes? They just look like oversights to me, but maybe there was a reason why, for example, copy and coarsen wasn't preserving allowedOverlap?. Finally, now the joint calling pipeline/test_combiner_works segfaults, ugh:. ```; $ hail -m unittest test.hail.methods.test_impex.VCFTests.test_combiner_works; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010e5fa090, pid=64905, tid=33795; #; # JRE version: Java(TM) SE Runtime Environment (8.0_45-b14) (build 1.8.0_45-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.45-b02 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # J 8877 C1 is.hail.expr.types.physical.PLocus$$anon$1.compare(Lis/hail/annotations/Region;JLis/hail/annotations/Region;J)I (117 bytes) @ 0x000000010e5fa090 [0x000000010e5f9de0+0x2b0]; #; ```. The rest of the tests pass (the other Python failures are cascaded failures from test_combiner_works, I double-checked in the hopes of finding an easier example to debug.) It is pretty clearly related to the no repartition optimization. If I disable it, test_combiner_works passes. I haven't tracked this down, but I do have one question @chrisvittal: who's responsible for freeing the inputs (that is, clearing the input regions) to multi-way zip join? I don't see where that happens.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5424:1756,clear,clearly,1756,https://hail.is,https://github.com/hail-is/hail/pull/5424,2,['clear'],"['clearing', 'clearly']"
Usability,"y, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0Y2E5NmE2ZC02MjMxLTQ1YTctYmQyOS1kYTA0ZmZhNTliYzQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjRjYTk2YTZkLTYyMzEtNDVhNy1iZDI5LWRhMDRmZmE1OWJjNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""4ca96a6d-6231-45a7-bd29-da04ffa59bc4"",""prPublicId"":""4ca96a6d-6231-45a7-bd29-da04ffa59bc4"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.2""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6210214""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[451],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14238:3441,Learn,Learn,3441,https://hail.is,https://github.com/hail-is/hail/pull/14238,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"y, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1MzAxOWZkZC04YjQwLTQ5NmUtYjRmYS0wMzA5MTAxOTBkZWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjUzMDE5ZmRkLThiNDAtNDk2ZS1iNGZhLTAzMDkxMDE5MGRlYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""53019fdd-8b40-496e-b4fa-030910190dec"",""prPublicId"":""53019fdd-8b40-496e-b4fa-030910190dec"",""dependencies"":[{""name"":""cryptography"",""from"":""42.0.2"",""to"":""42.0.4""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6261585""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14344:3447,Learn,Learn,3447,https://hail.is,https://github.com/hail-is/hail/pull/14344,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,y.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.Optimize$.is$hail$expr$ir$Optimize$$runOpt$1(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$apply$1.apply$mcV$sp(Optimize.scala:25); at is.hail.expr.ir.Optimize$$ano,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:11395,Simpl,Simplify,11395,https://hail.is,https://github.com/hail-is/hail/issues/8338,2,['Simpl'],['Simplify']
Usability,"yeah this was a simple error, forgot to do one upstream processing step",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11413#issuecomment-1050268863:16,simpl,simple,16,https://hail.is,https://github.com/hail-is/hail/issues/11413#issuecomment-1050268863,2,['simpl'],['simple']
Usability,yes much clearer. Corrected!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1423#issuecomment-281794307:9,clear,clearer,9,https://hail.is,https://github.com/hail-is/hail/pull/1423#issuecomment-281794307,2,['clear'],['clearer']
Usability,"yes, sure. I'll ask Kumar for more feedback tomorrow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7240#issuecomment-540264157:35,feedback,feedback,35,https://hail.is,https://github.com/hail-is/hail/pull/7240#issuecomment-540264157,2,['feedback'],['feedback']
Usability,"your intuition is exactly what we're doing. We look for bind and lambda AST nodes, add those to the declared scope. If we find a `top_level=False` reference not in that scope, we error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3055#issuecomment-369986005:5,intuit,intuition,5,https://hail.is,https://github.com/hail-is/hail/pull/3055#issuecomment-369986005,2,['intuit'],['intuition']
Usability,"ython-jsonschema/jsonschema/compare/v4.10.2...v4.10.3"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.2...v4.10.3</a></p>; <h2>v4.10.2</h2>; <ul>; <li>Fix a second place where subclasses may have added attrs attributes (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/982"">#982</a>).</li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.1...v4.10.2"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.1...v4.10.2</a></p>; <h2>v4.10.1</h2>; <ul>; <li>Fix Validator.evolve (and APIs like <code>iter_errors</code> which call it) for cases; where the validator class has been subclassed. Doing so wasn't intended to be; public API, but given it didn't warn or raise an error it's of course; understandable. The next release however will make it warn (and a future one; will make it error). If you need help migrating usage of inheriting from a; validator class feel free to open a discussion and I'll try to give some; guidance (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/982"">#982</a>).</li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.0...v4.10.1"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.0...v4.10.1</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/python-jsonschema/jsonschema/blob/main/CHANGELOG.rst"">jsonschema's changelog</a>.</em></p>; <blockquote>; <h1>v4.15.0</h1>; <ul>; <li>A specific API Reference page is now present in the documentation.</li>; <li><code>$ref</code> on earlier drafts (specifically draft 7 and 6) has been &quot;fixed&quot; to; follow the specified behavior when present alongside a sibling <code>$id</code>.; Specifically the ID is now properly ignored, and references are resolved; a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12163:3549,guid,guidance,3549,https://hail.is,https://github.com/hail-is/hail/pull/12163,1,['guid'],['guidance']
Usability,"| key | key_len | ref | rows | filtered | Extra |; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+-------------------------------+---------+---------------------------------------------+------+----------+-----------------------------------------------------------+; | 1 | SIMPLE | billing_project_users | NULL | index | PRIMARY | PRIMARY | 204 | NULL | 3201 | 10.00 | Using where; Using index; Using temporary; Using filesort |; | 1 | SIMPLE | batches | NULL | ref | PRIMARY,batches_deleted,batches_token,batches_user_state,batches_time_completed,batches_billing_project_state | batches_billing_project_state | 102 | batch.billing_project_users.billing_project | 519 | 25.00 | Using where |; | 1 | SIMPLE | batches_n_jobs_in_complete_states | NULL | eq_ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 1 | 100.00 | NULL |; | 1 | SIMPLE | batches_cancelled | NULL | eq_ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 1 | 100.00 | Using index |; | 1 | SIMPLE | aggregated_batch_resources | NULL | ref | PRIMARY | PRIMARY | 8 | batch.batches.id | 44 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 102 | batch.aggregated_batch_resources.resource | 1 | 100.00 | NULL |; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+-------------------------------+---------+---------------------------------------------+------+----------+-----------------------------------------------------------+; ```. New plan; ```; +----+-------------+-----------------------------------+------------+--------+-----------------+-----------------+---------+-------------------------------------------+--------+----------+----------------------------------+; | id | select_type | table | partitions | type | poss",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12049:1427,SIMPL,SIMPLE,1427,https://hail.is,https://github.com/hail-is/hail/pull/12049,1,['SIMPL'],['SIMPLE']
Usability,"},{""name"":""notebook"",""from"":""5.7.16"",""to"":""6.4.12""},{""name"":""pygments"",""from"":""2.5.2"",""to"":""2.15.0""},{""name"":""requests"",""from"":""2.27.1"",""to"":""2.31.0""},{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""},{""name"":""sphinx"",""from"":""1.8.6"",""to"":""3.3.0""},{""name"":""tornado"",""from"":""5.1.1"",""to"":""6.3.3""},{""name"":""wheel"",""from"":""0.30.0"",""to"":""0.38.0""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CERTIFI-3164749"",""SNYK-PYTHON-CERTIFI-5805047"",""SNYK-PYTHON-IPYTHON-2348630"",""SNYK-PYTHON-IPYTHON-3318382"",""SNYK-PYTHON-JUPYTERCORE-3063766"",""SNYK-PYTHON-MISTUNE-2940625"",""SNYK-PYTHON-NBCONVERT-2979829"",""SNYK-PYTHON-NOTEBOOK-1041707"",""SNYK-PYTHON-NOTEBOOK-2441824"",""SNYK-PYTHON-NOTEBOOK-2928995"",""SNYK-PYTHON-PYGMENTS-1086606"",""SNYK-PYTHON-PYGMENTS-1088505"",""SNYK-PYTHON-PYGMENTS-5750273"",""SNYK-PYTHON-REQUESTS-5595532"",""SNYK-PYTHON-SETUPTOOLS-3180412"",""SNYK-PYTHON-SPHINX-570772"",""SNYK-PYTHON-SPHINX-570773"",""SNYK-PYTHON-SPHINX-5811865"",""SNYK-PYTHON-SPHINX-5812109"",""SNYK-PYTHON-TORNADO-5537286"",""SNYK-PYTHON-TORNADO-5840803"",""SNYK-PYTHON-WHEEL-3180413""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""pr-warning-shown""],""priorityScoreList"":[null,null,null,531,null,null,null,null,null,null,null,null,null,null,509,null,null,null,null,384,494,null],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Remote Code Execution (RCE)](https://learn.snyk.io/lesson/improper-input-validation/?loc&#x3D;fix-pr); 🦉 [Improper Privilege Management](https://learn.snyk.io/lesson/insecure-design/?loc&#x3D;fix-pr); 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [More lessons are available in Snyk Learn](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13932:10837,Learn,Learn,10837,https://hail.is,https://github.com/hail-is/hail/pull/13932,6,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"~So this PR is me trying to switch just `TableFilter` over to the correct region memory management model we've decided on.~. ~I used this `usingFreshContext` method to pass a new context to the producer that filter is consuming from so that filter can clear unused rows.~. This PR is where I'm cleaning up region management. So far, I've decided the following:. Addressed: ; - `TableFilter`; - `TableHead` (via `rvd.head`); - `TableTail` (via `rvd.tail`). No change needed: ; - `TableMapRows`; - `TableMapGlobals`; - `TableRange`; - `TableLiteral`. I also added a test using the new `hl.zeros` that's intended to catch memory leaks in filter by going through lots of large rows. For some reason, this test is failing on CI with OOM despite seeming to use constant memory on my local machine, I am still looking into why this is. Mostly, I'm wondering if this is consistent with what y'all imagined correct Region management would look like before I go through and do the rest of them. ; @cseed @tpoterba @catoverdrive @patrick-schultz",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8199:252,clear,clear,252,https://hail.is,https://github.com/hail-is/hail/pull/8199,1,['clear'],['clear']
Usability,"~Stacked on #10770~; ~Stacked on #10791~. This PR attempts to allow linear algebra codegen methods, like the LAPACK wrappers and the local whitening methods I'm working on, to defensively assert shape compatibility preconditions, without generating redundant runtime checks. (I always hate when we're pushed to avoid using code generation abstractions (in this case, just factoring code into smaller functions), because they generate worse code.). The method is pretty simple. SNDArray shapes are now arrays of `SizeValue`, which is a sum type with cases `SizeValueDyn(Value[Long])` and `SizeValueStatic(Long)`. I don't think static sizes occur very often, but it was a simple addition. `SizeValue`s can be compared statically with `==`, or at runtime with `ceq`: the former is true only if we can prove statically that the two sizes must be equal, while the latter emits code to check equality at runtime, using static knowledge to elide dynamic checks where possible. The way we encode static knowledge that two sizes are equal is by using the same local variable to store both. The primary interface to introduce that static knowledge (other than using the same set of sizes to construct multiple SNDArrays), is the method `coerceToShape(cb: CodeBuilder, newShape: Seq[SizeValue]): SNDArrayValue`, which emits code to dynamically assert that `this.shape` agrees with `newShape`, then returns `this` with shape replaced by `newShape`. Thus, `a.coerceToShape(cb, newShape).shape == newShape` will always be true, preserving the static knowledge about the shape of `a`. As a simple example, `gemm` verifies its inputs with (simplifying to the case with no transposes); ```; val Seq(m, n) = C.shapes; val k = A.shapes(1); A.assertHasShape(cb, FastIndexedSeq(m, k), errMsg); B.assertHasShape(cb, FastIndexedSeq(k, n), errMsg); ```; If we call this with; ```; val m, n, k = \\ compute expected dim sizes. \\ emit dynamic size checks once; val A_ = A.coerceToShape(cb, IndexedSeq(m, k)); val B_ = B.coerce",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10783:469,simpl,simple,469,https://hail.is,https://github.com/hail-is/hail/pull/10783,2,['simpl'],['simple']
Usability,"~Stacked on #10906~. This PR refactors `MethodBuilder.invoke` and `EmitCodeBuilder.invoke(S)Code` to take/return values. * `invoke` now takes a `CodeBuilderLike`. It is used in places where there is only access to a `CodeBuilder` (not an `EmitCodeBuilder`), so I had to use the generic interface, and had to move a couple methods on `EmitCodeBuilder` to `CodeBuilderLike`. I have never understood this Emit/non-Emit split; would be a great simplification if we could collapse it.; * This change pushed some (S)Code->(S)Value refactorings inside some aggregator implementations, which generate and invoke internal methods.; * I had to keep a version of `MethodBuilder.invoke` that doesn't take a CodeBuilder, for use in `ThisLazyFieldRef.get`. Will have to think more about how this should work when Code is (mostly) gone. Maybe lazy fields should not subclass Value, and to access a lazy field requires an explicit `load(cb: CodeBuilder): Value[T]`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10907:440,simpl,simplification,440,https://hail.is,https://github.com/hail-is/hail/pull/10907,1,['simpl'],['simplification']
Usability,"~Stacked on #8283~. We were creating fresh regions to pass as the `partitionRegion` to compiled functions deep within `ContextRDD` pipelines. Doing it that way, there's no clear owner responsible for freeing those regions. We're currently relying on Spark to clean them up. This PR adds a `partitionRegion` field to `RVDContext`. This way, the root consumer is responsible for creating the partition region before running the iterator, and for freeing it after. This is a step towards clarifying the structure of region ownership.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8288:172,clear,clear,172,https://hail.is,https://github.com/hail-is/hail/pull/8288,1,['clear'],['clear']
Usability,"~Stacked on #8874, not by necessity, but because the following PR lowering TableJoin depends on both this and that.~. * Before, `TableStage` defined it's per-partition behavior in an abstract method `def partition(ctxRef: Ref): IR`. This makes defining a new `TableStage` a bit heavy syntactically, and means we can't inspect the type of the partition IR without apply the function to something. This PR replaces the abstract method with two fields `ctxRefName: String` and `partitionIR: IR`. It defines a method `def partition(ctx: IR): IR` using these, which is more ergonomic to use because the context isn't forced to be a `Ref`. * With the type of the partition result accessible, this PR requires that type to be a `TStream<TStruct>`. Without this requirement, there is no clear connection between the partitioner and the rest of the `TableStage`. The only violation of this requirement was mapping to some other type right before collecting; this use is accommodated by a `mapCollect` method which combines the steps. * The binding structure of `TableStage` has been slightly reorganized. The `letBindings`, which are used on the master, and the `broadcastVals` which are used on the driver (previously, they had to also be usable on master), have been teased apart. In the new structure:; * `letBindings` are as before: a sequence of bindings which are evaluated in sequence on the master, whose bindings are visible in the `contexts` expression and in the `broadcastVals`; * `broadcastVals` are now a separate sequence of bindings, which are evaluated on the master in parallel (each broadcast binding sees only the `letBindings`, no previous `broadcastVals`), and whose bindings are visible only in the `partitionIR`; * `globals` is now required to be a `Ref`, which is defined in `letBindings` and redefined in `broadcastVals`, so that the `Ref` is valid in later `letBindings`, in `contexts`, as well as in the `partitionIR`. This does mean that `globals` is always broadcast, even when it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8917:779,clear,clear,779,https://hail.is,https://github.com/hail-is/hail/pull/8917,1,['clear'],['clear']
Usability,"~~Stacked on #8140~~. This PR adds support for the new streams in the emitter for ArrayFilter, ArrayZip, ArrayFlatMap, If, and Let. It also changes the semantics of `Stream` slightly: Before, a producer had to close itself before calling EOS on its consumer. Now, the consumer is responsible for closing the producer after the producer calls EOS. This makes flatMap slightly more complicated, but it allows a significant simplification to zip. To implement the different modes of `ArrayZip`, I added `extendNA` and `take`. `extendNA` turns a stream into an infinite stream, where values after the end are missing, to allow the consumer to decide what to do when the stream ends. `take` is then needed to end infinite streams. Both use `COption` to encode whether the child stream has ended / whether to end the child stream. I still intend to convert uses of `COption` to use `CodeConditional` after lowering is unblocked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8156:421,simpl,simplification,421,https://hail.is,https://github.com/hail-is/hail/pull/8156,1,['simpl'],['simplification']
Usability,"~~Stacked on #9177~~. These are tricky because of the overlapping lifetimes of the accumulator values. The solution implemented here is to keep two regions. When running the fold body, one region is empty, and the other holds just the previous accumulator. Then we deep copy the new accumulator to the empty region, clear the other one, then swap the two regions before moving to the next iteration. This required expanding the StagedRegion API a bit. First, it now strictly tracks the parent StagedRegion, even in the non-allocating case where the parent wraps the same run-time region. Second, in addition to copying a value to the parent, we can now copy a value to a sibling. It enforces at compile time that the two regions have the same parent. It follows that either both are actually separate regions, or both are just wrappers around the parent region. In the latter case, copying to a sibling is a no-op.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9178:316,clear,clear,316,https://hail.is,https://github.com/hail-is/hail/pull/9178,1,['clear'],['clear']
Usability,"~~Stacked on #9232.~~. This adds memory management to StreamGrouped and StreamGroupByKey. As always, the case where the inner stream is never consumed causes complications. Because the child stream gets its per-element region from the consumer of the inner stream, if the inner stream is unconsumed we have to pass some other region. The solution implemented here uses the outer stream's eltRegion. If the outer stream's consumer allows creating new regions, the grouping node creates an owned region to construct child stream elements in, and clears it every element (because it is never passed to a consumer). Otherwise, all child elements get created in the outer stream's eltRegion.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9234:544,clear,clears,544,https://hail.is,https://github.com/hail-is/hail/pull/9234,1,['clear'],['clears']
Usability,"…urces. TJ has raised a bunch of very legitimate concerns about the expressivity of; hailtop.batch. In this PR, I basically rebuilt hailtop.batch from scratch as; a learning exercise. Once I understood how it worked, I added two valuable; features:. 1. `hb.remote` creates a ""remote"" resource which is never localized but still; creates dependency relationships. 2. `ResourceToStringPickler` which pickles resources appropriately even if; they are nested within other structures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11378:165,learn,learning,165,https://hail.is,https://github.com/hail-is/hail/pull/11378,1,['learn'],['learning']
