quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability," # ImportError: cannot import name 'soft_unicode' from 'markupsafe'.; # # So, forcing a downgrade. This isn't the best solution, but we need it to get; # # our tests pass.; pip3 install ""${PIP_ARGS[@]}"" --upgrade 'markupsafe==2.0.1'. # ################################################################################; # # CUDA; # ################################################################################. # note_build_stage ""Install CUDA"". # # See https://www.tensorflow.org/install/source#gpu for versions required.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # if [[ ""${DV_INSTALL_GPU_DRIVERS}"" = ""1"" ]]; then; # # This script is only maintained for Ubuntu 20.04.; # UBUNTU_VERSION=""2004""; # # https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_local; # echo ""Checking for CUDA...""; # if ! dpkg-query -W cuda-11-3; then; # echo ""Installing CUDA...""; # UBUNTU_VERSION=""2004""; # curl -O https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin; # sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600; # # From https://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212772; # sudo -H apt-key adv --fetch-keys ""http://developer.download.nvidia.com/compute/cuda/repos/ubuntu${UBUNTU_VERSION}/x86_64/3bf863cc.pub""; # sudo add-apt-repository -y ""deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /""; # sudo -H apt-get update ""${APT_ARGS[@]}""; # # From: https://superuser.com/a/1638789; # sudo -H DEBIAN_FRONTEND=noninteractive apt-get \; # -o Dpkg::Options::=--force-confold \; # -o Dpkg::Options::=--force-confdef \; # -y --allow-downgrades --allow-remove-essential --allow-change-held-packages \; # full-upgrade; # sudo -H apt-get install ""${APT_ARGS[@]}"" cuda-11-3; # fi; # echo ""Checking for CUDNN...""; # if [[ ! -e /usr/local/cuda-11/include/cudnn.h ]]; then; # echo ""Installing CUDNN...""; # CUD",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:3074,down,download,3074,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,2,['down'],['download']
Availability," - If you are simply trying to use the numpy version that you have installed:; > your installation is broken - please reinstall numpy.; > - If you have already reinstalled and that did not fix the problem, then:; > 1. Check that you are using the Python you expect (you're using /usr/bin/python),; > and that you have no directories in your PATH or PYTHONPATH that can; > interfere with the Python and numpy versions you're trying to use.; > 2. If (1) looks fine, you can open a new issue at; > https://github.com/numpy/numpy/issues. Please include details on:; > - how you installed Python; > - how you installed numpy; > - your operating system; > - whether or not you have multiple versions of Python installed; > - if you built from source, your compiler versions and ideally a build log; > ; > Note: this error has many possible causes, so please don't comment on; > an existing issue about this - open a new one instead.; > ; > Original error was: PyCapsule_Import could not import module ""datetime""; > ; > Traceback (most recent call last):; > File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main; > ""__main__"", fname, loader, pkg_name); > File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code; > exec code in run_globals; > File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 223, in <module>; > File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 204, in Main; > File ""/usr/lib/python2.7/subprocess.py"", line 523, in call; > return Popen(*popenargs, **kwargs).wait(); > File ""/usr/lib/python2.7/subprocess.py"", line 711, in __init__; > errread, errwrite); > File ""/usr/lib/python2.7/subprocess.py"", line 1235, in _execute_child; > self.pid = os.fork(); > OSError: [Errno 11] Resource temporarily unavailable: '/usr/bin/python'; > ; > real 19m19.271s; > user 1084m5.580s; > sys 17m12.750s; > Traceback (most recent call last):; > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>; > app.run(main); > File ""/usr/local/lib/python2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/274#issuecomment-598179709:2179,error,error,2179,,https://github.com/google/deepvariant/issues/274#issuecomment-598179709,2,['error'],['error']
Availability," -rw-rw-r-- 1 zhoujianglin zhoujianglin 9725M Apr 26 15:42 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai; -rw-rw-r-- 1 zhoujianglin zhoujianglin 749M Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.pac; ```. However, If I run the follow bash script, it can not find `ref_idx` through `ls` command, whereas shell condition expression ` [ -f $ref_idx ]` return `true`.; here is the script:; ```shell; #!/bin/bash. dvsif=""/lustre/Data/toolsDB//deepvariant.sif""; ref_idx=""/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa"". wkdir=""/lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP""; bamdir=""${wkdir}/mappinged_bams""; logdir=""${wkdir}/logs""; vcfoutdir=""${wkdir}/DeepVariant_outputs"". source activate ~/.conda/envs/zjlEnv. echo -e ""ref_idx is $ref_idx\n""; if [ -f ""$ref_idx"" ];; then; echo -e ""ref_idx $ref_idx exists!\n""; which ls; echo -e ""ls -al --block=M ${ref_idx}*\n""; ls -al --block=M ""${ref_idx}*""; echo -e ""ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*\n""; ls -al --block=M ""/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*""; echo -e ""/bin/ls -al --block=M ${ref_idx}*\n""; /bin/ls -al --block=M ""${ref_idx}*"". else; echo -e ""Warning!! ref_idx [$ref_idx] not exist!\n""; fi. ls -al ""${ref_idx}*""; singularity run $dvsif ls $ref_idx. ```. Here is the running output:; ```shell; $ bash scripts/02_run_deepvariant.sh ; ref_idx is /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa. ref_idx /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa exists!. /usr/bin/ls; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. ls: cannot access /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*: No such file or directory; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. ls: cannot access /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*: No such file or directory; /bin/ls ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1568200761:1870,echo,echo,1870,,https://github.com/google/deepvariant/issues/653#issuecomment-1568200761,4,['echo'],['echo']
Availability, 12:12:06.012 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:06.076 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:16.724 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 1; name: pbc_varicall (1); status: COMPLETED; exit: 1; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:16.741 [Task monitor] ERROR nextflow.processor.TaskProcessor - Error executing process > 'pbc_varicall (1)'. Caused by:; Process `pbc_varicall (1)` terminated with an error exit status (1); Command executed:. run_deepvariant --model_type PACBIO --ref /data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta --reads /data/shared/clinical/LongRead/Data//m84011_220902_175841_Aln.bam --output_vcf /data/shared/clinical/LongRead/Data//Analysis/out_m84011_220902_175841_NFR_sif.vcf.gz --num_shards 40 --regions chr20. Command exit status:; 1. Command output:; I0608 12:13:28.741300 139794368661312 call_variants.py:462] Processed 100001 examples in 196 batches [0.087 sec per 100]; I0608 12:14:06.236101 139794368661312 call_variants.py:462] Processed 150001 examples in 293 batches [0.083 sec per 100]; I0608 12:14:43.829042 139794368661312 call_variants.py:462] Processed 200001 examples in 391 batches [0.081 sec per 100]; I0608 12:15:22.101066 139794368661312 call_variants.py:462] Processed 250001 examples in 489 batches [0.080 sec per 100]; I0608 12:15:59.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308:5073,Error,Error,5073,,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308,1,['Error'],['Error']
Availability," 902, in create_session; self.tf_sess = self._session_creator.create_session(); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 669, in create_session; init_fn=self._scaffold.init_fn); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/session_manager.py"", line 295, in prepare_session; config=config); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/session_manager.py"", line 209, in _restore_checkpoint; saver.restore(sess, checkpoint_filename_with_path); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py"", line 1315, in restore; err, ""a Variable name or other graph key that is missing""); tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. /opt/models/pacbio/model.ckpt.data-00000-of-00001; No such file or directory; 	 [[node save_1/RestoreV2 (defined at usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:629) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_8s8eyzhg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_8s8eyzhg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_8s8eyzhg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_8s8eyzhg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main; use_tpu=FLAGS.use_tpu,; File ""tmp/Bazel.runfiles_8s8eyzhg/runfiles/com_google_deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/757#issuecomment-1864800013:16162,error,error,16162,,https://github.com/google/deepvariant/issues/757#issuecomment-1864800013,1,['error'],['error']
Availability," > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; ========== [Mon 05 Jun 2023 04:03:17 PM UTC] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting; Found existing installation: pyparsing 2.2.0; Uninstalling pyparsing-2.2.0:; Successfully uninstalled pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; Using pip 23.1.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Installing collected packages: pyparsing; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.22.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; ========== [Mon 05 Jun 2023 04:03:18 PM UTC] Stage 'build-prereq.sh complete' starting; ```. The running of `./build_and_test.sh`:; ```; + source settings.sh; ++ export DV_USE_PREINSTALLED_TF=0; ++ DV_USE_PREINSTALLED_TF=0; ++ export TF_NEED_GCP=1; ++ TF_NEED_GCP=1; ++ export CUDNN_INSTALL_PATH=/usr/lib/aarch64-linux-gnu; ++ CUDNN_INSTALL_PATH=/usr/lib/aarch64-linux-gnu; ++ DV_BAZEL_VERSION=5.3.0; ++ export PATH=/root/bin:/root/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:10581,ERROR,ERROR,10581,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,1,['ERROR'],['ERROR']
Availability," Best,. Brad Thomas. ________________________________; From: Ryan Poplin <notifications@github.com>; Sent: Friday, February 9, 2018 12:54 PM; To: google/deepvariant; Cc: Brad Thomas; Author; Subject: [External]Re: [google/deepvariant] Build and test works, binaries do not (#47). Great to hear. There are minimum allele fractions that are used to generate candidate variants here (https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L165), you'll likely want to lower those thresholds for your use case. For the model itself, there is no explicit allele fraction, but keep in mind that the model was trained to predict the diploid genotype states of {hom ref, het, and hom var} so things that are lower allele fraction will likely be classified as 0/0 by the model. We don't currently have a version that does somatic variant calling. -; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/47#issuecomment-364524990>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqVYdivUTLfEIl26QitFq5k-svzBeks5tTJSBgaJpZM4R5yAT>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/47#issuecomment-364650047:1754,error,error-free,1754,,https://github.com/google/deepvariant/issues/47#issuecomment-364650047,2,['error'],"['error-free', 'errors']"
Availability, DV_USE_GCP_OPTIMIZED_TF_WHL=0; ++ DV_USE_GCP_OPTIMIZED_TF_WHL=0; ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-2.11.0.deepvariant_gcp-cp27-none-linux_x86_64.whl; ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-2.11.0.deepvariant_gcp-cp27-none-linux_x86_64.whl; ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow; ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow; ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow; ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow; ++ export DV_TF_NUMPY_VERSION=1.19.2; ++ DV_TF_NUMPY_VERSION=1.19.2; ++ export DV_INSTALL_GPU_DRIVERS=0; ++ DV_INSTALL_GPU_DRIVERS=0; ++ export PYTHON_VERSION=3.8; ++ PYTHON_VERSION=3.8; +++ which python3.8; ++ export PYTHON_BIN_PATH=/usr/bin/python3.8; ++ PYTHON_BIN_PATH=/usr/bin/python3.8; ++ export PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages; ++ PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages; ++ export USE_DEFAULT_PYTHON_LIB_PATH=1; ++ USE_DEFAULT_PYTHON_LIB_PATH=1; ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api'; ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api'; + bazel; /root/bin/bazel: line 220: /root/.bazel/bin/bazel-real: cannot execute binary file: Exec format error; /root/bin/bazel: line 220: /root/.bazel/bin/bazel-real: Success; + PATH=/root/bin:/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin; + [[ 0 = \1 ]]; + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api deepvariant/...; /root/bin/bazel: line 220: /root/.bazel/bin/bazel-real: cannot execute binary file: Exec format error; /root/bin/bazel: line 220: /root/.bazel/bin/bazel-real: Success; ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:14174,error,error,14174,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,4,['error'],['error']
Availability," I suppose to run the make_example parallel?; I use the following command: ; seq 0 47 | parallel -q --halt 2 --line-buffer python3 make_examples.zip --mode calling --ref /data/input/human_g1k_v37.fasta --reads /data/input/c6c4c1db-4328-4aa9-b038-074c9a453117.dedup.bam --examples make_examples.tfrecord@12.gz. showing error:. E0430 18:57:45.160124 140015706085184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_9oblbsyi/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '33']"".; E0430 18:57:45.128387 140717112878912 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_gd9fj22_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '2']"".; E0430 18:57:45.149224 139802704738112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_2hbfxd92/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '16']"".; E0430 18:57:45.196900 140351706515264 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles__ytoy0a6/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '4']"".; E0430 18:57:45.304501 140371551012672 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_w7jwxlqo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '28']"".; E0430 18:57:45.337900 139621533210432 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_22p2hp0z/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '45']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:1052,failure,failure,1052,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability," ImportError(msg); ImportError: Traceback (most recent call last):; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so); ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```; module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \; --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \; --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \; --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>; from deepvariant import pileup_image; File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>; from third_party.nucleus.util import ranges; File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>; from third_party.nucleus.io import bed; File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-453685106:2637,error,error,2637,,https://github.com/google/deepvariant/issues/137#issuecomment-453685106,1,['error'],['error']
Availability," So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > ; > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?. If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8.; ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:; ```; $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json; {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} ; ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/568#issuecomment-1251857213:1625,checkpoint,checkpoint,1625,,https://github.com/google/deepvariant/issues/568#issuecomment-1251857213,2,['checkpoint'],['checkpoint']
Availability," This behaviour is the source of the following dependency conflicts.; google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ========== [Mon 05 Jun 2023 03:51:40 PM UTC] Stage 'run-prereq.sh complete' starting; ========== [Mon 05 Jun 2023 03:51:40 PM UTC] Stage 'Update package list' starting; ========== [Mon 05 Jun 2023 03:51:41 PM UTC] Stage 'build-prereq.sh: Install development packages' starting; Calling wait_for_dpkg_lock.; ========== [Mon 05 Jun 2023 03:51:42 PM UTC] Stage 'Install bazel' starting; /root/bin/bazel: line 220: /root/.bazel/bin/bazel-real: cannot execute binary file: Exec format error; /root/bin/bazel: line 220: /root/.bazel/bin/bazel-real: Success; ~/bazel /media/HostShared/deepvariant-r1.5; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0; 100 46.5M 100 46.5M 0 0 23.2M 0 0:00:02 0:00:02 --:--:-- 27.1M; /media/HostShared/deepvariant-r1.5; ========== [Mon 05 Jun 2023 03:51:44 PM UTC] Stage 'Install CLIF binary' starting; CLIF already installed.; ========== [Mon 05 Jun 2023 03:51:44 PM UTC] Stage 'Download and configure TensorFlow sources' starting; ========== [Mon 05 Jun 2023 03:51:44 PM UTC] Stage 'Cloning TensorFlow from github as ../tensorflow doesn't exist' starting; Cloning into 'tensorflow'...; remote: Enumerating objects: 1585302, done.; remote: Counting objects: 100% (346968/346968), done.; remote: Compressing objects: 100% (5367/5367), done.; remote: Total 1585302 (delta 342939), reused 342327 (delta 341589), pack-reused 1238334; Receiving objec",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:5495,error,error,5495,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,2,['error'],['error']
Availability," Updating files: 100% (12761/12761), done.; Note: switching to 'v2.11.0'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at d5b57ca93e5 Merge pull request #58598 from tensorflow/vinila21-patch-1; WARNING: current bazel installation is not a release version.; Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.; 	--config=mkl 	# Build with MKL support.; 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL).; 	--config=monolithic 	# Config for mostly static monolithic build.; 	--config=numa 	# Build with NUMA support.; 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.; 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API.; Preconfigured Bazel build configs to DISABLE default on features:; 	--config=nogcp 	# Disable GCP support.; 	--config=nonccl 	# Di",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:7602,down,download,7602,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,4,['down'],"['download', 'downloaded']"
Availability," absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: /input/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:22:14.603199 140118199654144 genomics_reader.py:223] Reading /input/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:22:14.780351 140118199654144 make_examples.py:648] Writing examples to /output/make_examples.tfrecord.gz; I0629 23:22:14.780567 140118199654144 make_examples.py:648] Writing gvcf records to /output/gvcf.tfrecord.gz; I0629 23:22:14.781277 140118199654144 make_examples.py:648] Overhead for preparing inputs: 0 seconds; I0629 23:22:14.797983 140118199654144 make_examples.py:648] 0 candidates (0 examples) [0.02s elapsed]; I0629 23:23:33.302437 140118199654144 make_examples.py:648] 102 candidates (110 examples) [78.50s elapsed]; I0629 23:23:37.605793 140118199654144 make_examples.py:648] 202 candidates (223 examples) [4.30s elapsed]; [E::bgzf_read] Read block operation failed with error 4 after 0 of 4 bytes; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads; reads.extend(sam_reader.query(region)); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__; record, not_done = self._raw_next(); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next; not_done = self._cc_iterable.PythonNext(record); ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_im0i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:11368,error,error,11368,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,2,['error'],['error']
Availability," again.; -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11""; +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11""; ; function note_build_stage {; echo ""========== [$(date)] Stage '${1}' starting""; ```; ```; diff --git a/build-prereq.sh b/build-prereq.sh; index ad34e285..1fc2d203 100755; --- a/build-prereq.sh; +++ b/build-prereq.sh; @@ -41,7 +41,7 @@ source settings.sh; ; note_build_stage ""Install the runtime packages""; ; -./run-prereq.sh; +#./run-prereq.sh; ; note_build_stage ""Update package list""; ; @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {; then; echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling""; else; - pushd ~/bazel; - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh; - chmod +x bazel-*.sh; - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null; - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh; - popd; + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64; + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel; + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk; + chmod +x /usr/local/bin/bazel; + chmod +x /usr/local/bin/bazelisk; fi; }; ```; ```; diff --git a/tools/build_clif.sh b/tools/build_clif.sh; index c7c3378b..a08ab475 100755; --- a/tools/build_clif.sh; +++ b/tools/build_clif.sh; @@ -39,7 +39,7 @@ echo ========== Run this script in root mode.; CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}""; ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}""; PROTOBUF_VERSION=3.13.0; -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}""; +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}""; # CLIF_PIN can be set to",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217:2728,down,download,2728,,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217,1,['down'],['download']
Availability," aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testda; aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testdata/${REF}.fai"" -d ""${INPUT_DIR}""; ; ## Pull the docker image.; -sudo docker pull google/deepvariant:""${BIN_VERSION}""; +sudo docker pull dkurtaev/deepvariant:latest; ; echo ""Run DeepVariant...""; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; - google/deepvariant:""${BIN_VERSION}"" \; - /opt/deepvariant/bin/run_deepvariant \; + dkurtaev/deepvariant:latest \; + /opt/deepvariant/bin/run_deepvariant --call_variants_extra_args=use_openvino=true --make_examples_extra_args=regions=chr1 \; --model_type=WGS \; --ref=""/input/${REF}.gz"" \; --reads=""/input/${BAM}"" \; @@ -100,6 +100,6 @@ pkrusche/hap.py /opt/hap.py/bin/hap.py \; -f ""${INPUT_DIR}/${TRUTH_BED}"" \; -r ""${UNCOMPRESSED_REF}"" \; -o ""${OUTPUT_DIR}/happy.output"" \; - --engine=vcfeval; + --engine=vcfeval -l chr1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done."". ```. Runtime:; ```; $ grep '^real' /tmp/open; real 7m38.326s; real 15m12.564s; real 7m15.173s; ```. 2. Use your Docker image, use_openvino=false; The code diff:; ```; $ git diff; diff --git a/scripts/run_wgs_case_study_docker.sh b/scripts/run_wgs_case_study_docker.sh; index 3dc9712..78712d8 100755; --- a/scripts/run_wgs_case_study_docker.sh; +++ b/scripts/run_wgs_case_study_docker.sh; @@ -65,14 +65,14 @@ aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testda; aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testdata/${REF}.fai"" -d ""${INPUT_DIR}""; ; ## Pull the docker image.; -sudo docker pull google/deepvariant:""${BIN_VERSION}""; +sudo docker pull dkurtaev/deepvariant:latest; ; echo ""Run DeepVariant...""; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; - google/deepvariant:""${BIN_VERSION}"" \; - /opt/deepvariant/bin/run_deepvariant \; + dkurtaev/deepvariant:latest \; + /opt/deepvariant/bin/run_dee",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735276044:1781,echo,echo,1781,,https://github.com/google/deepvariant/pull/363#issuecomment-735276044,1,['echo'],['echo']
Availability," but you have markupsafe 2.0.1 which is incompatible.; ========== [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install CUDA' starting; ========== [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install TensorRT' starting; ========== [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; ========== [Sun 04 Jun 2023 11:11:27 PM UTC] Stage 'run-prereq.sh complete' starting; ```. The last time I tried running `./build-prereq.sh`, I got error on the building of Clif. llvm-11-linker-tools not available.; and now the error is:; ```; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276:4528,error,error,4528,,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276,1,['error'],['error']
Availability," caused the issue here: https://github.com/pallets/markupsafe/issues/286.; # # Specifically:; # # ImportError: cannot import name 'soft_unicode' from 'markupsafe'.; # # So, forcing a downgrade. This isn't the best solution, but we need it to get; # # our tests pass.; pip3 install ""${PIP_ARGS[@]}"" --upgrade 'markupsafe==2.0.1'. # ################################################################################; # # CUDA; # ################################################################################. # note_build_stage ""Install CUDA"". # # See https://www.tensorflow.org/install/source#gpu for versions required.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # if [[ ""${DV_INSTALL_GPU_DRIVERS}"" = ""1"" ]]; then; # # This script is only maintained for Ubuntu 20.04.; # UBUNTU_VERSION=""2004""; # # https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_local; # echo ""Checking for CUDA...""; # if ! dpkg-query -W cuda-11-3; then; # echo ""Installing CUDA...""; # UBUNTU_VERSION=""2004""; # curl -O https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin; # sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600; # # From https://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212772; # sudo -H apt-key adv --fetch-keys ""http://developer.download.nvidia.com/compute/cuda/repos/ubuntu${UBUNTU_VERSION}/x86_64/3bf863cc.pub""; # sudo add-apt-repository -y ""deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /""; # sudo -H apt-get update ""${APT_ARGS[@]}""; # # From: https://superuser.com/a/1638789; # sudo -H DEBIAN_FRONTEND=noninteractive apt-get \; # -o Dpkg::Options::=--force-confold \; # -o Dpkg::Options::=--force-confdef \; # -y --allow-downgrades --allow-remove-essential --allow-change-held-packages \; # full-upgrade; # sudo -H apt-get install ""${APT_ARGS[@]}"" cuda-11-3; # fi; # echo ""Checking for CUDNN...""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:2994,echo,echo,2994,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,2,['echo'],['echo']
Availability," chr20 -o chr20.bam`) and the reference `chr20.fa`.; The command:; `user@deepvariant:~/data$ blasr chr20.bam chr20.fa --bam --out alignments20.bam`; This command ran for about 13.5 hours on my local machine, and produced a file with size of 6.3GB, while the original `chr20.bam` file size was only 2.3GB . 2. I've sorted the produced alignments20.bam file using the samtools.; The command:; `user@deepvariant:~/data$ samtools sort -f alignments20.bam alignments20_sorted.bam`; This command produced a sorted file with size of 7.75GB. 3. I tried running the `make_examples` script again with the new `alignments20_sorted.bam` file.; The command:; ```; python bin/make_examples.zip \; --mode training \; --ref ""data/chr20.fa"" \; --reads ""data/alignments20_sorted.bam"" \; --examples ""training-examples/training_set.with_label.tfrecord.gz"" \; --confident_regions ""data/NA12878.sorted.bed"" \; --truth_variants ""data/NA12878.sorted.vcf.gz"" \; --regions ""chr20"" \; --norealign_reads; ```; And The output: (receiving the same QUAL field missing error); ```; 2019-01-29 11:46:16.329383: W third_party/nucleus/io/sam_reader.cc:125] Unknown tag pb: in header line, ignoring: @HD VN:1.5 SO:coordinate pb:3.0.1; 2019-01-29 11:46:16.333216: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0129 11:46:16.334961 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/alignments20_sorted.bam with NativeSamReader; I0129 11:46:16.337215 140471159555840 make_examples.py:1024] Preparing inputs; 2019-01-29 11:46:16.340804: W third_party/nucleus/io/sam_reader.cc:125] Unknown tag pb: in header line, ignoring: @HD VN:1.5 SO:coordinate pb:3.0.1; 2019-01-29 11:46:16.344462: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0129 11:46:16.346041 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/alignments20_sorted.bam with NativeSamReader; I0129 11:46:16.360527 140471159555840 genomics_reader.py:174] Reading prj",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-458487916:1185,error,error,1185,,https://github.com/google/deepvariant/issues/138#issuecomment-458487916,1,['error'],['error']
Availability," consult you.; First I verify that my host directory is successfully mounted to the container directory.`/mnt/QJref.fa /mnt/input.bam`; ```; singularity exec -B $TMPDIR:$TMPDIR,""${WORK_DIR}"":/mnt /dellfsqd2/ST_OCEAN/USER/sunzhilong/1_Software/dpv/deepvariant_1.4.0.sif bash; Singularity> cd / && ls; bin boot dellfsqd2 dev environment etc home lib lib32 lib64 libx32 media mnt opt proc root run sbin singularity srv sys tmp usr var; Singularity> cd mnt && ls; QJref.fa input.bam QJref.fa.fai input.bam.bai tmp_dir; ```; Then I ran the following script.; ```; cat test0215.sh; WORK_DIR=/path1/4_Test/qingjiang/dpv; export TMPDIR=""$PWD/tmp_dir""; singularity run -B$TMPDIR:$TMPDIR,""${WORK_DIR}"":/mnt \; /path1/1_Software/dpv/deepvariant_1.4.0.sif /opt/deepvariant/bin/run_deepvariant \; --num_shards=3 \; --model_type=PACBIO \; --ref=/mnt/QJref.fa \; --reads=/mnt/input.bam \; --output_vcf=/mnt/output.vcf.gz \; --output_gvcf=/mnt/output.g.vcf.gz \; --intermediate_results_dir /mnt/dpv \; ```; The core error is `ValueError: NOT_FOUND: Could not open /mnt/input.bam; [E::hts_open_format] Failed to open file ""/mnt/input.bam"" : No such file or directory`However, I have verified the existence of `/mnt/input.bam`.; The complete error information is as follows.; Sincerely look forward to your help! thank you; ```; sh test0215.sh; I0216 00:56:07.446549 140582811191104 run_deepvariant.py:342] Re-using the directory for intermediate results in /mnt/dpv. ***** Intermediate results will be written to /mnt/dpv in docker. ****. ***** Running the command:*****; time seq 0 2 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/QJref.fa"" --reads ""/mnt/input.bam"" --examples ""/mnt/dpv/make_examples.tfrecord@3.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/mnt/dpv/gvcf.tfrecord@3.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealig",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/613#issuecomment-1431702886:1117,error,error,1117,,https://github.com/google/deepvariant/issues/613#issuecomment-1431702886,1,['error'],['error']
Availability," cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600; # # From https://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212772; # sudo -H apt-key adv --fetch-keys ""http://developer.download.nvidia.com/compute/cuda/repos/ubuntu${UBUNTU_VERSION}/x86_64/3bf863cc.pub""; # sudo add-apt-repository -y ""deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /""; # sudo -H apt-get update ""${APT_ARGS[@]}""; # # From: https://superuser.com/a/1638789; # sudo -H DEBIAN_FRONTEND=noninteractive apt-get \; # -o Dpkg::Options::=--force-confold \; # -o Dpkg::Options::=--force-confdef \; # -y --allow-downgrades --allow-remove-essential --allow-change-held-packages \; # full-upgrade; # sudo -H apt-get install ""${APT_ARGS[@]}"" cuda-11-3; # fi; # echo ""Checking for CUDNN...""; # if [[ ! -e /usr/local/cuda-11/include/cudnn.h ]]; then; # echo ""Installing CUDNN...""; # CUDNN_TAR_FILE=""cudnn-11.3-linux-x64-v8.2.0.53.tgz""; # wget -q https://developer.download.nvidia.com/compute/redist/cudnn/v8.2.0/${CUDNN_TAR_FILE}; # tar -xzvf ${CUDNN_TAR_FILE}; # sudo cp -P cuda/include/cudnn.h /usr/local/cuda-11/include; # sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-11/lib64/; # sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-11/lib64/; # sudo chmod a+r /usr/local/cuda-11/lib64/libcudnn*; # sudo ldconfig; # fi; # # Tensorflow says to do this.; # sudo -H apt-get install ""${APT_ARGS[@]}"" libcupti-dev > /dev/null; # fi. # # If we are doing a gpu-build, nvidia-smi should be install. Run it so we; # # can see what gpu is installed.; # nvidia-smi || :; # fi. # ################################################################################; # # TensorRT; # ################################################################################. # note_build_stage ""Install TensorRT"". # # Address the issue:; # # 'dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory'; # # It's unclear whether we need this or not. Setting up to get r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:4157,down,download,4157,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,2,['down'],['download']
Availability," dig deeper into the training behavior, can you check this:; What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files.; To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:; ```; class 0, count: 101,679,899; class 1, count: 145,911,730; class 2, count: 98,914,057; ```; There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidates that feed into the classifier), and many many other details that are specific to your data. Which is why I said our team cannot help debug the details of your case. But hopefully by examining your own distribution, you can first see if the training (and tuning) data makes sense or not. If the data has very skewed distribution, there are also other techniques that the ML community uses to improve the accuracy. But I won't be able to get into that. It's also not what DeepVariant designed for.; DeepVariant is wrapped around TensorFlow, which is a much more general purpose ML tool. If there are functionalities that we don't provide, please also look into TensorFlow to see if they have something useful for you. I'm closing this issue now because this is not really a DeepVariant issue. But if you believe this actually reveals some bugs in our codebase, I'm happy to discuss further if you can show a reproducible example that demonstrate the error.; Closing this issue now. But happy to follow up on this issue if you have more thoughts/questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/203#issuecomment-518462111:2952,error,error,2952,,https://github.com/google/deepvariant/issues/203#issuecomment-518462111,2,['error'],['error']
Availability," done so far:. I tried downloading the BAM file again with `curl` (just to be sure the file is ok) with this command:; `curl -O ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/sorted_final_merged.bam`. I'm runnning version 1.9 of samtools and htslib, this is my output for the same commands:; ```; user@deepvariant:~/data$ samtools --version; samtools 1.9; Using htslib 1.9; Copyright (C) 2018 Genome Research Ltd. user@deepvariant:~/data$ samtools view -h ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/sorted_final_merged.bam chr20 -o chr20.bam. user@deepvariant:~/data$ samtools view -h chr20.bam | head; @HD	VN:1.4	GO:none	SO:coordinate; @SQ	SN:chrM	LN:16571	M5:6b9e15a5937653b0006de435f91578c0; @SQ	SN:chr1	LN:249250621	M5:94f0d1b1622299238a1d8a0711dd06c7; @SQ	SN:chr2	LN:243199373	M5:854e985b2e19c122b9f67f6453965693; @SQ	SN:chr3	LN:198022430	M5:8abc85e73b1c75518a03743de2c2b14b; @SQ	SN:chr4	LN:191154276	M5:2d37b4e662928cc6c58b84b2a4cc8648; @SQ	SN:chr5	LN:180915260	M5:250f4e82a213269b0a0e4aebb0468470; @SQ	SN:chr6	LN:171115067	M5:409088215d77f0bc72364b390430a5a7; @SQ	SN:chr7	LN:159138663	M5:ef15cde5c82fb860694bf8f611807459; @SQ	SN:chr8	LN:146364022	M5:8fbef8c3eaaac674cc6e690d1641464b; ```; As you can see I don't get the EOF error when viewing `chr20.bam`. I tries running make_examples with the new files and I get the same error as you got here:. > @mosh305 I do not have experience with mapping, but the README for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here.; > ...; > ; > Hope this helps!; > ; > ```; > 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; > WARNING: Logging before flag parsing goes to stderr.; > I0115 00:54:33.942667 140481635538688 genomics_reader.py:174]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-457253153:1331,error,error,1331,,https://github.com/google/deepvariant/issues/138#issuecomment-457253153,1,['error'],['error']
Availability," etc. Juan Pablo Aguilar. ________________________________; From: Pi-Chuan Chang ***@***.***>; Sent: Friday, September 20, 2024 6:52:36 PM; To: google/deepvariant ***@***.***>; Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>; Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions).; The core question here is: Would you be able to get truth data for the bats you're studying?. I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> .; I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. —; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>.; You are receiving this because you were mentioned.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/878#issuecomment-2364755195:2005,avail,available,2005,,https://github.com/google/deepvariant/issues/878#issuecomment-2364755195,2,['avail'],['available']
Availability," for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```; 20765 / 21141 (98.2%) full SNP recovery; 20872 / 21141 (98.7%) partial SNP recovery; 243 / 258 (94.2%) full insertion recovery; 249 / 258 (96.5%) partial insertion recovery; 208 / 228 (91.2%) full deletion recovery; 213 / 228 (93.4%) partial deletion recovery; ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:; If you go to “[explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select “**func_cds**” (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:4713,recover,recovery,4713,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability," incompatible.; ========== [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install CUDA' starting; ========== [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install TensorRT' starting; ========== [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; ========== [Sun 04 Jun 2023 11:11:27 PM UTC] Stage 'run-prereq.sh complete' starting; ```. The last time I tried running `./build-prereq.sh`, I got error on the building of Clif. llvm-11-linker-tools not available.; and now the error is:; ```; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"") ; -- Checking for module 'protobuf';",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276:4584,avail,available,4584,,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276,1,['avail'],['available']
Availability," make_examples.tfrecord@12.gz. showing error:. E0430 18:57:45.160124 140015706085184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_9oblbsyi/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '33']"".; E0430 18:57:45.128387 140717112878912 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_gd9fj22_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '2']"".; E0430 18:57:45.149224 139802704738112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_2hbfxd92/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '16']"".; E0430 18:57:45.196900 140351706515264 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles__ytoy0a6/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '4']"".; E0430 18:57:45.304501 140371551012672 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_w7jwxlqo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '28']"".; E0430 18:57:45.337900 139621533210432 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_22p2hp0z/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '45']"".; E0430 18:57:45.424449 139874966882112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_wv1oakms/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '46']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:1331,failure,failure,1331,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability," model at the same time?. **The make_examples script is:**; `BASE=""${HOME}/Documents/source""; BIN_DIR=""${BASE}/bin""; MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard""; MODEL=""${MODELS_DIR}/model.ckpt""; N_SHARDS=""64""; BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam""; REF=""/home/suanfa/Documents/source/ref/hg19.fasta""; var=${BAM##*/}; var=${var%.*}; path=""/home/suanfa/Documents/shishiming/training_WES_model""; OUTPUT_DIR=""$path/output""; EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz""; CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed""; TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz""; LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'; ( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \; python ""${BIN_DIR}""/make_examples.zip \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM}"" \; --examples ""${EXAMPLES}"" \; --confident_regions ${CONFIDENT_REGIONS} \; --truth_variants ${TRUTH_VARIANTS} \; --task {}; ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**; > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz; PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz; PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz; PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/69#issuecomment-386515701:1205,echo,echo,1205,,https://github.com/google/deepvariant/issues/69#issuecomment-386515701,1,['echo'],['echo']
Availability," needed; python setup.py install; # install from wheel; python setup.py bdist_wheel; pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall; # verify; python -c ""import google.protobuf""; ```. ## OpenBLAS 0.3.5. ```bash; git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5; cd OpenBLAS-0.3.5; make TARGET=power8; make TARGET=power8 PREFIX=$HOMEPATH/inst install; ```. ## Boost 1.66.0. ```bash; wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz; tar xzf boost_1_66_0.tar.gz; cd boost_1_66_0; ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst; ./b2 dll-path=""$HOMEPATH/inst/lib"" install; ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash; # development packages; yum install python-devel python-pip -y. # dependency of numpy 1.14.6; OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6; # verify; python -c ""import numpy"". # dependecy of scipy 1.2.0; OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0; # verify; python -c ""imp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:8424,error,error,8424,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['error'],['error']
Availability," now the ```rtg-tools format``` miraculously work using the following command. ```; docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; realtimegenomics/rtg-tools format \; -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta""; ```. And this is the result . ```; Formatting FASTA data; Processing ""/reference/GRCh38_no_alt_analysis_set.fasta"". Detected: 'Human GRCh38 with UCSC naming', installing reference.txt. Input Data; Files : GRCh38_no_alt_analysis_set.fasta; Format : FASTA; Type : DNA; Number of sequences: 195; Total residues : 3099922541; Minimum length : 970; Mean length : 15897038; Maximum length : 248956422. Output Data; SDF-ID : 809c9a82-d8d5-477a-865b-772d28741815; Number of sequences: 195; Total residues : 3099922541; Minimum length : 970; Mean length : 15897038; Maximum length : 248956422; ```. However this ```rtg-tools mendelian``` still result in error of ```Error: An IO problem occurred: ""Not in GZIP format""``` when running the following command below; ```; docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; -v ""${PWD}/output"":""/output"" \; realtimegenomics/rtg-tools mendelian \; -i ""/output/HG002_trio_merged.vcf.gz"" \; -o ""/output/HG002_trio_annotated.output.vcf.gz"" \; --pedigree=/reference/trio.ped \; -t /reference/GRCh38_no_alt_analysis_set.sdf \; | tee output/deepvariant.input_rtg_output.txt; ```. Have tried looking the wrong data and it seems the following GLNexus VCF Merge command is giving corrupted ```HG002_trio_merged.vcf.gz```. ```; docker run \; -v ""${PWD}/output"":""/output"" \; quay.io/mlin/glnexus:v1.2.7 \; /usr/local/bin/glnexus_cli \; --config DeepVariant_unfiltered \; /output/HG002.g.vcf.gz \; /output/HG003.g.vcf.gz \; /output/HG004.g.vcf.gz \; | docker run -i google/deepvariant:deeptrio-""${BIN_VERSION}-gpu"" \; bcftools view - \; | docker run -i google/deepvariant:deeptrio-""${BIN_VERSION}-gpu"" \; bgzip -c > output/HG002_trio_merged.vcf.gz; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/632#issuecomment-1512450759:953,error,error,953,,https://github.com/google/deepvariant/issues/632#issuecomment-1512450759,2,"['Error', 'error']","['Error', 'error']"
Availability," present on the command line: ""['/tmp/Bazel.runfiles_05qe3qax/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '36']"".; E0430 18:57:45.197033 140638292031296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_75j2ynwd/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '5']"".; E0430 18:57:45.264279 139811152422720 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i060jaf0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:7988,error,errors,7988,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:9382,error,errors,9382,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_0ekpfvin/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '24']"".; E0430 18:57:45.283955 140581469652800 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_brxc6_sa/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '7']"".; E0430 18:57:45.303462 139795832272704 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_sfy61tb_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '29']"".; E0430 18:57:45.331091 140537432155968 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_y60taw80/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '31']"".; E0430 18:57:45.239560 139714767980352 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_v3df_cxj/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E0430 18:57:45.264230 139873562601280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_qtxrg7dl/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '6']"".; E0430 18:57:45.193969 139692519348032 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:6037,error,errors,6037,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_2hbfxd92/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '16']"".; E0430 18:57:45.196900 140351706515264 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles__ytoy0a6/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '4']"".; E0430 18:57:45.304501 140371551012672 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_w7jwxlqo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '28']"".; E0430 18:57:45.337900 139621533210432 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_22p2hp0z/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '45']"".; E0430 18:57:45.424449 139874966882112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_wv1oakms/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '46']"".; E0430 18:57:45.268234 140085723301696 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_g62feq4g/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '10']"".; E0430 18:57:45.190006 140494428116800 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_gsw00kpo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '12']"".; E0430 18:57:45.278714 140080891017024 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:2132,error,errors,2132,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_3baynv6p/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '47']"".; E0430 18:57:45.249558 140521800120128 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_hpf7iban/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"".; E0430 18:57:45.245847 140159308461888 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_0ekpfvin/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '24']"".; E0430 18:57:45.283955 140581469652800 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_brxc6_sa/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '7']"".; E0430 18:57:45.303462 139795832272704 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_sfy61tb_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '29']"".; E0430 18:57:45.331091 140537432155968 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_y60taw80/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '31']"".; E0430 18:57:45.239560 139714767980352 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_v3df_cxj/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:5479,error,errors,5479,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_75j2ynwd/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '5']"".; E0430 18:57:45.264279 139811152422720 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i060jaf0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:8267,error,errors,8267,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles__ytoy0a6/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '4']"".; E0430 18:57:45.304501 140371551012672 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_w7jwxlqo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '28']"".; E0430 18:57:45.337900 139621533210432 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_22p2hp0z/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '45']"".; E0430 18:57:45.424449 139874966882112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_wv1oakms/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '46']"".; E0430 18:57:45.268234 140085723301696 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_g62feq4g/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '10']"".; E0430 18:57:45.190006 140494428116800 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_gsw00kpo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '12']"".; E0430 18:57:45.278714 140080891017024 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles__lr697ii/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '20']"".; E0430 18:57:45.366031 140648053425984 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:2411,error,errors,2411,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_brxc6_sa/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '7']"".; E0430 18:57:45.303462 139795832272704 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_sfy61tb_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '29']"".; E0430 18:57:45.331091 140537432155968 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_y60taw80/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '31']"".; E0430 18:57:45.239560 139714767980352 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_v3df_cxj/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E0430 18:57:45.264230 139873562601280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_qtxrg7dl/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '6']"".; E0430 18:57:45.193969 139692519348032 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_05qe3qax/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '36']"".; E0430 18:57:45.197033 140638292031296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:6316,error,errors,6316,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:9103,error,errors,9103,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_hpf7iban/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"".; E0430 18:57:45.245847 140159308461888 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_0ekpfvin/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '24']"".; E0430 18:57:45.283955 140581469652800 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_brxc6_sa/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '7']"".; E0430 18:57:45.303462 139795832272704 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_sfy61tb_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '29']"".; E0430 18:57:45.331091 140537432155968 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_y60taw80/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '31']"".; E0430 18:57:45.239560 139714767980352 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_v3df_cxj/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E0430 18:57:45.264230 139873562601280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:5758,error,errors,5758,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_i060jaf0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:8545,error,errors,8545,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_q2sdkm67/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '23']"".; E0430 18:57:45.246095 140479227369280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:9660,error,errors,9660,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:8824,error,errors,8824,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_q2sdkm67/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '23']"".; E0430 18:57:45.246095 140479227369280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_uphv_tdy/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '37']"".; E0430 18:57:45.317537 139819477477184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_4750gtic/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '43']"".; E0430 18:57:45.318566 140493027030848 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_mw222qvc/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '19']"".; E0430 18:57:45.281981 139640920373056 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_087sqql0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '18']"".; E0430 18:57:45.269598 140672023549760 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:10775,error,errors,10775,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_prpwm4tu/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '41']"".; E0430 18:57:45.343238 140414174025536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_dqd3ut4s/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '32']"".; E0430 18:57:45.247818 140240365713216 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_8s9w7qaa/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '25']"".; E0430 18:57:45.247906 139736525375296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_8kqng5_c/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '1']"".; E0430 18:57:45.354531 139703252227904 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_47rk8xc1/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '22']"".; E0430 18:57:45.318170 140515109386048 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_4p5rc3ja/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '35']"".; E0430 18:57:45.306068 140062873229120 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xavizfpc/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '42']"".; E0430 18:57:45.268234 140590012761920 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:12727,error,errors,12727,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_q2sdkm67/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '23']"".; E0430 18:57:45.246095 140479227369280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_uphv_tdy/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '37']"".; E0430 18:57:45.317537 139819477477184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_4750gtic/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '43']"".; E0430 18:57:45.318566 140493027030848 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_mw222qvc/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '19']"".; E0430 18:57:45.281981 139640920373056 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_087sqql0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '18']"".; E0430 18:57:45.269598 140672023549760 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_prpwm4tu/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '41']"".; E0430 18:57:45.343238 140414174025536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:11054,error,errors,11054,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_v3df_cxj/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E0430 18:57:45.264230 139873562601280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_qtxrg7dl/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '6']"".; E0430 18:57:45.193969 139692519348032 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_05qe3qax/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '36']"".; E0430 18:57:45.197033 140638292031296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_75j2ynwd/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '5']"".; E0430 18:57:45.264279 139811152422720 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i060jaf0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:7152,error,errors,7152,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_y60taw80/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '31']"".; E0430 18:57:45.239560 139714767980352 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_v3df_cxj/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E0430 18:57:45.264230 139873562601280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_qtxrg7dl/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '6']"".; E0430 18:57:45.193969 139692519348032 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_05qe3qax/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '36']"".; E0430 18:57:45.197033 140638292031296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_75j2ynwd/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '5']"".; E0430 18:57:45.264279 139811152422720 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i060jaf0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:6873,error,errors,6873,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_q2sdkm67/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '23']"".; E0430 18:57:45.246095 140479227369280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_uphv_tdy/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '37']"".; E0430 18:57:45.317537 139819477477184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:9939,error,errors,9939,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability," response, I do not have a docker image yet. And I attached the detailed steps here for your reference. It's a bit long :). # DeepVariant. ## Environment. ```bash; # Power8 environment; export CPU=power8; export HOMEPATH=/home/qilibj; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # AT 11.0 environment; source /etc/profile; module load at11.0; export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # python2 and pip environment; export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH; export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages; export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python; export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages; ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash; # download source code; wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz; tar -zxvf cmake-3.13.3.tar.gz; cd cmake-3.13.3. # build scirpt; ./bootstrap; make -j20; make -j20 install; export PATH=/usr/local/bin:$PATH; ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash; # download source code; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz; tar -zxvf protobuf-all-3.6.1.tar.gz; cd protobuf-3.6.1/. # clean static protobuf build; make uninstall; make distclean. # environment; export CPU=power8; export HOMEPATH=/home/qilibj; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:1044,down,download,1044,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['down'],['download']
Availability," run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main; commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles; check_flags(); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags; raise RuntimeError('The model files {}* do not exist. Potentially '; RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open; ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash; docker run \; -v `pwd`:`pwd` -w `pwd` \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \; --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \; --model_type=WGS \; --ref=""input/data/${REF}"" \; --reads=""input/data/${BAM}"" \; --output_vcf=""output/${OUTPUT_VCF}"" \; --output_gvcf=""output/${OUTPUT_GVCF}"" \; --regions chr20 \; --num_shards=$(nproc) \; --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn.; I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn.; INFO:tensorflow:TPU job name tpu_worker; I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker; INFO:tensorflow:Graph wa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874:4432,error,error,4432,,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874,4,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability," subtract:; ```bash; bedtools subtract \; -a HG003_043024.indels_only.bcftools_filter.vcf.gz \; -b HG003_indels_043024.vcf.gz | wc -l. 180869; ```. So roughly it matches. Now look at some variants:; ```bash; bedtools subtract \; -a HG003_043024.indels_only.bcftools_filter.vcf.gz \; -b HG003_indels_043024.vcf.gz | head. chr1	10247	.	TAAACCCTA	T	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:9:41:28,4:0.097561:0,14,10; chr1	98999	.	TTTTATTTA	T,TTTTATTTATTTA	20	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:10:31:20,9,2:0.290323,0.0645161:19,16,12,16,0,21; chr1	99092	.	C	CT	2.7	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:3:50:19,7:0.14:0,1,8; chr1	101674	.	C	CAAA	0.6	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:9:29:23,2:0.0689655:0,8,17; chr1	104160	.	A	AACAC,AACACACAC	15.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:5:79:1,37,21:0.468354,0.265823:13,14,6,14,0,9; chr1	108545	.	C	CA	2.7	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:3:44:12,21:0.477273:0,1,6; chr1	109575	.	CGT	C,CGTGTGT	13	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:4:22:0,8,10:0.363636,0.454545:11,13,15,13,0,4; chr1	111513	.	C	CTA	19.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:18:33:0,30:0.909091:19,22,0; chr1	180150	.	AC	A,GC	15	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:2:19:2,6,9:0.315789,0.473684:11,13,2,13,0,1; chr1	180174	.	TAA	T	3.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:3:14:7,4:0.285714:0,9,0; ```. So there are few variants that we are not picking up. Next, I picked the region where variant ""chr1 10247"" is and ran make_examples with a debug command:. Without filter command:; ```bash; chr1 10240 T ['TA']; chr1 10246 TA ['T']; chr1 10249 A ['C']; chr1 10253 TA ['T']; chr1 10256 A ['C']; ```; I see these five variants. With filtering I see:; ```bash; FILTERING CANDIDATES; chr1 10240 T ['TA']; chr1 10246 TA ['T']; chr1 10253 TA ['T']; ```. I am unsure how to reproduce this. Are you using a publicly available bam file? I can also run DV with and without this command and generate results to investigate further. It would be faster and helpful if you can point me to the bam you are using so it's more specific to your issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/813#issuecomment-2089338246:2310,avail,available,2310,,https://github.com/google/deepvariant/issues/813#issuecomment-2089338246,1,['avail'],['available']
Availability," tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; werkzeug 2.3.4 requires MarkupSafe>=2.1.1, but you have markupsafe 2.0.1 which is incompatible.; ========== [Mon 05 Jun 2023 03:51:39 PM UTC] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ========== [Mon 05 Jun 2023 03:51:40 PM UTC] Stage 'run-prereq.sh complete' starting; ========== [Mon 05 Jun 2023 03:51:40 PM UTC] Stage 'Update package list' starting; ========== [Mon 05 Jun 2023 03:51:41 PM UTC] Stage 'build-prereq.sh: Install development packages' starting; Calling wait_for_dpkg_lock.; ========== [Mon 05 Jun 2023 03:51:42 PM UTC] Stage 'Install bazel",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:4378,ERROR,ERROR,4378,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,1,['ERROR'],['ERROR']
Availability," tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; werkzeug 2.3.4 requires MarkupSafe>=2.1.1, but you have markupsafe 2.0.1 which is incompatible.; ========== [Mon 05 Jun 2023 10:22:30 PM EDT] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ========== [Mon 05 Jun 2023 10:22:31 PM EDT] Stage 'run-prereq.sh complete' starting; ========== [Mon 05 Jun 2023 10:22:31 PM EDT] Stage 'Update package list' starting; ========== [Mon 05 Jun 2023 10:22:32 PM EDT] Stage 'build-prereq.sh: Install development packages' starting; Calling wait_for_dpkg_lock.; ========== [Mon 05 Jun 2023 10:22:32 PM EDT] Stage 'Install bazel",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053:5404,ERROR,ERROR,5404,,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053,1,['ERROR'],['ERROR']
Availability," the reference and non-reference read counts instead generated the reference call because a candidate was not made at that position.; > ; > Second, I would recommend that you look at the visual report that @MariaNattestad created in the most recent DeepVariant release. There is a way to run this on previous VCF files, see: [This page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); > ; > In that visualization, take a look at the VAF support for each call. The nearby variant phenomenon manifests as a higher number of REF calls with a VAF close to 1.0. In humans, this seems to be DeepVariant avoiding false calls in LINE elements and segmental duplications, but this could be undesirable depending on your reference genome and population structure. Hello, in my case, which is not humans, I find the following. First, the reads I used are the same used during the reference genome assembly process. Therefore, any new homozygous variant with a vaf of ~ 1 is either the reflect of assembly errors or mapping errors. I do find such variants. But I am more intrigued by the peak of Hom (x/x) at a vaf of ~ 0.5 . am I right to assume this is not typical and might reflect a problem? ; Interestingly for the reference calls, there also seems to be 2 peaks, one with a vaf around 0.2 which I guess is all right and one with a vaf around 0.5 which I guess also indicates a potential problem. ![genotypes_deepvariant](https://user-images.githubusercontent.com/23341393/72908229-7db81b00-3d35-11ea-99f9-e3dfa126a127.png). As I am working with an asexual diploid, I can't replicate the methodology of the mosquito to retrain deepvariant. I, however, have an ancestral population and the direct descendant, with absolutely no reason to believe the descendant might exhibit new mutations (except for the ones that might randomly occur but those should be negligible as it did not really have the time to diverge much, they are separated by a few generations max'). The",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/257#issuecomment-577247342:1319,error,errors,1319,,https://github.com/google/deepvariant/issues/257#issuecomment-577247342,2,['error'],['errors']
Availability," the reference needed for reading the cram file. Pysam uses a similar approach. . **The REF_PATH and REF_CACHE**; One of the key concepts in CRAM is that it is uses reference based compression. This means that Samtools needs the reference genome sequence in order to decode a CRAM file. Samtools uses the MD5 sum of the each reference sequence as the key to link a CRAM file to the reference genome used to generate it. By default Samtools checks the reference MD5 sums (@SQ “M5” auxiliary tag) in the directory pointed to by $REF_PATH environment variable (if it exists), falling back to querying the European Bioinformatics Institute (EBI) reference genome server, and further falling back to the @SQ “UR” field if these are not found. While the EBI have an MD5 reference server for downloading reference sequences over http, we recommend use of a local MD5 cache. We have provided with Samtools a basic script (misc/seq_cache_populate.pl) to convert your local yeast.fasta to a directory tree of reference sequence MD5 sums:. <samtools_src_dir>/misc/seq_cache_populate.pl -root /some_dir/cache yeast.fasta; export REF_PATH=/some_dir/cache/%2s/%2s/%s:http://www.ebi.ac.uk/ena/cram/md5/%s; export REF_CACHE=/some_dir/cache/%2s/%2s/%s; REF_PATH is a colon separated list of directories in which to search for files named after the sequence M5 field. The : in http:// is not considered to be a separator. Hence using the above setting, any CRAM files that are not cached locally may still be looked up remotely. In this example “%2s/%2s/%s” means the first two digits of the M5 field followed by slash, the next two digits and slash, and then the remaining 28 digits. This helps to avoid one large directory with thousands of files in it. The REF_CACHE environment variable is used to indicate that any downloaded reference sequences should be stored locally in this directory in order to avoid subsequent downloads. This should normally be set to the same location as the first directory in REF_PATH.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/38#issuecomment-372143466:1836,down,downloaded,1836,,https://github.com/google/deepvariant/issues/38#issuecomment-372143466,2,['down'],"['downloaded', 'downloads']"
Availability," to this variant call, there are a few things that I see: . First, DeepVariant has a very low confidence in this call. The GQ of 4 corresponds to a 40% chance of being incorrect. Interestingly, the second most likely call at this position according to DeepVariant is 0/0 (HomRef). This is in spite of a 0.27 variant allele frequency (something that most callers would probably consider as either 0/0 HomRef or 0/1 HET). . This is an indication that DeepVariant may think that one of the haplotypes (either the Ref one or the Alt one) are unreliable (e.g. that they are reads which map from a different part of the genome), but doesn't know which to consider. Some other lines of evidence DeepVariant might use for that is the higher coverage (1200 is a coverage that would often be seen in duplicated parts of the genome) and the unusual allele frequency ratio (70% Ref, 30% Alt). Another piece of evidence we can't see but DeepVariant may use is the Insert Size channel if this is Illumina data. . A few questions -. 1) What is the sequencing technology used here, and which type of instrument. Is this PacBio or Illumina here? ; 2) Is this some form of panel sequencing targeting the region? . One suggestion to try (especially if this is panel short read sequencing) - downsample the region to ~80-100 coverage and see if the call changes. Especially look for the GQ confidence to go up as 4 is very low. If you want to avoid such situations more, you might want to put a higher GQ threshold for downstream filtering, and for a specific case like this look for cases where the PL values show higher probability for HOMREF and ALT than HET. A GQ threshold of 10 would be a 90% probability the call is correct, a GQ threshold of 20 would be a 99% threshold. . Just from the evidence presented here, this site is going to be difficult to call, as just on the VAF this look more like a HET (though the other factors mentioned here about copy number variants could be the factor in allowing a REF call.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/655#issuecomment-1570674832:1402,down,downsample,1402,,https://github.com/google/deepvariant/issues/655#issuecomment-1570674832,4,['down'],"['downsample', 'downstream']"
Availability," whether this affects singularity); 1.17.5; 4. Just to confirm, which *simg file are you using? The command you run? Was this with or without GPU?. I tried using the deepvariant-0.9.0.simg image from here with and without GPU: `https://storage.googleapis.com/deepvariant/singularity_images`; # Pull Singularity images; INPUT_DIR='singularity'; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/singularity_images""; # Non-gpu image; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/deepvariant-0.9.0.simg; # GPU image; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/deepvariant-0.9.0-gpu.simg. # Test Singularity DeepVariant0.9.0 image on test data; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; ${INPUT_DIR}/deepvariant-${BIN_VERSION}.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz . # Errors:. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2020-01-31 01:37:29.333483: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . # Test Singularity DeepVariant0.9.0 GPU image on test data; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; ${INPUT_DIR}/deepvariant-${BIN_VERSION}-gpu.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz . # Errors: ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_0Ul6DZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 43, in <module>; import tensorflow as tf; File ""/usr/local/lib/python2.7/dist-packages/tensorflow",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/265#issuecomment-580549772:1347,Error,Errors,1347,,https://github.com/google/deepvariant/issues/265#issuecomment-580549772,1,['Error'],['Errors']
Availability," while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```; sudo sh run_deepvariant.sh; Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally; latest: Pulling from deepvariant-docker/deepvariant; 18d680d61657: Pull complete; 0addb6fece63: Pull complete; 78e58219b215: Pull complete; eb6959a66df2: Pull complete; 54de1d38bbd7: Pull complete; d17c3563217d: Pull complete; ba1bdbdefce9: Pull complete; 94eba53c4ad9: Pull complete; 413f494b0501: Pull complete; 4d89363e7fb4: Pull complete; e9213d1ccf36: Pull complete; fb6121657d6b: Pull complete; Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f; Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest; docker images; terminate called after throwing an instance of 'std::bad_alloc'; what(): std::bad_alloc; ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `docker ps -a` after the script stopped from that error message. So, that puts me back where I started, and I actually have that extra error message (over trying to use Docker from the instance launched via ECS). Nevertheless, if I make any additional progress, I will let you know. **Update (4/10/2019)**: FYI, if anybody else has a similar problem, I eventually remembered that I needed to add myself to the Docker group using `sudo usermod -a -G docker ec2-user`, exiting, and then starting a new ssh session (a similar command was useful when I wanted to use gcsfuse along with Docker on Google Cloud, which is what I am currently testing...).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480642492:1970,error,error,1970,,https://github.com/google/deepvariant/issues/167#issuecomment-480642492,3,['error'],['error']
Availability,"# Follow https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md. I got a machine:. ```bash; host=""${USER}-deepvariant-vm""; zone=""us-west1-b"". gcloud compute instances create ${host} \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --maintenance-policy ""TERMINATE"" \; --accelerator=type=nvidia-tesla-p100,count=1 \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-16"" \; --boot-disk-size ""300"" \; --zone ""${zone}"" \; --min-cpu-platform ""Intel Skylake""; ```. I sshed into my machine:. ```bash; gcloud compute ssh pichuan-deepvariant-vm --zone us-west1-b; ```. I ran this with my own `YOUR_PROJECT` and `OUTPUT_GCS_BUCKET` setting.; Then the following is basically just copy/paste from the doc:. ```; BUCKET=""gs://deepvariant""; VERSION=""1.6.1""; DOCKER_IMAGE=""google/deepvariant:${VERSION}"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${VERSION}/DeepVariant-inception_v3-${VERSION}+data-wgs_standard""; GCS_PRETRAINED_WGS_MODEL=""${MODEL_BUCKET}/model.ckpt"". OUTPUT_BUCKET=""${OUTPUT_GCS_BUCKET}/customized_training""; TRAINING_DIR=""${OUTPUT_BUCKET}/training_dir"". BASE=""${HOME}/training-case-study""; DATA_BUCKET=gs://deepvariant/training-case-study/BGISEQ-HG001. INPUT_DIR=""${BASE}/input""; BIN_DIR=""${INPUT_DIR}/bin""; DATA_DIR=""${INPUT_DIR}/data""; OUTPUT_DIR=""${BASE}/output""; LOG_DIR=""${OUTPUT_DIR}/logs""; SHUFFLE_SCRIPT_DIR=""${HOME}/deepvariant/tools"". REF=""${DATA_DIR}/ucsc_hg19.fa""; BAM_CHR1=""${DATA_DIR}/BGISEQ_PE100_NA12878.sorted.chr1.bam""; BAM_CHR20=""${DATA_DIR}/BGISEQ_PE100_NA12878.sorted.chr20.bam""; BAM_CHR21=""${DATA_DIR}/BGISEQ_PE100_NA12878.sorted.chr21.bam""; TRUTH_VCF=""${DATA_DIR}/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf.gz""; TRUTH_BED=""${DATA_DIR}/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_nosomaticdel_chr.bed"". N_SHARDS=16; ```. ```bash; mkdir -p ""${OUTPUT_DIR}""; mkd",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/793#issuecomment-2008639269:275,mainten,maintenance-policy,275,,https://github.com/google/deepvariant/issues/793#issuecomment-2008639269,1,['mainten'],['maintenance-policy']
Availability,"## When there isn't an error message at all:; Is it possible that it could be running out of memory? That could be why running on an individual region succeeds while it fails on the whole bed file. Out of memory issues are hard to catch because they don't result in error messages. I ran the exome case study myself just now and it worked fine. In terms of compute resources, our testing system goes as low as ""n1-standard-8"" on Google Cloud, which is 8 vCPUs and 30 GB of memory. If your setup is less than 30GB of memory that might be the cause of the issue. Reducing the number of shards to 1 might help, but if it doesn't, you might just need to use a machine with more resources. ## When faidx also fails; Check that the fasta looks okay and perhaps redo the `samtools faidx` that created the `.fai` in the first place just in case. Is the ""chr1"" the exact sequence name of one the sequences in the fasta?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/483#issuecomment-917501282:23,error,error,23,,https://github.com/google/deepvariant/issues/483#issuecomment-917501282,2,['error'],['error']
Availability,"##########; # # CUDA; # ################################################################################. # note_build_stage ""Install CUDA"". # # See https://www.tensorflow.org/install/source#gpu for versions required.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # if [[ ""${DV_INSTALL_GPU_DRIVERS}"" = ""1"" ]]; then; # # This script is only maintained for Ubuntu 20.04.; # UBUNTU_VERSION=""2004""; # # https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_local; # echo ""Checking for CUDA...""; # if ! dpkg-query -W cuda-11-3; then; # echo ""Installing CUDA...""; # UBUNTU_VERSION=""2004""; # curl -O https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin; # sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600; # # From https://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212772; # sudo -H apt-key adv --fetch-keys ""http://developer.download.nvidia.com/compute/cuda/repos/ubuntu${UBUNTU_VERSION}/x86_64/3bf863cc.pub""; # sudo add-apt-repository -y ""deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /""; # sudo -H apt-get update ""${APT_ARGS[@]}""; # # From: https://superuser.com/a/1638789; # sudo -H DEBIAN_FRONTEND=noninteractive apt-get \; # -o Dpkg::Options::=--force-confold \; # -o Dpkg::Options::=--force-confdef \; # -y --allow-downgrades --allow-remove-essential --allow-change-held-packages \; # full-upgrade; # sudo -H apt-get install ""${APT_ARGS[@]}"" cuda-11-3; # fi; # echo ""Checking for CUDNN...""; # if [[ ! -e /usr/local/cuda-11/include/cudnn.h ]]; then; # echo ""Installing CUDNN...""; # CUDNN_TAR_FILE=""cudnn-11.3-linux-x64-v8.2.0.53.tgz""; # wget -q https://developer.download.nvidia.com/compute/redist/cudnn/v8.2.0/${CUDNN_TAR_FILE}; # tar -xzvf ${CUDNN_TAR_FILE}; # sudo cp -P cuda/include/cudnn.h /usr/local/cuda-11/include; # sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-11/lib64/; # sudo ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:3380,down,download,3380,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,2,['down'],['download']
Availability,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. ; (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html; Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP.; If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/92#issuecomment-418171330:444,robust,robust,444,,https://github.com/google/deepvariant/issues/92#issuecomment-418171330,1,['robust'],['robust']
Availability,"(https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out “complex variants” (with more than one variant at a position), but .vcf files containing those variants weren’t flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:; ```; 68759 / 72556 (94.8%) full SNP recovery; 71276 / 72556 (98.2%) partial SNP recovery; 3027 / 3648 (83.0%) full insertion recovery; 3413 / 3648 (93.6%) partial insertion recovery; 3119 / 3911 (79.7%) full deletion recovery; 3596 / 3911 (91.9%) partial deletion recovery; ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:; ```; 51417 / 54229 (94.8%) full SNP recovery; 53116 / 54229 (97.9%) partial SNP recovery; 1964 / 2391 (82.1%) full insertion recovery; 2242 / 2391 (93.8%) partial insertion recovery; 2058 / 2537 (81.1%) full deletion recovery; 2349 / 2537 (92.6%) partial deletion recovery; ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a “*partial*” recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didn’t feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), bu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:1857,recover,recovery,1857,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"). > Note: Python 2 should be built from AT 11.0. ```bash; # download source code ; wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz; tar -zxvf Python-2.7.15.tgz; cd Python-2.7.15. # environment; export HOMEPATH=/home/qilibj; export CPU=power8. # check gcc before build, should be AT11.0; which gcc. # build; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static; make -j20; make install. # set environment; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin; export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH; export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15; echo ""$(python --version)"". # Pip 19.0.2; wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate; $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst; #pip install --upgrade --force-reinstall pip; echo ""$(pip --version)""; pip install setuptools nose asv cython future protobuf==3.6.1 six mock; pip install --upgrade setuptools; ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash; # download source code; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz; tar -zxvf protobuf-all-3.6.1.tar.gz; cd protobuf-3.6.1/. # clean static protobuf build; make uninstall; make distclean. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static; make clean; make -j20; # optional; make -j20 check # check if protobuf build is good; # install; make install; sudo ldconfig # refresh shared librar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:5820,echo,echo,5820,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['echo'],['echo']
Availability,").; 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.; mkdir: cannot create directory ‘logs’: Permission denied; 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k; 0inputs+0outputs (0major+73minor)pagefaults 0swaps; Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists.; time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled""; parallel: This job failed:; sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0; docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists.; ERRO[0000] error waiting for container: context canceled; ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483490946:4672,Error,Error,4672,,https://github.com/google/deepvariant/issues/171#issuecomment-483490946,2,"['Error', 'error']","['Error', 'error']"
Availability,")/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; (05:40:22) INFO: Found applicable config definition build:dynamic_kernels in file /tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; (05:40:23) INFO: Current date is 2023-12-18; (05:40:23) DEBUG: /root/.cache/bazel/_bazel_root/18a0a1d061f0109a3b92fbdafbaf1bbd/external/org_tensorflow/third_party/repo.bzl:132:14: ; Warning: skipping import of repository 'com_google_protobuf' because it already exists.; (05:40:23) INFO: Analyzed 189 targets (0 packages loaded, 0 targets configured).; (05:40:23) INFO: Found 141 targets and 48 test targets...; (05:40:24) ERROR: /deepvariant/third_party/nucleus/util/python/BUILD:13:11: CLIF wrapping third_party/nucleus/util/python/math.clif failed: (Exit 3): pyclif failed: error executing command ; (cd /root/.cache/bazel/_bazel_root/18a0a1d061f0109a3b92fbdafbaf1bbd/execroot/com_google_deepvariant && \; exec env - \; bazel-out/k8-opt-exec-50AE0418/bin/external/clif/pyclif --modname third_party.nucleus.util.python.math -c bazel-out/k8-opt/bin/third_party/nucleus/util/python/math.cc -g bazel-out/k8-opt/bin/third_party/nucleus/util/python/math.h -i bazel-out/k8-opt/bin/third_party/nucleus/util/python/math_init.cc --prepend clif/python/types.h -I. -Ibazel-out/k8-opt/bin -Iexternal/com_google_absl -Ibazel-out/k8-opt/bin/external/com_google_absl -Iexternal/clif -Ibazel-out/k8-opt/bin/external/clif -Iexternal/com_google_glog -Ibazel-out/k8-opt/bin/external/com_google_glog -Iexternal/com_github_gflags_gflags -Ibazel-out/k8-opt/bin/external/com_github_gflags_gflags -Iexternal/com_google_protobuf -Ibazel-out/k8-opt/bin/external/com_google_protobuf -Iexternal/zlib -Ibazel-out/k8-opt/bin/external/zlib -Iexternal/local_config_python -Ibazel-out/k8-opt/bin/external/loc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:10461,error,error,10461,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,1,['error'],['error']
Availability,"* Please make sure that contig names are consistent in both BAM file and reference. May be you could paste couple of lines (10 lines) from BAM and from your reference?; * Having ""Failed to retrieve block: unexpected end of file"" error message may mean that BAM index does not match the BAM file. Could you try to reindex your BAM?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/367#issuecomment-716198032:229,error,error,229,,https://github.com/google/deepvariant/issues/367#issuecomment-716198032,1,['error'],['error']
Availability,"**Provided Exome on Provided WGS .bam Alignment**:; ```; 68759 / 72556 (94.8%) full SNP recovery; 71276 / 72556 (98.2%) partial SNP recovery; 3027 / 3648 (83.0%) full insertion recovery; 3413 / 3648 (93.6%) partial insertion recovery; 3119 / 3911 (79.7%) full deletion recovery; 3596 / 3911 (91.9%) partial deletion recovery; ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:; ```; 51417 / 54229 (94.8%) full SNP recovery; 53116 / 54229 (97.9%) partial SNP recovery; 1964 / 2391 (82.1%) full insertion recovery; 2242 / 2391 (93.8%) partial insertion recovery; 2058 / 2537 (81.1%) full deletion recovery; 2349 / 2537 (92.6%) partial deletion recovery; ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a “*partial*” recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didn’t feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):; ```; 39494 / 41450 (95.3%) full SNP recovery; 39678 / 41450 (95.7%) partial SNP recovery; ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and I’m not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the “*full*” ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:2520,recover,recovery,2520,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=72:00:00; #SBATCH --mem-per-cpu=64GB. module purge; module load parallel; module load singularity. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \; --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \; --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **I get the error:** ; ; ```; raise ValueError('The regions to call is empty. Check your --regions and '; ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa).; parallel: This job failed:; /opt/deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/527#issuecomment-1067792214:95,down,download,95,,https://github.com/google/deepvariant/issues/527#issuecomment-1067792214,3,"['down', 'error']","['download', 'error']"
Availability,", in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```; # install docker; sudo yum check-update; curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker; distribution=$(. /etc/os-release;echo $ID$VERSION_ID); curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \; sudo tee /etc/yum.repos.d/nvidia-docker.repo; sudo yum install -y nvidia-docker2; semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker; sudo restorecon -v /usr/bin/nvidia-docker. # start docker; sudo systemctl start docker; sudo systemctl status docker; sudo systemctl enable docker. # install deps; sudo yum groupinstall -y 'Development Tools' && \; sudo yum install -y epel-release && \; sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools; echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \; echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \; source ~/.bashrc. # install singularity; mkdir -p ${GOPATH}/src/github.com/sylabs && \; cd ${GOPATH}/src/github.com/sylabs && \; git clone https://github.com/sylabs/singularity.git && \; cd singularity; git checkout v3.1.1; cd ${GOPATH}/src/github.com/sylabs/singularity && \; ./mconfig && \; cd ./builddir && \; make && \; sudo make install; ; DVVER=0.8.0; # make deepvariant CPU image; sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}; sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest; sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2; sudo docker push localhost:5000/deepvariant:latest; singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest; ; # make deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-482761898:1193,echo,echo,1193,,https://github.com/google/deepvariant/issues/132#issuecomment-482761898,1,['echo'],['echo']
Availability,",cloud-platform"" \; --image-family ""centos-8"" \; --image-project ""centos-cloud"" \; --machine-type ""e2-standard-16"" \; --boot-disk-size ""200G"" \; --zone ""us-west1-b""; ```. ssh into the machine:; ```; gcloud compute ssh ${USER}-centos8; ```. Check OS version:; ```; [pichuan@pichuan-centos8 ~]$ cat /etc/os-release; NAME=""CentOS Linux""; VERSION=""8""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""8""; PLATFORM_ID=""platform:el8""; PRETTY_NAME=""CentOS Linux 8""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:8""; HOME_URL=""https://centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/""; CENTOS_MANTISBT_PROJECT=""CentOS-8""; CENTOS_MANTISBT_PROJECT_VERSION=""8""; ```. I installed singularity on the machine following instructions on https://sylabs.io/guides/3.7/admin-guide/installation.html#installation-on-linux. Confirmed the version:; ```; [pichuan@pichuan-centos8 ~]$ singularity --version; singularity version 3.7.0-1.el8; ```. I'm using the data in Quick Start to test. I downloaded data in the Quick Start: https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md. Then, I ran:; ```; BIN_VERSION=1.1.0. singularity build deepvariant.sif docker://google/deepvariant:${BIN_VERSION}. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1; ```. After this, examine the content in ""${OUTPUT_DIR}/intermediate_results_dir"". ```; [pichuan@pichuan-centos8 ~]$ ls -1 ""${OUTPUT_DIR}/intermediate_results_dir""; call_variants_output.tfrecord.gz; gvcf.tfrecord-00000-of-00001.gz; make_examples.tfrecord-00000-of-00001.gz; ```. Next, I want to try running with `--inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/296#issuecomment-767294612:1841,down,downloaded,1841,,https://github.com/google/deepvariant/issues/296#issuecomment-767294612,2,['down'],['downloaded']
Availability,"-------------------------------+----------------------+----------------------+; | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |; | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |; | | | MIG M. |; |===============================+======================+======================|; | 0 Tesla P100-PCIE... Off | 00000000:00:04.0 Off | 0 |; | N/A 34C P0 29W / 250W | 0MiB / 16384MiB | 1% Default |; | | | N/A |; +-------------------------------+----------------------+----------------------+; ; +-----------------------------------------------------------------------------+; | Processes: |; | GPU GI CI PID Type Process name GPU Memory |; | ID ID Usage |; |=============================================================================|; | No running processes found |; +-----------------------------------------------------------------------------+; ```. Then I install cuda. This was from: https://developer.nvidia.com/cuda-downloads; ```; curl -O https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run ; export TERM=xterm; sudo sh cuda_12.1.0_530.30.02_linux.run; ```. ```; export PATH=/usr/local/cuda-12.1/bin:$PATH; export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH; sudo ldconfig; ```. ```; [pichuan@pichuan-gpu2 ~]$ nvcc --version; nvcc: NVIDIA (R) Cuda compiler driver; Copyright (c) 2005-2023 NVIDIA Corporation; Built on Tue_Feb__7_19:32:13_PST_2023; Cuda compilation tools, release 12.1, V12.1.66; Build cuda_12.1.r12.1/compiler.32415258_0; ```. This is not 11.8, but is a newer version. So let's test with it. Install Singularity:. ```; curl -O https://raw.githubusercontent.com/google/deepvariant/r1.5/scripts/install_singularity.sh; sed -i -e 's/apt-get/yum/g' install_singularity.sh; bash -x install_singularity.sh; ```. Check version:; ```; [pichuan@pichuan-gpu2 ~]$ singularity --version; singularity version 3.7.0; ```. The rest is similar to https://github.com/google/deepvariant/issue",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471348553:1969,down,download,1969,,https://github.com/google/deepvariant/issues/619#issuecomment-1471348553,1,['down'],['download']
Availability,"--scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-64"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. I sshed into the machine. ```bash; gcloud compute ssh pichuan-cpu --zone us-west1-b; ```. Then, on the machine, I get DeepVariant r1.5 source first:. ```bash; git clone https://github.com/google/deepvariant.git; cd deepvariant/; git checkout r1.5; ```. And I confirmed the version:. ```; pichuan@pichuan-cpu:~/deepvariant$ git log | head; commit ab068c4588a02e2167051bd9e74c0c9579462b51; Author: pichuan <pichuan@google.com>; Date: Mon Feb 27 23:03:48 2023 -0800. Update README.md; ; PiperOrigin-RevId: 512838102. ```. From there, I followed the instructions on https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-build-test.md; So I ran:. ```bash; sudo su; ./build-prereq.sh; ```. My run succeeded. I looked at my log to see the section close to where your error occurred. And I see:. ```; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"") ; -- Checking for module 'protobuf'; -- Found protobuf, version 3.13.0; -- Checking for module 'libglog'; -- Found libglog, version 0.4.0; -- Looking for pth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785:1660,error,error,1660,,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785,1,['error'],['error']
Availability,"-char"". # for GPU enabled; # fix ""ImportError: No module named google.protobuf"" by install protobuf from source; bazel clean; bazel shutdown; bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \; --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \; --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \; --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \; --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \; --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &; bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only; bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary; bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; echo 'Expect a usage message:'; (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; ```. ## Fix DV Error. ```bash; ################################################################################; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test; # use lscpu to show the actual CPU number; ################################################################################; python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160; python -c ""import psutil;print(p/sutil.cpu_count; ())"" #160. vim deepvariant/resources.py; --------------------------------; def _get_cpu_count():; """"""Gets the number of physical cores in this machine.; Returns:; int >= 1 if the call to get the cpu_count succeeded, or 0 if not.; """"""; # return psutil.cpu_count(logical=False) or 0 ==> comment; return 20;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:19607,echo,echo,19607,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['echo'],['echo']
Availability,"-output_gvcf=""output/${OUTPUT_GVCF}"" \; --regions chr20 \; --num_shards=$(nproc) \; --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn.; I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn.; INFO:tensorflow:TPU job name tpu_worker; I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker; INFO:tensorflow:Graph was finalized.; I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt; I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt; INFO:tensorflow:prediction_loop marked as finished; I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished; WARNING:tensorflow:Reraising captured error; W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error; Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call; return fn(*args); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn; return self._call_tf_sessionrun(options, feed_dict, fetch_list,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun; return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,; tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt; [[{{node save_1/RestoreV2}}]]. During handling of the above exception,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874:6055,error,error,6055,,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874,2,['error'],['error']
Availability,"-xzf singularity-ce-${VERSION}.tar.gz && \; cd singularity-ce-${VERSION}; ```. ```bash; ./mconfig && \; make -C builddir && \; sudo make -C builddir install; ```. At this point, I have singularity installed. ```bash; $ singularity --version; singularity-ce version 4.1.0; ```. ## Get data and run DeepVariant. Now, let me try to follow similar steps:. ```bash; singularity build DeepVariant_1.6.1.sif docker://google/deepvariant:1.6.1; ```. From here, I used https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-pacbio-model-case-study.md to test. Download data:. ```bash; mkdir -p reference. FTPDIR=ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids. curl ${FTPDIR}/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | gunzip > reference/GRCh38_no_alt_analysis_set.fasta; curl ${FTPDIR}/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.fai > reference/GRCh38_no_alt_analysis_set.fasta.fai; ```. ```bash; mkdir -p input; HTTPDIR=https://downloads.pacbcloud.com/public/dataset/HG003/deepvariant-case-study. curl ${HTTPDIR}/HG003.GRCh38.chr20.pFDA_truthv2.bam > input/HG003.GRCh38.chr20.pFDA_truthv2.bam; curl ${HTTPDIR}/HG003.GRCh38.chr20.pFDA_truthv2.bam.bai > input/HG003.GRCh38.chr20.pFDA_truthv2.bam.bai; ```. ```bash; ulimit -u 10000; BIN_VERSION=""1.6.1""; mkdir -p deepvariant_output; ```. @Carl-labhub mentioned ""When I run it, I’m doing so from an interactive session with singularity exec"". I'm a bit confused by this. Maybe you mean `singularity shell`? So I tried:. ```bash; singularity shell --bind /usr/lib/locale/ DeepVariant_1.6.1.sif; ```; This gets into a shell mode, then I ran:. ```; Singularity> /opt/deepvariant/bin/run_deepvariant \; > --model_type PACBIO \; > --ref reference/GRCh38_no_alt_analysis_set.fasta \; > --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \; > --output_vcf deepvariant_output/output.vcf.gz \; > --num_shards $(nproc) \; > --regions chr20; ```. Directly `singularity exec` wit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/812#issuecomment-2076206716:3572,down,downloads,3572,,https://github.com/google/deepvariant/issues/812#issuecomment-2076206716,2,['down'],['downloads']
Availability,". **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out “complex variants” (with more than one variant at a position), but .vcf files containing those variants weren’t flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:; ```; 68759 / 72556 (94.8%) full SNP recovery; 71276 / 72556 (98.2%) partial SNP recovery; 3027 / 3648 (83.0%) full insertion recovery; 3413 / 3648 (93.6%) partial insertion recovery; 3119 / 3911 (79.7%) full deletion recovery; 3596 / 3911 (91.9%) partial deletion recovery; ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:; ```; 51417 / 54229 (94.8%) full SNP recovery; 53116 / 54229 (97.9%) partial SNP recovery; 1964 / 2391 (82.1%) full insertion recovery; 2242 / 2391 (93.8%) partial insertion recovery; 2058 / 2537 (81.1%) full deletion recovery; 2349 / 2537 (92.6%) partial deletion recovery; ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a “*partial*” recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didn’t feel comfortable showing comparisons between variant callers on my page with notes/code on my [Gen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:1766,recover,recovery,1766,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"./gvcf.tfrecord@8.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sample_name ""SAMPLENAME"" --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. /opt/deepvariant/bin/call_variants --outfile ""./call_variants_output.tfrecord.gz"" --examples ""./make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/pacbio"". /opt/deepvariant/bin/postprocess_variants --ref ""stdchroms.hg38.fa"" --infile ""./call_variants_output.tfrecord.gz"" --outfile ""./SAMPLENAME.deepVariant.vcf.gz"" --cpus ""8"" --gvcf_outfile ""./SAMPLENAME.deepVariant.g.vcf.gz"" --nonvariant_site_tfrecord_path ""./gvcf.tfrecord@8.gz"" --sample_name ""SAMPLENAME""; ```. And here are the two last commands with std out ... ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""./call_variants_output.tfrecord.gz"" --examples ""./make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(; I0510 12:13:42.483308 47501039724352 call_variants.py:563] Total 1 writing processes started.; I0510 12:13:42.487790 47501039724352 dv_utils.py:370] From ./make_examples.tfrecord-00000-of-00008.gz.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0510 12:13:42.487916 47501039724352 call_variants.py:588] Shape of input examples: [100, 199, 9]; I0510 12:13:42.488451 47501039724352 call_variant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/818#issuecomment-2104434632:1362,checkpoint,checkpoint,1362,,https://github.com/google/deepvariant/issues/818#issuecomment-2104434632,1,['checkpoint'],['checkpoint']
Availability,".10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m3.261s; user 0m5.770s; sys 0m5.974s; I0910 00:06:33.584306 140309422569216 run_deepvariant.py:364] None; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>; app.run(main); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run; _run_main(main, args); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1.; ```. However, in your case, it seems like there's nothing useful in the log. I think I've heard about similar cases before (where there was no useful error message showing up). I previously wondered if it's possible that `parallel` somehow hid away some message. But I can't immediately think of a reproducible setting that I can debug. But speaking of ""returned non-zero exit status 252"", I did a quick search in our GitHub issues and found: https://github.com/google/deepvariant/issues/325; Can you see if this might be relevant to your issue?. If so, I'd still like to find a way to reproduce on my side, so I can see if we can make a more meaningful error message... 🤔",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-689891360:4044,error,error,4044,,https://github.com/google/deepvariant/issues/345#issuecomment-689891360,2,['error'],['error']
Availability,".85.12 CUDA Version: 12.0 |; |-------------------------------+----------------------+----------------------+; | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |; | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |; | | | MIG M. |; |===============================+======================+======================|; | 0 Tesla P100-PCIE... Off | 00000000:00:04.0 Off | 0 |; | N/A 34C P0 29W / 250W | 0MiB / 16384MiB | 1% Default |; | | | N/A |; +-------------------------------+----------------------+----------------------+; ; +-----------------------------------------------------------------------------+; | Processes: |; | GPU GI CI PID Type Process name GPU Memory |; | ID ID Usage |; |=============================================================================|; | No running processes found |; +-----------------------------------------------------------------------------+; ```. Then I install cuda. This was from: https://developer.nvidia.com/cuda-downloads; ```; curl -O https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run ; export TERM=xterm; sudo sh cuda_12.1.0_530.30.02_linux.run; ```. ```; export PATH=/usr/local/cuda-12.1/bin:$PATH; export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH; sudo ldconfig; ```. ```; [pichuan@pichuan-gpu2 ~]$ nvcc --version; nvcc: NVIDIA (R) Cuda compiler driver; Copyright (c) 2005-2023 NVIDIA Corporation; Built on Tue_Feb__7_19:32:13_PST_2023; Cuda compilation tools, release 12.1, V12.1.66; Build cuda_12.1.r12.1/compiler.32415258_0; ```. This is not 11.8, but is a newer version. So let's test with it. Install Singularity:. ```; curl -O https://raw.githubusercontent.com/google/deepvariant/r1.5/scripts/install_singularity.sh; sed -i -e 's/apt-get/yum/g' install_singularity.sh; bash -x install_singularity.sh; ```. Check version:; ```; [pichuan@pichuan-gpu2 ~]$ singularity --version; singularity version 3.7.0; ```. The rest is similar to https://githu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471348553:1927,down,downloads,1927,,https://github.com/google/deepvariant/issues/619#issuecomment-1471348553,1,['down'],['downloads']
Availability,".dna.alt.fa\; --reads=data/hg005_gm26107.mrna.grch38.bam\; --output_vcf=output/HG005.output.vcf.gz \; --num_shards=$(nproc) \; --regions=data/chr20_CDS_3x.bed\; --make_examples_extra_args=""split_skip_reads=true,channels=''"" \; --intermediate_results_dir output/intermediate_results_dir. the error ; ***** Running the command:*****; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required.; I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required.; I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required.; I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required.; I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required.; I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required.; I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1303717562:1333,error,errors,1333,,https://github.com/google/deepvariant/issues/581#issuecomment-1303717562,1,['error'],['errors']
Availability,".g. Q10 is 90% confidence in call, Q20 is 99% confidence, Q30 99.9% confidence, and so on). **--filter-name LowQ --filter ""DP <200 "" --filter-name LowD** This field implies to me you are doing panel sequencing or deep exome sequencing, as this is a high value. The sample info should have DP present and it will not differ between GATK and DeepVariant output. You can use the same filter. . **--filter ""DP> 10000 "" --filter-name HigD** This is again the DP field, which is present in the call file and can also be used. **MQ<40.0 "" --filter-name SedT** This filters low mappability regions. This is actually a fairly high value, which means this will aggressively filter low mappability regions. MQ is seen by DeepVariant and used in calling to determine the variant call and confidence, so it will be reflected in the GQ value. However, MQ is not reported into the VCF, so this filter cannot be used for filtering without additional annotation of the VCF. If you want to filter out low mappability regions, I would recommend intersecting with the high mappability BED file from genome in a bottle. **--filter ""SOR > 50.0 "" --filter-name LowSOR** This filter relates to the strand of reads over a variant. Strand bias is something which DeepVariant can see in its inputs and will use this information to determine variant calls and assign confidence to those calls. However, strand bias is not reported a a separate value in the VCF, so this filter cannot be used for filtering without additional annotation of the VCF. I would say that use of this additional filter isn't needed. **--filter ""AN <150 "" --filter-name LowMiss""** As I understand this filter, it quantifies the number of different alleles identified at a position. I suppose this is some measure of the error rate around a position. If I understand the annotation correctly, DeepVariant should never produce value which come remotely close to this value in the cohort. You can exclude this filter as I don't think it would ever trigger.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/642#issuecomment-1535446429:2717,error,error,2717,,https://github.com/google/deepvariant/issues/642#issuecomment-1535446429,1,['error'],['error']
Availability,"//github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash; # download source code; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz; tar -zxvf protobuf-all-3.6.1.tar.gz; cd protobuf-3.6.1/. # clean static protobuf build; make uninstall; make distclean. # environment; export CPU=power8; export HOMEPATH=/home/qilibj; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static; make clean; make -j20; make -j20 check # check if protobuf build is good; # install; make install; sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig; #cd .. # verify; echo ""$(which protoc)""; echo ""$(protoc --version)""; ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash; # download source code; wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip; mkdir bazel-0.15.0; unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0; cd bazel-0.15.0. # environment; export CPU=power8; export HOMEPATH=/home/qilibj; export JAVA_HOME=/usr/lib/jvm/java-1.8.0; export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch; PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh; rsync -avP output/bazel $HOMEPATH/inst/bin/; # veri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:2319,echo,echo,2319,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,4,['echo'],['echo']
Availability,/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:12:06.012 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:06.076 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:16.724 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 1; name: pbc_varicall (1); status: COMPLETED; exit: 1; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:16.741 [Task monitor] ERROR nextflow.processor.TaskProcessor - Error executing process > 'pbc_varicall (1)'. Caused by:; Process `pbc_varicall (1)` terminated with an error exit status (1); Command executed:. run_deepvariant --model_type PACBIO --ref /data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta --reads /data/shared/clinical/LongRead/Data//m84011_220902_175841_Aln.bam --output_vcf /data/shared/clinical/LongRead/Data//Analysis/out_m84011_220902_175841_NFR_sif.vcf.gz --num_shards 40 --regions chr20. Command exit status:; 1. Command output:; I0608 12:13:28.741300 139794368661312 call_variants.py:462] Processed 100001 examples in 196 batches [0.087 sec per 100]; I0608 12:14:06.236101 139794368661312 call_variants.py:462] Processed 150001 examples in 293 batches [0.083 sec per 100]; I0608 12:14:43.829042 139794368661312 call_variants.py:462] Processed 200001 examples in 391 batches [0.081 sec per 100]; I0608 12:15:22.101066 139794368661312 call_variants.py:462] Processed 250001 ex,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308:5032,ERROR,ERROR,5032,,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308,1,['ERROR'],['ERROR']
Availability,"/analysis/deepvariant/data:/data -v; XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0; /opt/deepvariant/bin/run_deepvariant --model_type=WES; --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam; --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed; --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz; --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/; drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b; mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir; docker pull google/deepvariant:0.9.0; # this was ran, some directories censored by XXXXXXXXXX for security reasons; LINE='docker run -it -u `id -u`:`id -g` -v; /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v; /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v; /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed; google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant; --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam; --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed; --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz; --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'; echo ""$LINE""; eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b; drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>; wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,; >; > You can add; >; > docker run -it -v /data:/data \; > -u `id -u`:`id -g`; >; > to your docker command to avoid this issue.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/550#issuecomment-1205591500>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/A2LCPRQWWLAYOZXICW5LXSDVXQAGNANCNFSM55QXIB6A>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/550#issuecomment-1205685158:1818,echo,echo,1818,,https://github.com/google/deepvariant/issues/550#issuecomment-1205685158,1,['echo'],['echo']
Availability,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py ; https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/197#issuecomment-512112524:1649,error,error,1649,,https://github.com/google/deepvariant/issues/197#issuecomment-512112524,2,['error'],['error']
Availability,"/hs37d5.fa.gzi; ```. Then, I ran `make_examples` similar to the way you did in your original post:; ```; ## Run `make_examples`; ( time seq 0 $((N_SHARDS-1)) | \; parallel -k --line-buffer \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""hs37d5.fa.gz"" \; --reads ""151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam"" \; --examples ""HG002.examples.tfrecord@${N_SHARDS}.gz"" \; --regions ""agilent_sureselect_human_all_exon_v5_b37_targets.bed"" \; --gvcf ""HG002.gvcf.tfrecord@${N_SHARDS}.gz"" \; --task {} \; ) 2>&1 | tee ""make_examples.log""; ```; This took on 13m33.192s a 64-core, 128GB RAM machine. Before I proceeded with call_variants, I first checked that the output files from make_examples exist:; ```; ls HG002.examples.tfrecord*.gz | wc -l; ```; I see 64 of them here.; A common issue is that if the make_examples step failed but you didn't notice, then the next step will fail.; Common failure modes I've seen before:; - if you were running make_examples, but abort in the middle by ctrl-c. Sometimes not all the make_examples in the background were killed. If you just re-run make_examples without killing all background make_examples first, the output might be corrupted.; - if make_examples failed completely without outputting HG002.examples.tfrecord*.gz at all, it'll also cause a failure. Our hope is that you'll notice this in the errors that make_examples displayed. If you're creating some kind of workflow yourself, you will need to make sure you check the error code of the runs. If make_examples died, you shouldn't proceed with call_variants. After my make_examples run and confirming that I have the output files, I ran call_variants:; ```; ## Run `call_variants`; ( time \; /opt/deepvariant/bin/call_variants \; --outfile ""HG002.cvo.tfrecord.gz"" \; --examples ""HG002.examples.tfrecord@${N_SHARDS}.gz"" \; --checkpoint ""model.ckpt"" \; ) 2>&1 | tee ""call_variants.log"" &; ```; When I run this on the same 64-core, 128GB RA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:3842,failure,failure,3842,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,2,['failure'],['failure']
Availability,"/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; python -c 'import numpy as np; print(np.version.version)'; ```; Which shows:; ```; 1.19.2; ```. It seems like my machine doesn't already have numpy, though:. ```; [pichuan@pichuan-centos7 Python-3.8.10]$ pip3.8 show numpy; WARNING: Package(s) not found: numpy; ```; doesn't show anything. ## Install numpy 1.23.0 to see it breaks things. I ran:; ```; pip3.8 install numpy==1.23.0; ```; (Because you mentioned your cluster has 1.23.0). Now this shows:. ```; [pichuan@pichuan-centos7 ~]$ pip3.8 show numpy; Name: numpy; Version: 1.23.0; Summary: NumPy is the fundamental package for array computing with Python.; Home-page: https://www.numpy.org; Author: Travis E. Oliphant et al.; Author-email: None; License: BSD; Location: /home/pichuan/.local/lib/python3.8/site-packages; Requires: ; Required-by: ; ```. Then I re-ran:. ```; # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1; ```. Which still seems to work fine for me. And, this actually shows 1.23.0 as well:; ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; python -c 'import numpy as np; print(np.version.version)'; ```. ```; 1.23.0; ```. I also checked TensorFlow version:. ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; python -c 'import tensorflow; print(tensorflow.__version__)'; ```; This shows:; ```; 2.7.0; ```. @asherrar Let me know what you think I need to change to try to reproduce the error you saw. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/610#issuecomment-1429156759:4683,error,error,4683,,https://github.com/google/deepvariant/issues/610#issuecomment-1429156759,1,['error'],['error']
Availability,"/opt/deepvariant/bin/call_variants \; --outfile call_variants_output.tfrecord \; --examples output.examples.tfrecord \; --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants; exec /opt/deepvariant/bin/postprocess_variants \; --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \; --infile call_variants_output.tfrecord \; --outfile output.vcf. %runscript; if [ $# -eq 0 ]; then; echo '''Example Usage:. # download data to input and models; singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs; singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models; singularity run --app call_variants deepvariant-custom.simg. # postprocess variants; singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md; '''; else; exec ""$@""; fi. %post; export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)""; echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list; curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -; apt-get -y update && apt-get install -y google-cloud-sdk parallel wget; rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile; BASH_HEADER='#!/bin/bash' && \; printf ""%s\n%s\n"" \; ""${BASH_HEADER}"" \; 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \; /opt/deepvariant/bin/make_examples && \; printf ""%s\n%s\n"" \; ""${BASH_HEADER}"" \; 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \; /opt/deepvariant/bin/call_variants && \; printf ""%s\n%s\n"" \; ""${BASH_HEADER}"" \; 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \; /opt/deepvariant/bin/postprocess_variants && \; printf ""%s\n%s\n"" \; ""${BASH_HEADER}"" \; 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \; /opt/deepvariant/bin/model_train &&",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-458208323:2677,echo,echo,2677,,https://github.com/google/deepvariant/issues/132#issuecomment-458208323,1,['echo'],['echo']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================. FAILED: //deepvariant:make_examples_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; (06:29:20) FAIL: //deepvariant:make_examples_test (shard 1 of 2) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log); (06:29:20) INFO: From Testing //deepvariant:make_examples_test (shard 1 of 2):; ==================== Test output for //deepvariant:make_ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:99866,error,errors,99866,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:08) FAIL: //deepvariant/realigner:aligner_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log); (06:29:08) INFO: From Testing //deepvariant/realigner:aligner_test:; ==================== Test output for //deepvariant/realigner:aligner_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/aligner_test.runfiles/com_google_deepvariant/deepvariant/realigner/aligner_test.py"", line 40, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:13951,error,errors,13951,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:08) [2,482 / 2,523] 16 / 38 tests, 2 failed; Testing //deepvariant:call_variants_test; 0s local ... (41 actions, 1 running); (06:29:09) FAIL: //deepvariant:call_variants_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log); (06:29:09) INFO: From Testing //deepvariant:call_variants_test:; ==================== Test output for //deepvariant:call_variants_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_test.runfiles/com_google_deepvariant/deepvariant/call_variants_test.py"", line 48, in <module>; import tensorflow as ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:16409,error,errors,16409,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:09) FAIL: //deepvariant:model_train_test (shard 3 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log); (06:29:09) INFO: From Testing //deepvariant:model_train_test (shard 3 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 3 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:18646,error,errors,18646,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:09) [2,484 / 2,523] 17 / 38 tests, 3 failed; Testing //deepvariant:model_train_test [0s (9 actions)] ... (39 actions, 2 running); (06:29:09) FAIL: //deepvariant:model_train_test (shard 2 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log); (06:29:09) INFO: From Testing //deepvariant:model_train_test (shard 2 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 2 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_trai",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:20801,error,errors,20801,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant/labeler:customized_classes_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log); (06:29:10) INFO: From Testing //deepvariant/labeler:customized_classes_labeler_test:; ==================== Test output for //deepvariant/labeler:customized_classes_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/customized_classes_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/customized_classes_labeler_test.py"", line 41, in <module>; from third_party.nucleus.io",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:32383,error,errors,32383,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant/labeler:positional_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log); (06:29:10) INFO: From Testing //deepvariant/labeler:positional_labeler_test:; ==================== Test output for //deepvariant/labeler:positional_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/positional_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/positional_labeler_test.py"", line 40, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_roo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:25168,error,errors,25168,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant:model_train_test (shard 1 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log); (06:29:10) INFO: From Testing //deepvariant:model_train_test (shard 1 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 1 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:27984,error,errors,27984,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant:tf_utils_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log); (06:29:10) INFO: From Testing //deepvariant:tf_utils_test:; ==================== Test output for //deepvariant:tf_utils_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/tf_utils_test.runfiles/com_google_deepvariant/deepvariant/tf_utils_test.py"", line 40, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disabl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:23093,error,errors,23093,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) [2,488 / 2,523] 19 / 38 tests, 5 failed; Testing //deepvariant:data_providers_test; 0s local ... (35 actions, 2 running); (06:29:10) FAIL: //deepvariant:data_providers_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log); (06:29:10) INFO: From Testing //deepvariant:data_providers_test:; ==================== Test output for //deepvariant:data_providers_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/data_providers_test.runfiles/com_google_deepvariant/deepvariant/data_providers_test.py"", line 43, in <module>; import tensorf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:30139,error,errors,30139,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:11) FAIL: //deepvariant:model_train_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log); (06:29:11) INFO: From Testing //deepvariant:model_train_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:35263,error,errors,35263,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:11) FAIL: //deepvariant:model_train_test (shard 7 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log); (06:29:11) INFO: From Testing //deepvariant:model_train_test (shard 7 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 7 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:37418,error,errors,37418,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) FAIL: //deepvariant:haplotypes_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log); (06:29:12) INFO: From Testing //deepvariant:haplotypes_test:; ==================== Test output for //deepvariant:haplotypes_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/haplotypes_test.runfiles/com_google_deepvariant/deepvariant/haplotypes_test.py"", line 43, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:41859,error,errors,41859,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) FAIL: //deepvariant:model_eval_test (shard 8 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log); (06:29:12) INFO: From Testing //deepvariant:model_eval_test (shard 8 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 8 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:44268,error,errors,44268,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) [2,492 / 2,523] 21 / 38 tests, 7 failed; Testing //deepvariant:model_eval_test [0s (10 actions)] ... (31 actions, 2 running); (06:29:12) FAIL: //deepvariant:model_eval_test (shard 1 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log); (06:29:12) INFO: From Testing //deepvariant:model_eval_test (shard 1 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 1 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:39573,error,errors,39573,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:13) FAIL: //deepvariant:model_eval_test (shard 10 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log); (06:29:13) INFO: From Testing //deepvariant:model_eval_test (shard 10 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 10 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:50851,error,errors,50851,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:13) FAIL: //deepvariant:model_eval_test (shard 7 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log); (06:29:13) INFO: From Testing //deepvariant:model_eval_test (shard 7 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 7 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:48702,error,errors,48702,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:13) [2,495 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_eval_test [0s (8 actions)] ... (28 actions, 2 running); (06:29:13) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (06:29:13) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:46417,error,errors,46417,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:14) FAIL: //deepvariant:model_eval_test (shard 3 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log); (06:29:14) INFO: From Testing //deepvariant:model_eval_test (shard 3 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 3 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:57438,error,errors,57438,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:14) FAIL: //deepvariant:model_eval_test (shard 4 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log); (06:29:14) INFO: From Testing //deepvariant:model_eval_test (shard 4 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 4 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:55289,error,errors,55289,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:14) [2,498 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_eval_test [0s (5 actions)] ... (25 actions, 2 running); (06:29:14) FAIL: //deepvariant:model_eval_test (shard 5 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log); (06:29:14) INFO: From Testing //deepvariant:model_eval_test (shard 5 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 5 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:53004,error,errors,53004,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:15) FAIL: //deepvariant:model_eval_test (shard 2 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log); (06:29:15) INFO: From Testing //deepvariant:model_eval_test (shard 2 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 2 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:59587,error,errors,59587,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:15) FAIL: //deepvariant:model_train_test (shard 4 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log); (06:29:15) INFO: From Testing //deepvariant:model_train_test (shard 4 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 4 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:64028,error,errors,64028,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:15) [2,502 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test [0s (5 actions)] ... (21 actions, 2 running); (06:29:15) FAIL: //deepvariant:model_train_test (shard 9 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log); (06:29:15) INFO: From Testing //deepvariant:model_train_test (shard 9 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 9 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_trai",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:61736,error,errors,61736,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) FAIL: //deepvariant:model_train_test (shard 5 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log); (06:29:16) INFO: From Testing //deepvariant:model_train_test (shard 5 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 5 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:66183,error,errors,66183,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) FAIL: //deepvariant:model_train_test (shard 8 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log); (06:29:16) INFO: From Testing //deepvariant:model_train_test (shard 8 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 8 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:68338,error,errors,68338,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) [2,506 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test (shard 10 of 10); 0s local ... (17 actions, 2 running). FAILED: //deepvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/exe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:70493,error,errors,70493,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:17) FAIL: //deepvariant/realigner/allele_count_linear:model_evaluation_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log); (06:29:17) INFO: From Testing //deepvariant/realigner/allele_count_linear:model_evaluation_test:; ==================== Test output for //deepvariant/realigner/allele_count_linear:model_evaluation_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/realigner/allele_count_linear/mode",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:77037,error,errors,77037,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:17) FAIL: //deepvariant:variant_caller_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log); (06:29:17) INFO: From Testing //deepvariant:variant_caller_test:; ==================== Test output for //deepvariant:variant_caller_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/variant_caller_test.runfiles/com_google_deepvariant/deepvariant/variant_caller_test.py"", line 43, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:74600,error,errors,74600,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/python:allelecounter_wrap_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log); (06:29:18) INFO: From Testing //deepvariant/python:allelecounter_wrap_test:; ==================== Test output for //deepvariant/python:allelecounter_wrap_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/python/allelecounter_wrap_test.runfiles/com_google_deepvariant/deepvariant/python/allelecounter_wrap_test.py"", line 38, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:82360,error,errors,82360,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/realigner/allele_count_linear:generate_trained_model_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner/allele_count_linear:generate_trained_model_test:; ==================== Test output for //deepvariant/realigner/allele_count_linear:generate_trained_model_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/generate_trained_model_test.runfiles/com_google_deepvariant/deepvariant/real",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:80021,error,errors,80021,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/realigner/python:debruijn_graph_wrap_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner/python:debruijn_graph_wrap_test:; ==================== Test output for //deepvariant/realigner/python:debruijn_graph_wrap_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/python/debruijn_graph_wrap_test.runfiles/com_google_deepvariant/deepvariant/realigner/python/debruijn_graph_wrap_test.py"", line 38, in <module>; from third_part",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:84854,error,errors,84854,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/realigner:window_selector_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner:window_selector_test:; ==================== Test output for //deepvariant/realigner:window_selector_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/window_selector_test.runfiles/com_google_deepvariant/deepvariant/realigner/window_selector_test.py"", line 40, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:89705,error,errors,89705,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) [2,512 / 2,523] 28 / 38 tests, 14 failed; Testing //deepvariant/realigner:realigner_test; 0s local ... (11 actions, 2 running); (06:29:18) FAIL: //deepvariant/realigner:realigner_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner:realigner_test:; ==================== Test output for //deepvariant/realigner:realigner_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/realigner_test.runfiles/com_google_deepvariant/deepvariant/realigner/realigner_test.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:87425,error,errors,87425,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:19) FAIL: //deepvariant/labeler:haplotype_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log); (06:29:19) INFO: From Testing //deepvariant/labeler:haplotype_labeler_test:; ==================== Test output for //deepvariant/labeler:haplotype_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/haplotype_labeler_test.py"", line 40, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:94602,error,errors,94602,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:19) FAIL: //deepvariant:make_examples_test (shard 2 of 2) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log); (06:29:19) INFO: From Testing //deepvariant:make_examples_test (shard 2 of 2):; ==================== Test output for //deepvariant:make_examples_test (shard 2 of 2):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/deepvariant/make_examples_test.py"", line 48, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:97096,error,errors,97096,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:19) FAIL: //deepvariant:pileup_image_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log); (06:29:19) INFO: From Testing //deepvariant:pileup_image_test:; ==================== Test output for //deepvariant:pileup_image_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/pileup_image_test.runfiles/com_google_deepvariant/deepvariant/pileup_image_test.py"", line 43, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-op",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:92199,error,errors,92199,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) FAIL: //deepvariant/labeler:labeled_examples_to_vcf_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log); (06:29:20) INFO: From Testing //deepvariant/labeler:labeled_examples_to_vcf_test:; ==================== Test output for //deepvariant/labeler:labeled_examples_to_vcf_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf_test.runfiles/com_google_deepvariant/deepvariant/labeler/labeled_examples_to_vcf_test.py"", line 39, in <module>; from third_party.nucleus.io import vcf; File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:103040,error,errors,103040,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) FAIL: //deepvariant:modeling_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log); (06:29:20) INFO: From Testing //deepvariant:modeling_test:; ==================== Test output for //deepvariant:modeling_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/modeling_test.runfiles/com_google_deepvariant/deepvariant/modeling_test.py"", line 41, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disabl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:109980,error,errors,109980,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) [2,519 / 2,523] 34 / 38 tests, 20 failed; Testing //deepvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:105896,error,errors,105896,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:21) FAIL: //deepvariant/python:variant_calling_wrap_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log); (06:29:21) INFO: From Testing //deepvariant/python:variant_calling_wrap_test:; ==================== Test output for //deepvariant/python:variant_calling_wrap_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/python/variant_calling_wrap_test.runfiles/com_google_deepvariant/deepvariant/python/variant_calling_wrap_test.py"", line 38, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:112055,error,errors,112055,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:21) FAIL: //deepvariant:postprocess_variants_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log); (06:29:21) INFO: From Testing //deepvariant:postprocess_variants_test:; ==================== Test output for //deepvariant:postprocess_variants_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants_test.runfiles/com_google_deepvariant/deepvariant/postprocess_variants_test.py"", line 46, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:114563,error,errors,114563,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:21) INFO: Elapsed time: 14.901s, Critical Path: 13.35s; (06:29:21) INFO: 43 processes: 43 local.; (06:29:21) INFO: Build completed, 24 tests FAILED, 44 total actions; //deepvariant:allelecounter_test (cached) PASSED in 0.5s; //deepvariant:dv_vcf_constants_test (cached) PASSED in 1.7s; //deepvariant:exclude_contigs_test (cached) PASSED in 0.9s; //deepvariant:postprocess_variants_lib_test (cached) PASSED in 0.1s; //deepvariant:resources_test (cached) PASSED in 1.7s; //deepvariant:utils_test (cached) PASSED in 0.5s; //deepvariant:variant_calling_test (cached) PASSED in 0.6s; //deepvariant/environment_tests:env_smoke_test (cached) PASSED in 0.7s; //deepvariant/environment_tests:protobuf_implementation_test (cached) PASSED in 1.2s; //deepvariant/realigner:fast_pass_aligner_tes",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:116710,error,errors,116710,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['errors']
Availability,"/venv; WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages); Python 3.8.10; pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible.; google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting; Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting; ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. T",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279:4268,ERROR,ERROR,4268,,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279,1,['ERROR'],['ERROR']
Availability,"058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.; Instructions for updating:; Use standard file APIs to check for files with this prefix.; I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt; I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op.; I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op.; I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA...; I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s; user	0m23.000s; sys	2m0.390s; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>; app.run(main); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run; _run_main(main, args); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247; ```; I'm attaching the code and the entire output. . Thanks a lot. ; [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/249#issuecomment-565657419:5621,checkpoint,checkpoint,5621,,https://github.com/google/deepvariant/issues/249#issuecomment-565657419,1,['checkpoint'],['checkpoint']
Availability,"0avgtext+0avgdata 1828maxresident)k; 0inputs+0outputs (0major+73minor)pagefaults 0swaps; Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists.; time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled""; parallel: This job failed:; sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0; docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists.; ERRO[0000] error waiting for container: context canceled; ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or withou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483490946:4847,error,error,4847,,https://github.com/google/deepvariant/issues/171#issuecomment-483490946,2,['error'],['error']
Availability,"1) @chapmanb : I think this is what you're looking for! @depristo pointed it out me, and I felt dumb for not thinking just to edit the WORKSPACE (and instead I linked the file to the ""right place"" instead).; In the `WORKSPACE` file of DeepVariant, you can see this at the bottom.; I tried changing the path:; ```; new_local_repository(; name = ""clif"",; build_file = ""third_party/clif.BUILD"",; path = ""/home/pichuan"",; ); ```. And I make sure the two files are there:; ```; $ ls /home/pichuan/clif/bin/; pyclif pyclif_proto; ```; After this change, it seems to run past the part where it can't find clif! Basically the `missing input file '@clif//:clif/bin/pyclif_proto'` error was no longer there after this change. 2) You're right -- I just tried installing TensorFlow with `conda install tensorflow` on CentOS6. It's so easy and smooth. That's great. However, I'm not sure which directory I should point to as a replacement for the pointer in our WORKSPACE file:; ```; # Import tensorflow. Note path.; local_repository(; name = ""org_tensorflow"",; path = ""../tensorflow"",; ); ```; So I'm currently block on that. Maybe you'll have better luck once you get past 1). Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386752411:671,error,error,671,,https://github.com/google/deepvariant/issues/29#issuecomment-386752411,1,['error'],['error']
Availability,"1. Docker installation is not DeepVariant specific. You may follow steps from the official docker website https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository; 2. From the output it looks like you run it on a machine with 2 cores. In Google tutorial n1-standard-64 instance is used which has 64 cores. ; 3. From the output of the last command it is not clear what the error is. Could you post the command you used for creating an instance? It could be that call_variants command ran out of memory.; 4. Although Google tutorial page contains the pricing for pre-emptible instances it is only given for the reference. It is not recommended to run this tutorial on a pre-emptible instances because in the case the instance is preemted the job cannot restart automatically. More complex configuration (like Kubernetes) is required in order to use pre-emptible instances.; 5. Recently a new version of DeepVariant was released, so instead of using 0.9.0 the new version 1.1.0 and docker path google/deepvariant should be used. Although, using the latest version is preferred the old 0.9.0 should work as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/399#issuecomment-749327121:391,error,error,391,,https://github.com/google/deepvariant/issues/399#issuecomment-749327121,2,['error'],['error']
Availability,"1.2 produces same error. ```; 2022-02-10 12:57:29.123141: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>; _ll.load_library(_main_dir); File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library; py_tf.TF_LoadLibrary(lib); tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/514#issuecomment-1035509300:18,error,error,18,,https://github.com/google/deepvariant/issues/514#issuecomment-1035509300,1,['error'],['error']
Availability,"10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static; make clean; make -j20; make -j20 check # check if protobuf build is good; # install; make install; sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig; #cd .. # verify; echo ""$(which protoc)""; echo ""$(protoc --version)""; ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash; # download source code; wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip; mkdir bazel-0.15.0; unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0; cd bazel-0.15.0. # environment; export CPU=power8; export HOMEPATH=/home/qilibj; export JAVA_HOME=/usr/lib/jvm/java-1.8.0; export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch; PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh; rsync -avP output/bazel $HOMEPATH/inst/bin/; # verification; bazel info; ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash; # gpg public key; wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b; rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories; [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:2858,down,download,2858,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['down'],['download']
Availability,"134217728; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0120 14:08:27.178606 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader; I0120 14:08:27.193892 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader; I0120 14:08:30.685934 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1-1000 [3.57s elapsed]; I0120 14:08:30.687139 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1001-2000 [0.00s elapsed]; I0120 14:08:30.688232 140531010582272 make_examples.py:782] Found 0 candidates in chr5:2001-3000 [0.00s elapsed]; I0120 14:08:30.689320 140531010582272 make_examples.py:782] Found 0 candidates in chr5:3001-4000 [0.00s elapsed]; I0120 14:08:30.690371 140531010582272 make_examples.py:782] Found 0 candidates in chr5:4001-5000 [0.00s elapsed]; I0120 14:08:30.691399 140531010582272 make_examples.py:782] Found 0 candidates in chr5:5001-6000 [0.00s elapsed]; I0120 14:08:30.692424 140531010582272 make_examples.py:782] Found 0 candidates in chr5:6001-7000 [0.00s elapsed]; I0120 14:08:30.693455 140531010582272 make_examples.py:782] Found 0 candidates in chr5:7001-8000 [0.00s elapsed]; I0120 14:08:30.694483 140531010582272 make_examples.py:782] Found 0 candidates in chr5:8001-9000 [0.00s elapsed]; I0120 14:08:30.695507 140531010582272 make_examples.py:782] Found 0 candidates in chr5:9001-10000 [0.00s elapsed]; 2019-01-20 14:08:30.703660: F deepvariant/allelecounter.cc:122] Check failed: offset + len <= read.aligned_quality_size() (5 vs. 0); ```; So it seems there is a problem with the BAM file but only in some regions. Do you think this error will be resolved if I generate the BAM file again using blasr?. [sorted_final_merged.header.sam.txt](https://github.com/google/deepvariant/files/2776530/sorted_final_merged.header.sam.txt)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-455862468:4152,error,error,4152,,https://github.com/google/deepvariant/issues/138#issuecomment-455862468,1,['error'],['error']
Availability,"1_Software/dpv/deepvariant_1.4.0.sif bash; Singularity> cd / && ls; bin boot dellfsqd2 dev environment etc home lib lib32 lib64 libx32 media mnt opt proc root run sbin singularity srv sys tmp usr var; Singularity> cd mnt && ls; QJref.fa input.bam QJref.fa.fai input.bam.bai tmp_dir; ```; Then I ran the following script.; ```; cat test0215.sh; WORK_DIR=/path1/4_Test/qingjiang/dpv; export TMPDIR=""$PWD/tmp_dir""; singularity run -B$TMPDIR:$TMPDIR,""${WORK_DIR}"":/mnt \; /path1/1_Software/dpv/deepvariant_1.4.0.sif /opt/deepvariant/bin/run_deepvariant \; --num_shards=3 \; --model_type=PACBIO \; --ref=/mnt/QJref.fa \; --reads=/mnt/input.bam \; --output_vcf=/mnt/output.vcf.gz \; --output_gvcf=/mnt/output.g.vcf.gz \; --intermediate_results_dir /mnt/dpv \; ```; The core error is `ValueError: NOT_FOUND: Could not open /mnt/input.bam; [E::hts_open_format] Failed to open file ""/mnt/input.bam"" : No such file or directory`However, I have verified the existence of `/mnt/input.bam`.; The complete error information is as follows.; Sincerely look forward to your help! thank you; ```; sh test0215.sh; I0216 00:56:07.446549 140582811191104 run_deepvariant.py:342] Re-using the directory for intermediate results in /mnt/dpv. ***** Intermediate results will be written to /mnt/dpv in docker. ****. ***** Running the command:*****; time seq 0 2 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/QJref.fa"" --reads ""/mnt/input.bam"" --examples ""/mnt/dpv/make_examples.tfrecord@3.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/mnt/dpv/gvcf.tfrecord@3.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LC_CTYP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/613#issuecomment-1431702886:1341,error,error,1341,,https://github.com/google/deepvariant/issues/613#issuecomment-1431702886,1,['error'],['error']
Availability,"21tufdoh/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in main; write_variants_to_vcf(; File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 772, in write_variants_to_vcf; with vcf.VcfWriter(; File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 174, in __init__; self._writer = self._native_writer(output_path, **kwargs); return NativeVcfWriter(; File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 287, in __init__; self._writer = vcf_writer.VcfWriter.to_file(output_path, header,; ValueError: UNKNOWN: Could not open variants_path: /data/shared/clinical/LongRead/Data//Analysis/out_m84011_220902_175841_NFR_sif.vcf.gz. real 0m7.906s; user 0m8.421s; sys 0m8.363s. Command error:; I0608 12:13:28.741300 139794368661312 call_variants.py:462] Processed 100001 examples in 196 batches [0.087 sec per 100]; I0608 12:14:06.236101 139794368661312 call_variants.py:462] Processed 150001 examples in 293 batches [0.083 sec per 100]; I0608 12:14:43.829042 139794368661312 call_variants.py:462] Processed 200001 examples in 391 batches [0.081 sec per 100]; I0608 12:15:22.101066 139794368661312 call_variants.py:462] Processed 250001 examples in 489 batches [0.080 sec per 100]; I0608 12:15:59.773940 139794368661312 call_variants.py:462] Processed 300001 examples in 586 batches [0.079 sec per 100]; I0608 12:16:37.228438 139794368661312 call_variants.py:462] Processed 350001 examples in 684 batches [0.079 sec per 100]; I0608 12:17:07.588583 139794368661312 call_variants.py:468] Processed 390233 examples in 763 batches [0.078 sec per 100]; I0608 12:17:07.588791 139794368661312 call_variants.py:471] Done calling variants from a total of 390233 examples. real 5m9.540s; user 294m6.601s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308:9817,error,error,9817,,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308,2,['error'],['error']
Availability,"3.6.1 six mock; pip install --upgrade setuptools; ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash; # download source code; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz; tar -zxvf protobuf-all-3.6.1.tar.gz; cd protobuf-3.6.1/. # clean static protobuf build; make uninstall; make distclean. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static; make clean; make -j20; # optional; make -j20 check # check if protobuf build is good; # install; make install; sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig; #cd .. # verify; echo ""$(which protoc)""; echo ""$(protoc --version)""; ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash; # share build for Python; python --version # python 2.7 or newer; protoc --version; # build; cd protobuf-3.6.1/python/; python setup.py build; python setup.py test; # install from source as deepvariant needed; python setup.py install; # install from wheel; python setup.py bdist_wheel; pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall; # verify; python -c ""import google.protobuf""; ```. ## OpenBLAS 0.3.5. ```bash; git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5; cd OpenBLAS-0.3.5; make TARGET=power8; make TARGET=power8 PREFIX=$HOMEPATH/inst install; ```. ## Boost 1.66.0. ```bash; wget -qc https://dl.bintray.com/boostorg/re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:6879,echo,echo,6879,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,4,['echo'],['echo']
Availability,"3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result.; And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:; ```; gcloud compute instances create ""${USER}-1"" \; --image-family ""ubuntu-1604-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-1"" \; --zone ""us-west1-b""; ```. 2. I ssh'ed into the machine using this command:; ```; gcloud compute ssh ""${USER}-1""; ```. 3. I downloaded the input file needed:; ```; # Downloading the reference file takes a while.; # It's only used for the header in postprocess_variants.; wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz; gunzip ucsc.hg19.fasta.gz; wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz; gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:; wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz; ```. 4. I pull the docker image, and run the command:; ```; sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \; -v ${PWD}:/data \; gcr.io/deepvariant-docker/deepvariant:0.7.2 \; /opt/deepvariant/bin/postprocess_variants \; --ref /data/ucsc.hg19.fasta \; --infile /data/call_variants_output.tfrecord.gz \; --outfile /data/output.vcf.gz; ```. As I mentioned, this took:; ```; real 0m24.779s; user 0m0.033s; sys 0m0.022s; ```. I used `top` to keep an eye on the memory usage. The highest I've noticed is roughly the following:; ```; PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND; 4882 root 20 0 1445956 229032 103824 R 99.3 6.1 0:22.46 python; ```. This produced 90,359 total lines, of which 78,085 are actual variant calls (PASS); ```; $ zcat output.vcf.gz | grep -v '^#' | wc -l; 90359. $ zcat output.vcf.gz | grep -v '^#' | grep PASS | wc -l; 78085; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480150395:1367,Down,Download,1367,,https://github.com/google/deepvariant/issues/167#issuecomment-480150395,1,['Down'],['Download']
Availability,"3a2d7; Note: switching to '9ec44bde4f7f40de342a1286f84f5b608633a2d7'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at 9ec44bd Replace C++ `#import <...>` with `#include <...>`; + git init; Reinitialized existing Git repository in /root/clif/.git/; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/737#issuecomment-1818093820:2288,echo,echo,2288,,https://github.com/google/deepvariant/issues/737#issuecomment-1818093820,2,['echo'],['echo']
Availability,"5993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']; I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz; I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz; I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s; user	0m30.820s; sys	1m32.400s; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>; app.run(main); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run; _run_main(main, args); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1; ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. ; Thank you in advance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/249#issuecomment-565441661:29945,error,error,29945,,https://github.com/google/deepvariant/issues/249#issuecomment-565441661,1,['error'],['error']
Availability,"5_AGATGTAC_L008.posiSrt.markDup.bam"" \; --examples ""HG002.examples.tfrecord@${N_SHARDS}.gz"" \; --regions ""agilent_sureselect_human_all_exon_v5_b37_targets.bed"" \; --gvcf ""HG002.gvcf.tfrecord@${N_SHARDS}.gz"" \; --task {} \; ) 2>&1 | tee ""make_examples.log""; ```; This took on 13m33.192s a 64-core, 128GB RAM machine. Before I proceeded with call_variants, I first checked that the output files from make_examples exist:; ```; ls HG002.examples.tfrecord*.gz | wc -l; ```; I see 64 of them here.; A common issue is that if the make_examples step failed but you didn't notice, then the next step will fail.; Common failure modes I've seen before:; - if you were running make_examples, but abort in the middle by ctrl-c. Sometimes not all the make_examples in the background were killed. If you just re-run make_examples without killing all background make_examples first, the output might be corrupted.; - if make_examples failed completely without outputting HG002.examples.tfrecord*.gz at all, it'll also cause a failure. Our hope is that you'll notice this in the errors that make_examples displayed. If you're creating some kind of workflow yourself, you will need to make sure you check the error code of the runs. If make_examples died, you shouldn't proceed with call_variants. After my make_examples run and confirming that I have the output files, I ran call_variants:; ```; ## Run `call_variants`; ( time \; /opt/deepvariant/bin/call_variants \; --outfile ""HG002.cvo.tfrecord.gz"" \; --examples ""HG002.examples.tfrecord@${N_SHARDS}.gz"" \; --checkpoint ""model.ckpt"" \; ) 2>&1 | tee ""call_variants.log"" &; ```; When I run this on the same 64-core, 128GB RAM machine, it usually only uses about 500% CPU (instead of all of the 64 cores). This step took about 2m. I can confirm that I successfully run this step without the errors you saw. However, if I remove the files first by `rm -f HG002.examples.tfrecord*.gz` and then repeat the call_variants command above, I can see the errors you reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:4242,failure,failure,4242,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,2,['failure'],['failure']
Availability,"75c978033f9adc7c2a/external/org_tensorflow/third_party/py/python_configure.bzl"", line 138, column 25, in _check_python_lib; 		auto_config_fail(""Invalid python library path: %s"" % python_lib); 	File ""/home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7c2a/external/org_tensorflow/third_party/remote_config/common.bzl"", line 12, column 9, in auto_config_fail; 		fail(""%sConfiguration Error:%s %s\n"" % (red, no_color, msg)); Error in fail: Configuration Error: Invalid python library path: ""; (11:50:12) INFO: Repository go_sdk instantiated at:; /home/user/Documents/deepvariant-r1.5/WORKSPACE:116:14: in <toplevel>; /home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7c2a/external/org_tensorflow/tensorflow/workspace0.bzl:134:20: in workspace; /home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7c2a/external/com_github_grpc_grpc/bazel/grpc_extra_deps.bzl:36:27: in grpc_extra_deps; /home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7c2a/external/io_bazel_rules_go/go/private/sdk.bzl:431:28: in go_register_toolchains; /home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7c2a/external/io_bazel_rules_go/go/private/sdk.bzl:130:21: in go_download_sdk; Repository rule _go_download_sdk defined at:; /home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7c2a/external/io_bazel_rules_go/go/private/sdk.bzl:117:35: in <toplevel>; (11:50:12) ERROR: Analysis of target '//:binaries' failed; build aborted: Configuration Error: Invalid python library path: ""; (11:50:12) INFO: Elapsed time: 0.552s; (11:50:12) INFO: 0 processes.; (11:50:12) FAILED: Build did NOT complete successfully (0 packages loaded, 0 t\; argets configured); ```; Do you have any suggestions? Thank you for your time!; Looks like we are getting there for this one. Just fyi, fortunately, I was able to run deepvariant on another unix system using singularity pull.; After updating the numpy and implementing the GPU command -nv, it runs pretty fast and error-free.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1584813838:3638,ERROR,ERROR,3638,,https://github.com/google/deepvariant/issues/657#issuecomment-1584813838,3,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error-free']"
Availability,"8/site-packages/pip (python 3.8); WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages); Installing collected packages: pyparsing; WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages); ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages); ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting; WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages); WA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279:10285,ERROR,ERROR,10285,,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279,1,['ERROR'],['ERROR']
Availability,"8_Verily_v1.genome.fa.gz.fai --ref_gzi gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz.gzi --gcsfuse"": exit status 1: /examples_output.tfrecord@""${SHARDS}"".gz\n --reads ""/input-gcsfused-{}/${BAM}""\n --ref ""${INPUT_REF}""\n --task {}\n --regions gs://canis/CNR-data/CDS-canonical.bed"" # ENABLE_FUSE\n']; Traceback (most recent call last):; File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>; run(); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run; _run_make_examples(pipeline_args); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples; _wait_for_results(threads, results); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results; result.get(); File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get; raise self._value; RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/781565864516461293"" failed: executing pipeline: Execution failed: action 6: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION); details:; '@type': type.googleapis.com/google.genomics.v2alpha1.ContainerStoppedEvent; actionId: 1; exitStatus: 1; stderr: |+; /examples_output.tfrecord@""${SHARDS}"".gz\n --reads ""/input-gcsfused-{}/${BAM}""\n --ref ""${INPUT_REF}""\n --task {}\n --regions gs://canis/CNR-data/CDS-canonical.bed"" # ENABLE_FUSE\n']; Traceback (most recent call last):; File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>; run(); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run; _run_make_examples(pipeline_args); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples; _wait_for_results(threads, results); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results; result.get(); File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get; raise self._value; RuntimeEr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437055644:3958,error,error,3958,,https://github.com/google/deepvariant/issues/116#issuecomment-437055644,1,['error'],['error']
Availability,"://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:; > ; > **Describe the issue:** Am getting the error as ""Fatal Python error: Segmentation fault""; > ; > **Setup**; > ; > * Operating system: Ubuntu 22.04.2 LTS; > * DeepVariant version: 1.6.1; > * Installation method (Docker, built from source, etc.): Docker; > * Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Its a Pabcio CLR data. Read Input is provided in Fastq format and reference in FASTA format.; > ; > **Steps to reproduce:**; > ; > * Command: sudo docker run ; > -v ""${INPUT_DIR}"":""/input"" ; > -v ""${OUTPUT_DIR}"":""/output"" ; > google/deepvariant:""${BIN_VERSION}"" ; > /opt/deepvariant/bin/run_deepvariant ; > --model_type=PACBIO ; > --ref=/input/RILWLs1.fasta ; > --reads=/input/Out.fastq ; > --output_vcf=/output/output.vcf.gz ; > --output_gvcf=/output/output.g.vcf.gz ; > --intermediate_results_dir /output/intermediate_results_dir ; > --num_shards=15; > * Error trace: (if applicable); > ; > **Does the quick start test work on your system?** Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Yes. Test data works fine. ![Screenshot from 2024-04-17 12-24-22](https://private-user-images.githubusercontent.com/68117296/323111309-41ac66ff-ff52-493f-b18f-f017921caa86.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTMzMzcyOTIsIm5iZiI6MTcxMzMzNjk5MiwicGF0aCI6Ii82ODExNzI5Ni8zMjMxMTEzMDktNDFhYzY2ZmYtZmY1Mi00OTNmLWIxOGYtZjAxNzkyMWNhYTg2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDE3VDA2NTYzMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg3ZDQ3ZTBmNDFjYWQ4YWQyNmM4MDdmYTJiYjVjNzlhYmI1MDA2NzQxOGY3MjA1ZjU1ODY3ZDUzOTcyMTkyNzQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVw",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/807#issuecomment-2060514080:1022,Error,Error,1022,,https://github.com/google/deepvariant/issues/807#issuecomment-2060514080,1,['Error'],['Error']
Availability,"://github.com/pgrosu/test/assets/6555937/f1f478fa-8ffc-4a9a-b5de-4f123658750d). ![image](https://github.com/pgrosu/test/assets/6555937/eb14b3e0-3424-4dc5-82b3-c77091c871a2). Given visual similarity, these were confirmed via Euclidean distance (0.9931127, 0.8543731 and 1.052052, respectively). This indicates the feature set might exhibit strong similarity for interpretation. . Looking at one network (PacBio), it might be possible to confirm calibration by testing for network-resiliency. Via perturbation analysis it should be possible to get insight into a channel's response under perturbation, and their binary interactions under such conditions. Keeping the variant unchanged within a window on each side for preserving the call, the inspection each channel vulnerability response to perturbation can be tested. This resulted in the following perturbation response ($`c\_*`$ denotes a channel, and $`i\_*\_*`$ represents a binary interaction between two channels):. ![image](https://github.com/pgrosu/test/assets/6555937/97c6b13e-e80b-48ae-939d-2367e7ab65c1). The above can be mapped into a network of interactions among the channels:. ![image](https://github.com/pgrosu/test/assets/6555937/cc0e1e2a-278f-4178-a124-67b0321bba3e). Based on the above mapping, by testing well-interacting channels through a probabilistically value-update -- within DeepVariant-acceptable values -- it might be possible to check for shifts in genotype mimicking Mendelian violation. Selecting `base_quality` and staying within DeepVariant's minimum acceptable value, random sampling with replacement was performed in the window outside the variant region. A shift in genotype was achieved giving a measure of network resiliency. Other channels being more strongly-connected could provide more aggressive shifts in genotype. This can be offset by restrictions in convolutional motifs within the network, or be shifted to the code via threshold limitations in `make_examples`. Thank you and Happy 4th of July!; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1619352040:2132,resilien,resiliency,2132,,https://github.com/google/deepvariant/issues/666#issuecomment-1619352040,1,['resilien'],['resiliency']
Availability,":31 PM EDT] Stage 'Update package list' starting; ========== [Mon 05 Jun 2023 10:22:32 PM EDT] Stage 'build-prereq.sh: Install development packages' starting; Calling wait_for_dpkg_lock.; ========== [Mon 05 Jun 2023 10:22:32 PM EDT] Stage 'Install bazel' starting; WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on.; Bazel 5.3.0 already installed on the machine, not reinstalling; ========== [Mon 05 Jun 2023 10:22:32 PM EDT] Stage 'Install CLIF binary' starting; CLIF already installed.; ========== [Mon 05 Jun 2023 10:22:32 PM EDT] Stage 'Download and configure TensorFlow sources' starting; HEAD is now at d5b57ca93e5 Merge pull request #58598 from tensorflow/vinila21-patch-1; You have bazel 5.3.0 installed.; Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.; 	--config=mkl 	# Build with MKL support.; 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL).; 	--config=monolithic 	# Config for mostly static monolithic build.; 	--config=numa 	# Build with NUMA support.; 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.; 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API.; Preconfigured Bazel build configs to DISABLE default on features:; 	--config=nogcp 	# Disable GCP support.; 	--config=nonccl 	# Di",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053:7125,down,download,7125,,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053,2,['down'],"['download', 'downloaded']"
Availability,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU; ```; The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name; 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX); 3) contig name or * for unmapped; 4) mapped position of base 1 of a read on the reference sequence; 5) MAPQ mapping quality; 6) CIGAR string describing insertions and deletions; 7) Name of mate; 8) Position of mate; 9) Template length; 10) Read Sequence; 11) Read Quality; 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658769491:1958,error,error,1958,,https://github.com/google/deepvariant/issues/682#issuecomment-1658769491,8,"['down', 'error']","['down', 'error']"
Availability,"; --image-family ""ubuntu-1804-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""e2-medium"" \; --zone ""us-west1-b""; ```. After ssh into the machine, I ran:. ```; sudo apt -y update && sudo apt -y install docker.io; ```. And then followed the steps here:. https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md. For the main DeepVariant command, I ran:. ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --intermediate_results_dir /output/intermediate_results_dir \; --num_shards=1 \; --call_variants_extra_args=""use_openvino=true"" \; 2>&1 | tee /tmp/deepvariant.log; ```. With this run above, all steps (including call_variants) completed without errors. After that run, I repeated the call_variants step:; ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/call_variants \; --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" \; --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" \; --checkpoint ""/opt/models/wgs/model.ckpt"" \; --use_openvino; ```; which worked fine too. You mentioned you used DeepVariant1.1.0 version via Docker, but you also mentioned your command was:; `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32`. Can you be more specific about how you run this command?. And, another pointer for you:; In our Dockerfile, we set th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/432#issuecomment-806341687:1334,error,errors,1334,,https://github.com/google/deepvariant/issues/432#issuecomment-806341687,1,['error'],['errors']
Availability,"; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz . # Errors:. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2020-01-31 01:37:29.333483: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . # Test Singularity DeepVariant0.9.0 GPU image on test data; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; ${INPUT_DIR}/deepvariant-${BIN_VERSION}-gpu.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz . # Errors: ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_0Ul6DZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 43, in <module>; import tensorflow as tf; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); Fi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/265#issuecomment-580549772:2106,Error,Errors,2106,,https://github.com/google/deepvariant/issues/265#issuecomment-580549772,1,['Error'],['Errors']
Availability,"; --reads_child ${outdir2}/C1_haplotagged.bam; --reads_parent1 ${outdir2}/F1_haplotagged.bam; --reads_parent2 ${outdir2}/M1_haplotagged.bam; --output_vcf_child ${outdir4}/C1.output.vcf.gz; --output_vcf_parent1 ${outdir4}/F1.output.vcf.gz; --output_vcf_parent2 ${outdir4}/M1.output.vcf.gz; --sample_name_child 'C1'; --sample_name_parent1 'F1'; --sample_name_parent2 'M1'; --num_shards 8; --output_gvcf_child ${outdir4}/C1.g.vcf.gz; --output_gvcf_parent1 ${outdir4}/F1.g.vcf.gz; --output_gvcf_parent2 ${outdir4}/M1.g.vcf.gz; --use_hp_information. **However,the log file of DeepTrio still contains errors：**(The result files have been generated); cat log |grep -i error; W1008 21:26:50.592375 47245352568640 call_variants.py:353] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio). Please double-check that the model is trained with the same parameters and version of DeepVariant as you generated the examples with. An error will not appear when these are mismatched because of how InceptionV3 works. Note that if you set --pileup_image_height in DeepVariant, then you must use a model trained with that same parameter.; W1009 09:06:50.674110 47029842433856 call_variants.py:353] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio). Please double-check that the model is trained with the same parameters and version of DeepVariant as you generated the examples with. An error will not appear when these are mismatched because of how InceptionV3 works. Note that if you set --pileup_image_height in DeepVariant, then you must use a model trained with that same parameter.; W1009 18:31:59.770313 48004354086720 call_variants.py:353] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio). Please double-check that the model is trained with the same parameters and version of DeepVariant as you generated the examples with. An error will not appear when these are mismatched",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/488#issuecomment-939618673:1985,error,error,1985,,https://github.com/google/deepvariant/issues/488#issuecomment-939618673,1,['error'],['error']
Availability,"; > --image-project ""ubuntu-os-cloud"" --machine-type ""custom-64-131072""; > --boot-disk-size ""300"" --zone ""us-west2-b"" --min-cpu-platform ""Intel; > Skylake""; >; > ssh into the machine:; >; > gcloud compute ssh pichuan-cpu --zone us-west2-b; >; > Get the binaries and models:; >; > BUCKET=""gs://deepvariant""; > BIN_VERSION=""1.4.0""; > MODEL_VERSION=""1.4.0""; >; > BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}""; > MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard""; >; > mkdir -p bin; > # Download the DeepVariant binaries.; > gsutil -m cp ""${BIN_BUCKET}/*"" bin/; > chmod a+x bin/*; >; > Then, I ran:; >; > cd bin; bash run-prereq.sh; cd -; >; > The run-prereq.sh tends to be the most tricky one - it will require root; > permission, and it'll install a bunch of stuff on your machine. If you; > can't use Docker because of root permissions, you likely won't be able to; > run this as well.; >; > Download test data:; >; > INPUT_DIR=""${PWD}/quickstart-testdata""; > DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; >; > mkdir -p ${INPUT_DIR}; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; >; > Run make_examples:; >; > OUTPUT_DIR=""${PWD}/quickstart-output""; > ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566:1675,Down,Download,1675,,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566,1,['Down'],['Download']
Availability,"; attrs=attr_protos, op_def=op_def); File ""usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 3485, in _create_op_internal; op_def=op_def); File ""usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1949, in __init__; self._traceback = tf_stack.extract_stack(). real	0m19.667s; user	0m15.445s; sys	0m3.603s; I1219 05:41:49.700348 140338112591616 run_deepvariant.py:416] None; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>; app.run(main); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run; _run_main(main, args); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" )' returned non-zero exit status 1.; ```. The error seems to suggest that the model file (`/opt/models/pacbio/model.ckpt.data-00000-of-00001`) does not exist. Can you try running the following command:. ```; BIN_VERSION=""1.1.0""; docker run -it google/deepvariant:""${BIN_VERSION}"" /bin/bash; ls /opt/models/pacbio/model.ckpt.data-00000-of-00001; ```. You should see the following output:. ```; └──╼ docker run -it google/deepvariant:1.1.0 /bin/bash; $root@df876e3a15f7:/opt/deepvariant# ls /opt/models/pacbio/; model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.meta; $root@df876e3a15f7:/opt/deepvariant# ls /opt/models/pacbio/model.ckpt.data-00000-of-00001; /opt/models/pacbio/model.ckpt.data-00000-of-00001; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/757#issuecomment-1864800013:21284,checkpoint,checkpoint,21284,,https://github.com/google/deepvariant/issues/757#issuecomment-1864800013,2,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"; make -j20; make install. # set environment; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin; export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH; export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15; echo ""$(python --version)"". # Pip 19.0.2; wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate; $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst; #pip install --upgrade --force-reinstall pip; echo ""$(pip --version)""; pip install setuptools nose asv cython future protobuf==3.6.1 six mock; pip install --upgrade setuptools; ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash; # download source code; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz; tar -zxvf protobuf-all-3.6.1.tar.gz; cd protobuf-3.6.1/. # clean static protobuf build; make uninstall; make distclean. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static; make clean; make -j20; # optional; make -j20 check # check if protobuf build is good; # install; make install; sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig; #cd .. # verify; echo ""$(which protoc)""; echo ""$(protoc --version)""; ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash; # share build for Python; python --version # python 2.7 or",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:6303,down,download,6303,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['down'],['download']
Availability,"===== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting; Calling wait_for_dpkg_lock.; ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting; WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on.; Bazel 3.7.2 already installed on the machine, not reinstalling; ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting; CLIF already installed.; ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting; M	tensorflow/core/kernels/mlir_generated/build_defs.bzl; HEAD está ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes; You have bazel 3.7.2 installed.; Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.; 	--config=mkl 	# Build with MKL support.; 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL).; 	--config=monolithic 	# Config for mostly static monolithic build.; 	--config=numa 	# Build with NUMA support.; 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.; 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API.; Preconfigured Bazel build configs to DISABLE default on features:; 	--config=nogcp 	# Disable GCP support.; 	--config=nonccl 	# Di",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279:7231,down,download,7231,,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279,2,['down'],"['download', 'downloaded']"
Availability,"======= [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; ========== [Sun 04 Jun 2023 11:11:27 PM UTC] Stage 'run-prereq.sh complete' starting; ```. The last time I tried running `./build-prereq.sh`, I got error on the building of Clif. llvm-11-linker-tools not available.; and now the error is:; ```; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"") ; -- Checking for module 'protobuf'; -- Found protobuf, version 3.13.0; -- Checking for module 'libglog'; -- Found libglog, version 0.4.0; -- Looking for pthread.h; -- Looking for pthread.h - found; -- Performing",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276:4608,error,error,4608,,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276,2,"['echo', 'error']","['echo', 'error']"
Availability,"=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-2; #SBATCH --mem-per-cpu=68GB; #SBATCH --qos=maxjobs500. module purge; module load parallel; module load singularity. EXOME_IDs_FILE=/scratch/c.c21087028/checking_variant_deepvariant/exome_ID_file; HG38_REFERENCE=/scratch/c.c21087028/coverage_graph_and_clincnv_files/ClinCNV/hg38/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna; PICARDMARKDUPLICATES_SORTEDBAM=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_markedduplicates_GCA_000001405.15_GRCh38_no_alt_analysis_set.bam; REGIONS=""chr15:41,132,484-42,007,831""; OUTPUT_VCF=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set_checkingvariantregion.vcf.gz; OUTPUT_GVCF=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set_checkvariantregion.g.vcf.gz; INTERMEDIATE_RESULTS=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$REGIONS \; --make_examples_extra_args=""emit_realigned_reads=true,realigner_diagnostics=/output/realigned_reads"" \; --output_vcf=$OUTPUT_VCF \; --output_gvcf=$OUTPUT_GVCF \; --intermediate_results_dir=$INTERMEDIATE_RESULTS""; ```. with the error: . ```; ***** Intermediate results will be written to /scratch/c.c21087028/checking_variant_deepvariant/E036-H-013_TAAGGCGA-ACTGCATA_L007_PE_output_intermediate in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/c.c21087028/coverage_graph_and_clincnv_files/ClinCNV/hg38/GCA_000001405.15_GRCh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/691#issuecomment-1667692113:1537,error,error,1537,,https://github.com/google/deepvariant/issues/691#issuecomment-1667692113,2,['error'],['error']
Availability,"> **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:; > ; > **Describe the issue:** Am getting the error as ""Fatal Python error: Segmentation fault""; > ; > **Setup**; > ; > * Operating system: Ubuntu 22.04.2 LTS; > * DeepVariant version: 1.6.1; > * Installation method (Docker, built from source, etc.): Docker; > * Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Its a Pabcio CLR data. Read Input is provided in Fastq format and reference in FASTA format.; > ; > **Steps to reproduce:**; > ; > * Command: sudo docker run ; > -v ""${INPUT_DIR}"":""/input"" ; > -v ""${OUTPUT_DIR}"":""/output"" ; > google/deepvariant:""${BIN_VERSION}"" ; > /opt/deepvariant/bin/run_deepvariant ; > --model_type=PACBIO ; > --ref=/input/RILWLs1.fasta ; > --reads=/input/Out.fastq ; > --output_vcf=/output/output.vcf.gz ; > --output_gvcf=/output/output.g.vcf.gz ; > --intermediate_results_dir /output/intermediate_results_dir ; > --num_shards=15; > * Error trace: (if applicable); > ; > **Does the quick start test work on your system?** Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Yes. Test data works fine. ![Screenshot from 2024-04-17 12-24-22](https://private-user-images.githubusercontent.com/68117296/323111309-41ac66ff-ff52-493f-b18f-f017921caa86.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTMzMzcyOTIsIm5iZiI6MTcxMzMzNjk5MiwicGF0aCI6Ii82ODExNzI5Ni8zMjMxMTEzMDktNDFhYzY2ZmYtZmY1Mi00OTNmLWIxOGYtZjAxNzkyMWNhYTg2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDE3VDA2NTYzMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg3ZDQ3ZTBmNDFjYWQ4YWQyNmM4MDdmYTJiYjVjNzlhYmI1MDA2NzQxOGY3MjA1ZjU1ODY3ZDUzOTcyMTkyNzQmWC1BbXotU2lnbmVkSGVhZGVycz1ob",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/807#issuecomment-2060514080:141,error,error,141,,https://github.com/google/deepvariant/issues/807#issuecomment-2060514080,3,"['error', 'fault']","['error', 'fault']"
Availability,"> @RenzoTale88 after installing through bioconda, the binaries and models for DeepVariant will be located under the following path, where $ENV_NAME is the name of the conda environment.; > ; > ```; > $ ls miniconda2/envs/${ENV_NAME}/share/deepvariant-0.9.0-0; > binaries models ; > ```; > ; > The binaries can be run as shown in [this script](https://github.com/google/deepvariant/blob/r0.9/scripts/run_wgs_case_study_binaries.sh), which goes through the [WGS case study (Docker instructions)](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md). For example, you can run:; > ; > ```; > $ python miniconda2/envs/${ENV_NAME}/share/deepvariant-0.9.0-0/binaries/D; > eepVariant/0.9.0/DeepVariant-0.9.0/make_examples.zip <flags>; > ```; > ; > Note, you may have to run `chmod +x miniconda2/envs/${ENV_NAME}/share/deepvariant-0.9.0-0/binaries/D eepVariant/0.9.0/DeepVariant-0.9.0/make_examples.zip` prior to running the command above. This will apply to other binaries as well (`call_variants`, `postprocess_variants`, etc.). Let me know if you have any other questions!; > ; > @prabal97 could you share the error you are seeing?. I am getting the following error even after using the binaries in the mentioned directories . ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/252#issuecomment-568349835:1131,error,error,1131,,https://github.com/google/deepvariant/issues/252#issuecomment-568349835,2,['error'],['error']
Availability,"> @dkurt Keeping them in the image is fine! I'm actually more curious about whether I can get rid of that big model.ckpt.data-00000-of-00001 file. :). @pichuan, that's good question. Checkpoint is used to restore model training and that's why it takes a lot of size. Probably, internally it contains not just weights but also gradients and intermediate outputs for layer. `.pb` model can be used for inference but using TensorFlow 1.x API, not sure about Estimator, unfortunately. I moved OpenVINO conversion into runtime anyway - that seems now simpler and doesn't oversize an image. > @dkurt One more question for you -- do you see any downside of enabling --use_openvino as default in our CPU run? Once this is built into our CPU docker image, it'll be nice to have it as default. I want to know if it might crash on non-Intel hardware or not. (I can also test it myself, but haven't got around to do that yet). Just tried the image on [n2d-standard-8](https://cloud.google.com/compute/docs/machine-types#n2d_machine_types) from GCP and it works fine through OpenVINO backend (AMD EPYC 7B12). So seems like we can freely turn OpenVINO by default for CPU only environment. Shall I do it in this PR or you can switch it separately?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735703602:183,Checkpoint,Checkpoint,183,,https://github.com/google/deepvariant/pull/363#issuecomment-735703602,3,"['Checkpoint', 'down']","['Checkpoint', 'downside']"
Availability,> @husamia Can you see if any earlier logs have more information? See if you can find another Traceback with more informative error messages?. I closed the container. . > @husamia Basically what you are seeing is that you're running out of memory. Try it on a machine with more memory. that's a good point. is there an option to specify the temp folder? this would solve my problem.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/412#issuecomment-767600297:126,error,error,126,,https://github.com/google/deepvariant/issues/412#issuecomment-767600297,1,['error'],['error']
Availability,"> @nilesh-iiita to address this issue, you should not need to realign the reads. Instead, you can pass the `--sample_name=<NAME>` to the `run_deepvariant` command. `<NAME>` can be set to any desired value. It seems like your BAM file is missing a sample name, and when this happens, `make_examples` fails. Adding this flag will ensure that there is a sample name available for `make_examples` to use. Thanks! It worked very well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/435#issuecomment-810516515:363,avail,available,363,,https://github.com/google/deepvariant/issues/435#issuecomment-810516515,1,['avail'],['available']
Availability,"> @nvnieuwk Does it mean you only encounter this issue when running on a small region? Does the same setting work when you run something like the Quick Start?. Yes I've tried it with a CRAM file that contains the whole chromosome 21 and this works, but when I use a BAM with the subset `chr22:0-40001`, I get the earlier mentioned error",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/640#issuecomment-1550781075:331,error,error,331,,https://github.com/google/deepvariant/issues/640#issuecomment-1550781075,1,['error'],['error']
Availability,> @williamrowell Can you check whether your CPU supports AVX instruction?. This is the likely cause. No AVX support on this node. Seems odd that there's a core dump with no error message. ```bash; wrowell@mp0608-sge:~$ lscpu | grep Flags; Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 popcnt aes lahf_lm tpr_shadow vnmi flexpriority ept vpid dtherm ida arat; ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/419#issuecomment-774782391:173,error,error,173,,https://github.com/google/deepvariant/issues/419#issuecomment-774782391,1,['error'],['error']
Availability,"> @zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?. OS:Ubuntu 20.04 , I also running with root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/859#issuecomment-2275039756:68,error,errors,68,,https://github.com/google/deepvariant/issues/859#issuecomment-2275039756,2,['error'],"['error', 'errors']"
Availability,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe; > […](#); > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread? — Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658794438:308,down,downloaded,308,,https://github.com/google/deepvariant/issues/682#issuecomment-1658794438,1,['down'],['downloaded']
Availability,"> Did you run `tensorflow.test.is_gpu_available()` from the DeepVariant docker?. Yes i did , I have posted the result which shows that in python shell the gpu can be identified with tensorflow in the first comment. > Could you try the suggestion from this [thread](https://stackoverflow.com/questions/48658204/tensorflow-failed-call-to-cuinit-cuda-error-no-device). Actuallly i have tried to set ` CUDA_VISIBLE_DEVICES=0 ` in System ENV ,it did't work .So I tried to find the place where sets the value of the env in your code , and want to set the ` CUDA_VISIBLE_DEVICES=0 ` , but i did't find. So ,i turn to ask for your help. I think the reason why the error occurs may be in your code the value of the ` CUDA_VISIBLE_DEVICES` does't match with my device.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/820#issuecomment-2126036319:348,error,error-no-device,348,,https://github.com/google/deepvariant/issues/820#issuecomment-2126036319,2,['error'],"['error', 'error-no-device']"
Availability,"> Do you recommend read trimming before alignment using tools such as fastp?. No - we don't perform read trimming and in fact, this can hurt model performance (because we trained on untrimmed data). We observed this when running our models on processed with Opossum (which performs trimming):. <img width=""1167"" alt=""image"" src=""https://github.com/google/deepvariant/assets/1536935/4e0cd335-0818-4cec-ae0c-ef294e98da39"">. > I can see that this is the repository for the human reference genome, which DeepVariant recommends. You can use a reference with or without alt contigs. With ALT contigs we have previously observed a slight increase in error rates with other models. I have not investigated whether they have an impact with our RNA-seq model. __Note:__ I have updated this after speaking with my teammates regarding this question.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/791#issuecomment-1997884080:643,error,error,643,,https://github.com/google/deepvariant/issues/791#issuecomment-1997884080,1,['error'],['error']
Availability,"> FYI I submitted a pull request to GLnexus repo for the ""nomod"" preset for merging (no filters or genotype revision). [dnanexus-rnd/GLnexus#229](https://github.com/dnanexus-rnd/GLnexus/pull/229) If this is accepted, you'll be able to try it out without downloading an external .yml file.; > ; > @aderzelle Please let me know if you have any questions/comments related to this issue. If not, please feel free to close it :). Thanks for your detail explanation! I think I have all I need ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/326#issuecomment-663874710:254,down,downloading,254,,https://github.com/google/deepvariant/issues/326#issuecomment-663874710,1,['down'],['downloading']
Availability,"> Hello Ferdinand,; > ; > I have a few questions which may help us to understand whether this would be expected or not. First, can you tell me how many variants are Refcall in this sample (zcat Sample.final.vcf.gz | grep RefCall | wc -l) and how many variants are PASS in this sample (zcat Sample.final.vcf.gz | grep PASS | wc -l); > ; > Second, is it possible for you to point me to the capture regions that you used (the S07604514 BED file) or, if that is not possible, for you to tell me how many bases it covers.; > ; > Knowing this information will help understand whether the number of variants are within expectations, whether they are a function of something about the sample, or whether there is some other issue to address. Generally, the commands do not seem in error.; > ; > Thanks,; > Andrew. Thanks for your quick response. I have 1191 RefCall variants and 10972 PASS variants in the final VCF file. We sequenced the sample NA12878 from the HapMap project, for benchmarking it with hap.py against the GIAB reference data.; As you mentioned we used the Agilent SureSelect Human All Exon V6 r2 Bedfile (S07604514 BED file), which is also attached to this message. [S07604514_Regions.txt.gz](https://github.com/google/deepvariant/files/2914627/S07604514_Regions.txt.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/158#issuecomment-468228631:773,error,error,773,,https://github.com/google/deepvariant/issues/158#issuecomment-468228631,1,['error'],['error']
Availability,"> Hello,; > ; > I'm very new to model training and honestly, coding, so thank you for your patience! I'm trying to run my own samples following along with the [advanced training case study](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). I've reached the stage where I need to locally shuffle the training examples using the shuffle_tfrecords_beam.py script.; > ; > I downloaded the latest version of tensorflow (2.15) and was initially getting an error that apache beam was not being recognized, and realized that beam did not install because its latest version (2.54) was incompatible with the current version of numpy (1.26) that was being imported. I uninstalled that new version of numpy in tensorflow and installed an older version that would be compatible (1.24.4), and then was able to install apache beam (2.54). However, now I'm getting even more errors (see below). Do you have any advice on which versions of everything I should make sure to have installed correctly before running the shuffle script? Any guidance is very much appreciated.; > ; > Not so much a question but I want to confirm my understanding of the pipeline from the tutorial, as again I am very new to this. First step is to run deepvariant make_examples in training mode to create training and validation sets. In the documents, these are individual chromosomes, but in theory these could be whole individuals or multiple individuals, is that correct? And then make_examples in training mode should be run multiple times independently for training and validation sets? If for example, I used Chromosome 1 for my training set and Chromosome 2 for my validation set, should those repeated runs be made on different chromosomes, or the same chromosomes? Then finally, once everything is shuffled, run model_train and model_eval. Let me reply to this part first:; ""First step is to run deepvariant make_examples in training mode to create training and validation sets. In the docum",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/793#issuecomment-2008095137:410,down,downloaded,410,,https://github.com/google/deepvariant/issues/793#issuecomment-2008095137,6,"['down', 'error']","['downloaded', 'error', 'errors']"
Availability,"> Hi @Axze-rgb,; > ; > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types − that's the basic hypothesis here.; > ; > So here's a quick way you can fix the multiallelic issue above:; > ; > 1) First split the multiallelic sites into biallelic records like this:; > ; > ```; > bcftools norm -m - multi_allelic.vcf > biallelic.vcf; > ```; > ; > 2) Then parse for the `0/0` and `./.` genotypes − I'm assuming your genotypes are not phased:; > ; > ```; > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv; > ```; > ; > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data.; > ; > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. ; It's easy to fix by asking bcftools itself to make the new line; > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1651199762:1495,error,error,1495,,https://github.com/google/deepvariant/issues/682#issuecomment-1651199762,1,['error'],['error']
Availability,"> Hi @JosephLalli ; > ; > ; > ; > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. ; > ; > ; > ; > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first.; > ; > ; > ; > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it.; > ; > ; > ; > What timeframe do you think is required for your purposes?; > ; > ; > ; > Thank you,; > ; > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,; Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/534#issuecomment-2266268721:350,error,errors,350,,https://github.com/google/deepvariant/issues/534#issuecomment-2266268721,2,"['avail', 'error']","['available', 'errors']"
Availability,"> Hi @X1angyang; > ; > The model is InceptionV3. You can see the layers of one of the DeepVariant models like this:; > ; > ```; > import tensorflow as tf; > ; > !gsutil cp gs://deepvariant/models/DeepVariant/0.10.0/DeepVariant-inception_v3-0.10.0+data-wgs_standard/model* /tmp/; > checkpoint_path = '/tmp/model.ckpt'; > ; > reader = tf.compat.v1.train.NewCheckpointReader(checkpoint_path); > shape_map_for_layers = reader.get_variable_to_shape_map(); > print(shape_map_for_layers); > ```; > ; > I just tested that in Colab (https://colab.research.google.com/).; > ; > However, reimplementing all of DeepVariant from bam to output VCF would be a huge project. If you are interested in something smaller to get started, I'd like to bring this blog post to your attention: https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction/.; > It has an associated Colab notebook that walks through some smaller but still challenging examples of how to use genomic data in machine learning using TensorFlow and Nucleus.; > ; > I hope that helps!; > Maria. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/328#issuecomment-663306398:872,error,error-correction,872,,https://github.com/google/deepvariant/issues/328#issuecomment-663306398,2,['error'],['error-correction']
Availability,"> Hi @ZuyaoLiu ,; > ; > Just to clarify, you meant that you're running multiple call_variants on the same machine at the same time, so they're all opening the same tmp file?; > ; > If that's the case, then I can see that being an issue. I'll file an internal issue to track, and will name the h5 separately. Currently our code is: https://github.com/google/deepvariant/blob/r1.6/deepvariant/keras_modeling.py#L98 and I can see this being an issue when multiple call_variants are run. We'll make sure to create a more unique filepath in the future to avoid issue!; > ; > On the other hand, historically we don't recommend running multiple call_variants runs on the same machine. Because TensorFlow will parallelize and use multiple CPUs already.; > ; > @ZuyaoLiu @crazysummerW Just for my sanity check, can you confirm that if you run just one call_variants on the machine, then it worked? (I want to make sure there are no other issues). @pichuan ,. Yes, you get me correctly. So I run call_variants on a cluster where each node is in charge of a single job. As I set my private tmp dir, these jobs will target the same h5 file, and it will cause the issue. . Currently, I am running the program by setting a unique tmp path to different jobs so that they won't use the same h5 file simultaneously. And they all worked well and finished with no errors.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/725#issuecomment-1823460228:1345,error,errors,1345,,https://github.com/google/deepvariant/issues/725#issuecomment-1823460228,1,['error'],['errors']
Availability,"> Hi @ZuyaoLiu; > ; > When I tested calling and training, I also saw that message. But in both of my calling and training, the GPU was utialized.; > ; > We added an entry in FAQ: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-am-i-seeing-cuda_error_not_initialized-initialization-error-while-running-on-gpu; > ; > and I mentioned that message in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-training-case-study.md#test-the-model as well.; > ; > @ZuyaoLiu , can you help check whether the results of calling is reasonable on your side, and whether GPU is utilized or not?; > ; > And, similarly in the training case, some of the warning messages you have might not affect the results. Can you also check whether you can run through the steps (and whether GPU is utilized or not)?; > ; > Thank you!. Hi @pichuan ,. I finished testing with a trio from a non-model species, and found a huge difference. Basically, under the default human model, V 1.6 produces more sites violating mendelian rules than V1.5. The post is here #726 .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/722#issuecomment-1793557479:297,error,error-while-running-on-gpu,297,,https://github.com/google/deepvariant/issues/722#issuecomment-1793557479,1,['error'],['error-while-running-on-gpu']
Availability,"> Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message. Thank you!; It'll make things easier for the prospective users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/160#issuecomment-470924522:113,error,error,113,,https://github.com/google/deepvariant/issues/160#issuecomment-470924522,1,['error'],['error']
Availability,"> Hi @ahgillmo; > ; > We do have a prototype implementation for somatic calling, which can take a tumor and normal BAM and call subclonal variants. However, we don't yet have enough confidence in the available truth sets, and that they come from a diverse enough sampling of cancers with mutational profiles, for us be certain in releasing something of high quality.; > ; > We're watching developments in the area of these truth sets and hope to be able to further develop the somatic caller in the future. Where can I find the prototype and try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/351#issuecomment-888743997:200,avail,available,200,,https://github.com/google/deepvariant/issues/351#issuecomment-888743997,1,['avail'],['available']
Availability,"> Hi @asalimih ,; > ; > can you downsample your bam for this specific variant and run it again?; > ; > ```shell; > samtools view -s 0.5 -b -@16 YOU_BAM.bam > YOUR_BAM.downsampled.bam; > ```; > ; > And run it one more time to see if this specifically has a different genotype?. sure, no change in GT (using v1.6.1):; ```; chr1 1668449 . A G 42.1 PASS . GT:GQ:DP:AD:VAF:PL 1/1:27:77:36,41:0.532468:42,26,0; ```; I tried with `samtools view -s 0.25` too:; ```; chr1 1668449 . A G 35.5 PASS . GT:GQ:DP:AD:VAF:PL 1/1:16:44:22,22:0.5:35,16,0; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/824#issuecomment-2130507225:32,down,downsample,32,,https://github.com/google/deepvariant/issues/824#issuecomment-2130507225,2,['down'],"['downsample', 'downsampled']"
Availability,"> Hi @husamia; > ; > It looks like the error message is indicating that the disk is full, which can occur even when there is memory. Can you check how much hard disk space is present on the machine.; > ; > If you are running low on space unexpectedly, you may want to check that you aren't accumulating space from Docker runs that weren't cleaned up by the system. It could be worth looking at [this page](https://docs.docker.com/config/pruning/) if that is the case. the disk has more than 100X times the size. So it's not a disk space. I will rerun after pruning to see if it solves the problem. > Hi @husamia; > Another thing to note is that DeepVariant doesn't currently support Windows. We recommend getting a Linux machine. Let us know if that works for you. Docker Desktop linux containers run natively on Windows 10.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/400#issuecomment-749549925:39,error,error,39,,https://github.com/google/deepvariant/issues/400#issuecomment-749549925,1,['error'],['error']
Availability,"> Hi @husamia; > ; > The openVINO acceleration occurs at the call_variants stage, not during make_examples. If you are running from the Docker image, each stage should report its runtime in standard error. I would use that reported time for the call_variants stage to assess whether there is any improvement. Is performance at the make_examples stage is dependent on the disk read/write?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/408#issuecomment-766349948:199,error,error,199,,https://github.com/google/deepvariant/issues/408#issuecomment-766349948,1,['error'],['error']
Availability,"> Hi @jaspez yeah my apologies - when I read your comment more carefully, it seemed like you used `1`, so I removed my previous answer. `--gvcf_gq_binsize=1` will only merge records when they have identical GQ values, so there would be no loss of information at least in terms of GQ, but as you already saw this will not be exactly the same as what you specified (single line per position).; > ; > Unfortunately we do not currently have an option to keep every single non-variant position, as this would make the gVCF files extremely large. In general I'd recommend not doing this anyway, since this will eventually slow down any downstream processing of the gVCFs such as merging gVCFs using GLnexus, etc. I think the easiest way to achieve this would be by post-processing the gVCFs generated with `--gvcf_gq_binsize=1`. For example, the `break_blocks` option in [gvcftools](https://sites.google.com/site/gvcftools/home/configuration-and-analysis) seems to do this, based on an answer in this [forum](https://www.biostars.org/p/136461/).; > ; > May I ask what is your use case that prefers every non-variant position to be written?; > ; > Best, Ted. Thanks @tedyun for your reply. I'm interested not only in non-variant positions but also variant positions to be written individually. Some surrounding variants with the same GQ are written in the same line with `--gvcf_gq_binsize=1`, losing other important information fields for these variants. Best,; David.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/282#issuecomment-966408955:621,down,down,621,,https://github.com/google/deepvariant/issues/282#issuecomment-966408955,2,['down'],"['down', 'downstream']"
Availability,"> Hi @leorippel; > ; > In your log, the error says:; > ; > ```; > 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory; > ```; > ; > Can you confirm that you actually have this file? From what you described earlier, you're trying to rename files into this format, but I'm not sure what you actually rename them to. Yes, Sorry for the late reply. when I type the input command "" --nonvariant_site_tfrecord_path ""/input/gvcf.tfrecord@30.gz"" "" I understand that the script will look for this pattern, no? Because I tried *gvcf.tfrecord@30.gz also didn't work and as I mentioned before my entry files are ""SPLIT2.gvcf.tfrecord-00000-of-00030.gz and SPLIT.gvcf.tfrecord-00000-of-00030.gz "". The ""*"" before the pattern should work? maybe two --nonvariant_site_tfrecord_pat flags? . how Can I pass those 2 differents names to the argument?. Cheers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/413#issuecomment-771149411:40,error,error,40,,https://github.com/google/deepvariant/issues/413#issuecomment-771149411,1,['error'],['error']
Availability,"> Hi @linlin-coder , Right, because in v1.5.0 we didn't really update DeepTrio PacBio, we decided to just point our users to v1.4.0, which was the version without the direct read haplotagging built in.; > ; > Like I mention, we expect v1.6.0 (coming out before end of this year) to have a new version of DeepTrio PacBio which won't require an extra step of WhatsHap in between. Thank you to the author and the software developer for their continuous maintenance of open-source tools. As a software user, I will also continue to pay attention to the subsequent updates and article publications of this software. I look forward to more exchanges in the future",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/689#issuecomment-1661420506:450,mainten,maintenance,450,,https://github.com/google/deepvariant/issues/689#issuecomment-1661420506,1,['mainten'],['maintenance']
Availability,"> Hi @linlin-coder,; > ; > I noticed that you were using 1.4.0 of DeepTrio, and there are Docker containers for DeepTrio 1.5.0:; > ; > [deeptrio-1.5.0](https://hub.docker.com/layers/google/deepvariant/deeptrio-1.5.0/images/sha256-82759ab1e1289b4ebcf5af8760a1446013ceb8e538aa1ffbf6bea5402012960c?context=explore); > ; > [deeptrio-1.5.0-gpu](https://hub.docker.com/layers/google/deepvariant/deeptrio-1.5.0-gpu/images/sha256-6876344f0cbc235909326fd7757129ed80cd9cfc6ef04251bd9d330c4301ad84?context=explore); > ; > So DeepTrio has its own models, as does DeepVariant, both of which are version-specific. Regarding DeepVariant specifically I know that the variant call probabilities are well-calibrated within each model individually, so that GLnexus can operate on them -- something that Andrew confirmed previously.; > ; > Hope it helps, Paul. thanks for your suggestion, meanwhile i installed deeptrio-1.5.0 in my computer, but the analysising result of deeptrio-1.5.0 display run failed, error information is ; ```; 2023-08-02 10:09:51.033332: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; To run DeepTrio PACBIO, please use version v1.4.0. See https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-pacbio-case-study.md; ``` ; cause of this cause of this error information, i use deeptrio v1.4.0 to call variation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/689#issuecomment-1661402240:987,error,error,987,,https://github.com/google/deepvariant/issues/689#issuecomment-1661402240,2,['error'],['error']
Availability,"> Hi @mosh305; > I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`. @pichuan Thank you for pointing that out, I am not so familiar with bioinformatics so I don't really know how to continue from here.; Where can I find the right input for `--truth_variants` for my reference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-450633841:268,error,errors,268,,https://github.com/google/deepvariant/issues/128#issuecomment-450633841,1,['error'],['errors']
Availability,"> Hi @pioneer-pi ,; > ; > Can you please put some more details? Please follow the suggestions in this doc: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md, which suggests you to run `sudo su` before running `./build-prereq.sh`. One thing you can do is run:; > ; > ```shell; > ./build-prereq.sh 2>&1 | tee /tmp/dv_build.log; > ```; > ; > Then upload the `dv_build.log` here so a detailed log is available. I pull the docker image of deepvariant:1.5.0, and then I start a container through `docker run -it deepvariant /bin/bash`. In this environment(I am root), I git clone the source code and try to build it from source according to the suggestions. The problem happened while I running the ./build-prereq.sh. The more detail information:. ```; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; + cd clif; + [[ ! -z 9ec44bde4f7f40de342a1286f84f5b608633a2d7 ]]; + git checkout 9ec44bde4f7f40de342a1286f84f5b608633a2d7; Note: switching to '9ec44bde4f7f40de342a1286f84f5b608633a2d7'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at 9ec44bd Replace C++ `#import <...>` with `#include <...>`; + git init; Reinitialized existing Git repository in /root/clif/.git/; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/737#issuecomment-1818093820:425,avail,available,425,,https://github.com/google/deepvariant/issues/737#issuecomment-1818093820,2,['avail'],['available']
Availability,"> Hi @themkdemiiir,; > ; > Although, it is absolutely possible to split the bam into chromosomes and run them separably there are better way to make a pipeline. There are 3 binaries that DeepVariant executes: make_examples, call_variants, and postprocess_variants. You may run those binaries from the docker.; > ; > * make_examples is highly parallelized already. You may shard it to as many shards as needed by simply specifying the output of make_examples as sharded by adding @ to the file name and add `--task` flag that specifies the task number for each shard.; > * call_variants will be run with the same number of shards.; > * postprocess_variants has to be run in a single process.; > ; > Here is an example of running shard 11 of make_examples and call_variants broken into 200 shards:; > ; > ```; > bin/make_examples \; > --examples /tmn/your_examples.tfrecord@200.gz \; > --mode calling \; > --reads /tmp/your_input_bam.bam \; > --realign_reads \; > --ref=/tmp/your_reference.fna \; > --task=11; > ; > # Input for each instance of call_variants is the output of one instance of make_examples:; > bin/call_variants.par \; > --batch_size=32 \; > --checkpoint <Path to the model checkpoint or saved model>.ckpt \; > --examples /tmp/your_examples.tfrecord-00011-of-00200.gz \; > --outfile /tmp/your_call_variants_output.cvo.tfrecord-00011-of-00200.gz; > ; > # Input for for postprocess would be the output of all instances of call_variants:; > /tmp/your_call_variants_output.cvo.tfrecord@200.gz; > ```. So how could I merge the output of the call_variants step?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/744#issuecomment-1855569624:1158,checkpoint,checkpoint,1158,,https://github.com/google/deepvariant/issues/744#issuecomment-1855569624,4,['checkpoint'],['checkpoint']
Availability,"> Hi!; > ; > Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint.; > ; > ```; > model_example_info_json = f'{checkpoint_path}/example_info.json'; > model_example_shape = dv_utils.get_shape_and_channels_from_json(; > model_example_info_json; > ); > ```; > ; > Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here?. Hello, first, thank you very much for your help. Yes, the example_info.json exist, but do not have any content. Should it contain some information?; ![Captura desde 2024-08-27 08-57-05](https://github.com/user-attachments/assets/753ee356-ed61-415f-8156-7932fd1cbce4)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/869#issuecomment-2311718261:112,checkpoint,checkpoint,112,,https://github.com/google/deepvariant/issues/869#issuecomment-2311718261,2,['checkpoint'],"['checkpoint', 'checkpoints']"
Availability,"> Hi,; > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:; > ; > CondaError: Downloaded bytes did not match Content-Length; > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2; > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2; > Content-Length: 229846992; > downloaded bytes: 217650750; > ; > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/228#issuecomment-614524936:163,error,errors,163,,https://github.com/google/deepvariant/issues/228#issuecomment-614524936,4,"['Down', 'down', 'error']","['Downloaded', 'downloaded', 'error', 'errors']"
Availability,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was.; > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:; > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.); > (2) Is this reliably reproducible on the same input?; > ; > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM).; When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```; I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants; I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples; real	3m0.610s; user	74m46.176s; sys	3m15.360s; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>; app.run(main); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run; _run_main(main, args); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero e",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/232#issuecomment-548709854:209,error,errors,209,,https://github.com/google/deepvariant/issues/232#issuecomment-548709854,5,"['error', 'reliab']","['error', 'errors', 'reliably']"
Availability,"> I'm happy to hear you have enjoyed my YouTube videos :); > ; > Hmm, there should be a more informative error message above the one that says ""parallel: This job failed"". If you don't see it, try running it without parallel and without the ""@"" sharding in the output file names.; > ; > I wouldn't recommend using `bedtools bamtobed` to generate the bed file, even if other ways aren't working. That is because it would generate a region for every read, which is definitely not the --regions DeepVariant is expecting! Since you do have the exome capture bed file, then let's get that working instead :); > ; > Also, does it work for one of the regions in the `idt_capture_novogene.grch38.bed` file?. for your last question here I've tried to run with region ""chr1:450739-451678"" from the `idt_capture_novogene.grch38.bed` file and it produced vcf files both for the test bam file in the WES run and for my personal bam file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/483#issuecomment-917356380:105,error,error,105,,https://github.com/google/deepvariant/issues/483#issuecomment-917356380,1,['error'],['error']
Availability,"> Probably the quickest way would be to process each sample individually and then combine them together, by first creating [gVCF outputs](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-gvcf-support.md) and then merging them using [GLnexus](https://github.com/dnanexus-rnd/GLnexus). A nice tutorial on how to do this is available at the following link:; > ; > https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md. Thanks for your reply! It seems too time and resource consuming to separately run for each sample. If I got the resource, I would have a try. Best ~",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/651#issuecomment-1575342924:337,avail,available,337,,https://github.com/google/deepvariant/issues/651#issuecomment-1575342924,1,['avail'],['available']
Availability,"> Thank you @ZuyaoLiu for the question and the solution. We'll give it a try and improve this.; > ; > One question for you @ZuyaoLiu , did you have any issues using Singularity + GPU to run variant calling as well, or are you seeing this issue with training only? (I'm curious because I've tried Singularity+GPU for variant calling, and that worked fine. But I haven't personally tried Singularity+GPU training yet. So I'll first want to see if I can reproduce that issue). Hi @pichuan ,. When I run the GPU version, I got this error mesages, but it still finished SNP calling and all the output files seemed fine. == CUDA ==; CUDA Version 11.3.1; 2023-10-30 00:30:39.544727: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:40.075465: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:40.617831: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:41.161964: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:41.707151: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:42.254657: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:42.796956: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:43.322127: E tensorflow/compiler/xla/stream_exec",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/722#issuecomment-1784889993:528,error,error,528,,https://github.com/google/deepvariant/issues/722#issuecomment-1784889993,3,['error'],['error']
Availability,"> This error might be caused by missing base quality scores in the BAM file, were you expecting this?; > DeepVariant does require valid base quality scores. You could technically use filler values, but DeepVariant was only trained with real base qualities, so the results will be much more reliable and accurate if you can get a BAM file with real base quality scores. I am expecting missing quality scores. I would like to ignore it. Would that be possible?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/396#issuecomment-743390856:7,error,error,7,,https://github.com/google/deepvariant/issues/396#issuecomment-743390856,2,"['error', 'reliab']","['error', 'reliable']"
Availability,">When executing using CPUs, TensorFlow by default uses all of the available cores on the machine. So in our case study, which runs on a 64 core machine, we are using all 64 cores to evaluate these tensors. Thank you! I didn't understand there was a component of this that was automatically determining the number of cores I was using and making use of them. Yes, I was using 8 cores. >Also I want to ask - in your original post are you processing exomes? If so, are you providing a capture regions bed to make_examples? . Yes, I am currently evaluating DeepVariant on Exomes and WGS samples. I did indeed provide a regions bed to `make_examples`. My original issue I was asking about was a shard that seemed to be running forever (I broke up each shard for `make_examples` onto its own single core w/2Gb memory). But, this was probably an issue with the instance I was using for that particular shard and the way our system was mishandling the restart. I can get the exomes to run through DeepVariant reliably now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/105#issuecomment-430745296:66,avail,available,66,,https://github.com/google/deepvariant/issues/105#issuecomment-430745296,2,"['avail', 'reliab']","['available', 'reliably']"
Availability,"@A-Tsai I want to make sure I understand your use case. You want GPU to be used with the specified fraction of memory. In case the GPU is not available, you want to use CPU, limited to one thread on one core. Is this correct?. Update: The code, as it is written, will only use the specified config for lines 330-336, which are running a sanity check. In order to use this config when running the model, it will have to be passed to the estimator.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/159#issuecomment-471716420:142,avail,available,142,,https://github.com/google/deepvariant/pull/159#issuecomment-471716420,1,['avail'],['available']
Availability,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/90#issuecomment-416812290:400,mask,mask,400,,https://github.com/google/deepvariant/issues/90#issuecomment-416812290,1,['mask'],['mask']
Availability,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/90#issuecomment-417185546:672,down,down,672,,https://github.com/google/deepvariant/issues/90#issuecomment-417185546,1,['down'],['down']
Availability,"@AlfWa Have you tried it without running it being in interactive mode, basically without the `-it` flag? In interactive mode you usually need to do more work to get it to work. Try it first without that flag, but just curious why are you working with it in interactive mode as it should work outside of that mode? Are you getting the same attribute error that way too? . Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/104#issuecomment-429383473:349,error,error,349,,https://github.com/google/deepvariant/issues/104#issuecomment-429383473,1,['error'],['error']
Availability,"@AndrewCarroll ; _I think this request corresponds to wanting gVCF output. When you use the --output_gvcf option. This will write reference ranges for regions of the genome that did not produce any candidates for variant calling. I did not answer this question in the prior response._. I agree GVCF gives more information, but I need to process the VCF file and downstream processing tools accepts only VCF format. Just like in GATK we can get information for all bases using ""-ERC BP resolution"", is it possible here in deep variant to get information of all variant as well as non-variant sites in VCF format",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/318#issuecomment-646486563:362,down,downstream,362,,https://github.com/google/deepvariant/issues/318#issuecomment-646486563,1,['down'],['downstream']
Availability,"@AndrewCarroll hello Andrew, thank you for your reply! I'll explain my intentions:; As a project, I need is to select a reference (doesn't really matter of what) and a dataset of long reads of that reference, successfully train the DeepVariant model with that set, and then evaluate the the trained model accuracy for the long reads. All I need to do is to use the data to make sets of training examples, validation examples and test examples, train the model with the training set, evaluate each checkpoint with the validation set, eventually choose the best checkpoint and finally evaluate it with the test set. Very similar to this [case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md) DeepVariant provided, but with a dataset of long reads. Also thank you very much for pointing out that DeepVariant was not trained for non-CCS reads, I'll try using the dataset you provided! If I'll succeed training and evaluating the model with this dataset, it would help a lot to be able to compare my my final model to your trained model. Also if you can explain a little about how to work with the files in the dataset. Where can I find truth variants and confident regions file of it's reference for my training?. I hope this clarifies my purposes. It may seem like a small project, but I greatly appreciate your help with this, it is very important to me.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-458885417:497,checkpoint,checkpoint,497,,https://github.com/google/deepvariant/issues/138#issuecomment-458885417,2,['checkpoint'],['checkpoint']
Availability,@Argonvi What hardware do you have? SSE4.1 instructions were available on Intel CPUs since 2009 (https://en.wikipedia.org/wiki/SSE4). If you have a very old hardware it might not be possible compile DeepVariant. Could you try to run it on a Cloud virtual machine?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/552#issuecomment-1219769574:61,avail,available,61,,https://github.com/google/deepvariant/issues/552#issuecomment-1219769574,1,['avail'],['available']
Availability,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/552#issuecomment-1213590530:40,error,error,40,,https://github.com/google/deepvariant/issues/552#issuecomment-1213590530,1,['error'],['error']
Availability,"@Asppagh Usually when make_examples has an error and crashes, it should have the stack trace at the end. (I've seen them in the errors I've encountered before); In this case it seems like we're trying to find out why it didn't. ; I think it's possible to change the verbose level. I'll need to look into that later. I'm traveling so it'll take a while for me to get back to this. Adding @danielecook in case you have a chance to take a look.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870758299:43,error,error,43,,https://github.com/google/deepvariant/issues/465#issuecomment-870758299,2,['error'],"['error', 'errors']"
Availability,"@Axze-rgb That's correct, you have to use AD (allele depth), which counts only informative reads out of the total reads (that IGV shows):. VAF = 15/(75+15) = 0.166667. AD refers to the reference and alternate alleles (in comma-separated order) that pass the filters, IGV shows all of them. The GQ is good with a 0.0631 % error the call is incorrect, or 93.96 % the call is correct. Does that help?. Thanks,; `p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658655489:321,error,error,321,,https://github.com/google/deepvariant/issues/682#issuecomment-1658655489,1,['error'],['error']
Availability,"@Axze-rgb,. In bash when you declare a variable as:; ```; BAM=HiFi_vaga.sorted.bam; ```; Then you need to use it as `${BAM}`, for example:; ```bash; echo ${BAM}; # vs.; echo BAM; ```; Would show you the difference. This is a good source to know about bash variables: https://tldp.org/HOWTO/Bash-Prog-Intro-HOWTO-5.html. In your first run, when it could not locate the BAM file, it gave you the error that it can't locate the BAM file. Then when it was able to locate the bam, it told you that the index is corrupted. These two errors are not related, it was not giving you `can't locate BAM` because your index was corrupted. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/685#issuecomment-1646926450:149,echo,echo,149,,https://github.com/google/deepvariant/issues/685#issuecomment-1646926450,4,"['echo', 'error']","['echo', 'error', 'errors']"
Availability,"@ChristinaMulch . With respect to the mechanics of DeepVariant - You can merge a BAM file with multiple read groups or from several files with the same read group. When you do so, if there is only one Sample among these files (specifically, all read groups have the same SM: value), DeepVariant will call all of them together, and will use that sample name for the VCF header field. If the read groups have more than one Sample, DeepVariant will give an error. If you really need to run on that file even so, there is a flag you can provide to apply a sample name to the BAM. Does this answer your question?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/651#issuecomment-1554122525:454,error,error,454,,https://github.com/google/deepvariant/issues/651#issuecomment-1554122525,1,['error'],['error']
Availability,"@DineshRavindraRaju , . Would be great if I can get the entire file to see if memory usage is the issue. If you can put it temporarily to somewhere public until I download, that would be very helpful. Please send an email to shafin@google.com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/854#issuecomment-2248673466:163,down,download,163,,https://github.com/google/deepvariant/issues/854#issuecomment-2248673466,1,['down'],['download']
Availability,"@DineshRavindraRaju ,. It looks like it's not a memory issue rather it's a compilation issue. What operating system are you working on? Looks like it's throwing an error for typecasting `bytes`. Can you please run https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md to see if it runs to completion? You should be able to run it just by copy pasting the commands.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/854#issuecomment-2246860891:164,error,error,164,,https://github.com/google/deepvariant/issues/854#issuecomment-2246860891,1,['error'],['error']
Availability,@FarmOmics we are planning on a release very soon that will enable RNA-seq variant calling. I can ping you on this issue once that release is out.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/572#issuecomment-1275106892:98,ping,ping,98,,https://github.com/google/deepvariant/issues/572#issuecomment-1275106892,1,['ping'],['ping']
Availability,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:; ```; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/input/Homo_sapiens_assembly38.fasta \; --reads=/input/$FQ.align.sort.marked.bam \; --output_vcf=/output/$FQ.vcf.gz \; --output_gvcf=/output/$FQ.g.vcf.gz \; --num_shards=2 ; ```. Let me know if it helps. Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/675#issuecomment-1629492599:374,avail,available,374,,https://github.com/google/deepvariant/issues/675#issuecomment-1629492599,1,['avail'],['available']
Availability,"@GuillaumeHolley ,. After working on this for a while, it looks like the solution isn't that easy. On your end, can you please try filtering all the `NoCall` variants from the gvcf file as a post-processing and see if that helps? I was able to get rid of the GLNexus error by filtering `NoCall` variants with `bcftools`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/521#issuecomment-1100316870:267,error,error,267,,https://github.com/google/deepvariant/issues/521#issuecomment-1100316870,1,['error'],['error']
Availability,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/534#issuecomment-2263703106:109,avail,available,109,,https://github.com/google/deepvariant/issues/534#issuecomment-2263703106,6,['avail'],['available']
Availability,"@Kwondo87 I wasn't able to reproduce the Singularity issue on my side, so I'll need more information from you. I also noticed that your original post said you used https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md . Can you use https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md instead in case there's differences? (Although, I just quickly checked and they don't look different on the Singularity section). @Kwondo87 given that I'm not able to reproduce the error, can you give me your step-by-step, including how you get the image, how you run singularity, etc. What your OS is, etc. Maybe check the numpy versions in anywhere that might be relevant and just print them? . I'll be able to help more when I can reproduce on my side. (Something similar to what I did in https://github.com/google/deepvariant/issues/745#issuecomment-1840177389 will be really helpful. Although, in that case I also wasn't able to reproduce the issue)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/746#issuecomment-1842020344:520,error,error,520,,https://github.com/google/deepvariant/issues/746#issuecomment-1842020344,1,['error'],['error']
Availability,"@MariaNattestad thanks for the tag. Yes, we had seen this error before and @pichuan correctly identified it. If you have too many AUX tags then this error pops up. One way to test would be skip `PEPPER-Margin` entirely and run DeepVariant directly on the unphased bam and you'll see the same error. Unless WhatsHap is removing auxiliary tags, it should happen with that pipeline too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/490#issuecomment-948982282:58,error,error,58,,https://github.com/google/deepvariant/issues/490#issuecomment-948982282,3,['error'],['error']
Availability,@MetteBoge can you confirm that you have the following files under a model directory?. ```; ├── model; │ ├── model.ckpt.data-00000-of-00001; │ ├── model.ckpt.index; │ └── model.ckpt.meta; ```. You will want to make sure the model files have been downloaded to the model directory:. ```bash; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta; ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/777#issuecomment-1969735397:246,down,downloaded,246,,https://github.com/google/deepvariant/issues/777#issuecomment-1969735397,1,['down'],['downloaded']
Availability,"@MorganHow does your reference match the BAM file you are using? From looking at this error message, my first thought is that your BAM file is mapped to a different reference.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/372#issuecomment-717644098:86,error,error,86,,https://github.com/google/deepvariant/issues/372#issuecomment-717644098,1,['error'],['error']
Availability,"@Npaffen As @pichuan mentioned, I would be hesitant as well to combine them as these two models seem to have been designed with different parameters in mind [as shown here](https://github.com/google/deepvariant/blob/r1.5/scripts/run_deepvariant.py#L243-L261) (especially the image width, haplotype sorting and alternate aligned pileups). You can get more details in the [following blog](https://ai.googleblog.com/2020/09/improving-accuracy-of-genomic-analysis.html) as to how some of these parameters are utilized and minimize errors for different models.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1614995973:527,error,errors,527,,https://github.com/google/deepvariant/issues/666#issuecomment-1614995973,1,['error'],['errors']
Availability,"@Npaffen BAI and PBI have similar concepts, but different approaches. BAI is an R-tree approach, while PBI seems to be HDF5-like -- basically different formats. Regarding the error you see is because your BAM and reference don't match in their sequence contig names. For instance, the reference sequence has the chromosome naming convention of `chr1`, `chr2`, etc., but in the error I see `1` as a name to match against. So if you type the following command for you BAM file:. ```; samtools view -H GFX.bam | grep @SQ; ```. You should see something like this for the same naming convention for the `SN` field:. ```; @SQ SN:chr1 LN:249250621; @SQ SN:chr2 LN:243199373; @SQ SN:chr3 LN:198022430; @SQ SN:chr4 LN:191154276; @SQ SN:chr5 LN:180915260; @SQ SN:chr6 LN:171115067; @SQ SN:chr7 LN:159138663; @SQ SN:chr8 LN:146364022; ```. Also I'm assuming you used the same reference you aligned your reads against when generating your BAM files, as the reference used for DeepVariant.; ; Let me know if there is something I should expand on. Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1600293071:175,error,error,175,,https://github.com/google/deepvariant/issues/666#issuecomment-1600293071,2,['error'],['error']
Availability,"@Phillip-a-richmond Thanks for checking.; I can take a look today. Before I made the release, I'm pretty sure I checked Singularity+GPU worked, but I should check again. I'll get a GPU machine and see if I can reproduce the errors you're seeing.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/514#issuecomment-1035263880:224,error,errors,224,,https://github.com/google/deepvariant/issues/514#issuecomment-1035263880,1,['error'],['errors']
Availability,"@PlatonB thanks for the suggestion, I will file this request internally to determine if this is an optional feature we may want to include in a future release. Currently, DeepVariant can produce both a VCF and GVCF (along with other output files), so we wanted to give users the choice of which file to use downstream. stdout has been reserved for just logging outputs so users can monitor the status of the run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/253#issuecomment-567578821:307,down,downstream,307,,https://github.com/google/deepvariant/issues/253#issuecomment-567578821,1,['down'],['downstream']
Availability,"@RenzoTale88 after installing through bioconda, the binaries and models for DeepVariant will be located under the following path, where $ENV_NAME is the name of the conda environment. ```; $ ls miniconda2/envs/${ENV_NAME}/share/deepvariant-0.9.0-0; binaries models ; ```. The binaries can be run as shown in [this script](https://github.com/google/deepvariant/blob/r0.9/scripts/run_wgs_case_study_binaries.sh), which goes through the [WGS case study (Docker instructions)](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md). For example, you can run:. ```; $ python miniconda2/envs/${ENV_NAME}/share/deepvariant-0.9.0-0/binaries/D; eepVariant/0.9.0/DeepVariant-0.9.0/make_examples.zip <flags>; ```. Note, you may have to run `chmod +x miniconda2/envs/${ENV_NAME}/share/deepvariant-0.9.0-0/binaries/D; eepVariant/0.9.0/DeepVariant-0.9.0/make_examples.zip` prior to running the command above. This will apply to other binaries as well (`call_variants`, `postprocess_variants`, etc.). Let me know if you have any other questions!. @prabal97 could you share the error you are seeing?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/252#issuecomment-568129639:1087,error,error,1087,,https://github.com/google/deepvariant/issues/252#issuecomment-568129639,1,['error'],['error']
Availability,"@Rofidagamal I'm a bit stumped. The error suggests there is an issue with the bed file provided. ```; ValueError: OUT_OF_RANGE: EOF; ```. Maybe we can look a little closer at that and see if there is any sign of an issue there. Can you run:. ```; cut -f 1 data/chr20_CDS_3x.bed | wc; cut -f 1 data/chr20_CDS_3x.bed | uniq -c; ```. I wonder if it could also be related to the amount of space being allocated / avail. Can you also provide the output from the following:. ```; sudo docker run; -v ""$(pwd):$(pwd)""; -w $(pwd); google/deepvariant:""${BIN_VERSION}"" /bin/bash. # Once the image is running, run:; df -h; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1307848624:36,error,error,36,,https://github.com/google/deepvariant/issues/581#issuecomment-1307848624,2,"['avail', 'error']","['avail', 'error']"
Availability,"@Rofidagamal it looks like this is your error:. ```; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449; Fatal Python error: Aborted; ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1298853697:40,error,error,40,,https://github.com/google/deepvariant/issues/581#issuecomment-1298853697,2,['error'],['error']
Availability,"@SHuang-Broad , are you using a BAM file that is publicly available?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/491#issuecomment-960065189:58,avail,available,58,,https://github.com/google/deepvariant/issues/491#issuecomment-960065189,1,['avail'],['available']
Availability,"@SHuang-Broad It could be disk limit issue, but I have a suspicion it might be memory related. Try to launching the free command in the background on some interval like 60 sec, before all the deepvariant ones:. free -s 60 > dv_mem_usage.txt. Then launch deepvariant in on the same machine from another terminal. Once you get the failure stop the logging from the command above. And look to see if memory has become exhausted. The above command can also be launched in parallel as part of the submitted command if that makes it easier. If that's the case, then just increase the memory requirements for the job. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/491#issuecomment-960130177:329,failure,failure,329,,https://github.com/google/deepvariant/issues/491#issuecomment-960130177,1,['failure'],['failure']
Availability,@Suke-fudan - I am not entirely sure why this error has come up. Can you double check that you are using the correct reference genome?. Are you able to identify which region of the genome this error is occurring at?. Would you be comfortable sharing a file that allows us to reporduce the error?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/488#issuecomment-953896379:46,error,error,46,,https://github.com/google/deepvariant/issues/488#issuecomment-953896379,3,['error'],['error']
Availability,"@Zjianglin Can you check whether your singularity run can see the index file?. You said you have:. `singularity run /lustre/Data/toolsDB//deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref_idx --reads=$dedupbam --output_vcf=$vcfout --output_gvcf=$gvcfout --num_shards=32 >$logx 2>&1`. Can you try something like:. `singularity run /lustre/Data/toolsDB/deepvariant.sif ls $ref_idx` ?. By the way, can you `echo $ref_idx` to see what the value is? It should be something like `--ref=/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa`. Given that your name is `$ref_idx`, hopefully it's not the .fai file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1567721314:435,echo,echo,435,,https://github.com/google/deepvariant/issues/653#issuecomment-1567721314,1,['echo'],['echo']
Availability,"@adamnovak,. Just try to copy an old checkpoint file as a new file so it gets an updated timestamp, since just quickly looking at the tensorflow source code it seems to just look for the latest file:. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/checkpoint_utils.py#L150-L178. https://github.com/tensorflow/tensorflow/blob/55d62330dd9197e69ff8f1f03981784184706b2a/tensorflow/python/checkpoint/checkpoint_management.py#L326-L363. It if complains then it would be easy to tweak the checkpoints for what tensorflow is looking for in that directory. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/611#issuecomment-1513714977:37,checkpoint,checkpoint,37,,https://github.com/google/deepvariant/issues/611#issuecomment-1513714977,3,['checkpoint'],"['checkpoint', 'checkpoints']"
Availability,"@akolesnikov ; Thank you for the answer. All paths (both directories and fiels) that I included in my script do exist. Still, it shows me an error as file doesn't exist as I wrote in my first message above",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/577#issuecomment-1284441913:141,error,error,141,,https://github.com/google/deepvariant/issues/577#issuecomment-1284441913,1,['error'],['error']
Availability,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```; (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".; (18:45:18) INFO: Current date is 2018-12-17; (18:45:40) INFO: Analysed target //:binaries (88 packages loaded).; (18:45:40) INFO: Found 1 target...; (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'; (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'; Target //:binaries failed to build; (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist; (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s; (18:45:41) INFO: 0 processes.; (18:45:41) FAILED: Build did NOT complete successfully; (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".; (18:45:43) INFO: Current date is 2018-12-17; (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded).; (18:45:48) INFO: Found 1 target...; Target //:licenses_zip up-to-date:; bazel-genfiles/licenses.zip; (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s; (18:45:49) INFO: 0 processes.; (18:45:49) INFO: Build completed successfully, 1 total action; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-447918220:219,down,down,219,,https://github.com/google/deepvariant/issues/128#issuecomment-447918220,5,"['ERROR', 'down']","['ERROR', 'down']"
Availability,@andrewrech Thanks for reporting this! How are you running DeepVariant? Could you post the full output of the error message you saw because of this issue? Thanks!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/146#issuecomment-461153551:110,error,error,110,,https://github.com/google/deepvariant/issues/146#issuecomment-461153551,1,['error'],['error']
Availability,"@asherrar Unfortunately, I'm unable to reproduce what you're seeing. I'm going to write down what I did. Maybe you can spot what differences we have:. Create a CentOS7 machine to test:. ```; gcloud compute instances create ""${USER}-centos7"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""centos-7"" \; --image-project ""centos-cloud"" \; --machine-type ""e2-standard-16"" \; --zone ""us-west1-b"". gcloud compute ssh pichuan-centos7 --zone ""us-west1-b""; ```. By default the machine has Python2; ```; [pichuan@pichuan-centos7 ~]$ python --version ; Python 2.7.5; ```. ## Install Python 3.8.10; ```; sudo yum update; sudo yum install gcc openssl-devel bzip2-devel libffi-devel -y; sudo yum install -y wget; sudo yum install -y python3; ```. ```; wget https://www.python.org/ftp/python/3.8.10/Python-3.8.10.tgz; tar xvfz Python-3.8.10.tgz; ```. ```; cd Python-3.8.10; ./configure --enable-optimizations; ```. ```; sudo yum install -y make; sudo make altinstall; ```. ```; [pichuan@pichuan-centos7 Python-3.8.10]$ python3.8 --version; Python 3.8.10; ```. ## Install Singularity. ```; sudo yum update -y && \; sudo yum groupinstall -y 'Development Tools' && \; sudo yum install -y \; openssl-devel \; libuuid-devel \; libseccomp-devel \; wget \; squashfs-tools \; cryptsetup; ```. ```; export VERSION=1.14.12 OS=linux ARCH=amd64; # Downloads the required Go package; wget https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz; # Extracts the archive; sudo tar -C /usr/local -xzvf go$VERSION.$OS-$ARCH.tar.gz; # Deletes the ``tar`` file; rm go$VERSION.$OS-$ARCH.tar.gz. export VERSION=3.8.4; wget https://github.com/hpcng/singularity/releases/download/v${VERSION}/singularity-${VERSION}.tar.gz; tar -xzf singularity-${VERSION}.tar.gz; pushd singularity-3.8.4; export PATH=/usr/local/go/bin:$PATH. ./mconfig; make -C builddir; sudo make -C builddir install; ```. Check version:; ```; [pichuan@pichuan-centos7 ~]$ singularity --version; singularity version 3.8.4; ```. ## Try running DeepVari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/610#issuecomment-1429156759:88,down,down,88,,https://github.com/google/deepvariant/issues/610#issuecomment-1429156759,1,['down'],['down']
Availability,"@ashraf123456789 I don't think the commands should vary. Could you check that you have set `${BIN_VERSION}`? I have seen this error message when the variable is not set, causing the image name to be incorrect. You could try running the following:. ```; BIN_VERSION=""0.8.0"". sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=4; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/181#issuecomment-489226839:126,error,error,126,,https://github.com/google/deepvariant/issues/181#issuecomment-489226839,1,['error'],['error']
Availability,"@baozg and @yangxin-9 , . Additionally to sending the bam files, can you please also see if the files are not truncated? You can run the following command to check if the files are OK:. ```bash; samtools quickcheck -v *.bam > bad_bams.fofn && echo 'all ok' || echo 'some files failed check, see bad_bams.fofn'; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/794#issuecomment-2031020943:243,echo,echo,243,,https://github.com/google/deepvariant/issues/794#issuecomment-2031020943,2,['echo'],['echo']
Availability,"@baozg. After carefully bisecting your BAM file, it looks like the region that throws an error is chr12:7721068-7735636. Looking at the pileup, there are 5 large (~11k) deletions in that region of 3 different lengths:; ![image](https://github.com/google/deepvariant/assets/8753889/18e84dd4-27df-4059-aced-f6f9573e1f9a). One is length `11,843`, two are `11,844` and two are `11,845`. It looks like the trouble comes from attempting to represent and realign those INDEL candidates with 2 reads each. DeepVariant can't actually call deletions that long. If you set the [vsc_min_count_indel](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/make_examples_options.py#L292-L299) to 3, the problem goes away. So adding `--make_examples_extra_args=vsc_min_count_indels=3` should fix the issue. If desired, you can run DeepVariant on just that region with `--regions=chr12:7721068-7735636`. We will work on fixing this on our end as well in our next release. @yangxin-9 To avoid mixing issues may or may not be related, please create a new issue that shows the command you ran and the output. Also, if possible, please send us the input files used so we can try to reproduce the issue ourselves.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/794#issuecomment-2035806347:89,error,error,89,,https://github.com/google/deepvariant/issues/794#issuecomment-2035806347,1,['error'],['error']
Availability,@bcantarel The error suggests there are no quality scores for the current read. . * Can you double check that the file is not truncated? (`samtools quickcheck SAMN02990337.star.bam` can help with this). ; * Can you provide any details on how it was aligned?; * Which version of STAR did you use to perform the alignment?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/752#issuecomment-1856369666:15,error,error,15,,https://github.com/google/deepvariant/issues/752#issuecomment-1856369666,1,['error'],['error']
Availability,"@bioinformaticaomicalabs , yes it should contain some information like this:. ```bash; gsutil cat gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/example_info.json; {""version"": ""1.6.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}⏎; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/869#issuecomment-2313190840:140,checkpoint,checkpoints,140,,https://github.com/google/deepvariant/issues/869#issuecomment-2313190840,1,['checkpoint'],['checkpoints']
Availability,"@bkurtoglu ,. ONT_R9 has a very high error rate, DeepVariant isn't able to work on it directly. You can try our previous solution [PEPPER](https://github.com/kishwarshafin/pepper) for R9 data. It's also mentioned on our README page: . * Oxford Nanopore R9.4.1 data by using [PEPPER-DeepVariant](https://github.com/kishwarshafin/pepper). So it's unlikely you will be successful to run DeepVariant R10.4 model on R9 data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/814#issuecomment-2091045121:37,error,error,37,,https://github.com/google/deepvariant/issues/814#issuecomment-2091045121,1,['error'],['error']
Availability,"@chapmanb ; I'm actually pretty new to this whole build thing myself. And I'm not really that familiar with bazel myself.; Do you have some instructions on how to reproduce all the way to the errors you hit? Having that will be useful for me to try to figure this out. . And, I'll try to see if I find some bazel experts internally to look at your questions as well. Maybe this is a very trivial question for people who have seen it before...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-387179220:192,error,errors,192,,https://github.com/google/deepvariant/issues/29#issuecomment-387179220,1,['error'],['errors']
Availability,@chapmanb ; Thank you for your reply!. I checked the container PATH.; ```; ~$ echo $PATH; /opt/conda/envs/deepvariant/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin; ```. and I tried to find out if unzip exists in the bin directory.; ```; ~$ ls -l /opt/conda/envs/deepvariant/bin/; .; .; .; -rwxrwxr-x 2 root root 22480 Dec 11 2018 toe*; -rwxrwxr-x 2 root root 22512 Dec 11 2018 tput*; -rwxrwxr-x 2 root root 30680 Dec 11 2018 tset*; lrwxrwxrwx 1 root root 3 Jun 3 00:24 unlz4 -> lz4*; lrwxrwxrwx 1 root root 2 Jun 3 00:24 unlzma -> xz*; -rwxrwxr-x 2 root root 238086 May 18 15:34 unpack200*; lrwxrwxrwx 1 root root 2 Jun 3 00:24 unxz -> xz*; lrwxrwxrwx 1 root root 4 Jun 3 00:24 unzstd -> zstd*; -rwxrwxr-x 2 root root 25904 Dec 18 17:04 uuclient*; -rwxr-xr-x 1 root root 236 Jun 3 00:24 wheel*; lrwxrwxrwx 1 root root 7 Jun 3 00:24 wish -> wish8.6*; .; .; .; ```. The unzip itself doesn't seem to be installed during `conda install` .; Is this a problem that only happens to me?. Thanks!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/314#issuecomment-637888585:78,echo,echo,78,,https://github.com/google/deepvariant/issues/314#issuecomment-637888585,1,['echo'],['echo']
Availability,"@crazysummerW ,. Your truth file looks empty, see the TRUTH.TOTAL is 0. Can you please make sure that you have downloaded the right file and it contains records in the VCF?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/623#issuecomment-1483276108:111,down,downloaded,111,,https://github.com/google/deepvariant/issues/623#issuecomment-1483276108,1,['down'],['downloaded']
Availability,"@crazysummerW ; I had the same issue here. It turned out to be the problem of the h5 file in the tmp dir.; If multiple programs open the h5 simultaneously, the error would occur. So I avoided this by creating a unique tmp dir for each sample, which used a lot of file handles. @pichuan @kishwarshafin Could you please take a look at this? Probably renaming the h5 file to keep it unique would be a simple and easy solution.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/725#issuecomment-1820853733:160,error,error,160,,https://github.com/google/deepvariant/issues/725#issuecomment-1820853733,2,['error'],['error']
Availability,"@crazysummerW DeepVariant works well for identifying SNVs and indels at 50% and higher in the sample, with the exception that DeepVariant misses variants in the first/last ~100 bp of chrM because of the window size. For calling the high frequency variants, you can also use `gatk HaplotypeCaller`, but since the tool was optimized for short reads, there's a lot of additional tweaking both for `HaplotypeCaller` and `VariantFiltration` to get good results for HiFi. Callers that have been specifically designed and optimized for short reads, like Mutect2, do a great job of identifying low frequency heteroplasmic SNVs, but struggle with separating low frequency indels from sequencing errors. We've had some success with more general purpose low frequency variant callers like [lofreq](https://csb5.github.io/lofreq/) and [freebayes](https://github.com/freebayes/freebayes), but we still need to explore some parameters before sharing our recommended workflow. Because this is a HiFi question and not really directly a DeepVariant question, can you follow up on https://github.com/PacificBiosciences/pb-human-wgs-workflow-snakemake/issues/106?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/686#issuecomment-1654257037:686,error,errors,686,,https://github.com/google/deepvariant/issues/686#issuecomment-1654257037,1,['error'],['errors']
Availability,"@crazysummerW the error seems to suggest that the contigs in your bam file do not match the contigs in the reference you provided. Can you double check that `$star_fasta` is pointing to the same file as `hg19.fasta`, and that the contigs present in both are the same?. One possibility here could be that the `$star_fasta` provided here removed the `chr` prefix from the chromosomes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/635#issuecomment-1522115118:18,error,error,18,,https://github.com/google/deepvariant/issues/635#issuecomment-1522115118,1,['error'],['error']
Availability,"@danielecook ; Ok; I try the command that you write it runs successfully; the updated command is; BIN_VERSION=""1.4.0""; nproc=8; sudo docker run \; -v ""$(pwd):$(pwd)"" \; -w $(pwd) \; google/deepvariant:""${BIN_VERSION}"" \; run_deepvariant \; --model_type=WES \; --customized_model=model/model.ckpt \; --ref= Homo_sapiens.GRCh38.dna.alt.fa\; --reads=data/hg005_gm26107.mrna.grch38.bam\; --output_vcf=output/HG005.output.vcf.gz \; --num_shards=$(nproc) \; --regions=data/chr20_CDS_3x.bed\; --make_examples_extra_args=""split_skip_reads=true,channels=''"" \; --intermediate_results_dir output/intermediate_results_dir. the error ; ***** Running the command:*****; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required.; I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required.; I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required.; I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required.; I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required.; I1104 15:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1303717562:616,error,error,616,,https://github.com/google/deepvariant/issues/581#issuecomment-1303717562,1,['error'],['error']
Availability,"@danielecook If you have available resources through which I can help you out to perform this analysis, feel free to let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/701#issuecomment-1708709661:25,avail,available,25,,https://github.com/google/deepvariant/issues/701#issuecomment-1708709661,1,['avail'],['available']
Availability,@danielecook The same error after I put the reference in the working directory,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1303257810:22,error,error,22,,https://github.com/google/deepvariant/issues/581#issuecomment-1303257810,1,['error'],['error']
Availability,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant.; After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04.; ========== Load config settings.; ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting; ========== This script is only maintained for Ubuntu 20.04.; ========== Load config settings.; ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting; W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Falló la conexión [IP: 18.194.81.109 80]; W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Falló la conexión [IP: 18.194.81.109 80]; W: No se han podido descargar algunos archivos de índice, se han omitido, o se han utilizado unos antiguos en su lugar.; ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting; W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Falló la conexión [IP: 18.194.81.109 80]; W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Falló la conexión [IP: 18.194.81.109 80]; W: No se han podido descargar algunos archivos de índice, se han omitido, o se han utilizado unos antiguos en su lugar.; ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting; Calling wait_for_dpkg_lock.; ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M; WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-pack",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279:168,error,error,168,,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279,1,['error'],['error']
Availability,"@dennishendriksen ,. 1) Totally understandable, please give it a try when you have time and let us know if you are still facing issues. ; 2) Those are R9.4 data. The ONT model only supports R10.4 simplex or duplex. R9.4 has elevated error rate that causes a ton of candidates. DeepTio wouldn't work with R9 data. I am closing this issue. Feel free to reopen in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/724#issuecomment-1819466106:233,error,error,233,,https://github.com/google/deepvariant/issues/724#issuecomment-1819466106,2,['error'],['error']
Availability,"@dennishendriksen ,. It seems like you are using identical data for child and parent. That would create a lot of examples given all of the sites would be identical. Can you please try with HG002, HG003/HG004 duo data in your setup and see if you are still facing the same issue. You can download the data here:; ```bash; mkdir -p input; HTTPDIR=https://storage.googleapis.com/deepvariant/ont-case-study-testdata. curl ${HTTPDIR}/HG002_R104_sup_merged.50x.chr20.bam > input/HG002_R104_sup_merged.50x.chr20.bam; curl ${HTTPDIR}/HG002_R104_sup_merged.50x.chr20.bam.bai > input/HG002_R104_sup_merged.50x.chr20.bam.bai. curl ${HTTPDIR}/HG003_R104_sup_merged.40x.chr20.bam > input/HG003_R104_sup_merged.40x.chr20.bam; curl ${HTTPDIR}/HG003_R104_sup_merged.40x.chr20.bam.bai > input/HG003_R104_sup_merged.40x.chr20.bam.bai. curl ${HTTPDIR}/HG004_R104_sup_merged.40x.chr20.bam > input/HG004_R104_sup_merged.40x.chr20.bam; curl ${HTTPDIR}/HG004_R104_sup_merged.40x.chr20.bam.bai > input/HG004_R104_sup_merged.40x.chr20.bam.bai; ```. I would **strongly** suggest running it on a small chunk as runtime was one of the issues we faced with DeepTrio ONT mode.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/724#issuecomment-1818057327:287,down,download,287,,https://github.com/google/deepvariant/issues/724#issuecomment-1818057327,1,['down'],['download']
Availability,"@depristo after rereading the 'deepvariant-build-test.md' file I am starting to think that 'gsutil' is being used to download the relevant files from GCP. Anyways, I was able to successfully build it and will start fiddling with it. Thank you for this awesome software!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/9#issuecomment-351582326:117,down,download,117,,https://github.com/google/deepvariant/issues/9#issuecomment-351582326,1,['down'],['download']
Availability,"@desmodus1984 ,. Can you verify this issue is specific to DeepVariant and not your system? Can you run:. ```bash; singularity pull docker://ubuntu:latest; ```; And see if you are able to download that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/886#issuecomment-2378384133:187,down,download,187,,https://github.com/google/deepvariant/issues/886#issuecomment-2378384133,1,['down'],['download']
Availability,"@dkurt Keeping them in the image is fine! I'm actually more curious about whether I can get rid of that big model.ckpt.data-00000-of-00001 file. :) . @dkurt One more question for you -- do you see any downside of enabling --use_openvino as default in our CPU run? Once this is built into our CPU docker image, it'll be nice to have it as default. I want to know if it might crash on non-Intel hardware or not. (I can also test it myself, but haven't got around to do that yet).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735612657:201,down,downside,201,,https://github.com/google/deepvariant/pull/363#issuecomment-735612657,1,['down'],['downside']
Availability,@dkurt Thanks! One small downside is that the Docker image will have to include the old ckpt format as well as the new format. One question for you - do you know if the converted model format can be read and used with regular Estimator as well?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735541974:25,down,downside,25,,https://github.com/google/deepvariant/pull/363#issuecomment-735541974,1,['down'],['downside']
Availability,"@drtamermansour Why don't you download glibc 2.23 from here:. https://ftp.gnu.org/gnu/glibc/. Then either inline LD_LIBRARY_PATH or export it with the location of glibc 2.23 being one of the first libraries locations it searches for. Then try rerunning the program. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-453712458:30,down,download,30,,https://github.com/google/deepvariant/issues/137#issuecomment-453712458,1,['down'],['download']
Availability,"@ekofman In this case, it seems like the gVCF file generation might have had some issues.; Since that the gVCF generation requires output from make_examples stage, is it possible that the make_examples stage weren't completely correctly? Can you check the output size from there?. And, when running manually, a common failure mode is that sometimes people will start a run, and ctrl-c in the middle. But then, sometimes some of the Python processes won't be killed, resulting corrupted intermediate outputs. If you think this might be the case, I'd recommend re-run. If you kill the process manually, make sure to kill all in the background. If you don't think this is the case, we can discuss other possibilities to diagnose this together. (I don't supposed your BAM file is public?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/164#issuecomment-476864131:318,failure,failure,318,,https://github.com/google/deepvariant/issues/164#issuecomment-476864131,1,['failure'],['failure']
Availability,"@ekofman One question for you -- did you get this error when you directly specifying gs:// in your command?; If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is.; Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/164#issuecomment-476461225:50,error,error,50,,https://github.com/google/deepvariant/issues/164#issuecomment-476461225,2,"['error', 'reliab']","['error', 'reliable']"
Availability,"@fellen31 , . The easiest solution here would be for you to downgrade to 1.6.0 as these two versions should generate identical outputs. The only fix is in `call_variants` in cases with empty shards which happens very rarely when you are running things broken into multiple steps. Unless you are experiencing the issue, you can continue using 1.6.0. Please let us know if that solution doesn't work for you and we will build a docker for you, but, it may take some time so you may need to wait.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2189948982:60,down,downgrade,60,,https://github.com/google/deepvariant/issues/830#issuecomment-2189948982,1,['down'],['downgrade']
Availability,"@gevro Given the error information, can you try installing setuptools?; For example, https://stackoverflow.com/questions/14426491/python-3-importerror-no-module-named-setuptools",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/385#issuecomment-728239211:17,error,error,17,,https://github.com/google/deepvariant/issues/385#issuecomment-728239211,1,['error'],['error']
Availability,"@gunjanbaid Hey, this is what I've done so far:. I tried downloading the BAM file again with `curl` (just to be sure the file is ok) with this command:; `curl -O ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/sorted_final_merged.bam`. I'm runnning version 1.9 of samtools and htslib, this is my output for the same commands:; ```; user@deepvariant:~/data$ samtools --version; samtools 1.9; Using htslib 1.9; Copyright (C) 2018 Genome Research Ltd. user@deepvariant:~/data$ samtools view -h ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/sorted_final_merged.bam chr20 -o chr20.bam. user@deepvariant:~/data$ samtools view -h chr20.bam | head; @HD	VN:1.4	GO:none	SO:coordinate; @SQ	SN:chrM	LN:16571	M5:6b9e15a5937653b0006de435f91578c0; @SQ	SN:chr1	LN:249250621	M5:94f0d1b1622299238a1d8a0711dd06c7; @SQ	SN:chr2	LN:243199373	M5:854e985b2e19c122b9f67f6453965693; @SQ	SN:chr3	LN:198022430	M5:8abc85e73b1c75518a03743de2c2b14b; @SQ	SN:chr4	LN:191154276	M5:2d37b4e662928cc6c58b84b2a4cc8648; @SQ	SN:chr5	LN:180915260	M5:250f4e82a213269b0a0e4aebb0468470; @SQ	SN:chr6	LN:171115067	M5:409088215d77f0bc72364b390430a5a7; @SQ	SN:chr7	LN:159138663	M5:ef15cde5c82fb860694bf8f611807459; @SQ	SN:chr8	LN:146364022	M5:8fbef8c3eaaac674cc6e690d1641464b; ```; As you can see I don't get the EOF error when viewing `chr20.bam`. I tries running make_examples with the new files and I get the same error as you got here:. > @mosh305 I do not have experience with mapping, but the README for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here.; > ...; > ; > Hope this helps!; > ; > ```; > 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; > WARNING: Logging before flag parsing goes to stderr.; > I0115 00:54:33.942667 14048",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-457253153:57,down,downloading,57,,https://github.com/google/deepvariant/issues/138#issuecomment-457253153,1,['down'],['downloading']
Availability,"@gunjanbaid Thanks for your response!; I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out!. About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file.; [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-453809513:80,error,errors,80,,https://github.com/google/deepvariant/issues/138#issuecomment-453809513,1,['error'],['errors']
Availability,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash; /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/; ```; And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/866#issuecomment-2313203552:127,checkpoint,checkpoints,127,,https://github.com/google/deepvariant/issues/866#issuecomment-2313203552,2,['checkpoint'],['checkpoints']
Availability,"@helizabeth1103 @lucasbrambrink I'll clear up some confusion real quick here - the updated training script will only output checkpoints if tune performance outperforms existing performance. If you look closely in the log file you can see this line:. ```; I0401 03:09:48.932735 140045983049536 train.py:471] Skipping checkpoint with tune/f1_weighted=0.83932966 < previous best tune/f1_weighted=0.8400078; ```. Which states that checkpointing is being skipped because the performance was worse. So in general, if you aren't seeing checkpoints you likely need to adjust parameters or train for longer.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2033443746:124,checkpoint,checkpoints,124,,https://github.com/google/deepvariant/issues/797#issuecomment-2033443746,8,['checkpoint'],"['checkpoint', 'checkpointing', 'checkpoints']"
Availability,"@heznanda Try the following to see if it fixes that requirement:. 1) Install `qemu` and `colima` like this -- colima will temporarily change the Docker runtime context to colima (see below):. ```; brew install qemu; brew install colima; ```. 2) Enable colima to be your runtime for Docker via `colima start` like this with this configuration:. ```; colima start --arch x86_64 --cpu 2 --memory 2 --disk 12 --cpu-type Broadwell-v4; ```. The above settings are in gigabytes, so adjust accordingly to what you have available on your machine. 3) Now try running the docker container for DeepVariant again. . 4) After you are done, then run `colima stop` to change Docker back to its default configurations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575598935:511,avail,available,511,,https://github.com/google/deepvariant/issues/657#issuecomment-1575598935,1,['avail'],['available']
Availability,@husamia Can you see if any earlier logs have more information? See if you can find another Traceback with more informative error messages?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/412#issuecomment-767302975:124,error,error,124,,https://github.com/google/deepvariant/issues/412#issuecomment-767302975,1,['error'],['error']
Availability,"@husamia Unfortunately usually is not a reliable description that can be applied to Docker, as it performs many layers of abstraction that can cause a spike when you are not even aware of it. 80% is definitely not enough, especially with the layers of abstractions that DeepVariant also adds. On top of that you would have the Windows abstraction either running a virtual machine or ""leaner"" Windows Subsystem for Linux, which has its own abstractions. Think about it this way, how would you even be able to tell if there is a 10 second spike when Docker starts using 97-98-99% of resources if you need to wait for the OS process resource queue to clear in order to check the Docker status, but are limited/prevented to do so by multiple layers of resource management systems?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/412#issuecomment-767885510:40,reliab,reliable,40,,https://github.com/google/deepvariant/issues/412#issuecomment-767885510,2,['reliab'],['reliable']
Availability,"@kalexiou . `call_variants` is a binary in our Docker image too. So you can run:; ```; docker run google/deepvariant:1.1.0 /opt/deepvariant/bin/call_variants --help; ```; to look at all relevant flags. Your command should be probably something like:; ```; ...; /opt/deepvariant/bin/call_variants \; --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" \; --examples ""/output/intermediate_results_dir/make_examples.tfrecord@16.gz"" \; --checkpoint ""/opt/models/wgs/model.ckpt""; ```. The checkpoint should be either wgs, wes, or pacbio depending on which type you were using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/427#issuecomment-790376285:460,checkpoint,checkpoint,460,,https://github.com/google/deepvariant/issues/427#issuecomment-790376285,2,['checkpoint'],['checkpoint']
Availability,"@kishwarshafin ,. Sure, how do I share it ,bam file is around 125gb. Should I down sample it to 10,000k reads?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/854#issuecomment-2248557992:78,down,down,78,,https://github.com/google/deepvariant/issues/854#issuecomment-2248557992,1,['down'],['down']
Availability,"@kishwarshafin ,. What operating system are you working on?; Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file; [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/854#issuecomment-2248332964:291,error,error,291,,https://github.com/google/deepvariant/issues/854#issuecomment-2248332964,1,['error'],['error']
Availability,"@kishwarshafin . Sorry to let you know, but the researcher is not okay to share the BAM file due to confidentiality concerns. Quick question: where can I download the complete datasets (aligned BAM files) for HG002 and HG003 datasets for R10 ONT chemistry used for benchmarking in the study ""Local read haplotagging enables accurate long-read small variant calling""? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/854#issuecomment-2249065386:154,down,download,154,,https://github.com/google/deepvariant/issues/854#issuecomment-2249065386,1,['down'],['download']
Availability,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:; ```; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta; ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/857#issuecomment-2261832803:62,down,downloaded,62,,https://github.com/google/deepvariant/issues/857#issuecomment-2261832803,1,['down'],['downloaded']
Availability,"@kishwarshafin I just found the error that was causing this to abruptly exit without warning. I was running the script with insufficient memory, and after changing my instance type, everything ran as expected. Thank you very much for answering my questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/819#issuecomment-2101319701:32,error,error,32,,https://github.com/google/deepvariant/issues/819#issuecomment-2101319701,1,['error'],['error']
Availability,"@kishwarshafin,. Thank you for diving into this issue. The data was very likely derived from the [GIAB HG002 ONT Ultra-long UCSC sample](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/README_ONT-UL_UCSC_HG002.md) which base-called reads with guppy (version 3.2.5). We used minimap for alignment. I'll update our test to use different data for child and parent. Unfortunately I'm a bit pressed for time at the moment, but will do so on the first available occassion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/724#issuecomment-1818289082:528,avail,available,528,,https://github.com/google/deepvariant/issues/724#issuecomment-1818289082,1,['avail'],['available']
Availability,"@kishwarshafin,. Thank you so much for your reply. How do I get the error rate of the genome assembly? This is a human cancer cell line. I ran quast on the assembly comparing it with hg19 and the number of misassemblies ~2000 and the number of mismatches per 100kb is 124.3. Why does it generate a lot of examples?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/578#issuecomment-1291993883:68,error,error,68,,https://github.com/google/deepvariant/issues/578#issuecomment-1291993883,1,['error'],['error']
Availability,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```; [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1; Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally; Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... ; 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant; 18d680d61657: Pull complete ; 0addb6fece63: Pull complete ; 78e58219b215: Pull complete ; eb6959a66df2: Pull complete ; 54de1d38bbd7: Pull complete ; d17c3563217d: Pull complete ; ba1bdbdefce9: Pull complete ; 94eba53c4ad9: Pull complete ; 413f494b0501: Pull complete ; 4d89363e7fb4: Pull complete ; e9213d1ccf36: Pull complete ; fb6121657d6b: Pull complete ; Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f; Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1; root@e2fb03e85f9e:/# python -c ""import numpy""; root@e2fb03e85f9e:/# python -c ""import numpy as np""; root@e2fb03e85f9e:/# ; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/104#issuecomment-438545095:860,Down,Downloaded,860,,https://github.com/google/deepvariant/issues/104#issuecomment-438545095,1,['Down'],['Downloaded']
Availability,@leedchou can you share what you figured out was the cause of the error?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/485#issuecomment-1050345036:66,error,error,66,,https://github.com/google/deepvariant/issues/485#issuecomment-1050345036,1,['error'],['error']
Availability,"@mano2991 I'll close this issue for now, but feel free to reopen if you are still running into this error. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/231#issuecomment-554460778:100,error,error,100,,https://github.com/google/deepvariant/issues/231#issuecomment-554460778,1,['error'],['error']
Availability,"@mclaugsf Thanks for the update! ; 1) In terms of failed jobs -- we also noticed that our current recommendation of case studies tend to mask the issues if a run failed in the middle, because we currently pipe all output to log files. We're making some changes so that if anything fails in the middle, it'll be more clear to the users later. I'm still fixing a few more things, hopefully it'll come out in the next release.; For now it's a good idea to just check the log files to make sure previous runs were successfully done before proceeding. 2) For call_variants, can you check your `call_variants.log` file and see what the lines look like?; In my run for the WGS casestudy, it converges to something like:. ```; I0815 18:49:08.438520 140611550078720 call_variants.py:359] Processed 113665 examples in 223 batches [0.222 sec per 100]; I0815 18:49:09.491303 140611550078720 call_variants.py:359] Processed 114177 examples in 224 batches [0.222 sec per 100]; I0815 18:49:10.535501 140611550078720 call_variants.py:359] Processed 114689 examples in 225 batches [0.221 sec per 100]; ```. In our case study, we recommend just running one `call_variants` per machine. `call_variants` itself does utilize multiple CPUs now, so if you use top or htop to check your run, you should see that it uses more than one CPU. In my previous experience, running multiple `call_variants` on the same machine tends to make the run slower. If you're running call_variants separately on each shard, and if you can do each of them on different machines, that's probably most ideal. But if you plan to try running multiple `call_variants` on the same machine, you might want to watch out the speed because it will likely not be linearly faster. (If you find otherwise, let me know. I haven't tried it myself for a while now)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/105#issuecomment-430711053:137,mask,mask,137,,https://github.com/google/deepvariant/issues/105#issuecomment-430711053,2,['mask'],['mask']
Availability,"@melkerdawy Thanks for checking back.; I talked to @nmousavi a while ago and he didn't recall any changes, but said that he'll look into it. I'll ping him again. I can also spend some time later (I'm currently on vacation). We're not familiar with Singularity container, and don't currently plan to provide that yet. But we can certainly look into why the installation location changes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-457984083:146,ping,ping,146,,https://github.com/google/deepvariant/issues/132#issuecomment-457984083,1,['ping'],['ping']
Availability,"@mosh305 Everything looks as expected, that is the error that you should see! . Skipping reads without a QUAL score would be ideal, as @pgrosu mentioned, but would not be useful in this case as most (all?) of the BAM file is missing the QUAL field. The error should go away once you remap with BLASR and obtain quality scores.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-457677092:51,error,error,51,,https://github.com/google/deepvariant/issues/138#issuecomment-457677092,2,['error'],['error']
Availability,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```; python bin/make_examples.zip \; --mode training \; --ref ""data/chr20.fa"" \; --reads ""data/sorted_final_merged.bam"" \; --examples ""training-examples/training_set.with_label.tfrecord.gz"" \; --confident_regions ""data/NA12878.sorted.bed"" \; --regions ""chr20"" \; --truth_variants ""data/NA12878.sorted.vcf.gz"" \; --norealign_reads; ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:; * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. ; * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps!. ```; 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; WARNING: Logging before flag parsing goes to stderr.; I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader; I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs; 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-454225947:964,error,error,964,,https://github.com/google/deepvariant/issues/138#issuecomment-454225947,1,['error'],['error']
Availability,"@mosh305 I ran the below command and killed it before it had completed. Then, I tried to view the resulting BAM file using samtools and saw the EOF marking warning. Do you see this warning when viewing the file with samtools? To resolve this error, I would recommend downloading the BAM file again and maybe just pulling chromosome 20, as I did in the below command. It's possible that the earlier error was caused by an incomplete download. I am using verison 1.9 of samtools and htslib. I would recommend upgrading if you are using much older versions. ```; $ samtools --version; samtools 1.9; Using htslib 1.9; Copyright (C) 2018 Genome Research Ltd. $ samtools view -h ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/sorted_final_merged.bam chr20 -o chr20.bam. $ samtools view -h chr20.bam | head; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; @HD	VN:1.4	GO:none	SO:coordinate; @SQ	SN:chrM	LN:16571	M5:6b9e15a5937653b0006de435f91578c0; @SQ	SN:chr1	LN:249250621	M5:94f0d1b1622299238a1d8a0711dd06c7; @SQ	SN:chr2	LN:243199373	M5:854e985b2e19c122b9f67f6453965693; @SQ	SN:chr3	LN:198022430	M5:8abc85e73b1c75518a03743de2c2b14b; @SQ	SN:chr4	LN:191154276	M5:2d37b4e662928cc6c58b84b2a4cc8648; @SQ	SN:chr5	LN:180915260	M5:250f4e82a213269b0a0e4aebb0468470; @SQ	SN:chr6	LN:171115067	M5:409088215d77f0bc72364b390430a5a7; @SQ	SN:chr7	LN:159138663	M5:ef15cde5c82fb860694bf8f611807459; @SQ	SN:chr8	LN:146364022	M5:8fbef8c3eaaac674cc6e690d1641464b; ```. Hopefully downloading the file again/remapping the reads will produce a clean BAM file. I am still not sure as to why you are not seeing the error with chromosome 20, but I'll let you know if anything else comes to mind.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-455903892:242,error,error,242,,https://github.com/google/deepvariant/issues/138#issuecomment-455903892,6,"['down', 'error']","['download', 'downloading', 'error']"
Availability,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4; ```; ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>; ```. * Reformat line 109 so that each field is tab-separated; ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878; ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-453665864:184,error,error,184,,https://github.com/google/deepvariant/issues/138#issuecomment-453665864,2,['error'],['error']
Availability,"@moyarod ,. In that case, it would be ideal if you seek help from the galaxy community: https://help.galaxyproject.org/ as this is a platform-specific error and we can't reproduce this on our end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/579#issuecomment-1297628315:151,error,error,151,,https://github.com/google/deepvariant/issues/579#issuecomment-1297628315,1,['error'],['error']
Availability,"@mvelinder I noticed that you're running on t2 micro. And it seems like you're not running the Quick Start, but actually running on our WES BAM file. Given that t2 micro only has 1G RAM, make_examples likely ran out of memory. ; DeepVariant's error message when running OOM can be a bit confusing. This is something we still hope to improve. Can you try a machine with more RAM? If you're just running a small example like the Quick Start:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md. I've confirmed that **t2.medium** worked for just the [Quick Start](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md). After copying all the data, I ran:; ```; time sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --intermediate_results_dir /output/intermediate_results_dir \; --num_shards=1; ```; In my test run on a **t2.medium** instance, this took: ; ```; real0m23.790s; user0m0.032s; sys0m0.028s; ```; to complete.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/462#issuecomment-866404518:243,error,error,243,,https://github.com/google/deepvariant/issues/462#issuecomment-866404518,1,['error'],['error']
Availability,"@mvelinder I think sometimes this could happen when the environment variables were not manually set right. For example, can you do:; ```; echo $BIN_VERSION; ```; (and all the others that you might have in your command) to make sure they're all set as expected?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/462#issuecomment-867206060:138,echo,echo,138,,https://github.com/google/deepvariant/issues/462#issuecomment-867206060,1,['echo'],['echo']
Availability,"@myonaung I wonder if the error could be something else. The error seems to indicate that setting the thread to be on a specific CPU is the issue. Could you try a few things:. 1) Can you take this code and put it in a file called `affinity.c` and then compile with `gcc affinity.c -lpthread -o affinity`. Then run the program `./affinity` and tell us what you see:. ```C; #define _GNU_SOURCE; #include <pthread.h>; #include <stdio.h>; #include <stdlib.h>; #include <errno.h>. #define handle_error_en(en, msg) \; do { errno = en; perror(msg); exit(EXIT_FAILURE); } while (0). int; main(int argc, char *argv[]); {; int s;; cpu_set_t cpuset;; pthread_t thread;. thread = pthread_self();. /* Set affinity mask to include CPUs 0 to 7. */. CPU_ZERO(&cpuset);; for (int j = 0; j < 8; j++); CPU_SET(j, &cpuset);. s = pthread_setaffinity_np(thread, sizeof(cpuset), &cpuset);; if (s != 0); handle_error_en(s, ""pthread_setaffinity_np"");. /* Check the actual affinity mask assigned to the thread. */. s = pthread_getaffinity_np(thread, sizeof(cpuset), &cpuset);; if (s != 0); handle_error_en(s, ""pthread_getaffinity_np"");. printf(""Set returned by pthread_getaffinity_np() contained:\n"");; for (int j = 0; j < CPU_SETSIZE; j++); if (CPU_ISSET(j, &cpuset)); printf("" CPU %d\n"", j);. exit(EXIT_SUCCESS);; }; ```. You should see something like this:. ```Bash; $ ./affinity; Set returned by pthread_getaffinity_np() contained:; CPU 0; CPU 1; CPU 2; CPU 3; CPU 4; CPU 5; CPU 6; CPU 7; $; ```. 2) Could you tell us what operating system and cpu are your running? If it is Linux could you the following commands and tell us what you see (these will tell us something about your CPU, Linux version, and total number of threads you can have):. Command 1: `cat /proc/sys/kernel/threads-max`; Command 2: `lscpu`; Command 3: `cat /etc/os-release` ; Command 4: `lsb_release -a`. 3) Extra credit: This will tell us about total number of threads used by the application, and if they might be hitting the maximum allowable thread ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/497#issuecomment-993147588:26,error,error,26,,https://github.com/google/deepvariant/issues/497#issuecomment-993147588,4,"['error', 'mask']","['error', 'mask']"
Availability,"@nilesh-iiita to address this issue, you should not need to realign the reads. Instead, you can pass the `--sample_name=<NAME>` to the `run_deepvariant` command. `<NAME>` can be set to any desired value. It seems like your BAM file is missing a sample name, and when this happens, `make_examples` fails. Adding this flag will ensure that there is a sample name available for `make_examples` to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/435#issuecomment-810423494:361,avail,available,361,,https://github.com/google/deepvariant/issues/435#issuecomment-810423494,1,['avail'],['available']
Availability,"@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [External]Re: [google/deepvariant] Build and test works, binaries do not (#47). I wonder if there is an issue somehow with how you are building with tensorflow-gpu. What commands did you use to build it? We think this should work with tensorflow-gpu==1.4. Here is what I did to try it out:. git clone https://github.com/google/deepvariant.git. #edit settings.sh so that DV_GPU_BUILD=1 and DV_INSTALL_GPU_DRIVERS=1. ./build-prereq.sh; ./build_release_binaries.sh. then ran a test command with the quickstart testdata:. python deepvariant/bazel-bin/deepvariant/make_examples.zip; --mode calling; --ref ""${REF}""; --reads ""${BAM}""; --regions ""chr20:10,000,000-10,010,000""; --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". which executes as expected. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/47#issuecomment-363221616>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqV3UwUysMDiEktsAe-3kindiR3myks5tR22hgaJpZM4R5yAT>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/47#issuecomment-363230217:1996,error,error-free,1996,,https://github.com/google/deepvariant/issues/47#issuecomment-363230217,2,['error'],"['error-free', 'errors']"
Availability,"@nvnieuwk from my understanding, I would be surprised if the numpy error is related to the region. I feel that might be a red herring. Unfortunately I don't have a clear answer for you because I can't reproduce your exact setting.; If you think it can still be related to the small region, the next thing I'd suggest you try is: Start from the setting that worked before (CRAM file that contains the whole chromosome 21). First confirm that still works, and just change one thing: restrict to a smaller region and see if that still works or fails with the numpy error again. Sorry that I don't have better suggestions for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/640#issuecomment-1550815697:67,error,error,67,,https://github.com/google/deepvariant/issues/640#issuecomment-1550815697,4,['error'],['error']
Availability,"@observer2735 Can you say more about what you are trying to do? Is it germline variant calling? Or maybe counting all the errors in the reads?; Please elaborate, thank you!; Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/697#issuecomment-1681396124:122,error,errors,122,,https://github.com/google/deepvariant/issues/697#issuecomment-1681396124,1,['error'],['errors']
Availability,@obsh regenerating the `.bai` index file should fix the first warning. The `Unrecognized SAM header type` warning should not cause the job to fail. . Some questions for you:; * What is the command you used to run `make_examples`? Any additional output would also be helpful.; * Is task 8 the only one that failed?; * (Unrelated to this error) Which model do you plan to use for this data?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/207#issuecomment-523147155:336,error,error,336,,https://github.com/google/deepvariant/issues/207#issuecomment-523147155,1,['error'],['error']
Availability,"@obsh sounds good. I'll close this issue for now, but feel free to reopen if you run into any other errors.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/207#issuecomment-527996299:100,error,errors,100,,https://github.com/google/deepvariant/issues/207#issuecomment-527996299,1,['error'],['errors']
Availability,"@olechnwin ,. Looking at the log, it is generating a lot of examples. Is the error-rate of the `scaffolds_FINAL.fasta` too high? Can you give a little more context on what type of genome you are running this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/578#issuecomment-1291218327:77,error,error-rate,77,,https://github.com/google/deepvariant/issues/578#issuecomment-1291218327,1,['error'],['error-rate']
Availability,"@pgrosu ; A substantial increase (almost double) of the memory available to the DeepVariant cluster jobs worked, both jobs now succeeded. Thanks for your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/304#issuecomment-643144376:63,avail,available,63,,https://github.com/google/deepvariant/issues/304#issuecomment-643144376,1,['avail'],['available']
Availability,"@pgrosu ; Thanks for the answer.; I've tried this command, and it got the same error.; ```; [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options; samples_in_order, sample_role_to_train = one_sample_from_flags(; File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; return NativeSamReader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__; self._reader = sam_reader.SamReader.from_file(; ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam; parallel: This job failed:; /opt/deepvariant/bin/make_examples --m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/577#issuecomment-1700399250:79,error,error,79,,https://github.com/google/deepvariant/issues/577#issuecomment-1700399250,1,['error'],['error']
Availability,"@pgrosu ; Yes!! thank you! For a second, I thought that bazel-5.3.0-linux-arm64 is a folder. but it is an actual bazel bin. ; ```; > bazel; WARNING: Invoking Bazel in batch mode since it is not invoked from within a workspace (below a directory having a WORKSPACE file).; [bazel release 5.3.0]; Usage: bazel <command> <options> ... Available commands:; analyze-profile Analyzes build profile data.; aquery Analyzes the given targets and queries the action graph.; build Builds the specified targets.; canonicalize-flags Canonicalizes a list of bazel options.; clean Removes output files and optionally stops the server.; coverage Generates code coverage report for specified test targets.; cquery Loads, analyzes, and queries the specified targets w/ configurations.; dump Dumps the internal state of the bazel server process.; fetch Fetches external repositories that are prerequisites to the targets.; help Prints help for commands, or the index.; info Displays runtime info about the bazel server.; license Prints the license of this software.; mobile-install Installs targets to mobile devices.; print_action Prints the command line args for compiling a file.; query Executes a dependency graph query.; run Runs the specified target.; shutdown Stops the bazel server.; sync Syncs all repositories specified in the workspace file; test Builds and runs the specified test targets.; version Prints version information for bazel. Getting more help:; bazel help <command>; Prints help and options for <command>.; bazel help startup_options; Options for the JVM hosting bazel.; bazel help target-syntax; Explains the syntax for specifying targets.; bazel help info-keys; Displays a list of keys used by the info command. ```. What should we do next?. ```; > ./build-prereq.sh; ========== This script is only maintained for Ubuntu 20.04.; ========== Load config settings.; ========== [Mon 05 Jun 2023 10:22:12 PM EDT] Stage 'Install the runtime packages' starting; ========== This script is only maintain",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053:332,Avail,Available,332,,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053,1,['Avail'],['Available']
Availability,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile; ```; mkdir glibc && cd glibc; wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz; tar xvzf glibc-2.23.tar.gz; mkdir glibc-build && cd glibc-build; mkdir ../install; ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install; make -j `nproc`; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-453764783:245,error,error,245,,https://github.com/google/deepvariant/issues/137#issuecomment-453764783,1,['error'],['error']
Availability,"@pgrosu I got tensorflow on a different folder than deepvariant-r1.5 folder.; Just fyi, there are multiple installation of bazel: `/home/user/.bazel/bin` and `/usr/bin/`; The one that is working is /usr/bin/bazel. The command `/usr/bin/bazel build -c opt ${DV_COPT_FLAGS} --build_python_zip :binaries` inside the deepvariant-r1.5 folder gives another error:; ```; ERROR: An error occurred during the fetch of repository 'local_config_python':; Traceback (most recent call last):; 	File ""/home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7c2a/external/org_tensorflow/third_party/py/python_configure.bzl"", line 271, column 40, in _python_autoconf_impl; 		_create_local_python_repository(repository_ctx); 	File ""/home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7c2a/external/org_tensorflow/third_party/py/python_configure.bzl"", line 214, column 22, in _create_local_python_repository; 		_check_python_lib(repository_ctx, python_lib); 	File ""/home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7c2a/external/org_tensorflow/third_party/py/python_configure.bzl"", line 138, column 25, in _check_python_lib; 		auto_config_fail(""Invalid python library path: %s"" % python_lib); 	File ""/home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7c2a/external/org_tensorflow/third_party/remote_config/common.bzl"", line 12, column 9, in auto_config_fail; 		fail(""%sConfiguration Error:%s %s\n"" % (red, no_color, msg)); Error in fail: Configuration Error: Invalid python library path: ""; (11:50:11) ERROR: /home/user/Documents/deepvariant-r1.5/WORKSPACE:108:14: fetching python_configure rule //external:local_config_python: Traceback (most recent call last):; 	File ""/home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7c2a/external/org_tensorflow/third_party/py/python_configure.bzl"", line 271, column 40, in _python_autoconf_impl; 		_create_local_python_repository(repository_ctx); 	File ""/home/user/.cache/bazel/_bazel_user/7cc1383e03390275c978033f9adc7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1584813838:351,error,error,351,,https://github.com/google/deepvariant/issues/657#issuecomment-1584813838,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. ; I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/90#issuecomment-417995073:149,avail,available,149,,https://github.com/google/deepvariant/issues/90#issuecomment-417995073,1,['avail'],['available']
Availability,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. ; taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/90#issuecomment-416891480:1025,avail,available,1025,,https://github.com/google/deepvariant/issues/90#issuecomment-416891480,1,['avail'],['available']
Availability,"@pgrosu Thank you for the reply! I wouldn't have thought to install qemu and colima before. I tried your instructions and added `brew install docker` as well. Successfully started colima.; ```; > colima start --arch x86_64 --cpu 4 --memory 8 --disk 20 --cpu-type Broadwell-v4; INFO[0000] starting colima ; INFO[0000] runtime: docker ; INFO[0000] preparing network ... context=vm; INFO[0000] starting ... context=vm; INFO[0073] provisioning ... context=docker; INFO[0074] starting ... context=docker; INFO[0092] done ; ```; The docker run `docker run --platform linux/amd64 google/deepvariant:1.5.0` seems to be incomplete.; The first installation, it gave this message `Unable to find image 'google/deepvariant:1.5.0' locally; 1.5.0: Pulling from google/deepvariant` and after the pull complete message and the `Status: Downloaded newer image for google/deepvariant:1.5.0`, it was stucked: ; ```; 2023-06-04 16:15:06.784293: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; ```; and finally gave `ERRO[1898] error waiting for container: `; I stopped colima and rerun `docker run --platform linux/amd64 google/deepvariant:1.5.0`. it has been stuck like this for over 30 minutes with the same message:; ```; 2023-06-04 16:36:19.453896: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. ERRO[3173] error waiting for container:; ```; Do you have any suggestions?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575644623:820,Down,Downloaded,820,,https://github.com/google/deepvariant/issues/657#issuecomment-1575644623,3,"['Down', 'error']","['Downloaded', 'error']"
Availability,@pgrosu Thank you for the reply!; Using the commands:; ```; > rm .bazelrc; rm: cannot remove '.bazelrc': No such file or directory; > curl -L -O https://github.com/bazelbuild/bazel/releases/download/5.3.0/bazel-5.3.0-installer-linux-x86_64.sh; > chmod +x bazel-*.sh; chmod: changing permissions of 'bazel-5.3.0-installer-linux-x86_64.sh': Operation not permitted; > ./bazel-5.3.0-installer-linux-x86_64.sh --user > /dev/null; /home/user/bin/bazel: line 220: /home/user/.bazel/bin/bazel-real: cannot execute binary file: Exec format error; /home/user/bin/bazel: line 220: /home/user/.bazel/bin/bazel-real: Success; > sudo su; > rm .bazelrc; rm: cannot remove '.bazelrc': No such file or directory; > chmod +x bazel-*.sh; > ./bazel-5.3.0-installer-linux-x86_64.sh --user > /dev/null; > ./root/.bazel/bin/bazel; /root/.bazel/bin/bazel: line 220: /root/.bazel/bin/bazel-real: cannot execute binary file: Exec format error; /root/.bazel/bin/bazel: line 220: /root/.bazel/bin/bazel-real: Success; ```. so `./bazel-5.3.0-installer-linux-x86_64.sh --user > /dev/null` in root mode did not have any response.; But it seems that bazel is not installed properly.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577742056:190,down,download,190,,https://github.com/google/deepvariant/issues/657#issuecomment-1577742056,3,"['down', 'error']","['download', 'error']"
Availability,"@pgrosu Thank you for your guidance!!; So this is what I did for the sections you mentioned:; ```; # note_build_stage ""Install TensorFlow pip package"". # if [[ ""${DV_USE_PREINSTALLED_TF}"" = ""1"" ]]; then; # echo ""Skipping TensorFlow installation at user request; will use pre-installed TensorFlow.""; # else; # # Also pip install the latest TensorFlow with cpu support. We don't build the; # # full TF from source, but instead using prebuilt version. However, we still; # # need the full source version to build DeepVariant. # # Gets the nightly TF build: https://pypi.python.org/pypi/tf-nightly which is; # # necessary right now if we aren't pinning the TF source. We have observed; # # runtime failures if there's too much skew between the released TF package and; # # the source.; # if [[ ""${DV_TF_NIGHTLY_BUILD}"" = ""1"" ]]; then; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # echo ""Installing GPU-enabled TensorFlow nightly wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade tf_nightly_gpu; # else; # echo ""Installing CPU-only TensorFlow nightly wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade tf_nightly; # fi; # else; # # Use the official TF release pip package.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # echo ""Installing GPU-enabled TensorFlow ${DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION} wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade ""tensorflow-gpu==${DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION}""; # elif [[ ""${DV_USE_GCP_OPTIMIZED_TF_WHL}"" = ""1"" ]]; then; # echo ""Installing Intel's CPU-only MKL TensorFlow ${DV_GCP_OPTIMIZED_TF_WHL_VERSION} wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade ""intel-tensorflow==${DV_GCP_OPTIMIZED_TF_WHL_VERSION}""; # else; echo ""Installing standard CPU-only TensorFlow ${DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION} wheel""; pip3 install ""${PIP_ARGS[@]}"" --upgrade ""tensorflow==${DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION}""; # fi; # fi; # fi. # # A temporary fix.; # # Context: intel-tensorflow 2.7.0 will end up updating markupsafe to 2.1.1,; # # which caused the issue ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:206,echo,echo,206,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,8,"['echo', 'failure']","['echo', 'failures']"
Availability,"@pgrosu Thank you for your reply. This is the error (which started the whole troubleshooting):; ```; The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.; qemu: uncaught target signal 6 (Aborted) - core dumped; /opt/deepvariant/bin/run_deepvariant: line 2: 8 Aborted python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@""; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575575178:46,error,error,46,,https://github.com/google/deepvariant/issues/657#issuecomment-1575575178,2,"['avail', 'error']","['available', 'error']"
Availability,"@pgrosu The `tools/build_clif.sh` was successful!; Thank you!. After that I tried running this:; ```; > sudo docker run google/deepvariant:""${BIN_VERSION}""; WARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested; exec /opt/deepvariant/bin/run_deepvariant: exec format error; > sudo docker run --platform linux/amd64 google/deepvariant:""${BIN_VERSION}""; exec /opt/deepvariant/bin/run_deepvariant: exec format error; ```. Sorry, but what should I run before this?; Should I run the `./build-prereq.sh` and `./build_and_test.sh`?; Should I uncomment the `./run-prereq.sh` sections as well?. Actually, I am currently running the `./build-prereq.sh`:; ```; ========== This script is only maintained for Ubuntu 20.04.; ========== Load config settings.; ========== [Mon 05 Jun 2023 03:51:21 PM UTC] Stage 'Install the runtime packages' starting; ========== This script is only maintained for Ubuntu 20.04.; ========== Load config settings.; ========== [Mon 05 Jun 2023 03:51:21 PM UTC] Stage 'Misc setup' starting; ========== [Mon 05 Jun 2023 03:51:23 PM UTC] Stage 'Update package list' starting; ========== [Mon 05 Jun 2023 03:51:24 PM UTC] Stage 'run-prereq.sh: Install development packages' starting; Calling wait_for_dpkg_lock.; ========== [Mon 05 Jun 2023 03:51:24 PM UTC] Stage 'Install python3 packaging infrastructure' starting; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 100 2518k 100 2518k 0 0 8653k 0 --:--:-- --:--:-- --:--:-- 8623k; Collecting pip; Using cached pip-23.1.2-py3-none-any.whl (2.1 MB); Installing collected packages: pip; Attempting uninstall: pip; Found existing installation: pip 23.1.2; Uninstalling pip-23.1.2:; Successfully uninstalled pip-23.1.2; WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH.; Consider adding this directory to PATH or, if you prefer to suppress t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:365,error,error,365,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,4,['error'],['error']
Availability,"@pgrosu Wow! now I think it fixes it:; ```; > ./bazel-5.3.0-linux-arm64 ; WARNING: Invoking Bazel in batch mode since it is not invoked from within a workspace (below a directory having a WORKSPACE file).; Extracting Bazel installation...; [bazel release 5.3.0]; Usage: bazel <command> <options> ... Available commands:; analyze-profile Analyzes build profile data.; aquery Analyzes the given targets and queries the action graph.; build Builds the specified targets.; canonicalize-flags Canonicalizes a list of bazel options.; clean Removes output files and optionally stops the server.; coverage Generates code coverage report for specified test targets.; cquery Loads, analyzes, and queries the specified targets w/ configurations.; dump Dumps the internal state of the bazel server process.; fetch Fetches external repositories that are prerequisites to the targets.; help Prints help for commands, or the index.; info Displays runtime info about the bazel server.; license Prints the license of this software.; mobile-install Installs targets to mobile devices.; print_action Prints the command line args for compiling a file.; query Executes a dependency graph query.; run Runs the specified target.; shutdown Stops the bazel server.; sync Syncs all repositories specified in the workspace file; test Builds and runs the specified test targets.; version Prints version information for bazel. Getting more help:; bazel help <command>; Prints help and options for <command>.; bazel help startup_options; Options for the JVM hosting bazel.; bazel help target-syntax; Explains the syntax for specifying targets.; bazel help info-keys; Displays a list of keys used by the info command. ```. But the `bazel` command still returns:; ```; /root/.bazel/bin/bazel: line 220: /root/.bazel/bin/bazel-real: cannot execute binary file: Exec format error; /root/.bazel/bin/bazel: line 220: /root/.bazel/bin/bazel-real: Success; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577773461:300,Avail,Available,300,,https://github.com/google/deepvariant/issues/657#issuecomment-1577773461,2,"['Avail', 'error']","['Available', 'error']"
Availability,"@pichuan ; When I run echo, the output is empty. ; When I run; ```bash; ls ${INPUT_DIR}; ```; it shows a list of files of pwd, but not /data/deepvariant/test_bam/. If I run the script from /data/deepvariant directory, then it shows me files in /data/deepvariant, and if I run it from /data, then it shows me ls of /data",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/577#issuecomment-1284981058:22,echo,echo,22,,https://github.com/google/deepvariant/issues/577#issuecomment-1284981058,1,['echo'],['echo']
Availability,@pichuan @Roj4ck thanks for your quick reply. However the index is available in the same directory. I also tried removing it and recreating it with the samtools command. This didn't resolve the problem.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/310#issuecomment-637449360:67,avail,available,67,,https://github.com/google/deepvariant/issues/310#issuecomment-637449360,1,['avail'],['available']
Availability,"@pichuan Hi! When I downloaded all the pre-built binaries and run the run-prereq.sh scripts. How I suppose to run the make_example parallel?; I use the following command: ; seq 0 47 | parallel -q --halt 2 --line-buffer python3 make_examples.zip --mode calling --ref /data/input/human_g1k_v37.fasta --reads /data/input/c6c4c1db-4328-4aa9-b038-074c9a453117.dedup.bam --examples make_examples.tfrecord@12.gz. showing error:. E0430 18:57:45.160124 140015706085184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_9oblbsyi/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '33']"".; E0430 18:57:45.128387 140717112878912 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_gd9fj22_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '2']"".; E0430 18:57:45.149224 139802704738112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_2hbfxd92/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '16']"".; E0430 18:57:45.196900 140351706515264 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles__ytoy0a6/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '4']"".; E0430 18:57:45.304501 140371551012672 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_w7jwxlqo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '28']"".; E0430 18:57:45.337900 139621533210432 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Baz",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:20,down,downloaded,20,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,12,"['down', 'error', 'failure']","['downloaded', 'error', 'errors', 'failure']"
Availability,"@pichuan Thank for such a thorough description, really appreciate it. Super helpful to understand the different expectations and possible failure modes of each step. I will go back and make sure all of the preconditions you mentioned are met. One last comment though -- you didn't run call_variants on a GPU though it seems that is recommended; just makes it faster or is there any other reason to?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461416798:138,failure,failure,138,,https://github.com/google/deepvariant/issues/151#issuecomment-461416798,1,['failure'],['failure']
Availability,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/568#issuecomment-1251646879:788,error,error,788,,https://github.com/google/deepvariant/issues/568#issuecomment-1251646879,1,['error'],['error']
Availability,"@pichuan Thank you so much. I have no root in my local machine, so I start a deepvariant:1.5.0 docker container, and in this container, I git the source code and try to build it from source. The reason why I need to build it from source is that I want to change some source code of deepvariant(like pileup image code). ; I run the code:; ```; cd /root/clif/build; cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; ```; and the problem is also:; ```; -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```; I guess if I don't prebuilt protobuf before that? However, I found the build-prereq.sh have installed protobuf, I don't know the reason.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/739#issuecomment-1823759004:534,Error,Error,534,,https://github.com/google/deepvariant/issues/739#issuecomment-1823759004,1,['Error'],['Error']
Availability,"@pichuan That sounds reasonable, and I'm available if your team needs extra cycles with investigating this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/109#issuecomment-431180531:41,avail,available,41,,https://github.com/google/deepvariant/issues/109#issuecomment-431180531,1,['avail'],['available']
Availability,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks!. Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? ; ```; --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size; ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/568#issuecomment-1252420669:354,Avail,Available,354,,https://github.com/google/deepvariant/issues/568#issuecomment-1252420669,3,"['Avail', 'avail', 'checkpoint']","['Available', 'available', 'checkpoints']"
Availability,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error ; solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel; Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel; Reading package lists... Done; Building dependency tree ; Reading state information... Done; N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension; E: Unable to locate package bazel",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/89#issuecomment-415936477:101,error,error,101,,https://github.com/google/deepvariant/issues/89#issuecomment-415936477,2,['error'],['error']
Availability,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'; And i tried the installation and got this:; solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: ; ; ; From the log, it seems like the issue is that bazel was not installed.; After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits?; And, if install bazel failed for you, can you paste the part of log of how the installation failed for you?. By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/89#issuecomment-415936563:101,error,error,101,,https://github.com/google/deepvariant/issues/89#issuecomment-415936563,2,['error'],['error']
Availability,"@pichuan, I think it's only about the speed, yes. I can benchmark it on my end and let you know if there is any benefit to use thread. That's good idea to switch to 18.04! We can also perform switch to the latest version of OpenVINO (which was not available for 16.04):. ```; sudo curl -o GPG-PUB-KEY-INTEL-OPENVINO-2021 https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021; sudo apt-key add GPG-PUB-KEY-INTEL-OPENVINO-2021; sudo echo ""deb https://apt.repos.intel.com/openvino/2021 all main"" | sudo tee - a /etc/apt/sources.list.d/intel-openvino-2021.list; sudo apt-get update; sudo apt-get install -y --no-install-recommends intel-openvino-dev-ubuntu18-2021.1.110; sudo ln -s /opt/intel/openvino_2021 /opt/intel/openvino; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/393#issuecomment-742247654:248,avail,available,248,,https://github.com/google/deepvariant/pull/393#issuecomment-742247654,2,"['avail', 'echo']","['available', 'echo']"
Availability,"@pichuan, I'll take a look. Can you please refer what is a new checkpoint format? I've tried only checkpoints that were since r0.9.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735543558:63,checkpoint,checkpoint,63,,https://github.com/google/deepvariant/pull/363#issuecomment-735543558,2,['checkpoint'],"['checkpoint', 'checkpoints']"
Availability,"@poddarharsh15, can you please check if the files were downloaded correctly and if their sizes look good. The case studies are designed in a way that you can simply copy-paste the commands and it should work. I just tested the case study and it worked on my end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/853#issuecomment-2238236950:55,down,downloaded,55,,https://github.com/google/deepvariant/issues/853#issuecomment-2238236950,2,['down'],['downloaded']
Availability,"@ptrebert ; One clarifying question - Do you mean that you have multiple jobs that write to the same files at the same time, or multiple jobs that writes to different file names?. Previously, the issues was that if the user has some jobs they thought they killed (because they ctrl-c) but were still running in the background, this could cause the new jobs to write in the same files, and resulted in corrupted files. If they're with different names, I think it should be fine. If you're seeing errors with different names, I can give it a try and report back. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/175#issuecomment-560533134:495,error,errors,495,,https://github.com/google/deepvariant/issues/175#issuecomment-560533134,1,['error'],['errors']
Availability,"@ptrebert Thank you for reporting. ; Can you open another GitHub issue, with the command and full error (of the 2 jobs that failed), so we can help specifically with your issue?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/304#issuecomment-642781261:98,error,error,98,,https://github.com/google/deepvariant/issues/304#issuecomment-642781261,1,['error'],['error']
Availability,"@raphaelbetschart,. You can get exon information from the [GTF-formatted GENCODE files](https://www.gencodegenes.org/human/), which will label exon regions like this (including their start and end sites):. ```; chr1 HAVANA exon 12613 12721 . + . gene_id ""ENSG00000290825.1""; transcript_id ""ENST00000456328.2""; gene_type ""lncRNA""; gene_name ""DDX11L2""; transcript_type ""lncRNA""; transcript_name ""DDX11L2-202""; exon_number 2; exon_id ""ENSE00003582793.1""; level 2; transcript_support_level ""1""; tag ""basic""; tag ""Ensembl_canonical""; havana_transcript ""OTTHUMT00000362751.1"";; ```. With this you can determine where in the exon your variant falls in, and if it is near the end or beginning. I will focus on the high quality one variant, as the low quality one can be problematic. Skin tissue should be fine based on this figure: . ![image](https://github.com/google/deepvariant/assets/6555937/fc7823e6-de5f-46ea-80b9-59c5913d79de). The only other thing I can think of is that given that your number of reads is large, DeepVariant would downsample them before going into the model. So your supporting reads are picked by an allele counter, and it uses them to generate a matrix (image) that gets fed into the model generating the GT and GQ values. The height of these matrices is usually 100 rows. If it is greater it will randomly downsample from these reads, and usually use 95 of them as 5 are used for representing the reference sequence. I'm assuming you've updated the model as denoted in the tutorial and not used the regular WGS one. I know it's obvious, but as noted in the paper there is a difference between a RNA-seq model versus the WGS/WES one provided by DeepVariant. Other than that is there anything special around this site in IGV? Do you see this as a singular variant without anything surrounding it? Is there anything special of the sequences surrounding the variant (i.e. repeats/etc.)? Does it align uniquely or are there other alignments it can occur at? Do you see anything problema",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/701#issuecomment-1695957189:1034,down,downsample,1034,,https://github.com/google/deepvariant/issues/701#issuecomment-1695957189,1,['down'],['downsample']
Availability,"@richard-nm Can you paste your command too?. I wonder if you're using older code with newer models. In 1.3.0, we used to have this file that specifies the shape in 3 integers:. ```; $ gsutil cat gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.input_shape; 100 221 6; ```. In the later moment, we changed the format. For example, 1.4.0:. ```; $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json; {""version"": ""1.5.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}; ```; (We also added one more channel, which is why the shape is now 100 221 7.). From the error messages you're getting, it seems like you're using code version older than 1.4.0.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/627#issuecomment-1512358132:702,error,error,702,,https://github.com/google/deepvariant/issues/627#issuecomment-1512358132,1,['error'],['error']
Availability,"@saliksyed The real issue is that your BAM file does not contain those chromosomes/contigs as based on the reference file. That would probably will fix it. Sorry for the confusion, as the error was giving me a different signal. @nmousavi Not exactly, but I understand what's the trigger, and it probably would be helpful to provide more direct causes directly in the description of the events. The real thing that's happening here is that he doesn't have the right chromosome labels in his BAM files as compared to the reference genome, which misses all of them and triggers the error on the following lines of code:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L556-L561. The `Unrecognized SAM header type, ignoring:` is just the following warning-line of code that doesn't trigger the exit status of 1:. https://github.com/google/deepvariant/blob/aba55537eec832e6cea678349422124ef50680f4/third_party/nucleus/io/sam_reader.cc#L525. Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437207660:188,error,error,188,,https://github.com/google/deepvariant/issues/116#issuecomment-437207660,2,['error'],['error']
Availability,"@scott7z Is it possible to add an error message for this? Seems to be a common issue among users. @holgerbrandl as mentioned in #16, you can build the image from source that conforms to your environment. We prefer to provide 1 image with reasonable optimization settings. You may also consider using [Container-optimized OS](https://cloud.google.com/container-optimized-os/docs/) on Google Cloud to easily explore the tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/39#issuecomment-358337849:34,error,error,34,,https://github.com/google/deepvariant/issues/39#issuecomment-358337849,1,['error'],['error']
Availability,"@simoncchu can you provide more details: your singularity version and operating system version, the actual error message you're seeing, etc.; Anything that will help us reproduce or understand your issue will be helpful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/296#issuecomment-766990007:107,error,error,107,,https://github.com/google/deepvariant/issues/296#issuecomment-766990007,1,['error'],['error']
Availability,"@sivianil if the BAM file and reference FASTA files are publicly sharable as well, can you share them?; It'll be good if we can try to reproduce the error. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/606#issuecomment-1406491035:149,error,error,149,,https://github.com/google/deepvariant/issues/606#issuecomment-1406491035,1,['error'],['error']
Availability,@sivianil it looks to me like an issue with the location of your data. The error is saying that the reference file does not exist. Can you double check the following:. 1. Did you define `${INPUT_DIR}`?; 2. Do you have the `ucsc.hg19.chr20.unittest.fasta` in the input directory?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/593#issuecomment-1333821000:75,error,error,75,,https://github.com/google/deepvariant/issues/593#issuecomment-1333821000,1,['error'],['error']
Availability,"@solokopi since you're already on Ubuntu 16, you can also try using the binaries that we built.; You can just get it from this zip file:; https://github.com/google/deepvariant/releases/download/v0.7.0/deepvariant.zip; which has the binaries and the model files. You'll need to run `run-prereq.sh` first to set up your machine. But that will not require installing bazel.; Please let me know if that works for you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/89#issuecomment-416272658:185,down,download,185,,https://github.com/google/deepvariant/issues/89#issuecomment-416272658,1,['down'],['download']
Availability,"@sophienguyen01 , . If you are looking for INDEL purity then `--select_variant_types='indels'` should work well I believe? You are losing some INDELs but ultimately you are creating a training set that contains only INDELs. You can also generate more training samples by downsampling the bam and re-running `make_examples`. On the other hand, if you think about inference pipeline, when you are in prediction mode, you can't switch your `--select_variant_types` to something else than your training data as the model will now have to deal with data it has never seen before. There can be two scenarios:. 1) You train a model with `--select_variant_types='indels'` and after the model is trained, you are running inference with `--select_variant_types='indels multi-allelics'`. Then the model will have to deal with mult-allelic variants it has never seen before so the prediction on those would expected to be poor. 2) You train a model with `--select_variant_types='indels multi-allelics'` and allow a few snps to be present in the training. In which case during your inference or prediction, the model will be confident on all indel cases. It depends on what exactly you are trying to do, but, my suggestion would be to use `--select_variant_types='indels multi-allelics'` for your purpose.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/813#issuecomment-2091275266:271,down,downsampling,271,,https://github.com/google/deepvariant/issues/813#issuecomment-2091275266,1,['down'],['downsampling']
Availability,"@sophienguyen01 - from the log file it looks like everything worked. Here are all the tune/categorical accuracies from your training data. ```; tune/categorical_accuracy=0.9944317936897278; tune/categorical_accuracy=0.9909400343894958; tune/categorical_accuracy=0.9915463924407959; tune/categorical_accuracy=0.9925118088722229; tune/categorical_accuracy=0.9921825528144836; tune/categorical_accuracy=0.9924613237380981; tune/categorical_accuracy=0.9926846623420715; tune/categorical_accuracy=0.9929667711257935; tune/categorical_accuracy=0.9925829172134399; tune/categorical_accuracy=0.9926416277885437; tune/categorical_accuracy=0.9923893213272095; tune/categorical_accuracy=0.9925225377082825; ```. The first number represents accuracy direct from the pretrained model. Since none of the subsequent tuning evaluations outperformed the original, no checkpoints were created. One thing you could try: reduce the learning rate, and see if that helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2042819603:850,checkpoint,checkpoints,850,,https://github.com/google/deepvariant/issues/802#issuecomment-2042819603,2,['checkpoint'],['checkpoints']
Availability,"@sophienguyen01 can you try to run this again without using `--debug=true`? This runs tensorflow in eager mode which will be very inefficient. The other issue is that you don't have a checkpoint file because you didn't train long enough - and no checkpoint outperformed the existing performance on your tune dataset. Try re-running with `--debug=false` and `--config.num_epochs=10` and see where that gets you. If you get an OOM error with batch_size=512, reduce it and try again. If training produces a better model, it will be output in the `experiment_dir`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2033440565:184,checkpoint,checkpoint,184,,https://github.com/google/deepvariant/issues/802#issuecomment-2033440565,3,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"@sophienguyen01 the logs indicate checkpoints are output:. ```; I0423 18:41:59.026870 139913113728832 train.py:456] Saved checkpoint tune/f1_weighted=0.9114237 step=3352 epoch=1 path=model_train/checkpoints/ckpt-3352; I0423 18:44:53.215049 139913113728832 train.py:456] Saved checkpoint tune/f1_weighted=0.91949123 step=6704 epoch=2 path=model_train/checkpoints/ckpt-6704; I0423 18:47:47.292658 139913113728832 train.py:456] Saved checkpoint tune/f1_weighted=0.92320794 step=10056 epoch=3 path=model_train/checkpoints/ckpt-10056; ```. But as @kishwarshafin suggests, the warnings at the end are normal and can be ignored.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2073372104:34,checkpoint,checkpoints,34,,https://github.com/google/deepvariant/issues/802#issuecomment-2073372104,7,['checkpoint'],"['checkpoint', 'checkpoints']"
Availability,"@splaisan The intermediate directory is mainly used to generate and store [`TFRecord`](https://www.tensorflow.org/tutorials/load_data/tfrecord) files that are used among the `make_examples`, `call_variants` and `postprocess_variants` steps (performed by the `run_deepvariant` command above) to eventually generate the VCF and gVCF files used for downstream analysis. So you don't need them after a successfully completed DeepVariant run, as most folks are only interested in the resulting VCF and gVCF files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/296#issuecomment-1624413952:346,down,downstream,346,,https://github.com/google/deepvariant/issues/296#issuecomment-1624413952,1,['down'],['downstream']
Availability,"@ssm0808 ; Looking at the VCF file, it actually doesn't look like there are variants nearby. So it's not related to the issue I mentioned before.; If this data is sharable, it'll certainly be helpful if you can share the data (just chrX). An IGV screenshot at that location can also be helpful.; Otherwise, I'm not sure what's a best way that we can help diagnose this issue.; Let me know if you're able to provide more information. If not, I hope that one day our future model will be robust enough for your data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/109#issuecomment-436138293:486,robust,robust,486,,https://github.com/google/deepvariant/issues/109#issuecomment-436138293,1,['robust'],['robust']
Availability,"@sushruta the error mainly is here:. ```bash; ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100; ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/902#issuecomment-2453604525:14,error,error,14,,https://github.com/google/deepvariant/issues/902#issuecomment-2453604525,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"@wharvey31 when running `make_examples`, you'll need to add `--alt_aligned_pileup=diff_channels` for the PacBio model provided in v1.0.0. This will result in tf.Examples with two additional channels, so the shapes should match after that. If you did add this flag but are still seeing errors, please let me know, and I can help troubleshoot further. I would recommend using the `run_deepvariant` script when possible, as this will set various flags correctly for each model type (Illumina WGS, Illumina WES, PacBio, Hybrid). See [this quickstart doc](https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for an example of how to use this script through Docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/392#issuecomment-739048960:285,error,errors,285,,https://github.com/google/deepvariant/issues/392#issuecomment-739048960,1,['error'],['errors']
Availability,@williambrandler can you provide more detail regarding what you are trying to do?. Have you modified the existing dockerfile to replace the base image with the Databricks runtime image?. The error appears to indicate that the `apt` package manager is not available in the Databricks runtime image.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/476#issuecomment-894671300:191,error,error,191,,https://github.com/google/deepvariant/issues/476#issuecomment-894671300,2,"['avail', 'error']","['available', 'error']"
Availability,@yangyxt how much memory do you have available on this machine? Is it possible to increase the amount of memory?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/646#issuecomment-1546431553:37,avail,available,37,,https://github.com/google/deepvariant/issues/646#issuecomment-1546431553,1,['avail'],['available']
Availability,"@yangyxt was this resolved?; From the original error message, it seems to me that the input to call_variants was truncated. Which means that your make_examples run might have not been fully succeeded. Another possible issue is: If you happen to have multiple make_examples running and overwriting the same files, you also might have corrupted output from make_examples (which will cause the call_variants step to err out.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/564#issuecomment-1251331616:47,error,error,47,,https://github.com/google/deepvariant/issues/564#issuecomment-1251331616,1,['error'],['error']
Availability,"@zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/859#issuecomment-2271704593:66,error,errors,66,,https://github.com/google/deepvariant/issues/859#issuecomment-2271704593,2,['error'],"['error', 'errors']"
Availability,"@ziphra ,. Reads without any quality score provided to DeepVariant would cause this issue. One thing you can quickly see from your `samtools view` output is the flag of this read is `0x16`, you can go to this website: https://broadinstitute.github.io/picard/explain-flags.html and put in `0x16` and it'd say the read is unmapped. . A quick way to remove any improper reads would be to run this:; ```; INPUT_BAM=/path/to/input.bam; OUTPUT_BAM=/path/to/input.F0x904.bam; samtools view -@42 -F 0x904 ${INPUT_BAM} > ${OUTPUT_BAM}; ```; This will remove all non-primary reads and should get rid of the errors for you. You can put `0x904` on the explain-flags website to see which reads you will only keep.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/539#issuecomment-1139723040:597,error,errors,597,,https://github.com/google/deepvariant/issues/539#issuecomment-1139723040,1,['error'],['errors']
Availability,"@zivlang ,. The error says: `ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram`. Can you please do `ls /input/1115492_23181_0_0.cram` and see if the file exists in this file path?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/588#issuecomment-1321390027:16,error,error,16,,https://github.com/google/deepvariant/issues/588#issuecomment-1321390027,1,['error'],['error']
Availability,"@zyxue Fantastic! Feel free to ping us if you run into any other issues :). Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/99#issuecomment-428382405:31,ping,ping,31,,https://github.com/google/deepvariant/issues/99#issuecomment-428382405,1,['ping'],['ping']
Availability,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:; https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```; if (c->mtid < -1); return tf::errors::DataLoss(; ""Expected mtid >= 0 as mate is supposedly mapped: "",; read_message->ShortDebugString());; else if (c->mtid == -1) {; mate_position->set_reference_name(""*"");; } else {; mate_position->set_reference_name(h->target_name[c->mtid]);; }; mate_position->set_position(c->mpos);; mate_position->set_reverse_strand(bam_is_mrev(b));; ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/99#issuecomment-427462549:62,avail,available,62,,https://github.com/google/deepvariant/issues/99#issuecomment-427462549,2,"['avail', 'error']","['available', 'errors']"
Availability,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python; if options.n_cores != 1:; errors.log_and_raise(; 'Currently only supports n_cores == 1 but got {}.'.format(; options.n_cores), errors.CommandLineError); ```. Though there are possibilities around that like @pichuan mentioned. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/99#issuecomment-428686329:902,error,errors,902,,https://github.com/google/deepvariant/issues/99#issuecomment-428686329,2,['error'],['errors']
Availability,"A conda package for DeepVariant is now available through bioconda so you should be able to install with:; ```; conda install -c conda-forge -c bioconda deepvariant; ```; It includes wrapper scripts for each of the 3 steps (`dv_make_examples.py`, `dv_call_variants.py`, `dv_postprocess_variants.py`) that handle wrapping the internal locations of the pre-built zip files and models, so you can call these as normal command line options. These don't yet expose all options available in DeepVariant but are hopefully sufficient to run standard germline calling projects. I've also started a separate issue (#29) to discuss improvements we can make to improve portability, but hope the initial package helps for installing and using DeepVariant. I'd be happy for feedback and suggestions on this package as folks have a chance to use it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/9#issuecomment-354748344:39,avail,available,39,,https://github.com/google/deepvariant/issues/9#issuecomment-354748344,4,['avail'],['available']
Availability,A final update. We've just improved the error messages for these cases in the internal version. The next release of DeepVariant should have this fix.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/28#issuecomment-354390647:40,error,error,40,,https://github.com/google/deepvariant/issues/28#issuecomment-354390647,1,['error'],['error']
Availability,"A summary of last trials:; 1. Downloaded fasta file again from repository (since it had an error with chr1:4655405-4655474); 2. Ran again the WES run with the original files ; 3. Got again the ""parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --regions /input/idt_capture_novogene.grch38.bed --task 3"" Error without the more informative error message.; 4. Ran again the command without num shards flag:; BIN_VERSION=""1.2.0"". ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/output"":""/output"" \; -v ""${PWD}/reference"":""/reference"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref /reference/GRCh38_no_alt_analysis_set.fasta \; --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions /input/idt_capture_novogene.grch38.bed \; --output_vcf /output/HG003.output.vcf.gz \; --output_gvcf /output/HG003.output.g.vcf.gz \; --intermediate_results_dir /output/intermediate_results_dir; ```; 5. It ran and created only three intermediate files: call_variants_output.tfrecord, gvcf.tfrecord-00000-of-00001.gz, make_examples.tfrecord-00000-of-00001.gz without any Error message. I'm copying the last lines here:. ```; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; warnings.warn('`layer.apply` is deprecated and '; INFO:tensorflow:Done calling model_fn.; I0911 15:27:04.863512 139825053296448 estimator.py:1164] Done calling model_fn.; INFO:tensorflow:Graph was finalized.; I0911 15:27:05.510090 139825053296448 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/483#issuecomment-917442547:30,Down,Downloaded,30,,https://github.com/google/deepvariant/issues/483#issuecomment-917442547,4,"['Down', 'Error', 'error']","['Downloaded', 'Error', 'error']"
Availability,"A"". # # See https://www.tensorflow.org/install/source#gpu for versions required.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # if [[ ""${DV_INSTALL_GPU_DRIVERS}"" = ""1"" ]]; then; # # This script is only maintained for Ubuntu 20.04.; # UBUNTU_VERSION=""2004""; # # https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_local; # echo ""Checking for CUDA...""; # if ! dpkg-query -W cuda-11-3; then; # echo ""Installing CUDA...""; # UBUNTU_VERSION=""2004""; # curl -O https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin; # sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600; # # From https://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212772; # sudo -H apt-key adv --fetch-keys ""http://developer.download.nvidia.com/compute/cuda/repos/ubuntu${UBUNTU_VERSION}/x86_64/3bf863cc.pub""; # sudo add-apt-repository -y ""deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /""; # sudo -H apt-get update ""${APT_ARGS[@]}""; # # From: https://superuser.com/a/1638789; # sudo -H DEBIAN_FRONTEND=noninteractive apt-get \; # -o Dpkg::Options::=--force-confold \; # -o Dpkg::Options::=--force-confdef \; # -y --allow-downgrades --allow-remove-essential --allow-change-held-packages \; # full-upgrade; # sudo -H apt-get install ""${APT_ARGS[@]}"" cuda-11-3; # fi; # echo ""Checking for CUDNN...""; # if [[ ! -e /usr/local/cuda-11/include/cudnn.h ]]; then; # echo ""Installing CUDNN...""; # CUDNN_TAR_FILE=""cudnn-11.3-linux-x64-v8.2.0.53.tgz""; # wget -q https://developer.download.nvidia.com/compute/redist/cudnn/v8.2.0/${CUDNN_TAR_FILE}; # tar -xzvf ${CUDNN_TAR_FILE}; # sudo cp -P cuda/include/cudnn.h /usr/local/cuda-11/include; # sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-11/lib64/; # sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-11/lib64/; # sudo chmod a+r /usr/local/cuda-11/lib64/libcudnn*; # sudo ldconfig; # fi; # # Ten",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:3517,down,download,3517,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,2,['down'],['download']
Availability,"ARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; Python 3.8.10; pip 23.1.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); ========== [Sun 04 Jun 2023 11:11:13 PM UTC] Stage 'Install python3 packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; ========== [Sun 04 Jun 2023 11:11:24 PM UTC] Stage 'Install TensorFlow pip package' starting; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; werkzeug 2.3.4 requires MarkupSafe>=2.1.1, but you have markupsafe 2.0.1 which is incompatible.; ========== [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install CUDA' starting; ========== [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install TensorRT'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276:2685,ERROR,ERROR,2685,,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276,1,['ERROR'],['ERROR']
Availability,"Actually I have a suggestion:; Can you directly run the failed command. `./opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`. Without using the one-step run_deeptrio. I now remember that the way I wrote that script can make the underlying error unclear, and as a result hard to debug when an error occurs. If you directly run the failed job, you should get more helpful error message. Sorry for the inconvenience. I believe I improved that for run_deepvariant.py a while ago but haven't done the same for run_deeptrio.py.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/646#issuecomment-1547153842:984,error,error,984,,https://github.com/google/deepvariant/issues/646#issuecomment-1547153842,3,['error'],['error']
Availability,"Actually those messages might not be a warning, ""The above is not a warning and is just a point of information.""; https://discuss.tensorflow.org/t/tensorflow-with-proper-compiler-flag-error-message/12393/3. Now I will try with the test quickstart run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575652409:184,error,error-message,184,,https://github.com/google/deepvariant/issues/657#issuecomment-1575652409,1,['error'],['error-message']
Availability,"Actually, when I took a closer look at the logs, it says:. ```; 2023-03-16 05:35:30.141288: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; 2023-03-16 05:35:30.141355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: pichuan-gpu2; 2023-03-16 05:35:30.141366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: pichuan-gpu2; 2023-03-16 05:35:30.141423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; 2023-03-16 05:35:30.141471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 530.30.2; ```. So it seems like I'm able to reproduce this issue. . Let me take a closer look. I'll also want to test this on Ubuntu. I tested before release, but I'll want to test it again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471376570:210,error,error,210,,https://github.com/google/deepvariant/issues/619#issuecomment-1471376570,1,['error'],['error']
Availability,"After searching the error in our GitHub repo, it seems like https://github.com/google/deepvariant/issues/746 and https://github.com/google/deepvariant/issues/640 can be relevant. @malonzm1 you can check your numpy version, and see if you can update it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/782#issuecomment-1990498159:20,error,error,20,,https://github.com/google/deepvariant/issues/782#issuecomment-1990498159,1,['error'],['error']
Availability,"After taking a look at your error, it might also be a different problem. You might want to see what came out from you `get_int64_list(example, 'label')`. Is it possible that your example don't have a `'label'`? If you created your examples with `calling` mode in `make_examples`, they probably don't have a label, and might have resulted in that error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/110#issuecomment-432092602:28,error,error,28,,https://github.com/google/deepvariant/issues/110#issuecomment-432092602,2,['error'],['error']
Availability,"After trying to install a few things that I failed to install before, linking a few paths, I got to this error that concerns me:; ```; ImportError: /lib64/libc.so.6: version `GLIBC_2.17' not found (required by /usr/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so); ```. It's possible that TensorFlow itself requires a newer version of GLIBC than what's on CentOS 6.; I did some search and found some old thread that could be relevant:; https://github.com/tensorflow/tensorflow/issues/527. @chapmanb Is it possible at all to install this on a different OS? This is getting to a point that I'm worried I'm going down a path with no good ending in sight..",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386517018:105,error,error,105,,https://github.com/google/deepvariant/issues/29#issuecomment-386517018,2,"['down', 'error']","['down', 'error']"
Availability,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it?. This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-457987076:309,error,error,309,,https://github.com/google/deepvariant/issues/132#issuecomment-457987076,1,['error'],['error']
Availability,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```; sudo sh run_deepvariant.sh; Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally; latest: Pulling from deepvariant-docker/deepvariant; 18d680d61657: Pull complete; 0addb6fece63: Pull complete; 78e58219b215: Pull complete; eb6959a66df2: Pull complete; 54de1d38bbd7: Pull complete; d17c3563217d: Pull complete; ba1bdbdefce9: Pull complete; 94eba53c4ad9: Pull complete; 413f494b0501: Pull complete; 4d89363e7fb4: Pull complete; e9213d1ccf36: Pull complete; fb6121657d6b: Pull complete; Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f; Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest; docker images; terminate called after throwing an instance of 'std::bad_alloc'; what(): std::bad_alloc; ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480642492:409,down,down,409,,https://github.com/google/deepvariant/issues/167#issuecomment-480642492,3,"['down', 'error']","['down', 'error']"
Availability,"Also, when we tried to run `call_varaints.zip` with a training checkpoint we just found earlier, it failed with this exception below. We are not entirely sure what we did wrong. We just used your command to train and the command in the case study to run the model to produce variants; ```; root@qiuz-deepvariant-quickstart:~/case-study/output/logs# cat call_variants.log; WARNING: Logging before flag parsing goes to stderr.; I0209 02:46:47.705486 139970286499584 htslib_gcp_oauth.py:82] GCP credentials found; will be able to access non-public gs:// URIs from htslib; 2018-02-09 02:46:50.318843: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA; I0209 02:46:51.237144 139970286499584 call_variants.py:325] Initializing model from /root/case-study/output/model.ckpt; 2018-02-09 02:46:51.248949: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /root/case-study/output/model.ckpt: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_lnD8hJ/runfiles/genomics/deepvariant/call_variants.py"", line 387, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run; _sys.exit(main(_sys.argv[:1] + flags_passthrough)); File ""/tmp/Bazel.runfiles_lnD8hJ/runfiles/genomics/deepvariant/call_variants.py"", line 378, in main; batch_size=FLAGS.batch_size); File ""/tmp/Bazel.runfiles_lnD8hJ/runfiles/genomics/deepvariant/call_variants.py"", line 326, in call_variants; model.initialize_from_checkpoint(checkpoint_path, 3, False)(sess); File ""/tmp/Bazel.runfiles_lnD8hJ/runfiles/genomics/deepvariant/modeling.py"", line 298, in initialize_from_checkpoint; [self.n_classes_model_variable]); File ""/tmp/Bazel.runfiles_lnD8hJ/runfiles/genomics/deepvariant/tf_utils.py"", line 264, in model_sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/46#issuecomment-364502198:63,checkpoint,checkpoint,63,,https://github.com/google/deepvariant/issues/46#issuecomment-364502198,1,['checkpoint'],['checkpoint']
Availability,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```; terminate called after throwing an instance of 'std::system_error'; what(): Resource temporarily unavailable; ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-482393946:133,error,error,133,,https://github.com/google/deepvariant/issues/167#issuecomment-482393946,6,['error'],['error']
Availability,"Alternatively, you can use [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant). It will run all 3 stages and final VCF file will be available at the output bucket. Note that if you want gVCF output you need to also set the [corresponding flag](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration). Similarly if your index files does not follow standard naming convention (such as `.bam.bai`) you need to set them using their flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/222#issuecomment-534797540:179,avail,available,179,,https://github.com/google/deepvariant/issues/222#issuecomment-534797540,1,['avail'],['available']
Availability,"And @melop , the most recent time I tried to set up a GPU machine was using these steps:. https://github.com/google/deepvariant/issues/745#issuecomment-1840177389. I don't think I've seen the `failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected` error message you saw. Based on that error message I did a bit internet search. I wonder if this is relevant: https://stackoverflow.com/a/48715413 Specifically , try setting CUDA_VISIBLE_DEVICES to 0, by running `export CUDA_VISIBLE_DEVICES=0` and see if that works for you?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/761#issuecomment-1890184989:274,error,error,274,,https://github.com/google/deepvariant/issues/761#issuecomment-1890184989,2,['error'],['error']
Availability,"And, another thing I did is build bazel 0.11.0 with the older GLIBC. On my CentOS 6 GCE instance:; ```; $ ldd --version; ldd (GNU libc) 2.12; Copyright (C) 2010 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; Written by Roland McGrath and Ulrich Drepper.; ```. I basically followed https://gist.github.com/truatpasteurdotfr/d541cd279b9f7bf38ce967aa3743dfcb , but use bazel version 0.11.0 instead.; And in the `echo 'cd /tmp/bazel-0.4.5-dist && bash ./compile.sh && cp output/bazel /usr/local/bin' | scl enable devtoolset-3 bash` command I had to add `sudo` to the cp command. After this, I have a bazel 0.11.0:; ```; $ /usr/local/bin/bazel version; Extracting Bazel installation...; Build label: 0.11.0- (@non-git); Build target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar; Build time: Wed Nov 5 12:47:48 +50302 (1525237217268); Build timestamp: 1525237217268; Build timestamp as int: 1525237217268; ```. I haven't tried building with it, though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-385868054:546,echo,echo,546,,https://github.com/google/deepvariant/issues/29#issuecomment-385868054,1,['echo'],['echo']
Availability,"Andrea;; Thanks for following up and for all the additional details. It's a bit strange, as all the file paths in your error messages look like it got installed under python 3.6 rather than 2.7. It's hard to tell if that's just coming from the conda machinery or indicative of a different problem. . You could try installing in a separate environment as a first pass to avoid any conflicts:; ```; conda create -y -n deepvariant python=2.7 -c bioconda -c conda-forge deepvariant 'google-cloud-sdk<243.0.0'; ```; If that still has the same issue, then we'd need to dig more into the `post-link.sh` errors you're seeing. In this step deepvariant is downloading the trained model files from GCP, which can sometimes have internet issues or other problems. This previous post has some suggestions for debugging it:. https://github.com/google/deepvariant/issues/177#issuecomment-504940567. Hope this helps get it resolved and get deepvariant running for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/252#issuecomment-566496481:119,error,error,119,,https://github.com/google/deepvariant/issues/252#issuecomment-566496481,3,"['down', 'error']","['downloading', 'error', 'errors']"
Availability,Anna;; Apologies about the issues. If you also include the conda-forge channel in your install it should resolve cleanly:; ```; conda create -n deepvariant -c conda-forge -c bioconda python=2.7 deepvariant; ```; bioconda is heavily dependent on conda-forge packages so you'll want to include that whenever installing anything from bioconda to ensure all the dependencies are available. Hope this helps get it running for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/177#issuecomment-584441591:375,avail,available,375,,https://github.com/google/deepvariant/issues/177#issuecomment-584441591,1,['avail'],['available']
Availability,"Another test-; I've ran the WES exactly like it is with your test files (fasta bam and bed) and again I get this same error: ; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --regions /input/idt_capture_novogene.grch38.bed --task 3. In this example it also not working for a specific region ""chr20:10000000-10010000"" (some intermediate files are created but not the vcf file). The Error:; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --regions chr20:10000000-10010000 --task 0; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --regions chr20:10000000-10010000 --task 1; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --regions chr20:10000000-10010000 --task 2; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_res",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/483#issuecomment-917342943:118,error,error,118,,https://github.com/google/deepvariant/issues/483#issuecomment-917342943,2,"['Error', 'error']","['Error', 'error']"
Availability,"Apologies for no/late response. And Thank You for following-up. . My issue was : the failure to do ""docker build"" after git clone of the repo. . However, I am successful in getting the 0.8 docker image --> install the SW pre-reqs to recompile binaries inside docker --> export to new image for future use. . This issue should be closed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/342#issuecomment-696223840:85,failure,failure,85,,https://github.com/google/deepvariant/issues/342#issuecomment-696223840,1,['failure'],['failure']
Availability,"Apologies in advance for inviting myself into the conversation. I think it's worth mentioning that while there are merits to doing MNV calling, the use-case given (calling amino acid variation from SNPs) isn't the greatest. There's no guarantee that codons occur as triplets in the genome (though they tend to, they can also get split across exons). which suggests that MNV calling doesn't actually solve the problem in general. Phase-aware consequence predictors (bcftools csq) should, on the other hand, work just fine (neglecting phasing errors of course). FWIW, we use the following pipeline: deepvariant or gatk4 -> whatshap -> shapeit4 -> bcftools csq to predict protein polymorphisms (or really, whole proteomes from whole genomes) and that approach should work in this case too. To be clear, having MNV calling would make an excellent addition to DeepVariant, it just may not be a total solution to the problem posed.; -August",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/486#issuecomment-984133927:541,error,errors,541,,https://github.com/google/deepvariant/issues/486#issuecomment-984133927,2,['error'],['errors']
Availability,"Are you following the configurations as recommended on the following page, and specifying the number of workers as well?. https://cloud.google.com/genomics/docs/tutorials/deepvariant#pipeline_configurations. If so, then it will build the Pipelines API configs, which basically makes custom machines of this form:. ```; machine_type = 'custom-{0}-{1}'.format(; pipeline_args.make_examples_cores_per_worker,; pipeline_args.make_examples_ram_per_worker_gb * 1024); ```. Ref: https://github.com/google/deepvariant/blob/r0.7/deepvariant/docker/gcp_deepvariant_runner.py#L305-L307. Also I believe that `make_examples` is restricted to one core based on this:. ```; if options.n_cores != 1:; errors.log_and_raise(; 'Currently only supports n_cores == 1 but got {}.'.format(; options.n_cores), errors.CommandLineError); ```. Ref: https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1167-L1170. In any case, it will some time to explain the complete control flow, and if you look at the following two files I think you'll discover why based on the design of DeepVariant:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py. https://github.com/google/deepvariant/blob/r0.7/deepvariant/docker/gcp_deepvariant_runner.py. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/150#issuecomment-460850032:685,error,errors,685,,https://github.com/google/deepvariant/issues/150#issuecomment-460850032,2,['error'],['errors']
Availability,"As @AndrewCarroll said, we need workers log to investigate the failure. Please share workers log (you should be able to find them under `gs://canis/CNR-data/deep_variant_files/logs`).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437076116:63,failure,failure,63,,https://github.com/google/deepvariant/issues/116#issuecomment-437076116,1,['failure'],['failure']
Availability,"As these are sorted reads, by just looking at the BAM file, it starts with position 60001, as shown here - which why you are getting 0 candidates:. ```; 55ad4f97_28026_0 0 chr20 60001 50 618S27M1D8M1I6M1D7M1D5M1I9M1I5M1D20M1D8M1I24M1I35M1I9M1I2M1I1M1I52M1D3M1D15M2D4M2D12M1I21M1I5M1; D11M1D7M1I18M1I15M1D1M1D43M1I16M1D8M1I21M1D2M1D7M1I10M1I2M1D8M1D5M1D3M1D2M1I13M1D28M1I20M1I4M1I37M1I19M1I21M1D18M1I5M1D16M1I1M1I3M1I29M1I12M1D6M1I2M1I7; M1D1M1D2M1I4M1D22M1D18M1I4M1D12M1D4M1I1M1I3M2I17M1I1M1I44M1D3M1D2M1D10M1I11M2D1M1D9M1I19M1D2M1I32M1D2M1D8M1D20M1I14M1D6M1D15M1I7M1D3M1D25M1I6M1I8M1D11M; 1I7M1I11M1I12M1D2M1D3M1I70M1I23M1D3M1I48M1I21M1I46M1D14M1I3M1D10M1I6M1D34M2I8M1I11M1I5M1I10M1D8M1I8M1I14M1D19M1I26M1I6M1I13M1D4M1I2M1I33M1I8M1I7M1I12M1I1M1I4M1I8M1I3M1I1M1I3M2I4M1I14M1I1M1I5M1I1M1I1M1I2M2I2M1I3M1I1M4I3M1I1M1I1M2I3M4I5M1I3M1I1M1I3M3I5M1I6M1I2M1I1M2I1M1I7M1I3M2I3M1I5M2I1M2I4M1I1M1I2M1D4M1I6M1I3M1I2M1I1M4I1M1I1M2I5M1I3M1I3M1I2M1D1M1I2M2I1M1I1M1I4M3I1M2I2M1I6M1I4M3I1M3I1M3I8M2I47M1I11M1I8M1D3M1I1M1I30M1I15M1I6M1I17M1D18M1D4M1I19M1I28M1D37M1I23M1D7M1D21M1D79M1I12M1D1M1D9M1I21M1D44M1D30M1D3M1I13M1I9M1I34M1D10M1I; ```; Since no PHRED value is stored with a `*`, as shown here:. ```; AGTCTGCTTCATGCCTTTAACT * AS:i:-15583 ; ```; This is why the read triggers the assertion failure [here](https://github.com/google/deepvariant/blob/master/deepvariant/allelecounter.cc#L103):. ```C++; CHECK_LE(offset + len, read.aligned_quality_size());; ```. The preferred response that would be nice, is if the code could just identify which read (QNAME) it is referring to in order to verify this, or just have a flag to ignore reads that one has no QUAL score for. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-457426984:1277,failure,failure,1277,,https://github.com/google/deepvariant/issues/138#issuecomment-457426984,1,['failure'],['failure']
Availability,"BIN_PATH=""$HOMEPATH/inst/bin/python""; bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package; bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install; pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification; python -c ""import tensorflow as tf; print(tf.__version__)""; ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/google/clif). ```bash; # Prerequisites; cmake --version #3.5+; protoc --version # 3.2.0+ build from source code for both C++ and Python; pip install virtualenv; pip install pyparsing; yum install subversion; yum install ocaml; pip install 'pyparsing>=2.2.0'; pkg-config --libs python # workable. # download source code; cd $HOMEPATH; git clone https://github.com/google/clif.git; cd clif. # set environment; export INSTALL_DIR=""$HOMEPATH/inst""; export CLIFSRC_DIR=""$HOMEPATH/clif""; export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend""; export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python""; export PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages""; export PROTOC_PREFIX_PATH=""$(dirname ""$(dirname ""$(which protoc)"")"")"". export CLIF_VIRTUALENV=""$INSTALL_DIR""/clif; export CLIF_PIP=""$CLIF_VIRTUALENV/bin/pip"". virtualenv -p ""$PYTHON_BIN_PATH"" ""$CLIF_VIRTUALENV"". $CLIF_PIP install --upgrade pip; $CLIF_PIP install --upgrade setuptools. # Checkout LLVM and Clang source trees; mkdir -p $LLVM_DIR; cd $LLVM_DIR; svn co https://llvm.org/svn/llvm-project/llvm/trunk@307315 llvm; cd llvm/tools; svn co https://llvm.org/svn/llvm-project/cfe/trunk@307315 clang; ln -s -f -n $CLIFSRC_DIR/clif clif. # Builds must be done outside of the LLVM tree.; mkdir -p $BUILD_DIR; cd $BUILD_DIR; # Note ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:12385,down,download,12385,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['down'],['download']
Availability,Björn -- I'm agreed. I tried to look into building clif but it was too intense (https://github.com/google/clif#building) and had to give up. Right now the pre-built version assumes unpacking into `/usr` so is also not an option for a conda package. If you have time to investigate and think you can tackle that would be great. I've already gotten bazel up to date so should be able to try building with clif available.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-355455875:408,avail,available,408,,https://github.com/google/deepvariant/issues/29#issuecomment-355455875,1,['avail'],['available']
Availability,"CP cloud-orchestration framework developed external to our team. The speed-optimized one here is 70 min. However, as there are now multiple orchestration options (including Parabricks and ATGENOMIX) we have decided to separate the single-machine runtime from what can be achieved with orchestration. I understand you are running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware?. 1b); With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests?. The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\); Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your scrip",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483448362:1539,down,downloads,1539,,https://github.com/google/deepvariant/issues/171#issuecomment-483448362,1,['down'],['downloads']
Availability,"CP_OPTIMIZED_TF_WHL_FILENAME; +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME; ; # Set this to 1 to make our prereq scripts install the CUDA libraries.; # If you already have CUDA installed, such as on a properly provisioned; # Docker image, it shouldn't be necessary.; export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}""; ; -export PYTHON_VERSION=3.8; +export PYTHON_VERSION=3.9; # shellcheck disable=SC2155; export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})""; export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages""; @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1; # --experimental_build_setting_api""; # Presumably it won't be needed at some later point when bazel_skylib is; # upgraded again.; -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11""; +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11""; ; function note_build_stage {; echo ""========== [$(date)] Stage '${1}' starting""; ```; ```; diff --git a/build-prereq.sh b/build-prereq.sh; index ad34e285..1fc2d203 100755; --- a/build-prereq.sh; +++ b/build-prereq.sh; @@ -41,7 +41,7 @@ source settings.sh; ; note_build_stage ""Install the runtime packages""; ; -./run-prereq.sh; +#./run-prereq.sh; ; note_build_stage ""Update package list""; ; @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {; then; echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling""; else; - pushd ~/bazel; - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh; - chmod +x bazel-*.sh; - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null; - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh; -",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217:2132,echo,echo,2132,,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217,1,['echo'],['echo']
Availability,"CUDA 8.0, cudnn 6, and tensorflow-gpu 1.4. I ran the WES example. That went fine. Questions: what is the minimum allele frequency deepvariant will call? Is there a version contemplated that will do matched tumor/normal pairs? Unmatched pairs (as with a “pooled” normal)?. Thanks,; Brad Thomas. From: Ryan Poplin [mailto:notifications@github.com]; Sent: Monday, February 5, 2018 5:10 PM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [External]Re: [google/deepvariant] Build and test works, binaries do not (#47). Unfortunately DeepVariant isn't yet compatible with TensorFlow version 1.5 so I think you'll need to install tensorflow-gpu version 1.4 for this to work. In our build script we do this with; sudo -H pip install --upgrade 'tensorflow-gpu==1.4'. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/47#issuecomment-363252951>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqcP3vxIqOIV_Q6VUU-5cueBwPpQiks5tR4plgaJpZM4R5yAT>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/47#issuecomment-364172639:1596,error,error-free,1596,,https://github.com/google/deepvariant/issues/47#issuecomment-364172639,2,['error'],"['error-free', 'errors']"
Availability,"Can you ; ```; echo ${INPUT_DIR}; ```; to confirm that the value is what you expected?; And, just to be sure:; ```; ls ${INPUT_DIR}; ```; to make sure there are files there?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/577#issuecomment-1284961760:15,echo,echo,15,,https://github.com/google/deepvariant/issues/577#issuecomment-1284961760,1,['echo'],['echo']
Availability,Can you check if you have `example_info.json` output in your training data and validation data generation folders and if they are the same? If same then you can copy it to the directory and use it. The training loop is supposed to copy the `example_info.json` from training folder to the checkpoint output directory. Not sure if it was missing in your setup.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/869#issuecomment-2313193016:288,checkpoint,checkpoint,288,,https://github.com/google/deepvariant/issues/869#issuecomment-2313193016,1,['checkpoint'],['checkpoint']
Availability,"Can you check whether you're able to pull other public images on this machine?. From the error above it seems to have an ""Authentication error"", which doesn't quite make sense to me because our Docker hub image should be public. I just tried:; ```; singularity pull docker://google/deepvariant:""1.3.0""; ```; as a sanity check. I confirmed it worked for me (so at least hopefully there isn't an obvious mistake here on permission)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/513#issuecomment-1027495489:89,error,error,89,,https://github.com/google/deepvariant/issues/513#issuecomment-1027495489,2,['error'],['error']
Availability,"Can you provide the updated command you used?; The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash; sudo docker run \; -v ""$(pwd):$(pwd)"" \; -w $(pwd) \; google/deepvariant:""${BIN_VERSION}"" \; /bin/bash; ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1303540940:51,error,error,51,,https://github.com/google/deepvariant/issues/581#issuecomment-1303540940,1,['error'],['error']
Availability,Can you share the error message? Also cc'ing @kishwarshafin who might be better able to help with the PEPPER step.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/497#issuecomment-992114837:18,error,error,18,,https://github.com/google/deepvariant/issues/497#issuecomment-992114837,1,['error'],['error']
Availability,"Command that works, but runs out of memory is this:. ```; python $SCRIPTPATH/shuffle_tfrecords_beam.py \; --input_pattern_list=$INPUT_PATTERN \; --output_pattern_prefix=$OUTPUT_PREFIX \; --output_dataset_config_pbtxt=$OUTPUT_DATASET_CONFIG_PBTXT \; --output_dataset_name=$OUTPUT_DATASET_NAME; ```. Command that doesn't run and gives error:; ```; python $SCRIPTPATH/shuffle_tfrecords_beam.py \; --input_pattern_list=$INPUT_PATTERN \; --output_pattern_prefix=$OUTPUT_PREFIX \; --output_dataset_config_pbtxt=$OUTPUT_DATASET_CONFIG_PBTXT \; --output_dataset_name=$OUTPUT_DATASET_NAME \; --job_name=$JOBNAME \; --project=$PROJECT_NAME \; --temp_location=$TEMPLOCATION \; --save_main_session \; --region us-east1; ```. Obtained error: ```Invalid GCS path (<PATH>), given for the option: temp_location```. I also tried the SparkRunner which works, but which runs into the same issue of memory. It seems DirectRunner and SparkRunner try to shuffle everything in memory (RAM) and do not use local storage. May be DataflowRunner uses local storage (it accepts a --temp_location argument)? However, this is not available to me on my local machine since the DataflowRunner seems to require the code to be run on Google Cloud.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/360#issuecomment-707424697:333,error,error,333,,https://github.com/google/deepvariant/issues/360#issuecomment-707424697,3,"['avail', 'error']","['available', 'error']"
Availability,"Could be the stupidest advice in the universe but are you looking at your; vcf file :). Literally just thought talking through the problem might help, fellow; human, and no I didn't check the organism, you could have told me and I; would gkne the ncbi datanae downloaded the genomes aligned them checked; your region if interest don't worry if I see your name on the email thread; on this public github repository I won't reply and I'll loom forward your; paper on bioarvix hopefully,. Honestly all the best,. And if you don't care about prokaryotes then fair enough,. Joe. On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote:. > The name of the organism has been said in this thread, that you are unable; > to find it, and believe we deal with a prokaryote is pathetic, really. Why; > would we bother with your stupid advice when you didn't even take the time; > to read the thread?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658773430:260,down,downloaded,260,,https://github.com/google/deepvariant/issues/682#issuecomment-1658773430,1,['down'],['downloaded']
Availability,"Could you please run the following commands:. ```; echo $LD_LIBRARY_PATH; echo $PATH; ```. And also paste the path of where `libcublas.so.9.0` actually resides. Then we can patch the paths appropriately. Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/102#issuecomment-429170838:51,echo,echo,51,,https://github.com/google/deepvariant/issues/102#issuecomment-429170838,2,['echo'],['echo']
Availability,"DS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false; ```. I uploaded the modified file on this public s3 bucket so you can have a look on it directly from here : ; s3://dv-testfiles/hg19.fa; s3://dv-testfiles/ENCFF528VXT.bam. There you can find the genome I used for running too. Before i created the needed files ( done in the following docker container https://hub.docker.com/r/luisas/samtools/ ) :; ```; samtools index ENCFF528VXT.bam; samtools faidx hg19.fa; bgzip -c -i hg19.fa > hg19.fa.gz; samtools faidx ""hg19.fa.gz""; ```. Then I ran in the docker container you provide :; ```; mkdir shardedExamples. time seq 0 1 | parallel --eta --halt 2 python /opt/deepvariant/bin/make_examples.zip --mode calling --ref hg19.fa --regions chr20:10,000,000-10,010,000 --reads ENCFF528VXT.bam --examples shardedExamples/examples.tfrecord@2.gz --task {}. ```. ```; /opt/deepvariant/bin/call_variants --outfile call_variants_output.tfrecord --examples shardedExamples/examples.tfrecord@2.gz --checkpoint dv2/models/model.ckpt; ```. and here the error output:; ```; WARNING: Logging before flag parsing goes to stderr.; W0307 09:54:53.415692 140603705038592 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_vZjmn7/runfiles/genomics/deepvariant/call_variants.py"", line 410, in module; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run; _sys.exit(main(_sys.argv[:1] + flags_passthrough)); File ""/tmp/Bazel.runfiles_vZjmn7/runfiles/genomics/deepvariant/call_variants.py"", line 401, in main; batch_size=FLAGS.batch_size); File ""/tmp/Bazel.runfiles_vZjmn7/runfiles/genomics/deepvariant/call_variants.py"", line 324, in call_variants; examples_filename, example_format)); ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to reru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371096675:2986,checkpoint,checkpoint,2986,,https://github.com/google/deepvariant/issues/52#issuecomment-371096675,1,['checkpoint'],['checkpoint']
Availability,"Dear @kishwarshafin ; thank you for your help, the Tensorflow version is:; tensorflow 2.12.0 pypi_0 pypi; tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/; it only gives:; Usage:; singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again!; Best,; CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/673#issuecomment-1625547662:388,error,error,388,,https://github.com/google/deepvariant/issues/673#issuecomment-1625547662,1,['error'],['error']
Availability,"Dear Andrew,. Thank you for your quick reply. I agree with you that most sequencing and; resequencing projects will move towards HiFi reads rather than CLR reads.; However, there is a lot of CLR sequencing data that has been generated in; the past couple of years and continues to be produced currently and could; still be useful for groups without the means to resequence using the novel; HiFi reads. So, I definitely see a niche in a large part of the; bioinformatics community that do a lot of data reusing (nowadays data; parasites). So, if there is anything we can do to help you n development,; please feel free to let me know how we can collaborate. Kind regards,. Juan D. Montenegro. El mar., 15 sept. 2020 a las 18:37, Andrew Carroll (<; notifications@github.com>) escribió:. > Hi @jdmontenegro <https://github.com/jdmontenegro>; >; > For the question about multi-allelic heterozygous calls - yes, DeepVariant; > is able to all 1/2 events, and will represent these in one line as a GT 1/2; > call in the VCF.; >; > For CLR calling in DeepVariant. It is theoretically possible for us to; > make a model for DeepVariant that can call CLR data. However, this requires; > us to write a special candidate generation logic to deal with the higher; > error rate. Based on what we perceive for the direction of future use in; > the genomics community, we think that data generated will be increasingly; > HiFi, so we have not been able to highly prioritize CLR models. Feedback; > from users like yourself will be useful to us in evaluating if that; > prioritization makes sense. For now, I can't commit to a timeframe under; > which we would support a PacBio CLR model.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/347#issuecomment-693053180>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ACHSLOV5RPVLTVGDW2A44X3SF73E7ANCNFSM4RNQJZYQ>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/347#issuecomment-693080237:1253,error,error,1253,,https://github.com/google/deepvariant/issues/347#issuecomment-693080237,1,['error'],['error']
Availability,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/679#issuecomment-1637342845:303,avail,available,303,,https://github.com/google/deepvariant/issues/679#issuecomment-1637342845,1,['avail'],['available']
Availability,"Dear Paul:; Thank you so much for the speedy reply.; I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:; /share/app/singularity/3.8.1/bin/singularity exec \; --containall \; --bind /usr/lib/locale/:/usr/lib/locale/ \; --bind $ccsbam:$ccsbam \; --bind $ccsbam.bai:$ccsbam.bai \; --bind $fasta:$fasta \; --bind $fasta.fai:$fasta.fai \; --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \; /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****; time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main; return _run_code(code, main_globals, None,; File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300:179,error,error,179,,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300,1,['error'],['error']
Availability,"Dear Pi-Chuan,. Thanks for pointing out the worker log files since I didn't realize the files are log files. ; It is really helpful!. The error comes from the inappropriate bam index file name I used (*.bai instead of *.bam.bai) as the log file describes: ; CommandException: No URLs matched: gs://input_bam/IO_045.sam_sorted_dedup.bam.bai. After changing the bam index file name, the pipeline works now! ; Thank you so much for your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/120#issuecomment-439734780:138,error,error,138,,https://github.com/google/deepvariant/issues/120#issuecomment-439734780,1,['error'],['error']
Availability,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,; however, for WES.bed I got a similar error as below. . ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0; 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz; 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:; 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>; 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters; W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L; I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/249#issuecomment-565657419:116,error,error,116,,https://github.com/google/deepvariant/issues/249#issuecomment-565657419,2,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"DeepVariant is built with bazel. Internally we have an add-on in CLion to import bazel project. If this plug-in is available you can try to do that. Bazel project is in the file named ""BUILD"" which exists in all sub-directories. If importing bazel project is not available then you may need to create your project from scratch in your IDE and then add all source files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/792#issuecomment-2010856611:115,avail,available,115,,https://github.com/google/deepvariant/issues/792#issuecomment-2010856611,2,['avail'],['available']
Availability,Did you build yourself from scratch? We've never seen this error before. Can you confirm that you can run the prebuilt binary on this machine? It's possible that TensorFlow and ABSL have updated their code on github in a way that's breaking our build.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/24#issuecomment-354129126:59,error,error,59,,https://github.com/google/deepvariant/issues/24#issuecomment-354129126,1,['error'],['error']
Availability,"Did you edit settings.sh? Look where it says:. export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3"". you have to remove the options your CPU doesn't support. Something like this, for a minimal case. export DV_COPT_FLAGS="""". or this for something tuned to your particular CPU. export DV_COPT_FLAGS=""--copt=-march=native"". The DV_COPT_FLAGS variable is used by our scripts to pass flags to the build system.; The --copt= construction is a flag for Bazel, the build system that passes flags to the compiler,; The ""-march=native"" part is a flag for GCC or Clang that says to try to auto-detect the architecture.; So read the GCC manual to see what other options are available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/16#issuecomment-352893787:688,avail,available,688,,https://github.com/google/deepvariant/issues/16#issuecomment-352893787,1,['avail'],['available']
Availability,Did you run `tensorflow.test.is_gpu_available()` from the DeepVariant docker?. Could you try the suggestion from this [thread](https://stackoverflow.com/questions/48658204/tensorflow-failed-call-to-cuinit-cuda-error-no-device),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/820#issuecomment-2125953311:210,error,error-no-device,210,,https://github.com/google/deepvariant/issues/820#issuecomment-2125953311,1,['error'],['error-no-device']
Availability,Do you mean you're still getting the errors after that? Can you post your commands?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/104#issuecomment-443831937:37,error,errors,37,,https://github.com/google/deepvariant/issues/104#issuecomment-443831937,1,['error'],['errors']
Availability,"Do you see any other error messages higher up in the logs? The CalledProcessError is just the wrapper, so it doesn't tell us what went wrong inside make_examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/419#issuecomment-774270943:21,error,error,21,,https://github.com/google/deepvariant/issues/419#issuecomment-774270943,1,['error'],['error']
Availability,"Does build_and_test.sh run properly without this modification? There's really nothing special about our pre-built CLIF binary. Here's our exact build commands:. ```; # Install prereqs.; sudo -H apt-get -y install ninja-build subversion; sudo -H apt-get -y install virtualenv python-pip pkg-config; sudo -H pip install 'pyparsing>=2.2.0'; sudo -H pip install 'protobuf>=3.4'. echo === building protobufs. sudo -H apt-get install -y autoconf automake libtool curl make g++ unzip; wget https://github.com/google/protobuf/releases/download/v3.4.1/protobuf-cpp-3.4.1.tar.gz; tar xvzf protobuf-cpp-3.4.1.tar.gz; (cd protobuf-3.4.1 &&; ./autogen.sh &&; ./configure &&; make -j 32 &&; make -j 32 check &&; sudo make -j 32 install &&; sudo ldconfig). echo === building CLIF. git clone https://github.com/google/clif.git; sed -i 's/\$HOME\/opt/\/usr\/local/g' clif/INSTALL.sh; sed -i 's/-j 2//g' clif/INSTALL.sh; (cd clif && sudo ./INSTALL.sh). echo === creating package tgz. sudo find ${CLIF_DIR} -type d -exec chmod a+rx {} \;; sudo find ${CLIF_DIR} -type f -exec chmod a+r {} \;; tar czf ""${CLIF_PACKAGE}"" /usr/local/lib/libproto* ""${CLIF_DIR}"". echo === SUCCESS: package is ""${CLIF_PACKAGE}""; ```. which is similar to your script but not identical. In fact you may be getting burned by `sed -i 's/\$HOME\/opt/\/usr\/local/g' clif/INSTALL.sh` which changes the install dir from ~/opt to /usr/local/. Is there a reason not to use this pre-built binary? If you are able to do git clone you should be able to reach GCS to get the binary. If you don't want to do that inside the script, you can always do it outside the script once, install it manually, and then build_and_test.sh won't try to refetch. Or you can follow the exact instructions above and it should create the actual clif binaries we distribute. We are looking forward to an official binary version of CLIF from that team...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/12#issuecomment-351260272:375,echo,echo,375,,https://github.com/google/deepvariant/issues/12#issuecomment-351260272,5,"['down', 'echo']","['download', 'echo']"
Availability,"Does this fix the mis-linked `libnvinfer_plugin.so.7` dlerror? . Seems like both `libnvinfer_plugin.so.7` and `libnvinfer_plugin.so.8` are in `LD_LIBRARY_PATH`, but the binary `run_deepvariant` is linked against `libnvinfer_plugin.so.7`, which complains about missing `libcublas.so.12`. Here's the error I'm getting:; ```stdout; 2024-10-07 09:10:29.222934: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2024-10-07 09:11:35.925528: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2024-10-07 09:11:35.925571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; ```. Here's where I found `libnvinfer.so.7`:; ```stdout; [walid@a100: 1.6.1]$ singularity exec --nv deepvariant_1.6.1-gpu.sif ls /usr/local/nvidia/lib; libnvinfer.so.7 libnvinfer.so.8 libnvinfer_plugin.so.7 libnvinfer_plugin.so.8; ```. Here's my `ldd` call to see what it's linked to:; ```stdout; [walid@a100: 1.6.1]$ singularity exec --nv deepvariant_1.6.1-gpu.sif ldd /usr/local/nvidia/lib/libnvinfer_plugin.so.7; 	linux-vdso.so.1 (0x0000155555524000); 	libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x0000155553038000); 	libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x0000155553032000); 	librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x0000155553028000); 	libcublas.so.12 => not found; 	libcublasLt.so.12 =>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/844#issuecomment-2397203060:298,error,error,298,,https://github.com/google/deepvariant/issues/844#issuecomment-2397203060,1,['error'],['error']
Availability,"E-mail transmission cannot be; > guaranteed to be secured or error-free as information could be intercepted,; > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses.; > The sender therefore does not accept liability for any errors or omissions; > in the contents of this message, which arise as a result of e-mail; > transmission. If verification is required please request a hard-copy; > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort; > Myers, FL 33913, http://www.neogenomics.com (2017); >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>; > .; >. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381164890:4514,error,error-free,4514,,https://github.com/google/deepvariant/issues/62#issuecomment-381164890,2,['error'],"['error-free', 'errors']"
Availability,"EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU; ```; The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name; 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX); 3) contig name or * for unmapped; 4) mapped position of base 1 of a read on the reference sequence; 5) MAPQ mapping quality; 6) CIGAR string describing insertions and deletions; 7) Name of mate; 8) Position of mate; 9) Template length; 10) Read Sequence; 11) Read Quality; 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658769491:1834,error,errors,1834,,https://github.com/google/deepvariant/issues/682#issuecomment-1658769491,2,['error'],['errors']
Availability,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/72#issuecomment-436236198:82,error,error,82,,https://github.com/google/deepvariant/issues/72#issuecomment-436236198,2,"['error', 'failure']","['error', 'failure']"
Availability,"FYI I submitted a pull request to GLnexus repo for the ""nomod"" preset for merging (no filters or genotype revision). https://github.com/dnanexus-rnd/GLnexus/pull/229 If this is accepted, you'll be able to try it out without downloading an external .yml file. @aderzelle Please let me know if you have any questions/comments related to this issue. If not, please feel free to close it :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/326#issuecomment-661427604:224,down,downloading,224,,https://github.com/google/deepvariant/issues/326#issuecomment-661427604,1,['down'],['downloading']
Availability,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```; OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant; REF=/mnt/efs-genome/Ref/hg19.gatk.fasta; CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz""; FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \; --ref ""${REF}"" \; --infile ""${CALL_VARIANTS_OUTPUT}"" \; --outfile ""${FINAL_OUTPUT_VCF}""; ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480628311:887,error,error,887,,https://github.com/google/deepvariant/issues/167#issuecomment-480628311,1,['error'],['error']
Availability,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>; wrote:. > Hi @avilella <https://github.com/avilella>; >; > DeepVariant has been used on MGI datasets, both using the standard; > Illumina model, as well as retrained models. There is some complexity that; > the MGI/BGI technologies have evolved over time, so some demonstrations may; > not reflect the newest methods.; >; > The general finding is that the Illumina models tend to work well for MGI; > data, though we find examples of retraining for certain datasets improve; > further.; >; > Our advanced training tutorial; > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>; > walks through retraining an Illumina model for data from BGISEQ 500 and this; > comparison; > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>; > was conducted several years ago using the out-of-the-box Illumina model.; >; > If you know of any genome in a bottle sequencing datasets that are; > available from more recent MGI platforms, I'd be interested in pointers to; > those locations. I would be quite curious to see how the technology has; > evolved over the last several years.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/538#issuecomment-1138380160:1050,avail,available,1050,,https://github.com/google/deepvariant/issues/538#issuecomment-1138380160,1,['avail'],['available']
Availability,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:; https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine; You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings.; https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/88#issuecomment-414378920:23,error,error,23,,https://github.com/google/deepvariant/issues/88#issuecomment-414378920,2,"['echo', 'error']","['echo', 'error']"
Availability,"Following up on my previous comment,; I confirmed that hap.py results in `happy.output.summary.csv` are the same. @dkurt One thing similar to what I observed before: call_variants with openvino seems to block at the beginning for quite a bit before it starts printing each of the logs:. ```. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp0gfwv278/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp0gfwv278/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino. I1128 03:33:00.717135 139674856871680 call_variants.py:338] Shape of input examples: [100, 221, 6]; 2020-11-28 03:33:00.726560: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 AVX512F FMA; To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.; 2020-11-28 03:33:00.742278: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000175000 Hz; 2020-11-28 03:33:00.748254: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x419c1f0 executing computations on platform Host. Devices:; 2020-11-28 03:33:00.748310: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version; 2020-11-28 03:33:00.752221: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; W1128 03:33:02.766410 139674856871680 deprecation.py:323] From /tmp/Bazel.runfiles_rud4ovxa/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.; Instructions for updating:; Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735276922:488,checkpoint,checkpoint,488,,https://github.com/google/deepvariant/pull/363#issuecomment-735276922,1,['checkpoint'],['checkpoint']
Availability,"From looking at the shapes of the tensors, it seems like you might be using an older model checkpoint?; In an older release, we used to have 7 channels instead of 6. Can you confirm whether you're using the 0.7.0 model checkpoint?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/117#issuecomment-437086785:91,checkpoint,checkpoint,91,,https://github.com/google/deepvariant/issues/117#issuecomment-437086785,2,['checkpoint'],['checkpoint']
Availability,"From your error, it seems like here is the relevant part:. ```; 2019-03-31 18:31:26.447697: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard: Failed precondition: /mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?; ```. For the `call_variants` step, in this line:; ```; --checkpoint ""${MODEL}""; ```. `${MODEL}` is actually a prefix of the model file, not the directory.; So, in your case, `${MODEL}` here should be:; `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model`; not just the name of the directory. Please give that a try and see if it works. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/166#issuecomment-478396748:10,error,error,10,,https://github.com/google/deepvariant/issues/166#issuecomment-478396748,2,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"From your log, I suspect that the postprocess_variants step failed.; Your log only shows this:. ```; ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878; 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz; ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step?. ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: ; https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/868#issuecomment-2286801983:738,error,errors,738,,https://github.com/google/deepvariant/issues/868#issuecomment-2286801983,1,['error'],['errors']
Availability,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,; Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]; Sent: Tuesday, May 1, 2018 10:50 AM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-385706487:1388,error,error-free,1388,,https://github.com/google/deepvariant/issues/62#issuecomment-385706487,2,['error'],"['error-free', 'errors']"
Availability,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```; E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"".; parallel: This job failed:; python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2; ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/72#issuecomment-412946034:213,error,error,213,,https://github.com/google/deepvariant/issues/72#issuecomment-412946034,6,"['error', 'failure']","['error', 'errors', 'failure']"
Availability,"Given these confusions, I feel like some explanations of what ""direct phasing"" means, other than in this ticket, would reduce users' questions down the road.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/649#issuecomment-1550118274:143,down,down,143,,https://github.com/google/deepvariant/issues/649#issuecomment-1550118274,1,['down'],['down']
Availability,"Gottcha. Basically, my wish would be for DV to emit MNPs as single VCF line. This is because basically all effect prediction algorithms operate that way. It is technically possible to analyse phased VCFs and get protein-level effect predictions that will look at in-phase SNPs within a coding sequence (Haplosaurus, Bcftools CSQ), but the available tools for that are very limited in what they can annotate and report back. And they are generally not used (much) in (clinical) variant interpretation for that reason.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/520#issuecomment-1558742268:339,avail,available,339,,https://github.com/google/deepvariant/issues/520#issuecomment-1558742268,1,['avail'],['available']
Availability,"Great! The logs you posted confirmed that the checkpoints were not being written, but it's not clear _why_ that was the case. I will close this issue for now, but please don't hesitate to reopen if you encounter it again!. To your second question, that's correct! In 1.6, we migrated our training and inference platform from Slim to Keras, and as part of this effort we combined `model_train` and `model_eval` with a single executable `train` to make training easier.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2033038202:46,checkpoint,checkpoints,46,,https://github.com/google/deepvariant/issues/797#issuecomment-2033038202,2,['checkpoint'],['checkpoints']
Availability,"HI @pichuan, . I trained on a new dataset and run into similar issue. This time there are files created in checkpoint but I still get the same error. Only the first epoch has low tune/categorical_accuracy and the next remaining epoch the accuracy higher than 0.9. I attached the log file here ; [train_041924.log](https://github.com/google/deepvariant/files/15082130/train_041924.log). Here is the parameter I used to train: ; ```-config.num_epochs=10 \; --config.learning_rate=0.0001 \; --config.num_validation_examples=0 \; --experiment_dir=""model_train"" \; --strategy=mirrored \; --config.batch_size=32 \; ```. Would you take a look and let me know what's going wrong? Thank you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2073289661:107,checkpoint,checkpoint,107,,https://github.com/google/deepvariant/issues/802#issuecomment-2073289661,2,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"HI @pichuan, the program worked fine and finished with results. I was just wondering if there were other versions available because the docker image was specified with a version number (1.6.0). Thanks again for all your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/740#issuecomment-1828737051:114,avail,available,114,,https://github.com/google/deepvariant/issues/740#issuecomment-1828737051,1,['avail'],['available']
Availability,"HI @pichuan,. Please check this screenshot out and see if it is more clear. ![image](https://github.com/google/deepvariant/assets/34832128/82ed1379-29b4-403f-aa07-75002c1d831e). What I did was I first shelled into the container. Then I checked the files in `/opt/deepvariant/bin/` in the container because I tried to look for the `run_deeptrio` file, which could not be found when I followed steps in https://github.com/google/deepvariant/blob/r1.6/docs/deeptrio-quick-start.md#notes-on-singularity and gave the error message as in the title of this issue. Was it possible that I missed anything when running Deeptrio?. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/745#issuecomment-1840119054:512,error,error,512,,https://github.com/google/deepvariant/issues/745#issuecomment-1840119054,2,['error'],['error']
Availability,"HI!; any update on this topic?. We called multiple genomes recently and found a first example of 4 adjacent base substitution AACT => GGTC being called 4 separate SNVs. The support information is very similar for the 4 calls and I wonder why deepvariant did not call them as one single MNP. This makes that the annotation and effect prediction downstream are wrong. Thanks for your support. ![failed_MNP-call](https://github.com/google/deepvariant/assets/858516/a02c3b5a-0362-4030-be8a-8b3c49129a8f). here is the extract of the gVCF at that location for one sample. ```; chrNN 51225801 . T <*> 0 . END=51225807 GT:GQ:MIN_DP:PL 0/0:50:27:0,81,809; chrNN 51225808 . A G,<*> 30.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:26:17,9,0:0.346154,0:30,0,37,990,990,990; chrNN 51225809 . A G,<*> 31.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,38,990,990,990; chrNN 51225810 . C T,<*> 31.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,39,990,990,990; chrNN 51225811 . T C,<*> 32.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:28:17,9,0:0.321429,0:32,0,37,990,990,990; chrNN 51225812 . C <*> 0 . END=51225881 GT:GQ:MIN_DP:PL 0/0:48:26:0,87,869; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/238#issuecomment-1700653315:344,down,downstream,344,,https://github.com/google/deepvariant/issues/238#issuecomment-1700653315,1,['down'],['downstream']
Availability,Haha thanks for catching that warGning message! I'll take care of that :). Sorry it looks like the warnings about these HP-related flags are confusing!. First let me try to understand what you are trying to do:; 1) Is your BAM phased? e.g. using whatshap.; 2) Which documentation page/example are you following that gave you these errors originally?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/457#issuecomment-838736936:331,error,errors,331,,https://github.com/google/deepvariant/issues/457#issuecomment-838736936,1,['error'],['errors']
Availability,Has there been a solution to this error? I'm seeing the same thing. I'm running deepvariant:1.6.1-gpu in a WDL workflow. It runs without error when I use it interactively but throws the error inside the WDL task.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/783#issuecomment-2010093323:34,error,error,34,,https://github.com/google/deepvariant/issues/783#issuecomment-2010093323,3,['error'],['error']
Availability,"Having personally fought through all sorts of similar errors when we were preparing the OSS release, I know how painful this is. Before diving into this, maybe you can tell me what you are trying to do here. Are you saying that you can't run build_and_tesh.sh without modification, and you are trying to overcome some issue that's not itemized here? Or are you trying to do something else?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/12#issuecomment-351081960:54,error,errors,54,,https://github.com/google/deepvariant/issues/12#issuecomment-351081960,1,['error'],['errors']
Availability,"Hello @MariaNattestad ; Thanks for reply, it turns out BAM file is truncated, here is my train of thought and step to fix the problem.; 1. Because 3 bam(HG002 HG003 HG004) file report same error, and I also tried to redownload bam file, it didn't work  either,  it reports [W::bam_hdr_read] EOF marker is absent. The input is probably truncated and [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes; 2. I google [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes, this error mostly occur at samtools usage, I think it maybe bam format error.; 3. I convert bam to sam  using samtools , and it reports bam is truncated, Then convert sam back to bam. The size between two bam is different, the  original one about 8GB, but the one I generated is just about 800M; 4. I run make_example.py using new bam file,  it also report my bam is error, it may be bai and bam don't match.; 5. I try another bam file, https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/OsloUniversityHospital_Exome/151002_7001448_0359_AC7F6GANXX_Sample_HG005-EEogPU_v02-KIT-Av5_CGCATACA_L008.posiSrt.markDup.bam,; because i familiar with wget, so I use wget to download bam file. And it runs successful.; 6. So it maybe aria2c error, I redownload all file using wget and demo is successfully executed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/455#issuecomment-839412109:189,error,error,189,,https://github.com/google/deepvariant/issues/455#issuecomment-839412109,8,"['down', 'error']","['download', 'error']"
Availability,"Hello @ayeshbond!. Could you please add a log statement with the exact error that you're seeing? . Additionally, you can always disable the creation of the `vcf_stats_repot` in case it's blocking you from running DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/839#issuecomment-2302920900:71,error,error,71,,https://github.com/google/deepvariant/issues/839#issuecomment-2302920900,1,['error'],['error']
Availability,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far!. I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:; ```; python bin/make_examples.zip \; --mode training \; --ref ""data/chr5.fa"" \; --reads ""data/sorted_final_merged.bam"" \; --examples ""training-examples/training_set.with_label.tfrecord.gz"" \; --confident_regions ""data/NA12878.sorted.bed"" \; --truth_variants ""data/NA12878.sorted.vcf.gz"" \; --regions ""chr5"" \; --norealign_reads; ```; and this is the output:; ```; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader; I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader; I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-455862468:663,error,error,663,,https://github.com/google/deepvariant/issues/138#issuecomment-455862468,2,['error'],['error']
Availability,"Hello @lucasbrambrink,. Thank you very much for the response. I am attaching the log file herewith. THe command I used was: . singularity run -B /usr/lib/locale/:/usr/lib/locale/ deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""{rest_path}/tools/DeepVariant/ref_genomes/GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta"" --reads=""{rest_path}/MiniMap_SAM_BAM/11741-KA-0004.sorted.bam"" --output_vcf=""{rest_path}/deepvar_calls/11741-KA-0004_output.vcf.gz"" --output_gvcf=""{rest_path}/deepvar_calls/11741-KA-0004_output.g.vcf.gz"" --intermediate_results_dir ""{rest_path}/deepvar_calls/intermediate_results_dir/0004"" --num_shards=32 &> deepvar_0004.log. [deepvar_0004.log](https://github.com/user-attachments/files/16730424/deepvar_0004.log). Also, could you let me know how I can disable it the `vcf_stat_report`?` I tried to look for it but to no luck. It doesn't necessarily affect the variant calling through. Just gives an error/failure due to this last step. Thank you very much once again, and please let me know if I can get you any more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/839#issuecomment-2307275017:955,error,error,955,,https://github.com/google/deepvariant/issues/839#issuecomment-2307275017,2,"['error', 'failure']","['error', 'failure']"
Availability,"Hello @mosh305 . I would like to learn more about what you would like to do with this sample, and, if possible, propose some alternatives that are more likely to succeed. I don't believe that the NA12878 Mt.Sinai set here can be reliably processed. This is a non-CCS PacBio dataset, so there will be far too many candidate examples generated to process efficiently. Also, the DeepVariant models are not trained for non-CCS PacBio reads. May I recommend that instead you consider the CCS dataset for HG002 that was submitted to genome in a bottle:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_CCS_15kb/. If this does sound interesting to you, we can provide to you a model trained for the CCS data type. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-458681829:229,reliab,reliably,229,,https://github.com/google/deepvariant/issues/138#issuecomment-458681829,2,['reliab'],['reliably']
Availability,"Hello @pichuan , thanks for the swift reply. I installed bazel manually, the installations is working, however I get the same error from ./build-prereq.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/98#issuecomment-424863291:126,error,error,126,,https://github.com/google/deepvariant/issues/98#issuecomment-424863291,1,['error'],['error']
Availability,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:; `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/849#issuecomment-2232682994:1210,error,error,1210,,https://github.com/google/deepvariant/issues/849#issuecomment-2232682994,4,['error'],['error']
Availability,"Hello Andrew,. I am having the same problem... I am trying to call SNPs in a species with a very high density of SNPs, and short read callers do not perform well, they miss a lot of variants in cohort samples, resulting in ridiculously high mutation rates, or the opposite they reject everything as mapping errors. I am now turning to long reads... I have the hope to obtain a solid golden reference set. That might be useful for training a DeepVariant model with short reads. I will definitely let you know if I succeed (but that's a big IF). Thanks; Alex. Sent with [Proton Mail](https://proton.me/) secure email. ------- Original Message -------; On Wednesday, June 14th, 2023 at 18:59, Andrew Carroll ***@***.***> wrote:. > Hi ***@***.***(https://github.com/Axze-rgb); >; > We do have interest in potentially releasing some non-human models. The mosquito model was trained with a much older version of DeepVariant, and there have no been so many improvements to the main branch, it would probably make sense to train a new one as opposed to release the old one.; >; > The main limitation is actually high quality training data. For mosquitos, the advantage we have is the extended pedigree. Are there are any good sources for the sort of labelled training data we might need for this?; >; > Thanks,; > Andrew; >; > —; > Reply to this email directly, [view it on GitHub](https://github.com/google/deepvariant/issues/661#issuecomment-1591660025), or [unsubscribe](https://github.com/notifications/unsubscribe-auth/ATOL54WNMFQN53D3HST5553XLHUYLANCNFSM6AAAAAAZGA4ITE).; > You are receiving this because you were mentioned.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/661#issuecomment-1592619772:307,error,errors,307,,https://github.com/google/deepvariant/issues/661#issuecomment-1592619772,1,['error'],['errors']
Availability,"Hello Andrew,. Thank you for your reply. . I have prepared snippets of the BAM files for the trio with variant chr7:54624683. It would be interesting to see what you find!. > One thing I note - it looks to me like there are 3 alleles represented in the reads for the top parent: 1) there is an insertion event in-phase with a downstream HET SNP. 2) There is a reference allele in-phase with REF at that later position. 3) There is evidence for a T SNP that is also in-phase with the downstream HET variant. For the reads that are HET T, it could be interesting to see if they overlap any other variants that would suggest that they come from a copy number variant elsewhere in the genome. It may be the case that DeepTrio does not call a variant in the parent because some of the variant reads may be coming from elsewhere. It is an interesting thought! But even if there is an explanation for missing HET T, the AATATAT insertion allele is also missed in the father genotype. And for some reason it is shown as ./. Best regards,; Maria. [chr7_54624683.tar.gz](https://github.com/google/deepvariant/files/6352555/chr7_54624683.tar.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/440#issuecomment-824200851:326,down,downstream,326,,https://github.com/google/deepvariant/issues/440#issuecomment-824200851,2,['down'],['downstream']
Availability,"Hello Andrew,; ; I got the VCF line from only DeepVariant generated file for this specific position. From the DeepVariant REF column have G and the ALT column have GCTCT,GCTCTCT. Two different alternate alleles of both insertion types. So I can say this comes under Multiallelic Insertion category. . From the truth VCF file, there is no line for this coordinate position. When I evaluated using hap.py, it returns error as I commented earlier in the above post. . Does the model consider both Multiallelic variant type and Biallelic or only Biallelic during evaluation? Is there any way I can filter the VCF lines having Multiallelic variant types?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/606#issuecomment-1404771799:415,error,error,415,,https://github.com/google/deepvariant/issues/606#issuecomment-1404771799,1,['error'],['error']
Availability,"Hello Eugenio,. - I agree that it looks like the secondary alignments are causing problems, since neither the actual read sequence nor the base qualities are stored in the BAM records for secondary alignments. When the parser hits these rows, it seems to be having trouble parsing the `*` base quality string as individual values.; - The `minimap2` parameters `-x map-pb` and `-x asm` refer to alignment parameters, and don't make any assumptions on what types of reads are being aligned (e.g. reads-to-reference vs assembly-to-reference).; - The PacBio model for DeepVariant has been trained on reads-to-reference alignments with pbmm2.; - I would highly recommend aligning your HiFi reads for DeepVariant with [pbmm2](https://github.com/PacificBiosciences/pbmm2). In addition to the alignment presets (which I discuss in the next point), we have some post-alignment filters that are applied. It's also just easier to use with PacBio data. To align a human HiFi uBAM (`hifi_reads.bam`) to a reference for downstream variant calling, I use: `pbmm2 align --num-threads 24 --preset HIFI --sort -c 0 -y 70 --sample <sample_name> reference.fasta hifi_reads.bam aligned.bam`. This produces an aligned, sorted BAM, with all of the fields and tags necessary to be processed by DeepVariant. If you don't have a local SMRTLink installation, you can install pbmm2 with `conda install -c bioconda pbmm2`; - The `pbmm2 --preset HIFI` parameters are _roughly_ equivalent to these minimap parameters: `-x map-pb -a --eqx -L -O 5,56 -E 4,1 -B 5 --secondary=no -z 400,50 -r 2k -Y`. Notice that we don't use homopolymer compressed minimizers (`-H`). Billy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/434#issuecomment-815972148:1006,down,downstream,1006,,https://github.com/google/deepvariant/issues/434#issuecomment-815972148,1,['down'],['downstream']
Availability,"Hello Ferdinand,. I have a few questions which may help us to understand whether this would be expected or not. First, can you tell me how many variants are Refcall in this sample (zcat Sample.final.vcf.gz | grep RefCall | wc -l) and how many variants are PASS in this sample (zcat Sample.final.vcf.gz | grep PASS | wc -l). Second, is it possible for you to point me to the capture regions that you used (the S07604514 BED file) or, if that is not possible, for you to tell me how many bases it covers. Knowing this information will help understand whether the number of variants are within expectations, whether they are a function of something about the sample, or whether there is some other issue to address. Generally, the commands do not seem in error. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/158#issuecomment-467144061:752,error,error,752,,https://github.com/google/deepvariant/issues/158#issuecomment-467144061,1,['error'],['error']
Availability,"Hello Ryan,. I built on an Ubuntu 16 system with CUDA-9.0, CUDNN version 7, tensorflow-gpu installed via tf-nightly-GPU using the last build available of 1.5 (it depends on CUDA-9.0). As I mentioned, build_and_test.sh showed success, running all tests successfully. I can install CUDA 8, CUDNN 6 and try again. Brad Thomas. From: Ryan Poplin [mailto:notifications@github.com]; Sent: Monday, February 5, 2018 3:08 PM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [External]Re: [google/deepvariant] Build and test works, binaries do not (#47). I wonder if there is an issue somehow with how you are building with tensorflow-gpu. What commands did you use to build it? We think this should work with tensorflow-gpu==1.4. Here is what I did to try it out:. git clone https://github.com/google/deepvariant.git. #edit settings.sh so that DV_GPU_BUILD=1 and DV_INSTALL_GPU_DRIVERS=1. ./build-prereq.sh; ./build_release_binaries.sh. then ran a test command with the quickstart testdata:. python deepvariant/bazel-bin/deepvariant/make_examples.zip; --mode calling; --ref ""${REF}""; --reads ""${BAM}""; --regions ""chr20:10,000,000-10,010,000""; --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". which executes as expected. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/47#issuecomment-363221616>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqV3UwUysMDiEktsAe-3kindiR3myks5tR22hgaJpZM4R5yAT>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/47#issuecomment-363230217:141,avail,available,141,,https://github.com/google/deepvariant/issues/47#issuecomment-363230217,1,['avail'],['available']
Availability,"Hello Salik,. I am sorry you are encountering issues with the Cloud Runner. I can't definitively tell you what has gone wrong, but I can spot a few things that will be issues (there could also be others). First, I think the log snippet here comes from the main log of the cloud runner. The underlying program error can often be found in another folder of the same run. You should see a ""logs"" folder and this should contain a program-specific log (like make_examples.log). This can be more informative. From your run, I can see that you provide your FASTA as an uncompressed .FA file. I believe that the cloud runner requires a BGZIP compressed reference, a samtools FAIDX, and a GZI index all in the same place. You will need to do the following operations on the FASTA file in a bucket that you control:. bgzip -i GRCh38_Verily_v1.genome.fa; samtools faidx GRCh38_Verily_v1.genome.fa. afterward, you will need to put the resulting:. GRCh38_Verily_v1.genome.fa.gz; GRCh38_Verily_v1.genome.fa.gz.gzi; GRCh38_Verily_v1.genome.fa.gz.fai. in the same bucket that the cloud runner can access. . Hopefully these instructions seem reasonable and this unblocks you from this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-436856528:309,error,error,309,,https://github.com/google/deepvariant/issues/116#issuecomment-436856528,1,['error'],['error']
Availability,"Hello Saurabh,; What errors do you get? Could you paste the output?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/607#issuecomment-1412596619:21,error,errors,21,,https://github.com/google/deepvariant/issues/607#issuecomment-1412596619,1,['error'],['errors']
Availability,"Hello! Yes, it is a benign error. All it means is that your BAM file has a blank line in its header section. We will be removing this technically-correct but actually-pointlessly-annoying warning from future releases of DeepVariant and Nucleus.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/190#issuecomment-504067535:27,error,error,27,,https://github.com/google/deepvariant/issues/190#issuecomment-504067535,1,['error'],['error']
Availability,"Hello, ; I have encountered the same problem as mentioned in this issue. ; And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files.; The version I'm using is: google/deepvariant:""1.5.0"".; Here is the command i run:; ```; docker run \; -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \; -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \; google/deepvariant:""1.5.0"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \; --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \; --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \; --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \; --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \; --num_shards=5; ```; The error output is: ; ```; [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options; samples_in_order, sample_role_to_train = one_sample_from_flags(; File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/tmp/Bazel.runfiles_3_jead3w/runfil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/577#issuecomment-1700305170:864,error,error,864,,https://github.com/google/deepvariant/issues/577#issuecomment-1700305170,1,['error'],['error']
Availability,"Hello, ; Thanks for your reply.; I don't want to perform assembly. I just want to obtain a VCF file for the mitochondria based on the aligned BAM file.; I am unsure if the results for chrM in the VCF generated by DeepVariant are reliable.; PacBio mitochondrial data:; ![1690423792423](https://github.com/google/deepvariant/assets/70870741/f6a18fa3-a432-4d53-9824-20a9e309298c). If DeepVariant is not suitable for calling mitochondrial variants on PacBio mitochondrial data, are there any other software recommendations for calling variants at mitochondrial loci without assembly?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/686#issuecomment-1652817371:229,reliab,reliable,229,,https://github.com/google/deepvariant/issues/686#issuecomment-1652817371,1,['reliab'],['reliable']
Availability,"Hello, as you can see the error message is ""samtools: command not found"". Can you please see if there's a way you can install samtools for your environment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/579#issuecomment-1292297608:26,error,error,26,,https://github.com/google/deepvariant/issues/579#issuecomment-1292297608,1,['error'],['error']
Availability,"Hello, thank you for your reply! . Not setting `--model_type WGS ` led to an error. To clarify, when you say generating the training data, you're referring to including `--channels ""insert_size""` in the make_examples steps for the training and validation sets, correct? Or do you mean the step where the custom model is trained? . Thank you! . Haley",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2027660245:77,error,error,77,,https://github.com/google/deepvariant/issues/797#issuecomment-2027660245,1,['error'],['error']
Availability,"Hello, thanks for your answer. Actually my organism is an ancient tetraploid; it's quite old but we are able to find back the old duplicates easily (they just look like alleles with high divergence). The coverage in those regions doesn't deviate from what is expected. . I would bet the rotifers are variant dense, their genome is small (100 Mb) and there doesn't seem to be a lot of repeats. Somehow, it's quite the exact opposite of the human genome (large and full of repeats). ; The thing is, as it is an asexual, I can't replicate the trio strategy, as I only have a mother and a descendant. So I am unsure about what to do here. I was planning to call the variant in the mother and the daughter, assuming there should be all identical. Any new variant in the daughter I would regard as calling errors. (and I see new variants, though most of the variant in the daughter are the same as in the mother). I am unsure if retraining would make sense here. . EDIT: more simply, does the concept of a pedigree make any sense in a clonal organism?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/266#issuecomment-580767025:800,error,errors,800,,https://github.com/google/deepvariant/issues/266#issuecomment-580767025,2,['error'],['errors']
Availability,"Hello,. Did you follow the instructions here: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md?. It seems like you are missing distutils, please follow the instruction in the readme to see if the error persists.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/730#issuecomment-1813395301:226,error,error,226,,https://github.com/google/deepvariant/issues/730#issuecomment-1813395301,1,['error'],['error']
Availability,"Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing?. Thank you and best regards,; Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]; Sent: Saturday, April 14, 2018 12:09 AM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,; I'm not seeing the zip file. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-385701252:83,error,error,83,,https://github.com/google/deepvariant/issues/62#issuecomment-385701252,3,['error'],"['error', 'error-free', 'errors']"
Availability,"Hello,. I think it'd be helpful if you can share individual gVCF calls for the problematic site before merging (hopefully with a fewer number of samples) so that we can try to reproduce it. As you said we'll have to ask GLnexus maintainers about this issue.; I found this issue on the GLnexus repo https://github.com/dnanexus-rnd/GLnexus/issues/286 - I'd recommend adding a reproducible example there as well. About the PASS filter, if your downstream application explicitly requires having that filter value, I'd recommend using tools like `bcftools` to add it. I think `bcftools annotate --rename-annots` would work based on this page, using `FILTER/. PASS` as the mapping: https://samtools.github.io/bcftools/bcftools.html#annotate. Thank you. Best,; Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/633#issuecomment-1518235939:441,down,downstream,441,,https://github.com/google/deepvariant/issues/633#issuecomment-1518235939,1,['down'],['downstream']
Availability,"Hello,. I tried installing deepvariant using `conda install deepvariant` .; With this, conda successfully;; -Collects package metadata; -Solves environment; -prepares and verifies the transactions (i.e required packages to download/install/update). Unfortunately, executing the transaction fails with the error below,. ```; Preparing transaction: done; Verifying transaction: done; Executing transaction: | ERROR conda.core.link:_execute_post_link_actions(658): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'.; LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1; running your command again with `-v` will provide additional information; location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh; ==> script messages <==; <None>. Attempting to roll back.; failed; ERROR conda.core.link:_execute(568): An error occurred while installing package 'bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1'.; LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1; running your command again with `-v` will provide additional information; location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh; ==> script messages <==; <None>. Attempting to roll back. Rolling back transaction: done. LinkError: post-link script failed for package bioconda/label/cf201901::deepvariant-0.7.2-py27h5d9141f_1; running your command again with `-v` will provide additional information; location of failed script: /root/miniconda3/bin/.deepvariant-post-link.sh; ==> script messages <==; <None>; ```. I had a similar error installing with ; `conda install -c bioconda deepvariant` and `conda install -c bioconda/label/cf201901 deepvariant` and `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Any idea and solution to what could be causing the error, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/177#issuecomment-504749118:223,down,download,223,,https://github.com/google/deepvariant/issues/177#issuecomment-504749118,8,"['ERROR', 'down', 'error']","['ERROR', 'download', 'error']"
Availability,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out?. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]; Sent: Thursday, April 12, 2018 3:34 PM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,; From a quick look of your error, it doesn't look like anything I've ever; encountered before. If you could potentially set up a reproducible setting; that I can very quickly run, I can see if I can try it out and tell you; what might could have gone wrong. We don't currently have a tutorial for; training, unfortunately. And to be honest, even if we do, it probably; wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is; > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for; > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:; > [64,27,1,3]; >; >; > I hate to keep bothering people about this. Is there documentation on all; > of this that I can refer to?; >; >; > Thanks,; > Brad Thomas; >; >; > From: Pi-Chuan Chang [mailto:notifications@github.com]; > Sent: Tuesday, April 10, 2018 1:04 PM; > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>; > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <; > author@noreply.github.com<mailto:author@noreply.github.com>>; > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381164890:693,error,error,693,,https://github.com/google/deepvariant/issues/62#issuecomment-381164890,1,['error'],['error']
Availability,"Hello,. With make_examples I believe I have made examples I can use in model_train. The 64 files are named like this: 5PRR-RD_S86.examples.tfrecord-00000-of-00064. My protobuffer file contains this:. name: ""my-training-dataset""; tfrecord_path: ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord""; num_examples: 64. When I run model_train I see this error:. ValueError: Cannot find matching files with the pattern ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord"". How should I specify the tfrecord_path to get model_train to use the files?. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]; Sent: Thursday, April 5, 2018 6:56 PM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi again,; I didn't read carefully so I missed that you said you want to train a model.; If you want to get make_examples to create more candidates, the other flags you need to consider are: vsc_min_count_snps, vsc_min_count_indels, vsc_min_fraction_snps, vsc_min_fraction_indels. With the default values of these flags for VSC (Very Sensitive Caller), you simply won't be able to even get candidates generated for low allele fraction variants. So I would suggest playing around with those flags and see if more candidates come out. Thanks! Let us know how it goes. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-379110341>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqU5J11c7Zr-VYS_8CjFPh-UF6VIYks5tlq76gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual name",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-380158183:358,error,error,358,,https://github.com/google/deepvariant/issues/62#issuecomment-380158183,2,['error'],['error']
Availability,"Hello,; I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format.; See 'docker run --help'. (**For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file; provided to --reads.; "")**; it would be great help if anyone help me to sort out this issue.; I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --outp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/181#issuecomment-2160884273:205,error,error,205,,https://github.com/google/deepvariant/issues/181#issuecomment-2160884273,2,['error'],['error']
Availability,"Hello,; it's ok for me to share, where should I send you the download link?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/209#issuecomment-524318838:61,down,download,61,,https://github.com/google/deepvariant/issues/209#issuecomment-524318838,1,['down'],['download']
Availability,"Here I'll try to run Singularity on CentOS7 to see if I can reproduce the issue.; ; # Get a CentOS 7 machine; ```; gcloud compute instances create ""${USER}-centos"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""centos-7"" \; --image-project ""centos-cloud"" \; --machine-type ""e2-standard-16"" \; --zone ""us-west1-b"" \; --boot-disk-size ""200"" ; ```. # Install Singularity 3.5; Following steps here https://sylabs.io/guides/3.5/admin-guide/installation.html#installation-on-linux. Then I have:; ```; [pichuan@pichuan-centos singularity]$ singularity --version; singularity version 3.5.2; ```. # Run Quick Start with Singularity. I downloaded the data from [Quick Start](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md). and then I tried:; ```; singularity pull docker://google/deepvariant:1.1.0"". singularity exec --bind /usr/lib/locale/ \; docker://google/deepvariant:1.1.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --regions ""chr20:10,000,000-10,010,000"" \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --num_shards 24 -v 2; ```. This finished running and output the output.vcf.gz file without an issue. ---. Then, I was searching for ""status 252"" and found this earlier issue: https://github.com/google/deepvariant/issues/345 . At the end the issue seems to be that the CPU didn't have AVX instructions. Specifically, see @tedyun 's comment: https://github.com/google/deepvariant/issues/345#issuecomment-690820723. @williamrowell Can you check whether your CPU supports AVX instruction?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/419#issuecomment-774634611:651,down,downloaded,651,,https://github.com/google/deepvariant/issues/419#issuecomment-774634611,2,['down'],['downloaded']
Availability,"Here is an attempt to deliberately mess up the BAM file in the case study, so I can get the make_examples step to fail, and observe the logs.; However, in my test runs below, I'm seeing useful error messages. @Asppagh if you have suggestions on how I can reproduce an error type like yours. It'll be really helpful! Otherwise I'm currently stuck on how to help you debug this. I'll share my test runs below so you can take a look:. ---. I followed steps in:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md; to get data. ## I deliberately messed up the BAM, and ran `run_deepvariant`; ```; ls -l quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam; -rw-rw-r-- 1 pichuan pichuan 3925783 Nov 27 2017 quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam; ```; ```; head -c 3000000 quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam > quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam; cp quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam.bai quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; ```. I ran:; ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.truncated.bam \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=1; ```. for the sake of completeness, I'll paste the log below up to the stack trace in make_examples:. ```; I0629 23:08:46.468520 139667868600064 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpj5fx0phm. ***** Intermediate results will be written to /tmp/tmpj5fx0phm in docker. ****. ***** Running the command:*****; ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.truncated.bam"" ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:193,error,error,193,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,4,['error'],['error']
Availability,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]; Sent: Saturday, April 14, 2018 12:09 AM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,; I'm not seeing the zip file. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381621757:1220,error,error-free,1220,,https://github.com/google/deepvariant/issues/62#issuecomment-381621757,2,['error'],"['error-free', 'errors']"
Availability,"Hey @qili93 . Thanks for letting me know! Is there a docker image available for this build (DeepVariant or prereqs)? If not, I will try to do it myself. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-467621007:66,avail,available,66,,https://github.com/google/deepvariant/issues/123#issuecomment-467621007,1,['avail'],['available']
Availability,"Hey there,. I was able to get a training started up on GCP today. Here is what I did, hopefully it is helpful:. First I created an instance using the command-line from the doc you pointed to. `gcloud beta compute instances create ""${USER}-deepvariant-quickstart"" --scopes ""compute-rw,storage-full,cloud-platform"" --image-family ubuntu-1604-lts --image-project ubuntu-os-cloud --machine-type n1-standard-8 --boot-disk-size=200GB --zone us-west1-b --accelerator type=nvidia-tesla-k80,count=1 --maintenance-policy TERMINATE --restart-on-failure`. then I downloaded and built DeepVariant (here you could tweak different build optimization settings, but for now I left it alone):. ```; git clone https://github.com/google/deepvariant.git; cd deepvariant; ./build-prereq.sh; ./build_release_binaries.sh; ```. Then I downloaded and set up some of the variables from the case study doc (https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md); I had to change N_SHARDS to be 8 since we have 8 cpus on this instance. Then I ran make_examples in training mode on a small portion of the genome to create some labeled training data. I adapted the command line from the one used in the case study. You would also want to randomly shuffle the data but I didn't do that here. ```; ( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \; python ""${BIN_DIR}""/make_examples.zip \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM}"" \; --confident_regions ""${TRUTH_BED}"" \; --truth_variants ""${TRUTH_VCF}"" \; --examples ""${EXAMPLES}"" \; --regions ""20:10,000,000-12,000,000"" \; --task {}; ) >""${LOG_DIR}/make_examples.log"" 2>&1; ```. The --confident_regions, and --truth_variants are how you supply the truth data to the program in order to create the labels. Then I created a data.pbtxt config file that is described in the training doc (https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-model-training.md). It looks like:; ```; > cat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/46#issuecomment-363256889:492,mainten,maintenance-policy,492,,https://github.com/google/deepvariant/issues/46#issuecomment-363256889,4,"['down', 'failure', 'mainten']","['downloaded', 'failure', 'maintenance-policy']"
Availability,"Hi ; Hi @pichuan . Input I have provided was a raw FASTQ read files instead of aligned BAM file. ; So this was causing the error and it worked fine post that. . Thanks; > Hi @navishkumarb , It seems like you've marked this issue as closed. If there's any findings that would be helpful to share with the forum here, please do.; > ; > If you have further questions, please feel free to reach out again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/807#issuecomment-2063003253:123,error,error,123,,https://github.com/google/deepvariant/issues/807#issuecomment-2063003253,1,['error'],['error']
Availability,"Hi @ASLeonard ,. Is it possible to provide the input data so we can reproduce the error on our end? On our side, we didn’t update nucleus between versions so unsure why you are seeing this behavior. Would be very helpful if you can provide a small data to reproduce as all the tests involving cram files still passes on v1.6z",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/741#issuecomment-1831176447:82,error,error,82,,https://github.com/google/deepvariant/issues/741#issuecomment-1831176447,1,['error'],['error']
Availability,"Hi @ASLeonard . This is an interesting question. The ability to sort reads and label them with a phasing tag (specifically HP) is general to DeepVariant (meaning that on the code level it is straightforward to add to DeepVariant). This feature is only used for long reads. We performed experiments in non-trio phasing of short reads, but found there is not enough information for local phasing to add information. . Trio phasing can be much more informative for short reads over long ranges. The main obstacle is that we do not have pre-trained models which have learned how to use this information as we have for long reads. It would, in theory, be possible to train models for this (though it would be a reasonable amount of work). One of the obstacles for us to do this is that we don't know what to recommend as the best practices for the trio binning process. . I don't think that variant calling on an assembly is necessarily a good idea, because the assembly itself will have errors, and the expected distribution of REF, HET, and HOM calls will be quite different from the typical variant calling problem. Assemblies are usually less complete than the reference, especially with short read data, and this is likely to create a lot of mapping artifacts. . I don't have any good recommendations for how to incorporate trio haplotype information at this time, but if you have reasonable suggestions on how to do so, we are happy to consider using them within DeepTrio. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/451#issuecomment-830342295:983,error,errors,983,,https://github.com/google/deepvariant/issues/451#issuecomment-830342295,2,['error'],['errors']
Availability,"Hi @AndrewCarroll . I believe I have recreated this issue with HG002 from GIAB.; This is what I did:; - Downloaded ftp://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/OsloUniversityHospital_Exome/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam; - Converted the bam to fastq; - Made a 100bp and 75bp fastq; - Aligned all three fastqs (original-127bp, 100bp, 75bp) to https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz; - Marked dups etc; - Ran deep variant 1.4 on 100bp bam, 75bp bam, and original bam using WES model; - Use bed file consisting of regions from the 100bp bam with depth over 10 intersected with CDS regions.; ; [over10.cds.bed.txt](https://github.com/google/deepvariant/files/10231884/over10.cds.bed.txt). This is how the distributions look; Original-127bp; <img width=""786"" alt=""original_127bp"" src=""https://user-images.githubusercontent.com/8237552/207720422-ea64ddad-1290-4cc3-819d-4b9829e56981.png"">. 100bp; <img width=""786"" alt=""100bp"" src=""https://user-images.githubusercontent.com/8237552/207713090-c669cdbf-544c-4190-ac6b-6c091123c551.png"">. 75bp. <img width=""786"" alt=""75bp"" src=""https://user-images.githubusercontent.com/8237552/207713065-cdb71b28-8d69-45df-81e3-53b2f1d3aecf.png"">. This is what my command looked like; ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B /share/terra docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref /share/terra/rsrc/hg38/ref/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz \; --reads ./HG002.proc.bam \; --output_vcf HG002.over10dp.vcf.gz \; --output_gvcf HG002.over10dp.gvcf.gz \; --num_shards 8 \; --intermediate_results_dir ./dv_int_results \; --regions ../100bp/over10.cds.bed; ```. Thanks again for looking into this",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/586#issuecomment-1352251354:104,Down,Downloaded,104,,https://github.com/google/deepvariant/issues/586#issuecomment-1352251354,1,['Down'],['Downloaded']
Availability,"Hi @AndrewCarroll the output for `samtools view -H maddog_bam_trim_bwaMEM_sort_dedupped.bam | grep @SQ` is. ```; @SQ SN:I LN:15072434; @SQ SN:II LN:15279421; @SQ SN:III LN:13783801; @SQ SN:IV LN:17493829; @SQ SN:V LN:20924180; @SQ SN:X LN:17718942; @SQ SN:MtDNA LN:13794; ```. The alignment was done by a summer student working under the guidance of a post-doc (she recently had a baby so I didn't want to bother her) and it's possible a different reference version was used. In the error above I had used **c_elegans.PRJEB28388.WS274.genomic.fa**. We have another reference genome on our server so I tried it in-case this was the issue. Using **c_elegans.PRJNA13758.WS265.genomic.fa** deepvariant ran for more than 3 hours and then failed on Chromosome V with this error:. ```; ...; I0402 20:41:44.332051 47425001081536 make_examples.py:535] 25500 candidates (27904 examples) [26.82s elapsed]; I0402 20:42:04.004627 47425001081536 make_examples.py:535] 25600 candidates (28010 examples) [19.67s elapsed]; I0402 20:42:27.991226 47425001081536 make_examples.py:535] 25700 candidates (28130 examples) [23.99s elapsed]; I0402 20:42:35.967661 47425001081536 make_examples.py:535] 25813 candidates (28251 examples) [7.98s elapsed]; I0402 20:42:48.188316 47425001081536 make_examples.py:535] 25911 candidates (28355 examples) [12.22s elapsed]; I0402 20:42:49.405055 47425001081536 make_examples.py:535] 26014 candidates (28458 examples) [1.22s elapsed]; [E::fai_retrieve] Failed to retrieve block. (Seeking in a compressed, .gzi unindexed, file?); 2020-04-02 20:46:28.318323: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""V"" start: 5524980 end: 5526020; Fatal Python error: Aborted. Current thread 0x00002b21fe57cac0 (most recent call first):; File ""/tmp/Bazel.runfiles_e68bsnf0/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 73 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/292#issuecomment-608553986:483,error,error,483,,https://github.com/google/deepvariant/issues/292#issuecomment-608553986,4,['error'],['error']
Availability,"Hi @Asppagh ,. It can be many different reasons. ; Your machine setup definitely could be one of the factors.; And, not all inputs will take the same amount of time to run. For example, some regions in some BAMs might take longer to realign, etc. In DeepVariant, we tried to empirically set some thresholds so we hope that even the slowest cases are not too slow. But it's always useful to learn from our users what edge cases might still cause the DeepVariant to be slow. If your input BAM file is publicly sharable, you can also point us to it, and I'm happy to give it try and see if I can identify any reasons why it might be particularly slow. But it's also possible that your data is not publicly available. If that's the case, to diagnose your machine setup, you can start by running on some of our publicly shared data used in https://github.com/google/deepvariant/blob/r1.1/docs/metrics.md. Specifically under:; https://github.com/google/deepvariant/blob/r1.1/docs/metrics.md#how-to-reproduce-the-metrics-on-this-page. For example, you can run on our WGS BAM file: gs://deepvariant/case-study-testdata/HG003.novaseq.pcr-free.35x.dedup.grch38_no_alt.bam on your cluster using singularity , and see what runtime you're getting. And, one more question that will help us provide better support:; Do you know if make_examples finish running on your machine? If so, how long it took on how many cores? If make_examples finished, then what's the runtime on call_variants and postprocess_variants?; (One possible issue we've seen before is that the call_variants stage is slow if users run on CPUs without acceleration)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-864304812:703,avail,available,703,,https://github.com/google/deepvariant/issues/463#issuecomment-864304812,2,['avail'],['available']
Availability,"Hi @Asppagh ; From the error above it wasn't very informative. This seems like it failed on the make_examples step already. We should have just stopped there, instead of proceeding into call_variants and next steps. --> This is now fixed in internal code, and will be fixed in the next release. Another question is -- why did the failed make_examples not produce any useful logs?. This one is a bit less clear to me. . With the same setting, instead of using /opt/deepvariant/bin/run_deepvariant (which is a convenient script that combines 3 steps), can you try directly running with . `/opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord.gz""`. This should allow you to just run 1 make_examples, without using GNU parallel as well. Hopefully whatever error messages will be more clear here.; Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870041849:23,error,error,23,,https://github.com/google/deepvariant/issues/465#issuecomment-870041849,4,['error'],['error']
Availability,"Hi @Axze-rgb ,. instead of setting INPUT_DIR=""${PWD}"" please provide the absolute path. You can also do echo $INPUT_DIR to make sure the variable is set correctly. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/685#issuecomment-1646860852:104,echo,echo,104,,https://github.com/google/deepvariant/issues/685#issuecomment-1646860852,1,['echo'],['echo']
Availability,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported V",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1642950331:451,error,error,451,,https://github.com/google/deepvariant/issues/682#issuecomment-1642950331,2,['error'],"['error', 'errors']"
Availability,"Hi @Axze-rgb . Conceptually, it is possible, and most of the challenge (which will be substantial) will be in constructing a truth set that is reliable enough, and in things like whether mapping will be reliable enough or the amount of variation is samples. Also, as I really you might be looking for subclonal variants instead of full germline variants. If this last piece is the case, then re-training with DeepVariant is likely not a good fit. In terms of hardware itself, when warmstarting training from a checkpoint, it's generally possible to train a new model with a single GPU. The GPU itself used in the case study is relatively old (a P100), several generations older than the current A100 or H100 GPUs. However, that GPU was designed for industry applications, I am not sure how it would stack up against a current consumer GPU. However, one thing to check - how many of your Illumina reads are MAPQ0 versus MAPQ 1-5 versus MAPQ5+. With default parameters, DeepVariant doesn't see Illumina reads with MAPQ <5. With long reads we were able to lower that threshold to MAPQ1, but if you're not getting many reads with more than MAPQ5 and especially if you're not getting reads more than MAPQ0, then the reads can't be mapped reliably enough for DeepVariant to attempt calling, whether the model is retrained or not.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/716#issuecomment-1756858933:143,reliab,reliable,143,,https://github.com/google/deepvariant/issues/716#issuecomment-1756858933,4,"['checkpoint', 'reliab']","['checkpoint', 'reliable', 'reliably']"
Availability,"Hi @Axze-rgb . It's reasonable to try. There are non-human species for which we know DeepVariant works well,for example [rice](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant),. You are correct that with a good long-read dataset it should be possible to train a short read DeepVariant method. If you are able to make those data and reference available, we could try it. There are two things to keep an eye on when assessing whether DeepVariant will work well for your samples. First, keep an eye that runtime doesn't get unreasonable. DeepVariant runs per-site, which scales linearly with number of variant positions. . The second, is to look if there are many cases where DeepVariant is calling many variants as 0/0 which have high support for the alternate allele. It's possible that a high variant density will resemble the signature of copy number variation in humans and since humans don't have much variation relative to the reference, it may become hesitant to call such variants. Really the only way to know is to try and then do some QC on the results. It's my hope will have better support and some more advanced methods for such genomes in the intermediate future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/661#issuecomment-1594084840:405,avail,available,405,,https://github.com/google/deepvariant/issues/661#issuecomment-1594084840,1,['avail'],['available']
Availability,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/872#issuecomment-2329912331:151,error,errors,151,,https://github.com/google/deepvariant/issues/872#issuecomment-2329912331,2,['error'],['errors']
Availability,"Hi @Axze-rgb and Andrew,. Good catch on the newline character – it’s hard to slow down at times when things are fun :) . Before having a presentation -- as my bandwidth is a bit tight these days (though I usually love presentations) -- I would be curious to see what you first get from Clair3 and Andrew's candidate region, as well as any additional insight Andrew might get from the VCF. I have this funny feeling of what the outcome might be – and we can have the presentation later among the three of us (and anyone else that's interested) as things emerge more clearly. Thank you,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1652518468:82,down,down,82,,https://github.com/google/deepvariant/issues/682#issuecomment-1652518468,2,['down'],['down']
Availability,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inherit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1650246876:770,error,errors,770,,https://github.com/google/deepvariant/issues/682#issuecomment-1650246876,1,['error'],['errors']
Availability,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```; bcftools norm -m - multi_allelic.vcf > biallelic.vcf; ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```; bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv; ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1648597119:1458,error,error,1458,,https://github.com/google/deepvariant/issues/682#issuecomment-1648597119,1,['error'],['error']
Availability,"Hi @Axze-rgb,. You did pretty awesome, in terms of how far you got! Kishwar's suggestions are perfect, and always never hesitate to just post here if you feel you are spending too much time. It also took me time to understand the DeepVariant ecosystem, but once you see how it all works together it becomes a joy to use. Basically just freely ask, and someone here can get you there quicker :). You did great, and only a few minor things:. $`1)`$ So you are correct that you will need the index file, as DeepVariant uses [Nucleus](https://github.com/google/nucleus), which in turn uses [HTSlib](https://github.com/samtools/htslib/blob/master/hts.c#L4508-L4559), and will complain with an error like this (when trying to locate it):. ```; [E::idx_find_and_load] Could not retrieve index file for '/input/mysorted.bam'; ```. Maybe this helps, so regarding the types of files DeepVariant needs is in the following document:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md. $`2)`$ The reason the first time it failed is because the BAM variable wasn't referenced with ${BAM}, and was written as `--reads=/input/BAM`, which is totally understandable to overlook. I've done that myself too many times to count :). $`3)`$ Regarding the dry run mode, that [just prints the commands](https://github.com/google/deepvariant/blob/r1.5/scripts/run_deepvariant.py#L492-L497) without actually running them. . Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/685#issuecomment-1646901356:688,error,error,688,,https://github.com/google/deepvariant/issues/685#issuecomment-1646901356,1,['error'],['error']
Availability,"Hi @Carl-labhub , one thing to confirm:. In the original post, you said:. Installation method (Docker, built from source, etc.): Docker. But from the information you provided, it seems like the error you encountered was when you ran with Singularity. Can you confirm: Do you see the error both when you use Docker and Singularity, or just Singularity?. I'll plan to try to reproduce on my side. But clarifying that will be helpful. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/812#issuecomment-2076055167:194,error,error,194,,https://github.com/google/deepvariant/issues/812#issuecomment-2076055167,2,['error'],['error']
Availability,"Hi @DiableJambe ,. Sorry for my late response, I do not have a docker image yet. And I attached the detailed steps here for your reference. It's a bit long :). # DeepVariant. ## Environment. ```bash; # Power8 environment; export CPU=power8; export HOMEPATH=/home/qilibj; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # AT 11.0 environment; source /etc/profile; module load at11.0; export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # python2 and pip environment; export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH; export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages; export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python; export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages; ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash; # download source code; wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz; tar -zxvf cmake-3.13.3.tar.gz; cd cmake-3.13.3. # build scirpt; ./bootstrap; make -j20; make -j20 install; export PATH=/usr/local/bin:$PATH; ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash; # download source code; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz; tar -zxvf protobuf-all-3.6.1.tar.gz; cd protobuf-3.6.1/. # clean static protobuf build; make uninstall; make distclean. # environment; export CPU=power8; export HOMEPATH=/home/qilibj; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:955,failure,failure,955,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,4,"['down', 'failure']","['download', 'failure']"
Availability,"Hi @DiableJambe and @pichuan ,. This issue can be resolved by IBM Advance Toolchain 11.0 :). Some brief steps for your references of how to build DeepVariant on Power8 & Redhat 7.5. 1. Build the following packages with ""/usr/bin/gcc""; cmake 3.13.3; Protobuf 3.6.1 C++ (static build with --enable-static for bazel); bazel 0.15.0. 2. Install Advance Toolchain 11.0 and build the following packages with /opt/at11.0/bin/gcc; Python 2 and Pip 19.0.2; Protobuf 3.6.1 C++ (uninstall static and build shared); Protobuf 3.6.1 Python (should build and install from source or CLIF will fail); TensorFlow 1.12.0 (fix floatn.h error with the link Floatn.h error: https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f); CLIF; Opencv-python 3.4.5.20 (for tensor2tensor install). Then build DeepVariant will pass, and results here (excepted //deepvariant/labeler:haplotype_labeler_test tracked in issue 154). ```; ================================================================================; (05:42:50) INFO: Elapsed time: 715.015s, Critical Path: 689.68s; (05:42:50) INFO: 1835 processes: 1835 local.; (05:42:50) INFO: Build completed, 1 test FAILED, 2433 total actions; //deepvariant:allelecounter_test PASSED in 0.1s; //deepvariant:call_variants_test PASSED in 59.8s; //deepvariant:data_providers_test PASSED in 11.8s; //deepvariant:dv_vcf_constants_test PASSED in 0.5s; //deepvariant:exclude_contigs_test PASSED in 1.6s; //deepvariant:haplotypes_test PASSED in 1.7s. ▽; //deepvariant:modeling_test PASSED in 48.2s; //deepvariant:pileup_image_test PASSED in 1.8s; //deepvariant:postprocess_variants_lib_test PASSED in 0.1s; //deepvariant:postprocess_variants_test PASSED in 4.8s; //deepvariant:resources_test PASSED in 1.8s; //deepvariant:tf_utils_test PASSED in 3.8s; //deepvariant:utils_test PASSED in 0.1s; //deepvariant:variant_caller_test PASSED in 2.4s; //deepvariant:variant_calling_test PASSED in 0.1s; //deepvariant/environment_tests:env_smoke_test PASSED in 0.4s; //deepvariant/environmen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-464686381:615,error,error,615,,https://github.com/google/deepvariant/issues/123#issuecomment-464686381,2,['error'],['error']
Availability,"Hi @DiableJambe, . We use libssw (https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library) for our local alignment. This code directly uses emmintrin.h in ssw.c so there's no easy way to remove it for the powerpc architecture. That said, there appears to be a pull request to add PPC64 support (https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library/pull/35) but this has been pending for more than a year. We'd be more than happy to update libssw if you can get an implementation in there that doesn't require SSE intrinsics. Let us know if you want to go down that route.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-441822330:580,down,down,580,,https://github.com/google/deepvariant/issues/123#issuecomment-441822330,1,['down'],['down']
Availability,"Hi @Fred-07,. As @akolesnikov mentions, the reason that the reads are re-aligned in this way has to do with some fundamental aspects of how alignment penalties work. The alignment method, Smith Waterman, has alignment score penalties for gap open and gap extend. These penalties make the alignments you see as scoring higher than ones that open and extend a gap early in the repeat. Those alignment penalties are determined from looking at mismatch, insertion, and deletion rates across large amounts of homologous sequences. They work very well for high sequence complexity regions which have standard types of DNA replication error. In this highly repetitive context, the ways that sequence (specifically repeats) can be extended or deleted is a bit different. It might, in theory, be possible to derive better gap extend scores for regions like this, but this is both very hard and a more fundamental problem. I don't think this case is one we can easily solve without very extensive work. . I hope that the @akolesnikov suggestion of turning off realigner in regions of interest will be satisfactory. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/763#issuecomment-2148541698:628,error,error,628,,https://github.com/google/deepvariant/issues/763#issuecomment-2148541698,1,['error'],['error']
Availability,"Hi @HamiltonG. The one-step script whose usage is shown in https://github.com/google/deepvariant#how-to-run-deepvariant will work on a cluster, just note that giving it something like 64 threads will help it run faster.; Our case study [metrics](https://github.com/google/deepvariant/blob/r1.1/docs/metrics.md) are from runs with 64 CPU cores and no GPU, so those numbers should give you an idea if that works for your purposes. For the simple run_deepvariant case, if Docker isn't available to you on your cluster, the same container and commands can be used with Singularity. This is I think what most people do when running on a cluster. If you really want to optimize a process to run DeepVariant many times, it can be worth running the 3 stages separately and giving them different resources because make_examples wants many CPUs, call_variants runs faster on GPUs, and postprocess_variants really just needs 1 CPU. The [external solutions](https://github.com/google/deepvariant#external-solutions) do variations of this plus their own special sauce. I hope that helps answer your question,; Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/474#issuecomment-883613731:482,avail,available,482,,https://github.com/google/deepvariant/issues/474#issuecomment-883613731,2,['avail'],['available']
Availability,"Hi @JoelDaon , were you able to run this?; What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver.; I documented it for myself here:; https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```; ( time sudo nvidia-docker run \; -v /home/${USER}:/home/${USER} \; gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \; /opt/deepvariant/bin/call_variants \; --outfile ""${CALL_VARIANTS_OUTPUT}"" \; --examples ""${EXAMPLES}"" \; --checkpoint ""${MODEL}""; ) >""${LOG_DIR}/call_variants.log"" 2>&1; ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/81#issuecomment-415637165:546,checkpoint,checkpoint,546,,https://github.com/google/deepvariant/issues/81#issuecomment-415637165,1,['checkpoint'],['checkpoint']
Availability,"Hi @JosephLalli . At the time we were putting together the vg-giraffe paper, we noticed that Indel errors would occur because the positioning of read indel events in the CIGAR string were not always left-normalized. ABRA both fixed that issue and also seems to give some additional advantage by standardizing the representation before running the candidate generation in DeepVariant. Subsequent to that finding, both ourselves and the vg team built methods which left-normalize Indel CIGAR events during processing. We found that this reduced almost all, but not quite all, of the Indel performance difference with ABRA processed reads. Because we have built the DeepVariant vg pipeline to include read normalization with the --normalize_reads=true tag, we don't routinely benchmark the two methods against each other. Our last head-to-head benchmark on ABRA on and off on 35x HG003 was no_ABRA Indel F1=0.9953, with ABRA Indel F1=0.9958. @pichuan Has made [this linked gist](https://gist.github.com/pichuan/eedab4cf2e06fa7ceb2fad0f9b3f8066) that we use for efficient, single machine processing of vg giraffe+DeepVariant. We opted not to include the use of ABRA realignment in that pipeline. With the benchmark numbers available here, I hope this is sufficient information for you to decide whether you would like to include it or not. We continue to look at improvements in the Indel realignment/reassembly process to see if we can further improve in some of the manners that ABRA helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/629#issuecomment-1503848466:99,error,errors,99,,https://github.com/google/deepvariant/issues/629#issuecomment-1503848466,2,"['avail', 'error']","['available', 'errors']"
Availability,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes?. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/534#issuecomment-2266085916:334,error,errors,334,,https://github.com/google/deepvariant/issues/534#issuecomment-2266085916,2,"['avail', 'error']","['available', 'errors']"
Availability,"Hi @JoshuaUrrutia , thanks for checking back.; The issue has been fixed in this change:; https://github.com/google/deepvariant/commit/7ed8c6bbcfb2dc0da9b1011ba21d12791239de79. If you're using the latest version (v0.10.0), we don't expect you to see this error before. If you still observe some issues with this, please let us know by reopening this issue or filing a new one.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/186#issuecomment-618676397:254,error,error,254,,https://github.com/google/deepvariant/issues/186#issuecomment-618676397,1,['error'],['error']
Availability,"Hi @Jyoti-Mridha ,. I looked at your error again more closely, and I realize that `docker: invalid reference format.` is not referring to the FASTA file. ; It is something to do with your command, which doesn't have the correct format of how you would use Docker. For example, if I run:. ```bash; sudo docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --helpshort; ```; which shows me the flags. But if I run something similar to your command:. ```bash; sudo docker run google/deepvariant:{BIN_VERSION=""1.6.1""} /opt/deepvariant/bin/run_deepvariant --helpshort; ```. It gave me this error:. ```; docker: invalid reference format.; See 'docker run --help'.; ```. I think there might be other formatting errors in your command. My suggestion: Can you make sure you follow our Quick Start step-by-step first?; And, once that succeed, please make sure you use a command similar to https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/829#issuecomment-2162208092:37,error,error,37,,https://github.com/google/deepvariant/issues/829#issuecomment-2162208092,3,['error'],"['error', 'errors']"
Availability,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```; docker run \; -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \; -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \; google/deepvariant:""1.5.0"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/C162-2_final.fasta \; --reads=/input/C111_mapped.bam \; --output_vcf=/output/C111.vcf.gz \; --output_gvcf=/output/C111.g.vcf.gz \; --intermediate_results_dir /output/intermediate_results_dir \; --num_shards=5; ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/577#issuecomment-1700327386:598,avail,available,598,,https://github.com/google/deepvariant/issues/577#issuecomment-1700327386,1,['avail'],['available']
Availability,"Hi @MariaNattestad , thanks for the reply. I found there's much more STRs inside the GIAB VCFs than the ""missed"" ones, so I believe GIAB has treated the STRs quite seriously.; However in many sites I found, the repeating units seems to be inserted or deleted as a group, for example, ATATATATAT -> ATATATAT is observed, but ATATATATAT -> ATATTAAT or other cases is not.; Since the allele depths are also high enough, the probability should be very small that such cases are caused by sequencing errors.; I'm not very familiar with sequencing or sample preparation, could other source of errors have more dominate contributions?. On the other hand, STRs can indeed be detected by DeepVariant in the pileup images, but could it help by inputting the information explicitly? I believe that would separate mixed examples in an earlier stage in the data space.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/317#issuecomment-645258677:495,error,errors,495,,https://github.com/google/deepvariant/issues/317#issuecomment-645258677,2,['error'],['errors']
Availability,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here.; ```; 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609; 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990; ```; Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,; Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/517#issuecomment-1055258649:285,error,errors,285,,https://github.com/google/deepvariant/issues/517#issuecomment-1055258649,2,['error'],"['error', 'errors']"
Availability,"Hi @Modernism-01 . For ONT data can you try the merge set DeepVariant_unfiltered. The presets for DeepVariantWGS were determined based on Illumina WGS. I hope that will help recover ONT variants that are too aggressively filtered. If this is not the case, you could please report back here. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/778#issuecomment-2035863304:174,recover,recover,174,,https://github.com/google/deepvariant/issues/778#issuecomment-2035863304,1,['recover'],['recover']
Availability,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,; Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/517#issuecomment-1050344301:108,error,error,108,,https://github.com/google/deepvariant/issues/517#issuecomment-1050344301,4,['error'],['error']
Availability,"Hi @Npaffen , I'm late to this thread. If I'm missing some context please feel free to remind me. Regarding your question ""**why the homref variants and the missings are added to the vcf in the first place**"":. DeepVariant starts with a set of candidates. These candidates came from a set of heuristics that propose a bunch of sites that potentially have variants.; You can find some thresholds we use for the heuristics here: https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L194; which basically means - if there is an alt allele that has a certain number of reads supporting it, and a certain % of reads supporting it, it will be proposed as a potential candidate. Then, DeepVariant applies a classifier on these candidates. To learn more about the representation that DeepVariant uses, https://google.github.io/deepvariant/posts/2020-02-20-looking-through-deepvariants-eyes/ is a good explanation. Each of the example (""image"") has a probability distribution for 3 classes. Based on the probability, the GT is assigned. As mentioned in previous answers, when the probability distribution from DeepVariant shows that it's not as confident, the GT is set to `./.`. By default, DeepVariant outputs the candidates even when they're classified as `0/0`, or when they're set to `./.`. ; This won't affect downstream tools like hap.py, though. Because these are not considered when tools like hap.py calculates accuracy. What DeepVariant outputs complies with the VCF spec, which says ""FILTER - filter status: PASS if this position has passed all filters, i.e., a call is made at this position."" If you look at our VCF, you'll notice that all variants (not including `0/0` and `./.`) should have `PASS`. Hopefully this helps. @Npaffen let me know if there's anything else that's unclear.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1610105430:1344,down,downstream,1344,,https://github.com/google/deepvariant/issues/666#issuecomment-1610105430,2,['down'],['downstream']
Availability,"Hi @Npaffen . Yes, in phase variants, the reads are assigned a haplotag value. Briefly, in this process, a set of potential variants are scored with heuristics (no neural network) on the likelihood that they are heterozygous variants. A cluster of such variants forms a candidate seed for a haplotype. The evidence from multiple reads across multiple positions are used to identify the putative variants on that haplotype, and then reads are scored based on whether they fall into one of the haplotypes, the other, or cannot be phased. Because this haplotagging uses information from much longer stretches and more candidate variants than the individual process of variant calling, it has the advantage of a broader set of information. This haplotagging is used to populate the information in the ""haplotype channel"" which is one of the inputs for DeepVariant long read data. We [wrote a blog](https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/) describing this channel and its impact. Note that this process is only used to provide the information to the neural network for consider, the neural network will be able to learn when this channel is or is not reliable based on genome context, coverage, etc... the network's call on the genotype is what finally goes into a variant. As a result, haplotag is not used as input to generate the non-ref blocks of the gVCF, and as the final variants called are still from the neural network, the definition of a variant remains the same - a position with an ALT allele that receives a non-reference (0/0 or ./.) call. We are currently working on a deeper description of the phasing logic used in DeepVariant, which may help understand or reproduce the haplotag method more easily. Please let me know if anything in the explanation is unclear or can be elaborated further.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1602118672:1183,reliab,reliable,1183,,https://github.com/google/deepvariant/issues/666#issuecomment-1602118672,2,['reliab'],['reliable']
Availability,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/528#issuecomment-1067565656:701,error,error,701,,https://github.com/google/deepvariant/issues/528#issuecomment-1067565656,2,['error'],['error']
Availability,"Hi @RaphaelSanchesUSP . Between the two approaches, this - **repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?** is the one which would require much less work. Of the approaches, this might not require large changes and might be possible with training alone. One component that could be limiting for this approach is the ability to identify extremely well characterized samples that could be used as truth examples. Is there a polyploid species where the variants relative to the reference are known without almost any error, as is the case for the genome in a bottle samples for humans?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/562#issuecomment-1235851209:565,error,error,565,,https://github.com/google/deepvariant/issues/562#issuecomment-1235851209,1,['error'],['error']
Availability,"Hi @Sh1von ,. Thanks for reporting this. Currently that's how our pipeline is designed unfortunately. We don't automatically resume. However, if make_examples and call_variants has completed successfully, you can manually run postprocess_variants separately. The way to figure out the commands to use : You can run your original command with `--dry_run`, and then it'll break down the sequence of commands you need. Then, you can manually rerun the postprocess_variants command. I understand that being able to resume can be a useful feature. To automatically detect existing data robustly will be challenging, because we don't know if there might be corrupted data. But, I think it'll be possible to add a flag for users to skip steps. I will think about it a bit more. For now, please try manually re-run postprocess_variants, and see if that works for you. Sorry for the inconvenience!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/587#issuecomment-1319519059:376,down,down,376,,https://github.com/google/deepvariant/issues/587#issuecomment-1319519059,4,"['down', 'robust']","['down', 'robustly']"
Availability,Hi @Stikus . You're right that we haven't rebuild the corresponding Ubuntu 18 version like the one in gs://deepvariant/packages/oss_clif/oss_clif.ubuntu-18.latest.tgz. I'll file an internal bug and get to this when I can. I think I probably have time in the next week. Feel free to ping in another week if I don't reply.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/289#issuecomment-605288518:282,ping,ping,282,,https://github.com/google/deepvariant/issues/289#issuecomment-605288518,1,['ping'],['ping']
Availability,"Hi @Suke-fudan . The best value to filter on is the GQ value of the variant call itself. We know from empirical investigation that the GQ value is very well-calibrated with the empirical error rate (See Figure 2 of - https://www.nature.com/articles/nbt.4235). This error probability is in the PHRED scale, so a GQ of 10 means DeepVariant indicates a 90% probability the call is correct, while a GQ of 20 indicates a 99% probability the call is correct. The formula for PHRED and correctness probability can be [found here](https://en.wikipedia.org/wiki/Phred_quality_score). . Beyond this information about the relationship between estimated and empirical error, I can't help much more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/503#issuecomment-1019658392:187,error,error,187,,https://github.com/google/deepvariant/issues/503#issuecomment-1019658392,3,['error'],['error']
Availability,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/681#issuecomment-1641408177:254,error,error,254,,https://github.com/google/deepvariant/issues/681#issuecomment-1641408177,1,['error'],['error']
Availability,"Hi @Tonitsk8264 . PacBio CLR and ONT R9.4 have higher base error rates. It is possible to call variants on this, but you will need to use [PEPPER-Margin-DeepVariant](https://github.com/kishwarshafin/pepper) instead. Please see that GitHub link for details. The preset there to call variants with R9.4 data should be either `--ont_r9_guppy5_sup` or `--ont_r9_guppy4_hac` depending on how it is basecalled. The preset for CLR should be `--clr`. For GLnexus outputs, you can use DeepVariantWGS for merging general sequencing results.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/713#issuecomment-1741830142:59,error,error,59,,https://github.com/google/deepvariant/issues/713#issuecomment-1741830142,1,['error'],['error']
Availability,"Hi @WeiweiBian ,; first of all, the ""The index file is older than the data file"" warning is usually something to do with your input data files (BAM, VCF, or FASTA). It's usually just a warning and wouldn't affect the run. You should still be able to run the training. Looking at your error, it seems to me that you might not using the correct REF file that has the `chr` prefix. On my side, I will check to confirm that our training case study actually works as intended. But, specifically for your use case --; To re-iterate what @MariaNattestad has mentioned, the current DeepVariant setup is not designed for your use case, and our team won't really have the bandwidth to support a very different use case like yours right now. Please consider using another tool that is designed for your use case. If you plan to use TensorFlow (which is what we built on) for your own use case and explore the possibilities, that is great! Based on my experience, training with just CPUs would really slow for the training step (model_train and model_eval steps), I have not even attempted that myself to a real training run using only CPUs. I do not recommend it. I will close this issue given that your use case is not a feature that our team will have bandwidth to support officially. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/308#issuecomment-631608785:284,error,error,284,,https://github.com/google/deepvariant/issues/308#issuecomment-631608785,1,['error'],['error']
Availability,"Hi @WeiweiBian . In our discussion over email, I recommended that you use a somatic caller instead of trying to adapt DeepVariant to your needs, and I still think this is the best way to go. To answer your questions:; 1. No, this is a limit within Inception V3 that DeepVariant uses.; 2. We don't have any other training tutorials for other systems.; 3. We have done some exploratory work on a somatic variant caller, but it is not available yet, and it is meant for tumor-normal pairs with much lower coverage and higher allele frequency. It will not be possible to use this for your case. I think you would be much better off using a somatic variant caller for your research.; If you want to take transforming DeepVariant into a somatic caller on as a research project, you are welcome to do so, since it's open source. But we unfortunately don't have the bandwidth to guide you very much, since we have other exciting improvements to DeepVariant that we are already working on. Best of luck with your work!; Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/308#issuecomment-628304654:432,avail,available,432,,https://github.com/google/deepvariant/issues/308#issuecomment-628304654,2,['avail'],['available']
Availability,"Hi @Wenfei-Xian,. A max MAPQ score of 42 will likely have some effect, but I expect not an enormous one. I suspect that MAPQ at the lower end of the ranges would be more important, since if well-calibrated a difference between PHRED=42 and PHRED=60 is a very low additional absolute error probability. I have some bowtie mapped reads handy for a GIAB sample. I think I can conduct a quick experiment to see if that intuition is right.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/809#issuecomment-2067533385:283,error,error,283,,https://github.com/google/deepvariant/issues/809#issuecomment-2067533385,2,['error'],['error']
Availability,"Hi @X1angyang . The model is InceptionV3. You can see the layers of one of the DeepVariant models like this:; ```; import tensorflow as tf. !gsutil cp gs://deepvariant/models/DeepVariant/0.10.0/DeepVariant-inception_v3-0.10.0+data-wgs_standard/model* /tmp/; checkpoint_path = '/tmp/model.ckpt'. reader = tf.compat.v1.train.NewCheckpointReader(checkpoint_path); shape_map_for_layers = reader.get_variable_to_shape_map(); print(shape_map_for_layers); ```; I just tested that in Colab (https://colab.research.google.com/). However, reimplementing all of DeepVariant from bam to output VCF would be a huge project. If you are interested in something smaller to get started, I'd like to bring this blog post to your attention: https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction/.; It has an associated Colab notebook that walks through some smaller but still challenging examples of how to use genomic data in machine learning using TensorFlow and Nucleus. I hope that helps!; Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/328#issuecomment-663252998:824,error,error-correction,824,,https://github.com/google/deepvariant/issues/328#issuecomment-663252998,2,['error'],['error-correction']
Availability,"Hi @ZuyaoLiu ,; To confirm what you said -- do you mean that you train your own model (on your own data) and was able to get a much lower Mendelian violation rate? If so, that's great!!. Given that this is a non-human sample (not what we trained on), it seems like the right way to proceed is either to use our DeepTrio model, or like you said, to use your own customized model. So far both approaches seem like they would produce quite decent Mendelian violation rate. In the future, our team is interested in thinking more about making our model more generally robust to all non-human species as well. So thank you for your feedback. Hopefully the two options (either DeepTrio or your own model) will work for you for now. I'll close this issue now, but please feel free to share more thoughts.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/726#issuecomment-1852999418:563,robust,robust,563,,https://github.com/google/deepvariant/issues/726#issuecomment-1852999418,2,['robust'],['robust']
Availability,"Hi @ZuyaoLiu . When I tested calling and training, I also saw that message. But in both of my calling and training, the GPU was utialized. We added an entry in FAQ: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-am-i-seeing-cuda_error_not_initialized-initialization-error-while-running-on-gpu. and I mentioned that message in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-training-case-study.md#test-the-model as well. @ZuyaoLiu , can you help check whether the results of calling is reasonable on your side, and whether GPU is utilized or not?. And, similarly in the training case, some of the warning messages you have might not affect the results. Can you also check whether you can run through the steps (and whether GPU is utilized or not)?. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/722#issuecomment-1787602575:283,error,error-while-running-on-gpu,283,,https://github.com/google/deepvariant/issues/722#issuecomment-1787602575,1,['error'],['error-while-running-on-gpu']
Availability,"Hi @adamnovak , ; I can confirm that our current code is designed to wait for new checkpoints, and only evaluate new ones. I understand that it'll be great retrospectively evaluate older checkpoints too. But we haven't experimented with that. I haven't got time to do so; but in the next few weeks (to a month) I'll likely need to re-run the training tutorial anyway. I'll try to find a time to see if it could be easy to tweak that behavior (but I don't know for sure). I'll keep this issue open and assigned to me for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/611#issuecomment-1431715409:82,checkpoint,checkpoints,82,,https://github.com/google/deepvariant/issues/611#issuecomment-1431715409,2,['checkpoint'],['checkpoints']
Availability,"Hi @aderzelle ,; I think you can use the TensorFlow config string to constraint the CPU use of the call_variants step. For example, this discussion talked about how to run TF on one core:; https://medium.com/@liyin2015/tensorflow-cpus-and-gpus-configuration-9c223436d4ef. If you're running call_variants directly, you can add a flag like `--config_string ""device_count {key: 'cpu' value: 1} intra_op_parallelism_threads:1 inter_op_parallelism_threads:1""`; For example:. ```; sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/call_variants \; --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" \; --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" \; --checkpoint ""/opt/models/wgs/model.ckpt"" \; --config_string ""device_count {key: 'cpu' value: 1} intra_op_parallelism_threads:1 inter_op_parallelism_threads:1""; ```. With this extra arg, I do see that:; ```; I1015 19:57:25.812590 140110048159488 estimator.py:212] Using config: {'_model_dir': '/tmp/tmpt8af___k', '_tf_random_seed': None, '_save_summary_steps': 10; 0, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {; key: ""cpu"" ; value: 1; }; intra_op_parallelism_threads: 1; inter_op_parallelism_threads: 1; ```; But I'm not 100% sure that TensorFlow actually fully follow the instructions here or not. If you're using the one-step script (`run_deepvariant`), you can add:; `--call_variants_extra_args=""config_string=\""device_count {key: 'cpu' value: 1} intra_op_parallelism_threads:1 inter_op_parallelism_threads:1\""""`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/361#issuecomment-709562825:787,checkpoint,checkpoint,787,,https://github.com/google/deepvariant/issues/361#issuecomment-709562825,1,['checkpoint'],['checkpoint']
Availability,"Hi @aderzelle . Thank you, this is a good question. We have observed this phenomenon as well. The answer is somewhat complicated. . DeepVariant seems to have learned something about the concept of segmental duplication, where positions that appear to be variants are actually due to mismapping of similar regions which may (or may not) be captured in the reference genome. The way this manifests in a genome pileup is as one phased haplotype that is mostly reference and (one or more) phased haplotype that is variant-dense. The signal for this is further enhanced when the VAF is closer to 0.33 or 0.25 (more directly suggesting copy number 3 or 4), but it can also occur close to 0.5 (which can still indicate a copy number of 4). These regions can be variants in thee diploid genome that are incorrectly called as REF, or they could be markers of a copy number variant. In human genomes, this can suggest a user look into that region for either known copy number variants or coverage differences. One question to ask - are these regions at generally higher coverage than you would expect? . In certain variant-dense species, we have observed this phenomenon to complicate calling [in this blog we investigate this for mosquito genomes](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). In this blog, we show the ability to re-train for a variant-dense species using a pedigree. If you have a pedigree available, we could also explore this with you. We are working on ways that will allow DeepVariant to more explicitly indicate when it thinks this is the case, and to provide more information (e.g. average coverage in the sample) to DeepVariant that will allow it to better separate variants from makers of segmental duplication.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/266#issuecomment-580713806:1488,avail,available,1488,,https://github.com/google/deepvariant/issues/266#issuecomment-580713806,2,['avail'],['available']
Availability,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/209#issuecomment-553647872:1171,avail,available,1171,,https://github.com/google/deepvariant/issues/209#issuecomment-553647872,2,['avail'],['available']
Availability,"Hi @aderzelle, in the case of position 10764356, the allele fraction is a bit lower in the case of the RefCall. A few other implementation details that might cause the differences between samples: DeepVariant randomly samples the reads as the pileup images generated can accommodate at most 100 reads. In the case of high coverage regions, the observed allele fraction can change as a result of this downsampling. Sampling for a particular sample is deterministic, but may happen differently across samples. Another source of difference between the three samples might be caused the realigner. DeepVariant runs a realignment that can be turned off by adding the flag `--norealign_reads` to the `make_examples` step. Turning the realigner off entirely will likely hurt overall accuracy, but for this example, it might be useful to see if that's affecting the results. Regions with many nearby variants do end up being challenging for the neural network to correctly classify. However, in the case of position 9780248, it is surprising that a candidate was not generated. Candidate generation should not be affected by the nearby variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/278#issuecomment-592330459:400,down,downsampling,400,,https://github.com/google/deepvariant/issues/278#issuecomment-592330459,1,['down'],['downsampling']
Availability,"Hi @aderzelle, thank you for your question. I believe this is coming from the cohort merging step (by GLnexus) assuming that you used `--config DeepVariantWGS` or `--config DeepVariant` for merging, not the DeepVariant itself. The merging step by GLnexus includes filtering alleles and revising genotypes and we have conducted an extensive study [1] on finding the best merging parameters for DeepVariant outputs, which was later pushed to the open-source GLnexus. The current version of the merging parameters uses `min_AQ1 = min_AQ2 = 10` (AQ means ""allele quality"") as you can see here https://github.com/dnanexus-rnd/GLnexus/blob/4d057dcf24b68b33de7a9759ae65ca2b144a3d47/src/cli_utils.cc#L874 The definitions of these parameters can be found at https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration . I believe this is the reason why you are seeing the sharp drop at `GQ = 10` as the alleles corresponding to them were already filtered. If you'd like to merge DeepVariant gVCFs without any filtering or genotype revision, you can download the `.yml` file here https://gist.github.com/tedyun/1d4f57ca67fb18647b7b251f9e0b35c2 and use `--config DeepVariant_nomod.yml` instead when running GLnexus. I hope this helps and please let us know if you have any more questions/comments. [1] https://doi.org/10.1101/2020.02.10.942086. Best,; Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/326#issuecomment-659742784:1039,down,download,1039,,https://github.com/google/deepvariant/issues/326#issuecomment-659742784,1,['down'],['download']
Availability,"Hi @aditya-88, thanks for filing this bug! We will look into both 1) using disutils.spawn and 2) improving the error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/160#issuecomment-470633217:111,error,error,111,,https://github.com/google/deepvariant/issues/160#issuecomment-470633217,1,['error'],['error']
Availability,"Hi @ahgillmo . We do have a prototype implementation for somatic calling, which can take a tumor and normal BAM and call subclonal variants. However, we don't yet have enough confidence in the available truth sets, and that they come from a diverse enough sampling of cancers with mutational profiles, for us be certain in releasing something of high quality. . We're watching developments in the area of these truth sets and hope to be able to further develop the somatic caller in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/351#issuecomment-696510915:193,avail,available,193,,https://github.com/google/deepvariant/issues/351#issuecomment-696510915,1,['avail'],['available']
Availability,"Hi @ajsa-nukovic , thanks for reporting the issue. First, I tried to reproduce your issue. I haven't been able to reproduce it yet. I wrote down my commands below:. Get a Ubuntu18.04 machine ; ```; gcloud compute instances create ""${USER}-test"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-1804-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""e2-medium"" \; --zone ""us-west1-b""; ```. After ssh into the machine, I ran:. ```; sudo apt -y update && sudo apt -y install docker.io; ```. And then followed the steps here:. https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md. For the main DeepVariant command, I ran:. ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --intermediate_results_dir /output/intermediate_results_dir \; --num_shards=1 \; --call_variants_extra_args=""use_openvino=true"" \; 2>&1 | tee /tmp/deepvariant.log; ```. With this run above, all steps (including call_variants) completed without errors. After that run, I repeated the call_variants step:; ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/call_variants \; --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" \; --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" \; --checkpoint ""/opt/models/wgs/model.ckpt"" \; --use_openvino; ```; which worked fine too. You mentioned you used DeepVariant1.1.0 version via Docker, but you also mentioned your command was:; `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz -",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/432#issuecomment-806341687:140,down,down,140,,https://github.com/google/deepvariant/issues/432#issuecomment-806341687,1,['down'],['down']
Availability,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running.; please see below code and log file. ###### code #############; #!/usr/bin/env nextflow. nextflow.enable.dsl=2; params.outdir = '/home/deepak/integration/resu1'; params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'; params.refhg38 = '/home/deepak/integration/hg381_22XYM'; params.bed = '/home/deepak/integration'. workflow {; // Define channels for input data; Channel; .fromPath(""${params.data_dir}/*_sorted_md.bam""); .map { file -> ; def sample_id = file.baseName.replace('_sorted_md', ''); return [sample_id, file]; }; .set { read_pairs }; /// Step 1. DeepVariant; DeepVariant(read_pairs, params.refhg38, params.bed); }. process DeepVariant {; tag ""deepavar on ${sample_id}""; publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'; cpus 4; //BIN_VERSION 1.6.1. input:; tuple val(sample_id), path(read_files); val(params.refhg38); val(params.bed); ; output:; //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs; tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:; """"""; docker run \; -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \; google/deepvariant:latest \; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \; --reads /opt/bam/${read_files} \; --regions /opt/bed/hg38_exomeY.bed \; --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \; --num_shards ${task.cpus}; """"""; }. ######## code ################. terminal:; (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1); [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/883#issuecomment-2352056013:147,error,error,147,,https://github.com/google/deepvariant/issues/883#issuecomment-2352056013,1,['error'],['error']
Availability,"Hi @alanlamsiu ,. If I understand correctly, your .sif file was previously built from our Docker version?. I'm going to walk through what I've tested so far. Maybe you can check which step is different from your experience. ---. Just to make sure I try it myself, here is what I did:. Get a GPU machine to test with:. ```bash; gcloud compute instances create ""${USER}-gpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --maintenance-policy ""TERMINATE"" \; --accelerator=type=nvidia-tesla-p100,count=1 \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-16"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. I ssh to the machine `gcloud compute ssh pichuan-gpu --zone us-west1-b`. Because my machine doesn't have Nvidia driver installed, I used:. ```bash; wget https://raw.githubusercontent.com/google/deepvariant/r1.6/scripts/install_nvidia_docker.sh; sudo bash -x install_nvidia_docker.sh ; ```; (the docker part is probably not necessary. I just need the driver). And then because I want to test Singularity, I install that with:. ```bash; wget https://raw.githubusercontent.com/google/deepvariant/r1.6/scripts/install_singularity.sh; sudo bash -x install_singularity.sh ; ```. Now, my machine has Singularity. I'll start following https://github.com/google/deepvariant/blob/r1.6/docs/deeptrio-quick-start.md#notes-on-singularity. I ran:. ```bash; BIN_VERSION=1.6.0; singularity pull docker://google/deepvariant:deeptrio-""${BIN_VERSION}-gpu""; ```. This created the file `deepvariant_deeptrio-1.6.0-gpu.sif` on my machine. I checked its size:. ```bash; pichuan@pichuan-gpu:~$ ls -lh deepvariant_deeptrio-1.6.0-gpu.sif ; -rwxrwxr-x 1 pichuan pichuan 12G Dec 5 07:38 deepvariant_deeptrio-1.6.0-gpu.sif; ```. ( @alanlamsiu , This is one thing I'd like you to double check. If you're converting from the 1.6.0 version, I don't think you should see `1.6.0rc2` in your .sif filename. Which is why I ask",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389:431,mainten,maintenance-policy,431,,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389,2,['mainten'],['maintenance-policy']
Availability,"Hi @amy-houseman . The strand of the read is one of the input channels in DeepVariant, so it is able to see that information and to learn the effects of strand bias on variant calling during training. For more information on what data is seen by DeepVariant, you can see the blog [Looking through DeepVariant's eyes](https://google.github.io/deepvariant/posts/2020-02-20-looking-through-deepvariants-eyes/). We don't write the strand information itself in the variant calls. For filtering, we instead recommend using the GQ field, which we find to be well calibrated with the probability of genotype error. Because DeepVariant sees the strand information, it will incorporate this into its confidence about the variant. If you have some specific aspect of your problem which you think the strand of reads will behave different from the genomes and exomes DeepVariant is trained on, and you want to do independent filtering, you would have to find some other method to annotate the strand information as DeepVariant does not write this directly to the VCF.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/719#issuecomment-1767795328:600,error,error,600,,https://github.com/google/deepvariant/issues/719#issuecomment-1767795328,2,['error'],['error']
Availability,"Hi @anands-repo . Thank you for running the evaluation! The work detailed in the blog and in the publication (https://www.biorxiv.org/content/biorxiv/early/2019/01/23/519025.full.pdf) represent our initial efforts to train a model on PacBio data. Subsequent to that publication, PacBio generated more extensive training Sequel II data. We used this data to build more robust training datasets across a diverse range of coverage, insert sizes, and machine runs. This is the model which has been released in version 0.8.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/201#issuecomment-516839518:368,robust,robust,368,,https://github.com/google/deepvariant/issues/201#issuecomment-516839518,1,['robust'],['robust']
Availability,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/224#issuecomment-540821357:175,avail,available,175,,https://github.com/google/deepvariant/issues/224#issuecomment-540821357,1,['avail'],['available']
Availability,"Hi @anands-repo . There are a large number of differences in the error profile of WGS and WES, including capture kit efficiency, additional errors from PCR in preparation, differences in the amount of on-target reads, greater coverage variability in exomes, and probably many other factors that are not completely understood. This paper: https://www.pnas.org/content/112/17/5473 is probably a good place to start on some of the factors that differ between the assays. For deduplication, we use Picard MarkDuplicates as run by GATK. We observe only very negligible differences in variant call quality with and without MarkDuplicates, which only become observable at lower coverages (15x-22x). This is one reason we indicate MarkDuplicates as an optional step in our BestPractices.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/329#issuecomment-663696939:65,error,error,65,,https://github.com/google/deepvariant/issues/329#issuecomment-663696939,2,['error'],"['error', 'errors']"
Availability,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/230#issuecomment-546050008:187,down,downsampling,187,,https://github.com/google/deepvariant/issues/230#issuecomment-546050008,8,['down'],"['downsample', 'downsampling']"
Availability,"Hi @anands-repo, can you share more details on the following?. - Operating system; - DeepVariant version - I'm assuming you are building 1.0.0 from source, but please let me know if it's a different version; - Command used to build; - Error trace after passing `--host_javabase=@local_jdk//:jdk`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/355#issuecomment-696846763:235,Error,Error,235,,https://github.com/google/deepvariant/issues/355#issuecomment-696846763,1,['Error'],['Error']
Availability,"Hi @andrewrech, I was not able to reproduce this error. Could you provide the commands you used when you ran into this issue?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-462246230:49,error,error,49,,https://github.com/google/deepvariant/issues/145#issuecomment-462246230,1,['error'],['error']
Availability,"Hi @anitagh , I want to give you an update that after today's release (v0.9.0), you can now use the `--sample_name` flag with run_deepvariant.py:; https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L89. And, we also made the behavior more robust so that even with multiple or no sample names, we'll try to assign a reasonable default, and proceed with a warning (but without crashing). If you have more questions please feel free to follow up here, or file new issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/222#issuecomment-553655187:263,robust,robust,263,,https://github.com/google/deepvariant/issues/222#issuecomment-553655187,1,['robust'],['robust']
Availability,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/222#issuecomment-536320209:757,avail,available,757,,https://github.com/google/deepvariant/issues/222#issuecomment-536320209,1,['avail'],['available']
Availability,"Hi @anitagh and @PlatonB , ; to give you an update on this issue, we have made a change internally that:; 1) Added `--sample_name` to run_deepvariant.py; 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/222#issuecomment-535311937:258,error,error,258,,https://github.com/google/deepvariant/issues/222#issuecomment-535311937,1,['error'],['error']
Availability,"Hi @ankurc17 ; Can you tell us more about what the issues are?; For example, what OS are you using, what command did you run and what error messages you've seen.; It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/574#issuecomment-1276221161:134,error,error,134,,https://github.com/google/deepvariant/issues/574#issuecomment-1276221161,2,['error'],['error']
Availability,"Hi @asalimih ,. can you downsample your bam for this specific variant and run it again?. ```bash; samtools view -s 0.5 -b -@16 YOU_BAM.bam > YOUR_BAM.downsampled.bam; ```; And run it one more time to see if this specifically has a different genotype?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/824#issuecomment-2130501789:24,down,downsample,24,,https://github.com/google/deepvariant/issues/824#issuecomment-2130501789,2,['down'],"['downsample', 'downsampled']"
Availability,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/538#issuecomment-1138272184:863,avail,available,863,,https://github.com/google/deepvariant/issues/538#issuecomment-1138272184,1,['avail'],['available']
Availability,"Hi @avilella,. That's a great question. We did some limited experiments with DeepVariant on lower coverage samples, but not at the 2.5x-5x range directly (see attached image using an earlier version of DeepVariant than available on GitHub). . Typically at such a low depth you need to follow a joint calling strategy like the 1000 Genomes project in order to get accurate allele discovery across many samples. If you are trying to do single sample calling from low coverage, despite the relatively low quality of calls you'll get due to the low coverage, you can certainly use DeepVariant. You really don't need to do anything different than for a deep WGS sample, so just follow the case study example command lines. . There are some options in make_examples.py to manipulate the thresholds for generating candidate variant calls, but I'm not sure tweaking those will materially change the results. We'd be interested in hearing about your experiences with such low coverage samples if you do decide to try it out. ![screen shot 2018-01-17 at 11 14 01 am](https://user-images.githubusercontent.com/2250400/35062234-632d9068-fb78-11e7-84eb-66062ba79a43.png)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/40#issuecomment-358413895:219,avail,available,219,,https://github.com/google/deepvariant/issues/40#issuecomment-358413895,1,['avail'],['available']
Availability,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0; The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,; Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz); [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/220#issuecomment-532442476:83,avail,available,83,,https://github.com/google/deepvariant/issues/220#issuecomment-532442476,2,['avail'],['available']
Availability,"Hi @bopohdr ; Thank you, the log is helpful.; From the error, specifically this line:; ```; ValueError: Failed precondition: Cannot query without an index; ```; It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:; `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/232#issuecomment-549225504:55,error,error,55,,https://github.com/google/deepvariant/issues/232#issuecomment-549225504,1,['error'],['error']
Availability,"Hi @bopohdr, if it's possible, can you send me to full log?. In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:; ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/232#issuecomment-548948642:87,error,error,87,,https://github.com/google/deepvariant/issues/232#issuecomment-548948642,5,['error'],['error']
Availability,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/890#issuecomment-2401278866:213,avail,available,213,,https://github.com/google/deepvariant/issues/890#issuecomment-2401278866,1,['avail'],['available']
Availability,"Hi @chapmanb , another update:. I went through a lot of hacky steps and built CLIF. I'm actually not sure whether it's actually usable or not, so if you have a setup that quickly give it a try, that will be great. Here's the instruction on how to get `pyclif` to run on a CentOS 6 machine:; ```; # Get a machine; gcloud beta compute instances create ""${USER}-centos6"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""centos-6"" --image-project ""centos-cloud"" \; --machine-type ""custom-64-131072"" \; --boot-disk-size ""300"" --boot-disk-type ""pd-ssd"" \; --zone ""us-west1-b"". # ssh into it; gcloud compute ssh ${USER}-centos6 --zone us-west1-b; ```. ```; ##### On the GCE instance #####; # Install Python 2.7; sudo yum install -y centos-release-SCL; sudo yum install -y python27; source /opt/rh/python27/enable. gsutil -m cp gs://deepvariant/packages/oss_clif/oss_clif.centos-6.9.latest.tgz /tmp/; (cd / && sudo tar xzf ""/tmp/oss_clif.centos-6.9.latest.tgz""); sudo ldconfig # Reload shared libraries.; ```; (I had to build with Python 2.7. Didn't figure out how to build with 2.6. Let me know if you actually need Python 2.6?). Once you do this, you can run `/usr/local/clif/bin/pyclif` and should see the usage:; ```; $ /usr/local/clif/bin/pyclif; usage: pyclif [-h] [--py3output] [--matcher_bin MATCHER_BIN] [--nc_test]; [--dump_dir DUMP_DIR] [--binary_dump] [--modname MODNAME]; [--prepend PREPEND] [--include_paths INCLUDE_PATHS]; [--ccdeps_out MODNAME.cc] [--ccinit_out MODNAME_init.cc]; [--header_out MODNAME.h] [--cc_flags CC_FLAGS] [--indent INDENT]; input_filename; pyclif: error: too few arguments; ```. Please let me know once you have a chance to try it.; CentOS 6 is tricky. It feels like everything is old :(; Let me know what other things are blocking you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-385864674:1601,error,error,1601,,https://github.com/google/deepvariant/issues/29#issuecomment-385864674,2,['error'],['error']
Availability,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant.; 2. The directories where the input files are located.; 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1699480255:320,error,errors,320,,https://github.com/google/deepvariant/issues/184#issuecomment-1699480255,2,['error'],['errors']
Availability,"Hi @chrisfleisch , sorry it took me a while to find some time to try this. I just got an AMD machine on Google Cloud to test. But, I'm unable to reproduce your issue in the `make_examples` step.; I'll post what I did below (which didn't reproduce your error).; But, maybe this Stackoverflow issue could be related?; https://stackoverflow.com/questions/52026652/openblas-blas-thread-init-pthread-create-resource-temporarily-unavailable; Specifically, can you try the suggestion in https://stackoverflow.com/a/54746150 and let me know if that worked for you?. ---. For completeness, here is what I tried:. I got a AMD machine:. ```; gcloud compute instances create ""${USER}-amd"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-1604-lts"" --image-project ""ubuntu-os-cloud"" \; --machine-type ""n2d-standard-16"" --boot-disk-size ""100"" \; --zone ""europe-west4-b""; ```. On that machine, I ran:; ```; $ lscpu; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 16; On-line CPU(s) list: 0-15; Thread(s) per core: 2; Core(s) per socket: 8; Socket(s): 1; NUMA node(s): 1; Vendor ID: AuthenticAMD; CPU family: 23; Model: 49; Model name: AMD EPYC 7B12; Stepping: 0; CPU MHz: 2249.998; BogoMIPS: 4499.99; Hypervisor vendor: KVM; Virtualization type: full; L1d cache: 32K; L1i cache: 32K; L2 cache: 512K; L3 cache: 16384K; NUMA node0 CPU(s): 0-15; Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid; ```. Then, I ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/274#issuecomment-599870096:252,error,error,252,,https://github.com/google/deepvariant/issues/274#issuecomment-599870096,1,['error'],['error']
Availability,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/672#issuecomment-1613645470:28,error,error,28,,https://github.com/google/deepvariant/issues/672#issuecomment-1613645470,1,['error'],['error']
Availability,"Hi @crazysummerW ,. Looking at your error, it seems like this might be relevant:. ```; File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 241, in make_fid; fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5f.pyx"", line 122, in h5py.h5f.create; OSError: [Errno 5] Unable to synchronously create file (unable to lock file, errno = 5, error message = 'Input/output error'); ```. This is because this logic in our code writes a temp file:; https://github.com/google/deepvariant/blob/r1.6/deepvariant/keras_modeling.py#L97-L99. ```; tmp_weights_dir = tempfile.gettempdir(); tmp_weights_path = os.path.join(tmp_weights_dir, 'tmp_weights.h5'); model.save_weights(tmp_weights_path); ```. Can you check your setting, and see if somehow your run wasn't able to create a temp file?. I reran our set up in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md (using a GCP machine as an example) and wasn't able to reproduce that error. So, it'll be very helpful for me to understand your machine setup, and try to make our code more robust in the future. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/725#issuecomment-1799132190:36,error,error,36,,https://github.com/google/deepvariant/issues/725#issuecomment-1799132190,5,"['error', 'robust']","['error', 'robust']"
Availability,"Hi @crazysummerW ,. One more thought:; You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here.; That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:; When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:; ```; deepconsensus run \; --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \; --ccs_bam=${shard_id}.ccs.bam \; --checkpoint=model/checkpoint \; --output=${shard_id}.output.fastq; ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/672#issuecomment-1615974070:991,checkpoint,checkpoint,991,,https://github.com/google/deepvariant/issues/672#issuecomment-1615974070,2,['checkpoint'],['checkpoint']
Availability,"Hi @crazysummerW . The message here is most consistent with reads that do not have quality values. Inspection of the GIAB file indicates that this is the case here - the reads have bases and not quality values. These GIAB files appear to be deposited in 2018. It seems likely to me that they are PacBio continuous long read (CLR) sequencing instead of Circular Consensus Sequencing (CCS). PacBio CLR sequencing has a higher base error rate and DeepVariant is not designed to process this older type of sequence data. . Mechanically, the reason this input file fails is that it lacks quality values, which DeepVariant expects. CLR sequencing does not generate quality values. For test data, I recommend using a more recent set of sequencing which use the CCS prep, e.g. the contents of: . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_CCS_15kb_20kb_chemistry2/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/631#issuecomment-1507742336:429,error,error,429,,https://github.com/google/deepvariant/issues/631#issuecomment-1507742336,1,['error'],['error']
Availability,"Hi @crazysummerW,. That might be tricky as its deeply encoded in the pileup image construction - and how it's processed - which would would require some code-rewrite to extract it properly. If you have reads that don't span more than 95 for that specific variant position - or you downsample to 95 - you can reconstruct that from the BAM or DeepVariant realigned BAM files. . There might be other avenues I haven't thought about yet, though I'll keep thinking. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/707#issuecomment-1715948232:281,down,downsample,281,,https://github.com/google/deepvariant/issues/707#issuecomment-1715948232,1,['down'],['downsample']
Availability,"Hi @danielecook , I was trying various things that would require least amount of effort. I ended up just skipping and using the `google/deepvariant` docker image as-is.; I'm no expert in docker, just trying to get things running. ; Then I also have the issue that singularity can't use/convert the deepvariant docker image:; ```; $ singularity build --sandbox deepvariant_1_1_0 docker://gcr.io/deepvariant-docker/deepvariant:1.1.0; WARNING: Building sandbox as non-root may result in wrong file permissions; Docker image path: gcr.io/deepvariant-docker/deepvariant:1.1.0; ERROR MANIFEST_UNKNOWN: Manifest with tag '1.1.0' has media type 'application/vnd.docker.distribution.manifest.v2+json', but client accepts 'application/json'.; Cleaning up...; ```; This may be my inexperience in these things, but I'm simply having trouble getting them running.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/445#issuecomment-822613451:572,ERROR,ERROR,572,,https://github.com/google/deepvariant/issues/445#issuecomment-822613451,1,['ERROR'],['ERROR']
Availability,"Hi @danielecook ,. Thanks for the reply. I retried adding --cleanenv flag and get the same error. I also cleanup the tmp folder. Here is the command I tried. ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/tmp singularity run --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/580#issuecomment-1304582333:91,error,error,91,,https://github.com/google/deepvariant/issues/580#issuecomment-1304582333,1,['error'],['error']
Availability,"Hi @danielecook ,; I tried without ```--debug=false``` and set ```--config.num_epochs=10``` but I still get the same error that ```--config.num_epochs=10```. I attached my log file here . [train_040324.log](https://github.com/google/deepvariant/files/14873081/train_040324.log). THis is the command I used:; ```; BIN_VERSION=""1.6.1""; DOCKER_IMAGE=""google/deepvariant:${BIN_VERSION}"". time sudo docker run --gpus 1 \; -v /home/${USER}:/home/${USER} \; -w /home/${USER} \; ${DOCKER_IMAGE}-gpu \; train \; --config=s3-mount/deepvariant_training/script/dv_config.py:base \; --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \; --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \; --config.init_checkpoint=""${GCS_PRETRAINED_WGS_MODEL}"" \; --config.num_epochs=10 \; --config.learning_rate=0.02 \; --config.num_validation_examples=0 \; --experiment_dir=""model_train"" \; --strategy=mirrored \; --config.batch_size=512; ```. Did I miss anything?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2037432899:117,error,error,117,,https://github.com/google/deepvariant/issues/802#issuecomment-2037432899,1,['error'],['error']
Availability,"Hi @dbrami . With respect to the python version, this software is contained within Docker, so you don't need to worry about what version is on your system. They python versions that we can use are a function of the requirements in the dependencies of DeepVariant. In this case, we need to use Python 3.8 as a result of those dependencies. You are right that updating to Python 3.11 might have speed advantages, but this is something we will have to look at over time as underlying libraries are updated. . With respect to GLnexus, we are expecting that there may be further updates to GLnexus, and will look at updates to that when those might become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/755#issuecomment-1865191737:651,avail,available,651,,https://github.com/google/deepvariant/issues/755#issuecomment-1865191737,1,['avail'],['available']
Availability,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions).; The core question here is: **Would you be able to get truth data for the bats you're studying**?. I quickly looked through your recent discussion with @kishwarshafin .; I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/878#issuecomment-2364726373:999,avail,available,999,,https://github.com/google/deepvariant/issues/878#issuecomment-2364726373,1,['avail'],['available']
Availability,"Hi @desmodus1984 ,; For many of the non-human applications, we see many use cases where people just apply our release models. ; I think directly using our model would be a good enough start for your downstream application. If you have some way to evaluate (e.g., Mendelian violation), then you can do some comparison to assess how good the calls are. If you have trio data, you can try to run DeepTrio (also using our release model) , which I think will be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/878#issuecomment-2333164220:199,down,downstream,199,,https://github.com/google/deepvariant/issues/878#issuecomment-2333164220,1,['down'],['downstream']
Availability,"Hi @dhwani2410 . Is there any chance that this is from a sample for which publicly available data is present (e.g. HG001). I could look at pileups in the region for a more informed opinion. To your question about different variants - DeepVariant classifies event on a position-by-position basis, so the classifier does not have information about what output it gave at nearby variants. This can cause you to know a bit more than the classifier when looking at its full output. But it explains why the classifier can have a different result when two variants are putatively phased. One phenomenon that we observe with DeepVariant is that it often calls positions with substantial support as reference when they are nearby to other variants. This seems to be related to regions of segmental duplication, where the apparent variants come from reads that are mismapped to the region. We have a poster which documents this effect: https://pbs.twimg.com/media/ERe2bSyWsAcE00h?format=jpg&name=4096x4096. So DeepVariant seems to learn something of the signature of segmental duplication and is likely not calling these positions as variant for this reason. On average, DeepVariant seems to be correct in these cases (that they are not true variants) more often than it is incorrect, which is why it has learned this pattern. However, it will not be correct in all cases. Either way, when you observe this pattern, it is a good idea to look at the region and consider whether the apparent variants may come from a duplication of related sequence.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/318#issuecomment-645810441:83,avail,available,83,,https://github.com/google/deepvariant/issues/318#issuecomment-645810441,2,['avail'],['available']
Availability,"Hi @dhwani2410 . The VCF DeepVariant generates does contain hom-ref calls, which are labeled with ""RefCall"" instead of ""PASS"" in the FILTER column. These are the positions that DeepVariant evaluated candidate variants at (due to signal in some reads) but found to be hom-ref. The gVCF includes many more positions that were not evaluated and is only needed for specific applications. It uses blocks to keep the file size reasonably short. For more information on the gVCF format, see our documentation page on that topic: https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md. From your question, it sounds like the VCF file has the information you need and works with the downstream tools you mentioned, so you may not need the gVCF file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/318#issuecomment-645470394:701,down,downstream,701,,https://github.com/google/deepvariant/issues/318#issuecomment-645470394,1,['down'],['downstream']
Availability,"Hi @dmarkie . Thank you for your feedback. We did struggle and discuss internally on the representation that we should use for the hemizygous calls to make. Ultimately, we decided to use 0/0 and 1/1 for our presumption that this would break fewer downstream methods. However, some of that is a subjective judgement. The compromise of having the option in postprocess to handle this is an interesting one. We'll talk internally about the amount of effort and maintenance to support this. I can't make a commitment to anything now, but it is a very reasonable proposal.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/751#issuecomment-1854763028:247,down,downstream,247,,https://github.com/google/deepvariant/issues/751#issuecomment-1854763028,4,"['down', 'mainten']","['downstream', 'maintenance']"
Availability,"Hi @dridk, my apologies, I didn't notice the branch for this pull request. We are no longer maintaining the r0.5 branch. However, thank you for the suggestion. We will keep an eye out for this kind of error in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/424#issuecomment-780948386:201,error,error,201,,https://github.com/google/deepvariant/pull/424#issuecomment-780948386,1,['error'],['error']
Availability,"Hi @duceppemo , can you clarify what error message you were seeing when you try with a BAM file with `.csi` indices?. I just tested with data from https://github.com/google/deepvariant/blob/r1.2/docs/deepvariant-quick-start.md. And I deliberately deleted the `.bai` index file and created a `.csi` instead:. ```; $ rm -f quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam.bai; $ samtools index -c quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam; $ ls quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam*; quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam; quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam.csi; ```. After that, it seems like I was still able to go through the Quick Start steps without any issues. DeepVariant is using htslib to read BAM files, and it seems like `.csi` is already supported there. Can you give me an reproducible example, if you're seeing any issues?. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/481#issuecomment-919633316:37,error,error,37,,https://github.com/google/deepvariant/issues/481#issuecomment-919633316,1,['error'],['error']
Availability,"Hi @eaooms , ; DeepVariant adds an additional channel to represent the HP information.; If you have some intermediate output of make_examples available, you can try using https://github.com/google/deepvariant/blob/r1.6.1/docs/show-examples.md to visualize them. In addition to the blog post, this preprint might provide the information that you need: https://doi.org/10.1101/2023.09.07.556731",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/823#issuecomment-2127458570:142,avail,available,142,,https://github.com/google/deepvariant/issues/823#issuecomment-2127458570,1,['avail'],['available']
Availability,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/680#issuecomment-1641138568:651,recover,recovered,651,,https://github.com/google/deepvariant/issues/680#issuecomment-1641138568,1,['recover'],['recovered']
Availability,"Hi @ekofman , sorry forgot to answer this one.; Looking at the error line:; ```; [E::fai_retrieve] Failed to retrieve block: error reading file; ```; It seems to me that it might be having some trouble reading from the reference FASTA file and its corresponding FAI file. Can you check with FASTA file (and corresponding FAI) file you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/164#issuecomment-476379583:63,error,error,63,,https://github.com/google/deepvariant/issues/164#issuecomment-476379583,2,['error'],['error']
Availability,"Hi @ekofman ,. I am unable to reproduce this FASTA querying error on my machine. Can you verify the md5sums of the files you have on your local machine? When I copy the above gs:// paths, I see. $ md5sum Homo_sapiens_assembly19.fasta*; 886ba1559393f75872c1cf459eb57f2d Homo_sapiens_assembly19.fasta; fdc0ab679f6461d78980de2a2e97e8f3 Homo_sapiens_assembly19.fasta.fai. and with those files can query the position 1:10147 successfully.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/164#issuecomment-476650890:60,error,error,60,,https://github.com/google/deepvariant/issues/164#issuecomment-476650890,1,['error'],['error']
Availability,"Hi @elcortegano . Thank you for the file, it's very informative, and I have a few observations that might help. First, all of the reads in this file which have sequence bases do have the correct number of quality values. The reads are not malformatted. However, there are reads with the SAM flag 256, secondary alignment. This occurs when the mapper finds a place which is almost or as good to map the reads to. Not all mappers report secondary alignments, and this is often controlled by a parameter. These reads have neither sequence bases, nor quality values, but do have a CIGAR string. I believe (but am not certain) that DeepVariant is attempting to parse these reads, and this is causing the error. I was not able to confirm, since I wasn't able to find the reference genome used to map. These reads can be validly ignored by DeepVariant. If this is the case, there are a few options to proceed. First, I believe that if you perform the command: . ```; samtools view -bh -F 256 file.bam > new_file.bam; ```. The file should now work with DeepVariant. . One thing it might be good to consider, based on my inspection of the CIGAR strings, I think these are likely HiFi reads. The program tag for minimap indicates the parameter -ax map-pb. I think that parameter is optimized for CLR. I believe the parameter for CCS/HiFi is -ax asm20. We usually take mapped BAM files from pbmm2, which wraps minimap2 with parameters optimized for HiFi. This could be why we didn't notice this exact issue before. If this is the source of your problem, our team can fix this behavior in future releases by ignoring flag 256 reads. You may want to consider mapping with pbmm2 as well (https://github.com/PacificBiosciences/pbmm2). If this does not fix your issue, could you please point me to the reference genome which you used to map to, I would need to try running DeepVariant and walk through the error more closely. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/434#issuecomment-815421572:699,error,error,699,,https://github.com/google/deepvariant/issues/434#issuecomment-815421572,2,['error'],['error']
Availability,"Hi @elcortegano . There are a few potential causes for this. First, you may want to extract this particular read and compare the number of bases in it against the number of base quality values (these will need to match). samtools view ${BAM} | grep m64036_210113_122249\/147655225\/ccs. should retrieve this particular read. One other thing which can cause this error is if the BAM file is truncated (for example if a download ran out of space). Could you check both of these (that the file isn't truncated, and that the read doesn't have an obvious problem) and provide a bit more information?. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/434#issuecomment-808822540:362,error,error,362,,https://github.com/google/deepvariant/issues/434#issuecomment-808822540,2,"['down', 'error']","['download', 'error']"
Availability,"Hi @esraaelmligy . One thing we find is that DeepVariant is much more conservative in assigning quality values compared to other callers. These values come from the probability of the call from the neural network. Generally, we observe that DeepVariant's probabilities are reasonably well-calibrated with empirical error rates. For an example of this, please see Figure 2 from the DeepVariant paper (https://www.nature.com/articles/nbt.4235 or the open preprint of the same work https://www.biorxiv.org/content/10.1101/092890v6.full.pdf). As a consequence, you should probably not filter in the same way as with other callers. You should likely have a lower threshold for DeepVariant calls.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/881#issuecomment-2354270901:315,error,error,315,,https://github.com/google/deepvariant/issues/881#issuecomment-2354270901,1,['error'],['error']
Availability,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/881#issuecomment-2359393776:75,toler,tolerance,75,,https://github.com/google/deepvariant/issues/881#issuecomment-2359393776,2,"['error', 'toler']","['error', 'tolerance']"
Availability,"Hi @fardokhtsadat . I realize in looking at the VCF entry, I was mistaken in saying DeepVariant sees a SNP and an Indel. In fact, it sees the candidates as you wrote. CAGCAGCGCT -> C; CAGCAGCGCT -> T. That's entirely on me, it should be clear from the VCF, and I don't have an excuse to make such a basic mistake. The call looks correct, it does look like a HET deletion of AGCAGCGCT. It looks like the realigner has decided to place a gap at this position and left-align the trailing T at the edge of the deletion so that when it is present it looks like a SNP. It's hard to authoritatively say why the realigner is going something without getting the actual BAM snippet and looking at the realignment. That part is in the heuristics of DeepVariant not the neural net. As a result of the re-alignment, DeepVariant sees the T SNP as a candidate but seems to correctly reject it. I think that's what's going on. In any case, a candidate here for the SNP seems to be a function of the realigner? . The behavior should not have changed from DeepVariant v1.2 to v1.5. In general, uncalled multiallelic events should be a relatively rare phenomenon. . Generally, if you need to, you can prune the alleles that are not called in DeepVariant VCF as long as the result of pruning stays compliant with the VCF spec expected by any downstream tools.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/618#issuecomment-1470986150:1322,down,downstream,1322,,https://github.com/google/deepvariant/issues/618#issuecomment-1470986150,2,['down'],['downstream']
Availability,"Hi @gambalab,. Thank you for the information. I tried using a Debian 11 docker image, and installed conda with python 3.8 but there seems to be other library conflicts. In the meantime if you want to have fun while your sysadmin performs a proper Docker install, you can run Docker in user-space using `udocker` in the following way:. https://indigo-dc.github.io/udocker/installation_manual.html. You don't need to install it as it say in the instructions. You can just do the following:. ```; wget https://github.com/indigo-dc/udocker/releases/download/1.3.9/udocker-1.3.9.tar.gz; tar xzvf udocker-1.3.9.tar.gz; cd udocker-1.3.9/udocker/; ./udocker pull google/deepvariant:1.5.0; ./udocker run google/deepvariant:1.5.0; ```. All the downloaded information is saved under the ` $HOME/.udocker` folder. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/669#issuecomment-1603444351:545,down,download,545,,https://github.com/google/deepvariant/issues/669#issuecomment-1603444351,2,['down'],"['download', 'downloaded']"
Availability,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/671#issuecomment-1610040880:264,Error,Error,264,,https://github.com/google/deepvariant/issues/671#issuecomment-1610040880,3,"['Error', 'error']","['Error', 'error']"
Availability,"Hi @genieusbio ,. One thing to note:. In https://gist.github.com/pichuan/baba6ee9bd9890be2a45076a4934dd38 , when you run `run_deepvariant`, this flag is specified: `--regions /input/idt_capture_novogene.grch38.bed`. Which means only the variants within the regions specified in the BED is used. If you look at the BED file:. ```; $ head -5 ./input/idt_capture_novogene.grch38.bed; chr1 69090 70008; chr1 450739 451678; chr1 685715 686654; chr1 925941 926013; chr1 930154 930336; ```. which does not include the region you're looking for. If you want to force call everything in that BAM file, you can simply remove the flag `--regions /input/idt_capture_novogene.grch38.bed` from your run. The downside is that will take longer. Or, if you just want to make sure that particular region is covered, then you can use @pgrosu 's suggestion and specify a small region that covers that range. Hopefully this is clear.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/708#issuecomment-1720730115:694,down,downside,694,,https://github.com/google/deepvariant/issues/708#issuecomment-1720730115,2,['down'],['downside']
Availability,"Hi @gneedle1 . It depends on the type of experiment. If the barcodes are the same sample and you are trying to get at some other specific property (e.g. cell type or preparation), then it's a question of sequencing coverage. If you will have enough coverage to make good quality calls within the reads of a single barcode (something like at least 15x-20x depending on your tolerance for errors), then subsetting by barcode could be reasonable. If you have less coverage, then the effects of reducing coverage will likely be much larger than whatever effect you are trying to detect. . If the barcodes separate different samples (i.e. those with different germline DNA), then the correct thing is to separate by barcode. I would need a little more information about the nature of the samples and what you are looking for to give you a more direct opinion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/772#issuecomment-1954778964:373,toler,tolerance,373,,https://github.com/google/deepvariant/issues/772#issuecomment-1954778964,2,"['error', 'toler']","['errors', 'tolerance']"
Availability,"Hi @gunjanbaid . Unfortunately I am not compiling for x86, but for IBM power, so most of the installation scripts need to be discarded, and packages need to be manually compiled from source using IBM's Advance Toolchain gcc compilers. I have finally gotten all bazel tests to complete as well as the build to complete. I was wondering whether you could explain one piece of the build files though - this is just out of curiosity. In build_release_binaries, there is a function that starts as follows - which seems to be performing a hack to fix something:; ```; # Bazel's --build_python_zip replaces our carefully engineered symbolic links; # with copies. This function puts the symbolic links back.; function fix_zip_file {; orig_zip_file=$1. # Step 1: Copy the zip file to a temporary place.; TMPDIR=$(mktemp -d -t tmp.XXXXXXXXXXX); # The .zip version of the binary doesn't have the header that makes it; # self-executable. We use that version because otherwise unzip would; # complain and raise an error code.; cp ""${orig_zip_file}.zip"" ""${TMPDIR}""; ```. Would you be able to give a quick explanation of what the problem is? I understand what it does, but I do not understand why it is needed, or whether it is just for convenience. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/356#issuecomment-699007209:1001,error,error,1001,,https://github.com/google/deepvariant/issues/356#issuecomment-699007209,1,['error'],['error']
Availability,"Hi @gunjanbaid I do not see the same issue now. I switched to openjdk-11. However, I still need to pass the --host_javabase option, which is not present by default in the build scripts. I do see another issue. The trace is as follows; ```; (02:26:24) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:413:1: ClifProtoLibraryGeneration third_party/nucleus/protos/bedgraph_pyclif.h failed (Exit 1): proto failed: error executing command; (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \; exec env - \; bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/bin/third_party/nucleus/protos/bedgraph_pyclif.cc -h bazel-out/ppc-opt/bin/third_party/nucleus/protos/bedgraph_pyclif.h '--strip_dir=bazel-out/ppc-opt/bin' '--source_dir='\''.'\''' third_party/nucleus/protos/bedgraph.proto). Execution platform: @bazel_tools//platforms:host_platform ; Traceback (most recent call last): ; File ""bazel-out/host/bin/external/clif/proto"", line 5, in <module>; from clif.python.proto import start ; File ""/root/opt/clif/lib64/python3.6/site-packages/clif/python/proto.py"", line 29, in <module>; from clif.python.utils import proto_util ; ImportError: libprotobuf.so.24: cannot open shared object file: No such file or directory. ```. This is for the following command from build_and_test.sh:; ```; bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \; deepvariant/...; ```. Why is bazel running ```exec env -``` here? This is invalidating library paths (LD_LIBRARY_PATH variable) where it would find ```libprotobuf.so```. As expected, when I run the failing command from the trace without ```exec env -```, it is fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/355#issuecomment-697093712:251,ERROR,ERROR,251,,https://github.com/google/deepvariant/issues/355#issuecomment-697093712,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi @gushenweiz,. A `RefCall` can happen for several reasons. Seems like you have a very high depth in this data. Would it be possible to downsample it to something between 90-100x and try again? It seems like the model does not think it's a variant based on the evidence. If you want to manually change the RefCall to pass then you have to do it on the VCF as a post-processing.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/750#issuecomment-1854506868:137,down,downsample,137,,https://github.com/google/deepvariant/issues/750#issuecomment-1854506868,1,['down'],['downsample']
Availability,"Hi @helizabeth1103 , the logic is in; https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`?. If you have that file, then this should be true:. ```; use_saved_model = tf.io.gfile.exists(; _CUSTOMIZED_MODEL.value; ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'); ```. And then:; ```; if use_saved_model:; logging.info('Using saved model: %s', str(use_saved_model)); ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/866#issuecomment-2285478515:293,checkpoint,checkpoints,293,,https://github.com/google/deepvariant/issues/866#issuecomment-2285478515,1,['checkpoint'],['checkpoints']
Availability,"Hi @hmkim - your BAM header looks okay to me. The first line `[E::hts_open_format] Failed to open file ...` indicates it may be an underlying samtools issue (since that seems to be an error message from htslib/samtools), are there any other lines from the error message, outputted earlier? Assuming that the path is correct, it should work. . The only thing I can think of with the provided info is to check that you have read permissions on the file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/141#issuecomment-455367612:184,error,error,184,,https://github.com/google/deepvariant/issues/141#issuecomment-455367612,2,['error'],['error']
Availability,"Hi @husamia . It looks like the error message is indicating that the disk is full, which can occur even when there is memory. Can you check how much hard disk space is present on the machine. If you are running low on space unexpectedly, you may want to check that you aren't accumulating space from Docker runs that weren't cleaned up by the system. It could be worth looking at [this page](https://docs.docker.com/config/pruning/) if that is the case.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/400#issuecomment-749251835:32,error,error,32,,https://github.com/google/deepvariant/issues/400#issuecomment-749251835,1,['error'],['error']
Availability,"Hi @husamia . Thank you for the question. The answer is a big complex. To summarize your question it is roughly. ```; The biggest issue that we have in calling de novos is managing ""false positive"" de novo events - not necessarily where the proband call is incorrect, but where a 0/1-0/0-0/0 call should be (for example 0/1-0/1-0/0). Will DeepTrio reduce the number of these calls.; ```. Calls in DeepVariant which are 0/1-0/0-0/0 where a human inspection in IGV shows evidence in the parent are generally caused by:. 1. Reads which have a MAPQ below the threshold that DeepVariant sees (MAPQ < 5). ; 2. Regions which DeepVariant seems to think may represent a segmental duplication where reads are mapped from a different region. In these cases, DeepVariant can all a position as 0/0. In terms of overall precision, DeepTrio has higher precision on de novo calls (0/1-0/0-0/0) than DeepVariant [tables for this are in the manuscript](https://www.biorxiv.org/content/10.1101/2021.04.05.438434v1). In the cases that you mention, DeepTrio will more often designate the parent as a nocall (0/1-./.-0/0) for example. The genotype quality in the parents in DeepTrio can be useful for reducing the Type II error that you mention. If you want to further reduce these positions, I expect it would be possible to post-filter using the coverage values for the parent calls in the VCF (further filtering those that have a reasonable number of AD for ALT reads). We'll also consider whether including that during the VCF generation could make sense. Please let me know if this didn't answer your question.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/450#issuecomment-829516306:1200,error,error,1200,,https://github.com/google/deepvariant/issues/450#issuecomment-829516306,1,['error'],['error']
Availability,"Hi @husamia . The openVINO acceleration occurs at the call_variants stage, not during make_examples. If you are running from the Docker image, each stage should report its runtime in standard error. I would use that reported time for the call_variants stage to assess whether there is any improvement.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/408#issuecomment-766309733:192,error,error,192,,https://github.com/google/deepvariant/issues/408#issuecomment-766309733,1,['error'],['error']
Availability,"Hi @internalsensor , please see my answer below.; (And, can you give us some feedback on why you don't use the Docker version, but decided to use the prebuilt binaries instead? Thank you!). ===; Hi @internalsensor , ; I think it's likely what @pgrosu said about multiple versions installed. It'll be useful to figure out what actually got used. I was not able to reproduce the error you found.; In case it's useful, here is what I did to try to reproduce. I used a modified version of the WES script, in which I made sure I pip install a pinned version of intervaltree, and I downloaded the prebuilt binaries instead of rebuilding on my own:. ```; git clone https://github.com/google/deepvariant.git; cd deepvariant; wget https://gist.githubusercontent.com/pichuan/5a1216e080ccaf286810af062d6cb7a2/raw/20f6b3e9473b8f2e7d520edace1f2bb7a7231f06/run_wes_case_study_prebuilt_binaries.sh; bash -x run_wes_case_study_prebuilt_binaries.sh; ```. This worked with the prebuilt binaries v0.7.2. So I wasn't able to reproduce your error.; You can also use `pip show intervaltree` to double check what pip package you have.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/155#issuecomment-464534790:377,error,error,377,,https://github.com/google/deepvariant/issues/155#issuecomment-464534790,6,"['down', 'error']","['downloaded', 'error']"
Availability,"Hi @jaspez yeah my apologies - when I read your comment more carefully, it seemed like you used `1`, so I removed my previous answer. `--gvcf_gq_binsize=1` will only merge records when they have identical GQ values, so there would be no loss of information at least in terms of GQ, but as you already saw this will not be exactly the same as what you specified (single line per position). Unfortunately we do not currently have an option to keep every single non-variant position, as this would make the gVCF files extremely large. In general I'd recommend not doing this anyway, since this will eventually slow down any downstream processing of the gVCFs such as merging gVCFs using GLnexus, etc. I think the easiest way to achieve this would be by post-processing the gVCFs generated with `--gvcf_gq_binsize=1`. For example, the `break_blocks` option in [gvcftools](https://sites.google.com/site/gvcftools/home/configuration-and-analysis) seems to do this, based on an answer in this [forum](https://www.biostars.org/p/136461/). May I ask what is your use case that prefers every non-variant position to be written?. Best,; Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/282#issuecomment-954067904:612,down,down,612,,https://github.com/google/deepvariant/issues/282#issuecomment-954067904,2,['down'],"['down', 'downstream']"
Availability,"Hi @jaydevshelat . DeepVariant's checkpoints are based on InceptionV3 and use slim, see https://github.com/google-research/tf-slim. I can share with you some code that @pichuan has written to read the checkpoints, but if you have any further questions on that, please consult the documentation for tensorflow or tf-slim.; ```; ! pip install tf-slim. import tensorflow.compat.v1 as tf; import os; import tf_slim as slim; from tf_slim.nets import inception_v3. !gsutil cp gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard/model* /tmp/; ckpt_file = '/tmp/model.ckpt'. graph = tf.Graph(). with graph.as_default():; images = tf.placeholder(tf.float32, shape=(None, 100, 221, 6)). with slim.arg_scope(inception_v3.inception_v3_arg_scope()):; _, end_points = inception_v3.inception_v3(images, is_training=False, ; num_classes=3,; create_aux_logits=False); ; print(""end_points:""); print(end_points.keys()); # Restore the checkpoint; sess = tf.Session(graph=graph); saver = tf.train.Saver(); saver.restore(sess, ckpt_file); ```. For training, you would need a lot more training data than the quickstart-testdata, as in multiple samples of WGS worth of sequencing data. For more information on training, see the documentation: https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/339#issuecomment-682069726:33,checkpoint,checkpoints,33,,https://github.com/google/deepvariant/issues/339#issuecomment-682069726,3,['checkpoint'],"['checkpoint', 'checkpoints']"
Availability,"Hi @jdmontenegro . For the question about multi-allelic heterozygous calls - yes, DeepVariant is able to all 1/2 events, and will represent these in one line as a GT 1/2 call in the VCF. For CLR calling in DeepVariant. It is theoretically possible for us to make a model for DeepVariant that can call CLR data. However, this requires us to write a special candidate generation logic to deal with the higher error rate. Based on what we perceive for the direction of future use in the genomics community, we think that data generated will be increasingly HiFi, so we have not been able to highly prioritize CLR models. Feedback from users like yourself will be useful to us in evaluating if that prioritization makes sense. For now, I can't commit to a timeframe under which we would support a PacBio CLR model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/347#issuecomment-693053180:407,error,error,407,,https://github.com/google/deepvariant/issues/347#issuecomment-693053180,1,['error'],['error']
Availability,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision?. You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors?. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334644453:325,error,errors,325,,https://github.com/google/deepvariant/issues/879#issuecomment-2334644453,2,['error'],['errors']
Availability,"Hi @jumpyknight ,. We have also noticed that when warmstarting from a checkpoint, there seems to be dip in accuracy at the beginning. You can see an example like this in this plot in our training case study from r0.7:; https://raw.githubusercontent.com/google/deepvariant/r0.7/docs/images/TensorBoardAccuracy.png. And specifically, for a while it was puzzling to us why model.ckpt-0 was much less accurate. After looking much closely into TensorFlow and the behavior or warmstarting, here is what we found:. It turns out that there's some subtlety to what exactly gets loaded in warm starting. It's documented here:; https://www.tensorflow.org/api_docs/python/tf/train/warm_start; Specifically, this:; ```; vars_to_warm_start: [Optional] One of the following:; * A regular expression (string) that captures which variables to warm-start (see tf.get_collection). This expression will only consider variables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option.; ```; Because in our code, we use a regular expression like this:; https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start.; This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:; ```; vars_to_warm_start=['|'.join(vars_to_include)]); ```; which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/185#issuecomment-494919509:70,checkpoint,checkpoint,70,,https://github.com/google/deepvariant/issues/185#issuecomment-494919509,2,['checkpoint'],['checkpoint']
Availability,"Hi @jumpyknight . Which GIAB sample are you using and which version of the truth set? For HG002, there is a new truth set (v4.1) - ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4.1_SmallVariantDraftBenchmark_12182019/. Which corrected a number of errors in the prior truth set. If you are using v3.3.2 for this sample, it would be interesting to know if those have been corrected. To you question about the type of variants that occur. Yes, it is known that repeat expansion and contraction is more likely to occur, and these tend to add to the full repeat content. So it is not unexpected to see changes in repeat number. . To your question about whether this may have caused DeepVariant to be more prone to call reference, I think the proportion of errors in Genome in a Bottle is quite small. DeepVariant is very accurate, so these may be a reasonable fraction of the total apparent errors, but they are not a large fraction of the total training sites. I don't think that the presence of errors in the training set will have a large impact on DeepVariant, but I it may make DeepVariant just a bit worse than it could otherwise.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/317#issuecomment-645804554:278,error,errors,278,,https://github.com/google/deepvariant/issues/317#issuecomment-645804554,4,['error'],['errors']
Availability,"Hi @kalexiou ,; I think what might have happened is that the make_examples stage ran out of memory.; I recently had a run on a different BAM, which had similar behavior as you described. A few suggestions:; (1) If you're using the same type of machine, try running with fewer number of num_shards which should allow each make_examples to have more RAM.; (2) If you can try a different machine type, try n1-highmem-16 (104GB RAM) to see if that helps. We're looking into how we can make our error messages informative if this is the key issue. Based on this observation, I suspect your intermediate make_examples output might not be complete.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/427#issuecomment-793438811:490,error,error,490,,https://github.com/google/deepvariant/issues/427#issuecomment-793438811,1,['error'],['error']
Availability,"Hi @kalexiou ,; if the file is not public, unfortunately I cannot download it or test it. Thanks for offering though. If you can share a bit more about what type of file this is (sequencing instrument, coverage, PCR-free or PCR-plus, etc) that might make this file unique, maybe I can try to see if I can reproduce the issue on another public file. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/427#issuecomment-789122414:66,down,download,66,,https://github.com/google/deepvariant/issues/427#issuecomment-789122414,1,['down'],['download']
Availability,"Hi @karoliinas ,; From your log, it seems like the DeepVariant model has made a prediction with unexpected numerical value. From your log, I'm unable to tell why this has occurred. In this command:. `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz""`. If you can share the `sample1.intermediate/call_variants_output.tfrecord.gz` (and optionally`sample1.intermediate/gvcf.tfrecord@19.gz` files) with me, I can able to look into the records and see which example has this issue. (Or, if you can narrow this down to a small BAM file, and if you can share that BAM file, that works too). Please email to pichuan@google.com if you can share. If you can't share the files, we can think about what we can do here to help identify which example caused the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/849#issuecomment-2221028135:1023,down,down,1023,,https://github.com/google/deepvariant/issues/849#issuecomment-2221028135,1,['down'],['down']
Availability,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:; 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you); 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/849#issuecomment-2233667709:661,error,error,661,,https://github.com/google/deepvariant/issues/849#issuecomment-2233667709,1,['error'],['error']
Availability,"Hi @kishwarshafin ,. No worries, thanks for finding the time to get back to me! And thanks for the explanation - I had read that line in the log file ""Not including more"", as it is including some. . So the truth data is generated from the offspring of 5 trios. Variants for the parents and offspring were called (using GATK4) against a reference, mendelian expectations were checked for each locus, and the loci that passed that check, as well as some hard filters (e.g. depth, GQ etc), were kept for the truth set. . The variants in the truth set are the combination of all the variants that passed these filters in all 5 trios, which amounts to around 450,000 variants (split into ~350k training, and ~100k for tuning). The reference is from a different population which which will probably result in more hom_alt SNPs against the ref, but other than that, I don't think this number of SNPs is particularly high for a 400Mb genome of a wild fish with relatively large pop sizes. The 0.5x downsampling of course doubles this number, resulting in ~900,000 truth vars in total. . So, could a solution be to increase the maximum for genotype_options_product? Or would you suggest subsampling the truth variants? . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/876#issuecomment-2336577721:990,down,downsampling,990,,https://github.com/google/deepvariant/issues/876#issuecomment-2336577721,1,['down'],['downsampling']
Availability,"Hi @kishwarshafin . I did install Singularity in a conda environment and then I used the singularity installed in the HPC, and in both systems I couldn't download the container.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/886#issuecomment-2378167772:154,down,download,154,,https://github.com/google/deepvariant/issues/886#issuecomment-2378167772,1,['down'],['download']
Availability,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:; [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:; [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/876#issuecomment-2345422270:269,error,error,269,,https://github.com/google/deepvariant/issues/876#issuecomment-2345422270,1,['error'],['error']
Availability,"Hi @kishwarshafin,. Thank you for explaining the details of the down sampling process. - a. We perform a downsampling of reads on a given window to ensure the processing time is manageable. Some reads may be discounted during this process.; - b. For a specific variant, reads with lower mapping quality will not be counted.; - c. For a specific variant, reads that contain that variant with lower base quality than the set threshold are discounted. For positions with higher than 100x coverage, is the downsampling performed sequentially as mentioned above? ; If not, is it randomly or specific process?. Thank you for your assistance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/836#issuecomment-2230517419:64,down,down,64,,https://github.com/google/deepvariant/issues/836#issuecomment-2230517419,3,['down'],"['down', 'downsampling']"
Availability,"Hi @kishwarshafin,. The training process starts as expected with GPU activity visible, but it abruptly stops without any error message while processing the first epoch and determining the best checkpoint metric (code snippet). This step completes as expected when using the CPU image with the same dataset and parameters. Initially, I thought TensorRT issues might be causing this stop, but I'll share the logs with you to get your perspective and an extra set of eyes on the problem. **Command:** ; ```; ( time sudo docker run --runtime=nvidia --gpus 1\; -v ${HOME}:${HOME} \; -w ${HOME} \; google/deepvariant:1.6.1-gpu \; train \; --config=""${BASE}/dv_config.py"":base \; --config.train_dataset_pbtxt=""${BASE}/training_set.pbtxt"" \; --config.tune_dataset_pbtxt=""${BASE}/validation_set.pbtxt"" \; --config.init_checkpoint=""${BASE}/checkpoint/deepvariant.wgs.ckpt"" \; --config.num_epochs=10 \; --config.learning_rate=0.0001 \; --config.num_validation_examples=0 \; --experiment_dir=${TRAINING_DIR} \; --strategy=mirrored \; --config.batch_size=512 \; ) > ""${LOG_DIR}/train.log"" 2>&1 &; ```; ```; I0508 17:53:46.544947 140534986602304 train.py:384] Starting epoch 0; I0508 17:53:46.545100 140534986602304 train.py:391] Performing initial evaluation of warmstart model.; I0508 17:53:46.545171 140534986602304 train.py:361] Running tune at step=0 epoch=0; I0508 17:53:46.545287 140534986602304 train.py:366] Tune step 0 / 15 (0.0%); I0508 17:54:10.069682 140512707213056 logging_writer.py:48] [0] tune/categorical_accuracy=0.22617188096046448, tune/categorical_crossentropy=1.3209192752838135, tune/f1_het=0.02283571846783161, tune/f1_homalt=0.09889934211969376, tune/f1_homref=0.843934178352356, tune/f1_macro=0.3218897581100464, tune/f1_micro=0.22617188096046448, tune/f1_weighted=0.21346084773540497, tune/false_negatives_1=6123.0, tune/false_positives_1=5727.0, tune/loss=1.3209190368652344, tune/precision_1=0.21375617384910583, tune/precision_het=0.19323670864105225, tune/precision_homalt=0.05127762",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/819#issuecomment-2101161904:121,error,error,121,,https://github.com/google/deepvariant/issues/819#issuecomment-2101161904,3,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"Hi @koido ,; sorry that it took me a while to get back to this again.; Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:; https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227; And the location where the checkpoints are saved was specified earlier:; https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/127#issuecomment-449040624:133,checkpoint,checkpoints,133,,https://github.com/google/deepvariant/issues/127#issuecomment-449040624,3,['checkpoint'],"['checkpoint', 'checkpoints']"
Availability,"Hi @kokyriakidis ,; in this thread (when it was still r0.8), running `././build-prereq.sh && ./build_release_binaries.sh` fixed the original user's question. In the latest release (r0.9), it should work even if you run `build_and_test.sh` instead of `build_release_binaries.sh`. The main trick was this `fix_zip_rule` that makes sure the symbolic links are correct:; https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/build_release_binaries.sh#L41. In the issue that you reported in bcbio/bcbio-nextgen#3048, there is one more layer because you're using bioconda. I'm surprised that your issue was actually with v0.9.0. Given that we actually fixed `build_and_test.sh` in the latest version. @kokyriakidis Two questions for you:; 1. With bioconda, were you able to run with v0.8.0 like @chapmanb suggested?; 1. Did you actually try building DeepVariant binaries on your own? If you tried, did that work for you or did you get the same error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/199#issuecomment-570115804:968,error,error,968,,https://github.com/google/deepvariant/issues/199#issuecomment-570115804,1,['error'],['error']
Availability,"Hi @kokyriakidis . That reference should mask the PAR regions. It's unclear what could be going on for those variants which DeepVariant calls. They may be FP variants in difficult regions, or could be positions where additional copies exist that are similar on autosomes. In general, there are always likely to be some calls made on chrY. For reference, the New York Genome Center has sequenced all 1000genomes at 30x coverage and mapped to hg38. For the NA12878 (a female sample), GATK4 makes 6,935 heterozygous variant calls and 6,422 homozygous variant calls. (This VCF file is available at: http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20190425_NYGC_GATK/raw_calls/CEU/Sample_NA12878/analysis/NA12878.haplotypeCalls.er.raw.vcf.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/196#issuecomment-513911038:41,mask,mask,41,,https://github.com/google/deepvariant/issues/196#issuecomment-513911038,2,"['avail', 'mask']","['available', 'mask']"
Availability,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using?. Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/196#issuecomment-511731809:604,mask,mask,604,,https://github.com/google/deepvariant/issues/196#issuecomment-511731809,2,"['Error', 'mask']","['Errors', 'mask']"
Availability,"Hi @kostasgalexiou , can you provide more information like:; - What type of machines are you working on (how many cores, how much RAM); - Any error messages that you can share?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/427#issuecomment-788314979:142,error,error,142,,https://github.com/google/deepvariant/issues/427#issuecomment-788314979,1,['error'],['error']
Availability,"Hi @kostasgalexiou ,; Looking at the file size, they look reasonable, but I can't tell exactly whether they're complete or not.; You can certainly try directly to run call_variants. If some of the records are not complete or corrupted, call_variants or postprocess_variants might give you an error later on. I'm still curious on why it didn't finish though. If you have more new observations or logs that might be informative, please let me know. I suppose your input BAM file is not public? If it is public, I would love to try to reproduce your issue on a n1-standard-16 machine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/427#issuecomment-789115542:292,error,error,292,,https://github.com/google/deepvariant/issues/427#issuecomment-789115542,1,['error'],['error']
Availability,"Hi @leorippel . In your log, the error says:; ```; 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory; ```; Can you confirm that you actually have this file? From what you described earlier, you're trying to rename files into this format, but I'm not sure what you actually rename them to.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/413#issuecomment-767954630:33,error,error,33,,https://github.com/google/deepvariant/issues/413#issuecomment-767954630,1,['error'],['error']
Availability,"Hi @li1ba . Thank you for the BAM file, I've been able to download it and look at the region in IGV. To my eye, I can't see the reason DeepVariant is calling 0/1 based on the pileup I see. We're going to run a few experiments with this and see if we can identify either something DeepVariant sees that we don't or if this is highlighting some sort of edge case or bug in the code.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/592#issuecomment-1334238783:58,down,download,58,,https://github.com/google/deepvariant/issues/592#issuecomment-1334238783,1,['down'],['download']
Availability,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334737190:653,down,downloaded,653,,https://github.com/google/deepvariant/issues/879#issuecomment-2334737190,4,"['down', 'error']","['downloaded', 'error', 'errors']"
Availability,"Hi @lucasbrambrink,. I actually tried with different batch_size (32 and 512) but the batch_size takes longer so I switched to 512. I also tried with epoch=10 but still have encountered the same error. I just updated my error log file with the error ```No checkpoint found.```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2033267320:194,error,error,194,,https://github.com/google/deepvariant/issues/802#issuecomment-2033267320,4,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"Hi @lykstudio,. Ultima has a separate fork of deepvariant.; It's not completely public yet.; Please contact me at doron.shemtov@ultimagen.com for further details for early access. See usage instructions below. Best,; Doron. # Generating unfiltered germline callset. ## Requirements. The workflow below assumes that you have a sorted, duplicate marked UG BAM/CRAM file. ; We also assume that you built the UG DeepVariant docker (>=1.4.12) per separate instructions file.; Official gatk and picard installations are required. . ### Files required for the analysis (download locally); The following files are publicly available:. gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta; gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai; gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.dict; gs://gcp-public-data--broad-references/hg38/v0/wgs_calling_regions.hg38.interval_list. ### UG-specific files; DeepVariant model files ; * WGS calling (model 1.2); ```; gs://concordanz/deepvariant/model/germline/v1.2_rc2/model.ckpt-710000.data-00000-of-00001; gs://concordanz/deepvariant/model/germline/v1.2_rc2/model.ckpt-710000.index; gs://concordanz/deepvariant/model/germline/v1.2_rc2/model.ckpt-710000.meta; ```. DeepVariant-ug docker container:; ```; gcr.io/ganymede-331016/deepvariant:ug-1.4.13; ```. ## Generating whole genome callset . Instructions below require ability to run whole genome DeepVariant. DeepVariant is split into 3 stages: make_examples, call_variants, and postprocess_variants. We normally run make_examples on a genome split into 200 equal intervals in parallel through cromwell engine, but any parallelization engine will do. Each make_examples process creates examples.tfrecords.gz file which contains a single image and variant metadata for each candidate. The set of tfrecords file is read by call_variants as a single tensorflow dataset. call_variants runs optimally on a machine which contains a single g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/711#issuecomment-1734891580:563,down,download,563,,https://github.com/google/deepvariant/issues/711#issuecomment-1734891580,2,"['avail', 'down']","['available', 'download']"
Availability,"Hi @maca8e . You are correct that DeepVariant_unfiltered is a preferable preset for DeepTrio calling. We had meant to update that in the case study documentation for the most recent release, and failing to do so is an oversight that we will correct. The DeepTrio paper does describe the unfiltered preset as preferable, and it should be reflected here. . With respect to a reference for DeepTrio's workings, have you seen the [DeepTrio preprint](https://www.biorxiv.org/content/10.1101/2021.04.05.438434v1)? If so, is there an item you would like described in greater detail. With respect to why NA12891/NA12892 are not used for training the parent model, this is simply because NIST does not have a truth set for these samples, while a truthset from NIST is available for HG001.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/475#issuecomment-892390206:759,avail,available,759,,https://github.com/google/deepvariant/issues/475#issuecomment-892390206,2,['avail'],['available']
Availability,"Hi @mallikag9 . I don't see a BED file for the exome regions in your command. For exome, we typically restrict to the capture regions of the exome (sometimes with a 100bp pad region). . You can download the capture regions with this command:. ```; HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/idt_capture_novogene.grch38.bed > input/idt_capture_novogene.grch38.bed; ```. and add `--regions /input/idt_capture_novogene.grch38.bed` to the command.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/735#issuecomment-1817582712:194,down,download,194,,https://github.com/google/deepvariant/issues/735#issuecomment-1817582712,1,['down'],['download']
Availability,"Hi @mano2991 , Two questions:; (1) Can you tell me what environment (e.g., OS, version) you're running this on? ; There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run.; (2); Can you try rerunning with:; `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/231#issuecomment-548147127:170,error,error,170,,https://github.com/google/deepvariant/issues/231#issuecomment-548147127,3,['error'],['error']
Availability,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/520#issuecomment-1559853651:244,error,errors,244,,https://github.com/google/deepvariant/issues/520#issuecomment-1559853651,3,['error'],['errors']
Availability,"Hi @maryawood . It might be possible to train a classifier in this manner, but it is certainly outside the use cases which we would typically train for. If you are looking for an assessment of how ""confident"" DeepVariant is in a call, I would recommend you take a look at the ""GQ"" field. This PHRED value is quite well calibrated with the probability of a caller error in our investigations (see: Figure2 of [the original DeepVariant paper](https://www.nature.com/articles/nbt.4235). If possible using GQ may be more informative than training a model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/454#issuecomment-836125971:363,error,error,363,,https://github.com/google/deepvariant/issues/454#issuecomment-836125971,1,['error'],['error']
Availability,"Hi @may199128 ,. There can be several reasons for that:. > 1. PacBio Direct Data (top track): Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). The lower GQ can be caused by several issues. If this is a variant dense region, then the model can be less confident in correctly calling the variant. Given that it looks like a structural variant, have you considered using a structural variant caller like [PBSV](https://github.com/PacificBiosciences/pbsv) for these cases?. > 2. For the PacBio Capture data (bottom track) has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF?. The could be several reasons for seeing the difference: ; a. We perform a downsampling of reads on a given window to make sure the processing time is manageable. So, some reads can get discounted during that process.; b. For a specific variant, reads with lower mapping quality will not be counted.; c. For a specific variant, reads that contain that variant with lower base quality then set is discounted. Please note that our pileup image height is 100, so we can only represent 100 reads per variant within an example. Having 3000x would mean the reads will be downsampled to a fraction that can be represented in the example. Please let me know if you have any other questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/836#issuecomment-2189741503:1067,down,downsampling,1067,,https://github.com/google/deepvariant/issues/836#issuecomment-2189741503,2,['down'],"['downsampled', 'downsampling']"
Availability,"Hi @mclaugsf,. Let me give you a bit more context here on the runtime of call_variants. call_variants is the deep learning component of DeepVariant, so it relies on TensorFlow to execute the inception_v3 model used to evaluate our genotype likelihoods. In the 0.7 case study, make_examples creates 5,847,041 genomic tensors that need to be evaluated. When executing using CPUs, TensorFlow by default uses all of the available cores on the machine. So in our case study, which runs on a 64 core machine, we are using all 64 cores to evaluate these tensors. . So a rough estimate of the core-hours needed for the DeepVariant WGS case is:. 64 cores * 205 minutes of runtime ~= 219 core hours ~= 9 days. So if you are running on a machine with a single core, you should see call_variants take ~9 days. This is a bit of an over-estimate because 64 cores isn't 64x more efficient than 1 core. . Based on your 1 day turn around I'd guess you are running on a machine with 8 cores. Note these numbers assume you are using a modern CPU with AVX etc instruction sets. Not having those can increase the runtime by ~4x or so. Also I want to ask - in your original post are you processing exomes? If so, are you providing a capture regions bed to make_examples? Normally an exome produces < 100k examples (contrast that with 5.8M in a whole genome) so the runtime should be 60x less on an exome. That means instead of 9 days on a single core you are looking at 3.5 hours.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/105#issuecomment-430736386:416,avail,available,416,,https://github.com/google/deepvariant/issues/105#issuecomment-430736386,2,['avail'],['available']
Availability,"Hi @melkerdawy , thanks for reporting this issue.; In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:; What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files.; To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:; ```; class 0, count: 101,679,899; class 1, count: 145,911,730; class 2, count: 98,914,057; ```; There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/203#issuecomment-518462111:661,checkpoint,checkpoints,661,,https://github.com/google/deepvariant/issues/203#issuecomment-518462111,2,['checkpoint'],['checkpoints']
Availability,"Hi @moldach . Thank you for the header data. The chromosome names in the BAM (I, I, III, IV, V, X, MtDNA) differ from those in your original reference file (chrI_pilon, chrII_pilon), etc... This is what is causing the first error, DeepVariant requires chromosome names to match in order to run. The second error is a bit harder to diagnose, but I would guess this is because the sequence of your reference genome does not extend as far as some of the mapping positions in the BAM file. My suspicion is that the reference length is mismatched, but it might be possible that the reference sequence ends in real genomic DNA that reads are mapping to (and then extending beyond the reference length) and this causes DeepVariant to fail (I haven't seen this before, but it could be a plausible behavior). I think the safest thing is to remap the reads to what you know for sure is the same reference you will call on, and let me know if this issue remains. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/292#issuecomment-608968890:224,error,error,224,,https://github.com/google/deepvariant/issues/292#issuecomment-608968890,2,['error'],['error']
Availability,"Hi @moldach ; somehow your logs above have a lot of spaces in the middle, making it hard to read. It seems like the last step was looking for `/scratch/moldach/bin/quickstart-output/output.vcf.gz` but couldn't find it. . I'll walk through the steps again to see if I can reproduce your error, but meanwhile, can you try:. ```; singularity run -B $PWD,/usr/lib/locale/ \; ```. instead of . ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; ```. And see if it works for you? Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-606340201:286,error,error,286,,https://github.com/google/deepvariant/issues/287#issuecomment-606340201,1,['error'],['error']
Availability,"Hi @moldach,. The error message indicates that the sequence contig names present in the reference genome don't match those in the BAM file. . It would be useful to know the names and lengths of the contigs in the BAM header. Are you able to provide the output of this command:. samtools view -H maddog_bam_trim_bwaMEM_sort_dedupped.bam | grep \@SQ. Thank you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/292#issuecomment-607119273:18,error,error,18,,https://github.com/google/deepvariant/issues/292#issuecomment-607119273,1,['error'],['error']
Availability,"Hi @mosh305 ; I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-450422508:265,error,errors,265,,https://github.com/google/deepvariant/issues/128#issuecomment-450422508,1,['error'],['errors']
Availability,"Hi @ndesar . We do have a prototype implementation for somatic calling, which can take a tumor and normal BAM and call subclonal variants. However, we don't yet have enough confidence in the available truth sets, and that they come from a diverse enough sampling of cancers with mutational profiles, for us be certain in releasing something of high quality. From the title of your issue, is it correct that you have PacBio HiFi data for a tumor line? This is interesting, we're keeping an eye on adoption of HiFi data for cancer sequencing, since it has potential to improve some of the truth sets. For the present, we don't have a widely released method you can use for somatic calling, and this isn't on the immediate roadmap. However, hopefully in the medium-to-long term this is an area we'll be able to get to.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/352#issuecomment-696511944:191,avail,available,191,,https://github.com/google/deepvariant/issues/352#issuecomment-696511944,1,['avail'],['available']
Availability,"Hi @observer2735,. So your depth is very high, which either indicates that you are trying to measure something with very low VAF (which this is not the case with a value of 0.4), or you might have duplicated parts of the genome or are working with very small genomic region. Now having said that, you could try down-sampling your region to something along the lines of 80-100, and see if the call changes. Keep in mind, the pileup images for DeepVariant are ~100 reads, so it will randomly down-sample from the reads to fit into the maximum of the allowed pileup image. . You seem to have one call that was rejected, meaning a RefCall entry of a proposed candidate but rejected as non-variant by the model, and then uncalled (`./.`) because your GQ is less than 20. Your QUAL is 0, indicating there is no variant there. Your GQ is around 11-12, which this is just a RefCall based on the model. The reason your read depth (DP) is smaller than the number of rows you are counting might be that it locally realigned the reads, and then the allele counter got a different number for the DP given a different number of supporting reads. Probably looking at your BAM in IGV might help to confirm. Also aligning to [GRCh38 without ALT contigs](https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/references/GRCh38/GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta.gz) might also be a better option to try than hg19 for generating the BAM files, and then also using that as a reference in DeepVariant -- as DeepVariant assumes the same reference was used during the mapping when generating the BAM files. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/697#issuecomment-1680213963:311,down,down-sampling,311,,https://github.com/google/deepvariant/issues/697#issuecomment-1680213963,2,['down'],"['down-sample', 'down-sampling']"
Availability,"Hi @obsh, I am still not sure what is causing the failure. I noticed that you are using an older release (v0.6.1), so I would suggest switching to the latest v0.8.0 release. I'm not sure that this will address the failures, but I would recommend it regardless since we have updated the code and models. . As a sanity check, you could try running the command above with different data. [This page](https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration) contains an example using Whole Exome Sequencing (WES) data. If the problem is fixed, perhaps there is something unexpected about your data, and we can further investigate. We also recommend that you try directly running DeepVariant through the Docker image, which may provide additional error messages that are helpful for debugging. You can refer to [this document](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) for an example. Please let us know if you run into the issue through this setup. One thing to note: our models have been trained using human data, and may not necessarily generalize well across species. We have trained a model for mosquito data, and while doing so, we noticed that retraining using data from this species significantly improved performance (more details in [this post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/)). The mosquito model is not public, but we are happy to share it with you. Feel free to email me at gunjanbaid@google.com for more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/207#issuecomment-524686835:50,failure,failure,50,,https://github.com/google/deepvariant/issues/207#issuecomment-524686835,3,"['error', 'failure']","['error', 'failure', 'failures']"
Availability,"Hi @one-matrix ,. From your original post, you mentioned you ran `python deepvariant/call_variants.py`. That won't work in DeepVariant setup. For DeepVariant, all binaries needs to be built with bazel. Unlike other pure Python setup, simply `python` a .py file won't execute it correctly. This is documented in the https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md page that @danielecook mentioned before. But, for extra clarity, let me run through it again, and write it down below for your reference. Here is an example of how I build and execute DeepVariant binaries:. # First, get a machine to run. In my example, I used a machine from GCP, using a command like this: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-details.md#command-for-a-cpu-only-machine-on-google-cloud-platform. ```bash; gcloud compute instances create ""${USER}-cpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-64"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. # ssh into the machine, and get the latest DeepVariant repo. Then, I ssh into the machine:. ```bash; gcloud compute ssh ${USER}-cpu --zone us-west1-b; ```. Then I get the repo:. ```bash; git clone https://github.com/google/deepvariant.git; cd deepvariant; ```. Following in the instructions in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md. I first run:. ```bash; sudo su; ```. and then:. ```bash; ./build-prereq.sh; ```. This step does a lot of stuff, including checking out other repos such as clif and tensorflow, and using that as part of the build environment. On my machine that I tested with just now, it took me 10m56.021s. and then run:. ```bash; ./build_and_test.sh; ```. This step took about 7min on my machine. . The [build_and_test.sh](https://github.com/google/deepvariant/blob/r1.6/build_and_test.sh) script is",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872:501,down,down,501,,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872,2,['down'],['down']
Availability,"Hi @pgrosu and @AndrewCarroll . - My variant doesn't fall close to an exon border. ; - I've used the RNA-model from here: [RNA-model](https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard). ; - You are correct, I have a diplod human germline sample. ; - The variant is neither in the ENCODE blacklist nor in RepeatMasker, however the Umap M24 track has a value of 0.375.; - The MAPQ value is 28.5, which shouldn't be a problem; - The coverage of the region is high, because the transcript is abundant (TPM is 1100). . My guess would be that this problem arises from downsampling? The depth at this site is almost 4000X.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/701#issuecomment-1696908264:632,down,downsampling,632,,https://github.com/google/deepvariant/issues/701#issuecomment-1696908264,1,['down'],['downsampling']
Availability,"Hi @pgrosu, thanks very much for the help with troubleshooting. . 1. affinity.c compilation run into error: . ```; ./affinity; pthread_setaffinity_np: Invalid argument.; ```. ```; 2. cat /proc/sys/kernel/threads-max; 2061146; lscpu; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 32; On-line CPU(s) list: 0-31; Thread(s) per core: 1; Core(s) per socket: 16; Socket(s): 2; NUMA node(s): 2; Vendor ID: GenuineIntel; CPU family: 6; Model: 63; Model name: Intel(R) Xeon(R) CPU E5-2698 v3 @ 2.30GHz; Stepping: 2; CPU MHz: 2798.211; CPU max MHz: 3600.0000; CPU min MHz: 1200.0000; BogoMIPS: 4600.13; Virtualization: VT-x; L1d cache: 32K; L1i cache: 32K; L2 cache: 256K; L3 cache: 40960K; NUMA node0 CPU(s): 0-15; NUMA node1 CPU(s): 16-31; Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts md_clear spec_ctrl intel_stibp flush_l1d. cat /etc/os-release; NAME=""Red Hat Enterprise Linux Server""; VERSION=""7.9 (Maipo)""; ID=""rhel""; ID_LIKE=""fedora""; VARIANT=""Server""; VARIANT_ID=""server""; VERSION_ID=""7.9""; PRETTY_NAME=""Red Hat Enterprise Linux""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:redhat:enterprise_linux:7.9:GA:server""; HOME_URL=""https://www.redhat.com/""; BUG_REPORT_URL=""https://bugzilla.redhat.com/"". REDHAT_BUGZILLA_PRODUCT=""Red Hat Enterprise Linux 7""; REDHAT_BUGZILLA_PRODUCT_VERSION=7.9; REDHAT_SUPPORT_PRODUCT=""Red Hat Enterprise Linux""; REDHAT_SUPPORT_PRODUCT_VERSION=""7.9"". lsb_r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/497#issuecomment-993155459:101,error,error,101,,https://github.com/google/deepvariant/issues/497#issuecomment-993155459,1,['error'],['error']
Availability,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-480358330:279,avail,available,279,,https://github.com/google/deepvariant/issues/137#issuecomment-480358330,1,['avail'],['available']
Availability,"Hi @pichuan , Thanks for your reply. As your suggestion, after removing the double quote around the *, the `ls` run normally in `bash` script. However, the `ls` in `deepvariant` image of `singularity` still failed. Notably, If I add a `which ls;` before a `ls -al $ref_idx*`, it runs normally so that I can see the detailed information for the files..; Here is the script:; ```bash; #!/bin/bash. nthreads=32; dvsif=""/lustre/Data/toolsDB/deepvariant.sif""; ref_idx=""/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa"". wkdir=""/lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP""; bamdir=""${wkdir}/mappinged_bams""; logdir=""${wkdir}/logs""; vcfoutdir=""${wkdir}/DeepVariant_outputs"". source activate ~/.conda/envs/zjlEnv. echo -e ""ref_idx is $ref_idx\n""; if [ -f ""$ref_idx"" ];; then; echo -e ""ref_idx $ref_idx exists!\n""; which ls; echo -e ""ls -al --block=M ${ref_idx}*\n""; ls -al --block=M ${ref_idx}*; echo -e ""ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*\n""; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*; else; echo -e ""Warning!! ref_idx [$ref_idx] not exist!\n""; fi. echo -e ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif ls -al ${ref_idx}*""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif ls -al ${ref_idx}*; echo -e ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif which ls; ls -al ${ref_idx}*""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif which ls; ls -al ${ref_idx}*. ```. Here is the running output:; ```shell; /usr/bin/ls; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. -rw-rw-r-- 1 zhoujianglin zhoujianglin 3042M Apr 26 14:53 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; -rw-rw-r-- 1 zhoujianglin zhoujianglin 5985M Apr 26 15:23 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M Apr 26 15:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1575922269:717,echo,echo,717,,https://github.com/google/deepvariant/issues/653#issuecomment-1575922269,4,['echo'],['echo']
Availability,"Hi @pichuan ,. Yes, the error messages seem not affect the run and the GPU was utilized during the run. ; I will run another round of training step, and will check the GPU utilization and the messages. Also, I have two questions about the training step. 1. In the Blog (Improved non-human variant calling using species-specific DeepVariant models), in a trio, one offspring was used for establishing the ""silver dataset"", and five other progenies were used for training and evaluating. So the individuals used for generating the truth dataset and training are different.; However, in the deepvariant documents, it seems that the truth dataset, training and evaluating examples all come from HG001, the same individual. Does the individual used for generating truth dataset and training have to be different? If not, could you please explain why di d you use different individuals in the first case?. 2. If I have multiple trios, can I first call ""silver set"" with a child from each trio separately, and make examples using the same child from each trio with its silver set, and then shuffle all examples together to train. Thank you!. Zuyao",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/722#issuecomment-1787688990:24,error,error,24,,https://github.com/google/deepvariant/issues/722#issuecomment-1787688990,1,['error'],['error']
Availability,"Hi @pichuan ,; Im running this for RNA seq study ; In the documentation itself the model is there, I have just downloaded those files",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/743#issuecomment-1844710019:111,down,downloaded,111,,https://github.com/google/deepvariant/issues/743#issuecomment-1844710019,1,['down'],['downloaded']
Availability,"Hi @pichuan ,; You are right, the problem is with the index file. ; samtools index is done for all samples before running deepvariant , however for some of the larger .bam files it did not produced index files and therefore error in deepvariant. . Thank you !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/232#issuecomment-549458167:224,error,error,224,,https://github.com/google/deepvariant/issues/232#issuecomment-549458167,1,['error'],['error']
Availability,"Hi @pichuan . Here is a helper shell script for that: https://raw.githubusercontent.com/anands-repo/deepvariant/r1.0/tools/post_eval.sh. Steps to use:; 1. Create a target empty working directory: `$WORKDIR`; 2. Launch model_eval with `--checkpoint_dir=$WORKDIR`, and direct output logs to `$WORKDIR/eval.log`; 3. Launch post_eval.sh as: `post_eval.sh $TRAINING_DIRECTORY $WORKDIR` where (`$TRAINING_DIRECTORY` is the original directory where checkpoints were dumped by model_train). The post_eval script copies one checkpoint after another to $WORKDIR from $TRAINING_DIRECTORY and modifies the ""checkpoint"" file in that directory, in coordination with model_eval, so that model_eval runs on one checkpoint after another just like when it is launched concurrently with training.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/378#issuecomment-721485772:442,checkpoint,checkpoints,442,,https://github.com/google/deepvariant/issues/378#issuecomment-721485772,4,['checkpoint'],"['checkpoint', 'checkpoints']"
Availability,"Hi @pichuan . I am not running on Google Cloud, but on a local machine. So I went with the default runner. When I use DataflowRunner the shuffle script requests arguments relevant to GCS. For example I get errors such as:. ```Invalid GCS path (<PATH>), given for the option: temp_location```. <PATH> here is actually a valid path in my machine. Kindly advise. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/360#issuecomment-707423529:206,error,errors,206,,https://github.com/google/deepvariant/issues/360#issuecomment-707423529,1,['error'],['errors']
Availability,"Hi @pichuan ; I just used the command you suggested but I am not getting any log.; could you please let me know how to set /opt/deepvariant/bin/make_examples parameter to get the errors?; Thanks,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870744502:179,error,errors,179,,https://github.com/google/deepvariant/issues/465#issuecomment-870744502,1,['error'],['errors']
Availability,"Hi @pichuan ~. I tried the code you provided but it print nothing error.; There is also nothing output file in the output folder. Here is the code:. ```sh; $ sudo docker run \; > -v ""${INPUT_DIR}"":""/input"" \; > -v ""${OUTPUT_DIR}"":""/output"" \; > google/deepvariant:""${BIN_VERSION}"" \; > /opt/deepvariant/bin/make_examples \; > --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta \; > --reads /input/NA12878_S1.chr20.10_10p1mb.bam \; > --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz \; > --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz \; > --regions chr20:10,000,000-10,010,000 \; > --task 0. $ ls; quickstart-output quickstart-testdata. $ ls quickstart-output/; intermediate_results_dir. ```. Best,; Jerry",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-689958395:66,error,error,66,,https://github.com/google/deepvariant/issues/345#issuecomment-689958395,1,['error'],['error']
Availability,"Hi @pichuan ~. Thank you for this quickly reply~. I tried to add `--user root` into docker command like the solved issue #325 ; But it still didn't show any additional error message like the issue ; I also check the disk and it is still have about 9 Gb free space. Here is the code and message output. ```sh; $ BIN_VERSION=""1.0.0""; $ sudo docker pull google/deepvariant:""${BIN_VERSION}""; Digest: sha256:6ef8f3b4c4465e41ee7597cd2351a7c44dd8b62a849a47766316507a6234f5f8; Status: Downloaded newer image for google/deepvariant:1.0.0; docker.io/google/deepvariant:1.0.0. $ INPUT_DIR=""${PWD}/quickstart-testdata""; $ ls -1 ${INPUT_DIR}; NA12878_S1.chr20.10_10p1mb.bam; NA12878_S1.chr20.10_10p1mb.bam.bai; test_nist.b37_chr20_100kbp_at_10mb.bed; test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; ucsc.hg19.chr20.unittest.fasta; ucsc.hg19.chr20.unittest.fasta.fai; ucsc.hg19.chr20.unittest.fasta.gz; ucsc.hg19.chr20.unittest.fasta.gz.fai; ucsc.hg19.chr20.unittest.fasta.gz.gzi. $ OUTPUT_DIR=""${PWD}/quickstart-output""; $ ls ${OUTPUT_DIR}; intermediate_results_dir. $ df -h; 檔案系統 容量 已用 可用 已用% 掛載點; udev 7.8G 0 7.8G 0% /dev; tmpfs 1.6G 11M 1.6G 1% /run; /dev/sda1 109G 95G 8.9G 92% /; tmpfs 7.9G 200K 7.9G 1% /dev/shm; tmpfs 5.0M 4.0K 5.0M 1% /run/lock; tmpfs 7.9G 0 7.9G 0% /sys/fs/cgroup; /dev/loop1 56M 56M 0 100% /snap/core18/1885; /dev/loop3 55M 55M 0 100% /snap/gtk-common-themes/1502; /dev/loop2 162M 162M 0 100% /snap/gnome-3-28-1804/128; /dev/loop4 161M 161M 0 100% /snap/gnome-3-28-1804/116; /dev/loop0 30M 30M 0 100% /snap/snapd/8790; /dev/loop5 63M 63M 0 100% /snap/gtk-common-themes/1506; /dev/loop6 55M 55M 0 100% /snap/core18/1880; /dev/loop7 30M 30M 0 100% /snap/snapd/8542; /dev/loop8 39M 39M 0 100% /snap/remmina/4309; /dev/loop9 40M 40M 0 100% /snap/remmina/4324; tmpfs 1.6G 40K 1.6G 1% /run/user/108; tmpfs 1.6G 12K 1.6G 1% /run/user/1000. $ sudo docker run \; > --user root \; > -v ""${INPUT_DIR}"":""/input"" \; > -v ""${OUTPUT_DIR}"":""/output"" \; > google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-689932270:168,error,error,168,,https://github.com/google/deepvariant/issues/345#issuecomment-689932270,2,"['Down', 'error']","['Downloaded', 'error']"
Availability,"Hi @pichuan, @akolesnikov,. I'm new to DeepTrio and couldn't locate the log files, but I have intermediate results showing that DeepTrio ran successfully without errors. Additionally, I successfully benchmarked the .vcf files generated by DeepTrio. I've attached screenshots for reference. Your assistance is greatly appreciated.; Thank you. finished log; ![Screenshot from 2024-05-07 09-52-02](https://github.com/google/deepvariant/assets/45700858/1f9f1b6d-bdd5-4d5d-87fd-a1416e8b4f22); ![Screenshot from 2024-05-07 09-52-32](https://github.com/google/deepvariant/assets/45700858/1c40eb86-018e-4df7-a290-963dccb767b8). Benchmark; ![Screenshot from 2024-05-07 09-52-59](https://github.com/google/deepvariant/assets/45700858/e98c8307-12ba-4c15-a26a-2323948e8f05)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/815#issuecomment-2097677205:162,error,errors,162,,https://github.com/google/deepvariant/issues/815#issuecomment-2097677205,1,['error'],['errors']
Availability,"Hi @pichuan, I have tried singularity as suggested at the link and it worked fine. But I got the message below. The deepvariant version is 1.6.0 as used in the case at the link. Are there other versions available? How can I list the available versions? Thank you very much for all your help. 2023-11-24 20:50:47.554286: I tensorflow/core/platform/cpu_feature_guard.cc:193]; This TensorFlow binary is optimized with oneAPI Deep Neural Network Library; (oneDNN) to use the following CPU instructions in performance-critical operations:; AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate comp; iler flags. > Hi @spz1st , Building on different systems can be tricky. Have you considered using solutions like Singularity (or directly using Docker if you have permission)? An example of running with Singularity can be found in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-pacbio-model-case-study.md.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/740#issuecomment-1826444464:203,avail,available,203,,https://github.com/google/deepvariant/issues/740#issuecomment-1826444464,2,['avail'],['available']
Availability,"Hi @pichuan, sorry for the slow response! I've only tried `very_sensitive_caller`, and while it seems to be working alright, I'm getting lower-than-desired precision and quite low recall, even when adding additional training data or adjusting the evaluation metrics. This may be fixable by tuning parameters more, so I'm just trying to get a handle on all the different options available to customize the training process!. One other question - I see that including a VCF with population-level allele frequencies is an option. Is there a specific format that the frequencies need to be in for compatibility with DeepVariant? (e.g. do they need to be in a specific INFO field?) Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/433#issuecomment-810405206:378,avail,available,378,,https://github.com/google/deepvariant/issues/433#issuecomment-810405206,1,['avail'],['available']
Availability,"Hi @pichuan, thank you for getting back so quickly! I'm working on patient data, so unfortunately it's not something I can share. . About the files you requested, I now see that there is no file called: `sample1.intermediate/call_variants_output.tfrecord.gz`, instead there's a number of files:; `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`; also instead of `gvcf.tfrecord@19.gz`; there are:; `gvcf.tfrecord-[00000-00018]-of-00019.gz`. That's probably why the above command for postprocess_variants doesn't work, right? I am using 19 threads. I copied the command from `--dry_run=true`. So my question is, how to pass multiple arguments to` --infile` and `--nonvariant_site_tfrecord_path`?. Thank you so much, I'm very happy if it turns I merely had a faulty command!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/849#issuecomment-2222290171:765,fault,faulty,765,,https://github.com/google/deepvariant/issues/849#issuecomment-2222290171,1,['fault'],['faulty']
Availability,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/849#issuecomment-2235713407:177,error,error,177,,https://github.com/google/deepvariant/issues/849#issuecomment-2235713407,5,"['avail', 'down', 'error']","['available', 'download', 'error']"
Availability,"Hi @pichuan, thanks for the explanation! I've been working on using DeepVariant to train my own sequencing-type specific model, and I'm getting to the point of wanting to mess with some of the different options available to improve performance. It sounds like `vcf_candidate_importer` would be less relevant for this purpose, but what about `unspecified_caller`? How does that option differ from `very_sensitive_caller`?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/433#issuecomment-807115854:211,avail,available,211,,https://github.com/google/deepvariant/issues/433#issuecomment-807115854,1,['avail'],['available']
Availability,"Hi @pichuan,. I tried to use `postprocess_variants_child_extra_args, postprocess_variants_parent1_extra_args, postprocess_variants_parent2_extra_args.` with deeptrio by running the docker: docker://google/deepvariant:deeptrio-1.6.1. here's my example code where parent1 is the father in the trio; ```; /opt/deepvariant/bin/deeptrio/run_deeptrio \; --model_type ""WGS"" \; --ref {params.ref_genome} \; --reads_child {input.child_cram} \; --reads_parent1 {input.dad_cram} \; --reads_parent2 {input.mom_cram} \; --output_vcf_child {output}/{params.child_name}.vcf.gz \; --output_vcf_parent1 {output}/{params.dad_name}.vcf.gz \; --output_vcf_parent2 {output}/{params.mom_name}.vcf.gz \; --sample_name_child {params.child_name} \; --sample_name_parent1 {params.dad_name} \; --sample_name_parent2 {params.mom_name} \; --num_shards {threads} \; --intermediate_results_dir deeptrio_tmp/{wildcards.family} \; --postprocess_variants_parent1_extra_args=""--haploid_contigs=""chrX,chrY"",--par_regions_bed={input.PAR}"" \; --output_gvcf_child {output}/{params.child_name}.g.vcf.gz \; --output_gvcf_parent1 {output}/{params.dad_name}.g.vcf.gz \; --output_gvcf_parent2 {output}/{params.mom_name}.g.vcf.gz \; --novcf_stats_report; ```. but I got the following error:; ```; FATAL Flags parsing error: Unknown command line flag 'postprocess_variants_parent1_extra_args'. Did you mean: postprocess_variants_extra_args ?; Pass --helpshort or --helpfull to see help on flags.; ```; checking --helpfull, it seems only --postprocess_variants_extra_args is available.; Did I misunderstand the use of postprocess_variants_parent1_extra_args?. Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/816#issuecomment-2119232553:1239,error,error,1239,,https://github.com/google/deepvariant/issues/816#issuecomment-2119232553,3,"['avail', 'error']","['available', 'error']"
Availability,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```; INFO: Using cached SIF image; I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s; user	0m0.121s; sys	0m0.125s; ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```; INFO: Using cached SIF image; FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/533#issuecomment-1088051366:139,Error,Error,139,,https://github.com/google/deepvariant/issues/533#issuecomment-1088051366,3,"['Error', 'error']","['Error', 'error']"
Availability,"Hi @pichuan,. The ""intervaltree==2.1.0"" resolved my another failed case of ""//deepvariant:make_examples_test"". While ""//deepvariant/labeler:haplotype_labeler_test"" still failed. And the following is the error message that I got:. ```; FAIL: test_make_labeler_ref(truths=[], expected_end=21, expected_start=9, bufsize=0, candidates=[reference_bases: ""A""; alternate_bases: ""C""; end: 11; reference_name: ""20""; start: 10; , reference_bases: ""A""; alternate_bases: ""C""; end: 21; reference_name: ""20""; start: 20; ]) (__main__.HaplotypeLabelerClassUnitTest); test_make_labeler_ref(truths=[], expected_end=21, expected_start=9, bufsize=0, candidates=[reference_bases: ""A""; alternate_bases: ""C""; end: 11; reference_name: ""20""; start: 10; , reference_bases: ""A""; alternate_bases: ""C""; end: 21; reference_name: ""20""; start: 20; ]) (__main__.HaplotypeLabelerClassUnitTest); test_make_labeler_ref(truths=[], expected_end=21, expected_start=9, bufsize=0, candidates=[reference_bases: ""A""; ----------------------------------------------------------------------; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/dc155a991b1776fcc65387121539d20a/execroot/com_google_deepvariant/bazel-out/ppc-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/absl_py/absl/third_party/unittest3_backport/case.py"", line 37, in testPartExecutor; yield; File ""/root/.cache/bazel/_bazel_root/dc155a991b1776fcc65387121539d20a/execroot/com_google_deepvariant/bazel-out/ppc-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/absl_py/absl/third_party/unittest3_backport/case.py"", line 162, in run; testMethod(); File ""/root/.cache/bazel/_bazel_root/dc155a991b1776fcc65387121539d20a/execroot/com_google_deepvariant/bazel-out/ppc-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/absl_py/absl/testing/parameterized.py"", line 256, in bound_param_test; test_method(self, **testcase_params); File ""/root/.cache/bazel/_bazel_root/dc155a991b1776fcc65387121539d20a/execroot/com_google_deepvariant/baz",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/154#issuecomment-464683367:203,error,error,203,,https://github.com/google/deepvariant/issues/154#issuecomment-464683367,1,['error'],['error']
Availability,"Hi @pichuan,. The sample is HG00438 from 1000G, which downloaded from; ```; /vol1/fastq/ERR398/008/ERR3988768/ERR3988768_1.fastq.gz; /vol1/fastq/ERR398/008/ERR3988768/ERR3988768_2.fastq.gz; ```. I tried to reproduce this issue with an 1MB bam file: [HG00438.chr1_1000000_2000000.bam.txt](https://github.com/user-attachments/files/16170832/HG00438.chr1_1000000_2000000.bam.txt) (.txt is only for uploading to github). Deepvariant found 5115 examples on it. Do you think this data is normal?. If that 1MB region looks OK, then I guess this issue might be caused by some complex region in the graph, which cannot be well surjected to the bam file. I need some time to carefully check the data, and maybe is more likely an issue with the pangenome graph or `vg`. Many thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/847#issuecomment-2222140217:54,down,downloaded,54,,https://github.com/google/deepvariant/issues/847#issuecomment-2222140217,1,['down'],['downloaded']
Availability,"Hi @pichuan,. VM instance: n1-standard-16 (16 vCPUs, 60 GB memory). I don't get any error messages. The instance is still on and not giving any errors....or at least I haven't found any logs myself... Below is the structure of the contents in the VM instance:. ├── [drwxrwxr-x 4.0K] input; │ └── [drwxrwxr-x 4.0K] data; │ ├── [-rw-rw-r-- 2.9G] Annuum.v1.6.Total.fa; │ ├── [-rw-rw-r-- 1.6M] Annuum.v1.6.Total.fa.fai; │ ├── [-rw-rw-r-- 17G] FC85.sort.pcr_rem.RG.kept.bam; │ └── [-rw-rw-r-- 9.2M] FC85.sort.pcr_rem.RG.kept.bam.bai; └── [drwxrwxr-x 4.0K] output; └── [drwxr-xr-x 4.0K] intermediate_results_dir; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00000-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00001-of-00016.gz; ├── [-rw-r--r-- 337M] gvcf.tfrecord-00002-of-00016.gz; ├── [-rw-r--r-- 337M] gvcf.tfrecord-00003-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00004-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00005-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00006-of-00016.gz; ├── [-rw-r--r-- 337M] gvcf.tfrecord-00007-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00008-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00009-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00010-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00011-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00012-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00013-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00014-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00015-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00000-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00001-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00002-of-00016.gz; ├── [-rw-r--r-- 9.9G] make_examples.tfrecord-00003-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00004-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00005-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00006-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00007-of-00016",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/427#issuecomment-788690917:84,error,error,84,,https://github.com/google/deepvariant/issues/427#issuecomment-788690917,2,['error'],"['error', 'errors']"
Availability,"Hi @pichuan,. like I mentioned before, I was also working with another tool that can make use of the GPU (SpliceAI) and I did some configurations and package installations to make this tool runable. Somehow this also fixed my problems with DeepVariant now. The error is gone and call_variants stage went through in 37 min using our GPU. Maybe there was something wrong with the CUDA drivers... I don't know. I'm very sorry for the inconveniences!. Best regards,. Sebastian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/321#issuecomment-675317201:261,error,error,261,,https://github.com/google/deepvariant/issues/321#issuecomment-675317201,1,['error'],['error']
Availability,"Hi @pichuan,. sorry I was on vacation. Mhm strange I've checked your test command on my Debian 10 machine and it's showing the container nvidia-smi output without any problems. . I've checked your script. Did you install any NVIDIA drivers before CUDA? If I remember right, I did something like ""nivida-detect"" and installed the proposed package. What is your version of nvidia-container-toolkit (mine is 1.1.2-1) ? I saw in your mentioned issue that people there are using a newer one. So maybe it is worth a try to downgrade. You can also try something like ""sudo modprobe nvidia-uvm"". I have had this issue with another tool that wanted to use the GPU. Somehow the card was not ready and this fixed my problem. I hope this helps. I'm quite new in the GPU world. Best regards,. Sebastian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/321#issuecomment-674744222:517,down,downgrade,517,,https://github.com/google/deepvariant/issues/321#issuecomment-674744222,1,['down'],['downgrade']
Availability,"Hi @pichuan,; Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! ; Best,; ```. ***** Running the command:*****; time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s; user	0m0.699s; sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/243#issuecomment-579406829:163,error,errors,163,,https://github.com/google/deepvariant/issues/243#issuecomment-579406829,1,['error'],['errors']
Availability,"Hi @pichuan,; Thanks for the response. ; As our data is not publicly available, soI tried to use the benchmark data in the following link to get the better comparison.; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-exome-case-study.md; In the link below, you mentioned about ""sec per 100"" on the log file is .67 sec for your hardware configuration. That should be proportionally adjustable on my machine's configuration (I use an 8 core machine and 64GB memory). ; https://github.com/google/deepvariant/issues/74. But unfortunately It is not the case on my machine. I got way higher time for different runs. from 20 second to some times 1 minutes per 100.; Surprisingly singularity does not use the full memory, 64 GB made available to it.; I am confused that if I set num_shards to the number of cores for example in my case 8, it makes the process even slower than when I set it to one.; May I kindly ask how much memory normally singularity uses?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-864505178:69,avail,available,69,,https://github.com/google/deepvariant/issues/463#issuecomment-864505178,2,['avail'],['available']
Availability,"Hi @pioneer-pi ,. Can you please put some more details? Please follow the suggestions in this doc: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md, which suggests you to run `sudo su` before running `./build-prereq.sh`. One thing you can do is run:. ```bash; ./build-prereq.sh 2>&1 | tee /tmp/dv_build.log; ```; Then upload the `dv_build.log` here so a detailed log is available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/737#issuecomment-1818039062:400,avail,available,400,,https://github.com/google/deepvariant/issues/737#issuecomment-1818039062,1,['avail'],['available']
Availability,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/858#issuecomment-2261202112:788,checkpoint,checkpoint,788,,https://github.com/google/deepvariant/issues/858#issuecomment-2261202112,1,['checkpoint'],['checkpoint']
Availability,"Hi @poddarharsh15 , it seems like you're certain that the DeepTrio run finished correctly.; In that case, I agree with @akolesnikov 's original assessment that this can be an issue for the downstream glnexus step, which we can't directly support. One suggestion to try:; If you need to check your run a bit more closely, maybe breaking it down to just running this part first:. ```bash; udocker run \; -v ""${PWD}/output"":""/output"" \; quay.io/mlin/glnexus:v1.2.7 \; /usr/local/bin/glnexus_cli \; --config DeepVariant_unfiltered \; /output/HG002.g.vcf.gz \; /output/HG003.g.vcf.gz \; /output/HG004.g.vcf.gz; ```. before piping to the next step. Maybe that could help you identify what the errors are coming out from that step?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/815#issuecomment-2098938294:189,down,downstream,189,,https://github.com/google/deepvariant/issues/815#issuecomment-2098938294,3,"['down', 'error']","['down', 'downstream', 'errors']"
Availability,"Hi @qili93 ; I wasn't able to reproduce your error. Here is what I did (on a Ubuntu 16 machine); ```; git clone https://github.com/google/deepvariant.git; cd deepvariant; ./build-prereq.sh && pip install --user 'intervaltree==2.1.0'; bazel test -c opt //deepvariant/labeler:haplotype_labeler_test; ```. And this passed for me. Currently your setting might be outside our actively supported platform. If you can suggest a patch (that wouldn't break other settings), we're happy to make a fix internally as well. But we don't currently have extra bandwidth to look into this issue. One more question for you (it'll really help us understand your need and why you need to build) -- Were you able to run with our prebuilt docker container image? If so, what was the reason that you decided to build on your own? . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/154#issuecomment-464843333:45,error,error,45,,https://github.com/google/deepvariant/issues/154#issuecomment-464843333,1,['error'],['error']
Availability,"Hi @qili93 ; can you paste your error messages here?. Many of the recent test errors reported by users are related to the fact that we didn't pin our intervaltree version in our last release, and intervaltree v3 came out and had some API changes... So, the first thing to try is to change this line:; https://github.com/google/deepvariant/blob/r0.7/run-prereq.sh#L86; to:; ```; pip install --user 'intervaltree==2.1.0'; ```; and see if the tests will pass? Please let me know. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/154#issuecomment-464599230:32,error,error,32,,https://github.com/google/deepvariant/issues/154#issuecomment-464599230,2,['error'],"['error', 'errors']"
Availability,"Hi @raphaelbetschart,. It's beginning to feel more and more there are some issues with this site. With a mappability score so low for that region, and a 4000x depth recovering only 203 reads, suggests multiple scenarios one of which could be as Andrew mentioned of segmental duplication. This would require more analysis of the region and the reads, one of which could be as Andrew suggested varied isoforms. Keep in mind DeepVariant will also [cap the reads at 1500](https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#how-are-ad-and-dp-values-calculated) if the depth is too high. Another thing about low mappability is that for the WGS model there will be local realignment triggered, and that can result also in the lower number of reads. To get a BAM of your realigned reads for that region, just add the following to your DeepVariant script:. ```; --make_examples_extra_args=""emit_realigned_reads=true,realigner_diagnostics=/output/realigned_reads; ```. as described in the [FAQ section](https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work) or in the [following comment](https://github.com/google/deepvariant/issues/691#issuecomment-1662968609). Make sure to create the `realigned_reads` directory first, by adding the following line to your script (assuming you have a defined `OUTPUT_DIR` variable):. `mkdir -p ""${OUTPUT_DIR}/realigned_reads""` . After you relaunch the script, the BAM file(s) representing that region would be the one you would use in IGV. What percentage of your call sites exhibit this behavior? Were you able to look closer at the reads to compare among each other as Andrew suggested to see if they are either high expression or varied isoforms?. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/701#issuecomment-1697167719:165,recover,recovering,165,,https://github.com/google/deepvariant/issues/701#issuecomment-1697167719,1,['recover'],['recovering']
Availability,"Hi @raphaelbetschart,. Just wondering on a few things:. 1) What are your QUAL and GQ scores for that call site?; 2) Is that SNP at an exon boundary?; 3) What tissue is this from? (Different tissue types can have an impact with DeepVariant RNA-Seq.); 4) Is this site in the [REDIportal](http://srv00.recas.ba.infn.it/atlas/search.html)? . Based on this curve, at 5x coverage you should still get a good majority of the CDS label variants that you saw at 3x coverage (this figure is from the Supplementary data available in [the paper](https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031?login=false) listed in the Reference section):. ![image](https://github.com/google/deepvariant/assets/6555937/2f6f8745-89ee-455e-8d20-950ef983875b). Thanks,; Paul. #### References; [1] [A deep-learning-based RNA-seq germline variant caller](https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031?login=false)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/701#issuecomment-1695811605:509,avail,available,509,,https://github.com/google/deepvariant/issues/701#issuecomment-1695811605,2,['avail'],['available']
Availability,"Hi @richard-nm , thanks for the update. Given that our team didn't build or maintain the bioconda version, I'm not familiar with many things here. One question and one comment for you:; 1. Question: Where can I find documentation of this tool? For example, ""dv_call_variants.py"" isn't part of our GitHub repo, so I'm not familiar with that at all.; 2. Comment: Purely based on the error message you posted:; ```; Baseline DeepVariant arguments; File ""/tmp/Bazel.runfiles_j_t9fnwc/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374; raise ValueError(f'Shape mismatch in {example_info_json} and '; ^; SyntaxError: invalid syntax; ```; The corresponding line would be this one:; https://github.com/google/deepvariant/blob/r1.4/deepvariant/call_variants.py#L374; I'm not exactly why that would cause a SyntaxError though. It's a bit hard for me to figure out given that it's wrapped in something that I'm not familiar with. I did try to follow your steps above, but didn't succeed in installing:; ```; $ conda create -n deepvar python=3.7.5; $ conda install -c bioconda deepvariant=1.4.0; ```; gave me:; ```; UnsatisfiableError: The following specifications were found; to be incompatible with the existing python installation in your environment:. Specifications:. - deepvariant=1.4.0 -> python[version='>=3.6,<3.7.0a0']. Your python: python=3.7.5; ```. @richard-nm One more question for you -- is it possible to use Docker or Singularity? Which our team can support more easily as well. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/627#issuecomment-1518213948:381,error,error,381,,https://github.com/google/deepvariant/issues/627#issuecomment-1518213948,1,['error'],['error']
Availability,"Hi @ruolin ,; thanks for reporting this issue. I'll try running on your BAM and reference and see if we can reproduce the issue.; We have in the past seen cases where the jobs run out of memory, and our error messages in that situation isn't very clear. So @danielecook 's guess of OOM makes sense. But the memory you're reporting sounds like it should be enough. So let me see if I can reproduce this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/446#issuecomment-826519447:203,error,error,203,,https://github.com/google/deepvariant/issues/446#issuecomment-826519447,2,['error'],['error']
Availability,"Hi @sclan ; to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur.; The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: ; ```; def main(_):; check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir); check_flags(). commands = create_all_commands(); for command in commands:; print('\n***** Running the command:*****\n{}\n'.format(command)); try:; subprocess.check_call(command, shell=True, executable='/bin/bash'); except subprocess.CalledProcessError as e:; logging.info(e.output); raise; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/232#issuecomment-596040813:190,error,errors,190,,https://github.com/google/deepvariant/issues/232#issuecomment-596040813,2,['error'],['errors']
Availability,"Hi @segoerge ; Sorry that it took a while for me to get to this again. I'm now trying to get a Debian 10 to reproduce your issue. But I'm actually stuck at getting nvidia-smi to work on Debian 10. Here is what I've done so far:. ## Get a Debian 10 machine; ```; gcloud compute instances create ""${USER}-debian-10-gpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --maintenance-policy ""TERMINATE"" \; --accelerator=type=nvidia-tesla-p100,count=1 \; --image=debian-10-buster-v20200618 \; --image-project=debian-cloud \; --machine-type n1-standard-16 \; --zone ""us-west1-b""; ```. ## On the machine, install driver and docker; I did:; ```; curl https://gist.githubusercontent.com/pichuan/c538f04f08cd367c6ea2ad2df7be4de0/raw/a3c8dd11b5365dfa39351265dd53d7d986b84d8b/debian10_install_nvidia_docker.sh | bash -x; ```; to install. You can take a look at https://gist.githubusercontent.com/pichuan/c538f04f08cd367c6ea2ad2df7be4de0/raw/a3c8dd11b5365dfa39351265dd53d7d986b84d8b/debian10_install_nvidia_docker.sh to see what I did. At the end, this command failed:; ```; pichuan@pichuan-debian-10-gpu:~$ sudo docker run --gpus 1 nvidia/cuda:10.0-base nvidia-smi; docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""process_linux.go:449: container init caused \""process_linux.go:432: running prestart hook 0 caused \\\""error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: initialization error: driver error: failed to process request\\\\n\\\""\"""": unknown.; ERRO[0000] error waiting for container: context canceled ; ```; I saw this being reported here as well: https://github.com/NVIDIA/nvidia-container-toolkit/issues/183 . I'll need to figure this out because I can actually test DeepVariant behavior on this. If you have suggestions on how to get this work, let me know and I can proceed. Otherwise I'll take a look again later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/321#issuecomment-671016803:376,mainten,maintenance-policy,376,,https://github.com/google/deepvariant/issues/321#issuecomment-671016803,6,"['Error', 'error', 'mainten']","['Error', 'error', 'maintenance-policy']"
Availability,"Hi @sgoe1,. Using the 1.0.0 image, the variant calling fails on nearly all of my input samples with the following error (sites vary from one sample to another):; ```; 2020-09-03 10:01:02.237494: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpqosj7aak/call_variants_output.tfrecord.gz; 2020-09-03 10:01:02.575525: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 63099; I0903 10:01:02.988874 140046207305472 postprocess_variants.py:1079] CVO sorting took 0.012529869874318441 minutes; I0903 10:01:02.989492 140046207305472 postprocess_variants.py:1081] Transforming call_variants_output to variants.; I0903 10:01:02.989910 140046207305472 postprocess_variants.py:1108] Merging and writing variants to VCF and gVCF.; I0903 10:01:02.996278 140046207305472 genomics_writer.py:172] Writing /<REDACTED>/ID.2.vcf.gz with NativeVcfWriter; I0903 10:01:02.998338 140046207305472 genomics_writer.py:172] Writing /<REDACTED>/ID.2.g.vcf.gz with NativeVcfWriter; W0903 10:01:17.865604 140046207305472 postprocess_variants.py:394] Alt allele indices found from call_variants_outputs for variant reference_bases: ""CTT""; alternate_bases: ""CT""; alternate_bases: ""CTTT""; alternate_bases: ""CTTTTTTTCT""; calls {; info {; key: ""AD""; value {; values {; int_value: 7; }; values {; int_value: 7; }; values {; int_value: 0; }; values {; int_value: 0; }; }; }; info {; key: ""DP""; value {; values {; int_value: 19; }; }; }; info {; key: ""VAF""; value {; values {; number_value: 0.3684210526315789; }; values {; number_value: 0.0; }; values {; number_value: 0.0; }; }; }; genotype: -1; genotype: -1; call_set_name: ""ID""; }; end: 21441513; reference_name: ""chr16""; start: 21441510; is [[0], [0], [0, 1], [0, 2], [1], [1, 2], [2]], which is invalid.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_fbg2uft9/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1143, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.6/dist-packages/te",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/341#issuecomment-686397941:114,error,error,114,,https://github.com/google/deepvariant/issues/341#issuecomment-686397941,1,['error'],['error']
Availability,"Hi @sh940202123 , it's not obvious to me why this might be the case. It's strange that no error message comes out at all. Can you try something even simpler, like:; ```; sudo docker run google/deepvariant:1.0.0 /opt/deepvariant/bin/make_examples --help; ```; And see if the information comes out correctly?. I'll also check with my team member tomorrow to see if anyone has other suggestions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-690806128:90,error,error,90,,https://github.com/google/deepvariant/issues/345#issuecomment-690806128,2,['error'],['error']
Availability,"Hi @sh940202123 ,; Sorry that our error messages are still quite cryptic at this time. The last traceback is actually not quite as useful. You're seeing it because we uses Python's subprocess.check_call to call each of the commands:; https://github.com/google/deepvariant/blob/7ed651ed54d8563530d58ba80187121337fd10f2/scripts/run_deepvariant.py#L362. Usually, I hope that whatever appeared right before that is useful, though. For example, if I deliberately deleted the bam file, I got:. ```; ***** Running the command:*****; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. [E::hts_open_format] Failed to open file ""/input/NA12878_S1.chr20.10_10p1mb.bam"" : No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_1ip32q9b/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_1ip32q9b/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_1ip32q9b/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_1ip32q9b/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2063, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_1ip32q9b/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 427, in default_options; with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:; File ""/tmp/Bazel.runfiles_1ip32q9b/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_1ip",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-689891360:34,error,error,34,,https://github.com/google/deepvariant/issues/345#issuecomment-689891360,1,['error'],['error']
Availability,"Hi @sh940202123 it seems the CPU on the host `Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz` doesn't support AVX instruction ( https://en.wikipedia.org/wiki/List_of_Intel_Core_i7_microprocessors#%22Lynnfield%22_(45_nm) ), which is required for the TensorFlow release version we use in the docker image. Please see this previous comment https://github.com/google/deepvariant/issues/217#issuecomment-530580878 for more details. That being said, I do find it strange that it's silently not producing outputs, instead of showing an error message about the unsupported instruction.. Is it possible for you to try the same command in a machine with newer CPU? For Intel CPUs, _Sandy Bridge_ (released in 2011) or later architectures should support AVX. https://en.wikipedia.org/wiki/List_of_Intel_Core_i7_microprocessors#Sandy_Bridge_microarchitecture_(2nd_generation)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-690820723:521,error,error,521,,https://github.com/google/deepvariant/issues/345#issuecomment-690820723,1,['error'],['error']
Availability,Hi @situssog ; From the error message it seems like there's something wrong with the base quality scores in your BAM. Is there more information you can provide? Are you able to use the same BAM file with other tools that reads the base quality scores?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/270#issuecomment-587577840:24,error,error,24,,https://github.com/google/deepvariant/issues/270#issuecomment-587577840,1,['error'],['error']
Availability,"Hi @sivianil . Thank you for the files. With them, I was able to get a better idea of the problem. The problem is that the file that you are providing as your truth set file (801_snp_short_indel_with_quality_reference.vcf.gz) has an entry on chr1 position 8669 which disagrees in the REF field with the file that you are providing as your reference (pseudo801.fasta.gz). According to *pseudo801.fasta.gz* the reference base is *G*. The line in *801_snp_short_indel_with_quality_reference.vcf.gz* has an entry on this field as:. ```; 1 8669 . C . 38 PASS DP=16 GT:GQ:DP 0|0:38:16; ```. According to this VCF, the reference base listed at this position is *C*. You will get this error with hap.py regardless the content of the DeepVariant file. This error does not relate to DeepVariant at all. If you want to do any comparison with 801_snp_short_indel_with_quality_reference.vcf.gz you will need to reconcile the difference between the reference and the contents of the VCF. . Does it really make sense to apply hap.py to this dataset? Hap.py was developed for comparison with highly curated truth datasets made with multiple technologies and/or corroborated by extensive pedigree information (e.g. as is available in Genome in a Bottle or Platinum Genomes). I'm not sure that the data present in the 1001 Arabidopsis Genomes projects would sufficiently allow such a comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/606#issuecomment-1407228342:677,error,error,677,,https://github.com/google/deepvariant/issues/606#issuecomment-1407228342,3,"['avail', 'error']","['available', 'error']"
Availability,"Hi @sivianil . That is interesting. I don't think that this error message has something to do with the allele being multiallelic. We generate multiallelic outputs for human samples and hap.py works for those. . If you want to filter to only bi-allelic calls, you can post-process the VCF with bcftools . `bcftools view -m2 -M2`. From reading the error, it seems that the most likely explanation is that the reference genome used in the hap.py evaluation does not exactly match the sequence of the reference genome used to map the reads in the BAM file used in DeepVariant. Are you certain those two files are exactly the same?. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/606#issuecomment-1405862600:60,error,error,60,,https://github.com/google/deepvariant/issues/606#issuecomment-1405862600,2,['error'],['error']
Availability,"Hi @snakesch , pinging one more time to see if its possible for you to share the bam.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/833#issuecomment-2189418775:15,ping,pinging,15,,https://github.com/google/deepvariant/issues/833#issuecomment-2189418775,1,['ping'],['pinging']
Availability,"Hi @sophienguyen01 , ; Is there a reason why you're setting `--config.num_validation_examples=0`? You'll need to have a reasonable amount of num_validation_examples for the model to be able to evaluate and pick a reasonable checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2073324455:224,checkpoint,checkpoint,224,,https://github.com/google/deepvariant/issues/802#issuecomment-2073324455,1,['checkpoint'],['checkpoint']
Availability,"Hi @sophienguyen01 , can you specifically point out the line of the error? All the lines in the logs are API warnings, you can safely ignore those.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2073368951:68,error,error,68,,https://github.com/google/deepvariant/issues/802#issuecomment-2073368951,1,['error'],['error']
Availability,"Hi @sophienguyen01,. Just a few additional notes. It's been awhile since I run things on AWS. . My instinct is that the most cost-effective instance will turn out to be m7i.4xlarge. m7i.8xlarge will likely be slightly more expensive, but should scale close to linear in speed. . If you have PacBio data and experience a failure, you might want to try R7iz.4xlarge or R7iz.8xlarge. The GPU instances will be faster, but I suspect not necessarily cost-optimal. So it depends on what you are looking for.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/696#issuecomment-1681230125:320,failure,failure,320,,https://github.com/google/deepvariant/issues/696#issuecomment-1681230125,1,['failure'],['failure']
Availability,"Hi @sophienguyen01,. The correct way would be to add the parameter during the inference. That way examples are created with the correct height. The difference in accuracy can be explained by the fact that reads are downsampled to the `pileup_image_height` max coverage. There are probably locations where the coverage is larger than 75 and more reads get into the image. Although, model does not use those extra reads but since reads are sorted by position we may have more support in certain cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/893#issuecomment-2405675396:215,down,downsampled,215,,https://github.com/google/deepvariant/issues/893#issuecomment-2405675396,1,['down'],['downsampled']
Availability,"Hi @spz1st ,; Was that just a warning and you're still able to run DeepVariant, or does the program actually crashed after that?; I think the message just means that your machine might not have certain optimized ops, but I think you should still be able to run it. If the code did crash, please let me know if there are more error messages that you're seeing.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/740#issuecomment-1828442518:325,error,error,325,,https://github.com/google/deepvariant/issues/740#issuecomment-1828442518,1,['error'],['error']
Availability,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:; ```bash; singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'; ```; And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/555#issuecomment-1223153383:421,error,error,421,,https://github.com/google/deepvariant/issues/555#issuecomment-1223153383,1,['error'],['error']
Availability,"Hi @tedyun,. 1. In this use case, we have phased and accurate data from the same cohort **X** that we use for the imputation.; 2. I was actually thinking about simply deleting the GQ=0 sites from my GVCFs which seem to be the simpler solution. As you said, they don't provide any useful information. I just wanted to point out here that having those records in output might confuse downstream applications (i.e. imputation).; 3. Unfortunately not. The problem is that our imputation system is exclusively based on the PL values and doesn't even read GT or GQ. Thank you for your questions and suggestions. Guillaume",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/403#issuecomment-760775624:382,down,downstream,382,,https://github.com/google/deepvariant/issues/403#issuecomment-760775624,2,['down'],['downstream']
Availability,"Hi @tetsuro90, `run_deepvariant` is only available for Docker and not for Conda. You can reference [this doc](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md) for the flags needed to write out GVCFs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/316#issuecomment-641651605:41,avail,available,41,,https://github.com/google/deepvariant/issues/316#issuecomment-641651605,1,['avail'],['available']
Availability,"Hi @tgelafr-btx , thanks for waiting. It took me a while to get back to this. Before I share my work log, one observation from your error earlier:; It seems like you're using Python 3.10. Note that DeepVariant 1.5.0 is bulit with Python 3.8. So, can you try with Python 3.8?. ---. Here is what I tried. On a GCE instance, I ran:. ```bash; wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; bash Miniconda3-latest-Linux-x86_64.sh -b -u -p $HOME/miniconda; eval ""$(${HOME}/miniconda/bin/conda shell.bash hook)""; ```. Then, I ran:. ```bash; conda config --add channels defaults && \; conda config --add channels bioconda && \; conda config --add channels conda-forge; conda create -y -n dv-env deepvariant; conda activate dv-env; ```. Which seems to work (without error). I don't actually know how to use conda (or deepvariant in conda). But I did see the files here: . ```; (dv-env) pichuan@pichuan-cpu:~$ ls /home/pichuan/miniconda/envs/dv-env/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/; call_variants.zip licenses.zip model_train.zip runtime_by_region_vis.zip; call_variants_keras.zip make_examples.zip multisample_make_examples.zip settings.sh; deeptrio make_examples_somatic.zip postprocess_variants.zip show_examples.zip; freeze_graph.zip model_eval.zip run-prereq.sh vcf_stats_report.zip; ```. These are probably the files that were packaged with the last release: https://github.com/google/deepvariant/releases/tag/v1.5.0. @tgelafr-btx Question for you: Have you consider using Docker or Singularity, which are better supported by our team? Like the example in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md or https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-pacbio-model-case-study.md . Anyway, hopefully my test with conda install was somewhat informative. If you figure out how to install+use it, please update here. I don't think I would be able to provide further support on conda here t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/736#issuecomment-1829204521:132,error,error,132,,https://github.com/google/deepvariant/issues/736#issuecomment-1829204521,2,['error'],['error']
Availability,"Hi @themkdemiiir,. Although, it is absolutely possible to split the bam into chromosomes and run them separably there are better way to make a pipeline. There are 3 binaries that DeepVariant executes: make_examples, call_variants, and postprocess_variants. You may run those binaries from the docker. * make_examples is highly parallelized already. You may shard it to as many shards as needed by simply specifying the output of make_examples as sharded by adding @<num of shards> to the file name and add `--task` flag that specifies the task number for each shard. ; * call_variants will be run with the same number of shards.; * postprocess_variants has to be run in a single process. Here is an example of running shard 11 of make_examples and call_variants broken into 200 shards:. ```; bin/make_examples \; --examples /tmn/your_examples.tfrecord@200.gz \; --mode calling \; --reads /tmp/your_input_bam.bam \; --realign_reads \; --ref=/tmp/your_reference.fna \; --task=11. # Input for each instance of call_variants is the output of one instance of make_examples:; bin/call_variants.par \; --batch_size=32 \; --checkpoint <Path to the model checkpoint or saved model>.ckpt \; --examples /tmp/your_examples.tfrecord-00011-of-00200.gz \; --outfile /tmp/your_call_variants_output.cvo.tfrecord-00011-of-00200.gz. # Input for for postprocess would be the output of all instances of call_variants:; /tmp/your_call_variants_output.cvo.tfrecord@200.gz; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/744#issuecomment-1836586525:1116,checkpoint,checkpoint,1116,,https://github.com/google/deepvariant/issues/744#issuecomment-1836586525,4,['checkpoint'],['checkpoint']
Availability,"Hi @umahsn. 1. Training data comes from: the Human Pangenome Reference Consortium, [linked in this GitHub repo](https://github.com/human-pangenomics/HG002_Data_Freeze_v1.0). This includes HiFi sequencing for HG003 and HG004 which we contributed. It also includes data available on the [Genome in a Bottle FTP](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/) in the CCS folders for individuals. 2. Most of these datasets are available as FASTQ files. These are mapped with pbmm2 using the default parameters for HiFi. 3. For HG002 and HG004, we use v4.2 truth set. For the other samples, we use the v3.3.2 truth set. For HG001, HG005, HG006, and HG007, the truth set used is still v3.3.2 for training, since we do not yet have v4.2 for these samples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/381#issuecomment-726521665:268,avail,available,268,,https://github.com/google/deepvariant/issues/381#issuecomment-726521665,2,['avail'],['available']
Availability,"Hi @woodoo46 ; Can you give me more information like:; Which OS you're using, what singularity version, etc. And, are there more logs before the first line?; ```; I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None; ```. It'll help if I can try reproducing the error first.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/444#issuecomment-821754409:275,error,error,275,,https://github.com/google/deepvariant/issues/444#issuecomment-821754409,1,['error'],['error']
Availability,"Hi @yangyxt ,; I see... For now, to help you continue your work, I suggest using run_deeptrio with the `--dry_run=true` flag to get the list of commands, and run the commands there individually for now. Sorry for the inconvenience. The goal for having the one-step run_deeptrio.py script was to make things easier. But I need to do some improvements to make the error reporting better in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/646#issuecomment-1549015401:362,error,error,362,,https://github.com/google/deepvariant/issues/646#issuecomment-1549015401,1,['error'],['error']
Availability,"Hi @yangyxt ,; In your log, I saw this line which is a bit strange:. ```; Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error; ```. I tried to search for that function in our r1.4 codebase (which is the version you mentioned you're using):. ```; git clone https://github.com/google/deepvariant.git; cd deepvariant/; git checkout r1.4; find . -type f -exec grep -H call_deeptrio_per_pair {} \;; ```. And I can't find that function in our codebase. Can you confirm that you're running our version, or maybe you're running a modified version from somewhere else?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/646#issuecomment-1547115920:199,error,error,199,,https://github.com/google/deepvariant/issues/646#issuecomment-1547115920,1,['error'],['error']
Availability,"Hi @yassineS . Thank you for the question. In short, DeepVariant tends to call fewer variants as coverage drops (this is similar to other callers). We have benchmarks for down to 15x of Illumina WGS [at our ""20 is the new 30 blog post](https://google.github.io/deepvariant/posts/2019-09-10-twenty-is-the-new-thirty-comparing-current-and-historical-wgs-accuracy-across-coverage/). This also breaks down the types of errors by class as coverage falls. I am not sure what the lower bound of coverage for using DeepVariant. At some point, imputation approaches will be required instead of variant calling ones. I would guess this is somewhere around 5x-8x. . I am curious how low you consider low coverage, so I understand your use case.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/279#issuecomment-591172632:171,down,down,171,,https://github.com/google/deepvariant/issues/279#issuecomment-591172632,3,"['down', 'error']","['down', 'errors']"
Availability,"Hi @yexiao2016z, that's very exciting to hear. The best place to start is https://github.com/google/deepvariant/blob/r0.4/deepvariant/pileup_image.py#L244 which is the python function build_pileup() that we use to create the pileup tensor. Going down the function call stack will show you everything needed to build the tensors. There's a high-performance C++ piece of code that actually constructs the tensor from a pile of reads here as https://github.com/google/deepvariant/blob/r0.4/deepvariant/pileup_image_native.cc that will ultimately be called by pileup_image.py.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/23#issuecomment-353986978:246,down,down,246,,https://github.com/google/deepvariant/issues/23#issuecomment-353986978,1,['down'],['down']
Availability,"Hi @zihhuafang ,; The flag was added after 1.6.1 was released. Sorry about that. Note that `run_deeptrio` is a wrapper script that just runs the underlying binaries. So, for now you can run `run_deeptrio` with the `--dry_run` flag, which will print out all the commands it is going to run with each of the steps. From there, you can modify to make sure the postprocess_variants has the correct flag for the corresponding samples. Sorry for the inconvenience for now. The `postprocess_variants_parent1_extra_args` flag will be available in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/816#issuecomment-2121705660:526,avail,available,526,,https://github.com/google/deepvariant/issues/816#issuecomment-2121705660,1,['avail'],['available']
Availability,Hi @zjminglead; The error messages say the BAM file looks truncated. Does it give any errors when you run `samtools view <BAM> | tail` and look at the end of the BAM file?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/455#issuecomment-836919821:20,error,error,20,,https://github.com/google/deepvariant/issues/455#issuecomment-836919821,2,['error'],"['error', 'errors']"
Availability,"Hi @zxy1555847 . @MariaNattestad is correct that there are only a small number of errors, so it is hard to definitively tell you what is going on. . However, one thing I want to point out is that in general for exome sequencing, we expect for all analysis methods, accuracy will start dropping outside of the capture ranges with an increasing amount the farther we go from the capture. We also expect Indel to be affected more than SNP. . The reasons for this is that sequence coverage begins to drop toward the boundaries of the capture (the amount of this drop depends on the particular capture and the sequence context around it, but on average it will be the case). In general, lower coverage will mean lower accuracy, but we observe that coverage has a larger effect on Indels than SNPs (this is detailed in our [Extensive sequence dataset](https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1) paper. The reasons that are complex (though if you want me to further elaborate, I can try). . In short, Indel accuracy dropping outside of capture regions is expected to some extent, and this is a function of the underlying sequencing method as opposed to the analysis method.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/616#issuecomment-1444172404:82,error,errors,82,,https://github.com/google/deepvariant/issues/616#issuecomment-1444172404,1,['error'],['errors']
Availability,"Hi @zxy1555847 . It looks like this output is the result of running GLnexus on gVCFs. I believe you must be running DeepVariant on the 40 single samples and then GLnexus on the gVCF output as recommended in our best practices. The sample name that occurs in the gVCF file comes from the sample name in the BAM file tag. (as @pgrosu suggests, that should be what follows the `SM:` tag from the output of `samtools view -H ${CRAM} | grep SM`. DeepVariant should take that value as its sample name. DeepVariant should raise an error if a single BAM file has multiple sample names, suggesting that if these files were able to run through and produce output, they should be using the reads appropriately. . In either case, you can tell DeepVariant to over-ride any sample names present in a file and produce output from all reads with a sample name provided by you as a user. To do so, you can add the flag `--sample_name` with your sample name to the command.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/670#issuecomment-1607949879:524,error,error,524,,https://github.com/google/deepvariant/issues/670#issuecomment-1607949879,1,['error'],['error']
Availability,"Hi @zyxue , we'll look into this a bit more. Might be something we can improve on the Nucleus codebase. Feel free to ping again if we don't give another updates in a few days.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/99#issuecomment-427117714:117,ping,ping,117,,https://github.com/google/deepvariant/issues/99#issuecomment-427117714,1,['ping'],['ping']
Availability,"Hi Aiken,. I am assuming this is from a germline diploid sample, which is what the variant caller is designed for. Could you give a little background on your experiment, just to be sure I'm not missing anything in my assumptions below. [Based on the paper](https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031), the training was performed on RNA-seq samples that were not single cell. In theory it should work, though the 10x would be downsampled to 95 reads because of how the input to the model operates. Then first 5 row are used for representing the reference sequence, bringing the pileup image to a 100 rows. Try it with the RNA-seq model from [the case study](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-rnaseq-case-study.md), given the above, though lowering the number of reads might help. I would be curious on how it validates with your data. Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/705#issuecomment-1708658232:458,down,downsampled,458,,https://github.com/google/deepvariant/issues/705#issuecomment-1708658232,1,['down'],['downsampled']
Availability,"Hi Alex,. Thank you for your patience. We were able to reproduce your issue and have determined that it is likely caused by `htslib`. In particular, DV uses `htslib` version `1.13` which only experimentally supports CRAM v3.1. Updating the `htslib` version to the latest (`1.18`) fixed this issue for me. You can update `htslib` yourself for the time being by updating [this section](https://github.com/google/deepvariant/blob/r1.6/WORKSPACE#L24-L32).; ```; http_archive(; name = ""htslib"",; build_file = ""//:third_party/htslib.BUILD"",; sha256 = ""f1ab53a593a2320a1bfadf4ef915dae784006c5b5c922c8a8174d7530a9af18f"",; strip_prefix = ""htslib-1.18"",; urls = [; ""https://github.com/samtools/htslib/releases/download/1.18/htslib-1.18.tar.bz2"",; ],; ); ```. Please note that I have not yet tried `htslib 1.18` in other workflows, and those might be affected by the change: there is a chance this change has negative consequences in other circumstances. That said, if you are currently blocked in your workflow you can give that a try! Meanwhile, we are working on updating `htslib` on our end to be included it in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/741#issuecomment-1850869554:700,down,download,700,,https://github.com/google/deepvariant/issues/741#issuecomment-1850869554,1,['down'],['download']
Availability,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/870#issuecomment-2307643608:35,error,error,35,,https://github.com/google/deepvariant/issues/870#issuecomment-2307643608,1,['error'],['error']
Availability,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658889277:541,down,down,541,,https://github.com/google/deepvariant/issues/682#issuecomment-1658889277,4,"['down', 'error']","['down', 'error']"
Availability,"Hi Amy,. As Pi-Chuan mentioned is good. I only see a total of 14 reads supporting at position 41,570,158 of chromosome 15 -- hopefully its the same BAM file as the one used in DeepVariant. . Now regarding IGV here are a few things:. $`1)`$ Under View > Preferences > Alignments set the following three:. Uncheck ""Downsample reads"" like this:. ![image](https://github.com/google/deepvariant/assets/6555937/4f10a4d9-a26f-432b-adef-79095c0536b2). Check ""Show mismatch bases"":. ![image](https://github.com/google/deepvariant/assets/6555937/d0543c66-0737-4a42-bf17-35e45c48ed50). Check ""Label indels > threshold"", and have a value of 0 (and uncheck Hide indels):. ![image](https://github.com/google/deepvariant/assets/6555937/c9354639-0915-470d-b073-35817549c50c). $`2)`$ Under View > Preferences > Third Gen use these settings:. Here again perform the following:. * Uncheck ""Downsample reads""; * Check ""Label indels > label threshold"", and have a value of 0 ; * Uncheck ""Hide indels < indel size threshold"" . ![image](https://github.com/google/deepvariant/assets/6555937/46777d27-0098-4899-ba9b-8c6fc0e3baa6). Let me know if it helps. Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/691#issuecomment-1662692855:313,Down,Downsample,313,,https://github.com/google/deepvariant/issues/691#issuecomment-1662692855,2,['Down'],['Downsample']
Availability,"Hi Andrea, I am getting the same error while I am trying to run the deepvariant code through the conda installation. Did you find a solution for it?. > Thank you for your quick answer. I had to make a couple of changes to the command (see below), but now it seems to be working:; > ; > ```; > conda create -y -n deepvariant -c bioconda -c conda-forge python=2.7 deepvariant google-cloud-sdk=239.0.0; > ```; > ; > Everything is installed correctly. Is there a guide to follow for locally installed variant caller?; > I'm not sure I've been able to find it.; > ; > Thank you again for your support,; > Andrea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/252#issuecomment-567477006:33,error,error,33,,https://github.com/google/deepvariant/issues/252#issuecomment-567477006,2,['error'],['error']
Availability,"Hi Andrew, thank you very much for the feedback. This is something new I have learnt about the BAM files. Using the filtered BAM file, the error message disappears. The number of variants called has also increased considerably (~x20 for variants with PASS tag). Our reads are in fact HiFi. We have been doing the alignment with `minimap2 -ax map-pb` because to our understanding `deepvariant` is designed for read alignments (and not assembly-to-reference alignments as achieved with `minimap2 -ax asm`). Is this a misunderstanding? Could `deepvariant` be safely used with BAMs for assembly-to-reference alignments?. Thank you again,; Eugenio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/434#issuecomment-815783472:139,error,error,139,,https://github.com/google/deepvariant/issues/434#issuecomment-815783472,2,['error'],['error']
Availability,"Hi Andrew,. I am not sure how to provide the BAM file you request, if I run:. samtools view -bh <file.bam> <read> > file_read.bam . An error appears indicating that the read specifies an invalid region or unknown reference. Could you please provide a more detailed command?. Thank you; Eugenio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/434#issuecomment-813523906:135,error,error,135,,https://github.com/google/deepvariant/issues/434#issuecomment-813523906,1,['error'],['error']
Availability,"Hi Andrew,. Thank you for your response. I de-identified the BAM file and wanna upload it here, but I received an error that ""We don’t support that file type."" Is there a way to send it? I appreciate your time and help!. Best,; Feng",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/109#issuecomment-2107852838:114,error,error,114,,https://github.com/google/deepvariant/issues/109#issuecomment-2107852838,1,['error'],['error']
Availability,"Hi Andrew,. Thanks for your response. There are a few items here which I'll address. 1. Is your main request that we have the ability to output a hemizygous representation of the VCF? This is something we are starting to think about for VCF and gVCF as we prepare to work with the T2T assemblies. Yes proper representation on X chromosome is important, and it's caused this problem for downstream analyses of pathogenic hemizygous variants. Likely would be true for de novo hemizygous variants on male non-PAR chromosome X. If this were fixed sooner than later that would increase confidence in DeepTrio. Until that's fixed, I'll be shifting back to DeepVariant GVCF->GLNexus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient?. If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:; 1. Run DeepTrio on trio.; 2. BCFtools to cut-out chrX + Y; 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?); 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together...;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/518#issuecomment-1048108100:386,down,downstream,386,,https://github.com/google/deepvariant/issues/518#issuecomment-1048108100,2,['down'],['downstream']
Availability,"Hi Andrew,. The Gold standard vcf file you mentioned above is only based on SHORE pipeline. Yes, you were absolutely correct! The reference bases acc to fasta file and VCF file doesn't match. Excluding that, when I tried to run the model on subset of positions for chr1:100-249000 [chr1:250951-250951 disagree on what the reference bases should be! (A != T) ] , I can't get any true positives in the result. The result contains only FN, so the model didn't make call for single variant position which are present in Truth VCF file. Please look at the screenshot I attached. I will ask my supervisor, if there is any possibility to reconcile the difference b/w the reference and bases of the VCF. Thanks for finding the actual error. . Best,; Anil. <img width=""1505"" alt=""Screenshot 2023-01-30 at 15 04 23"" src=""https://user-images.githubusercontent.com/75676816/215498753-e4340ba2-0573-4b13-a10d-33fb593cfd9f.png"">",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/606#issuecomment-1408682802:726,error,error,726,,https://github.com/google/deepvariant/issues/606#issuecomment-1408682802,1,['error'],['error']
Availability,"Hi Andrew,; Thanks for answering my questions.It is very informative.; Currently I am using the GATK pipeline to identify any novel strains for a; particular bacteria genus. So far it makes sense, meaning the known mutated; locations on the genome can be found using the pipeline. However, there are; a lot of possible false positives, which could be either potential new; SNPs, or just sequencing error. That's what prompted me to explore; DeepVarient in the first place, to minimize false positives from sequencing; error.; As I understand that GATK has a step to incorporate known variants to; correct for downstream analysis. But bacteria in general do not have those; information. I am wondering do you have any toolbox on this topic?; I'd love to perform some comparisons between different variant detection of; bacteria genomes in the near future. Will keep you posted if I find; anything interesting. On Wed, Oct 31, 2018 at 7:13 PM Andrew Carroll <notifications@github.com>; wrote:. > This is a very interesting question, and the answers to it are complex. I; > assume for the sake of the question that you have FASTQ data from; > sequencing a single bacterial colony (so this is not a metagenomics; > question).; >; > Let's divide the question between ""can it technically be done"" and ""will; > the answers be scientifically valid""; >; > To the question ""can it technically be done"", the answer is probably yes.; > I am not aware that we have specifically attempted this in bacteria. But if; > you have a FASTA file with a reference for a species and FASTQ reads, you; > should be able to generate variant calls for it.; >; > To the question ""will the answers be scientifically valid"", it is; > important to note calling variants in bacterial genomes is an area of open; > research. Using DeepVariant is reasonable, but I don't think you'll able to; > consider the output of any method (DeepVariant or other) as certain to give; > you fully correct results on this problem right out of the bo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/114#issuecomment-435084063:398,error,error,398,,https://github.com/google/deepvariant/issues/114#issuecomment-435084063,6,"['down', 'error']","['downstream', 'error']"
Availability,"Hi Andy, thank you for your response. I am working with ancient DNA which in the vast majority of the cases comes; at coverages between 0.1-1X. So data missingness is a reality we know how; to deal with, I just want to make sure that the calls we are making are; accurate. The second family of data I am working with are indigenous groups that are; at least diverged from the reference over 2000 generations ago. We observe; a strong bias towards the reference allele using GATK, but it'll be very; interesting to see how DeepVariant behave in such cases. On Wed, 26 Feb 2020 at 11:17, Andrew Carroll <notifications@github.com>; wrote:. > Hi @yassineS <https://github.com/yassineS>; >; > Thank you for the question. In short, DeepVariant tends to call fewer; > variants as coverage drops (this is similar to other callers). We have; > benchmarks for down to 15x of Illumina WGS at our ""20 is the new 30 blog; > post; > <https://google.github.io/deepvariant/posts/2019-09-10-twenty-is-the-new-thirty-comparing-current-and-historical-wgs-accuracy-across-coverage/>.; > This also breaks down the types of errors by class as coverage falls.; >; > I am not sure what the lower bound of coverage for using DeepVariant. At; > some point, imputation approaches will be required instead of variant; > calling ones. I would guess this is somewhere around 5x-8x.; >; > I am curious how low you consider low coverage, so I understand your use; > case.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/279?email_source=notifications&email_token=AANPQIK47CJ7LXIEDGA365DREW3YTA5CNFSM4K2FW2S2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEM6JIGA#issuecomment-591172632>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AANPQIIDTK3D5ON7PYU7BE3REW3YTANCNFSM4K2FW2SQ>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/279#issuecomment-591260702:850,down,down,850,,https://github.com/google/deepvariant/issues/279#issuecomment-591260702,3,"['down', 'error']","['down', 'errors']"
Availability,"Hi Attila,. So your account would need `sudo` privileges, which you probably already figured out. The `run-prereq.sh` itself [contains calls](https://github.com/google/deepvariant/blob/r0.4/run-prereq.sh) using `sudo`, which is why you are getting the `not permitted` OS error. If you curious to see the trace of the script to determine where the issue might be arising from, just run it like this and that will provide you with an exact control-flow:. `sudo bash -x ./run-prereq.sh`. So these suggestions are just for curiosity purposes, and Pi-Chuan's recommendation is the correct one since it has been validated on Ubuntu 16.04. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/41#issuecomment-360945398:271,error,error,271,,https://github.com/google/deepvariant/issues/41#issuecomment-360945398,1,['error'],['error']
Availability,"Hi Bo,. First remove the following two from your command-line:. ```; --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp; --intermediate_results_dir=/tmp; ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/679#issuecomment-1636698433:579,error,error,579,,https://github.com/google/deepvariant/issues/679#issuecomment-1636698433,1,['error'],['error']
Availability,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo; processor	: 0; vendor_id	: GenuineIntel; cpu family	: 6; model		: 63; model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz; stepping	: 2; microcode	: 0x3c; cpu MHz		: 1200.024; cache size	: 30720 KB; physical id	: 0; siblings	: 24; core id		: 0; cpu cores	: 12; apicid		: 0; initial apicid	: 0; fpu		: yes; fpu_exception	: yes; cpuid level	: 15; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts; bugs		: cpu_meltdown spectre_v1 spectre_v2; bogomips	: 5187.99; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/74#issuecomment-391790774:1504,down,downloaded,1504,,https://github.com/google/deepvariant/issues/74#issuecomment-391790774,1,['down'],['downloaded']
Availability,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```; ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam; ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` ; INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam; ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```; INPUT_DIR=""${PWD}/inputs"" ; BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam; ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```; INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```; Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1699969751:556,echo,echo,556,,https://github.com/google/deepvariant/issues/184#issuecomment-1699969751,2,['echo'],['echo']
Availability,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow.; It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-479584377:270,error,error,270,,https://github.com/google/deepvariant/issues/167#issuecomment-479584377,2,['error'],['error']
Availability,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483500506:924,error,error,924,,https://github.com/google/deepvariant/issues/171#issuecomment-483500506,2,['error'],['error']
Availability,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. ; Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```; docker run \; --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \; google/deepvariant:""1.5.0"" ls -l /input; ```. $`2)`$ This is using volumes, which is a different approach:. ```; docker volume create --name dv-vol. docker run \; --mount source=dv-vol,target=""/input"" \; google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \; --mount source=dv-vol,target=""/input"" \; google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \; --mount source=dv-vol,target=""/input"" \; google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol; ```. If the volume removal gives you an error like this:. ```; Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]; ```; Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```; docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2; ```. Let me know the results of both steps. Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1701584604:1196,error,error,1196,,https://github.com/google/deepvariant/issues/184#issuecomment-1701584604,2,"['Error', 'error']","['Error', 'error']"
Availability,"Hi Charles,; the bad_alloc error could indicate that you're running out of memory on this machine.; It seemes like m5.4xlarge have 64 GB RAM? Currently postprocess_variants reads in everything in memory and sorts them, which can take quite a lot of memory depending on how many records the previous step generated.; I suggest trying this step on a machine with more RAM, or keep an an eye on whether the memory usage is an issue. Currently for our WGS Case Study , we recommend getting a machine with 128GB RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-479348077:27,error,error,27,,https://github.com/google/deepvariant/issues/167#issuecomment-479348077,1,['error'],['error']
Availability,"Hi Cory (@cmclean),. Thank you for the updated version, and when you get a chance could you please update the binaries as there is no `0.5.2` version yet available:. ```Bash; $ gsutil ls -l gs://deepvariant/binaries/DeepVariant/; gs://deepvariant/binaries/DeepVariant/0.4.0/; gs://deepvariant/binaries/DeepVariant/0.4.1/; gs://deepvariant/binaries/DeepVariant/0.5.0/; gs://deepvariant/binaries/DeepVariant/0.5.1/; $; ```. Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/57#issuecomment-371614660:154,avail,available,154,,https://github.com/google/deepvariant/pull/57#issuecomment-371614660,1,['avail'],['available']
Availability,"Hi Cory,. After fixing the issue, the run completed without any error. ; My yaml file has arguments for both vcf and gvcf but different values.; --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \; --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant.; I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,; Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/86#issuecomment-414199549:64,error,error,64,,https://github.com/google/deepvariant/issues/86#issuecomment-414199549,1,['error'],['error']
Availability,"Hi Daniel,; Thanks for your response!. If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory; > ERROR : Child exit with status 255. However, if I specify the image:. ```; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc; ```; The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help!; Dave",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/546#issuecomment-1180869896:88,error,error,88,,https://github.com/google/deepvariant/issues/546#issuecomment-1180869896,3,"['ERROR', 'avail', 'error']","['ERROR', 'available', 'error']"
Availability,"Hi Edoardo,. Thank you for filing this issue. This is an expected behavior in the current implementation of DeepVariant. As it is impractical & inefficient to represent each base position with hom. ref. calls in gVCF files, we consolidate multiple hom. ref. positions with similar GQ values into one gVCF block. A gVCF block with `MIN_DP=0` (but with positive GQ/PL values) will be created when the nearby hom. ref. positions also have very low GQ (but not all 0). Another thing that makes this problem more subtle is that we exclude lower quality from counting the DP. We think it makes sense to separate out blocks with no coverage in gVCF records and set GT to `./.` as you suggested. We started internal discussion about it and started tracking the issue internally. We will be sure to give an update here whenever we have any update. For your last question about GLnexus, I'm not aware of a GLnexus setting that can set DP zero outputs as missing. The only thing I can think of for now is adding an annotation for DP=0 calls using [bcftools](http://samtools.github.io/bcftools/bcftools.html), etc. and handling them separately in downstream analysis. I hope this helps and please let us know if you have any follow up questions or comments. I'll keep this issue open until we have an update. Thank you. Best,; Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/346#issuecomment-692271819:1135,down,downstream,1135,,https://github.com/google/deepvariant/issues/346#issuecomment-692271819,1,['down'],['downstream']
Availability,"Hi Eva, . Usually such comparisons are rare, as Kishwar suggested through Heng's article. If you are curious about such a comparison, below is a table generated on GIAB samples through [GATK's HaplotypeCaller](https://gatk.broadinstitute.org/hc/en-us/articles/17295731870235-Masked-reference-genomes) on GRCh38 and GRCh38 with masked alt regions:. ![image](https://github.com/google/deepvariant/assets/6555937/18be1f0e-6c1f-4c65-ae76-51661af20282). Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/37#issuecomment-1675079201:275,Mask,Masked-reference-genomes,275,,https://github.com/google/deepvariant/issues/37#issuecomment-1675079201,2,"['Mask', 'mask']","['Masked-reference-genomes', 'masked']"
Availability,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/675#issuecomment-1632300046:523,error,error,523,,https://github.com/google/deepvariant/issues/675#issuecomment-1632300046,2,['error'],['error']
Availability,"Hi Guillaume,. Thank you for filing the issue and for the detailed explanation of your use case. I'd like to ask you some more questions to better understand the situation and to find a potential solution. 1. If we call the cohort you're processing with DeepVariant+GLnexus ""cohort **X**"", are you (a) using cohort **X** as a reference panel to impute another cohort **Y**, (b) using another cohort **Y** as a reference panel to impute your cohort **X**, or (c) using imputation software (e.g. Beagle) to re-genotype cohort **X** using the PL values in cohort **X** itself?; 2. In the example case you mentioned (""some samples have an actual variant but most of the other samples have a no call""), the no calls in the other samples would imply we don't have enough evidence (in terms of coverage, read quality, mapping quality, etc.) to call the other samples either reference or variant. Would keeping that cohort-level variant desirable for your downstream application? If it is, is there any other type of filters you can use (other than the imputation score) to keep those records (e.g. maximum of GQs in all samples)?; 3. Changing the no-call genotypes `./.` to the reference calls `0/0` is a relatively simple transformation (e.g. `bcftools +missing2ref`) that we use for some specific downstream applications. Would that help in your situation?. Thank you,; Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/403#issuecomment-760500649:948,down,downstream,948,,https://github.com/google/deepvariant/issues/403#issuecomment-760500649,4,['down'],['downstream']
Availability,"Hi Gunjan,; and thanks a lot for your reply. Yes, the directories where all accessible and under ```root``` (I know it can be done better....).; Indeed when I added to the docker command the option ``` --user root``` the error changed and was very clear: ``` disk full```.; It remains to me to free disk or change docker location, add a docker group to allow users run it without ```sudo``` and rerun it. I am pretty confident it should work. With Regards,; -A",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/325#issuecomment-659193187:221,error,error,221,,https://github.com/google/deepvariant/issues/325#issuecomment-659193187,2,['error'],['error']
Availability,"Hi I'm the GLnexus maintainer. From that side we're currently lacking a motivating, medium/large scale study with DeepVariant gVCF files which would provide the context to chase down the gnarly corner cases that arise in gVCF merging / joint genotyping, completing the current ""experimental"" integrated configuration. There are a few candidates in the pipeline but more would be really welcome. Ping me if I can help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/142#issuecomment-465059695:178,down,down,178,,https://github.com/google/deepvariant/issues/142#issuecomment-465059695,2,"['Ping', 'down']","['Ping', 'down']"
Availability,"Hi Ji,. I understand better what you're trying to do -- glad for Maria's questions and Andrew's comments. I'm not sure DeepVariant might be optimal for that, as it was designed for germline variant-calling, and these errors are usually cleaned/corrected by other means before they arrive in DeepVariant. For STR analysis maybe [HipSTR for Illumina](https://github.com/HipSTR-Tool/HipSTR) or [DeepRepeat for Nanopore](https://github.com/WGLab/DeepRepeat) might help as a first pass, but I'm still trying to think a bit more here. . Regarding DeepVariant, I need think a bit longer about how it might be used as an inference tool given how it is designed. You can still experiment with what I mentioned to see how it reacts, though it might not be something I would put a lot of confidence until you validate it by other means. . As you mentioned, keep in mind you need to compare with a truth set you might have to generate in your lab via something like Sanger sequencing with a high-fidelity PCR enzyme. Sorry if this lead you too far astray, but I wanted to post before you spent too much time. Let us know in case there are any questions you might have of why and how DeepVariant operates. Thanks,; Paul. #### References. [1] [Genome-wide profiling of heritable and de novo STR variations (HipSTR paper)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5482724/); [2] [DeepRepeat: direct quantification of short tandem repeats on signal data from nanopore sequencing](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02670-6)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/697#issuecomment-1683256496:217,error,errors,217,,https://github.com/google/deepvariant/issues/697#issuecomment-1683256496,1,['error'],['errors']
Availability,"Hi Lucas,. yes, the only version I can install is DeepVariant 0.7.0. I tried to install tensorflow-estimator first (v2.13.1) but still have same error as mentioned. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/835#issuecomment-2187865343:145,error,error,145,,https://github.com/google/deepvariant/issues/835#issuecomment-2187865343,1,['error'],['error']
Availability,"Hi Maria,. Thanks for the response. My Intent is to generate frozen graph from the available checkpoints. The code snippet is my own. Do you think it needs any fixing / addition? . Is there anyone who can provide steps/methods/guidance? I tried from inside as well as outside the Docker. I even tried Google Colab with different Hardware configurations -- i.e. combination of CPU, GPU, TPU. And also with different TF versions. I am never able to import the meta graph and restore the checkpoint. I always get ""No Op Kernel was registered"" with different Op names. Additional question: for training:. - Can I train on the ""quickstart-testdata"" provided in deepvariant? ; - And how do I produce a frozen graph during a training run?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/339#issuecomment-681204545:83,avail,available,83,,https://github.com/google/deepvariant/issues/339#issuecomment-681204545,6,"['avail', 'checkpoint']","['available', 'checkpoint', 'checkpoints']"
Availability,"Hi Maria,; I'm very glad and excited to get a response from you personally. I appreciate your work and get a lot of help from your youtube videos :); Thank you very much for the answer, this is exactly what I've thought and tried to do. For a specific region (for example: ""chr15:98707564-98707715"") it worked well and produced a vcf file. For the bed file I've used the command:; bedtools bamtobed [OPTIONS] -i <BAM>; It extracted the regions from the bam file and than I removed the last three columns (bedtools creates bed file with 6 columns). The problem is that when I run the command with the exome regions from the capture protocol it also not working for me; (""idt_capture_novogene.grch38.bed""). Again I get the error:; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/wes_deepvarfast_38.sorted.bam --examples /output/inter_res/make_examples.tfrecord@8.gz --gvcf /output/inter_res/gvcf.tfrecord@8.gz --regions /input/idt_capture_novogene.grch38.bed --task 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/483#issuecomment-917336418:721,error,error,721,,https://github.com/google/deepvariant/issues/483#issuecomment-917336418,1,['error'],['error']
Availability,"Hi Maria,; Thanks a lot for your help!; [problematic logs with training.docx](https://github.com/google/deepvariant/files/4641018/problematic.logs.with.training.docx). Now I am setting Google Cloud SDK in our Linux system, but whenever I run the following command, there is an error.; ( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \; sudo nvidia-docker run \; -v ${HOME}:${HOME} \; google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/make_examples \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM_CHR1}"" \; --examples ""${OUTPUT_DIR}/training_set.with_label.tfrecord@${N_SHARDS}.gz"" \; --truth_variants ""${TRUTH_VCF}"" \; --confident_regions ""${TRUTH_BED}"" \; --task {} \; --regions ""'chr1'"" \; ) >""${LOG_DIR}/training_set.with_label.make_examples.log"" 2>&1; Since there are no GPUs in our server, I changed the ""nvidia-docker"" to ""docker"", and the ""${BIN_VERSION}-gpu"" to ""${BIN_VERSION}"", but it still didn't work with an error that 'The index file is older than the data file'.; The log is attached here and I wonder whether the training mode could work without a GPU machine. Thanks a lot!; Best regards,; Weiwei",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/308#issuecomment-629860393:277,error,error,277,,https://github.com/google/deepvariant/issues/308#issuecomment-629860393,2,['error'],['error']
Availability,"Hi Maria,; thanks for your answer. I will thus not merge WGS and WES data, but analyze them separately instead. This way I can compare and have a look at the potential issues you mention. ; And thanks for checking: I am indeed looking at germline variant calling. A question regarding the pileup images you mention that are downsampled during runtime to 95x:; Here (https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details.md#updates-on-deepvariant-since-precisionfda-truth-challenge-and-biorxiv-preprint) it says: ""_The biggest change was to move away from RGB-encoded (3-channel) pileup images and instead represent the aligned read data using a multi-channel tensor data layout. We currently represent the data as a 6-channel raw tensor in which we encode: ..._"" Is the downsampling to 95x still applied in the new design?. thanks, Christian.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/338#issuecomment-680771609:324,down,downsampled,324,,https://github.com/google/deepvariant/issues/338#issuecomment-680771609,2,['down'],"['downsampled', 'downsampling']"
Availability,"Hi Mark and Asha,; here's what I believe the current status is:; (1) If there is just an empty shard (a shard file that exist, but just contains 0 record) out of many, what happens is the code will move on to the next shard to attempt to read image/format. -- this is what Mark meant by the previously fixed empty shards bug.; (2) However, if all the shard files exist but all of them contains 0 records, the current code can fail with that error message above. In this case, if the actual error message observed is:; The TF examples in /mnt/data/input/gs/wgs-test-shan/test_samples/UDN689484temp/examples/examples_output.tfrecord-00000-of-00064.gz has image/format 'None' (expected 'raw'). It seems like this call_variant run is specifically being done on on that one file. And if that file has 0 record, unfortunately it will currently fail with that error. :-(. So, I think this is a real bug that we should fix. Because we do expect the use case where users run 64 separate call_variants, and some of them might have complete empty single input file. Is that correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/27#issuecomment-355805026:441,error,error,441,,https://github.com/google/deepvariant/issues/27#issuecomment-355805026,3,['error'],['error']
Availability,"Hi Masaru,; we have not tried loading the model checkpoints this way before.; Since it's a colab, can you share the colab so we can try it out as well?. I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/127#issuecomment-445917254:48,checkpoint,checkpoints,48,,https://github.com/google/deepvariant/issues/127#issuecomment-445917254,2,['checkpoint'],"['checkpoint', 'checkpoints']"
Availability,"Hi Nima, ; I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. ; ```; call-varia--root--180510-193828-03: SUCCESS; Traceback (most recent call last):; File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>; run(); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run; _run_call_variants(pipeline_args); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants; result.get(); File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get; raise self._value; RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]].; (exit status 1); ```. Here are the full runner log. You can find out the yam file in the same repo.; [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log); [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log); [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/70#issuecomment-388183666:95,avail,available,95,,https://github.com/google/deepvariant/issues/70#issuecomment-388183666,4,"['Error', 'avail', 'error']","['Error', 'available', 'error']"
Availability,"Hi Paul, . I got an error when running on my HPC so I'm just waiting for the IT people to get back to me, I assume its a simple fix since I have managed to get the deepvariant container to work a few months back: . ```; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LANG = ""en_GB.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LANG = ""en_GB.UTF-8""; are supported and installed on your system.; ```. I'll let you know when they reply!; Amy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/691#issuecomment-1667418894:20,error,error,20,,https://github.com/google/deepvariant/issues/691#issuecomment-1667418894,2,['error'],['error']
Availability,"Hi Paul, ; Thank you for the answer, it works!; Although I still got some error about the format of BAM file, I can try if I can resolve it on my own. Thanks again!; LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/577#issuecomment-1702241369:74,error,error,74,,https://github.com/google/deepvariant/issues/577#issuecomment-1702241369,1,['error'],['error']
Availability,"Hi Paul, thanks for mentioning this issue.; I looked at our documentation and noticed that an update was made to our README a few days ago with this extra description:. Pre-built binaries are available at [gs://deepvariant/](https://console.cloud.google.com/storage/browser/deepvariant).; These are compiled to use SSE4 and AVX instructions, so you'll need a CPU (such as Intel Sandy Bridge) that supports them. (The file /proc/cpuinfo lists these features under ""flags"".). But it seems like this new information to the doc hasn't be synced to the external GitHub yet. This should come out in the new year at the latest. I suspect we'd like to keep the pre-built binary having optimization. But we will at least add that line of disclaimer so that it's clear what the binaries are built for.; Would it be ok for you to build DeepVariant for your CPU by following [Building and testing; DeepVariant](docs/deepvariant-build-test.md), or do you need pre-built binaries without AVX from us?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/21#issuecomment-353701703:192,avail,available,192,,https://github.com/google/deepvariant/issues/21#issuecomment-353701703,2,['avail'],['available']
Availability,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue.; [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/94#issuecomment-422863842:167,error,error,167,,https://github.com/google/deepvariant/issues/94#issuecomment-422863842,4,"['error', 'failure']","['error', 'failures']"
Availability,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me ; docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling.; See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol; dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input; total 0; -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world; 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file; touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file; -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input; total 0; -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file; -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1701949973:635,Error,Error,635,,https://github.com/google/deepvariant/issues/184#issuecomment-1701949973,1,['Error'],['Error']
Availability,"Hi Paul,. Thank you very much for responding to my questions and providing detailed explanations, and it's give me some very import tips tha I ignore before, so very appreciate for your reply. A few hours ago I tried to change command --regions chx:xxxxx-xxxxxx to --regions chx, deleted the locations of rigion and it output excepted files. But somethings confused me again, for example, my research topic is about repeat times in the NGS data, and my original intention in using Deepvariant is to detect the sequencing noise and delete them or find the true data in noised data. However ,what I saw is that the Deepvariant only can print one mutation such like following string:. chx xxxxxx .	TAAA	T	1.6	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:5:490:36,81:0.165306:0,3,25. This is very contrary to common sense, because in this loci it have at least 490 reads to cover it (it maybe more because Deepvariant can't recognize all reads due to empty align), Deepvariant only give one mutation that is TAAA to T, but when I open IGV to focus on the loci, it shows that they are more than one mutation, in fact, it's far more than one mutation. I mentioned in the previous paragraph that I am very grateful for your reply because you give me one tip is that :"" Keep in mind, the pileup images for DeepVariant are ~100 reads, so it will randomly down-sample from the reads to fit into the maximum of the allowed pileup image."" So I think maybe what confuse me is that Deepvariant only can detect 100x depth data? or somethings else I can do to detect truth sequence data in NGS data?. Very sorry to bother you, wish you a pleasant work and life,; Ji",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/697#issuecomment-1680308857:1334,down,down-sample,1334,,https://github.com/google/deepvariant/issues/697#issuecomment-1680308857,1,['down'],['down-sample']
Availability,"Hi Paul,; Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:; ```; lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam; lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta; ```; Looks the docker knows where the file is. And this is my Linux info and docker version:; ```; Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux; Docker version 18.03.1-ce, build 9ee9f40; ```; I'm new to Linux, hoping this can provide useful information. Thanks, ; LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/577#issuecomment-1702203397:66,reboot,rebooting,66,,https://github.com/google/deepvariant/issues/577#issuecomment-1702203397,1,['reboot'],['rebooting']
Availability,"Hi Phil,; an update:; @cmclean pointed out that it comes from this line of our code:; https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/resources.py#L158. We're getting this information for debugging purpose only (DeepVariant outputs some information about the run in case developers need to remember how the run was done). ; I suspect your run was done on a system where the method wasn't implemented. One possible fix is to make our code more robust is to:; ```; try:; freq = psutil.cpu_freq(); return freq.current if freq is not None else 0.0; except NotImplementedError:; return 0.0; ```. We'll fix this internally soon, and it should come out next time we make a release. Thanks for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/191#issuecomment-504492772:491,robust,robust,491,,https://github.com/google/deepvariant/issues/191#issuecomment-504492772,1,['robust'],['robust']
Availability,"Hi Phil,; as you can see from the log you posted, the error actually came from:; ```; File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq; ""can't find current frequency file""); ```; If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how.; And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/191#issuecomment-504481029:54,error,error,54,,https://github.com/google/deepvariant/issues/191#issuecomment-504481029,4,['error'],['error']
Availability,"Hi Pi-Chuan, ; I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```; call-varia--root--180508-211940-52: FAILURE; [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]; [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-te",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/70#issuecomment-387564029:102,error,error,102,,https://github.com/google/deepvariant/issues/70#issuecomment-387564029,8,"['ERROR', 'Error', 'FAILURE', 'error']","['ERROR', 'Error', 'FAILURE', 'error']"
Availability,"Hi Pi-Chuan,; Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well.; ```; make-examp--root--180505-205721-02: FAILURE; [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']; [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']; Traceback (most recent call last):; File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>; run(); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/70#issuecomment-386838731:73,error,error,73,,https://github.com/google/deepvariant/issues/70#issuecomment-386838731,6,"['ERROR', 'Error', 'FAILURE', 'error']","['ERROR', 'Error', 'FAILURE', 'error']"
Availability,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam""; Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/219#issuecomment-531389119:17,error,error,17,,https://github.com/google/deepvariant/issues/219#issuecomment-531389119,1,['error'],['error']
Availability,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```; wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl; ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python; DESCRIPTOR = _descriptor.FileDescriptor(; name='tensorflow/core/framework/resource_handle.proto',; package='tensorflow',; syntax='proto3',; serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/94#issuecomment-423037408:44,error,errors,44,,https://github.com/google/deepvariant/issues/94#issuecomment-423037408,2,"['down', 'error']","['download', 'errors']"
Availability,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/677#issuecomment-1636029771:494,down,down,494,,https://github.com/google/deepvariant/issues/677#issuecomment-1636029771,2,"['down', 'resilien']","['down', 'resilient']"
Availability,"Hi Shruti,. Glad to hear that the renaming fixed the prior error. I don't see the bash or yaml files attached, but I'm curious how many variants are present in the VCF output file and how that compares to the GATK3 output (and verifying that you're running on human samples). File sizes can vary due to additional annotations added or compression (and compression level) applied to the result. On a Unix system you can find the number of lines in the output VCF file using. wc -l ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"". or, if it's gzip compressed,. zcat ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"" | wc -l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/86#issuecomment-414351015:59,error,error,59,,https://github.com/google/deepvariant/issues/86#issuecomment-414351015,1,['error'],['error']
Availability,"Hi Sidharth,. Thanks for your kind comments.; I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:; > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform.; Then, are your scripts for shuffling training set available only in Google Cloud Platform?. Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/133#issuecomment-451807897:295,avail,available,295,,https://github.com/google/deepvariant/issues/133#issuecomment-451807897,1,['avail'],['available']
Availability,"Hi Sophie,. So it is best to train across all the samples. The reason is that the model will need to be representative of all those samples, and you don't want to overfit for one sample over another. Today there is more data than computing power and memory, so training happens by batching the data, training on a batch, and then tweaking the model in the follow-up batches. Here's a visual example of what could happen:. ![image](https://github.com/google/deepvariant/assets/6555937/3ff13990-c2cc-4863-a904-bb0219791b06). In the first batch, the coefficients will be biased in a monotonically increasing function. Then when the second batch is used to tweak the model's parameters, it will shift towards a monotonically decreasing function shifting it towards an opposite direction. Then when the third batch comes in it will shift the parameters in the other direction. Sure, the independent variable (x-axis) here is a simple one-dimensional type, but this can become complex with multiple channels (`read base`, `base quality`, `mapping quality`, etc). And of course if the training data is shuffled, then the validation data and tuning data should also be shuffled in order to have the same data representation - with the exception of the test data, which will be used for benchmarking the model as a real scenario (though there is additional read shuffling when downsampling with too many reads for a pileup image). As @akolesnikov mentioned, the `input_pattern_list` parameter of the shuffle script takes a list of files, so you can do it all at once. Let me know if I should expand on anything. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/698#issuecomment-1711046219:1368,down,downsampling,1368,,https://github.com/google/deepvariant/issues/698#issuecomment-1711046219,2,['down'],['downsampling']
Availability,"Hi Sophie,. This is great news! Yes, usually that is the expected behavior after several rounds of training. Let me answer each aspect separately:. $`1)`$ So given a trained model, you can specify a custom checkpoint file via `--customized_model`, as shown under the [*Pick a model*](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md#pick-a-model) section. Probably it would be easiest to pick the one that is specified by the `best_checkpoint.txt` file. $`2)`$ Regarding `.pb` files, these are serialized binary ProtoBuf formatted versions of the model with additional details, denoted as the [*TensorFlow's SavedModel format*](https://www.tensorflow.org/guide/saved_model). When performing variant calling, DeepVariant can only use `.ckpt` model files - not `.pb` files - as specified under the [*Convert model.ckpt to model.pb*](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#convert-modelckpt-to-modelpb-savedmodel-format) section. May I ask why you might need the ProtoBuf formatted file? . $`3)`$ Regarding the `model.ckpt.example_info.json` file, it is used to validate the checkpointed model's JSON file with the JSON file generated for the examples files, matching against a few specs such as channels and shape (tensor image dimensions), to ensure data and model match before performing variant calling. It should have been automatically copied over by the [`copy_over_example_info_json()` function](https://github.com/google/deepvariant/blob/r1.5/deepvariant/model_train.py#L151-L162). Basically it contains the version of DeepVariant, the tensor image shape (rows, columns, channels) and enumerated channels. There are different ones for different technologies, and below is a list of the contents for each instrument:. ##### ONT R10.4; ```Json; {""version"": ""1.5.0"", ""shape"": [100, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ```. ##### PacBio; ```Json; {""version"": ""1.5.0"", ""shape"": [100, 199, 9], ""channels"": [1,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1732869051:206,checkpoint,checkpoint,206,,https://github.com/google/deepvariant/issues/706#issuecomment-1732869051,2,['checkpoint'],['checkpoint']
Availability,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system?; 2) How much free memory do you have?; 3) How much free disk space do you have?; 4) How many CPU cores do you have and how occupied are they?; 5) Do you NVIDIA GPUs that are available to you on your system?. I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/681#issuecomment-1641013019:495,avail,available,495,,https://github.com/google/deepvariant/issues/681#issuecomment-1641013019,1,['avail'],['available']
Availability,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```; # install gsutil; curl https://sdk.cloud.google.com | bash; exec -l $SHELL; # verify that gsutil is working; gsutil. # install wget and bzip2, which are both needed to download miniconda; sudo yum install bzip2 wget; wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh; bash Miniconda2-latest-Linux-x86_64.sh ; source ~/.bashrc. # gsutil is failing now; gsutil; export BOTO_CONFIG=/dev/null; # gsutil should be working again; gsutil. # create new conda env, add channels, install deepvaraint; conda create -n dv python=2.7; conda activate dv; conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge; conda install -n dv deepvariant -v; ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`?; * Did you add all conda channels in the correct order?; * Could you post the entire output from running `conda install -v deepvariant`?.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-452921108:424,error,error,424,,https://github.com/google/deepvariant/issues/137#issuecomment-452921108,2,['error'],['error']
Availability,"Hi dhwani2410,. That functionality is not available. If you could tell me what exactly you're trying to achieve I may have some suggestions for you. Thank you; Alexey",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/188#issuecomment-501453743:42,avail,available,42,,https://github.com/google/deepvariant/issues/188#issuecomment-501453743,1,['avail'],['available']
Availability,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2; I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : ; - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc.; The make command ran well (no error of what I can see) but when I do make check it crashes with ; test-math-isinff.cc: Command not found; If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ?; Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-480128599:579,down,down,579,,https://github.com/google/deepvariant/issues/137#issuecomment-480128599,3,"['down', 'error', 'fault']","['down', 'error', 'fault']"
Availability,"Hi kmarianski,. This line is suspicious. ; ```; Re-using the directory for intermediate results in /tmp/kmarians_4189323/tmpxrz5rqbp; ```. Each DeepVariant job needs a separate `intermediate_directory`. Could you verify that each job uses different temp directory?. The error in the log comes from TensorFlow library. Unfortunately, we are unable to help with TensorFlow (which is a third party tool).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/602#issuecomment-1381120099:270,error,error,270,,https://github.com/google/deepvariant/issues/602#issuecomment-1381120099,1,['error'],['error']
Availability,"Hi masgouri@, . Thanks for the excellent question and for sharing that you've been having good experiences with DeepVariant. We are always interested in user stories so if you feel like sharing more about your experiences with DeepVariant please send them our way. There are a few separate issues here; let me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predic",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/67#issuecomment-383764665:623,down,down,623,,https://github.com/google/deepvariant/issues/67#issuecomment-383764665,2,['down'],['down']
Availability,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage.; In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. ; Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/249#issuecomment-563510580:146,failure,failure,146,,https://github.com/google/deepvariant/issues/249#issuecomment-563510580,1,['failure'],['failure']
Availability,"Hi there! Thanks for the great work.; I encountered the similar problem here. I have PacBio long-read scRNA-seq data, and I am trying to use DeepVariant on the pseudobulk level. However,`isoseq groupdedup` removed the quality scores in my bam files during preprocessing, which causes error ; As you mentioned above, should I skip the deduplication step (but keep primer removal, tag, refine, barcode correction and sorting) and then align to reference genome using `pbmm2`? Or should I use another deduplication tool that keeps base quality score?. Thanks for any help in advance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/672#issuecomment-2388558929:284,error,error,284,,https://github.com/google/deepvariant/issues/672#issuecomment-2388558929,1,['error'],['error']
Availability,"Hi there!. I tried to combine the deepvariant's gvcf files using GATK and it returned a error because of the ""NON_REF"".; Do you have any other recommendation? Or did you tested your gvcf in GATK?. This is the error that I got using GATK:; A USER ERROR has occurred: The list of input alleles must contain <NON_REF> as an allele but that is not the case at position 10325413; please use the Haplotype Caller with gVCF output to generate appropriate records. The DeepVariant ""<NON_REF>"" allele is ""<*>""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/45#issuecomment-481414559:88,error,error,88,,https://github.com/google/deepvariant/issues/45#issuecomment-481414559,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi! When I downloaded all the pre-built binaries and run the run-prereq.sh scripts. How I suppose to run the make_example parallel?; I use the following command: ; seq 0 47 | parallel -q --halt 2 --line-buffer python3 make_examples.zip --mode calling --ref /data/input/human_g1k_v37.fasta --reads /data/input/c6c4c1db-4328-4aa9-b038-074c9a453117.dedup.bam --examples make_examples.tfrecord@12.gz. showing error:. E0430 18:57:45.160124 140015706085184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_9oblbsyi/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '33']"".; E0430 18:57:45.128387 140717112878912 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_gd9fj22_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '2']"".; E0430 18:57:45.149224 139802704738112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_2hbfxd92/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '16']"".; E0430 18:57:45.196900 140351706515264 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles__ytoy0a6/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '4']"".; E0430 18:57:45.304501 140371551012672 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_w7jwxlqo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '28']"".; E0430 18:57:45.337900 139621533210432 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:1017,error,errors,1017,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability,"Hi!. I read both of blog posts, and I could see that even the primary goal is working with human data, DV is very robust. My specie is diploid, so Iguess it helps, and the variant density should no be too different from humam or rice. . I Actually have two datasets; one is the megagametophyte (1n) of the same individuals (2n). Unfortunatelly, at this point, I don't have a gold dataset to train the data. I'm trying to get at least a truth set to help me in this quest. . Thanks for enlightening",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/357#issuecomment-698608583:114,robust,robust,114,,https://github.com/google/deepvariant/issues/357#issuecomment-698608583,1,['robust'],['robust']
Availability,Hi!. I'm not sure I've seen this error before. It seems that the file is accessible given that it appears to be failing on parsing of the `DeepVariantDatasetConfig` proto. . Is is possible for you to share 1 of the files in the mounted bucket? That would allow us to try this on our end. Thanks!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/837#issuecomment-2187745312:33,error,error,33,,https://github.com/google/deepvariant/issues/837#issuecomment-2187745312,1,['error'],['error']
Availability,"Hi!. Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint.; ```; model_example_info_json = f'{checkpoint_path}/example_info.json'; model_example_shape = dv_utils.get_shape_and_channels_from_json(; model_example_info_json; ); ```. Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/869#issuecomment-2307639231:104,checkpoint,checkpoint,104,,https://github.com/google/deepvariant/issues/869#issuecomment-2307639231,2,['checkpoint'],"['checkpoint', 'checkpoints']"
Availability,"Hi, ; I am now testing the quickstart with the test data (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) inside of docker and I get the error ValueError: Not found: Could not open quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam. I followed the instructions and ; ```; OUTPUT_DIR=quickstart-testdata/; REF=quickstart-testdata/ucsc.hg19.chr20.unittest.fasta; BAM=quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam. ## test deepvariant; docker run \; -v /home/${USER}:/home/${USER} \; gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""${REF}"" \; --reads ""${BAM}"" \; --regions ""chr20:10,000,000-10,010,000"" \; --examples ""${OUTPUT_DIR}/examples.tfrecord.gz""; ```. The BAM file is there, when I try ls $BAM, I get: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam. Any suggestions would be great, thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/104#issuecomment-439540680:170,error,error,170,,https://github.com/google/deepvariant/issues/104#issuecomment-439540680,1,['error'],['error']
Availability,"Hi, ; I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done; Verifying transaction: done; Executing transaction: done; ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'.; Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0; location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh; ==> script messages <==; <None>; ==> script output <==; stdout: ; stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1...; INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2...; INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3...; INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4...; INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5...; INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6...; INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7...; INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8...; INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9...; INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10...; INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11...; INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12...; INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13...; INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14...; INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15...; INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16...; INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17...; INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18...; INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19...; INFO 1101 15:01:00.705409 util.py] Retrying r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/228#issuecomment-549130970:20,error,error,20,,https://github.com/google/deepvariant/issues/228#issuecomment-549130970,4,"['ERROR', 'down', 'error']","['ERROR', 'download', 'error']"
Availability,"Hi, ; thank you both for the answers and suggestions. > The error comes from the line `output_queue = multiprocessing.Queue()` Could you try a simple test? Run docker in CLI model: `docker run -it <DeepVariant image> bash` Inside docker start Python3 and execute:; > ; > ```; > import multiprocessing; > q = multiprocessing.Queue(); > ```; > ; > Please let us know if that works. No, it doesn't work. I get the following error that parallels the one above (full disclosure: I run it again with udocker, not docker):; ```; Python 3.8.10 (default, May 26 2023, 14:05:08); [GCC 9.4.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import multiprocessing; >>> q = multiprocessing.Queue(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory; ```. Also the approach suggested by @kishwarshafin unfortunately didn't work for me. I thought that udocker could be a viable option considering what said in #669. Maybe I'll try to downgrade to 1.5.0 since it's the version that was mentioned in the orginal post. . I'm not really familiar with multiprocessing but I will have a look. If you have any additional pointers, I would be really grateful for them :) . Thank you! ; Federico . EDIT: I tried running DeepVariant v1.5.0 and indeed it works! So I guess it is an issue of the newer release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/733#issuecomment-1818694916:60,error,error,60,,https://github.com/google/deepvariant/issues/733#issuecomment-1818694916,6,"['down', 'error']","['downgrade', 'error']"
Availability,"Hi, @MariaNattestad . Thank you very much for your kind advice. I have figured out what caused this error and it did work. Additionally, I don't understand how DeepVariant defines those candidate variants when making examples. I know it is implemented by the file ""allelecounter.cilf"", but I get limited information from this file. ; Could you please tell me more information about the candidate variants part?. Thank you again for your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/485#issuecomment-920069873:100,error,error,100,,https://github.com/google/deepvariant/issues/485#issuecomment-920069873,1,['error'],['error']
Availability,"Hi, @akolesnikov ; I have about 90GB of memory and I only analyzed chromosome 20. I had no problem running DV1.6 on the same server. However, when I specified to use T7 model parameters(--customized_model model/weights-51-0.995354.ckpt), an error occurred. What should I do about this?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/725#issuecomment-1791849240:241,error,error,241,,https://github.com/google/deepvariant/issues/725#issuecomment-1791849240,1,['error'],['error']
Availability,"Hi, @pichuan . I am trying to run with the followings command:; ```; singularity shell -B /usr/lib/locale/:/usr/lib/locale/ --nv ~/data/images/deepvariant_gpu; ```; But it still doesn't work.; There are two files in the `/usr/lib/locale/` folder, so I don't know whether it works after rebooting the machine. ; ![image](https://user-images.githubusercontent.com/43125963/225547562-bf86b5df-60cd-45d4-8d7c-a6ff986090f4.png). I will ask the HPC manager to reboot the machine. ; Thanks a lot!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471459575:286,reboot,rebooting,286,,https://github.com/google/deepvariant/issues/619#issuecomment-1471459575,2,['reboot'],"['reboot', 'rebooting']"
Availability,"Hi, @pichuan, thanks for your quick replay.; I ran the command `/opt/deepvariant/bin/run_deepvariant --version` using GPU version in singularity image . It return the `CUDA_ERROR_UNKNOWN` error as above I mentioned. Now I am trying to use the 1.5.0 version. I use the same test command and it return the same error as followings:; ```; Singularity> /opt/deepvariant/bin/run_deepvariant --version; 2023-03-16 09:39:40.831726: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-03-16 09:39:40.953050: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.; 2023-03-16 09:39:42.599918: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; 2023-03-16 09:39:42.599962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: yy01.local; 2023-03-16 09:39:42.599972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: yy01.local; 2023-03-16 09:39:42.600020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; 2023-03-16 09:39:42.600049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5; DeepVariant version 1.5.0; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471145851:188,error,error,188,,https://github.com/google/deepvariant/issues/619#issuecomment-1471145851,4,['error'],"['error', 'errors']"
Availability,"Hi, I am experiencing similar issue - VM, 32 threads, 64GB RAM. Could you provide the experimental container? ; Btw, thank you for outstanding work while making this software available for us. This tool has great value is reliable and important for us. Regards, ; Tomasz Stokowy, Leader Scientific Computing, University of Bergen, Norway. Running via docker 1.6.1, earlier steps work smoothly. cat /proc/version; Linux version 6.1.0-22-amd64 (debian-kernel@lists.debian.org) (gcc-12 (Debian 12.2.0-14) 12.2.0, GNU ld (GNU Binutils for Debian) 2.40) #1 SMP PREEMPT_DYNAMIC Debian 6.1.94-1 (2024-06-21). Error log:. ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""/Reference/core_ref_GRCh38_hla_decoy_ebv/genome.fa"" --infile ""/Output/call_variants_output.tfrecord.gz"" --outfile ""/Output/CoriellIndex.vcf"" --cpus ""32"" --gvcf_outfile ""/Output/CoriellIndex.gvcf"" --nonvariant_site_tfrecord_path ""/Output/gvcf.tfrecord@32.gz"". I0823 15:16:56.752997 139658307389248 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: CoriellIndex; 2024-08-23 15:16:56.766309: I deepvariant/postprocess_variants.cc:94] Read from: /Output/call_variants_output-00000-of-00001.tfrecord.gz; 2024-08-23 15:18:01.806248: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 10880665; I0823 15:20:45.074391 139658307389248 postprocess_variants.py:1313] CVO sorting took 3.805263650417328 minutes; I0823 15:20:45.077561 139658307389248 postprocess_variants.py:1316] Transforming call_variants_output to variants.; I0823 15:20:45.077694 139658307389248 postprocess_variants.py:1318] Using 32 CPUs for parallelization of variant transformation.; I0823 15:20:51.014987 139658307389248 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: CoriellIndex. real	8m32.455s; user	7m11.835s; sys	1m25.577s; Process ForkPoolWorker-2:; Traceback (most recent call last):; File ""/usr/lib/python3.8/multiproces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/804#issuecomment-2308162449:175,avail,available,175,,https://github.com/google/deepvariant/issues/804#issuecomment-2308162449,3,"['Error', 'avail', 'reliab']","['Error', 'available', 'reliable']"
Availability,"Hi, here is the output:; `; dv_call_variants.py -h; Baseline DeepVariant arguments; File ""/tmp/Bazel.runfiles_dwq0j2la/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 356; f'The file {input_shape_file} should contain 3 integers'); ^; SyntaxError: invalid syntax; `; If you check dv_make_examples.py and dv_postprocess_variants.py, you can find similar output.; I also tried to solve this syntax by replace f-strings to .format, and get another syntax error:; `Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_gxfcz7rb/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>; from deepvariant import make_examples_core; File ""/tmp/Bazel.runfiles_gxfcz7rb/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 645; options: deepvariant_pb2.SampleOptions; ^; SyntaxError: invalid syntax; `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/627#issuecomment-1512334269:471,error,error,471,,https://github.com/google/deepvariant/issues/627#issuecomment-1512334269,1,['error'],['error']
Availability,"Hi, sorry to bother again. I am wondering if I run DeepVariant on my non-deduplicated reads, will the results be reliable or make sense? Probably there will be artifactual mutations?; In short, I should still run DeepVariant on deduplicated reads, right?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/672#issuecomment-2393536188:113,reliab,reliable,113,,https://github.com/google/deepvariant/issues/672#issuecomment-2393536188,1,['reliab'],['reliable']
Availability,"Hi, thanks for your reply. When I retried it, it showed the error with 'subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling' and --task {}' returned non-zero exit status 1.; For the codes I used, is it available to send to your email? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/305#issuecomment-623005616:60,error,error,60,,https://github.com/google/deepvariant/issues/305#issuecomment-623005616,2,"['avail', 'error']","['available', 'error']"
Availability,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps.; Alexey",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/198#issuecomment-512031369:211,checkpoint,checkpoints,211,,https://github.com/google/deepvariant/issues/198#issuecomment-512031369,10,['checkpoint'],"['checkpoint', 'checkpoints']"
Availability,"Hi,. Just to make sure I understand the issue: you are able to successfully install DeepVariant 0.7.0 with Python 2.7, but you are unable to install 1.15 or later; the goal is for you to install the latest version of DeepVariant, 1.6.0. . The relevant error that I see is:; ```; deepvariant [1.0.0|1.1.0|...|1.5.0] would require; │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;; ```; Is it possible to resolve this conflict? I will try myself to see if I can get it to work on GCP, and report back.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/835#issuecomment-2187229102:252,error,error,252,,https://github.com/google/deepvariant/issues/835#issuecomment-2187229102,1,['error'],['error']
Availability,"Hi,. Sorry, I could be wrong but I suspect this may be relevant to the codebase. The nf-core script is responsible for passing the parameters correctly to `dv_make_examples.py`. Here the parameters seem to have been passed correctly and the `dv_make_examples.py` script throws an error. . Do you know why this is the case? Could it be to do with the data? Is it okay that the organism is a *Plasmodium*? Do you know what the frequency file is which it is referring to?. Thanks again,; Phil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/191#issuecomment-504330013:280,error,error,280,,https://github.com/google/deepvariant/issues/191#issuecomment-504330013,1,['error'],['error']
Availability,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334875005:278,fault,fault,278,,https://github.com/google/deepvariant/issues/879#issuecomment-2334875005,1,['fault'],['fault']
Availability,"Hi,. Thanks for the reply, but it doesn't address my question.; My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:; > ; > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual.; https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667; https://onlinelibrary.wiley.com/doi/10.1111/mec.12105; https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs.; I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it.; I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV?. > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks.; > ; > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/878#issuecomment-2364502771:1494,reliab,reliable,1494,,https://github.com/google/deepvariant/issues/878#issuecomment-2364502771,2,['reliab'],['reliable']
Availability,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future?. P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2335169866:1046,error,error,1046,,https://github.com/google/deepvariant/issues/879#issuecomment-2335169866,1,['error'],['error']
Availability,"Hi,; From a quick look of your error, it doesn't look like anything I've ever; encountered before. If you could potentially set up a reproducible setting; that I can very quickly run, I can see if I can try it out and tell you; what might could have gone wrong. We don't currently have a tutorial for; training, unfortunately. And to be honest, even if we do, it probably; wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is; > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for; > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:; > [64,27,1,3]; >; >; > I hate to keep bothering people about this. Is there documentation on all; > of this that I can refer to?; >; >; > Thanks,; > Brad Thomas; >; >; > From: Pi-Chuan Chang [mailto:notifications@github.com]; > Sent: Tuesday, April 10, 2018 1:04 PM; > To: google/deepvariant <deepvariant@noreply.github.com>; > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <; > author@noreply.github.com>; > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62); >; > CAUTION: This email originated from outside the organization. DO NOT click; > links or open attachments unless you recognize the sender and know the; > content is safe.; >; > I think you'll want:; > tfrecord_path:; > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064""; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub<; > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,; > or mute the thread<; > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>.; >; >; > This message contains confidential information and is intended only for; > the individual named. If you are not the named addressee you should not; > disseminate, distr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-380935943:31,error,error,31,,https://github.com/google/deepvariant/issues/62#issuecomment-380935943,3,['error'],['error']
Availability,"Hi,; I'll take a look. Give me a few days. Please feel free to ping back if you don't hear from me by end of this week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-386026449:63,ping,ping,63,,https://github.com/google/deepvariant/issues/62#issuecomment-386026449,1,['ping'],['ping']
Availability,"Hi,; Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'; This error persists even when I include intel_pstate=disable .; Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/104#issuecomment-437599222:52,error,error,52,,https://github.com/google/deepvariant/issues/104#issuecomment-437599222,2,['error'],['error']
Availability,"Hi,; On the same page , it also mentioned other runners such as SparkRunner.; Our shuffling script uses Apache Beam, which can run on different; infrastructures such as Spark or Dataflow, and is not only restricted to; Google Cloud. However, our example was done on Google Cloud. You can set it; up on different things to run. If you're running on smaller amount of examples where your machine can; handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,; >; > Thanks for your kind comments.; > I understood what is wrong.; >; > However, this page (https://beam.apache.org/documentation/) says:; >; > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service; > within Google Cloud Platform.; > Then, are your scripts for shuffling training set available only in Google; > Cloud Platform?; >; > Best,; >; > Masaru; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/133#issuecomment-451809290:847,avail,available,847,,https://github.com/google/deepvariant/issues/133#issuecomment-451809290,1,['avail'],['available']
Availability,"Hi,; Thanks a lot for your immediate response, i have followed the above; instructions given by you, now the docker command is running fine, but I; have come across a new error. *[E::hts_open_format] Failed to open file; ""/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result""; : Is a directory*. *ValueError: UNKNOWN: Could not open variants_path:; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result*. here i have used the same path for docker run (-v; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result); and also same path for run_deepvariant (--output_vcf; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result; ) , Here i am not able to rectify what minor error in my command, i am; following the same pattern mentioned in the link shared, i might be; missing out something minute. Here is my command which is used. sudo docker run -v; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3; -v; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result; google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --reads; /media/manish/Dat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/829#issuecomment-2162307749:171,error,error,171,,https://github.com/google/deepvariant/issues/829#issuecomment-2162307749,4,['error'],['error']
Availability,"Hi,; as you can see in the message:; ```; I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']; ```; This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? ; Maybe in addition to ""Could not parse"", we can say something more verbose like:; `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`; Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/73#issuecomment-389394212:657,error,error,657,,https://github.com/google/deepvariant/issues/73#issuecomment-389394212,2,['error'],['error']
Availability,"Hi,; can you tell us the operating system you're on? Did the step with run-prereq.sh finish without any error messages?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/41#issuecomment-360677087:104,error,error,104,,https://github.com/google/deepvariant/issues/41#issuecomment-360677087,1,['error'],['error']
Availability,"Hi,; originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data.; How about at least posting the commands you used?. From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty.; (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381167653:785,error,error,785,,https://github.com/google/deepvariant/issues/62#issuecomment-381167653,2,['error'],['error']
Availability,"Hi,; this error corresponding to this line in the Nucleus codebase:; https://github.com/google/nucleus/blob/master/nucleus/io/sam_reader.cc#L409. which I think is indicating your BAM file actually isn't quite we're expecting. One qustion for you:; Is there anything after `fragment_name`? If so, it's useful to find out the read in your BAM file so we can understand it better. ; samtools view YOUR_BAM | grep FRAGMENT_NAME; might give you more information about the read that our SamReader is complaining. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/99#issuecomment-426810731:10,error,error,10,,https://github.com/google/deepvariant/issues/99#issuecomment-426810731,1,['error'],['error']
Availability,"Hi. What OS are you running on? I actually don't see this crash on the Ubuntu 16 setup.; If you can let me know how to reproduce the error, we'll make sure to fix it and will come out with the next release. Thanks for reporting!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/78#issuecomment-398508100:133,error,error,133,,https://github.com/google/deepvariant/issues/78#issuecomment-398508100,1,['error'],['error']
Availability,"Hmm, having no doubts is essential. Would you be comfortable with posting a few complete rows from the VCF file, which would include this variant and a few above and below. DeepVariant is base-specific, so it would tell us something that might be captured by a few rows. Also could you post the whole script and command you used to run DeepVariant? You can mask out anything that is sensitive. . Just trying to be thorough we're not missing anything. Thanks,; `p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/691#issuecomment-1662870870:357,mask,mask,357,,https://github.com/google/deepvariant/issues/691#issuecomment-1662870870,1,['mask'],['mask']
Availability,How did you solve this? Same error here.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/543#issuecomment-1228240854:29,error,error,29,,https://github.com/google/deepvariant/issues/543#issuecomment-1228240854,1,['error'],['error']
Availability,"I FMA; File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 772, in write_variants_to_vcf; with vcf.VcfWriter(; File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 174, in __init__; self._writer = self._native_writer(output_path, **kwargs); File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 309, in _native_writer; return NativeVcfWriter(; File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 287, in __init__; self._writer = vcf_writer.VcfWriter.to_file(output_path, header,; ValueError: UNKNOWN: Could not open variants_path: /data/shared/clinical/LongRead/Data//Analysis/out_m84011_220902_175841_NFR_sif.vcf.gz. real 0m7.906s; user 0m8.421s; sys 0m8.363s. Work dir:; /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711. Tip: when you have fixed the problem you can continue the execution adding the option `-resume` to the run command line; Jun-08 12:17:16.749 [Task monitor] DEBUG nextflow.Session - Session aborted -- Cause: Process `pbc_varicall (1)` terminated with an error exit status (1); Jun-08 12:17:16.752 [main] DEBUG nextflow.Session - Session await > all processes finished; Jun-08 12:17:16.764 [main] DEBUG nextflow.Session - Session await > all barriers passed; Jun-08 12:17:16.776 [main] DEBUG nextflow.trace.WorkflowStatsObserver - Workflow completed > WorkflowStats[succeededCount=0; failedCount=1; ignoredCount=0; cachedCount=0; pendingCount=0; submittedCount=0; runningCount=0; retriesCount=0; abortedCount=0; succeedDuration=0ms; failedDuration=15m 11s; cachedDuration=0ms;loadCpus=0; loadMemory=0; peakRunning=1; peakCpus=1; peakMemory=0; ]; Jun-08 12:17:16.977 [main] DEBUG nextflow.cache.CacheDB - Closing CacheDB done; Jun-08 12:17:16.991 [main] DEBUG nextflow.script.ScriptRunner - > Execution complete -- Goodbye; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308:12658,error,error,12658,,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308,2,['error'],['error']
Availability,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/166#issuecomment-478394293:198,error,error,198,,https://github.com/google/deepvariant/issues/166#issuecomment-478394293,1,['error'],['error']
Availability,"I am actually happy we at least can rule something out. Those rotifers have led us to failure on this for years now, there is something that we miss. That we all miss.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658896248:86,failure,failure,86,,https://github.com/google/deepvariant/issues/682#issuecomment-1658896248,1,['failure'],['failure']
Availability,"I am getting an error with channel being different; Find below the error coming and the command I'm currently using-; docker run -u $(id -u):$(id -g) \; -v ""${PWD}/quickstart-output"":""/quickstart-output"" \; -v ""${PWD}/quickstart-input"":""/quickstart-input"" \; -v ""/BXRX_ANALYSIS/HRD_MeetaS/projects/vijay/UMI_pipeline/cicero_ref/reference_hg38_noalt/Homo_sapiens/GRCh38_no_alt/FASTA"":""/FASTA"" \; -v ""${PWD}/model"":""/model"" \; -w $(pwd) \; google/deepvariant:latest \; run_deepvariant \; --model_type=WES \; --customized_model=/model/model.ckpt \; --ref=/FASTA/GRCh38_no_alt.fa \; --reads=/quickstart-input/Aligned.sortedByCoord.out.bam \; --output_vcf=/quickstart-output/output.vcf.gz \; --num_shards=30 \; --intermediate_results_dir /quickstart-output/intermediate_results_dir; ![image (2)](https://github.com/google/deepvariant/assets/45894456/c1961bb4-6e7d-477c-bab6-b267ba31eb33)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/743#issuecomment-1835892559:16,error,error,16,,https://github.com/google/deepvariant/issues/743#issuecomment-1835892559,2,['error'],['error']
Availability,I am tempted to fix all the errors by uninstalling the python packages and reinstalling based on the required package version.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577808511:28,error,errors,28,,https://github.com/google/deepvariant/issues/657#issuecomment-1577808511,1,['error'],['errors']
Availability,"I assign this to my self, but --; since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:; https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346; And for training, in order to start from a checkpoint, you can see code in this:; https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:; https://github.com/keras-team/keras/issues/5273; (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/127#issuecomment-446036697:335,checkpoint,checkpoint,335,,https://github.com/google/deepvariant/issues/127#issuecomment-446036697,2,['checkpoint'],['checkpoint']
Availability,"I can confirm that downgrading bazel to 0.8.1 as suggested in that comment worked for me.; Here's what I did to install an older version of bazel:; ```; BAZEL_VERSION=0.8.1; wget https://github.com/bazelbuild/bazel/releases/download/""${BAZEL_VERSION}""/bazel-""${BAZEL_VERSION}""-installer-linux-x86_64.sh; chmod +x bazel-*.sh; ./bazel-""${BAZEL_VERSION}""-installer-linux-x86_64.sh --user; ```; Give this temporary solution a try and let me know if it works. We'll still need to fix this in a more principled way.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/19#issuecomment-353388370:19,down,downgrading,19,,https://github.com/google/deepvariant/issues/19#issuecomment-353388370,2,['down'],"['downgrading', 'download']"
Availability,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:; `; I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default; 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz; 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602; I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes; I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants.; I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default; I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes; I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s; user 220m0.378s; sys 13m54.784s. `. Samples with problems:; `; I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default; 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz; 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573; I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/868#issuecomment-2290172397:154,error,error,154,,https://github.com/google/deepvariant/issues/868#issuecomment-2290172397,1,['error'],['error']
Availability,"I concur this issye has been stalling my thesis for years. Nature high SNP density is a real problem. I have some preliminary promising results with long reads but the bulk of my dara are illumina. Anyway, thanks for your reply and I will keep you posted. Cheers. Alex. Sent from ProtonMail mobile. -------- Original Message --------; On 16 Jun 2023, 06:33, Andrew Carroll wrote:. > Hi ***@***.***(https://github.com/Axze-rgb); >; > It's reasonable to try. There are non-human species for which we know DeepVariant works well,for example [rice](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant),; >; > You are correct that with a good long-read dataset it should be possible to train a short read DeepVariant method. If you are able to make those data and reference available, we could try it.; >; > There are two things to keep an eye on when assessing whether DeepVariant will work well for your samples. First, keep an eye that runtime doesn't get unreasonable. DeepVariant runs per-site, which scales linearly with number of variant positions.; >; > The second, is to look if there are many cases where DeepVariant is calling many variants as 0/0 which have high support for the alternate allele. It's possible that a high variant density will resemble the signature of copy number variation in humans and since humans don't have much variation relative to the reference, it may become hesitant to call such variants. Really the only way to know is to try and then do some QC on the results.; >; > It's my hope will have better support and some more advanced methods for such genomes in the intermediate future.; >; > —; > Reply to this email directly, [view it on GitHub](https://github.com/google/deepvariant/issues/661#issuecomment-1594084840), or [unsubscribe](https://github.com/notifications/unsubscribe-auth/ATOL54R5OCVCQKEQAK6USQDXLPOX5ANCNFSM6AAAAAAZGA4ITE).; > You are receiving this because you were mentioned.Message ID: **",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/661#issuecomment-1594153599:828,avail,available,828,,https://github.com/google/deepvariant/issues/661#issuecomment-1594153599,1,['avail'],['available']
Availability,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```; # install docker; sudo yum check-update; curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker; distribution=$(. /etc/os-release;echo $ID$VERSION_ID); curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \; sudo tee /etc/yum.repos.d/nvidia-docker.repo; sudo yum install -y nvidia-docker2; semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker; sudo restorecon -v /usr/bin/nvidia-docker. # start docker; sudo systemctl start docker; sudo systemctl status docker; sudo systemctl enable docker. # install deps; sudo yum groupinstall -y 'Development Tools' && \; sudo yum install -y epel-release && \; sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools; echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \; echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \; source ~/.bashrc. # install singularity; mkdir -p ${GOPATH}/src/github.com/sylabs && \; cd ${GOPATH}/src/github.com/sylabs && \; git clone https://github.com/sylabs/singularity.git && \; cd singularity; git checkout v3.1.1; cd ${GOPATH}/src/github.com/sylabs/singularity && \; ./mconfig && \; cd ./builddir && \; make && \; sudo make install; ; DVVER=0.8.0; # make deepvariant CPU image; sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}; sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest; sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2; sudo docker push localhost:5000/deepvariant:latest;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-482761898:569,echo,echo,569,,https://github.com/google/deepvariant/issues/132#issuecomment-482761898,1,['echo'],['echo']
Availability,"I could extract the three commands make_examples, call_variants and postprocess_variants from the output. Here it is:. ```; seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""stdchroms.hg38.fa"" --reads ""SAMPLENAME.bam"" --examples ""./make_examples.tfrecord@8.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""./gvcf.tfrecord@8.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sample_name ""SAMPLENAME"" --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. /opt/deepvariant/bin/call_variants --outfile ""./call_variants_output.tfrecord.gz"" --examples ""./make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/pacbio"". /opt/deepvariant/bin/postprocess_variants --ref ""stdchroms.hg38.fa"" --infile ""./call_variants_output.tfrecord.gz"" --outfile ""./SAMPLENAME.deepVariant.vcf.gz"" --cpus ""8"" --gvcf_outfile ""./SAMPLENAME.deepVariant.g.vcf.gz"" --nonvariant_site_tfrecord_path ""./gvcf.tfrecord@8.gz"" --sample_name ""SAMPLENAME""; ```. And here are the two last commands with std out ... ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""./call_variants_output.tfrecord.gz"" --examples ""./make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(; I0510 12:13:42.483308 47501039724352 call_variants.py:563] Total 1 writing processes star",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/818#issuecomment-2104434632:799,checkpoint,checkpoint,799,,https://github.com/google/deepvariant/issues/818#issuecomment-2104434632,1,['checkpoint'],['checkpoint']
Availability,I created a build script and a singularity image updating to 0.5.2 in the processes; here is my fork:; https://github.com/ink1/deepvariant/releases/tag/v0.5.2a; The binary release is the singularity image. My original image was quite large because I built everything inside of the container. Instead I resorted to the original Dockerfile which relies on pre-built zip files which my build script downloads. Still the image is 2 GB but then it should just run I presume. The changes I had to do to the Dockerfile are probably optional - my docker version does not like the lines with ARG.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/6#issuecomment-372644789:396,down,downloads,396,,https://github.com/google/deepvariant/issues/6#issuecomment-372644789,1,['down'],['downloads']
Availability,"I do have access to a linux distributed computing system so I will re-try there and see how it goes. Thanks for letting me know, I will update should I still encounter the same error on the different OS",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/304#issuecomment-620715339:177,error,error,177,,https://github.com/google/deepvariant/issues/304#issuecomment-620715339,1,['error'],['error']
Availability,"I downloaded and ran the pre-built binaries *.zip (DeepVariant v 7.0.2) from GitHub. In fact, I have installed 'intervaltree==2.1.0', but it does not works? Strange.....",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/155#issuecomment-464509971:2,down,downloaded,2,,https://github.com/google/deepvariant/issues/155#issuecomment-464509971,1,['down'],['downloaded']
Availability,"I followed the directions on that page, and for the most part everything seemed to work, but the docker install commands failed:. sudo apt-get -qq -y update; E: The repository 'https://download.docker.com/linux/ubuntu buster Release' does not have a Release file. sudo apt-get -qq -y install docker-ce; E: Package 'docker-ce' has no installation candidate. So instead I ran an alternate docker installation, which succeeded (sudo apt install docker.io). I don't know if this is the ultimate problem. The first command within the docker seems to complete with no errors:. ***** Running the command:*****; time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hs37d5.fa.gz"" --reads ""/input/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --regions ""20"" --task {}. ...omitting much output... It does take 40 minutes as opposed to the advertised 8, though. I was using pre-emptible instances so perhaps this caused delay, but I did test it 3 times, and it is reliably ~40 mins each time. The second command within the docker dies, this is all the output:. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --; checkpoint ""/opt/models/wgs/model.ckpt""; I1217 09:08:41.108182 139680301201152 call_variants.py:313] Set KMP_BLOCKTIME to 0; 2020-12-17 09:08:41.511115: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA; 2020-12-17 09:08:42.039849: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz; 2020-12-17 09:08:42.070759: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5abc760 executing computations on platform Host. D",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/399#issuecomment-749313156:185,down,download,185,,https://github.com/google/deepvariant/issues/399#issuecomment-749313156,2,"['down', 'error']","['download', 'errors']"
Availability,"I found an ungainly solution so I can still batch submit jobs. Using `/bin/bash -c ""<stuff>""`, I can pass two commands to singularity exec. So I can do changing directory and running deepvariant in ""one"" command. The full command that worked was; ```; singularity exec -no-home --cleanenv --containall -B tmp:/tmp,input:/input,output:/output deepvariant_1.1.0.sif \; /bin/bash -c ""cd output; ../opt/deepvariant/bin/call_variants \; --outfile /output/intermediate_results_dir/call_variants_output.tfrecord.gz \; --examples /output/intermediate_results_dir/make_examples.tfrecord@24.gz \; --checkpoint /opt/models/pacbio/model.ckpt \; --use_openvino""; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-763572811:589,checkpoint,checkpoint,589,,https://github.com/google/deepvariant/issues/404#issuecomment-763572811,1,['checkpoint'],['checkpoint']
Availability,"I get a 8 VCPUs, 52 GB RAM [n1-highmem-8](https://cloud.google.com/compute/docs/machine-types#n1_high-memory_machine_types) machine to test:. ```; gcloud compute instances create ""${USER}-test-speed"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-1804-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-highmem-8"" \; --zone ""us-west2-b"" \; --boot-disk-size 100G \; --min-cpu-platform ""Intel Skylake""; ```. On the machine, I installed Singularity:; ```; curl https://gist.githubusercontent.com/pichuan/7840c8ba80ad31fee9d6f8bea20edb6a/raw/cbf62eb2ea2f141351801db76781d99d04704b4e/install_singularity_3.7.0.sh | \; sed -e s'|github.com/sylabs|github.com/hpcng|' | \; bash -x; ```. Here's the version:; ```; pichuan@pichuan-test-speed:~$ singularity --version; singularity version 3.7.0; ```. I followed:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-exome-case-study.md; to download the data. And then:. ```; mkdir -p output; mkdir -p output/intermediate_results_dir. # Pull the image.; BIN_VERSION=1.1.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref reference/GRCh38_no_alt_analysis_set.fasta \; --reads input/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions input/idt_capture_novogene.grch38.bed \; --output_vcf output/HG003.output.vcf.gz \; --output_gvcf output/HG003.output.g.vcf.gz \; --num_shards $(nproc) \; --intermediate_results_dir output/intermediate_results_dir 2>&1 | tee /tmp/all.log; ```. I'll paste part of the log of each step so that you can compare. ## make_examples; make_examples speed is roughly:; ```; I0622 21:19:25.373434 140610510067456 make_examples.py:648] Task 7/8: 4900 candidates (5187 examples) [27.99s elapsed]; I0622 21:19:35.260825 139809239041792 make_examples.py:648] Task 1/8: 4809 candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866352316:937,down,download,937,,https://github.com/google/deepvariant/issues/463#issuecomment-866352316,1,['down'],['download']
Availability,"I get the same error. There appears to be Cuda 12 modules being used even though Cuda 11 is installed? Adding '--env LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/lib/python3.8/dist-packages/nvidia/cublas/lib:/usr/local/lib/python3.8/dist-packages/nvidia/cuda_nvrtc/lib:/usr/local/lib/python3.8/dist-packages/nvidia/cuda_runtime/lib:/usr/local/lib/python3.8/dist-packages/nvidia/cudnn/lib' lets the image see all these libraries and stops the ""Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file"" error. . But now during the call_variants step, I get a new error --> ""2024-03-11 23:23:22.756430: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED; 2024-03-11 23:23:22.756490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Possibly insufficient driver version: 470.57.2"". Just doing '--env LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/lib/python3.8/dist-packages/nvidia/cublas/lib' also seems to get past the ""Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12:"" error, but now I get ""could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error"" during the call_variants step. The 1.6.0-gpu image appears to have some mixed cuda 11 & cuda 12 module library conflict issues. Some of these issues may be suppressed if you have a sufficient nvidia driver for both cuda 11 and cuda 12 (I'm still waiting to test that though).; Note that 1.5.0 has no issues running for me.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/761#issuecomment-1990592785:15,error,error,15,,https://github.com/google/deepvariant/issues/761#issuecomment-1990592785,5,['error'],['error']
Availability,I get the same errors with ```conda create -n deepvariant python=2.7 deepvariant```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/177#issuecomment-486070285:15,error,errors,15,,https://github.com/google/deepvariant/issues/177#issuecomment-486070285,1,['error'],['errors']
Availability,"I got a machine to test:. ```; gcloud compute instances create ""${USER}-gpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --maintenance-policy ""TERMINATE"" \; --accelerator=type=nvidia-tesla-p100,count=1 \; --image-family ""centos-7"" \; --image-project ""centos-cloud"" \; --machine-type ""n1-standard-16"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. On the machine, I install nvidia driver first:. ```; sudo yum update -y && sudo yum install -y python3; curl https://raw.githubusercontent.com/GoogleCloudPlatform/compute-gpu-installation/main/linux/install_gpu_driver.py --output install_gpu_driver.py; sudo python3 install_gpu_driver.py; ```. After that, I can confirm that nvidia-smi exists:; ```; [pichuan@pichuan-gpu2 ~]$ nvidia-smi; Thu Mar 16 04:47:54 2023 ; +-----------------------------------------------------------------------------+; | NVIDIA-SMI 525.85.12 Driver Version: 525.85.12 CUDA Version: 12.0 |; |-------------------------------+----------------------+----------------------+; | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |; | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |; | | | MIG M. |; |===============================+======================+======================|; | 0 Tesla P100-PCIE... Off | 00000000:00:04.0 Off | 0 |; | N/A 34C P0 29W / 250W | 0MiB / 16384MiB | 1% Default |; | | | N/A |; +-------------------------------+----------------------+----------------------+; ; +-----------------------------------------------------------------------------+; | Processes: |; | GPU GI CI PID Type Process name GPU Memory |; | ID ID Usage |; |=============================================================================|; | No running processes found |; +-----------------------------------------------------------------------------+; ```. Then I install cuda. This was from: https://developer.nvidia.com/cuda-downloads; ```; curl -O https://developer.download.nvidia.com/compute/cuda",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471348553:135,mainten,maintenance-policy,135,,https://github.com/google/deepvariant/issues/619#issuecomment-1471348553,1,['mainten'],['maintenance-policy']
Availability,"I got the following to work (I haven't tested to the end, but successfully reached calling variants). I'm going to keep iterating and seeing how much of these commands I can remove. Opening singularity through a shell; `singularity shell --no-home --cleanenv --containall -B tmp:/tmp,input:/input,output:/output deepvariant_1.1.0.sif`. Changing directory to something I've bound (e.g. ouptut), and then running call_variants; ```; cd ouput; ../opt/deepvariant/bin/call_variants \; --examples ""/output/intermediate_results_dir/make_examples.tfrecord@24.gz"" \; --outfile ""/output/intermediate_results_dir/call_variants_out.tfrecord.gz"" \; --checkpoint ""/opt/models/pacbio/model.ckpt"" \; --use_openvino; ```; At this point, we made progress with the following; ```; Model Optimizer version: 	. [ SUCCESS ] Generated IR version 10 model.; [ SUCCESS ] XML file: /output/./model.xml; [ SUCCESS ] BIN file: /output/./model.bin; [ SUCCESS ] Total execution time: 30.04 seconds. ; [ SUCCESS ] Memory consumed: 699 MB; ```; With persistent model.bin/mapping/xml files in my output folder. I tried unsuccessfully with different binds to be able to write files to the `/` directory in the container, which is where the openvino graph is being written. It may be related to the directory structure on our cluster not meshing well with the container.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-763490283:639,checkpoint,checkpoint,639,,https://github.com/google/deepvariant/issues/404#issuecomment-763490283,1,['checkpoint'],['checkpoint']
Availability,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/247#issuecomment-563285549:176,down,downstream,176,,https://github.com/google/deepvariant/issues/247#issuecomment-563285549,4,['down'],['downstream']
Availability,"I guess the naming pattern is related to second question.; Say I have a 50x depth BAM file that I want to downsample to 20%. I can squeeze about 5 downsampled BAMs out of 50x.; Given I assume i will perform make_examples with ""--training"" within a loop of say 5 iterations, what would the naming scheme look like? Hence the importance of the seed parameter if downsampling same BAM mulitiple times within a loop; i would change seed each time... I hope this clears up the questions and motivations behind them....",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/765#issuecomment-1909090188:106,down,downsample,106,,https://github.com/google/deepvariant/issues/765#issuecomment-1909090188,6,['down'],"['downsample', 'downsampled', 'downsampling']"
Availability,"I had set the environment variables just didn't include them in the above message. That error was certainly caused by the `**Replace this string with exactly one of the following [WGS,WES,PACBIO]**` string. However, I'm still getting an _unrelated_ error:; ## Set the environment; ```; [moldach@cdr767 bin]$ BIN_VERSION=""0.10.0""; [moldach@cdr767 bin]$ INPUT_DIR=""${PWD}/quickstart-testdata""; [moldach@cdr767 bin]$ OUTPUT_DIR=""${PWD}/quickstart-output""; [moldach@cdr767 bin]$ salloc --time=0:30:0 --mem=8000; [moldach@cdr767 bin]$ singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; > docker://google/deepvariant:""${BIN_VERSION}"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; > --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; > --regions ""chr20:10,000,000-10,010,000"" \; > --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; > --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; > --num_shards=1; WARN[0000] ""/run/user/3019658"" directory set by $XDG_RUNTIME_DIR does not exist. Eithe r create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such fil e or directory: Trying to pull image in the event that it is a public image.; I0327 13:31:58.252949 47794500922048 run_deepvariant.py:241] Re-using the directory fo r intermediate results in /tmp/tmp63xxmwmi. ***** Intermediate results will be written to /tmp/tmp63xxmwmi in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mo de calling --ref ""/scratch/moldach/bin/quickstart-testdata/ucsc.hg19.chr20.unittest.fa sta"" --reads ""/scratch/moldach/bin/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmp63xxmwmi/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmp63xxmwmi/gv cf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Paral",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-605306987:88,error,error,88,,https://github.com/google/deepvariant/issues/287#issuecomment-605306987,2,['error'],['error']
Availability,"I have been experiencing the same error when trying to build DeepVariant from the Dockerfile they provided but I managed to pull working images from Docker by following the steps below:; ```BASH; BIN_VERSION=""1.1.0-gpu""; docker image pull google/deepvariant:$BIN_VERSION; ```. Pulling the image from remote is not ideal for us as I would prefer to use the Dockerfile to increase transparency in how the image is created. However, having a working DeepVariant is better than nothing. We are using Ubuntu 16.04 but we would greatly prefer to run Ubuntu 18.04 as our OS for running DeepVariant. Does DeepVariant 1.1.0 now support Ubuntu 18.04 hosts?. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-821311465:34,error,error,34,,https://github.com/google/deepvariant/issues/441#issuecomment-821311465,1,['error'],['error']
Availability,I have checked my bam file according to the command you gave and it shows that 'all ok'. The error may not be caused by the bam file.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/794#issuecomment-2033377369:93,error,error,93,,https://github.com/google/deepvariant/issues/794#issuecomment-2033377369,1,['error'],['error']
Availability,I have installed chardet 3.0.4 by using 'pip install chardet==3.04'. ; But the error are still reported.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/634#issuecomment-1518574416:79,error,error,79,,https://github.com/google/deepvariant/issues/634#issuecomment-1518574416,1,['error'],['error']
Availability,"I have now solved this error.; Firstly, input within shell:; > singularity shell deepvariant_1.5.0.sif. Then,; > pip install --upgrade pip; > pip install chardet==3.04",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/634#issuecomment-1518577444:23,error,error,23,,https://github.com/google/deepvariant/issues/634#issuecomment-1518577444,1,['error'],['error']
Availability,I have picked up an error in the original cram files for the 4 samples that did not work. Thank you for the help!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/776#issuecomment-1978286182:20,error,error,20,,https://github.com/google/deepvariant/issues/776#issuecomment-1978286182,1,['error'],['error']
Availability,"I identified the read pairs that are causing the problem:. ```; [read_id]/2 145 chr1 10535 59 50M * 0 0 [read_seq] CC?DD@DDDDDEEEEEFFFFFFHHHHJIJJJJJIIJJGHHHHFFFFFCCC ...; [read_id]/1 81 chr10 38696640 69 29M1062N21M * 0 0 [read_seq] JJJJJJJJJJJJJJJJJJJJIJIFIGIJJIJJIGHGJHHFHHFFFFFCCB ...; ```; These are the primary alignments, they also has a few non-primary alignments. Hmm... the pair of reads are aligned to two chromosomes, is that why `make_examples` is raising the error? Could those reads just be ignored? I tried `make_examples` with one other bam, and see the same error. Also, wondering how `make_examples` deals with non-primary alignments?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/99#issuecomment-426828245:472,error,error,472,,https://github.com/google/deepvariant/issues/99#issuecomment-426828245,2,['error'],['error']
Availability,"I just verified that --regions ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" in fact processes two regions. So make_examples is working as expected. Your error looks like it is caused by missing the quotes around the regions argument. So make_examples interprets:. `... --regions 20 21 --gvcf /HD_disk/real-case...`. as . `... --regions 20` <= keyword args for make_examples; `21 --gvcf /HD_disk/real-case...` <= positional arguments to make_examples. hence the error you are seeing. Just doing:. `... --regions ""20 21"" --gvcf /HD_disk/real-case...`. should fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/72#issuecomment-412948943:166,error,error,166,,https://github.com/google/deepvariant/issues/72#issuecomment-412948943,2,['error'],['error']
Availability,"I ran `/opt/deepvariant/bin/run_deepvariant` and I believe it ran out of threads during the `make_examples` step when I tried to use all the cores on the AMD machine. Here's more of the error. > OpenBLAS blas_thread_init: RLIMIT_NPROC 4096 current, 8254915 max; > OpenBLAS blas_thread_init: pthread_create failed for thread 63 of 64: Resource temporarily unavailable; > OpenBLAS blas_thread_init: RLIMIT_NPROC 4096 current, 8254915 max; > Traceback (most recent call last):; > File ""/tmp/Bazel.runfiles_XqQaQr/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>; > import numpy as np; > File ""/usr/local/lib/python2.7/dist-packages/numpy/__init__.py"", line 142, in <module>; > from . import core; > File ""/usr/local/lib/python2.7/dist-packages/numpy/core/__init__.py"", line 47, in <module>; > raise ImportError(msg); > ImportError:; > ; > IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!; > ; > Importing the multiarray numpy extension module failed. Most; > likely you are trying to import a failed build of numpy.; > Here is how to proceed:; > - If you're working with a numpy git repository, try `git clean -xdf`; > (removes all files not under version control) and rebuild numpy.; > - If you are simply trying to use the numpy version that you have installed:; > your installation is broken - please reinstall numpy.; > - If you have already reinstalled and that did not fix the problem, then:; > 1. Check that you are using the Python you expect (you're using /usr/bin/python),; > and that you have no directories in your PATH or PYTHONPATH that can; > interfere with the Python and numpy versions you're trying to use.; > 2. If (1) looks fine, you can open a new issue at; > https://github.com/numpy/numpy/issues. Please include details on:; > - how you installed Python; > - how you installed numpy; > - your operating system; > - whether or not you have multiple versions of Python installed; > - if you built from source, your compiler versio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/274#issuecomment-598179709:186,error,error,186,,https://github.com/google/deepvariant/issues/274#issuecomment-598179709,2,['error'],['error']
Availability,"I ran it with a different dataset with the same command just changed the files, I am getting a different error; This is the command I have; -v ""/media/eniac/WD1/HiFi_Dikaryon_data/Hifi_Assemblies"":""/input"" \; -v ""/media/eniac/WD1/HiFi_Dikaryon_data/Hifi_Assemblies/docker_out:/output"" \; google/deepvariant:1.2.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/G1-hifi.contigs.fasta \; --reads=/input/G1_sorted.bam \; --output_vcf=/output/output.vcf \; --num_shards=4. [E::hts_open_format] Failed to open file ""/input/G1_sorted.bam"" : No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_ai032aw7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 173, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_ai032aw7/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_ai032aw7/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ai032aw7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 159, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_ai032aw7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 121, in default_options; samples_in_order, sample_role_to_train = one_sample_from_flags(; File ""/tmp/Bazel.runfiles_ai032aw7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 80, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/tmp/Bazel.runfiles_ai032aw7/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 128, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/tmp/Bazel.runfiles_ai032aw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_ai032aw7/runfiles/com_google_deepvariant/th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/492#issuecomment-961288846:105,error,error,105,,https://github.com/google/deepvariant/issues/492#issuecomment-961288846,1,['error'],['error']
Availability,"I ran the above command as such, but the terminal didn't return any errors except `sudo: unable to resolve host smd` where `smd` is the OpenStack instance name. `sudo: unable to resolve host smd` message didn't cause any problems in another OpenStack instance where I have been successful with running deepvariant. . ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""/input/ilAriAges1.fasta.bgz"" \; --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" \; --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" \; --norealign_reads \; --vsc_min_fraction_indels ""0.12"" \; --task 54 --logtostderr; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/315#issuecomment-638428497:68,error,errors,68,,https://github.com/google/deepvariant/issues/315#issuecomment-638428497,1,['error'],['errors']
Availability,"I recently experienced a similar issue in which I kept getting the error `ValueError: NOT_FOUND: could not load fasta and/or fai for fasta` when I'd try to run DeepVariant via Docker. The command I was using looked like:; ```; docker run \; -v ""/data/analysis_data/ngs/r64558e_20231017_193725/bam"":""/input"" \; -v ""/data/analysis_data/ngs/r64558e_20231017_193725/result_DeepVariant"":""/output"" \; google/deepvariant:""1.6.0"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=/data/bioinfo.shared/index/hg38_gatk/hg38.fa \; --reads=/input/m64558e_231018_115114.hifi_reads.sorted.add-rg.rm-tags.bam \; --output_vcf=/output/FD800429.vcf.gz \; --intermediate_results_dir /output/intermediate_results_dir \; --num_shards=1; ```. Not having used Docker before, I wasn't aware that I needed to mount all directories I needed to access so that Docker could see them. This issue and [this article](https://towardsdatascience.com/how-to-mount-a-directory-inside-a-docker-container-4cee379c298b) helped me figure out where I went wrong (i.e. using the absolute path in the --ref parameter without having mounted it). The adjusted command (that worked) looked like:; ```; docker run \; -v ""/data/bioinfo.shared/index/hg38_gatk/"":""/index"" \; -v ""/data/analysis_data/ngs/r64558e_20231017_193725/bam"":""/input"" \; -v ""/data/analysis_data/ngs/r64558e_20231017_193725/result_DeepVariant"":""/output"" \; google/deepvariant:""1.6.0"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=/index/hg38.fa \; --reads=/input/m64558e_231018_115114.hifi_reads.sorted.add-rg.rm-tags.bam \; --output_vcf=/output/FD800429.vcf.gz \; --intermediate_results_dir /output/intermediate_results_dir \; --num_shards=1; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1793241251:67,error,error,67,,https://github.com/google/deepvariant/issues/653#issuecomment-1793241251,1,['error'],['error']
Availability,"I second this feature request. We typically run DV in WDL (backed by Cromwell, on GCP) workflows. We try our best to take advantage of the spot machines but as you know, spot VMs can be preempted non-predictably and the more resource reserved for that machine, the chance is higher for it to be preempted within a certain period (i.e. smaller VMs survive longer before taken away). OTH smaller VMs take longer to finish the job on the same chunk of data, hence the overall preemption rate is likely the same as the bigger ones. So if there's a way to do check-pointing, even during the execution of a step, and resuming from that after recovery from the preemption, it'd be a huge saving for us. Thanks!; Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/749#issuecomment-1930787197:636,recover,recovery,636,,https://github.com/google/deepvariant/issues/749#issuecomment-1930787197,1,['recover'],['recovery']
Availability,"I see the same issue, but with Ubuntu-16. (02:53:00) ERROR: /root/variant_calling/deepvariant/deepvariant/protos/BUILD:56:1: //deepvariant/protos:deepvariant_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'; (02:53:00) ERROR: /root/variant_calling/deepvariant/deepvariant/protos/BUILD:56:1 1 input file(s) do not exist. This is running on IBM Power 8 in a docker container, so I built pyclif from source. However, the location of pyclif isn't the same as what is in build-prereq.sh, so I commented that section out because `which pyclif` works. Would appreciate any help. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/6#issuecomment-440897520:53,ERROR,ERROR,53,,https://github.com/google/deepvariant/issues/6#issuecomment-440897520,2,['ERROR'],['ERROR']
Availability,"I solve this by shuting down multiprocessing (`--cpus ""0""`) using the following command; ```bash; postprocess_variants --cpus ""0"" --ref ""/input/GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta"" --infile ""/tmp/call_variants_output.tfrecord.gz"" --outfile ""/input/{OUTVCF.gz}"" ; ```; But I still not sure what cuase Broken pipe lipe.; I also tried less core like `--cpu ""12""` still get `BrokenPipeError: [Errno 32] Broken pipe`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/804#issuecomment-2041871135:24,down,down,24,,https://github.com/google/deepvariant/issues/804#issuecomment-2041871135,1,['down'],['down']
Availability,"I stand corrected, this is an error with GLNexus, The per-sample vcf produced by DeepVariant shows the locus as expected.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/453#issuecomment-834362623:30,error,error,30,,https://github.com/google/deepvariant/issues/453#issuecomment-834362623,1,['error'],['error']
Availability,"I strongly concur. Singularity images would be nice. Using Docker has already given me multiple diseases. It's such a hassle and from what other colleagues tell me, I am not the only one. ; Note that there is nothing wrong with the deepvariant image, it's the Docker process that can cause many problems running, pulling images, restarting, generating errors, etc ... ; Like this issue, unresolved since 2017: ; https://github.com/docker/for-win/issues/813. Dark Souls bosses are easier to take down than pulling a docker image on some systems. ; So to be clear again, nothing wrong at all with deepvariant, which I love more and more btw, but having something else than Docker would be indeed really great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/243#issuecomment-562108502:352,error,errors,352,,https://github.com/google/deepvariant/issues/243#issuecomment-562108502,4,"['down', 'error']","['down', 'errors']"
Availability,I suspect there's a problem with your BED file. Is there a bad interval in that BED file? I wonder if there's an off-by-one error somewhere in the BED reader (I really hope not).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/71#issuecomment-387583838:124,error,error,124,,https://github.com/google/deepvariant/issues/71#issuecomment-387583838,1,['error'],['error']
Availability,"I think I know what's happening. The `${USER}` was `/root` when running docker. It was maybe caused by a `sudo bash`? When I changed it, everything seems OK. Similar Error #141 .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-491138418:166,Error,Error,166,,https://github.com/google/deepvariant/issues/184#issuecomment-491138418,1,['Error'],['Error']
Availability,"I think it's because it's a Mac M1 which is `aarch64` (`arm64`), so let's try the following one:; ```; curl -L -O https://github.com/bazelbuild/bazel/releases/download/5.3.0/bazel-5.3.0-linux-arm64; ```; Let me know if it runs for you when you execute it via the following:. ```; chmod +x bazel-5.3.0-linux-arm64; ./bazel-5.3.0-linux-arm64; ```. Let me know if that fixes it. Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577767675:159,down,download,159,,https://github.com/google/deepvariant/issues/657#issuecomment-1577767675,1,['down'],['download']
Availability,"I think the error is simpler than that. If you grep for these specific flags (i.e. `noparse_sam_aux_fields`, `norealign_reads`, and `nosort_by_haplotypes`) they do not exist in `make_examples` -- though it uses them in the command-line -- and thus it does not know how to process them, which is probably why you are seeing the 252 exit status:. ```Bash; $ grep -E 'noparse_sam_aux_fields|norealign_reads|nosort_by_haplotypes' deepvariant/make_examples.py; $; ```; Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/419#issuecomment-774693583:12,error,error,12,,https://github.com/google/deepvariant/issues/419#issuecomment-774693583,2,['error'],['error']
Availability,"I think you are getting the wrong ""gsutil"". There is an Ubuntu package with that name and matching error messages, but what you need is the ""Google Cloud SDK"" (see https://cloud.google.com/sdk/downloads).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/5#issuecomment-349832933:99,error,error,99,,https://github.com/google/deepvariant/issues/5#issuecomment-349832933,2,"['down', 'error']","['downloads', 'error']"
Availability,I tracked the problem down to building with bazel 0.19.0 rather that 0.15.0.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/134#issuecomment-450400001:22,down,down,22,,https://github.com/google/deepvariant/issues/134#issuecomment-450400001,1,['down'],['down']
Availability,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was.; Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:; (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.); (2) Is this reliably reproducible on the same input?. Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/232#issuecomment-548613339:205,error,errors,205,,https://github.com/google/deepvariant/issues/232#issuecomment-548613339,3,"['error', 'reliab']","['error', 'errors', 'reliably']"
Availability,"I tried, but then I get this error:; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_39ce4fku/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 47, in <module>; import tensorflow as tf; File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 101, in <module>; from tensorflow_core import *; File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 40, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load; File ""<frozen importlib._bootstrap>"", line 947, in _find_and_load_unlocked; File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 50, in __getattr__; module = self._load(); File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 44, in _load; module = _importlib.import_module(self.__name__); File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/python/__init__.py"", line 68, in <module>; from tensorflow.core.protobuf.meta_graph_pb2 import TensorInfo; File ""/gpfs/home/evrong01/.local/lib/python3.6/site-packages/tensorflow_core/core/protobuf/meta_graph_pb2.py"", line 526, in <module>; serialized_options=None, file=DESCRIPTOR),; File ""/tmp/Bazel.runfiles_39ce4fku/runfiles/com_google_protobuf/python/google/protobuf/descriptor.py"", line 534, in __new__; return _message.default_pool.FindFieldByName(full_name); KeyError: ""Couldn't find field tensorflow.TensorInfo.CompositeTensor.type_spec""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/385#issuecomment-728242699:29,error,error,29,,https://github.com/google/deepvariant/issues/385#issuecomment-728242699,1,['error'],['error']
Availability,I used the right one for hg38 with the PAR regions masked as stated here:; ```; http://lh3.github.io/2017/11/13/which-human-reference-genome-to-use; ```; I see 401 variants on Y out of total 117.009,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/196#issuecomment-512585902:51,mask,masked,51,,https://github.com/google/deepvariant/issues/196#issuecomment-512585902,1,['mask'],['masked']
Availability,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:; ```; WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/; export SINGULARITY_CACHEDIR=$WORKING_DIR; export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/; mkdir -p $WORKING_DIR/tmp/. singularity exec \; 	-e \; 	-c \; 	-H $WORKING_DIR \; 	-B $WORKING_DIR/tmp:/tmp \; 	-B /usr/lib/locale/:/usr/lib/locale/ \; 	-B ""${BAM_DIR}"":""/bamdir"" \; 	-B ""${FASTA_DIR}"":""/genomedir"" \; 	-B ""${OUTPUT_DIR}"":""/output"" \; 	docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""/genomedir/$FASTA_FILE"" \; --reads=""/bamdir/$PROBAND_BAM"" \; --output_vcf=""/output/$PROBAND_VCF"" \; --output_gvcf=""/output/$PROBAND_GVCF"" \; --intermediate_results_dir=""/output/intermediate"" \; --num_shards=$NSLOTS ; ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/514#issuecomment-1156819727:1221,error,error,1221,,https://github.com/google/deepvariant/issues/514#issuecomment-1156819727,1,['error'],['error']
Availability,"I was able to run `make_examples` multiple times and have `call_variants` use multiple sharded tfrecord files at once. But I guess from this thread that the same is not possible for `postprocess_variants`?. If I run:. ```; postprocess_variants --ref Homo_sapiens.GRCh37.dna.primary_assembly.fa \; --infile call_variants_mysample.tfrecord.gz --outfile mysample.vcf.gz \; --nonvariant_site_tfrecord_path gvcf1_parent1.tfrecord@32.gz,gvcf3_parent1.tfrecord@32.gz \; --gvcf_outfile mysample.gvcf.gz; ```. I get errors like:. ```; gvcf1_parent1.tfrecord@32.gz,gvcf3_parent1.tfrecord-00031-of-00032.gz; No such file or directory; ```. So is the solution to loop through (or run in parallel) my gvcf tfrecord files, output multiple gvcfs, and then concat them with bcftools?. FYI, the `postprocess_variants` help page from docker://google/deepvariant:deeptrio-1.5.0-gpu implies that multiple tfrecord files will be accepted:. ```; --nonvariant_site_tfrecord_path: Optional. Path(s) to the non-variant sites protos in TFRecord format to convert to gVCF file. This should be the complete set of outputs from the --gvcf flag of make_examples.py.; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/413#issuecomment-1477945211:507,error,errors,507,,https://github.com/google/deepvariant/issues/413#issuecomment-1477945211,1,['error'],['errors']
Availability,"I will try to use GPUs. Thanks for the advice. I have one more question. I just wanted to make sure that model_train use all the available CPUs or GPUs in the machine I am using by default. In other words, If I dont use GNU parallel with model_train and model_eval, it wont utilize only one core by default.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/192#issuecomment-507682235:129,avail,available,129,,https://github.com/google/deepvariant/issues/192#issuecomment-507682235,1,['avail'],['available']
Availability,"I'll close this issue for now. @yangyxt if you are able to find more detailed errors, feel free to update and reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/646#issuecomment-1552499124:78,error,errors,78,,https://github.com/google/deepvariant/issues/646#issuecomment-1552499124,1,['error'],['errors']
Availability,"I'm currently testing on a low-pass WGS bam (~2GB, from blood biopsy) for quicker debugging turnaround time, and am successfully getting 16 shards and cores to run when GCP has the appropriate machine type available, here is output of lscpu:. ```; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 16; On-line CPU(s) list: 0-15; Thread(s) per core: 2; Core(s) per socket: 8; Socket(s): 1; NUMA node(s): 1; Vendor ID: GenuineIntel; CPU family: 6; Model: 63; Model name: Intel(R) Xeon(R) CPU @ 2.30GHz; Stepping: 0; CPU MHz: 2300.000; BogoMIPS: 4600.00; Hypervisor vendor: KVM; Virtualization type: full; L1d cache: 32K; L1i cache: 32K; L2 cache: 256K; L3 cache: 46080K; NUMA node0 CPU(s): 0-15; ```. I then get 16 messages like this:; `; Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']`. Then the candidate site lines begin printing out. . How much memory per shard/core/worker (assuming one worker per shard and core if I'm not mistaken) is recommended?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/150#issuecomment-461090328:206,avail,available,206,,https://github.com/google/deepvariant/issues/150#issuecomment-461090328,1,['avail'],['available']
Availability,"I'm going to close this issue, since it seems to boil down to either a network issue or a problem installing gsutil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/17#issuecomment-352605040:54,down,down,54,,https://github.com/google/deepvariant/issues/17#issuecomment-352605040,1,['down'],['down']
Availability,"I'm going to try installing CUDA 11.3 on the CentOS7 machine first, to confirm whether that will address the issue. I followed: https://developer.nvidia.com/cuda-11.3.0-download-archive?target_os=Linux. ```; wget https://developer.download.nvidia.com/compute/cuda/11.3.0/local_installers/cuda_11.3.0_465.19.01_linux.run; sudo sh cuda_11.3.0_465.19.01_linux.run; ```. ```; export PATH=/usr/local/cuda-11.3/bin:$PATH; export LD_LIBRARY_PATH=/usr/local/cuda-11.3/lib64:$LD_LIBRARY_PATH; sudo ldconfig; ```. ```; [pichuan@pichuan-gpu2 ~]$ nvcc --version; nvcc: NVIDIA (R) Cuda compiler driver; Copyright (c) 2005-2021 NVIDIA Corporation; Built on Sun_Mar_21_19:15:46_PDT_2021; Cuda compilation tools, release 11.3, V11.3.58; Build cuda_11.3.r11.3/compiler.29745058_0; ```. Now, with this, I tried:. ```; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}-gpu"" python -c 'import tensorflow as tf;print(tf.test.is_gpu_available())'; ```. which still gave me False! Hmm. I'll search the error on the internet to see if I can find something useful",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471410648:169,down,download-archive,169,,https://github.com/google/deepvariant/issues/619#issuecomment-1471410648,3,"['down', 'error']","['download', 'download-archive', 'error']"
Availability,"I'm going to try out this:. https://stackoverflow.com/questions/67045622/tensorflow-stream-executor-cuda-cuda-driver-cc328-failed-call-to-cuinit-cuda. on the machine where I just installed CUDA 11.3. First, just `sudo yum install nvidia-modprobe` didn't seem to work for me. So I had this workaround first:. ```; sudo su. cat <<EOF > /etc/yum.repos.d/nvidia.repo; [nvidia]; baseurl=https://developer.download.nvidia.com/compute/cuda/repos/rhel7/x86_64/; enabled=1; gpgcheck=0; EOF; ```. And then; ```; sudo yum install nvidia-modprobe; ```. Check version:. ```; nvidia-modprobe --version; ```; shows:; ```; nvidia-modprobe: version 440.118.02; ```. check CUDA version again:; ```; [pichuan@pichuan-gpu2 ~]$ nvcc --version; nvcc: NVIDIA (R) Cuda compiler driver; Copyright (c) 2005-2021 NVIDIA Corporation; Built on Sun_Mar_21_19:15:46_PDT_2021; Cuda compilation tools, release 11.3, V11.3.58; Build cuda_11.3.r11.3/compiler.29745058_0; ```. Try this again:; ```; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}-gpu"" python -c 'import tensorflow as tf;print(tf.test.is_gpu_available())'; ```; Still false -- didn't seem to help:. ```; 2023-03-16 07:01:52.583106: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; 2023-03-16 07:01:52.583190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: pichuan-gpu2; 2023-03-16 07:01:52.583209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: pichuan-gpu2; 2023-03-16 07:01:52.583304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; 2023-03-16 07:01:52.583352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1; False; ```. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471426355:400,down,download,400,,https://github.com/google/deepvariant/issues/619#issuecomment-1471426355,1,['down'],['download']
Availability,"I'm guessing that that is an effect of Python PIP trying to be helpful.; CLIF provides two Python programs/tools (pyclif and pyclif_proto) which are; Python. PIP (with setup.py) creates tiny launchers for them for user; convenience, but encode build Python path and eg. --py3 option into those; launchers.; When user environment for CLIF use is different from the build environment; those launchers are not correct anymore and needs to be removed/regenerated; or otherwise ""fixed"" to reflect different conditions. On Thu, May 3, 2018 at 3:17 AM Brad Chapman <notifications@github.com>; wrote:. > Pi-Chuan and Mike;; > Thanks for all this background and help. I'm trying to fit this into the; > conda recipe bazel build for DeepVariant but am not sure how to take; > advantage of using the local anaconda python in that context. The error I'm; > seeing is that bazel can't find pyclif_proto:; >; > (17:56:01) INFO: Found 1 target...; > (17:56:01) [0 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt; > (17:56:01) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'; > (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1: //third_party/nucleus/protos:variants_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'; > Target //deepvariant:binaries failed to build; > (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1 1 input file(s) do not exist; >; > which I thought was triggered by the difficulty running pyclif without; > having the local python installed. It could also be due to not installing; > is in /usr/local/bin since I have to remain sandboxed in the work; > directory, but I did adjust the PATH to include the download location.; >; > Sorry I'm stuck here due to me limited knowledge of bazel tweaking. Either; > understanding how to handle a root install of the pre-build pyclif or; > tweaking to use the lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386327937:832,error,error,832,,https://github.com/google/deepvariant/issues/29#issuecomment-386327937,1,['error'],['error']
Availability,"I'm happy to hear you have enjoyed my YouTube videos :). Hmm, there should be a more informative error message above the one that says ""parallel: This job failed"". If you don't see it, try running it without parallel and without the ""@"" sharding in the output file names. I wouldn't recommend using `bedtools bamtobed` to generate the bed file, even if other ways aren't working. That is because it would generate a region for every read, which is definitely not the --regions DeepVariant is expecting! Since you do have the exome capture bed file, then let's get that working instead :). Also, does it work for one of the regions in the `idt_capture_novogene.grch38.bed` file?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/483#issuecomment-917346497:97,error,error,97,,https://github.com/google/deepvariant/issues/483#issuecomment-917346497,1,['error'],['error']
Availability,"I'm not sure I fully understand, I'm not a very experienced docker user. . The command is being run by a non-root user who is part of the docker user group. They are running the commands in the same directories that they ran them in before, rerunning it with alignments that have been filtered differently than their first run, but otherwise identical to their previous runs that worked just fine. The command is even directly copied and pasted). I'm a bit baffled because as far as I can discern, any user/permission issues should have also factored in the last time. But it worked before a recent reboot and now no longer does. I've also tried restarting docker to no avail. In my own non-root account I was previously able to run the quickstart example, but now that will not work for me either. We supplied our working director as ${PWD} rather than ${HOME} which I would have thought would address the location issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1699174840:599,reboot,reboot,599,,https://github.com/google/deepvariant/issues/184#issuecomment-1699174840,2,"['avail', 'reboot']","['avail', 'reboot']"
Availability,"I've also tried on Ubuntu 18.04 and getting similar problems. Have you tried these test on systems other than 16.04, or should I really try to downgrade to that exact version? Thanks!. `Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-54-generic x86_64)`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/199#issuecomment-514398912:143,down,downgrade,143,,https://github.com/google/deepvariant/issues/199#issuecomment-514398912,1,['down'],['downgrade']
Availability,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning; **2)** After an 1-2 hours I would have expected to see that error message with the previous runs.; **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-479738587:334,error,error,334,,https://github.com/google/deepvariant/issues/167#issuecomment-479738587,1,['error'],['error']
Availability,"I've made the suggested changes at https://github.com/zyxue/deepvariant/commit/cc09d6da17dcb700144cb3cd8dd2b7ece2c3ad86. ```diff; diff --git a/third_party/nucleus/io/sam_reader.cc b/third_party/nucleus/io/sam_reader.cc; index d8c7cae..1b020be 100644; --- a/third_party/nucleus/io/sam_reader.cc; +++ b/third_party/nucleus/io/sam_reader.cc; @@ -445,11 +445,15 @@ tf::Status ConvertToPb(const bam_hdr_t* h, const bam1_t* b,; // Set the mates map position if the mate is not unmapped.; if (paired && !(c->flag & BAM_FMUNMAP)) {; Position* mate_position = read_message->mutable_next_mate_position();; - if (c->mtid < 0); + if (c->mtid < -1); return tf::errors::DataLoss(; ""Expected mtid >= 0 as mate is supposedly mapped: "",; read_message->ShortDebugString());; - mate_position->set_reference_name(h->target_name[c->mtid]);; + else if (c->mtid == -1) {; + mate_position->set_reference_name(""*"");; + } else {; + mate_position->set_reference_name(h->target_name[c->mtid]);; + }; mate_position->set_position(c->mpos);; mate_position->set_reverse_strand(bam_is_mrev(b));; }; ```. What command do you use to build the docker image, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/99#issuecomment-428356537:648,error,errors,648,,https://github.com/google/deepvariant/issues/99#issuecomment-428356537,1,['error'],['errors']
Availability,I've pinged the @mrovner and @gpshead about CLIF. I'm hopeful they'll chime in here.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-355459571:5,ping,pinged,5,,https://github.com/google/deepvariant/issues/29#issuecomment-355459571,1,['ping'],['pinged']
Availability,"I've shared a slice of the [cram](https://polybox.ethz.ch/index.php/s/gs77cgkairybovm) and [index](https://polybox.ethz.ch/index.php/s/4TddHufT6wsGMaB) with the [reference](https://polybox.ethz.ch/index.php/s/koYmv6FLL59ahI7). This is definitely strange, because slicing out part of the first chromosome reproduces the crash, but slicing out chromosome 29 (this is on cattle) appears to run fine, so this must be some bizarre edge case. Even more strangely, if I use the container version of samtools to extract this exact slice with `--output-fmt-option version=3.1 `, it makes it further to the candidate generation stage but then potentially freezes (or is just very slow to decode the cram). I've attached the exact command and full error I get to reproduce this on v1.6.; [fulllog.txt](https://github.com/google/deepvariant/files/13497112/fulllog.txt)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/741#issuecomment-1831332493:737,error,error,737,,https://github.com/google/deepvariant/issues/741#issuecomment-1831332493,1,['error'],['error']
Availability,"INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. which also seems to work. This command below shows my TensorFlow version:. ```; pichuan@pichuan-gpu:~$ singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}-gpu"" python -c 'import tensorflow as tf; print(tf.__version__)'; INFO: Using cached SIF image; 2022-02-10 23:13:05.337920: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; 2.5.0; ```. To confirm the path:. ```; pichuan@pichuan-gpu:~$ singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}-gpu"" python -c 'import tensorflow as tf; print(tf.__file__)'; INFO: Using cached SIF image; 2022-02-10 23:12:22.632481: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; /usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py; ```. I have to say I don't really know how Singularity works, but here are a few commands I tried:. ```; pichuan@pichuan-gpu:~$ singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}-gpu"" ls /usr/local/lib/python3.8/dist-packages/tensorflow; INFO: Using cached SIF image; __init__.py __pycache__ _api compiler core include keras libtensorflow_framework.so.2 lite python tools xla_aot_runtime_src; ```; ```; pichuan@pichuan-gpu:~$ ls /usr/local/lib/python3.8/dist-packages/tensorflow; ls: cannot access '/usr/local/lib/python3.8/dist-packages/tensorflow': No such file or directory; ```. Not really sure how helpful this is. @Phillip-a-richmond if you spot any differences, let me know how I can change to reproduce the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/514#issuecomment-1035630725:3903,error,error,3903,,https://github.com/google/deepvariant/issues/514#issuecomment-1035630725,1,['error'],['error']
Availability,"If it helps, this is what the model folder looks like:. ```; total 401316; -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001; -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index; -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta; -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1; ```; (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```; MODEL_VERSION=""0.7.2""; MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard""; MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}; wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001; wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index; wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta; ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/166#issuecomment-478393809:463,down,download,463,,https://github.com/google/deepvariant/issues/166#issuecomment-478393809,4,"['down', 'error']","['download', 'downloading', 'error']"
Availability,"If the actual depth in a particular region is greater than the pileup image height, DeepVariant randomly downsamples reads until the image has been filled up. For the default DeepVariant models (height 100), an image can accommodate at most 95 reads in a given region (5 rows are reserved for the reference sequence). . You may be able to successfully run our pretrained models with a different pileup image height (via `--pileup_image_height` in `make_examples.py`), depending on the new height. However, we generally do not recommend using different image heights at training and inference time. If you wish to use a different pileup image height, we recommend retraining a new model with images of that height. . If you are working with extremely high coverage sequencing data for applications such as somatic sequencing, we recommend using a somatic caller instead of DeepVariant, which is a germline caller.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/425#issuecomment-782444906:105,down,downsamples,105,,https://github.com/google/deepvariant/issues/425#issuecomment-782444906,1,['down'],['downsamples']
Availability,"In case you don't want to rerun DeepVariant with the newer version to get the report, you can use this script to generate the VCF stats report from an existing VCF file: https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-vcf-stats-report.md; The script is only available in version 0.9+, but this way you won't have to rerun the whole pipeline.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/290#issuecomment-606166642:276,avail,available,276,,https://github.com/google/deepvariant/issues/290#issuecomment-606166642,1,['avail'],['available']
Availability,"In my downstream analysis with WhatsHap today I found that the VCF contains only 3,889,968. The data comes from PacBio CCS 10x sequencing and I wonder if this can be the correct number of SNPs for this method. E.g. I analyzed several WGS 30x datasets from Nebula so far and spotted amounts of SNPs in the range of 4.6-4.8 million. Is there anything that I missed here?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1613234641:6,down,downstream,6,,https://github.com/google/deepvariant/issues/666#issuecomment-1613234641,1,['down'],['downstream']
Availability,In order to debug the issue we need to see the error from DeepVariant. I see that you redirected stdout to `deepvariant_log.txt`. What is the content of this file?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/883#issuecomment-2354504549:47,error,error,47,,https://github.com/google/deepvariant/issues/883#issuecomment-2354504549,1,['error'],['error']
Availability,"In the current release, training occurs on chr1-19 using the v3.3.2 benchmark set for HG001, HG005-HG006 using BAM files mapped to GRCh37 (it's important to use GRCh37 when benchmarking with v3.3.2 as there are liftover artifacts on GRCh38 since v3.3.2 was not constructed on this truth set. v4.2 regions are used in training with HG002-HG004 in the current version with GRCh38. With the next version, we plan to fully withhold HG003 from training for all data types. chr20 is never used for training or model selection or anything that would influence model performance. It is a fully held-out test set. chr21 and chr22 are not used for training, but the performance on chr21 and chr22 are used in a tune set that identifies at what checkpoint to select the model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/381#issuecomment-728683346:734,checkpoint,checkpoint,734,,https://github.com/google/deepvariant/issues/381#issuecomment-728683346,1,['checkpoint'],['checkpoint']
Availability,"Indeed the file was truncated, sorry about that. I am still testing locally; with other even smaller files ( like : wget; http://dv-testfiles.s3.amazonaws.com/wgEncodeUwRepliSeqGm12878G1bAlnRep1.bam; which is public and smaller and not truncated ) and I get the same exact; error again. 2018-03-07 22:36 GMT+01:00 Paul Grosu <notifications@github.com>:. > I was suspicious something else might be the issue. So I did a simple test; > to see if there is an issue with Luisa's BAM file, and noticed that I; > cannot even create an index - which would naturally make even the; > prerequisite make_examples not complete properly:; >; > paul@gubuntu:~/data/luisa$ wget http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > --2018-03-07 <http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam--2018-03-07> 16:20:42-- http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > Resolving dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)... 52.218.52.113; > Connecting to dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)|52.218.52.113|:80... connected.; > HTTP request sent, awaiting response... 200 OK; > Length: 357342653 (341M) [binary/octet-stream]; > Saving to: âENCFF528VXT.bamâ; >; > ENCFF528VXT.bam 100%[=========================================================>] 340.79M 1.26MB/s in 5m 17s; >; > 2018-03-07 16:25:59 (1.08 MB/s) - âENCFF528VXT.bamâ saved [357342653/357342653]; >; > paul@gubuntu:~/data/luisa$ samtools index ENCFF528VXT.bam; > [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; > [E::bgzf_read] Read block operation failed with error -1 after 143 of 246 bytes; > samtools index: failed to create index for ""ENCFF528VXT.bam""; > paul@gubuntu:~/data/luisa$; > paul@gubuntu:~/data/luisa$; > paul@gubuntu:~/data/luisa$ cd ~/deepvariant/bazel-bin; > paul@gubuntu:~/deepvariant/bazel-bin$ PYTHONPATH=. /usr/bin/python deepvariant/make_examples --mode calling --ref /home/paul/data/luisa/hg19.fa --reads /home/paul/data/luisa/ENCFF528VXT.bam --exam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371306075:274,error,error,274,,https://github.com/google/deepvariant/issues/52#issuecomment-371306075,2,['error'],['error']
Availability,"Interesting. Could you share the command you ran and the error message?. On Tue, Apr 28, 2020 at 1:45 PM WeiweiBian <notifications@github.com> wrote:. > Thank a lot for your reply. The 'single quotes encased by double quotes'; > works for this case, but when I added more regions, it couldn't give me an; > available output and showed an exit status 247.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/305#issuecomment-620845064>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AB4W4PIOBHJ5DAXPKER4A63RO457FANCNFSM4MQ4ZT2Q>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/305#issuecomment-620891124:57,error,error,57,,https://github.com/google/deepvariant/issues/305#issuecomment-620891124,2,"['avail', 'error']","['available', 'error']"
Availability,"Interestingly, if I run `cd bin; ./run-prereq.sh` (without `sudo`) I get a permission error:; ```; ========== [Fri Jan 26 11:13:59 EST 2018] Stage 'Install TensorFlow pip package' starting ; Installing Google Cloud Platform optimized CPU-only TensorFlow wheel ; Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl...; OSError: Operation not permitted. ; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/41#issuecomment-360833579:86,error,error,86,,https://github.com/google/deepvariant/issues/41#issuecomment-360833579,1,['error'],['error']
Availability,"Is there a solution to the second error that occurs when renaming (model.ckpt.data-00000-of-00001 -> model.ckpt), or is this not supported for TPU usage?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1148070760:34,error,error,34,,https://github.com/google/deepvariant/issues/537#issuecomment-1148070760,1,['error'],['error']
Availability,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658785274:662,error,errors,662,,https://github.com/google/deepvariant/issues/682#issuecomment-1658785274,1,['error'],['errors']
Availability,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions?. I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-457977330:142,error,error,142,,https://github.com/google/deepvariant/issues/132#issuecomment-457977330,1,['error'],['error']
Availability,"It is an interesting point about homopolymer reads that they shouldn't be considered at all. I will think about it further. My thoughts were that the CNN probably filters out such information, and no additional gain would be available by removing those reads. Also, an upstream heterozygous SNV might disambiguate the indel allele correctly through realignment. Thanks for confirming that partial insertions are considered and not discarded. However, there are still cases where a site has two alternative insertion alleles (say, CT, and CTCTTT; both alleles are supported by reads covering both the left and right positions of the insertion), where it may not be possible to determine which allele a partially overlapping read supports (the read terminates with an insertion of CT). But this may be an extremely rare occurrence and one that is not considered relevant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/213#issuecomment-527641443:225,avail,available,225,,https://github.com/google/deepvariant/issues/213#issuecomment-527641443,1,['avail'],['available']
Availability,"It is not a requirement to use Google Cloud or its SDK. You should be able to still use DeepVariant without having to install anything related to Google Cloud.; One issue here is that we put our data (including pre-built binaries) on Google Cloud storage. So you might not have access to them. You can try the browser version to see if you can view or download the data: https://console.cloud.google.com/storage/browser/deepvariant. But even if that doesn't work, you should still be able to build the binary from scratch:; https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. The example input data (such as FASTA, BAM files) can be found on their original sites. For example, in the Case Study we listed where we got the files: https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-case-study.md#test-data",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/17#issuecomment-352085708:352,down,download,352,,https://github.com/google/deepvariant/issues/17#issuecomment-352085708,1,['down'],['download']
Availability,"It is the bam file of a TCGA sample. I didn't align it myself, it's downloaded directly from a TCGA host. I will check and see it's validity, thank you for the information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/99#issuecomment-426813624:68,down,downloaded,68,,https://github.com/google/deepvariant/issues/99#issuecomment-426813624,1,['down'],['downloaded']
Availability,"It looks like you are using PacBio data, but not setting the PB `--mode` flag to `pacbio` ([docs](https://docs.nvidia.com/clara/parabricks/4.2.1/documentation/tooldocs/man_deepvariant.html#available-operating-modes)). The default for that flag is `shortread` which will not work with the long reads in PacBio data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/798#issuecomment-2030252774:189,avail,available-operating-modes,189,,https://github.com/google/deepvariant/issues/798#issuecomment-2030252774,1,['avail'],['available-operating-modes']
Availability,"It looks like you're not mounting any directories in your Singularity command. See the FAQ for how to debug that:; https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open -- ""Why can't it find one of the input files? E.g., ""Could not open"""". If that doesn't work, can you include the error messages too?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/474#issuecomment-885791994:346,error,error,346,,https://github.com/google/deepvariant/issues/474#issuecomment-885791994,1,['error'],['error']
Availability,"It seems like original question is resolved for now.; If there are more questions for `call_variants`, feel free to open another issue.; I think it's also possible to do with whether Intel MKL is available or not on your machine. If your speed reported in the `call_variants` step is much slower, feel free to open another issue and we can discuss there.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/105#issuecomment-430714499:196,avail,available,196,,https://github.com/google/deepvariant/issues/105#issuecomment-430714499,1,['avail'],['available']
Availability,"It should also be available in the v0.10.0 release. If not, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/290#issuecomment-606155318:18,avail,available,18,,https://github.com/google/deepvariant/issues/290#issuecomment-606155318,1,['avail'],['available']
Availability,"It was run with 256G RAM node and all other samples finish in the same RAM nodes. I will send you data later; ________________________________; From: Lucas Brambrink ***@***.***>; Sent: Tuesday, March 26, 2024 6:46:34 PM; To: google/deepvariant ***@***.***>; Cc: Zhigui Bao ***@***.***>; Author ***@***.***>; Subject: Re: [google/deepvariant] Fatal Python error: Segmentation fault (Issue #794). Sure thing! You can send me the files at ***@***.******@***.***>. Additionally, Seg faults can sometimes happen from OOMs (running out of memory). Do you have the memory specs of the instance you are running this on? Thanks!. —; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/794#issuecomment-2021094547>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AE5Y3VRRFLRCYTPDYDZDFY3Y2GX7VAVCNFSM6AAAAABFG7OINSVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDAMRRGA4TINJUG4>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/794#issuecomment-2021114740:356,error,error,356,,https://github.com/google/deepvariant/issues/794#issuecomment-2021114740,3,"['error', 'fault']","['error', 'fault', 'faults']"
Availability,"It's also possible to start training from our released checkpoints, if you want, so you can either start from scratch, start from imagenet, or start from a DeepVariant released model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/46#issuecomment-364535704:55,checkpoint,checkpoints,55,,https://github.com/google/deepvariant/issues/46#issuecomment-364535704,1,['checkpoint'],['checkpoints']
Availability,Jun-08 12:02:05.804 [main] DEBUG nextflow.Session - Igniting dataflow network (2); Jun-08 12:02:05.809 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > pbc_varicall; Jun-08 12:02:05.810 [main] DEBUG nextflow.script.ScriptRunner - > Awaiting termination; Jun-08 12:02:05.810 [main] DEBUG nextflow.Session - Session await; Jun-08 12:02:05.895 [Actor Thread 5] DEBUG nextflow.container.SingularityCache - Singularity found local store for image=docker://google/deepvariant:1.5.0; path=/data/shared/clinical/LongRead/cache/google-deepvariant-1.5.0.img; Jun-08 12:02:06.011 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run; Jun-08 12:02:06.012 [Task submitter] INFO nextflow.Session - [55/335c47] Submitted process > pbc_varicall (1); Jun-08 12:07:05.943 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:12:06.012 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:06.076 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:16.724 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 1; name: pbc_varicall (1); status: COMPLETED; exit: 1; error: -; workDir: /data/shared/clinical/LongRead/Pipel,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308:3981,error,error,3981,,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308,2,['error'],['error']
Availability,"Just confirming I can reproduce the error myself. I think I know what the problem is. In the meantime you can use the previous labeling algorithm as a workaround. Just add ' --labeler_algorithm positional_labeler' to your command line, which is working for me just fine right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/71#issuecomment-387907040:36,error,error,36,,https://github.com/google/deepvariant/issues/71#issuecomment-387907040,1,['error'],['error']
Availability,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/91#issuecomment-1019990521:263,Down,Downside,263,,https://github.com/google/deepvariant/issues/91#issuecomment-1019990521,2,['Down'],['Downside']
Availability,"K-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```; Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele; ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/680#issuecomment-1640133876:1941,down,downstream,1941,,https://github.com/google/deepvariant/issues/680#issuecomment-1640133876,1,['down'],['downstream']
Availability,"Looking at this error message, I wonder if it's related to Python3 vs Python2.; Currently DeepVariant still only supports Python2. Adding @chapmanb (who maintains DeepVariant on bioconda ) , do you think there might be other issues going on here? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/252#issuecomment-566176982:16,error,error,16,,https://github.com/google/deepvariant/issues/252#issuecomment-566176982,1,['error'],['error']
Availability,"Looks like the relevant error message is:; ```; ValueError: UNKNOWN: Could not open variants_path: /data/shared/clinical/LongRead/Data//Analysis/out_m84011_220902_175841_NFR_sif.vcf.gz; ```; On many systems, writing an output file is not possible if the directory is not present already, so can you make sure the directory exists first:. ```; mkdir -p /data/shared/clinical/LongRead/Data//Analysis/; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/659#issuecomment-1584844298:24,error,error,24,,https://github.com/google/deepvariant/issues/659#issuecomment-1584844298,1,['error'],['error']
Availability,"M_TARGETS_TO_BUILD=PowerPC \; -DPYTHON_INCLUDE_DIR=""$HOMEPATH/inst/include/python2.7"" \; -DPYTHON_LIBRARY=""$HOMEPATH/inst/lib/libpython2.7.so"" \; -DPYTHON_EXECUTABLE=""$HOMEPATH/inst/bin/python"" \; ""$LLVM_DIR/llvm""; make -j20 clif-matcher; # export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH; make -j20 clif_python_utils_proto_util; make -j20 install. ## Get back to the CLIF Python directory and have pip run setup.py.; cd ""$CLIFSRC_DIR""; # Grab the python compiled .proto; cp ""$BUILD_DIR/tools/clif/protos/ast_pb2.py"" clif/protos/; # Grab CLIF generated wrapper implementation for proto_util.; cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.cc"" clif/python/utils/; cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.h"" clif/python/utils/; cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.init.cc"" clif/python/utils/; # install; export C_INCLUDE_PATH=/home/qilibj/inst/include; export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include; ""$CLIF_PIP"" install .; # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif.""; python setup.py bdist_wheel; # Note: pyclif should be installed into virtualenv; ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl; pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify; python -c ""from clif.python.proto import start"". # link for deepvariant; ln -s /home/qilibj/inst/clif /usr/local/; ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash; # Checkout repository and submodules; git clone https://github.com/skvark/opencv-python.git; cd opencv-python/; # fetch the tags to your local repository; git fetch --all --tags --prune; # check out tag 3.4.5.20; git checkout tags/20; # load submoduel; git submodule update --init --recursive. # Dependency; pip install pyparsing; yum install qt-devel; # Build; python setup.py bdist_wheel. # Insatll; pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:14671,echo,echo,14671,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['echo'],['echo']
Availability,"Machine has 64 cores, 2TB RAM, Centos is OS. Deep variant docker code works well when input bam file size is less than; 20 Gb file size, but when I increase the file size / coverage, I get the; error. On Wed, Sep 22, 2021 at 9:08 PM Pi-Chuan Chang ***@***.***>; wrote:. > @kirti141 <https://github.com/kirti141> from the log, I agree that it; > isn't quite clear.; > Can you tell us about your machine? How many CPU cores, RAM, what OS, etc.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/482#issuecomment-925047566>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ANQXTKYZH6MM2EGS7CBSZPTUDHZ7FANCNFSM5DR4DILA>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.; >; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/482#issuecomment-925379521:194,error,error,194,,https://github.com/google/deepvariant/issues/482#issuecomment-925379521,2,['error'],['error']
Availability,"Makes sense. I downloaded the files now, and it works with the RNAseq model. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/777#issuecomment-1971687728:15,down,downloaded,15,,https://github.com/google/deepvariant/issues/777#issuecomment-1971687728,1,['down'],['downloaded']
Availability,"Might not be the same issue but: I got this error message when doing a custom hello world run. My mistake was that when I removed comments from the example command, a space character was accidentally left behind after a backslash, rendering it useless.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/402#issuecomment-901465519:44,error,error,44,,https://github.com/google/deepvariant/issues/402#issuecomment-901465519,1,['error'],['error']
Availability,"Most likely this error is due to your reference and input BAM/SAM have different contig names. The error you see may happen if for example reference contigs are named ""chr1"", ""chr2"", etc but input input BAM/SAM contigs have names without ""chr"" prefix.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/106#issuecomment-430047336:17,error,error,17,,https://github.com/google/deepvariant/issues/106#issuecomment-430047336,2,['error'],['error']
Availability,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. ; But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process!. This my memory on Ubuntu-VirtualM:; Filesystem Size Used Avail Use% Mounted on; tmpfs 794M 1.1M 793M 1% /run; /dev/sda1 126G 15G 112G 12% /; tmpfs 3.9G 0 3.9G 0% /dev/shm; tmpfs 5.0M 0 5.0M 0% /run/lock; /dev/sda15 105M 6.1M 99M 6% /boot/efi; tmpfs 794M 4.0K 794M 1% /run/user/1000; :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/675#issuecomment-1630405873:295,Avail,Avail,295,,https://github.com/google/deepvariant/issues/675#issuecomment-1630405873,1,['Avail'],['Avail']
Availability,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/522#issuecomment-1059260579:32,error,error,32,,https://github.com/google/deepvariant/issues/522#issuecomment-1059260579,4,"['down', 'error']","['download', 'error']"
Availability,"My current investigation shows that this went down the path here:; https://github.com/samtools/htslib/blob/1.10.2/hts.c#L460-L463. which ended up identify this file as an FAI format. And then this format gets into this switch:; https://github.com/samtools/htslib/blob/1.10.2/hts.c#L1069-L1105; But FAI format doesn't get read here, so it got into the last branch of the switch:; ```; default:; errno = EFTYPE;; goto error;; ```. One potential solution here is that we can change the Nucleus BedReader to always read file as BED (and not using htslib's format detection). This could cause other issues (for example, unable to read bed.gz. (Although, I personally have not tried using bed.gz files yet). Another potential solution : maybe newer version of htslib would work. I have not tried that either. For now, please preprocess the file and remove the last column. I'll discuss with teammates to see if it makes sense to change the BedReader implementation in Nucleus for this. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/374#issuecomment-723752207:46,down,down,46,,https://github.com/google/deepvariant/issues/374#issuecomment-723752207,2,"['down', 'error']","['down', 'error']"
Availability,"My spidey sense is telling me that you have two versions installed. If you run the following Python commands you can see the search-order of paths to determine if you have another `intervaltree` module installed system-wide, and it prioritizes that one before yours:. ```Python; import sys; print(sys.path); ```. The easiest thing is to set the `PYTHONPATH`, or just download the package and untar it in the local deepvariant directory. Here's more info on the Python's search-order of modules:. https://leemendelowitz.github.io/blog/how-does-python-find-packages.html. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/155#issuecomment-464532038:367,down,download,367,,https://github.com/google/deepvariant/issues/155#issuecomment-464532038,1,['down'],['download']
Availability,"NOTE: I've checked the `alignments20_sorted.bam` file to see if the QUAL field is still set to * as @pgrosu pointed out here:. > As these are sorted reads, by just looking at the BAM file, it starts with position 60001, as shown here - which why you are getting 0 candidates:; > ; > ```; > 55ad4f97_28026_0 0 chr20 60001 50 618S27M1D8M1I6M1D7M1D5M1I9M1I5M1D20M1D8M1I24M1I35M1I9M1I2M1I1M1I52M1D3M1D15M2D4M2D12M1I21M1I5M1; > D11M1D7M1I18M1I15M1D1M1D43M1I16M1D8M1I21M1D2M1D7M1I10M1I2M1D8M1D5M1D3M1D2M1I13M1D28M1I20M1I4M1I37M1I19M1I21M1D18M1I5M1D16M1I1M1I3M1I29M1I12M1D6M1I2M1I7; > M1D1M1D2M1I4M1D22M1D18M1I4M1D12M1D4M1I1M1I3M2I17M1I1M1I44M1D3M1D2M1D10M1I11M2D1M1D9M1I19M1D2M1I32M1D2M1D8M1D20M1I14M1D6M1D15M1I7M1D3M1D25M1I6M1I8M1D11M; > 1I7M1I11M1I12M1D2M1D3M1I70M1I23M1D3M1I48M1I21M1I46M1D14M1I3M1D10M1I6M1D34M2I8M1I11M1I5M1I10M1D8M1I8M1I14M1D19M1I26M1I6M1I13M1D4M1I2M1I33M1I8M1I7M1I12M1I1M1I4M1I8M1I3M1I1M1I3M2I4M1I14M1I1M1I5M1I1M1I1M1I2M2I2M1I3M1I1M4I3M1I1M1I1M2I3M4I5M1I3M1I1M1I3M3I5M1I6M1I2M1I1M2I1M1I7M1I3M2I3M1I5M2I1M2I4M1I1M1I2M1D4M1I6M1I3M1I2M1I1M4I1M1I1M2I5M1I3M1I3M1I2M1D1M1I2M2I1M1I1M1I4M3I1M2I2M1I6M1I4M3I1M3I1M3I8M2I47M1I11M1I8M1D3M1I1M1I30M1I15M1I6M1I17M1D18M1D4M1I19M1I28M1D37M1I23M1D7M1D21M1D79M1I12M1D1M1D9M1I21M1D44M1D30M1D3M1I13M1I9M1I34M1D10M1I; > ```; > Since no PHRED value is stored with a `*`, as shown here:; > ; > ```; > AGTCTGCTTCATGCCTTTAACT * AS:i:-15583 ; > ```; > This is why the read triggers the assertion failure [here](https://github.com/google/deepvariant/blob/master/deepvariant/allelecounter.cc#L103):; > ; > ```c++; > CHECK_LE(offset + len, read.aligned_quality_size());; > ```; > ; > The preferred response that would be nice, is if the code could just identify which read (QNAME) it is referring to in order to verify this, or just have a flag to ignore reads that one has no QUAL score for.; > ; > Hope it helps,; > ~p. Viewing the file with samtools (and quickly killing the command) showed me that it is indeed still set to *, as you can see below:; ```; user@",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-458488164:1436,failure,failure,1436,,https://github.com/google/deepvariant/issues/138#issuecomment-458488164,1,['failure'],['failure']
Availability,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```; $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json; {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} ; ```. The ""channels"" values are enums. You can look them up in this proto:; https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```; CH_READ_BASE = 1;; CH_BASE_QUALITY = 2;; CH_MAPPING_QUALITY = 3;; CH_STRAND = 4;; CH_READ_SUPPORTS_VARIANT = 5;; CH_BASE_DIFFERS_FROM_REF = 6;; CH_INSERT_SIZE = 19;; ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/568#issuecomment-1253235153:10,checkpoint,checkpoints,10,,https://github.com/google/deepvariant/issues/568#issuecomment-1253235153,1,['checkpoint'],['checkpoints']
Availability,No luck either. I figured it seems that the Xeon CPU on my machine does not support AVX (according to /proc/cpuinfo). Some informative error message would be nice in such a situation. Couldn't the docker container be built without assuming avx presence? It would be slower I guess but easier to explore the tool.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/39#issuecomment-358230941:135,error,error,135,,https://github.com/google/deepvariant/issues/39#issuecomment-358230941,1,['error'],['error']
Availability,"No worries, but like I have studied quite a lot of dna and rna sequence; data. But i may also be missing the obvious answer. By the way hybrid assembly using both long and short reads can make for a; more complete assembly. On a comletely separate note, you check for methylation in your organism?; Id be happy to do it for you!. Joe. On Mon, 31 Jul 2023, 18:10 Axze-rgb, ***@***.***> wrote:. > Could be the stupidest advice in the universe but she you looking st your; > vcf file.or thinking if the necwr comment to send back to me, Literally; > just thought talking through the problem might help, fellow human, and no I; > didn't check the organism, you could have told me and I would gkne the ncbi; > datanae downloaded the genomes aligned them checked your region if interest; > don't worry if I see your name on the email thread on this public github; > repository I won't reply and I'll loom forward your paper on bioarvix; > hopefully, Honestly all the best, And if you don't care about prokaryotes; > then fair enough, Joe; > … <#m_-2096600892735742938_>; > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the; > organism has been said in this thread, that you are unable to find it, and; > believe we deal with a prokaryote is pathetic, really. Why would we bother; > with your stupid advice when you didn't even take the time to read the; > thread? — Reply to this email directly, view it on GitHub <#682 (comment); > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,; > or unsubscribe; > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ; > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>; > . You are receiving this because you commented.Message ID: @.*>; >; > There are so many trolls it's difficult to know when someone is just; > clumsy. I am willing to give you the benefit of the doubt. Buit really you; > could have read the messages ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658806137:713,down,downloaded,713,,https://github.com/google/deepvariant/issues/682#issuecomment-1658806137,1,['down'],['downloaded']
Availability,"No. Currently PacBio HiFi/CCS data is the only long-read sequencing type supported. ONT reads, including PromethIon, have a much higher error rate (same for PacBio CLR) and would therefore need special treatment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/277#issuecomment-594834868:136,error,error,136,,https://github.com/google/deepvariant/issues/277#issuecomment-594834868,1,['error'],['error']
Availability,"Not sure what changed, but I ran the same code again and it produced a checkpoint output file this time! ; Is the model_eval step no longer necessary? I see it in the 1.5 version of the case study documentation but not in the 1.6 version. ; Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2030917004:71,checkpoint,checkpoint,71,,https://github.com/google/deepvariant/issues/797#issuecomment-2030917004,1,['checkpoint'],['checkpoint']
Availability,"Note that not all our DeepTrio models use the default height in the code (which is the 100+100+100=300 that @danielecook is referring to). See here:; https://github.com/google/deepvariant/blob/r1.2/scripts/run_deeptrio.py#L181-L184. @Suke-fudan please considering using the one-step `run_deeptrio.py` script for this. See this section:; https://github.com/google/deepvariant/blob/r1.2/docs/deeptrio-quick-start.md#run-deeptrio-with-one-command. And, if you really want to break it down to multiple steps, you can still use run_deeptrio.py and add `--dry_run=true` to see the command breakdown. So, basically for PACBIO DeepTrio, you'll want to set:; `--pileup_image_height_child=60` and `--pileup_image_height_parent=40`; in your make_examples stage.; ; Does this make sense? Let me know if that works for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/488#issuecomment-929837599:481,down,down,481,,https://github.com/google/deepvariant/issues/488#issuecomment-929837599,1,['down'],['down']
Availability,"OK – that proceeded further, I think. Now the error is; ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes: [64,27,1,3]. I hate to keep bothering people about this. Is there documentation on all of this that I can refer to?. Thanks,; Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]; Sent: Tuesday, April 10, 2018 1:04 PM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. I think you'll want:; tfrecord_path: ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380193942>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth D",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-380197853:46,error,error,46,,https://github.com/google/deepvariant/issues/62#issuecomment-380197853,1,['error'],['error']
Availability,"OK. I noticed that my `pyclif_proto` is in /usr/local/bin/, not /usr/local/clif/bin. Not knowing if that really is an issue, I did the following:; ```; sudo ln -sf /usr/local/bin/pyclif_proto /usr/local/clif/bin/pyclif_proto; ```. And added that to my [experimental build-prereq.sh](https://gist.github.com/pichuan/7928d101a730c03167b6d80c9c3c58ac). Now I'm seeing a different error:; ```; (06:15:00) INFO: Found 80 targets and 33 test targets...; (06:15:00) ERROR: /home/pichuan/.cache/bazel/_bazel_pichuan/01047f0bd74be1f8c2eae71c8557726c/external/nsync/BUILD:441:1: C++ compilation of rule '@nsync//:nsync_cpp' failed (Exit 1): gcc failed: error executing command; (cd /home/pichuan/.cache/bazel/_bazel_pichuan/01047f0bd74be1f8c2eae71c8557726c/execroot/com_google_deepvariant && \; exec env - \; PATH=/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/pichuan/bin \; PWD=/proc/self/cwd \; PYTHON_BIN_PATH=/usr/local/bin/python2.7 \; PYTHON_LIB_PATH=/usr/local/lib/python2.7/site-packages \; TF_NEED_CUDA=0 \; TF_NEED_OPENCL_SYCL=0 \; /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 -MD -MF bazel-out/k8-opt/bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/common.pic.d -fPIC -iquote external/nsync -iquote bazel-out/k8-opt/genfiles/external/nsync -iquote external/bazel_tools -iquote bazel-out/k8-opt/genfiles/external/bazel_tools -isystem external/nsync/public -isystem bazel-out/k8-opt/genfiles/external/nsync/public -isystem external/bazel_tools/tools/cpp/gcc3 -x c++ '-std=c++11' -DNSYNC_ATOMIC_CPP11 -DNSYNC_USE_CPP11_TIMEPOINT -I./external/nsync//platform/c++11 -I./external/nsync//platform/gcc -I./external/nsync//platform/x86_64 -I./external/nsync//public -I./external/nsy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386513685:377,error,error,377,,https://github.com/google/deepvariant/issues/29#issuecomment-386513685,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"ON); details:; '@type': type.googleapis.com/google.genomics.v2alpha1.ContainerStoppedEvent; actionId: 1; exitStatus: 1; stderr: |+; /examples_output.tfrecord@""${SHARDS}"".gz\n --reads ""/input-gcsfused-{}/${BAM}""\n --ref ""${INPUT_REF}""\n --task {}\n --regions gs://canis/CNR-data/CDS-canonical.bed"" # ENABLE_FUSE\n']; Traceback (most recent call last):; File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>; run(); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run; _run_make_examples(pipeline_args); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples; _wait_for_results(threads, results); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results; result.get(); File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get; raise self._value; RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/781565864516461293"" failed: executing pipeline: Execution failed: action 6: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). timestamp: '2018-11-08T14:30:55.372655Z'; - description: Started running ""-c /opt/deepvariant_runner/bin/gcp_deepvariant_runner --project; valis-194104 --zones us-west1-b --docker_image gcr.io/deepvariant-docker/deepvariant:0.7.0 --outfile; gs://canis/CNR-data/TLE_a_001_deep_variant.vcf --staging gs://canis/CNR-data/deep_variant_files --model; gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard --regions; gs://canis/CNR-data/CDS-canonical.bed --bam gs://canis/CNR-data/TLE_a_001.bam --bai; gs://canis/CNR-data/TLE_a_001.bam.bai --ref gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz --ref_fai; gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz.fai --ref_gzi gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz.gzi --gcsfuse""; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.ContainerStartedEvent; actionId: 1; ipAddress:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437055644:5075,error,error,5075,,https://github.com/google/deepvariant/issues/116#issuecomment-437055644,1,['error'],['error']
Availability,"Oh, btw, the warning message in call_variants.py about image height might be confusing.; It is just a warning, so you should still be able to run. But I agree that this is confusing. We'll think about how to make things more robust. . For now, I would still recommend the one-command approach: https://github.com/google/deepvariant/blob/r1.2/docs/deeptrio-quick-start.md#run-deeptrio-with-one-command; which is our current way of making things more robust.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/488#issuecomment-929838628:225,robust,robust,225,,https://github.com/google/deepvariant/issues/488#issuecomment-929838628,2,['robust'],['robust']
Availability,"Oh, sorry I couldn't see that you already had one `--regions` in there.; I believe this one below (taken from your attached logs) should have worked, and it works for me locally, so I'll leave this here and ask my colleagues to weigh in.; ```; ***** Running the command:*****; time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/Homo_sapiens_assembly19.fasta"" --reads ""/input/proper.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""3:178936057-178936106 3:178952054-178952106"" --vsc_min_fraction_snps ""0.004"" --task {}. E0416 22:39:09.366390 140299630700288 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_WCb7xE/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"".; ``",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/305#issuecomment-620732836:703,error,errors,703,,https://github.com/google/deepvariant/issues/305#issuecomment-620732836,2,"['error', 'failure']","['errors', 'failure']"
Availability,"Ok that seems to be working with absolute path (at least it's making the examples right now). Also, the index of the bam was corrupted! it seems that you declare the BAM but then deepvariant goes to the index. Which makes sense of course, but maybe it would be a good idea to say somewhere in the doc to pay attention to the index? Or return an error like ""index not found"" rather than ""bam not found""? and why dry run didn't catch this? . Anyway, thank you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/685#issuecomment-1646862969:345,error,error,345,,https://github.com/google/deepvariant/issues/685#issuecomment-1646862969,1,['error'],['error']
Availability,One possibility make_examples could take long time is if reads are too long. If your reads are greater than 250 there will be a slow down.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/99#issuecomment-428662299:133,down,down,133,,https://github.com/google/deepvariant/issues/99#issuecomment-428662299,1,['down'],['down']
Availability,"One thing I will propose to do is at least to update the Nucleus message to say something more than just ""Not found"", so that even it fails, the error message will be more understandable.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/374#issuecomment-723753324:145,error,error,145,,https://github.com/google/deepvariant/issues/374#issuecomment-723753324,1,['error'],['error']
Availability,"Oo likely my fault! If I am adding the particular region around that variant such as ""chr15:41,132,484-42,007,831"". Do I still have to provide a WES bed file? I have this as my current script and last time it seemed like the bed file was the problem.. ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p htc; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-2; #SBATCH --mem-per-cpu=68GB; #SBATCH --qos=maxjobs500. module purge; module load parallel; module load singularity. EXOME_IDs_FILE=/scratch/c.c21087028/checking_variant_deepvariant/exome_ID_file; HG38_REFERENCE=/scratch/c.c21087028/coverage_graph_and_clincnv_files/ClinCNV/hg38/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna; PICARDMARKDUPLICATES_SORTEDBAM=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_markedduplicates_GCA_000001405.15_GRCh38_no_alt_analysis_set.bam; REGIONS=""chr15:41,132,484-42,007,831""; OUTPUT_VCF=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set_checkingvariantregion.vcf.gz; OUTPUT_GVCF=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set_checkvariantregion.g.vcf.gz; INTERMEDIATE_RESULTS=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$REGIONS \; --make_examples_extra_args=""emit_realigned_reads=true,realigner_diagnostics=/output/realig",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/691#issuecomment-1667692113:13,fault,fault,13,,https://github.com/google/deepvariant/issues/691#issuecomment-1667692113,1,['fault'],['fault']
Availability,Patching it internally and releasing it works great with me. I appreciate y'all considering this and pushing it through on the backend. Thank you for making DeepVariant available and all the helpful support.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/18#issuecomment-353720479:169,avail,available,169,,https://github.com/google/deepvariant/pull/18#issuecomment-353720479,1,['avail'],['available']
Availability,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1656474342:271,repair,repair,271,,https://github.com/google/deepvariant/issues/682#issuecomment-1656474342,4,['repair'],['repair']
Availability,"Peter;; Thanks for following up and glad to hear that this got it installed for you. I've been trying to replicate to fix the issue and avoid the manual pinning but can't seem to do on my system. Perhaps this was a temporary download issue with the google-cloud-sdk package, but it seems okay now. If anyone else stumbles across this same issue we can dig more but hopefully it was just something transient and we're good going forward. Thanks again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/177#issuecomment-487313448:225,down,download,225,,https://github.com/google/deepvariant/issues/177#issuecomment-487313448,1,['down'],['download']
Availability,"Pi-Chuan -- thanks for this. We'd ideally build with CLIF directly in bioconda to avoid you needing to have these custom builds, but will hold off on that until there is an easier to build/install CLIF dependency. Happy to test the new version with reduced glibc requirements when it's ready. Björn -- We do pin to 1.14 now in DeepVariant, with the downside that it's not compatible in a shared environment with other looks that pin to the bioconda 1.12 default. I can work around this for now by having DeepVariant in a separate environment, but would love to synchronize bioconda to 1.14 at some point. Thanks again for all this work and help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-385485505:349,down,downside,349,,https://github.com/google/deepvariant/issues/29#issuecomment-385485505,1,['down'],['downside']
Availability,"Pi-Chuan and Mike;; Thanks for all this background and help. I'm trying to fit this into the conda recipe bazel build for DeepVariant but am not sure how to take advantage of using the local anaconda python in that context. The error I'm seeing is that bazel can't find pyclif_proto:; ```; (17:56:01) INFO: Found 1 target...; (17:56:01) [0 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt; (17:56:01) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'; (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1: //third_party/nucleus/protos:variants_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'; Target //deepvariant:binaries failed to build; (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1 1 input file(s) do not exist; ```; which I thought was triggered by the difficulty running pyclif without having the local python installed. It could also be due to not installing is in `/usr/local/bin` since I have to remain sandboxed in the work directory, but I did adjust the PATH to include the download location. Sorry I'm stuck here due to me limited knowledge of bazel tweaking. Either understanding how to handle a root install of the pre-build pyclif or tweaking to use the local python would be helpful. Alternatively, if you can already build DeepVariant on a CentOS6 system yourself I could use the pre-build binaries the way we're doing now, just with the build against an older glibc. Thanks again for the help with this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386250002:228,error,error,228,,https://github.com/google/deepvariant/issues/29#issuecomment-386250002,5,"['ERROR', 'down', 'error']","['ERROR', 'download', 'error']"
Availability,"Pi-Chuan;; Awesome, thanks so much for the WORKSPACE path tip. That was perfect and exactly solved the clif issue. Nice one. The issue I'm running into now is that the build setup assumes that the libraries and include files are available in standard locations (`/usr`, I'm guessing) and within conda these will be inside the conda environment. So as soon as I compile htslib we get errors about now finding zlib.h, which is present in `$PREFIX/include` instead of `/usr/include`. I've tried hacking this include directory into the htslib copts:; ```; sed -i.bak ""s|\""-Wno-error\"",|\""-Wno-error\"", \""-I${PREFIX}/include\"",|"" third_party/htslib.BUILD; ```; but bazel is too smart and won't let us continue with non-bazel defined references:; ```; (00:28:31) ERROR: /home/conda/.cache/bazel/_bazel_conda/b3bf6b0de2935c6a10ef1e7d7b61873f/external/htslib/BUILD.bazel:209:1: in cc_library rule @htslib//:htslib: The include path '/opt/conda/conda-bld/deepvariant_1525566343740/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_p/include' references a path outside of the execution root.; ```; So at this point I'm stuck by my lack of knowledge of how to incorporate this into the bazel build instructions. I couldn't find any conda bazel builds that already do this as a template and am not familiar enough with it to build up on my own. Would it be possible to make the dependencies you're installing with apt as explicit bazel targets like clif? If so, then I could adjust paths to the conda `$PREFIX` rather than `/usr`. What do you think about that approach? Other bazel tips/tricks would be very welcome. Thanks again for helping with this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386869866:229,avail,available,229,,https://github.com/google/deepvariant/issues/29#issuecomment-386869866,5,"['ERROR', 'avail', 'error']","['ERROR', 'available', 'error', 'errors']"
Availability,"Pi-Chuan;; Thanks for this update and work. For bazel, we'd gotten that updated and building on conda with CentOS 6 so are good to go with that dependency, it's really just CLIF that we're struggling with for building. For clif, this is great progress, thank you. I resuscitated my bioconda build script and gave it a try with this. It's making better progress but unfortunately needs to reconstitute the system wide python install within the build environment which we can't do in conda. Everything there is in an isolated work directory so won't have the system shared libraries it wants:; ```; $ /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/usr/local/clif/bin/python; /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/usr/local/clif/bin/python: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory; ```; and the python libraries included symlink to the system wide ones you built against:; ```; lrwxrwxrwx 1 conda conda 56 May 2 17:54 _weakrefset.py -> /opt/rh/python27/root/usr/lib64/python2.7/_weakrefset.py; ```; I'm not sure if it's possible to make this more relocatable with any python as part of the build process. Sorry, I know it's a lot more work to make it relocatable like this but will allow install on all the systems we support where users don't have root privileges to rely on system libraries. Thanks again for helping with this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386074270:793,error,error,793,,https://github.com/google/deepvariant/issues/29#issuecomment-386074270,1,['error'],['error']
Availability,"Pichuan, to increase the ease use and expand adoption within the Bioinformatics community it might not hurt to have a collection of customized build-and-test environments at Google that match a variety of environment configurations that users have in place, or that common packages recommend out here. Sometimes folks will be curious to try out some new Bioinformatics software package, and the faster they get it to a running state on their own machines, the happier the experience enabling the community for that package to grow faster. Basically most people just want to use stuff - and want a turn-key solution - though some of us like tinkering with puzzles :) If their experience is good on something local - or even a cluster - then they'll see the obvious need to try it out on a Cloud environment. I sort of did it from the other side. Many times when I tested most of the GoogleGenomics tools, I would try them out in some real-world scenarios, I usually ran them against a variety of configurations. That helped with having better error messages, control flow decisions, documentation or additional features. Basically you have developed a great software - which is evolving - and now comes the service component of supporting it, which is just as important. Just a friendly recommendation,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-385874525:1042,error,error,1042,,https://github.com/google/deepvariant/issues/29#issuecomment-385874525,1,['error'],['error']
Availability,"Please provide more details on the issue (commands run, the error you saw, etc.) You can start with the [quickstart doc](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) or one of the case studies (linked on the top-level page) to better understand how to install and run DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/169#issuecomment-481854459:60,error,error,60,,https://github.com/google/deepvariant/issues/169#issuecomment-481854459,1,['error'],['error']
Availability,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/81#issuecomment-409913088:158,error,error,158,,https://github.com/google/deepvariant/issues/81#issuecomment-409913088,1,['error'],['error']
Availability,"Precision of IR: FP32; - Enable fusing: True; - Enable grouped convolutions fusing: True; - Move mean values to preprocess section: False; - Reverse input channels: False; TensorFlow specific parameters:; - Input model in text protobuf format: False; - Path to model dump for TensorBoard: None; - List of shared libraries with TensorFlow custom layers implementation: None; - Update the configuration file with input/output node names: None; - Use configuration file used to generate the model with Object Detection API: None; - Use the config file: None; Model Optimizer version:. [ SUCCESS ] Generated IR version 10 model.; [ SUCCESS ] XML file: /home/pichuan/./model.xml; [ SUCCESS ] BIN file: /home/pichuan/./model.bin; [ SUCCESS ] Total execution time: 24.29 seconds.; [ SUCCESS ] Memory consumed: 761 MB.; It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/en-us/openvino-toolkit/choose-download?cid=&source=upgrade&content=2020_3_LTS or on the GitHub*; WARNING:tensorflow:From /tmp/Bazel.runfiles_wz_ompqi/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.; ...; ```; After this, the call_variants steps started running with no issues:; ```; ...; I0116 03:14:04.107081 140161826506496 openvino_estimator.py:118] Using OpenVINO in call_variants.; I0116 03:14:04.367440 140161826506496 openvino_estimator.py:155] Processed 1 examples in call_variants (using OpenVINO); I0116 03:14:23.278933 140161826506496 openvino_estimator.py:155] Processed 15001 examples in call_variants (using OpenVINO); I0116 03:14:42.118756 140161826506496 openvino_estimator.py:155] Processed 30001 examples in call_variants (using OpenVINO); I0116 03:15:00.622359 140161826506496 openvino_estimator.py:155] Processed 45001 examples in call_variants (using OpenVINO); ...; ```; My run complete",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-761309014:4302,down,download,4302,,https://github.com/google/deepvariant/issues/404#issuecomment-761309014,1,['down'],['download']
Availability,"Probably the quickest way would be to process each sample individually and then combine them together, by first creating [gVCF outputs](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-gvcf-support.md) and then merging them using [GLnexus](https://github.com/dnanexus-rnd/GLnexus). A nice tutorial on how to do this is available at the following link:. https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/651#issuecomment-1575314566:335,avail,available,335,,https://github.com/google/deepvariant/issues/651#issuecomment-1575314566,1,['avail'],['available']
Availability,"Pulling both the cpu/gpu versions works but I get an error when trying to run:. ```; [moldach@cdr767 bin]$ singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; > docker://google/deepvariant:""${BIN_VERSION}"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \ **Replace this string with exactly one of the following [WGS,WES,PACBIO]**; FATAL: Unable to handle docker://google/deepvariant: uri: failed to get SHA of docker://google/deepvariant:: unable to parse image name docker://google/deepvariant:: invalid reference format; [moldach@cdr767 bin]$ --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; > --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; > --regions ""chr20:10,000,000-10,010,000"" \; > --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; > --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; > --num_shards=1; bash: --ref=/ucsc.hg19.chr20.unittest.fasta: No such file or directory; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-604736676:53,error,error,53,,https://github.com/google/deepvariant/issues/287#issuecomment-604736676,1,['error'],['error']
Availability,"Ran it again, and still hitting failures:; ```; done: true; error:; code: 9; message: 'Execution failed: action 1: unexpected exit status 1 was not ignored'; metadata:; '@type': type.googleapis.com/google.genomics.v2alpha1.Metadata; createTime: '2018-11-08T14:27:06.016940Z'; endTime: '2018-11-08T14:30:59.324697Z'; events:; - description: Worker released; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.WorkerReleasedEvent; instance: google-pipelines-worker-4b16fd95b691baddc54b0c5ec50dc6c7; zone: us-west1-b; timestamp: '2018-11-08T14:30:59.324697Z'; - description: 'Execution failed: action 1: unexpected exit status 1 was not ignored'; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.FailedEvent; cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored'; code: FAILED_PRECONDITION; timestamp: '2018-11-08T14:30:58.518326Z'; - description: Stopped running ""/bin/sh -c gsutil -q cp /google/logs/output gs://canis/CNR-data/deep_variant_files/runner_logs_20181108_082705.log""; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.ContainerStoppedEvent; actionId: 2; exitStatus: 0; stderr: ''; timestamp: '2018-11-08T14:30:58.416239Z'; - description: Started running ""/bin/sh -c gsutil -q cp /google/logs/output gs://canis/CNR-data/deep_variant_files/runner_logs_20181108_082705.log""; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.ContainerStartedEvent; actionId: 2; ipAddress: ''; portMappings: {}; timestamp: '2018-11-08T14:30:55.929647Z'; - description: Unexpected exit status 1 while running ""-c /opt/deepvariant_runner/bin/gcp_deepvariant_runner --project; valis-194104 --zones us-west1-b --docker_image gcr.io/deepvariant-docker/deepvariant:0.7.0 --outfile; gs://canis/CNR-data/TLE_a_001_deep_variant.vcf --staging gs://canis/CNR-data/deep_variant_files --model; gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard --regions; gs://canis/CNR-data/CDS-canonical.bed --bam gs:/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437055644:32,failure,failures,32,,https://github.com/google/deepvariant/issues/116#issuecomment-437055644,2,"['error', 'failure']","['error', 'failures']"
Availability,"Regarding loading the checkpoint, it worked for me. I wonder if the issue is because of the gotcha of the filenames. The --checkpoint argument to call_variants is actually supposed to be the model prefix name, not an actual file name. For example I just tried . `( time python bin/call_variants.zip --outfile ""${CALL_VARIANTS_OUTPUT}"" --examples ~/case-study/output/HG002.examples.tfrecord-00004-of-00008.gz --checkpoint /tmp/deepvariant/model.ckpt-726 --batch_size 32; ) >""${LOG_DIR}/call_variants.log"" 2>&1`. and it ran as expected. Let me know if that works for you. Another thing to keep in mind is that if you run model_train again without specifying the 'train_dir' arg then it will attempt to pick up where it left off.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/46#issuecomment-364545868:22,checkpoint,checkpoint,22,,https://github.com/google/deepvariant/issues/46#issuecomment-364545868,3,['checkpoint'],['checkpoint']
Availability,"Regarding the pretrained inception model: I was able to find an example that was pretrained on ImageNet classes (it is likely the same or at least very similar to the file that is mentioned in the code): https://github.com/tensorflow/models/tree/master/research/slim [about halfway down that page at Pre-Trained Models]. On the Cloud instance I download and unpack the checkpoint:; wget http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz; tar -xzvf inception_v3_2016_08_28.tar.gz. then in the training command you can add; "" --start_from_checkpoint inception_v3.ckpt"". After the tf_logging messages you'll see. model_train.py:160] Initializing model from checkpoint at inception_v3.ckpt; modeling.py:314] Checkpoint was trained against 1001 classes while our dataset is using 3, enabling fine-tuning. to let you know that it loaded the pre-trained network. I'll look into your checkpoint loading issue next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/46#issuecomment-364533837:282,down,down,282,,https://github.com/google/deepvariant/issues/46#issuecomment-364533837,7,"['Checkpoint', 'checkpoint', 'down']","['Checkpoint', 'checkpoint', 'down', 'download']"
Availability,"Reinitialized existing Git repository in /root/clif/.git/; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/737#issuecomment-1818093820:3452,Error,Error,3452,,https://github.com/google/deepvariant/issues/737#issuecomment-1818093820,1,['Error'],['Error']
Availability,Removing the conda environment gives me the same error.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/514#issuecomment-1035209001:49,error,error,49,,https://github.com/google/deepvariant/issues/514#issuecomment-1035209001,1,['error'],['error']
Availability,"Right, but which version of the Cuda Toolkit do you have? You can easily install the 9.0 from the link below, but I would do it as a local (non-sudo) user so you sandbox the changes to your environment in order to easily remove them later, if necessary:. https://developer.nvidia.com/cuda-90-download-archive. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/102#issuecomment-429154858:292,down,download-archive,292,,https://github.com/google/deepvariant/issues/102#issuecomment-429154858,1,['down'],['download-archive']
Availability,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/; https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-453800484:105,echo,echo,105,,https://github.com/google/deepvariant/issues/137#issuecomment-453800484,2,['echo'],['echo']
Availability,"Running with -v, everything looks normal except 2 error messages:. 1st error message:; ==============; ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===; prefix=/mnt/home/mansourt/miniconda3/envs/deepVar; source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully; python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7; py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py; pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc; compile rc: 1; compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ...; File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102; def keyworded(*arg1, arg2=1):; ^; SyntaxError: invalid syntax. compile stderr:. 2nd error message:; ==============; $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh; ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==; ==> exit code: 1 <==; ==> stdout <==; b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'; ==> stderr <==; b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-451711664:50,error,error,50,,https://github.com/google/deepvariant/issues/137#issuecomment-451711664,3,['error'],['error']
Availability,"Samtools use this approach to pass the reference needed for reading the cram file. Pysam uses a similar approach. . **The REF_PATH and REF_CACHE**; One of the key concepts in CRAM is that it is uses reference based compression. This means that Samtools needs the reference genome sequence in order to decode a CRAM file. Samtools uses the MD5 sum of the each reference sequence as the key to link a CRAM file to the reference genome used to generate it. By default Samtools checks the reference MD5 sums (@SQ “M5” auxiliary tag) in the directory pointed to by $REF_PATH environment variable (if it exists), falling back to querying the European Bioinformatics Institute (EBI) reference genome server, and further falling back to the @SQ “UR” field if these are not found. While the EBI have an MD5 reference server for downloading reference sequences over http, we recommend use of a local MD5 cache. We have provided with Samtools a basic script (misc/seq_cache_populate.pl) to convert your local yeast.fasta to a directory tree of reference sequence MD5 sums:. <samtools_src_dir>/misc/seq_cache_populate.pl -root /some_dir/cache yeast.fasta; export REF_PATH=/some_dir/cache/%2s/%2s/%s:http://www.ebi.ac.uk/ena/cram/md5/%s; export REF_CACHE=/some_dir/cache/%2s/%2s/%s; REF_PATH is a colon separated list of directories in which to search for files named after the sequence M5 field. The : in http:// is not considered to be a separator. Hence using the above setting, any CRAM files that are not cached locally may still be looked up remotely. In this example “%2s/%2s/%s” means the first two digits of the M5 field followed by slash, the next two digits and slash, and then the remaining 28 digits. This helps to avoid one large directory with thousands of files in it. The REF_CACHE environment variable is used to indicate that any downloaded reference sequences should be stored locally in this directory in order to avoid subsequent downloads. This should normally be set to the same location as",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/38#issuecomment-372143466:819,down,downloading,819,,https://github.com/google/deepvariant/issues/38#issuecomment-372143466,1,['down'],['downloading']
Availability,Second error (num_shards) has been resolved,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/309#issuecomment-631261750:7,error,error,7,,https://github.com/google/deepvariant/issues/309#issuecomment-631261750,1,['error'],['error']
Availability,"See: https://github.com/google/deepvariant/blob/r0.4/README.md#availability; ""Pre-built binaries are available at [gs://deepvariant/](https://console.cloud.google.com/storage/browser/deepvariant)""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/8#issuecomment-350520082:63,avail,availability,63,,https://github.com/google/deepvariant/issues/8#issuecomment-350520082,2,['avail'],"['availability', 'available']"
Availability,"Since DeepVariant isn't trained on this data, it will depend on how different this new datatype is from our existing training data. For the training data we used, you can see: https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-details-training-data.md. DeepVariant is known to be robust even on certain new data types. For example, when DNAnexus published this blog post, DeepVariant wasn't trained on NovaSeq, and yet DeepVariant performed well on NovaSeq data:; https://blog.dnanexus.com/2018-01-16-evaluating-the-performance-of-ngs-pipelines-on-noisy-wgs-data/. However, we also know that DeepVariant can be significantly more accurate if it has a chance to see the data in its training set. (For example, see: https://ai.googleblog.com/2018/04/deepvariant-accuracy-improvements-for.html). If you'd like to give it a try and let us know, that will be great, especially if you compare it to other baselines. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/107#issuecomment-430072409:294,robust,robust,294,,https://github.com/google/deepvariant/issues/107#issuecomment-430072409,1,['robust'],['robust']
Availability,"Since you already have 200X coverage of WGS data, the best quality variant calls would probably come from just taking the WGS data and running with that alone with `--model_type=WGS`. This is because the pileup images only fit up to 95 reads for each variant, so the 200X will already be downsampled during runtime to fit. The WES data will have some inherent biases due to the target enrichment process, so combining the datasets would carry its own potential issues. Luckily you don't need that since you have plenty of WGS data. Also I just want to check that you are only doing germline variant calling, since in my experience people with high coverage are often looking for low-frequency variants. DeepVariant is built and trained for germline variant calling only, and it can only report heterozygous, homozygous reference, and homozygous alternate genotypes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/338#issuecomment-679221703:288,down,downsampled,288,,https://github.com/google/deepvariant/issues/338#issuecomment-679221703,1,['down'],['downsampled']
Availability,"Singularity:; > https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity; >; > If you don't have root permission, you won't be able to install necessary; > things before running the binaries either.; > ------------------------------; >; > Here is what I did:; >; > Get a machine. (Not required to run on GCP. I just use this to get a; > machine to test); >; > gcloud compute instances create ""${USER}-cpu"" --scopes; > ""compute-rw,storage-full,cloud-platform"" --image-family ""ubuntu-2004-lts""; > --image-project ""ubuntu-os-cloud"" --machine-type ""custom-64-131072""; > --boot-disk-size ""300"" --zone ""us-west2-b"" --min-cpu-platform ""Intel; > Skylake""; >; > ssh into the machine:; >; > gcloud compute ssh pichuan-cpu --zone us-west2-b; >; > Get the binaries and models:; >; > BUCKET=""gs://deepvariant""; > BIN_VERSION=""1.4.0""; > MODEL_VERSION=""1.4.0""; >; > BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}""; > MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard""; >; > mkdir -p bin; > # Download the DeepVariant binaries.; > gsutil -m cp ""${BIN_BUCKET}/*"" bin/; > chmod a+x bin/*; >; > Then, I ran:; >; > cd bin; bash run-prereq.sh; cd -; >; > The run-prereq.sh tends to be the most tricky one - it will require root; > permission, and it'll install a bunch of stuff on your machine. If you; > can't use Docker because of root permissions, you likely won't be able to; > run this as well.; >; > Download test data:; >; > INPUT_DIR=""${PWD}/quickstart-testdata""; > DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; >; > mkdir -p ${INPUT_DIR}; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; > wget -P ${INPUT",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566:1267,Down,Download,1267,,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566,1,['Down'],['Download']
Availability,"So from what I see you've completed the following steps:. 1) Built and installed CLIF; 2) Installed Bazel; 3) Installed the Tensorflow Python Module; 4) Downloaded and configured Tensorflow from GitHub (we might need to checkout the proper version). The final step is to build the DeepVariant binaries. Just a note, you will require several GB of space for this to work. The DeepVariant zip files we eventually get will be quite small. (The zip files are basically Python scripts and bytecode with a compiled shared library.). Regarding what's missing or incompatible during the build, we will let the compiler tell us that, which will make it a bit easier to troubleshoot. Just to be sure we minimize surprises, we will do a couple of things first. To ensure the TensorFlow code we will compile against is of the same version as the TensorFlow python package (2.11.0), run the following in your `git clone` TensorFlow folder (the assumption is that your TensorFlow folder is outside your DeepVariant one):. ```; # Assuming you are in the DeepVariant directory. cd ../tensorflow; git checkout origin/r2.11 -f. # Here configure like before with the defaults; ./configure. cd ../deepvariant; ```. Once in the DeepVariant directory, perform each of these separately so we can isolate any issues:. ```; #!/bin/bash; source settings.sh. wget https://raw.githubusercontent.com/google/deepvariant/r1.5/.bazelrc. bazel build -c opt ${DV_COPT_FLAGS} --build_python_zip :binaries; ```. You may notice that we removed `.bazelrc` previously, that was so that we can ensure while we troubleshoot the `bazel` installation nothing gets triggered by the `.bazelrc` config. The last two things you have to run to complete the DeepVariant build are the following, though the above should give most of what you need:. ```; #!/bin/bash; source settings.sh. bazel build -c opt ${DV_COPT_FLAGS} --build_python_zip //deepvariant/labeler:labeled_examples_to_vcf; ```. ```; #!/bin/bash; source settings.sh. bazel build -c opt ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1581784104:153,Down,Downloaded,153,,https://github.com/google/deepvariant/issues/657#issuecomment-1581784104,1,['Down'],['Downloaded']
Availability,"So we were unable to reproduce this specific error. Regardless, we are overhauling how multiprocessing is used in `postprocess_variants` with our next release, which will very likely avoid this type of error. I am closing this issue for now. If someone is experiencing this issue and would like an experimental docker container to run, please comment on this issue and we will provide one!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/804#issuecomment-2113514063:45,error,error,45,,https://github.com/google/deepvariant/issues/804#issuecomment-2113514063,2,['error'],['error']
Availability,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/673#issuecomment-1625679434:420,error,error,420,,https://github.com/google/deepvariant/issues/673#issuecomment-1625679434,1,['error'],['error']
Availability,"Solve the problem --> the pipeline of using deeptrio bcftools cause error. Installing bcftools and using the following script works... I hope this help to improve the pipelining. ```; docker run \; -v ""${PWD}/output"":""/output"" \; quay.io/mlin/glnexus:v1.2.7 \; /usr/local/bin/glnexus_cli \; --config DeepVariant_unfiltered \; /output/HG002.g.vcf.gz \; /output/HG003.g.vcf.gz \; /output/HG004.g.vcf.gz \; | bcftools view -Oz -o ${PWD}/output/HG002_trio_merged.vcf.gz ; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/632#issuecomment-1512478424:68,error,error,68,,https://github.com/google/deepvariant/issues/632#issuecomment-1512478424,1,['error'],['error']
Availability,Solving the first error (libcublas.so.12) by creating a sandbox with singularity and adding the location of libcublas.so.12 to the env. I guess creating a soft link with ln -s would also work.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/722#issuecomment-1780922055:18,error,error,18,,https://github.com/google/deepvariant/issues/722#issuecomment-1780922055,1,['error'],['error']
Availability,"Some other things to look in to:. * Is what you have pasted above the full stack trace? If there's any other output, it would be helpful to see that as well.; * Could you try running `make_examples` directly using the below command? This is only using one shard. If this command fails, we may see a more informative error message. ```; sudo docker run \; -v ""/root/quickstart-testdata"":""/input"" \; -v ""/root/quickstart-output"":""/output"" \; google/deepvariant:latest \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" \; --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" \; --examples ""/output/make_examples.tfrecord@1.gz"" \; --gvcf ""/output/gvcf.tfrecord@1.gz"" \; --regions ""chr20:10,000,000-10,010,000""; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/325#issuecomment-659076993:316,error,error,316,,https://github.com/google/deepvariant/issues/325#issuecomment-659076993,1,['error'],['error']
Availability,Sorry about the install issues. The `post-link.sh` script that is failing downloads the trained models that DeepVariant uses from Google Buckets:. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/post-link.sh. Failures here are typically due to problems with gsutil picking up other configuration options on your system. This thread has a bunch of debugging and some suggestions to try to work around the gsutil problem:. https://github.com/bcbio/bcbio-nextgen/issues/2613. If you can try the tips there and let us know more details of the failures if you get stuck happy to help with specific suggestions. Hope this gets deepvariant installed for you.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/177#issuecomment-504940567:74,down,downloads,74,,https://github.com/google/deepvariant/issues/177#issuecomment-504940567,3,"['Failure', 'down', 'failure']","['Failures', 'downloads', 'failures']"
Availability,"Sorry for my late reply! To be honest, I believe I went with the [quick start](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md) and replaced the test data with my own. Then I started to debug on that ValueError, believing that was a potential bug (because of the error saying I was using `--make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`, while I was actually not; I put that first argument to false, not true).; I don't believe there is something wrong with your user flow! Your github is really nice and the docker and dependencies were very easily installed. I wouldn't want to comment more on that without extensively trying your tool, so maybe I can provide with proper feedback later :) I will definitely let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/457#issuecomment-844185505:295,error,error,295,,https://github.com/google/deepvariant/issues/457#issuecomment-844185505,2,['error'],['error']
Availability,"Sorry for my wrong posting of error messages.; I have tried different versions of deepvariant in conda, and messed up the conda environment. ; Actually I posted the deepvarint (1.3.0) error messages. : <(. Here is my attempts on the deepvariant 1.4.0: ; `; $ conda create -n deepvar python=3.7.5; $ conda install -c bioconda deepvariant=1.4.0; $ conda activate deepvar; $ dv_call_variants.py -h . `; And I got the similar error messages:. Baseline DeepVariant arguments; File ""/tmp/Bazel.runfiles_j_t9fnwc/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374; raise ValueError(f'Shape mismatch in {example_info_json} and '; ^; SyntaxError: invalid syntax. Wrapper arguments; usage: dv_call_variants.py [--cores CORES] --outfile OUTFILE --examples; EXAMPLES --sample SAMPLE; [--model {hybrid,pacbio,wes,wgs}] [-h]. DeepVariant call_variants wrapper. optional arguments:; --cores CORES; --outfile OUTFILE; --examples EXAMPLES Example directory from make_examples; --sample SAMPLE Sample name; --model {hybrid,pacbio,wes,wgs}; DeepVariant trained model to use, defaults to wgs; -h, --help; usage: dv_call_variants.py [--cores CORES] --outfile OUTFILE --examples; EXAMPLES --sample SAMPLE; [--model {hybrid,pacbio,wes,wgs}] [-h]; dv_call_variants.py: error: the following arguments are required: --outfile, --examples, --sample",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/627#issuecomment-1514340725:30,error,error,30,,https://github.com/google/deepvariant/issues/627#issuecomment-1514340725,4,['error'],['error']
Availability,"Sorry for the late replay. Unfortunately, it did not work. The error message says:; ERROR : Unknown image format/type: deepvariant.0.8.0.simg; ABORT : Retval = 255",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/178#issuecomment-499709284:63,error,error,63,,https://github.com/google/deepvariant/issues/178#issuecomment-499709284,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Sorry, @akolesnikov pointed out that you tried both.; I don't have an immediate answer to the second error then.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1140073910:101,error,error,101,,https://github.com/google/deepvariant/issues/537#issuecomment-1140073910,1,['error'],['error']
Availability,"Sorry, i used model_train.zip really, just pasted the incorrect command to issue. ; This is my correct command:; ```; python /leostore/software/deepvariant/bazel-bin/deepvariant/model_train.zip --dataset_config_pbtxt ""/leostore/analysis/development/liteng/deepvariant_test/test_train.config.txt"" --start_from_checkpoint inception_v3.ckpt; ```; The inception_v3.ckpt is downloaded from https://github.com/tensorflow/models/tree/master/research/slim#Data ; This is my config file:; ```; name: ""test-training-dataset""; tfrecord_path: ""/leostore/analysis/development/liteng/deepvariant_test/train_set/test_train.tfrecord.gz""; num_examples: 1; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/10#issuecomment-350909874:369,down,downloaded,369,,https://github.com/google/deepvariant/issues/10#issuecomment-350909874,1,['down'],['downloaded']
Availability,"Sounds good!; Yes, we still call it a pileup ""image"", it is just in the form of a TensorFlow tensor with 6 channels instead of an RGB image, which was limited to 3 color channels plus opacity. The downsampling to 95x is still applied and has been in all versions of DeepVariant. This blog post gives more detail on how the pileup images are structured: https://google.github.io/deepvariant/posts/2020-02-20-looking-through-deepvariants-eyes/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/338#issuecomment-680960164:197,down,downsampling,197,,https://github.com/google/deepvariant/issues/338#issuecomment-680960164,1,['down'],['downsampling']
Availability,Still yields a core dump with no error message. Going to test this on docker.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/419#issuecomment-774282552:33,error,error,33,,https://github.com/google/deepvariant/issues/419#issuecomment-774282552,1,['error'],['error']
Availability,"Sure thing! You can send me the files at lucasbrambrink@google.com. Additionally, Seg faults can sometimes happen from OOMs (running out of memory). Do you have the memory specs of the instance you are running this on? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/794#issuecomment-2021094547:86,fault,faults,86,,https://github.com/google/deepvariant/issues/794#issuecomment-2021094547,1,['fault'],['faults']
Availability,"Sure! You can find the checkpoints for each sequencing technology at `gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/`. For example, the model for Illumina data can be found at `gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt`. These models are mounted in our [Dockerfile](https://github.com/google/deepvariant/blob/r1.6.1/Dockerfile#L156-L200). Take a look at our [custom training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#advanced-case-study-train-a-customized-snp-and-small-indel-variant-caller-for-bgiseq-500-data) if you want to learn more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/801#issuecomment-2040306496:23,checkpoint,checkpoints,23,,https://github.com/google/deepvariant/issues/801#issuecomment-2040306496,6,['checkpoint'],['checkpoints']
Availability,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution?. This is what I see in the local docker container's models directory when running the image:; ```bash; root@8368b35e9c34:/# ls /opt/models/wgs/; model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta; ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1136578198:449,error,error,449,,https://github.com/google/deepvariant/issues/537#issuecomment-1136578198,1,['error'],['error']
Availability,"TPUT_VCF=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set_checkingvariantregion.vcf.gz; OUTPUT_GVCF=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set_checkvariantregion.g.vcf.gz; INTERMEDIATE_RESULTS=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$REGIONS \; --make_examples_extra_args=""emit_realigned_reads=true,realigner_diagnostics=/output/realigned_reads"" \; --output_vcf=$OUTPUT_VCF \; --output_gvcf=$OUTPUT_GVCF \; --intermediate_results_dir=$INTERMEDIATE_RESULTS""; ```. with the error: . ```; ***** Intermediate results will be written to /scratch/c.c21087028/checking_variant_deepvariant/E036-H-013_TAAGGCGA-ACTGCATA_L007_PE_output_intermediate in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/c.c21087028/coverage_graph_and_clincnv_files/ClinCNV/hg38/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/scratch/c.c21087028/checking_variant_deepvariant/E036-H-013_TAAGGCGA-ACTGCATA_L007_PE_markedduplicates_GCA_000001405.15_GRCh38_no_alt_analysis_set.bam"" --examples ""/scratch/c.c21087028/checking_variant_deepvariant/E036-H-013_TAAGGCGA-ACTGCATA_L007_PE_output_intermediate/make_examples.tfrecord@1.gz"" --emit_realigned_reads --gvcf ""/scratch/c.c21087028/checking_variant_deepvariant/E036-H-013_TAAGGCGA-ACTGCATA_L007_PE_output_intermediate/gvcf.tfrecord@1.gz"" --realigner_diagnostics ""/output/realigned_reads"" --regions ""chr15:41,132,484-42,007,831"" -",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/691#issuecomment-1667692113:2138,error,error,2138,,https://github.com/google/deepvariant/issues/691#issuecomment-1667692113,1,['error'],['error']
Availability,"TTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; >; > Run make_examples:; >; > OUTPUT_DIR=""${PWD}/quickstart-output""; > mkdir -p ""${OUTPUT_DIR}""; >; > python bin/make_examples.zip \; > --mode calling \; > --ref ""${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta"" \; > --reads ""${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam"" \; > --regions ""chr20:10,000,000-10,010,000"" \; > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"" \; > --channels ""insert_size""; >; > (To figure out which flags you need to add for each model, you can read; > https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L253; > . Sorry that we don't have better documentation than that right now); >; > For how to run this with multiple shards, and how to run the rest of the; > commands, please read; > https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md; >; > I just tested the steps above and confirmed that it worked for me on; > v1.4.0, at least for the make_examples step.; > If you encounter more issues with other steps, please feel free to ask; > again. I'd be happy to help.; >; > Note that I don't plan to put this into an official documentation page; > now, because that adds to our maintenance burden to keep it up to date.; > Given that we have the Docker/Singularity solution that works generally; > well for our users, I don't expect many of our users to need to use; > pre-built binaries. @zivlang <https://github.com/zivlang> thank you for; > your question so I have a chance to test it again and document it here.; > Hopefully this is helpful for you. Happy to answer more questions if you; > encounter more problems.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/590#issuecomment-1322695241>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALBF75YWC2I4SZFXBKRL4KTWJPVBNANCNFSM6AAAAAASFZYTTI>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566:3809,mainten,maintenance,3809,,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566,1,['mainten'],['maintenance']
Availability,"T_2021; Cuda compilation tools, release 11.3, V11.3.58; Build cuda_11.3.r11.3/compiler.29745058_0; ```. Try this again:; ```; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}-gpu"" python -c 'import tensorflow as tf;print(tf.test.is_gpu_available())'; ```; Still false -- didn't seem to help:. ```; 2023-03-16 07:01:52.583106: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; 2023-03-16 07:01:52.583190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: pichuan-gpu2; 2023-03-16 07:01:52.583209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: pichuan-gpu2; 2023-03-16 07:01:52.583304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; 2023-03-16 07:01:52.583352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1; False; ```. I tried one more thing, which is rebooting after installing nvidia-modprobe. I did:; ```; gcloud compute instances reset --zone us-west1-b pichuan-gpu2; ```. and then ssh back to the machine. ```; BIN_VERSION=1.5.0; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}-gpu"" python -c 'import tensorflow as tf;print(tf.test.is_gpu_available())'; ```. Oh wow, that actually worked. --> it returns True. Although, now I'm seeing @pgrosu 's comment above, and started wondering if it could be that restarting means I reset $LD_LIBRARY_PATH (because now it's empty , and the command above still worked). So, my new hypothesis that ""nvidia-modprobe helped"" might not be true. Need to test with clean setup again :). But at least something works now! I just don't exactly know what helped yet :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471426355:2033,reboot,rebooting,2033,,https://github.com/google/deepvariant/issues/619#issuecomment-1471426355,1,['reboot'],['rebooting']
Availability,"Thank a lot for your answer. Now the are public for real!. Luisa. 2018-03-07 16:53 GMT+01:00 Mark DePristo <notifications@github.com>:. > Thanks Luisa! It seems those s3 files aren't public:; >; > wget http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > --2018-03-07 07:28:01-- http://dv-testfiles.s3.; > amazonaws.com/ENCFF528VXT.bam; > Resolving dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)...; > 52.218.52.113; > Connecting to dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)|52.218.52.113|:80...; > connected.; > HTTP request sent, awaiting response... 403 Forbidden; > 2018-03-07 07:28:01 ERROR 403: Forbidden.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/52#issuecomment-371184018>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AWD1QUPeGVGaxtvJH4LH2Ygb1cSQEtjlks5tcAKUgaJpZM4SejU_>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371186430:628,ERROR,ERROR,628,,https://github.com/google/deepvariant/issues/52#issuecomment-371186430,1,['ERROR'],['ERROR']
Availability,"Thank a lot for your reply. The 'single quotes encased by double quotes' works for this case, but when I added more regions, it couldn't give me an available output and showed an exit status 247.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/305#issuecomment-620845064:148,avail,available,148,,https://github.com/google/deepvariant/issues/305#issuecomment-620845064,1,['avail'],['available']
Availability,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue?; Thank you in advance,; Best,; ```; File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>; import numpy as np; ImportError: No module named numpy; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/104#issuecomment-438484727:69,error,error,69,,https://github.com/google/deepvariant/issues/104#issuecomment-438484727,1,['error'],['error']
Availability,"Thank you @AndrewCarroll and @pichuan for the clarification. The calibration makes sense, and could be intriguing for inspecting DNN-resiliency. Having the same underlying Inception V3 network architecture for both PacBio and WGS, a point of natural comparability would be the logits kernel across all three genotypes:. ![image](https://github.com/pgrosu/test/assets/6555937/e8ebb437-0132-474e-9ada-c64256aeb791). ![image](https://github.com/pgrosu/test/assets/6555937/f1f478fa-8ffc-4a9a-b5de-4f123658750d). ![image](https://github.com/pgrosu/test/assets/6555937/eb14b3e0-3424-4dc5-82b3-c77091c871a2). Given visual similarity, these were confirmed via Euclidean distance (0.9931127, 0.8543731 and 1.052052, respectively). This indicates the feature set might exhibit strong similarity for interpretation. . Looking at one network (PacBio), it might be possible to confirm calibration by testing for network-resiliency. Via perturbation analysis it should be possible to get insight into a channel's response under perturbation, and their binary interactions under such conditions. Keeping the variant unchanged within a window on each side for preserving the call, the inspection each channel vulnerability response to perturbation can be tested. This resulted in the following perturbation response ($`c\_*`$ denotes a channel, and $`i\_*\_*`$ represents a binary interaction between two channels):. ![image](https://github.com/pgrosu/test/assets/6555937/97c6b13e-e80b-48ae-939d-2367e7ab65c1). The above can be mapped into a network of interactions among the channels:. ![image](https://github.com/pgrosu/test/assets/6555937/cc0e1e2a-278f-4178-a124-67b0321bba3e). Based on the above mapping, by testing well-interacting channels through a probabilistically value-update -- within DeepVariant-acceptable values -- it might be possible to check for shifts in genotype mimicking Mendelian violation. Selecting `base_quality` and staying within DeepVariant's minimum acceptable value, random sampling wit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1619352040:133,resilien,resiliency,133,,https://github.com/google/deepvariant/issues/666#issuecomment-1619352040,2,['resilien'],['resiliency']
Availability,"Thank you @AndrewCarroll. If the read is treated as a minimal [first-class object](https://en.wikipedia.org/wiki/First-class_citizen) (just a simple map/dictionary) would suffice, then you should be able to perform realignment after mapping. This way, it can become reactive without slowing down the analysis. Basically the information would not reside in a file, but rather encapsulated in the read itself. @PengJia6 The thing is that DeepVariant is position-focused at a specific base. That is how `make_examples` generates the variants from the allele counter for a region of a sample, which gets updated every time a new read is added to it. For instance, if you explore the allele counts, you'll get something like this for the different positions (the output is 0-based, and used the 1-based to identify each one):. ##### For Position: 89013075:. ```; position {; reference_name: ""chr10""; position: 89013074; }; ref_base: ""T""; ref_supporting_read_count: 35; read_alleles {; key: ""m64154_210327_091530/103023686/ccs/0""; value {; bases: ""TC""; type: INSERTION; count: 1; }; }; read_alleles {; key: ""m64154_210327_091530/128910218/ccs/0""; value {; bases: ""TC""; type: INSERTION; count: 1; }; }; ...; ```. ##### For Position: 89013076: . ```; position {; reference_name: ""chr10""; position: 89013075; }; ref_base: ""C""; ref_supporting_read_count: 35; read_alleles {; key: ""m64154_210327_091530/103023686/ccs/0""; value {; bases: ""CA""; type: DELETION; count: 1; }; }; read_alleles {; key: ""m64154_210327_091530/128910218/ccs/0""; value {; bases: ""CA""; type: DELETION; count: 1; }; }; ...; ```. ##### For Position: 89013077: ; ```; position {; reference_name: ""chr10""; position: 89013076; }; ref_base: ""A""; read_alleles {; key: ""m64154_210327_091530/142213575/ccs/0""; value {; bases: ""C""; type: SUBSTITUTION; count: 1; }; }; read_alleles {; key: ""m64154_210327_091530/4130912/ccs/0""; value {; bases: ""C""; type: SUBSTITUTION; count: 1; }; }; ...; ```. Given that the allele type (indel/substitution) changes ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/660#issuecomment-1590833828:291,down,down,291,,https://github.com/google/deepvariant/issues/660#issuecomment-1590833828,2,['down'],['down']
Availability,"Thank you @Luosanmu . I see. From your image, I think I understand why DeepVariant would make a REF call here. The variant in question is a 1-bp extension of a homopolymer (10A -> 11A). Homopolymers are generally difficult to sequence through. The number of reference-supporting reads are 47 and alternate-supporting reads are 10 (~16%), which is far from the typically-expected 50% if the position is heterozygous. DeepVariant's model has to weigh which probability is more likely: that this is a real HET event and the random sampling of the alleles causes the observations to be skewed as far as 16%, or is there a sufficiently recurring 1bp insertion error during sequencing that explains these insertions at this ratio. Presumably, over the bulk of DeepVariant's training, when it has seen similar situations, in more cases these are insertion errors. Now, whether that is what is truly going on in your sample, it's difficult for me as a human to say.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/770#issuecomment-1954881609:655,error,error,655,,https://github.com/google/deepvariant/issues/770#issuecomment-1954881609,2,['error'],"['error', 'errors']"
Availability,"Thank you @githubtefo for the log. The last step certainly looks strange to me:. ```; ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""/reference/Homo_sapiens.GRCh37.dna.primary_assembly.fa"" --infile ""/tmp/tmpba2iuryg/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""/output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpba2iuryg/gvcf.tfrecord@16.gz"". I0418 11:23:10.756783 140607260936000 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: 15337_Control; 2024-04-18 11:23:10.761841: I deepvariant/postprocess_variants.cc:94] Read from: /tmp/tmpba2iuryg/call_variants_output-00000-of-00001.tfrecord.gz; 2024-04-18 11:23:39.285004: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 8753635; I0418 11:24:21.877126 140607260936000 postprocess_variants.py:1313] CVO sorting took 1.1852648933728536 minutes; I0418 11:24:21.877437 140607260936000 postprocess_variants.py:1316] Transforming call_variants_output to variants.; I0418 11:24:21.877472 140607260936000 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation.; I0418 11:24:35.259627 140607260936000 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: 15337_Control. real	2m10.376s; user	1m41.800s; sys	0m24.640s; ```. I would expect `postprocess_variants` to be doing more. I believe @lucasbrambrink is looking into another issue in `postprocess_variants` related to multiprocessing (https://github.com/google/deepvariant/issues/804), but I'm not sure if this relevant. For now, can you try disable multiprocessing in the `postprocess_variants` step by setting `--cpus 0`. If you're using the run_deepvariant one-step script, you can add:. ```bash; --postprocess_variants_extra_args=""cpus=0""; ```. and see if that works for you. Please let us know. We'll try to make this more robust in the future!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/810#issuecomment-2068144877:1966,robust,robust,1966,,https://github.com/google/deepvariant/issues/810#issuecomment-2068144877,1,['robust'],['robust']
Availability,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480616982:295,error,error,295,,https://github.com/google/deepvariant/issues/167#issuecomment-480616982,2,['error'],['error']
Availability,"Thank you both for your inputs. Regarding the old, anecdotal observation that GPU isn't efficiently used, I didn't collect any GPU resources like this time. And here are the CPU/memory/disk usages for the same input data, under CPU vs under GPU modes, back then. Note these are collected from running the PEPPER pipeline (release 0.4.0). Note how using the GPU didn't help in terms wallclock time.; ![pepper shard-0 high-cpu resources](https://github.com/google/deepvariant/assets/16310888/e7970a06-b38d-4972-8a8d-6a5cf0595ef1); ![pepper shard-0 NVDA-P100 resources](https://github.com/google/deepvariant/assets/16310888/78b9da04-d9c7-4c5b-a730-ae99b8ee4908). And here's the cost of the GPU mode, broken down by SKU (we use Google cloud). ![pepper NVDA-P100 cost](https://github.com/google/deepvariant/assets/16310888/64316bdd-3ceb-47cb-a130-dd6da34dc8fc). In terms of running DV in ""production"", we did optimize the CPU pipeline down to below $20/sample. We didn't optimize the GPU pipeline because of the wall-clock issue. Based on the samples I've analyzed with 1.5.0 so far, the cost indeed dropped. Parabricks isn't really an option for us, as we build pipelines using WDL and run them on Terra. With all these said, I'm definitely not saying that this is a blocker for us. It is more of a curiosity/optimization question. Thank you!; Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/650#issuecomment-1550151017:704,down,down,704,,https://github.com/google/deepvariant/issues/650#issuecomment-1550151017,2,['down'],['down']
Availability,"Thank you for answer.; We are using Ubuntu 14.04 for our images (yes, still).; ```; # uname -a; Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux; ```; ```; root@417d805a5037:/outputs# lsb_release -a; No LSB modules are available. ; Distributor ID: Ubuntu ; Description: Ubuntu 14.04.6 LTS ; Release: 14.04 ; Codename: trusty ; ```; ```; root@417d805a5037:/outputs# gcc --version ; gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 ; Copyright (C) 2013 Free Software Foundation, Inc. ; This is free software; see the source for copying conditions. There is NO ; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; ```. Maybe we need newer `gcc`?. And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/236#issuecomment-557117908:283,avail,available,283,,https://github.com/google/deepvariant/issues/236#issuecomment-557117908,2,"['avail', 'down']","['available', 'download']"
Availability,"Thank you for clarification Guillaume - I think deleting `GQ = 0` sites is a reasonable solution if that works for your use case. I agree with you that the current `GT`, `GQ`, `PL` values we emit in this particular case can be confusing. Please let us know if you have any suggestion on improving it for your downstream application (i.e. emitting different `PL` values) - I'll be sure to discuss it with my team. Thank you,; Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/403#issuecomment-761187324:309,down,downstream,309,,https://github.com/google/deepvariant/issues/403#issuecomment-761187324,1,['down'],['downstream']
Availability,"Thank you for reporting the issue.; Can you tell us more about what environment you're building it in? (OS version, gcc version); I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:; ```; pichuan@pichuan-build:~$ uname -a; Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux; pichuan@pichuan-build:~/deepvariant$ lsb_release -a; No LSB modules are available.; Distributor ID: Ubuntu; Description: Ubuntu 16.04.6 LTS; Release: 16.04; Codename: xenial; ```. Then I clone our repo:; ```; pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git; ```; Confirmed it's on r0.9:; ```; pichuan@pichuan-build:~$ cd deepvariant/; pichuan@pichuan-build:~/deepvariant$ git branch; * r0.9; ```; And then I build:; ```; pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh ; ```; This completed without an error. I checked my gcc version:; ```; pichuan@pichuan-build:~/deepvariant$ gcc --version; gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/236#issuecomment-557101397:218,error,error,218,,https://github.com/google/deepvariant/issues/236#issuecomment-557101397,3,"['avail', 'error']","['available', 'error']"
Availability,"Thank you for the quick response!; I'd be glad to provide more information (the information listed below is from the original datasets / metrics provided from the genetic testing company that performed the tests utilizing their own tooling.); What type of sequencing data? Diagnostic Testing / XomeDx / Clinical Exome Sequence Analysis (provided in cram format with md5 hg19 as reference and the accompanying vcfs from said company) ; what depths - 152x mean depth of coverage with a quality threshold of 98.6; what organism - Humans using hg19 as reference (family of 4 two affected female probands two unaffected parents); Anything noticeably different from the data we used in case studies - nothing that i'm aware of at this time. It'll be great if you can also report: how many number of calls in your VCFs, how many GTs are in each calls (e.g., how many calls are ./.)? -I'm not completely sure where this is located but I believe I can find it. And, if your data is public, you can point to us and we can take a look. - The data is not available publicly yet but I would be glad to share it with you and your team. It has been submitted for public sharing with mygene2 (at least I'm pretty sure they are not online yet). I do, however, plan on sharing them online with Genome Connect and the rest of genetic community in the near future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/311#issuecomment-636996628:1043,avail,available,1043,,https://github.com/google/deepvariant/issues/311#issuecomment-636996628,1,['avail'],['available']
Availability,"Thank you for the response ; I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```; conda create -n deepvariant python=2.7; source activate deepvariant; conda install -c conda-forge google-cloud-sdk; conda install -v -y deepvariant &> deepvariant_insatll.log; ```. I got a successful installation inspite of the first error message just like you; However, running the code is producing another error:. ```; python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \; --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \; --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \; --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>; import tensorflow as tf; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_intern",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-453685106:430,error,error,430,,https://github.com/google/deepvariant/issues/137#issuecomment-453685106,2,['error'],['error']
Availability,"Thank you for the response. Using samtools coverage, I see that mean coverage are in ~130X for some chromosomes and 224X with mitochondria with one of the files, and I suspect that other files are similar. By downsampling, do you mean something like splitting fastq files (say 3 files with 1/3 of original using something like fastqsplitter)? I have never done this before, so an explicit answer would be greatly appreciated. Also, do you have suggestions on what to use to merge gvcf or vcf output?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/614#issuecomment-1440694835:209,down,downsampling,209,,https://github.com/google/deepvariant/issues/614#issuecomment-1440694835,1,['down'],['downsampling']
Availability,"Thank you for your input, I am able to find the checkpoints with this training.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2073378095:48,checkpoint,checkpoints,48,,https://github.com/google/deepvariant/issues/802#issuecomment-2073378095,1,['checkpoint'],['checkpoints']
Availability,"Thank you for your kind help! In fact ,I reran the same commands and got the result files without any error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/488#issuecomment-964829927:102,error,error,102,,https://github.com/google/deepvariant/issues/488#issuecomment-964829927,1,['error'],['error']
Availability,"Thank you for your quick answer. I had to make a couple of changes to the command (see below), but now it seems to be working:; ```; conda create -y -n deepvariant -c bioconda -c conda-forge python=2.7 deepvariant google-cloud-sdk=239.0.0; ```; Everything is installed correctly. However, when I try to run it I get the following error:; ```; python /PATH/TO/Andrea/myanaconda/deepvariant/share/deepvariant-0.9.0-0/binaries/DeepVariant/0.9.0/DeepVariant-0.9.0/call_variants.zip --help; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_lazCGY/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 47, in <module>; import tensorflow as tf; File ""/PATH/TO/Andrea/myanaconda/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/PATH/TO/Andrea/myanaconda/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 59, in <module>; from tensorflow.core.framework.graph_pb2 import *; File ""/PATH/TO/Andrea/myanaconda/deepvariant/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 6, in <module>; from google.protobuf import descriptor as _descriptor; File ""/tmp/Bazel.runfiles_lazCGY/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 47, in <module>; from google.protobuf.pyext import _message; ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_lazCGY/runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so); ```; I've tried to install an updated version of the library using ; ```conda install librosa```; but it didn't work. Any suggestion?. Thank you again for your support,; Andrea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/252#issuecomment-566564983:330,error,error,330,,https://github.com/google/deepvariant/issues/252#issuecomment-566564983,1,['error'],['error']
Availability,"Thank you for your reply @scott7z. CPU and OS infomation:; `uname -a`; Linux 6562232b4f47 4.4.0-57-generic #78-Ubuntu SMP Fri Dec 9 23:50:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux ; `head -n 1 /etc/issue`; Ubuntu 16.04.1 LTS \n \l. First, when I ran a container for deepvariant and executed the make_examples command; `./make_examples`; Nothing happened; `python make_examples.zip`; Still nothing happened. `unzip make_examples.zip`; `cd runfiles/genomics/deepvariant` ; #Add deepvariant to PYTHONPATH ; `echo ""export PYTHONPATH=\$PYTHONPATH:/opt/deepvariant/bin/runfiles/genomics"" >> /root/.bashrc` `source /root/.bashrc` ; `python make_examples.py`; Then I got; ""Illegal instruction (core dumped)"". This are dockerfile, run-prereq.sh and setting.sh, for reference.; [Dockerfile.zip](https://github.com/google/deepvariant/files/1554745/Dockerfile.zip)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/16#issuecomment-351322489:506,echo,echo,506,,https://github.com/google/deepvariant/issues/16#issuecomment-351322489,1,['echo'],['echo']
Availability,"Thank you for your reply!; 1、My machine doesn't have `/usr/bin/python3`.I don't have permission to change `/usr/bin/`.I tried to modify the source code, but I couldn't locate the code.; 2、I tried to install Singularity. I use the parameter `--without -- seccomp --without -- conmon` because of the following error; `./mconfig --without-suid --without-seccomp --without-conmon --prefix=/path/singularity && make -C ./builddir &&make -C ./builddir install`; ```; seccomp headers are required to build Singularity with seccomp support.; To disable seccomp support run mconfig using '--without-seccomp'. Cannot build conmon for OCI support without libseccomp headers.; Use --without-conmon to disable build and use conmon on PATH if present.; ```; Then I try to run it; ```; singularity run -B /path/locale/:/path/locale/ \; > docker://google/deepvariant:""1.4.0"" \; > /path/dpv_singu \; > --model_type=PACBIO \; > --ref=/path/ref_fasta/QJref.fa \; > --reads=/path/bam_files/F1N_sorted.merged.addg.uniq.rmdup.bam \; > --output_vcf=/path/output.vcf.gz \; > --output_gvcf=/path/output.g.vcf.gz \; > --intermediate_results_dir /path/intermediate_results_dir; ```; The error information is as follows; ```; INFO: Using cached SIF image; INFO: Converting SIF file to temporary sandbox...; FATAL: while handling /home/my_user_name/.singularity/cache/oci-tmp/sha256.83ce0d6bbe3695bcbaa348b73c48737bdbfaeaea2272b0105dd4bdfa7a804f18: while extracting image: root filesystem extraction failed: extract command failed: ERROR : Failed to create user namespace: user namespace disabled; : exit status 1; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/598#issuecomment-1359523260:308,error,error,308,,https://github.com/google/deepvariant/issues/598#issuecomment-1359523260,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Thank you for your reply!; For the following code, I don't have permission to modify the path `/usr/bin/`, and I didn't find `/usr/bin/python3` from `subprocess.py`, so I didn't fix the error either.; As a study student, I am working hard to learn to solve these mistakes. It hasn't been resolved yet.; ```; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/598#issuecomment-1356305359:186,error,error,186,,https://github.com/google/deepvariant/issues/598#issuecomment-1356305359,2,['error'],['error']
Availability,"Thank you so much Maria! It finally worked. I've changed the docker memory settings to be 32 GB, it was indeed the problem. The fasta file still had problems of EOF each time at different position, however I've downloaded it again and again until it finally worked !. Thank you again for the support :) !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/483#issuecomment-917606346:211,down,downloaded,211,,https://github.com/google/deepvariant/issues/483#issuecomment-917606346,1,['down'],['downloaded']
Availability,"Thank you so much for your assistance Paul. Answered slightly out of order:. 2. The location from which the commands were run is /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/. Inside this directory are two subdirectories: inputs (in which the assembly and bam files are) and outputs (in which the results go). 1. The commands run were:. BIN_VERSION=""1.5.0""; docker pull google/deepvariant:""${BIN_VERSION}"". INPUT_DIR=""${PWD}/inputs""; OUTPUT_DIR=""${PWD}/outputs"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa --reads=/input/NC_045426.1_A_filt_fixed_markdup_csort.bam --output_vcf=/output/NC_045426.1_A.vcf.gz --output_gvcf=/output/NC_045426.1_A.g.vcf.gz --intermediate_results_dir /output/NC_045426.1_A_intermediate_results_dir --num_shards=1 &. 3. The complete output of errors is:. 2023-08-30 21:45:18.422516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0830 21:45:20.409601 140002879141696 run_deepvariant.py:364] Re-using the directory for intermediate results in /output/NC_045426.1_A_intermediate_results_dir. ***** Intermediate results will be written to /output/NC_045426.1_A_intermediate_results_dir in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa"" --reads ""/input/NC_045426.1_A_filt_fixed_markdup_csort.bam"" --examples ""/output/NC_045426.1_A_intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/NC_045426.1_A_interm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1699892625:969,error,errors,969,,https://github.com/google/deepvariant/issues/184#issuecomment-1699892625,1,['error'],['errors']
Availability,"Thank you so much.; In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required.; Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation.; For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:; https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/127#issuecomment-446044386:313,checkpoint,checkpoints,313,,https://github.com/google/deepvariant/issues/127#issuecomment-446044386,2,['checkpoint'],['checkpoints']
Availability,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/684#issuecomment-1645793952:371,down,downsampled,371,,https://github.com/google/deepvariant/issues/684#issuecomment-1645793952,2,"['down', 'robust']","['downsampled', 'robust']"
Availability,"Thank you very much for your prompt response, particularly on the weekend!. I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works!. If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/166#issuecomment-478414504:469,error,error,469,,https://github.com/google/deepvariant/issues/166#issuecomment-478414504,4,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,Thank you very much for your quick replay.; I changed the version of the singularity to > 3 the problem was solved. however when I try to run the image using the following command ; singularity run -B /usr/lib/locale/:/usr/lib/locale/ /home/my_username/deepvariant_1.3.0.sif --model_type=WES --ref=input/Homo_sapiens_assembly38.fasta --reads=/oldHome/my_username/exome_data/EX2015.sorted.bam \ --output_vcf=output/output.vcf.gz --intermediate_results_dir=outout --num_shards=10; it returns the following error and stop; INFO: Convert SIF file to sandbox...; ERROR : Failed to create user namespace: user namespace not supported by your system; Thanks,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/513#issuecomment-1027691620:504,error,error,504,,https://github.com/google/deepvariant/issues/513#issuecomment-1027691620,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now!. From: Pi-Chuan Chang ***@***.***>; Sent: Friday, March 25, 2022 7:19 PM; To: google/deepvariant ***@***.***>; Cc: Jason Phillips ***@***.***>; Mention ***@***.***>; Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________; Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:; #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>.; You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/530#issuecomment-1079677356:375,error,errors,375,,https://github.com/google/deepvariant/issues/530#issuecomment-1079677356,1,['error'],['errors']
Availability,"Thank you! I re-ran the training and validation sets with that flag, and re-shuffled them. Now, however, when I go to train the model (using the same parameters as the example case study--I just want to test out the process) I'm not getting any checkpoints in the output training directory, just the event log and the json file. What does this mean? Is the training step failing, or do I simply need to adjust my parameters? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2029425877:245,checkpoint,checkpoints,245,,https://github.com/google/deepvariant/issues/797#issuecomment-2029425877,2,['checkpoint'],['checkpoints']
Availability,"Thank you! I'm still curious-- if RefCall entries are rejected by 'call_variants', why are they still reported in the final VCF? Do they enable some sort of helpful QC checks? If so, which? Since any downstream application would filter these out, I'm a bit unclear why an internal variant nomination process is included in the final output.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/386#issuecomment-728300689:200,down,downstream,200,,https://github.com/google/deepvariant/issues/386#issuecomment-728300689,1,['down'],['downstream']
Availability,"Thank you. I want to use a PacBio model trained on v3.3.2 benchmark variants. I assumed that the following model: deepvariant/models/DeepVariant/0.9.0/DeepVariant-inception_v3-0.9.0+data-pacbio_standard from DeepVariant bucket released in 2019 is trained on v3.3.2. However, when I run this model in call_variants using examples created by make_examples from DeepVariant v1.0.0, I get the following error:. `ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 8.`. Does this mean this model is not compatible with DeepVariant v1.0.0? If I recreate examples with 6 channels using DeepVariant v0.9, will that have a significant drop in accuracy? Also, is there a trained model on v3.3.2 of benchmark variants that is compatible with 8 channels?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/381#issuecomment-727285166:399,error,error,399,,https://github.com/google/deepvariant/issues/381#issuecomment-727285166,3,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"Thanks @ASLeonard . I tried one more with (still with my own versions this time) and added the `-B`:. ```; singularity build deepvariant.sif docker://google/deepvariant:${BIN_VERSION}; mkdir -p intermediate_results_dir; ```; ```; singularity run \; -B ${HOME}/input:/input,${HOME}/reference:/reference,${HOME}/deepvariant1:/deepvariant1,${HOME}/intermediate_results_dir:/intermediate_results_dir \; deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type ""PACBIO"" \; --ref /reference/GRCh38_no_alt_analysis_set.fasta \; --reads /input/HG003.GRCh38.chr20.pFDA_truthv2.bam \; --output_vcf /deepvariant1/output.vcf.gz \; --output_gvcf /deepvariant1/output.g.vcf.gz \; --num_shards $(nproc) \; --regions ""chr20:10,000,000-10,010,000"" \; --call_variants_extra_args ""use_openvino=true"" \; --intermediate_results_dir /intermediate_results_dir; ```. I tried this with a newer Singularity version, and still can't reproduce your error yet. Here's the machine I'm on:; ```; (deepvariant_whatshap) pichuan@pichuan-cpu:~$ singularity --version; singularity version 3.6.4; (deepvariant_whatshap) pichuan@pichuan-cpu:~$ uname -a; Linux pichuan-cpu 4.15.0-1091-gcp #104~16.04.1-Ubuntu SMP Tue Dec 15 19:05:28 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux; ```. I'll try again later with CentOS as well to see if I can reproduce your issue. If you find out anything else, please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-763239411:936,error,error,936,,https://github.com/google/deepvariant/issues/404#issuecomment-763239411,1,['error'],['error']
Availability,"Thanks @akolesnikov and @pichuan . Please find the details and the error-log below. Please note that I have upgraded the following dependencies according to Tensorflow - 2.11. . DV_BAZEL_VERSION=""5.3.0""; DV_GCP_OPTIMIZED_TF_WHL_VERSION=""2.11.0""; ABSL_VERSION=20210324.2; PROTOBUF_VERSION=3.19.6. **Error log:** ; (03:11:57) ERROR: /opt/deepvariant/third_party/nucleus/io/BUILD:1051:11: Compiling third_party/nucleus/io/gfile.cc failed: (Exit 1): gcc failed: error executing command; (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \; exec env - \; PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \; PWD=/proc/self/cwd \; PYTHON_BIN_PATH=/usr/local/bin/python3 \; PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \; TF2_BEHAVIOR=1 \; /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-. Also, at an earlier point in the build, there is one more issue - . Download from https://mirror.bazel.build/github.com/bazelbuild/rules_cc/archive/081771d4a0e9d7d3aa0eed2ef389fa4700dfb23e.tar.gz failed: class java.io.FileNotFoundException GET returned **404 Not Found**",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/607#issuecomment-1418449705:67,error,error-log,67,,https://github.com/google/deepvariant/issues/607#issuecomment-1418449705,5,"['Down', 'ERROR', 'Error', 'error']","['Download', 'ERROR', 'Error', 'error', 'error-log']"
Availability,"Thanks @gunjanbaid! , it's now one command but I still received a error:. sudo docker run \; > -v ""${INPUT_DIR}"":""/input"" \; > -v ""${OUTPUT_DIR}:/output"" \; > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=/input/ucsc.hg19.chr20.unittest.fasta \; > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; > --regions ""chr20:10,000,000-10,010,000"" \; > --output_vcf=/output/output.vcf.gz \; > --output_gvcf=/output/output.g.vcf.gz \; > --num_shards=4; docker: invalid reference format.; See 'docker run --help'. These commands are being run in a Unix shell, do you think the commands vary between Linux and Unix?. Best,. -Ashraf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/181#issuecomment-489169486:66,error,error,66,,https://github.com/google/deepvariant/issues/181#issuecomment-489169486,1,['error'],['error']
Availability,Thanks @nikostr for reporting this.; The zip file for 1.1.0 should be avaiable at https://github.com/google/deepvariant/releases/download/v1.1.0/deepvariant.zip now.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/436#issuecomment-814505837:129,down,download,129,,https://github.com/google/deepvariant/issues/436#issuecomment-814505837,1,['down'],['download']
Availability,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply!. Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**; This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**; The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**; 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**; Yes, I have successfully run it. **How much free memory do you have?**; 1.3T . **How much free disk space do you have?**; I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**; 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**; No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/681#issuecomment-1641137274:902,avail,available,902,,https://github.com/google/deepvariant/issues/681#issuecomment-1641137274,2,['avail'],['available']
Availability,"Thanks @pichuan :). Finally I got the root cause of this issue, it seem the return number of min on Ubuntu and RHEL are different. I tried to run the following commands on both python2:. The output of **Ubuntu** (on X86) is:; ```; >>> import mock; >>>; >>> expected_start=9; >>> expected_end=21; >>> bufsize=0; >>> expected_bases = 'A' * (expected_end - expected_start); >>>; >>> start=10; >>> end=21; >>> contig='20'; >>> ref_reader = mock.MagicMock(); >>> ref_reader.query.return_value = expected_bases; >>> contig_nbp = ref_reader.contig(contig).n_bases; >>> res = min(end + bufsize, contig_nbp); >>> res; 21; ```. And then I tried the same code on **RHEL 7.5 (both on X86 and Power**, the output is:. ```; >>> import mock; >>>; >>> expected_start=9; >>> expected_end=21; >>> bufsize=0; >>> expected_bases = 'A' * (expected_end - expected_start); >>>; >>> start=10; >>> end=21; >>> contig='20'; >>> ref_reader = mock.MagicMock(); >>> ref_reader.query.return_value = expected_bases; >>> contig_nbp = ref_reader.contig(contig).n_bases; >>> res = min(end + bufsize, contig_nbp); >>> res; <MagicMock name='mock.contig().n_bases' id='140373647899088'>; >>> int(res); 1; ```. And I accidentally run the above command with Python3, and it throw the following error:. ```; >>> res = min(end + bufsize, contig_nbp); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: '<' not supported between instances of 'MagicMock' and 'int'; ``` . So propose to fix the above type conversion if you have plan to support RHEL or upgrade to Python 3 in the future :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/154#issuecomment-464961152:1255,error,error,1255,,https://github.com/google/deepvariant/issues/154#issuecomment-464961152,1,['error'],['error']
Availability,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0""; docker run \; -v ""${HOME_DIR}"":""/home"" \; -v ""${TMP_DIR}"":""/tmpdir"" \; gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode=calling \; --sample_name=RHA \; --examples=/tmpdir/make_examples.tfrecord.gz \; --ref=/home/RHA.fa \; --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \; --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \; -v ""${HOME_DIR}"":""/home"" \; -v ""${TMP_DIR}"":""/tmpdir"" \; gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/call_variants \; --checkpoint=/opt/models/wgs/model.ckpt \; --examples=/tmpdir/make_examples.tfrecord.gz \; --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \; -v ""${HOME_DIR}"":""/home"" \; -v ""${TMP_DIR}"":""/tmpdir"" \; gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/postprocess_variants \; --ref=/home/RHA.fa \; --infile=/tmpdir/call_variants_output.tfrecord.gz \; --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \; --outfile=/home/out.vcf \; --gvcf_outfile=/home/out.gvcf. Thanks for all your help; Azita",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/222#issuecomment-536285730:1270,checkpoint,checkpoint,1270,,https://github.com/google/deepvariant/issues/222#issuecomment-536285730,1,['checkpoint'],['checkpoint']
Availability,"Thanks Luisa! It seems those s3 files aren't public:. wget http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; --2018-03-07 07:28:01-- http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; Resolving dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)... 52.218.52.113; Connecting to dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)|52.218.52.113|:80... connected.; HTTP request sent, awaiting response... 403 Forbidden; 2018-03-07 07:28:01 ERROR 403: Forbidden.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371184018:465,ERROR,ERROR,465,,https://github.com/google/deepvariant/issues/52#issuecomment-371184018,1,['ERROR'],['ERROR']
Availability,"Thanks Nima. I ran it again. Looks like the error is because it is unable to open the bed file I have provided. However, the bed file exists on gcp and my v0.6.1 code was able to access it. I am not sure what I am doing wrong. I was able to run the same code successfully if I provide the bed file in the example documentation (gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed). . Error file: gbsc-gcp-project-udn-dev-deep-variant/UDN668131_deepVariant_test4/deepvariant_staging_folder/logs/make_examples/0:. W::hts_idx_load2] The index file is older than the data file: /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bai; 2018-11-09 19:48:51.497793: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring: ; I1109 19:48:51.498179 140612532332288 genomics_reader.py:213] Reading /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bam with NativeSamReader; I1109 19:48:51.518172 140612532332288 make_examples.py:1075] Preparing inputs; [W::hts_idx_load2] The index file is older than the data file: /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bai; 2018-11-09 19:48:52.291229: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring: ; I1109 19:48:52.291625 140612532332288 genomics_reader.py:213] Reading /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bam with NativeSamReader; I1109 19:48:52.335163 140612532332288 make_examples.py:991] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']; [E::hts_open_format] **Failed to open file gs://gbsc-gcp-project-udn-dev-test/VCRome_2_1_hg19_capture_targets_chrStripped.bed**; Traceback (most recent call last):; File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/di",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/118#issuecomment-437503051:44,error,error,44,,https://github.com/google/deepvariant/issues/118#issuecomment-437503051,2,"['Error', 'error']","['Error', 'error']"
Availability,"Thanks Paul for pointing this out,. The reason why I used Parabricks is to add optional parameters and run DeepVariant in one command. However based on what you said, I will run 3 steps (make_examples, call_variants and post_process_variants) separately so I can add optional parameters in `make_examples` step. While doing `call_variants` step, it generates a lot of errors. One of the error points out that `input depth must be evenly divisible by filter depth: 6 vs 7`. What does it mean?. I also attached the error log [error.log](https://github.com/google/deepvariant/files/12731863/error.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1736300897:368,error,errors,368,,https://github.com/google/deepvariant/issues/706#issuecomment-1736300897,5,['error'],"['error', 'errors']"
Availability,"Thanks Paul for this very insightful comment,. I went ahead and redoing my retraining. I see improvements in the accuracy score. That helps a lot. Now my next step is to use the retrain model to run on our internal sample. I want to convert the .ckpt to .pb file. Here is the comment I got from the [tutorial](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md):. `sudo docker run \; -v $PWD:/input \; -v $PWD:/output \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/freeze_graph \; --checkpoint /input/model.ckpt \; --example_info_json /input/model.ckpt.example_info.json \; --output /output/model.pb`. What is the `model.ckpt.example_info.json` here? I don't see the json file being created when I do `model_train` which is the step that generate the `.ckpt` file?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1732052007:524,checkpoint,checkpoint,524,,https://github.com/google/deepvariant/issues/706#issuecomment-1732052007,1,['checkpoint'],['checkpoint']
Availability,"Thanks Paul, the 0.5.2 binaries are now available at the above bucket. Note that we also create a 'deepvariant.zip' asset with each tagged release that includes the binaries and models.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/57#issuecomment-371628818:40,avail,available,40,,https://github.com/google/deepvariant/pull/57#issuecomment-371628818,1,['avail'],['available']
Availability,Thanks Paul.; I added an internal bug to track your suggestion. DeepVariant still has quite a lot error messages that have room for improvement. Thanks for reporting this to us so we can itemize them and improve over time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/21#issuecomment-353730864:98,error,error,98,,https://github.com/google/deepvariant/issues/21#issuecomment-353730864,1,['error'],['error']
Availability,"Thanks again Paul:. 1). ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs ; -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa; -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam; -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 2) . INPUT_DIR=""${PWD}/inputs"" ; echo ${PWD}; /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. ls -l ${INPUT_DIR}; total 6125004; -rw-rw-r-- 1 ajp1 ajp1 3138120789 Aug 31 12:12 GCF_902635505.1_mSarHar1.11_genomic_baicompat.fa; -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam; -rw-rw-r-- 1 ajp1 ajp1 3133881452 Aug 31 12:12 NC_045426.1_A_filt_fixed_markdup_csort.bam. 3) . INPUT_DIR=""${PWD}/inputs"" ; BIN_VERSION=""1.5.0""; echo ${PWD}; /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. Note: ajp1 is in the docker user group, but does not have sudo permissions. they did not need sudo to run deepvariant on their earlier runs though and it worked just fine... Nonetheless, running without sudo gives the following:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input; total 0 . docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam; (this gave no outputs at all). Lastly, I tried specifying the directories as you did above:. INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". And I still had no output at all when running:. docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1700285417:553,echo,echo,553,,https://github.com/google/deepvariant/issues/184#issuecomment-1700285417,2,['echo'],['echo']
Availability,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/228#issuecomment-549166457:45,error,error,45,,https://github.com/google/deepvariant/issues/228#issuecomment-549166457,4,"['down', 'error']","['down', 'download', 'error']"
Availability,"Thanks for getting back to me. I have attached the screenshot for error messages:; <img width=""1368"" alt=""error_message_deepvariant"" src=""https://user-images.githubusercontent.com/30123717/145905106-9d351a82-a563-411c-b139-031f0eafa4ad.png"">",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/497#issuecomment-993005113:66,error,error,66,,https://github.com/google/deepvariant/issues/497#issuecomment-993005113,1,['error'],['error']
Availability,"Thanks for looking into this. I was under the impression that Deepvariant cannot call MNPs period. It sounded like a technical decision inside the code to look at each variant site independently and break potential MNPs up into individual SNPs. Did I get that wrong and would that mean that DV can infact call MNPs, but not always reliably?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/520#issuecomment-1558729655:331,reliab,reliably,331,,https://github.com/google/deepvariant/issues/520#issuecomment-1558729655,1,['reliab'],['reliably']
Availability,"Thanks for replying @danielecook ; But it still has a problem, I try to download the ref genome again. This is the error; 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required.; I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**; BIN_VERSION=""1.4.0""; nproc=8; sudo docker run \; -v ""$(pwd):$(pwd)"" \; -w $(pwd) \; google/deepvariant:""${BIN_VERSION}"" \; run_deepvariant \; --model_type=WES \; --customized_model=model/model.ckpt \; --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\; --reads=data/hg005_gm26107.mrna.grch38.bam\; --output_vcf=output/HG005.output.vcf.gz \; --num_shards=$(nproc) \; --regions=data/chr20_CDS_3x.bed\; --make_examples_extra_args=""split_skip_reads=true,channels=''"" \; --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1302733421:72,down,download,72,,https://github.com/google/deepvariant/issues/581#issuecomment-1302733421,4,"['Down', 'down', 'error']","['Downloads', 'download', 'error', 'errors']"
Availability,"Thanks for the added code.; Here are my follow-up questions:; - what is the pattern to use for file naming if I’m processing multiple BAM files?; - If downsampling same source BAM multiple times, do I perform loop function myself?; - Is there a seed parameter for downsampling fraction?; Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/765#issuecomment-1908687832:151,down,downsampling,151,,https://github.com/google/deepvariant/issues/765#issuecomment-1908687832,2,['down'],['downsampling']
Availability,Thanks for the clarification. Is the new PacBio training data publicly available? I apologize if this is described somewhere and I didn't find it.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/201#issuecomment-516853711:71,avail,available,71,,https://github.com/google/deepvariant/issues/201#issuecomment-516853711,1,['avail'],['available']
Availability,"Thanks for the explanations, @pichuan !. Just to re-iterate to make sure I can understand, . - it is not expected that DV 1.4.0 and 1.5.0 will output phased variants, i.e. the GT field should still look like 0/1 not 0|1. ; - Instead, phasing is done internally to DV (like the PEPPER step), so that accuracy can benefit. ; - Therefore we should still run a standalone phasing tool (e.g. whatshap, margin phase) to phase the outputs of DV 1.4.0 and 1.5.0, if phasing is needed.; - And internal phasing results are also available if one follows your suggestion above (i.e. peeking under the hood). Is this correct?. Also, looking forward to the new doc explaining the phasing!. Thanks,; Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/649#issuecomment-1547127685:518,avail,available,518,,https://github.com/google/deepvariant/issues/649#issuecomment-1547127685,1,['avail'],['available']
Availability,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/228#issuecomment-547966813:91,down,download,91,,https://github.com/google/deepvariant/issues/228#issuecomment-547966813,3,['down'],['download']
Availability,Thanks for the question!; I tried to run the quick start on a GCP VM but could not reproduce the issue. One hint from the [documentation](https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility) that the error links to is that it could have to do with numpy versions. Can you try `pip install numpy --upgrade` and then rerun?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/640#issuecomment-1533748996:234,error,error,234,,https://github.com/google/deepvariant/issues/640#issuecomment-1533748996,1,['error'],['error']
Availability,"Thanks for the question. Yes that is definitely some kind of bug, but I'm not able to reproduce it. It looks like something wrong with the rendering in vega-lite. How does this report look to you?: https://42basepairs.com/browse/gs/deepvariant/visual_reports/DeepVariant/1.5.0/WGS; This one has proper minus signs when I look at it. I'm asking because the report is effectively a website, so rendering can show up differently on different computers. A few things you could try:; 1. Open the HTML report in a different web browser (Chrome, Firefox, Safari, etc.); 2. Click the (...) in the top right corner of the report and go to ""Open in Vega Editor"".; 3. Play with any language settings on the computer or web browser in case it's the alphabet available that is missing the ""-"" character. If none of those solve the issue, then I'm also happy to take a look at your report, if you can share it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/643#issuecomment-1535257357:746,avail,available,746,,https://github.com/google/deepvariant/issues/643#issuecomment-1535257357,1,['avail'],['available']
Availability,"Thanks for the quick reply Mark. How about joint calling hundreds (100-200); of low coverage WGS? Would that make a difference to DeepVariant?. On Wed, Jan 17, 2018 at 7:29 PM, Mark DePristo <notifications@github.com>; wrote:. > Hi @avilella <https://github.com/avilella>,; >; > That's a great question. We done some limited experiments with DeepVariant; > on lower coverage samples, but not at the 2.5x-5x range directly (see; > attached image using an earlier version of DeepVariant than available on; > GitHub).; >; > Typically at such a low depth you need to follow a joint calling strategy; > like the 1000 Genomes project in order to get accurate allele discovery; > across many samples. If you are trying to do single sample calling from low; > coverage, despite the relatively low quality of calls you'll get due to the; > low coverage, you can certainly use DeepVariant. You really don't need to; > do anything different than for a deep WGS sample, so just follow the case; > study example command lines.; >; > There are some options in make_examples.py to manipulate the thresholds; > for generating candidate variant calls, but I'm not sure tweaking those; > will materially change the results. We'd be interested in hearing about; > your experiences with such low coverage samples if you do decide to try it; > out.; >; > [image: screen shot 2018-01-17 at 11 14 01 am]; > <https://user-images.githubusercontent.com/2250400/35062234-632d9068-fb78-11e7-84eb-66062ba79a43.png>; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/40#issuecomment-358413895>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAJpN-cW-EdQ649oZlMZPkDj6H6ILPLXks5tLkiqgaJpZM4Rh0y3>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/40#issuecomment-358416665:490,avail,available,490,,https://github.com/google/deepvariant/issues/40#issuecomment-358416665,1,['avail'],['available']
Availability,"Thanks for the quick reply, @pichuan . First of all, I followed the instructions in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md, but it gives the same error. 1. I got the image from ""docker://google/deepvariant:1.6.0"" I tried both: locally download the image and use the image without downloading. But they gave the same error.; 2. Follow the instructions in the link above to run the program. Here is the script that I used ; ```; #!/bin/bash. BIN_VERSION=""1.6.0"". INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}"". # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/746#issuecomment-1846470975:187,error,error,187,,https://github.com/google/deepvariant/issues/746#issuecomment-1846470975,4,"['down', 'error']","['download', 'downloading', 'error']"
Availability,"Thanks for the quick reply:; For me, make_examples.tfrecord@8.gz file is not generated and the following is the `make_examples.log` . ```{bash}; I0330 15:47:21.754682 140654028756736 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.756700 140654028756736 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.755398 140432560695040 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757477 140432560695040 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.770883 139863230490368 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.773075 139863230490368 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.754880 139747089467136 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.756903 139747089467136 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.754880 139944273491712 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757000 139944273491712 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.759158 140716713432832 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.761278 140716713432832 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.755259 140202003052288 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757451 140202003052288 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.765991 139705794897664 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.768276 139705794897664 errors.py:61] sample_name must be specified in calling mode.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/ref.fa --reads /input/sample.bam --examples /output/intermediate_results_dir/make_exa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/435#issuecomment-810383024:293,error,errors,293,,https://github.com/google/deepvariant/issues/435#issuecomment-810383024,4,['error'],['errors']
Availability,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :; - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12; - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK – so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99 – it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:; - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6; - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0 – this is great – is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/135#issuecomment-451075737:907,error,errors,907,,https://github.com/google/deepvariant/issues/135#issuecomment-451075737,3,['error'],"['error', 'errors']"
Availability,"Thanks for the reply. To be honest, things did not get working till now. I dont think you can help me in this issue more than this. I left it to my supervisor to sort it out. I just want to a confirmation that training scripts like model_train.zip and model_eval.zip is available in the conda build in order to not invest more time into sorting the error out without a reason. . Thanks so much again. You can close the issue now please.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/139#issuecomment-454151484:270,avail,available,270,,https://github.com/google/deepvariant/issues/139#issuecomment-454151484,2,"['avail', 'error']","['available', 'error']"
Availability,"Thanks for the response Dr. Nattestad. I was only given the hg19.fa files along with the cram files. ; Initially I discovered I was using an old version of Samtools so once I updated I tried using use the hg19.fa. I have updated and rebuilt my fai files using the command samtools faidx hg19.fa . I've set my environment variables as the following:; BIN_VERSION=""0.10.0""; BASE=""${HOME}/deepvariant-run""; INPUT_DIR=""${BASE}/input""; REF=""hg19.fa""; BAM=""2009617.cram""; OUTPUT_DIR=""${BASE}/output""; DATA_DIR=""${INPUT_DIR}/data""; OUTPUT_VCF=""2009617.vcf.gz""; OUTPUT_GVCF=""2009617.bam.g.vcf.gz""; OUTPUT_GVCF=""2009617.bam.g.vcf.gz""; Here is the command to execute deepvariant:; sudo docker run \; -v ""${DATA_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""/input/${REF}"" \; --reads=""/input/${BAM}"" \; --output_vcf=/output/${OUTPUT_VCF} \; --output_gvcf=/output/${OUTPUT_GVCF} \; --num_shards=$(nproc); and here is the new errors I'm seeing:; ValueError: Failed precondition: Cannot query without an index; parallel: This job failed:. Which eventually leads to the following errors where the process fails and ends: Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>; app.run(main); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run; _run_main(main, args); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples; --mode calling --ref ""/input/hg19.fa"" --reads ""/input/2009617.cram"" --exampl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/307#issuecomment-628230170:1040,error,errors,1040,,https://github.com/google/deepvariant/issues/307#issuecomment-628230170,1,['error'],['errors']
Availability,"Thanks for the update @amy-houseman . In your original message, it seems like the main error was:. ```; FATAL: could not open image /opt/deepvariant/bin/run_deepvariant: failed to retrieve path for /opt/deepvariant/bin/run_deepvariant: lstat /opt/deepvariant: no such file or directory; ```. I'm glad that you're able to adjust your command and get this working! Thank you for the update.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/717#issuecomment-1771016203:87,error,error,87,,https://github.com/google/deepvariant/issues/717#issuecomment-1771016203,1,['error'],['error']
Availability,"Thanks for the update, @Stikus . In the code I'm working on, I currently changed that block to:; ```; # Because of an issue with pypi's numpy on Ubuntu 14.04. we need to compile from; # source.; # See https://github.com/tensorflow/tensorflow/issues/6968#issuecomment-279061085; if [[ ""$(lsb_release -d)"" == *Ubuntu*14.04.* ]]; then; echo ""Installing numpy with -no-binary=:all:. This will take a bit longer.""; pip3 install ""${PIP_ARGS[@]}"" --no-binary=:all: ""numpy==${DV_TF_NUMPY_VERSION}""; else; pip3 install ""${PIP_ARGS[@]}"" ""numpy==${DV_TF_NUMPY_VERSION}""; fi; ```. But I'm also wondering if I should just remove if/else statement for different Ubuntu versions if we're not internally testing it to make sure everything still runs. So I might end up simplifying this further in the next release. Glad to hear that the fix you mentioned above worked for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/394#issuecomment-742700347:333,echo,echo,333,,https://github.com/google/deepvariant/issues/394#issuecomment-742700347,2,['echo'],['echo']
Availability,"Thanks for trying out the conda deepvariant package and apologies about the issue. unzip is a dependency on the bioconda recipe, and my guess is that it's available in the environmental bin directory ( `/opt/conda/envs/deepvariant/bin/`) but this is not present on your PATH within the docker container so it's not being found. If you add that to the PATH for the container environment, it'll hopefully resolve the problem. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/314#issuecomment-637733785:155,avail,available,155,,https://github.com/google/deepvariant/issues/314#issuecomment-637733785,1,['avail'],['available']
Availability,"Thanks for your help! I can ignore the warning about ""height"".; However,when I ran Deepvariant 1.1.0 and DeepTrio 1.2.0,the only error was about ""height"". When I ran Deepvariant 1.2.0 and DeepTrio 1.2.0,the errors were not only about ""height"",but also about ""ValueError"" like this:; **raise ValueError('call_variants_outputs did not pass sanity check.'); ValueError: call_variants_outputs did not pass sanity check. raise Exception('One or more postprocess_variants failed.'); Exception: One or more postprocess_variants failed.**. How should I deal with these errors？",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/488#issuecomment-940586642:129,error,error,129,,https://github.com/google/deepvariant/issues/488#issuecomment-940586642,3,['error'],"['error', 'errors']"
Availability,"Thanks for your interest in trying out training!. Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/80#issuecomment-401673684:270,down,download,270,,https://github.com/google/deepvariant/issues/80#issuecomment-401673684,1,['down'],['download']
Availability,Thanks much for suggesting this. I'm actively working on preparing a DeepVariant conda recipe for bioconda (https://github.com/bioconda/bioconda-recipes) along with the Google team. This might take a few days to get sorted out as there are a few pieces like bazel that appear to need updating in conda but I can report back here when it's available.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/9#issuecomment-350774284:339,avail,available,339,,https://github.com/google/deepvariant/issues/9#issuecomment-350774284,1,['avail'],['available']
Availability,"Thanks, Andrew!; I totally understand the priority setting. In the meantime, I've collected some DV-1.5.0 resource usage data on a particular sample (note the scattering schemes aren't the same between the two references). Overall it's making really good use of the resources available (**_maybe_** except the memory, but it's more likely I over-allocated). Hopefully, it can help your team with further tuning.; [30X.human.GRCh38.deepvariant.regular-resources-usage.pdf](https://github.com/google/deepvariant/files/11501324/30X.human.GRCh38.deepvariant.regular-resources-usage.pdf); [30X.human.T2T.deepvariant.regular-resources-usage.pdf](https://github.com/google/deepvariant/files/11501325/30X.human.T2T.deepvariant.regular-resources-usage.pdf). Thanks,; Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/650#issuecomment-1551851074:276,avail,available,276,,https://github.com/google/deepvariant/issues/650#issuecomment-1551851074,1,['avail'],['available']
Availability,"Thanks, Paul!. I do indeed sometimes see out-of-memory errors (e.g. for an even crazier sample with 140X coverage), but usually I get an PAPI error code 9 from that (based on experience, error code 9 indicates memory issues and error code 10 indicates disk issue, PAPI 10 is sort of an catch-all error code so it's not very informative). Never the less, the procedure you described is very helpful and I'll ; * try with increased the memory; * incorporate that into our workflow (conditionally, e.g. for high coverage samples), and ; * also use that for collecting data in tuning the resources allocated to DV. Thanks!; Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/491#issuecomment-960166365:55,error,errors,55,,https://github.com/google/deepvariant/issues/491#issuecomment-960166365,5,['error'],"['error', 'errors']"
Availability,"Thanks, just to followup: my `call_variants` step eventually finished after 1d2h31m. The last lines in my call_variants.log file read:. <pre>; 2018-10-17T14:30:33.396510159Z statfs 424901734400 available 4378992640 used 429280727040 total -- interval 10.0000 seconds 0 used; 2018-10-17T14:30:33.786897949Z I1017 14:30:33.786412 140161207068416 call_variants.py:359] Processed 10551585 examples in 329738 batches [0.904 sec per 100]; 2018-10-17T14:30:34.069377504Z I1017 14:30:34.068934 140161207068416 call_variants.py:359] Processed 10551617 examples in 329739 batches [0.904 sec per 100]; 2018-10-17T14:30:34.164880374Z I1017 14:30:34.164383 140161207068416 call_variants.py:359] Processed 10551649 examples in 329740 batches [0.904 sec per 100]; 2018-10-17T14:30:34.166325693Z I1017 14:30:34.166042 140161207068416 call_variants.py:361] Done evaluating variants; </pre>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/105#issuecomment-430723173:194,avail,available,194,,https://github.com/google/deepvariant/issues/105#issuecomment-430723173,1,['avail'],['available']
Availability,Thanks. ; I have solved this problem. The main reason is my machine can't access Google buckets for download as you say. I will close this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/228#issuecomment-550114233:100,down,download,100,,https://github.com/google/deepvariant/issues/228#issuecomment-550114233,1,['down'],['download']
Availability,"Thanks. I just tried to execute the command, but I get the following error message `ValueError: Cannot find matching files with the pattern ""/tmp/tmphskm66vr/call_variants_output.tfrecord.gz""`. The files in the tmp directory also seem to be gone.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/599#issuecomment-1360396137:69,error,error,69,,https://github.com/google/deepvariant/issues/599#issuecomment-1360396137,1,['error'],['error']
Availability,"Thanks. That helped. Now I'm facing the next error:; For every header in the reference file it prints; > ""header name"" is n bp and IS MISSING,. and then; > Please make sure the --ref input matches the build used for the input in --reads. That means that the reference genome that was used for creating the input I used in the variant calling pipe line command is different than the reference genome I used in that command? in which case, is there a way to find which reference genome was used for the creation of the input I used?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/588#issuecomment-1323439639:45,error,error,45,,https://github.com/google/deepvariant/issues/588#issuecomment-1323439639,1,['error'],['error']
Availability,"Thank’s ink1. I will try your singularity image, I have just finish build my own docker image. Le 13 mars 2018 à 13:13, ink1 <notifications@github.com<mailto:notifications@github.com>> a écrit :. I created a build script and a singularity image updating to 0.5.2 in the processes; here is my fork:; https://github.com/ink1/deepvariant/releases/tag/v0.5.2a; The binary release is the singularity image. My original image was quite large because I built everything inside of the container. Instead I resorted to the original Dockerfile which relies on pre-built zip files which my build script downloads. Still the image is 2 GB but then it should just run I presume. The changes I had to do to the Dockerfile are probably optional - my docker version does not like the lines with ARG. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/6#issuecomment-372644789>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfxQNJ8iEzMzNBFgr1bgmaUyF6v9pt7Nks5td7fxgaJpZM4Q6ZDg>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/6#issuecomment-372647046:592,down,downloads,592,,https://github.com/google/deepvariant/issues/6#issuecomment-372647046,1,['down'],['downloads']
Availability,"That paper is an early version of the code - so some things changed and some didn't. So let's parse this out:. 1) In the blog, if you look at [Jason's Jupyter notebooks](https://github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py ; https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the genera",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/197#issuecomment-512112524:383,error,error,383,,https://github.com/google/deepvariant/issues/197#issuecomment-512112524,2,['error'],['error']
Availability,"That's correct, we provide the models trained with Genome in a Bottle truth sets as part of our Docker image and also in [this directory](https://pantheon.corp.google.com/storage/browser/deepvariant/models%2FDeepVariant%2F). The truth sets are available publicly at ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/. . All of the models we provide can be used for inference for the respective data types (WGS, WES, PacBio). When running inference, you can specify which model you would like to use. You can use any one of our provided models, or you can train your own models and use those.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/324#issuecomment-658908897:244,avail,available,244,,https://github.com/google/deepvariant/issues/324#issuecomment-658908897,1,['avail'],['available']
Availability,"That's everything from the first indication of an error in the output. When I run make_examples directly, it core dumps with no stdout or stderr:; ```bash; singularity exec --bind /scratch:/tmp,/usr/lib/locale docker://google/deepvariant:1.1.0 /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples make_examples.tfrecord@24.gz --alt_aligned_pileup diff_channels --norealign_reads --vsc_min_fraction_indels 0.12 --task 0; ```. Unfortunately, this is collaborator data, so I can't share the BAM, but I checked to make sure the reference contig didn't match anything in [exclude_contigs.py](https://github.com/google/deepvariant/blob/r1.1/deepvariant/exclude_contigs.py), and the BAM was generated using our standard alignment arguments for pbmm2. I feel like it must be something obvious, but the lack of error message is making it hard to debug. Both the reference and the BAM are indexed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/419#issuecomment-774276776:50,error,error,50,,https://github.com/google/deepvariant/issues/419#issuecomment-774276776,2,['error'],['error']
Availability,"That's good, but let's go a bit slower just to be sure each individual component is working properly. I'm not sure Bazel is working properly, so let's try the following steps:. 1) Complete these last steps of `clif`:. ```; sudo mkdir -p /usr/clang/bin/; sudo ln -sf /usr/local/bin/clif-matcher /usr/clang/bin/clif-matcher; sudo mkdir -p /usr/local/clif/bin; sudo ln -sf /usr/local/bin/pyclif* /usr/local/clif/bin/; DIST_PACKAGES_DIR=$(python3 -c ""import site; print(site.getsitepackages()[0])""); sudo ln -sf ""${DIST_PACKAGES_DIR}""/clif/python /usr/local/clif/; ```. 2) Let's troubleshoot `bazel`, as `bazel` is also a bit tricky to install. First do the following:. ``sudo mv /root/.bazel /root/.bazel-orig``; ``sudo mv /root/bin/bazel /root/bin/bazel-orig``. Could you try the following steps and let me know what you see -- it would be nice to run as sudo and not as root directly:. ```; rm .bazelrc; curl -L -O https://github.com/bazelbuild/bazel/releases/download/5.3.0/bazel-5.3.0-installer-linux-x86_64.sh; chmod +x bazel-*.sh; ./bazel-5.3.0-installer-linux-x86_64.sh --user > /dev/null; ```. When you run it and launch it, it should look something like this:. ```; $ ./bazel-5.3.0-installer-linux-x86_64.sh --user > /dev/null; Extracting Bazel installation...; Starting local Bazel server and connecting to it...; $ bazel; [bazel release 5.3.0]; Usage: bazel <command> <options> ... Available commands:; analyze-profile Analyzes build profile data.; aquery Analyzes the given targets and queries the action graph.; build Builds the specified targets.; canonicalize-flags Canonicalizes a list of bazel options.; clean Removes output files and optionally stops the server.; coverage Generates code coverage report for specified test targets.; cquery Loads, analyzes, and queries the specified targets w/ configurations.; ...; ```. Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577183377:959,down,download,959,,https://github.com/google/deepvariant/issues/657#issuecomment-1577183377,2,"['Avail', 'down']","['Available', 'download']"
Availability,"The Bam file was downloaded from. ```; https://www.encodeproject.org/files/ENCFF528VXT/@@download/ENCFF528VXT.bam; ```. Then, since it was missing the @RG line, I added it manually just to test using picard:; ```; java -jar /picard.jar AddOrReplaceReadGroups I=ENCFF528VXT.bam O=ENCFF528VXT.bam RGID=4 RGLB=lib1 RGPL=illumina RGPU=unit1 RGSM=20; ```; The output of runninng; ```; samtools view -H ENCFF528VXT.bam; ```; is the following :; ```; @HD VN:1.5 SO:coordinate; @SQ SN:chr1 LN:249250621; @SQ SN:chr2 LN:243199373; @SQ SN:chr3 LN:198022430; @SQ SN:chr4 LN:191154276; @SQ SN:chr5 LN:180915260; @SQ SN:chr6 LN:171115067; @SQ SN:chr7 LN:159138663; @SQ SN:chr8 LN:146364022; @SQ SN:chr9 LN:141213431; @SQ SN:chr10 LN:135534747; @SQ SN:chr11 LN:135006516; @SQ SN:chr12 LN:133851895; @SQ SN:chr13 LN:115169878; @SQ SN:chr14 LN:107349540; @SQ SN:chr15 LN:102531392; @SQ SN:chr16 LN:90354753; @SQ SN:chr17 LN:81195210; @SQ SN:chr18 LN:78077248; @SQ SN:chr19 LN:59128983; @SQ SN:chr20 LN:63025520; @SQ SN:chr21 LN:48129895; @SQ SN:chr22 LN:51304566; @SQ SN:chrX LN:155270560; @SQ SN:chrY LN:59373566; @SQ SN:chrM LN:16571; @RG ID:4 LB:lib1 PL:illumina SM:20 PU:unit1; @PG ID:bwa PN:bwa VN:0.7.10-r789 CL:/usr/local/bin/bwa0.7.10 sampe -P reference_files/male.hg19.fa.gz ENCFF182MTO.sai ENCFF949NMY.sai ENCFF182MTO.fastq.gz ENCFF949NMY.fastq.gz; @PG ID:MarkDuplicates PN:MarkDuplicates VN:1.92() CL:net.sf.picard.sam.MarkDuplicates INPUT=[ENCFF182MTOENCFF949NMY.raw.srt.filt.srt.bam] OUTPUT=ENCFF182MTOENCFF949NMY.raw.srt.dupmark.bam METRICS_FILE=ENCFF182MTOENCFF949NMY.raw.srt.dup.qc REMOVE_DUPLICATES=false ASSUME_SORTED=true VALIDATION_STRINGENCY=LENIENT PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 READ_NAME_REGEX=[a-zA-Z0-9]+:[0-9]:([0-9]+):([0-9]+):([0-9]+).* OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 VERBOSITY=INFO QUIET=false COMPRESSION_LEVEL=5 MAX_RECORDS_I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371096675:17,down,downloaded,17,,https://github.com/google/deepvariant/issues/52#issuecomment-371096675,2,['down'],"['download', 'downloaded']"
Availability,"The Honourable Andrew and Paul.; Thank you both very much for your kind answers and advice, it will be very helpful for me in my next endeavours, Deepvariant is a very efficient and useful piece of software, thank you for all your hard work in making it available to us. I will follow your advice and read some other people's research papers. Sincere thanks again.; Cheng",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/680#issuecomment-1641247564:254,avail,available,254,,https://github.com/google/deepvariant/issues/680#issuecomment-1641247564,1,['avail'],['available']
Availability,"The TF/Cuda/cuDNN versions being used may be incompatible with your GPU. A few questions for you:. * Does the quickstart without GPU run without errors? Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; * What OS are you running on?; * Command to reproduce your issue?; * Are you able to run TF + GPU separately from DeepVariant?; * Do older versions of DeepVariant run without errors? I recommend trying 1.0.0 or 0.10.0. We recommend using the latest version for best results, but this is just for debugging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/452#issuecomment-833796921:145,error,errors,145,,https://github.com/google/deepvariant/issues/452#issuecomment-833796921,2,['error'],['errors']
Availability,"The `GLIBC` error indicates that you're running on an older operating system that DeepVariant doesn't support. The DeepVariant binaries are pre-compiled (unlike most other conda libraries, which get compiled on Centos 6 systems with an older glibc). Unfortunately this means that on older systems (like Centos <=7) they won't work. What operating system are you running it on? If you have access, it would be worth switching to a more up to date system or running on a cloud instance. Sorry for the issues and hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/252#issuecomment-568430043:12,error,error,12,,https://github.com/google/deepvariant/issues/252#issuecomment-568430043,1,['error'],['error']
Availability,"The actual error is ""The TF examples in /mnt/data/input/gs/wgs-test-shan/test_samples/UDN689484temp/examples/examples_output.tfrecord-00000-of-00064.gz has image/format \'None\' (expected \'raw\') which means you might need to rerun make_examples to genenerate the examples again."". @pichuan @depristo this is odd since the pipeline ran as a single workflow. The model and docker binary paths also seem correct. One issue I can think of is most of the shards being empty (the output has 64 shards, but it's only 1.3KB in total). Do you know if empty shards could cause such an error?. P.S. the 'gsutil not found' error is actually harmless. I think we should provide a 'parser' for these errors based on the logs that provides a meaningful error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/27#issuecomment-355032456:11,error,error,11,,https://github.com/google/deepvariant/issues/27#issuecomment-355032456,5,['error'],"['error', 'errors']"
Availability,"The bash script does bypass the python3 error, but then other missing package errors appear:; ```/opt/conda/envs/dv/bin/python /opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip --mode calling --ref /data/dpipe/rundata/refdata/hg/hg19_no_chr6_hap.fasta --reads /data/dpipe/rundata/runs/run1/NA12878/NA12878.bam --regions /data/dpipe/rundata/runs/run1/reference/CP.bed --sample_name NA12878 --examples /data/dpipe/rundata/runs/run1/dvout//NA12878.tfrecord@1.gz --task 0; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_qb8gn44e/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>; from deepvariant import make_examples_core; File ""/tmp/Bazel.runfiles_qb8gn44e/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 41, in <module>; from etils import epath; ModuleNotFoundError: No module named 'etils'; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/664#issuecomment-1593775230:40,error,error,40,,https://github.com/google/deepvariant/issues/664#issuecomment-1593775230,2,['error'],"['error', 'errors']"
Availability,"The command I ran was on version 0.10.0; `sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/input/GRCh38_latest_genomic.fna --reads=/input/SOL235_sorted.bam --regions ""NC_000007.14"" --output_vcf=/output/SOL235output.vcf.gz --output_gvcf=/output/SOL235output.g.vcf.gz --num_shards=1 \ `. I am running deep variant on MacOS Catalina Version 10.15.4 (19E287); Attached you'll find the full dump of the terminal from running the above command all the way until it errors out. Thanks for your help!; [DeepVariantDump.log](https://github.com/google/deepvariant/files/4545525/DeepVariantDump.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/304#issuecomment-620560432:577,error,errors,577,,https://github.com/google/deepvariant/issues/304#issuecomment-620560432,1,['error'],['errors']
Availability,"The command and error attached here in full, just in case that is needed to debug the problem.; [build_and_test_errors.txt](https://github.com/google/deepvariant/files/1670326/build_and_test_errors.txt)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/43#issuecomment-360999837:16,error,error,16,,https://github.com/google/deepvariant/issues/43#issuecomment-360999837,1,['error'],['error']
Availability,"The command for installing DeepVariant? . `singularity build DeepVariant_1.6.1.sif docker://google/deepvariant:1.6.1`. Or the full command that is written to stdout when DeepVariant runs? For this latter case, after installing nucleus the full command for deepvariant is not written to output. The last line of output is `KeyError: 'SerializedDType'`. I dont have the output saved from the test data run to retrieve the full command output with the error prior to installing nucleus as user, and will re-run that and update this comment with it in a few hours. I did, however, get the same error attempting to run deepvariant with my own data (prior to installing nucleus as user), and the output and command from that are below:. ```; for bam in $READS; do; 	echo ""running deepvariant on $bam""; 	run_deepvariant --model_type=PACBIO --ref=$REF --reads=$bam --output_vcf=$OUTDIR/$bam.vcf.gz --output_gvcf=$OUTDIR/$bam.g.vcf.gz --logging_dir=$LOGDIR --num_shards=$CORES; 	echo ""finished with $bam""; done. #output in block comment below. # running deepvariant on /work/cjm124/SWFst/VarCalling/reads/bc2001_aligned_sorted.bam; # 2024-04-23 11:42:51.281492: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; # To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; # I0423 11:42:57.943745 140073410221888 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpkmab_2kw. # ***** Intermediate results will be written to /tmp/tmpkmab_2kw in docker. ****. # ***** Running the command:*****; # time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/work/cjm124/SWFst/lvar3ref/Lvar_scaffolds.fasta"" --reads ""/work/cjm124/SWFst/VarCalling/reads/bc2001_aligned_sorted.bam"" --examples ""/tmp/tmpkmab_2kw/make_example",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/812#issuecomment-2075116946:449,error,error,449,,https://github.com/google/deepvariant/issues/812#issuecomment-2075116946,4,"['echo', 'error']","['echo', 'error']"
Availability,The error comes from the line `output_queue = multiprocessing.Queue()`; Could you try a simple test? ; Run docker in CLI model: `docker run -it <DeepVariant image> bash`; Inside docker start Python3 and execute:; ```; import multiprocessing; q = multiprocessing.Queue(); ```; Please let us know if that works.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/733#issuecomment-1816864777:4,error,error,4,,https://github.com/google/deepvariant/issues/733#issuecomment-1816864777,2,['error'],['error']
Availability,"The error message says ""Cannot query without an index"", so I'm guessing your CRAM file might be missing its index too. See: http://www.htslib.org/doc/samtools-index.html; Again see the [documentation](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details.md).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/307#issuecomment-628240247:4,error,error,4,,https://github.com/google/deepvariant/issues/307#issuecomment-628240247,1,['error'],['error']
Availability,The error messages sounds like it's not seeing your fasta index file. Since you are utilizing environment variables I would suggest verifying that those are accurate and that both your fasta and it's corresponding index file are present in that same directory.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/310#issuecomment-636143865:4,error,error,4,,https://github.com/google/deepvariant/issues/310#issuecomment-636143865,1,['error'],['error']
Availability,"The error reported in the `docx` file is:. ```; I1219 05:41:37.963743 139694699493120 call_variants.py:338] Shape of input examples: [100, 221, 9]; 2023-12-19 05:41:37.985946: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-12-19 05:41:38.002687: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz; 2023-12-19 05:41:38.008172: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c08e10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:; 2023-12-19 05:41:38.008269: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version; 2023-12-19 05:41:38.008459: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpz9j4xfvf; W1219 05:41:38.122338 139694699493120 estimator.py:1844] Using temporary folder as model directory: /tmp/tmpz9j4xfvf; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpz9j4xfvf', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_mas",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/757#issuecomment-1864800013:4,error,error,4,,https://github.com/google/deepvariant/issues/757#issuecomment-1864800013,1,['error'],['error']
Availability,The error suggests that you don't have enough CPU quota in the us-central region. You need at least 16 CPUs for the quickstart job. Please see https://cloud.google.com/compute/quotas for how to request more quota.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/60#issuecomment-375321687:4,error,error,4,,https://github.com/google/deepvariant/issues/60#issuecomment-375321687,1,['error'],['error']
Availability,The full content of that data is not publicly available. There are additional datasets available at the Genome in a Bottle FTP. These include:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. which represents the BAM file used in our case study evaluation. This data is used for training (excluding chr20 for evaluation). And HG005 - ; ; ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/ChineseTrio/HG005_NA24631_son/PacBio_SequelII_CCS_11kb/. And HG001/NA12878 -. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/PacBio_SequelII_CCS_11kb/. The above files for HG001 and HG005 are not used for training or evaluation of DeepVariant at this time.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/201#issuecomment-517517472:46,avail,available,46,,https://github.com/google/deepvariant/issues/201#issuecomment-517517472,2,['avail'],['available']
Availability,The functionality has been implemented in the internal codebase and will be available in the next release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/334#issuecomment-675909928:76,avail,available,76,,https://github.com/google/deepvariant/issues/334#issuecomment-675909928,1,['avail'],['available']
Availability,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling.; By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/536#issuecomment-1106635811:300,down,downsampling,300,,https://github.com/google/deepvariant/issues/536#issuecomment-1106635811,2,['down'],['downsampling']
Availability,"The issue stems from a mismatch between the set of channels the model was trained on and the channels in the examples generated during `run_deepvariant`. The important bit in the logs you posted is:; ```; From /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_output/training_dir_test2/checkpoints/ckpt-58/example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6].; I0327 22:12:15.248034 139725850806080 dv_utils.py:365] From /local/scratch/haley.arnold/14698718/tmpg5h0cte0/make_examples.tfrecord-00000-of-00001.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; W0327 22:12:15.248203 139725850806080 call_variants.py:541] Input shape [100, 221, 7] and model shape [100, 221, 6] does not match.; W0327 22:12:15.248327 139725850806080 call_variants.py:549] Input channels [1, 2, 3, 4, 5, 6, 19] and model channels [1, 2, 3, 4, 5, 6] do not match.; ```. Your customized model was trained on `[1, 2, 3, 4, 5, 6]` (the `BASE_CHANNELS`) but the examples in `make_examples.tfrecord-00000-of-00001.gz` have an extra channel, 19 (`insert_size`), which gets [added to the WGS model preset](https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L369). . You can either:; a) include `--channels ""insert_size""` when [generating the training data](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#training-set); b) don't set `--model_type WGS` when you call `run_deepvariant` (which you may not need to do regardless if you provide a `customized_model`). . The choice comes down to if you want to include the channel or not. Experiments have shown it provides a slight accuracy boost for WGS, but its not strictly necessary.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2027543371:304,checkpoint,checkpoints,304,,https://github.com/google/deepvariant/issues/797#issuecomment-2027543371,2,"['checkpoint', 'down']","['checkpoints', 'down']"
Availability,The number is referring to the number of steps in training when this checkpoint is saved.; You can see https://www.tensorflow.org/guide/checkpoints for more information.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/192#issuecomment-506979241:69,checkpoint,checkpoint,69,,https://github.com/google/deepvariant/issues/192#issuecomment-506979241,4,['checkpoint'],"['checkpoint', 'checkpoints']"
Availability,"The previous one was download link, if you want to see it on the web:. https://s3-us-west-2.amazonaws.com/human-pangenomics/index.html?prefix=submissions/3b9be4f8-a269-4f89-ab9c-a0a0b0a10af6--UCSC_HG002_R1041_nanopore/HG002_Sheared_R1041/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/821#issuecomment-2111109348:21,down,download,21,,https://github.com/google/deepvariant/issues/821#issuecomment-2111109348,1,['down'],['download']
Availability,The same error happens with `google/deepvariant:1.0.0`,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/354#issuecomment-695943329:9,error,error,9,,https://github.com/google/deepvariant/issues/354#issuecomment-695943329,1,['error'],['error']
Availability,"The short answer is yes. That's because that parameter gets fed to `prepare_inputs()`, which generates a `DeepVariantInput` object that generates a `tf.data.Dataset`, which gets fed in your case into an [`Estimator`](https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L415-L419) it constructs for you, that will then will be processed via `predict()` which sets up a [`MonitoredSession`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L595) which by default each Session is thread-safe. I believe the rest get used to monitor the sessions, but I would need to double-check on that. Turtles all the way down :). Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/105#issuecomment-430634265:670,down,down,670,,https://github.com/google/deepvariant/issues/105#issuecomment-430634265,1,['down'],['down']
Availability,"There should be a longer error trace coming from DeepVariant itself, which will be more informative than just the exit status code. Can you share that? If you need to, you can email me at marianattestad@google.com.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/305#issuecomment-623601298:25,error,error,25,,https://github.com/google/deepvariant/issues/305#issuecomment-623601298,1,['error'],['error']
Availability,"They’re being copied to the local machine actually!. Sent from my iPhone. > On Mar 25, 2019, at 11:29 PM, Pi-Chuan Chang <notifications@github.com> wrote:; > ; > @ekofman One question for you -- did you get this error when you directly specifying gs:// in your command?; > If so, can you try another run where you copy those files to your local machine first (and point to a local machine)? I know that we should (in theory) be able to read from GCS bucket because htslib should support it, but I have not done that much in the past, so I don't know how reliable it is.; > Thank you!; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/164#issuecomment-476601971:212,error,error,212,,https://github.com/google/deepvariant/issues/164#issuecomment-476601971,2,"['error', 'reliab']","['error', 'reliable']"
Availability,"This directory here contains `dockerfile` and other files that need to be `ADD` to the image; ![image](https://user-images.githubusercontent.com/25972546/33970607-df14b3b2-e0ae-11e7-8aea-0509ae0c9c61.png); `docker build -f dockerfile -t deepvariant_1214 .`; `Successfully built b829b45a9401`. This directory contains the deepvariant `models` and `quickstart-testdata` files downloaded from [https://console.cloud.google.com/storage/browser/deepvariant](url); ![image](https://user-images.githubusercontent.com/25972546/33970996-1a4e378a-e0b1-11e7-8852-9b63cb477f47.png); `docker run --name deepvariant_test_1214 -v /***/bioinfo/wangwd/workflow/deepvariant/data:/data -it b829b45a9401 /bin/bash`; Then I `cd /opt/deepvariant/bin/`; ![image](https://user-images.githubusercontent.com/25972546/33971209-4789bc8c-e0b2-11e7-833c-95f440712240.png); `./make_examples \; --mode calling \; --ref /data/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \; --reads /data/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --examples /data/quickstart-output/examples.tfrecord.gz`; When I finished executing this command, I did not get any result.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/16#issuecomment-351583972:374,down,downloaded,374,,https://github.com/google/deepvariant/issues/16#issuecomment-351583972,1,['down'],['downloaded']
Availability,This error is most likely due to the corrupted tf records file which is the output of call_variants step. In your set up the intermediate results are dumped into /tmp. Could it be that you ran multiple instances of deepvariant simultaneously with the same output directory?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/548#issuecomment-1194463806:5,error,error,5,,https://github.com/google/deepvariant/issues/548#issuecomment-1194463806,1,['error'],['error']
Availability,"This error might be caused by missing base quality scores in the BAM file, were you expecting this?; DeepVariant does require valid base quality scores. You could technically use filler values, but DeepVariant was only trained with real base qualities, so the results will be much more reliable and accurate if you can get a BAM file with real base quality scores.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/396#issuecomment-743387975:5,error,error,5,,https://github.com/google/deepvariant/issues/396#issuecomment-743387975,2,"['error', 'reliab']","['error', 'reliable']"
Availability,This error suggests you didn't properly pass the ref flag: . ```; E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required.; ```. One potential reason: `Downloads` is not being mounted within the image. The `-v` and `-w` flags do not mount the entire filesystem. Try moving Homo_sapiens.GRCh38.dna.alt.fa to your working directory.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1302738730:5,error,error,5,,https://github.com/google/deepvariant/issues/581#issuecomment-1302738730,3,"['Down', 'error']","['Downloads', 'error', 'errors']"
Availability,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1655336903:315,error,error,315,,https://github.com/google/deepvariant/issues/682#issuecomment-1655336903,1,['error'],['error']
Availability,"This is probably causing the issues `--call_variants_extra_args=""use_openvino=true""` as openvino is not currently supported (#541) and throws the same error you see here. Running without that extra arg should then work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/574#issuecomment-1277975462:151,error,error,151,,https://github.com/google/deepvariant/issues/574#issuecomment-1277975462,1,['error'],['error']
Availability,"This is very good! . #### For Singularity . You can take a look at the following two links:. https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-quick-start.md#notes-on-singularity. https://github.com/google/deepvariant/blob/r1.5/scripts/install_singularity.sh. #### For your Ubuntu instance . You are getting very close! To simplify the install in the `run-prereq.sh` file you can comment out (with the `#` symbol) the following sections:. 1) For the ""Install TensorFlow pip package"" keep only the ones with **CPU-only**, and comment out the others. 2) For ""Install CUDA"", comment out everthing. 3) For ""Install TensorRT"", comment out everthing. And then run it again. The rest of the errors in the `run-prereq.sh` are easy to fix, which we can do later individually by removing each one, and installing the minimum required version. Before we fix `clif`, could you tell me what you get for the following:. ```; lsb_release -sc. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - . add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". sudo apt-get update. sudo apt-get install -y llvm-11 llvm-11-dev clang-11 llvm-11-tools; ```. You might have a mismatch of a previous version of `clif` or its installed configuration files. You can check that via the following commands:. ```; llvm-config-11 --version; ```. The configs might be an older version, which you can check via the following:. ```; cat /usr/lib/llvm-11/lib/cmake/llvm/LLVMConfig.cmake | grep PACKAGE_VERSION; ```. Below is what I have:. ```; $ cat /usr/lib/llvm-11/lib/cmake/llvm/LLVMConfig.cmake | grep PACKAGE_VERSION; set(LLVM_PACKAGE_VERSION 11.1.0); $ cat /usr/lib/llvm-11/cmake/LLVMConfig.cmake | grep PACKAGE_VERSION; set(LLVM_PACKAGE_VERSION 11.1.0); $ cat /lib/llvm-11/cmake/LLVMConfig.cmake | grep PACKAGE_VERSION; cat: /lib/llvm-11/cmake/LLVMConfig.cmake: No such file or directory; $; ```. If you have a mismatch between the version and config,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575894236:696,error,errors,696,,https://github.com/google/deepvariant/issues/657#issuecomment-1575894236,2,['error'],['errors']
Availability,"This looks like an OS error. Also, it looks like the error is raised while building the model graph `backbone = add_l2_regularizers`. Could it be that you ran out of RAM?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/725#issuecomment-1791833776:22,error,error,22,,https://github.com/google/deepvariant/issues/725#issuecomment-1791833776,2,['error'],['error']
Availability,"This question is complex enough that it cuts to some of the fundamental issues of VCF. I expect that across the community, opinions will differ as to whether this represents troubling inconsistency as opposed to a strange edge case. The heart of this question is whether people will tend to interpret a 0/1 as ""I have evidence for a reference allele and evidence for the 1st alternate allele"" or as ""I have evidence for one copy of the ALT allele but for one non-REF position"". This could be fully expressed with REF: CATTA || ALT: C, CAGTA || GT: 1/2. I expect that the majority of programs don't do this sort of normalization, and I expect the majority of downstream tools operate in a way that doesn't assume that the two lines you post introduce inconsistency (that is most probably assume ""REF"" more like ""Evidence for at least one copy that is non-ALT, other lines may clarify if an additional non-REF allele is present). However, if you want to dig into this question further, I would encourage you to ask on one of the GA4GH forums about variant representations. I don't consider myself knowledgable enough to give definitive statements on edge cases like this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/247#issuecomment-563063086:658,down,downstream,658,,https://github.com/google/deepvariant/issues/247#issuecomment-563063086,1,['down'],['downstream']
Availability,"This was really puzzling me, so I started with a smallest possible reproducible setting and started debugging. . Now I understand why the results are different. . This update will be about the technical explanation of why different number of shards result in different result:. This is because when we're processing reads in a region, we (by default) first do a sampling of the reads down to `max_reads_per_partition` (default=1500) reads. Here is the code snippets that does that:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L842-L844. ```; if self.options.max_reads_per_partition > 0:; reads = utils.reservoir_sample(; reads, self.options.max_reads_per_partition, self.random); ```. This was originally an optimization for speed. A while ago we noticed that some regions in the genome took really long time to create examples. And this is because some regions have a lot of reads piled up.; Because of the way that germline DeepVariant is set up, the final pileup image has only a image height of 100 anyway, so we don't really need to process all the reads. But at this stage we still need to go through the realigner step later, so we decided to sample enough reads here so that the following steps can still use more information, but we cut off at the number of `max_reads_per_partition` (default=1500) reads. The randomization here is done with `self.random`, which is initialize with the same seed at the beginning. Because the seed is the same at the beginning, we're able to generate deterministic and reproducible results if you fix the number of tasks. However, when you run make_examples with different number of tasks, that means each task has its own `self.random`. Even though each of them started with the same seed, when you have different number of tasks(shards), these RandomState ends up progressing differently. This means when you look at a same region in two different runs (for example, I was looking at `20:3208913-3209912` in the exome), the",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/112#issuecomment-433598823:384,down,down,384,,https://github.com/google/deepvariant/issues/112#issuecomment-433598823,1,['down'],['down']
Availability,"This worked but now another problem appeared that seems to be related to this one. Seems the samtools index does not work:. Current thread 0x00007f283e6c9740 (most recent call first):; File ""/tmp/Bazel.runfiles_qz56zi29/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 976 in _make_allele_counter_for_region; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2023-06-21 07:21:53.632147: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""1"" start: 2295000 end: 2330000; Fatal Python error: Aborted. ```; Current thread 0x00007fe7f6689740 (most recent call first):; File ""/tmp/Bazel.runfiles_tfz52rn8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 976 in _make_allele_counter_for_region; File ""/tmp/Bazel.runfiles_tfz52rn8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1548 in candidates_in_region; File ""/tmp/Bazel.runfiles_tfz52rn8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1318 in process; File ""/tmp/Bazel.runfiles_rexajgra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 976 in _make_allele_counter_for_region; File ""/tmp/Bazel.runfiles_rexajgra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1548 in candidates_in_region; File ""/tmp/Bazel.runfiles_rexajgra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1318 in process; File ""/tmp/Bazel.runfiles_rexajgra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2183 in make_examples_runner; File ""/tmp/Bazel.runfiles_rexajgra/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186 in main; File ""/tmp/Bazel.runfiles_rexajgra/runfiles/absl_py/absl/app.py"", line 258 in _run_main; File ""/tmp/Bazel.runfiles_rexajgra/runfiles/absl_py/absl/app.py"", line 312 in run; File ""/tmp/Bazel.runfiles_rexajgra/runfiles/com_google_deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1600094995:612,error,error,612,,https://github.com/google/deepvariant/issues/666#issuecomment-1600094995,1,['error'],['error']
Availability,"To make it clearer, I put the path structure here.; ```; /deepvariant/core/; cloud_utils_test.py; math.py; ...; ```; And in `cloud_utils_test.py`:; ```; """"""Tests for deepvariant .core.cloud_utils."""""". from __future__ import absolute_import; from __future__ import division; from __future__ import print_function. import httplib; ...; ```; Through `httplib`, it imports `mimetools`, which imports `tempfile`, which imports `ramdom`, which imports `math`. ; But since there is a `math.py` in the same path, it shadows the `math` module in python's standard library, causing an error. To test the hypothesis, simply importing `httplib` in the same path caused the following error:; ```; >>> import httplib; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""xx/anaconda/envs/Python27/lib/python2.7/httplib.py"", line 80, in <module>; import mimetools; File ""xx/anaconda/envs/Python27/lib/python2.7/mimetools.py"", line 6, in <module>; import tempfile; File ""xx/anaconda/envs/Python27/lib/python2.7/tempfile.py"", line 35, in <module>; from random import Random as _Random; File ""xx/anaconda/envs/Python27/lib/python2.7/random.py"", line 45, in <module>; from math import log as _log, exp as _exp, pi as _pi, e as _e, ceil as _ceil; ***File ""math.py"", line 79, in <module>***; import numpy as np; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>; from . import add_newdocs; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/add_newdocs.py"", line 13, in <module>; from numpy.lib import add_newdoc; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/lib/__init__.py"", line 8, in <module>; from .type_check import *; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/lib/type_check.py"", line 11, in <module>; import numpy.core.numeric as _nx; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/core/__init__.py"", line 74, in <module>; from numpy.testing.nosetester impo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/32#issuecomment-355522771:575,error,error,575,,https://github.com/google/deepvariant/issues/32#issuecomment-355522771,4,['error'],['error']
Availability,Update:; I can confirm that I'm able to reproduce your error. We're working on a fix. Stay tuned!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-388450895:55,error,error,55,,https://github.com/google/deepvariant/issues/62#issuecomment-388450895,1,['error'],['error']
Availability,"Updating my previous response a bit. Could you share the output of the two echo commands below? I want to make sure there aren't any subtle differences with how quoting is done between both sets of commands. I don't immediately see what else could be causing this issue. Thanks!. ```; BIN_VERSION=""1.0.0""; INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". echo ""singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1"". echo ""singularity -s exec --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \; --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz""; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/402#issuecomment-757012167:75,echo,echo,75,,https://github.com/google/deepvariant/issues/402#issuecomment-757012167,3,['echo'],['echo']
Availability,"Versions; - singularity version 3.6.4-1.el7; - CentOS Linux release 7.9.2009; - Kernel: Linux 3.10.0-1160.6.1.el7.x86_64. The command I was running has some differences in the singularity setup, as I had to explicitly bind the scratch directory etc on the compute nodes. When running the command that **did** work for you, I get the following error immediately `OSError: [Errno 30] Read-only file system: '/output'`, due to the binding issue.; ; ```; singularity run -B ${INPUT}:/input,${OUTPUT}:/output,${OUTPUT}/intermediate_results_dir:/output/intermediate_results_dir,$TMPDIR:$TMPDIR \; deepvariant_1.1.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type ""PACBIO"" \; --ref /input/asm.fasta \; --reads /input/hifi.bam \; --output_vcf /output/asm.output.vcf.gz \; --output_gvcf /output/asm.output.g.vcf.gz \; --num_shards ""${THREADS}"" \; --call_variants_extra_args ""use_openvino=true"" \; --intermediate_results_dir /output/intermediate_results_dir; ```. This correctly makes the examples and saves the results to the *intermediate_results_dir*, the error happens at the start of call_variants, when the openvino model wants to write to the read-only container. I tried making a `models/pacbio` file and dowloaded the ckpt files, and then made a bind to `opt/models/pacbio/`, but also same error on the read only system. I've also tried running the `bin/call_variants` command from the login nodes and ran into the same error, which was surprising as I have write permissions to more locations on those nodes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-762181198:343,error,error,343,,https://github.com/google/deepvariant/issues/404#issuecomment-762181198,4,['error'],['error']
Availability,"Very awesome - forgot about that - thanks Cory! Just realized that the docs point to the old version (i.e. [Exome CS prelims](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-exome-case-study.md#preliminaries), [Whole Genome prelims](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md#preliminaries), [Quick Start prereqs](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-quick-start.md#download-the-deepvariant-binaries-and-install-prerequisites), etc.) in case new users git-clone. thx,; `p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/57#issuecomment-371635934:447,down,download-the-deepvariant-binaries-and-install-prerequisites,447,,https://github.com/google/deepvariant/pull/57#issuecomment-371635934,1,['down'],['download-the-deepvariant-binaries-and-install-prerequisites']
Availability,"Vini, Paul and Pi-Chuan;; Thanks much for the ping about updating the conda recipe. This is now synced to the latest release (0.7.0) so you can use that as a backup option in addition to your work on getting it built on 18.04. Please let me know if you run into any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/98#issuecomment-425452266:46,ping,ping,46,,https://github.com/google/deepvariant/issues/98#issuecomment-425452266,1,['ping'],['ping']
Availability,"WWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']; Traceback (most recent call last):; File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>; run(); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run; _run_call_variants(pipeline_args); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants; result.get(); File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get; raise self._value; RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]].; (exit status 1); ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/70#issuecomment-387564029:1932,checkpoint,checkpoint,1932,,https://github.com/google/deepvariant/issues/70#issuecomment-387564029,4,"['Error', 'checkpoint', 'error']","['Error', 'checkpoint', 'error']"
Availability,"Was this issue fixed? I'm having the same error:; ```; [E::cram_decode_slice] MD5 checksum reference mismatch at #1:248741259-248759777; [E::cram_decode_slice] CRAM: 857e35c22e237f102003142abf430800; [E::cram_decode_slice] Ref : 550702c7390d3ead48df01da66f85854; [E::cram_next_slice] Failure to decode slice; Traceback (most recent call last):; File ""/state/partition1/job-44859747/Bazel.runfiles_warfxbvu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1817, in region_reads_norealign; reads = reservoir_sample_reads(; File ""/state/partition1/job-44859747/Bazel.runfiles_warfxbvu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 976, in reservoir_sample_reads; return utils.reservoir_sample(iterable_of_reads, k, random); File ""/state/partition1/job-44859747/Bazel.runfiles_warfxbvu/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 117, in reservoir_sample; for i, item in enumerate(iterable):; File ""/state/partition1/job-44859747/Bazel.runfiles_warfxbvu/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 95, in __next__; record, not_done = self._raw_next(); File ""/state/partition1/job-44859747/Bazel.runfiles_warfxbvu/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 154, in _raw_next; not_done = self._cc_iterable.PythonNext(record); ValueError: DATA_LOSS: Failed to parse SAM record; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/741#issuecomment-2028785168:42,error,error,42,,https://github.com/google/deepvariant/issues/741#issuecomment-2028785168,2,"['Failure', 'error']","['Failure', 'error']"
Availability,"We are pretty certain this is due to the same bug noted in https://github.com/google/deepvariant/issues/7. We have a fix already internally and will make it available as soon as possible. In the meantime, if you *need* this to work you can follow the same trick of commenting out the call to `token = cloud_utils.oauth2_token()` and replacing it with `token = None`. Sorry about that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/14#issuecomment-351176839:157,avail,available,157,,https://github.com/google/deepvariant/issues/14#issuecomment-351176839,1,['avail'],['available']
Availability,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****; time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s; user 0m0.767s; sys 0m0.949s; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-482956117:210,error,error,210,,https://github.com/google/deepvariant/issues/132#issuecomment-482956117,1,['error'],['error']
Availability,"We have done those approaches, except for methylation maybe (not sure about that one). The main issue if we have a diploid genome, with a high heterozygosity, which leads to mapping scoring errors, as well as some callers totally losing their minds.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658811104:190,error,errors,190,,https://github.com/google/deepvariant/issues/682#issuecomment-1658811104,1,['error'],['errors']
Availability,"We have previously highlighted two examples where DeepVariant has been applied in non-human organisms:. * [Rice](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant) - are diploid and have similar variant density to humans with short-read data. The existing model worked well.; * [Mosquitos](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) - Used a retrained model to account for high variant density with short-read data. With mosquitos we found that our human-trained model had high numbers of false positive calls. This is likely because in humans increased variant density is often caused by mismapping of similar genomic regions, leading DeepVariant to not call what are likely artifactual variants (in humans). But in mosquitos, we variant density is much higher, so DV falsely discards what are real variants. Fortunately, zebrafish appear to have similar SNP densities with humans, and the fact you are using PacBio HiFi reads may also reduce variant-density issues. However, there are a number of factors that may contribute to poor performance: The specific strains being experimented with, regions of the genome being evaluated, differences in structural variation, coverage, etc. We would expect the DV human model to perform well in zebrafish, but it would be a good idea to estimate the error rate through a mendelian analysis, Sanger sequencing, or other methods to determine whether retraining is needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/415#issuecomment-771074189:1445,error,error,1445,,https://github.com/google/deepvariant/issues/415#issuecomment-771074189,1,['error'],['error']
Availability,"We now have an custom wheel for `intel-tensorflow==1.13.1` which fixes the above the installation issue. If you are seeing the error above, please make the following changes in [`run-prereq.sh`](https://github.com/google/deepvariant/blob/r0.9/run-prereq.sh). Replace [line 146](https://github.com/google/deepvariant/blob/r0.9/run-prereq.sh#L146) with the following:; ```; WHEEL_NAME=tensorflow-1.13.1-cp27-cp27mu-linux_x86_64.whl; curl ""https://storage.googleapis.com/penporn-kokoro/tf-mkl-1.13.1-py27/${WHEEL_NAME}"" > ""/tmp/${WHEEL_NAME}""; pip install ""${PIP_ARGS[@]}"" --upgrade ""/tmp/${WHEEL_NAME}""; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/263#issuecomment-577940658:127,error,error,127,,https://github.com/google/deepvariant/issues/263#issuecomment-577940658,1,['error'],['error']
Availability,"We're consulting with our teammate @ThomasColthurst to see if he has anything to add here about your error message. In the past, I did try building with both Ubuntu 14 and 18 and didn't encounter such issue, but I have not done so recently. I'll try soon. And bazel - I think 0.21 is the right version we're using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/199#issuecomment-514424604:101,error,error,101,,https://github.com/google/deepvariant/issues/199#issuecomment-514424604,1,['error'],['error']
Availability,"We've started testing DeepVariant on a machine with 128 cores from AMD. Setting --num_shards=$(nproc) results in this error:. > OpenBLAS blas_thread_init: RLIMIT_NPROC 4096 current, 8254915 max; > OpenBLAS blas_thread_init: pthread_create failed for thread 63 of 64: Resource temporarily unavailable. It seems to create way more threads than the machine can handle. Setting num_shards=40 will work on the AMD machine, but the number of shards it creates is variable and much more than 40. I've seen 81, 116, and 101 intermediate shards created. From what I remember, in all our previous usage on machines with 40 cores or less the number of shards always matched the number of cores when using num_shards=$(nproc). The AMD machine with num_shards=40 also runs much slower compared to our Skylake machines with 40 cores and num_shards=$(nproc). The AMD machine takes over 7 hours per WGS file compared to less then 5 hours with the Skylake machine. It looks like when we try to run on the AMD machine it creates 2x as many tasks than available processors which might explain the slowdown.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/274#issuecomment-597715853:118,error,error,118,,https://github.com/google/deepvariant/issues/274#issuecomment-597715853,2,"['avail', 'error']","['available', 'error']"
Availability,"Well, why do you want those events to be non random? . In nature they seem to do this; https://www.nature.com/articles/s41467-020-19614-y. In lab we see them do that ; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9710870/. Random breaks during their meiosis and subsequent repair might have generated sublonces in the petri dish.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1655361098:273,repair,repair,273,,https://github.com/google/deepvariant/issues/682#issuecomment-1655361098,1,['repair'],['repair']
Availability,"What OS & version are you running? (i.e., what is the output of uname -a ?). This error frequently shows up when using something other than Ubuntu 16. -Thomas C. On Fri, Dec 22, 2017 at 8:50 PM, Zihua Liu <notifications@github.com> wrote:. > When I run make-example.zip, the error shows up... Please fix it for me ;-; > ); >; > ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version; > `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/; > runfiles/protobuf_archive/python/google/protob; > uf/pyext/_message.so); >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/22>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AWascfGSdQRRp6h7WGfqGo2Co-d5DjRhks5tDFxxgaJpZM4RLiml>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/22#issuecomment-353700244:82,error,error,82,,https://github.com/google/deepvariant/issues/22#issuecomment-353700244,2,['error'],['error']
Availability,"What is the coverage, approximately? DeepVariant's pileup images can only really fit ~100 reads at each locus, but if you have very high coverage that could cause it to use a lot of memory. Downsampling in that case to about 100X would help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/614#issuecomment-1440666950:190,Down,Downsampling,190,,https://github.com/google/deepvariant/issues/614#issuecomment-1440666950,1,['Down'],['Downsampling']
Availability,What is the value of your ${INPUT_DIR} and ${OUTPUT_DIR} ? What is the output of ; echo $INPUT_DIR,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/262#issuecomment-574898473:83,echo,echo,83,,https://github.com/google/deepvariant/issues/262#issuecomment-574898473,1,['echo'],['echo']
Availability,"When I copy pasted your command, it was split up into two commands, with the `--ref` onwards showing up as a separate command. Could you try the following? This should show up as one command and you should no longer see the error. ```; BAMName=""VK446chrYx19""; INPUT_DIR=""${PWD}/""; OUTPUT_DIR=""${PWD}/${BAMName}_dv"". docker run \; -v ""${INPUT_DIR}:/input"" \; -v ""${OUTPUT_DIR}:/output"" \; google/deepvariant:""1.0.0"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/Hg19ChrY.fa \; --reads=/input/${BAMName}.bam \; --output_vcf=/output/${BAMName}.vcf.gz \; --output_gvcf=/output/${BAMName}.g.vcf.gz \; --num_shards=24; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/390#issuecomment-737431101:224,error,error,224,,https://github.com/google/deepvariant/issues/390#issuecomment-737431101,1,['error'],['error']
Availability,"When you refer to the method GATK has to incorporate known variants for quality control, I believe that you are referring to VQSR (variant quality score recalibrator). You are correct that this requires a set of ground truth information. It seems likely to me that VQSR and similar systems would not behave correctly on bacterial data even if ground truth were available. To understand whether events are false positives or real SNPs, I think you will want to get some orthogonal measure of whether they are accurate. It probably makes sense to look at the reads data for some of these sites in a tool like IGV to get a feel for whether they look reliable or not. One nice thing about DeepVariant is that the quality scores for variants calls are generally normally distributed and predict the human variant quality confidence quite well. One approach you can take is to see what the distribution of DeepVariant quality scores is for the variants you know are real and see whether the new variants have a similar confidence distribution.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/114#issuecomment-436379034:361,avail,available,361,,https://github.com/google/deepvariant/issues/114#issuecomment-436379034,2,"['avail', 'reliab']","['available', 'reliable']"
Availability,"While AWS was better than my local computer (with 8 GB of RAM and 4 cores) for running the 1st step (_make_examples_), I can likewise try running the Docker container in interactive mode on my own computer:. `docker run -it -v /c/Users/Charles/Documents/WGS_Exome_Analysis/My_Veritas_WGS:/mnt/wgs gcr.io/deepvariant-docker/deepvariant`. followed by moving to the appropriate directory and running the following script:. ```; OUTPUT_DIR=Genos_Provided; REF=../hg19.gatk.fasta. CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz""; FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \; --ref ""${REF}"" \; --infile ""${CALL_VARIANTS_OUTPUT}"" \; --outfile ""${FINAL_OUTPUT_VCF}""; ```. This is different than running interactive mode for **postprocess_variants** on AWS (which almost immediately ends, without error message or results file), but it has been running for more than one hour. So, I will provide an update if this works, but this sounds different than your experience with the t1.micro AWS instance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480640009:858,error,error,858,,https://github.com/google/deepvariant/issues/167#issuecomment-480640009,1,['error'],['error']
Availability,"Yes @pichuan, the intermediate output will be under `/DATA/transfer/deepvariant_tmp`. But the same `no space left` error will pop up. And if I set `tmp/`, then no this error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/296#issuecomment-767223258:115,error,error,115,,https://github.com/google/deepvariant/issues/296#issuecomment-767223258,4,['error'],['error']
Availability,"Yes, I have a GPU. I've made it work with. ```; gcr.io/deepvariant-docker/deepvariant_gpu:0.7.0; ```. But it pops out the `libcublas.so.9.0` related error with my own built (following instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972). ```; gcr.io/my_project/deepvariant_gpu:0.7.2; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/102#issuecomment-429143561:149,error,error,149,,https://github.com/google/deepvariant/issues/102#issuecomment-429143561,1,['error'],['error']
Availability,"Yes, I was having the same issue using the old version 0.4.1, when I change to 0.5.1:; ```; gcr.io/deepvariant-docker/deepvariant:0.5.1; ```. I get this error instead:; ```; WARNING: Logging before flag parsing goes to stderr.; W0307 21:19:10.482634 140039107020544 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib; W0307 21:19:10.488955 140039107020544 call_variants.py:299] Unable to read any records from shardedExamples/examples.tfrecord@64.gz. Output will contain zero records.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/call_variants.py"", line 391, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run; _sys.exit(main(_sys.argv[:1] + flags_passthrough)); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/call_variants.py"", line 382, in main; batch_size=FLAGS.batch_size); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/call_variants.py"", line 317, in call_variants; predictions = model.create(images, 3, is_training=False)['Predictions']; File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/modeling.py"", line 360, in create; images, num_classes, create_aux_logits=False, is_training=is_training); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/org_tensorflow_slim/nets/inception_v3.py"", line 483, in inception_v3; depth_multiplier=depth_multiplier); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/org_tensorflow_slim/nets/inception_v3.py"", line 104, in inception_v3_base; net = slim.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 181, in func_with_args; return func(*args, **current_args); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1011, in convolution; input_rank); ValueError: ('Co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371288942:153,error,error,153,,https://github.com/google/deepvariant/issues/52#issuecomment-371288942,1,['error'],['error']
Availability,"Yes, if you use `run_deepvariant` (which is a wrapper for the 3 separate steps), the `*_extra_args` flags are just a more flexible way to allow you specify flags for each step. ; In `run_deepvariant`, we hard-coded some of the commonly used flags but not all of them. For example, you can't directly specify `--ws_use_window_selector_model` to `run_deepvariant`.; We thought people might eventually have use cases for all other less known flags. (Which is why the `*_extra_args` flags exist, but haven't been advertised or documented other than just the flag description. `make_examples_extra_args` description can be found here:; https://github.com/google/deepvariant/blob/97cd861800ccb43d750f392b518e99d514adddd8/scripts/run_deepvariant.py#L92-L96. Regarding the downside of turning off `ws_use_window_selector_model` in make_examples -- yes, it'll be slower. It's a small model where we used to decide whether we need to realign a window or not. When we set it to default, we found that it significantly decreased runtime, with negligible trade-offs. . You can find the description of this feature when it's first released in v0.7:; https://github.com/google/deepvariant/releases/tag/v0.7.0. ""Changed window selector to use a linear decision model for choosing realignment candidates. This can be controlled by a flag. `-ws_use_window_selector_model` which is now on by default.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/272#issuecomment-586546504:765,down,downside,765,,https://github.com/google/deepvariant/issues/272#issuecomment-586546504,1,['down'],['downside']
Availability,"Yes, it's a fine balance indeed. Looking at it from different perspective. Higher than normal (in matched trios) of presumed ""de novo germline variants in the child"" , generally indicates sample QC problem. Another perspective, 99.9% of the de novo germline candidates in the child are false positives due to the type II error that I described. It's pretty significant!. In the context of the calling de novo germline variants in child. When there is QC issue, the will be way too many false positivies. Samples should be flagged. When it's just mapping quality issues, the variants should be execluded in the search i.e. don't call them as de novo. This would make the search much smaller. . This would be a model for the ""de novo germline in the child"". Would it be possible to then make calls for this model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/450#issuecomment-829604549:321,error,error,321,,https://github.com/google/deepvariant/issues/450#issuecomment-829604549,1,['error'],['error']
Availability,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from ; using the local libraries? . ```; INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>; from tensorflow.core.framework import function_pb2; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>; from google.protobuf import descriptor as _descriptor; File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>; from google.protobuf.internal import api_implementation; File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>; from google.protobuf.pyext import _message; TypeError: bases must be types; INFO: Cleaning up image...; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/580#issuecomment-1304645106:9,error,error,9,,https://github.com/google/deepvariant/issues/580#issuecomment-1304645106,1,['error'],['error']
Availability,Yes. This helps and from a model perspective this makes sense to add every site to the VCF that is a potential candidate for a variant. The last question I might raise is: What is your intention to have those positions added to the VCF by default and not as a opt-in option. To me it sound rather counterintuitive because I would argue that the majority of use-cases do not need those positions and/or removed them in downstream-analysis. But ofc this is you decision and just my view on the overall concept and I might be wrong here! . Thanks for all you help and patience so far!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1611159358:418,down,downstream-analysis,418,,https://github.com/google/deepvariant/issues/666#issuecomment-1611159358,1,['down'],['downstream-analysis']
Availability,"You are definitely following the recommended path for someone starting with `reads.bam`: `reads.bam` -> `extracthifi` -> `hifi_reads.bam` -> `pbmm2` -> `hifi_reads.aligned.bam` -> DeepVariant. The consensus kinetics tags are relatively recent additions, but we have noticed that these seem to cause OOM errors with `make_examples`, and if we strip these tags these errors seem to go away. A short term fix would be to remove these tags to produce a BAM to be used as input for DeepVariant:; `samtools view -b -x fi -x fp -x ri -x rp hifi_reads.aligned.bam > hifi_reads.aligned.nokinetics.bam`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/490#issuecomment-948869111:303,error,errors,303,,https://github.com/google/deepvariant/issues/490#issuecomment-948869111,2,['error'],['errors']
Availability,"You are right I've found the error: ; ""[E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2021-09-11 06:41:18.592077: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""chr1"" start: 4655405 end: 4655474; Fatal Python error: Aborted"" ; It is written few lines above the parallel error. I get this error with the original files of the WES run. (parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/483#issuecomment-917353570:29,error,error,29,,https://github.com/google/deepvariant/issues/483#issuecomment-917353570,4,['error'],['error']
Availability,"You are very welcome - thank you for your help!. FYI, the script recently stopped with the same error message. So, unless that file gives you another troubleshooting idea, I may look into other possible strategies (and/or look into more AWS documentation) and return to this issue when I get to the same stage with running DeepVariant (or at least report the alternative solution that I worked out).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-479788147:96,error,error,96,,https://github.com/google/deepvariant/issues/167#issuecomment-479788147,1,['error'],['error']
Availability,You have a space after the --ref flag. Be sure that is removed when you try running. That will cause an error.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1303724043:104,error,error,104,,https://github.com/google/deepvariant/issues/581#issuecomment-1303724043,1,['error'],['error']
Availability,"You're very welcome :); We can speculate, but it might just be sort of random things happening on the edges of the regions due to low numbers of errors overall. If you look at the number of errors different between these runs, it's like 26 vs 24 false positives for indels. I wouldn't draw any conclusions of trends from such small numbers. If you're curious you could inspect them in IGV though. I don't think we have any more insight into this from the DeepVariant side than you do.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/616#issuecomment-1440512685:145,error,errors,145,,https://github.com/google/deepvariant/issues/616#issuecomment-1440512685,2,['error'],['errors']
Availability,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`.; Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/166#issuecomment-478851260:272,error,error-prone,272,,https://github.com/google/deepvariant/issues/166#issuecomment-478851260,2,['error'],['error-prone']
Availability,"\; --machine-type ""e2-standard-16"" \; --zone ""us-west1-b"". gcloud compute ssh pichuan-centos7 --zone ""us-west1-b""; ```. By default the machine has Python2; ```; [pichuan@pichuan-centos7 ~]$ python --version ; Python 2.7.5; ```. ## Install Python 3.8.10; ```; sudo yum update; sudo yum install gcc openssl-devel bzip2-devel libffi-devel -y; sudo yum install -y wget; sudo yum install -y python3; ```. ```; wget https://www.python.org/ftp/python/3.8.10/Python-3.8.10.tgz; tar xvfz Python-3.8.10.tgz; ```. ```; cd Python-3.8.10; ./configure --enable-optimizations; ```. ```; sudo yum install -y make; sudo make altinstall; ```. ```; [pichuan@pichuan-centos7 Python-3.8.10]$ python3.8 --version; Python 3.8.10; ```. ## Install Singularity. ```; sudo yum update -y && \; sudo yum groupinstall -y 'Development Tools' && \; sudo yum install -y \; openssl-devel \; libuuid-devel \; libseccomp-devel \; wget \; squashfs-tools \; cryptsetup; ```. ```; export VERSION=1.14.12 OS=linux ARCH=amd64; # Downloads the required Go package; wget https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz; # Extracts the archive; sudo tar -C /usr/local -xzvf go$VERSION.$OS-$ARCH.tar.gz; # Deletes the ``tar`` file; rm go$VERSION.$OS-$ARCH.tar.gz. export VERSION=3.8.4; wget https://github.com/hpcng/singularity/releases/download/v${VERSION}/singularity-${VERSION}.tar.gz; tar -xzf singularity-${VERSION}.tar.gz; pushd singularity-3.8.4; export PATH=/usr/local/go/bin:$PATH. ./mconfig; make -C builddir; sudo make -C builddir install; ```. Check version:; ```; [pichuan@pichuan-centos7 ~]$ singularity --version; singularity version 3.8.4; ```. ## Try running DeepVariant with Singularity. I followed Quick Start to get data. ```; singularity pull docker://google/deepvariant:1.4.0; # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/610#issuecomment-1429156759:1345,Down,Downloads,1345,,https://github.com/google/deepvariant/issues/610#issuecomment-1429156759,1,['Down'],['Downloads']
Availability,"]; name=Advance Toolchain Unicamp FTP; baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7; failovermethod=priority; enabled=1; gpgcheck=1; gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b; # End of configuration file. # Install the Advance Toolchain; yum install advance-toolchain-at11.0-runtime; yum install advance-toolchain-at11.0-devel; yum install advance-toolchain-at11.0-perf; yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment; export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH; # Do not need to export; # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH ; # Load environment; sudo yum install environment-modules; source /etc/profile; module load at11.0; module unload at11.0; ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash; # download source code ; wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz; tar -zxvf Python-2.7.15.tgz; cd Python-2.7.15. # environment; export HOMEPATH=/home/qilibj; export CPU=power8. # check gcc before build, should be AT11.0; which gcc. # build; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static; make -j20; make install. # set environment; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin; export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH; export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15; echo ""$(python --version)"". # Pip 19.0.2; wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate; $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst; #pip install --upgrade --force-reinstall pip; echo ""$(pip --version)""; pip install setuptools nose asv cython future protobuf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:4885,down,download,4885,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['down'],['download']
Availability,"__Is there a seed parameter for downsampling fraction?__. I don't believe this is currently possible. What you can do though is you can downsample using samtools. . From `samtools view` you can specify:; ```; -s FLOAT subsample reads (given INT.FRAC option value, 0.FRAC is the; fraction of templates/read pairs to keep; INT part sets seed); ```; So you can subsample each bam like this:. ```bash; for i in `seq 1 5`; do; # i sets the seed.; samtools view -s ${i}.20 input.bam > input.${i}.20.bam; ```; Then run make_examples + shuffle to combine the results. Note that you want your training data to resemble the data you plan to run your model on. Subsampling can help improve performance in lower coverage regions, but if you plan to run this model at the original coverage level you'll want to train on that type of data as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/765#issuecomment-1911329739:32,down,downsampling,32,,https://github.com/google/deepvariant/issues/765#issuecomment-1911329739,2,['down'],"['downsample', 'downsampling']"
Availability,"__what is the pattern to use for file naming if I’m processing multiple BAM files?__. This can be whatever you like. When you perform shuffling, you want to specify a glob or list of patterns that will match. __If downsampling same source BAM multiple times, do I perform loop function myself?__. I'm not sure what you mean here. Can you provide more information?. __Is there a seed parameter for downsampling fraction?__. I don't think so - but I will double check on this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/765#issuecomment-1908918159:214,down,downsampling,214,,https://github.com/google/deepvariant/issues/765#issuecomment-1908918159,2,['down'],['downsampling']
Availability,"_build_stage ""Update package list""; ; @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {; then; echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling""; else; - pushd ~/bazel; - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh; - chmod +x bazel-*.sh; - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null; - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh; - popd; + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64; + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel; + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk; + chmod +x /usr/local/bin/bazel; + chmod +x /usr/local/bin/bazelisk; fi; }; ```; ```; diff --git a/tools/build_clif.sh b/tools/build_clif.sh; index c7c3378b..a08ab475 100755; --- a/tools/build_clif.sh; +++ b/tools/build_clif.sh; @@ -39,7 +39,7 @@ echo ========== Run this script in root mode.; CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}""; ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}""; PROTOBUF_VERSION=3.13.0; -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}""; +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}""; # CLIF_PIN can be set to a specific commit hash on; # https://github.com/google/clif/commits/main.; # If not set, the default is to checkout the latest commit.; @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \; wget \; unzip; ; +apt-get install ""${APT_ARGS[@]}"" python3-apt; +cd /usr/lib/python3/dist-packages; +if [ -e apt_pkg.so ]; then; + rm apt_pkg.so; +fi; +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so; +cd -; +; +export PATH=/root/.local/bin/:$PATH; +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev; +pip install pygobject; +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev; +pip install --upgrade pygobject; +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217:3443,echo,echo,3443,,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217,1,['echo'],['echo']
Availability,"_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p htc; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=12:00:00; #SBATCH --mem-per-cpu=128GB; #SBATCH --qos=maxjobs100. module purge; module load parallel; module load singularity. EXOME_IDs_FILE=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/RAW_input/NG0921_sampleIDs; HG38_REFERENCE=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/bwa/index/GCA_000001405.15_GRCh38_no_alt_analysis_set_refandindex/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna; PICARDMARKDUPLICATES_SORTEDBAM=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/picard/markduplicates/markedduplicates/{}PE_markedduplicates_GCA_000001405.15_GRCh38_no_alt_analysis_set.bam; BED_REGIONS=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/deepvariant/bed/Agilent-SureSelect-XT-Reagent-Kit-Human-AllExon-V6-hg38.bed; OUTPUT_VCF=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/deepvariant/vcf/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set.vcf.gz; OUTPUT_GVCF=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/deepvariant/gvcf/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set.g.vcf.gz; INTERMEDIATE_RESULTS=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/deepvariant/intermediateresults/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$BED_REGIONS \; --output_vcf=$OUTPUT_VCF \; --output_gvcf=$OUTPUT_GVCF \; --intermediate_results_dir=$INTERMEDIATE_RESULTS""; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/717#issuecomment-1770571154:1885,error,error,1885,,https://github.com/google/deepvariant/issues/717#issuecomment-1770571154,2,['error'],['error']
Availability,"_dir. INFO:tensorflow:Done calling model_fn.; I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn.; INFO:tensorflow:TPU job name tpu_worker; I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker; INFO:tensorflow:Graph was finalized.; I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt; I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt; INFO:tensorflow:prediction_loop marked as finished; I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished; WARNING:tensorflow:Reraising captured error; W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error; Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call; return fn(*args); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn; return self._call_tf_sessionrun(options, feed_dict, fetch_list,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun; return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,; tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt; [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/sa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874:6142,error,error,6142,,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874,2,['error'],['error']
Availability,"_variants_output.tfrecord.gz"" --examples ""./make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/pacbio"". /opt/deepvariant/bin/postprocess_variants --ref ""stdchroms.hg38.fa"" --infile ""./call_variants_output.tfrecord.gz"" --outfile ""./SAMPLENAME.deepVariant.vcf.gz"" --cpus ""8"" --gvcf_outfile ""./SAMPLENAME.deepVariant.g.vcf.gz"" --nonvariant_site_tfrecord_path ""./gvcf.tfrecord@8.gz"" --sample_name ""SAMPLENAME""; ```. And here are the two last commands with std out ... ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""./call_variants_output.tfrecord.gz"" --examples ""./make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(; I0510 12:13:42.483308 47501039724352 call_variants.py:563] Total 1 writing processes started.; I0510 12:13:42.487790 47501039724352 dv_utils.py:370] From ./make_examples.tfrecord-00000-of-00008.gz.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0510 12:13:42.487916 47501039724352 call_variants.py:588] Shape of input examples: [100, 199, 9]; I0510 12:13:42.488451 47501039724352 call_variants.py:592] Use saved model: True; I0510 12:13:52.162126 47501039724352 dv_utils.py:370] From /opt/models/pacbio/example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0510 12:13:52.163805 47501039724352 dv_utils.py:370] From ./make_examples.tfrecord-00000-of-00008.gz.example_info.json: ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/818#issuecomment-2104434632:1684,down,downstream,1684,,https://github.com/google/deepvariant/issues/818#issuecomment-2104434632,1,['down'],['downstream']
Availability,"``; gcr.io/deepvariant-docker/deepvariant:0.5.1; ```. I get this error instead:; ```; WARNING: Logging before flag parsing goes to stderr.; W0307 21:19:10.482634 140039107020544 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib; W0307 21:19:10.488955 140039107020544 call_variants.py:299] Unable to read any records from shardedExamples/examples.tfrecord@64.gz. Output will contain zero records.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/call_variants.py"", line 391, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run; _sys.exit(main(_sys.argv[:1] + flags_passthrough)); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/call_variants.py"", line 382, in main; batch_size=FLAGS.batch_size); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/call_variants.py"", line 317, in call_variants; predictions = model.create(images, 3, is_training=False)['Predictions']; File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/modeling.py"", line 360, in create; images, num_classes, create_aux_logits=False, is_training=is_training); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/org_tensorflow_slim/nets/inception_v3.py"", line 483, in inception_v3; depth_multiplier=depth_multiplier); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/org_tensorflow_slim/nets/inception_v3.py"", line 104, in inception_v3_base; net = slim.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 181, in func_with_args; return func(*args, **current_args); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1011, in convolution; input_rank); ValueError: ('Convolution not supported for input with rank', 1); ```; Have you seen this error before?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371288942:2075,error,error,2075,,https://github.com/google/deepvariant/issues/52#issuecomment-371288942,1,['error'],['error']
Availability,"```; I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2024-08-15 14:02:47.618984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64; 2024-08-15 14:02:47.619048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; 2024-08-15 14:02:50.434353: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NOT_FOUND: named symbol not found; []; ```I am encountering errors while testing deepvariants calling with gpu. It seems that some libraries for cuda are missing causing it to only work with cpu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/820#issuecomment-2291334900:1090,error,errors,1090,,https://github.com/google/deepvariant/issues/820#issuecomment-2291334900,1,['error'],['errors']
Availability,"```; INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output""; ```. `echo $INPUT_DIR`; returns /ybod2/cavery/deepvariant_run/quickstart-testdata. I am executing commands from the ""deepvariant_run"" directory. I made the change you suggested and received a new error:; `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/output"": invalid volume specification: ':/output'.`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/262#issuecomment-574900293:90,echo,echo,90,,https://github.com/google/deepvariant/issues/262#issuecomment-574900293,3,"['Error', 'echo', 'error']","['Error', 'echo', 'error']"
Availability,"`unspecified_caller` is an invalid option. I've never actually specified it, but I think the behavior should be that it should crash earlier (hopefully with a meaningful error message). . To train your own sequencing-type specific model, generally if the sequencer's base error rate is not too high, the default `very_sensitive_caller` should just work. But, if it's tricker cases like ONT reads, having a separate candidate generation process which is smarter about proposing candidates, and then using `vcf_candidate_importer` is the right way to go. @maryawood Can you say a bit more about why the default `vcf_candidate_importer` doesn't work for you? Do you get very imbalanced training data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/433#issuecomment-807187618:170,error,error,170,,https://github.com/google/deepvariant/issues/433#issuecomment-807187618,2,['error'],['error']
Availability,"ace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```; python bin/make_examples.zip \; --mode training \; --ref ""data/chr20.fa"" \; --reads ""data/sorted_final_merged.bam"" \; --examples ""training-examples/training_set.with_label.tfrecord.gz"" \; --confident_regions ""data/NA12878.sorted.bed"" \; --regions ""chr20"" \; --truth_variants ""data/NA12878.sorted.vcf.gz"" \; --norealign_reads; ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:; * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. ; * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps!. ```; 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; WARNING: Logging before flag parsing goes to stderr.; I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader; I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs; 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-454225947:1074,error,error,1074,,https://github.com/google/deepvariant/issues/138#issuecomment-454225947,1,['error'],['error']
Availability,"ad parallel; module load singularity. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \; --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \; --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **I get the error:** ; ; ```; raise ValueError('The regions to call is empty. Check your --regions and '; ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa).; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/527#issuecomment-1067792214:1605,error,error,1605,,https://github.com/google/deepvariant/issues/527#issuecomment-1067792214,1,['error'],['error']
Availability,"ad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi again,; I didn't read carefully so I missed that you said you want to train a model.; If you want to get make_examples to create more candidates, the other flags you need to consider are: vsc_min_count_snps, vsc_min_count_indels, vsc_min_fraction_snps, vsc_min_fraction_indels. With the default values of these flags for VSC (Very Sensitive Caller), you simply won't be able to even get candidates generated for low allele fraction variants. So I would suggest playing around with those flags and see if more candidates come out. Thanks! Let us know how it goes. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-379110341>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqU5J11c7Zr-VYS_8CjFPh-UF6VIYks5tlq76gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-379857500:1957,error,error-free,1957,,https://github.com/google/deepvariant/issues/62#issuecomment-379857500,8,['error'],"['error-free', 'errors']"
Availability,"ad3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.688877 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:43:41.804690 139796154570496 make_examples.py:648] Writing examples to quickstart-output/sing.make_examples.tfrecord.gz; I0629 23:43:41.804903 139796154570496 make_examples.py:648] Writing gvcf records to quickstart-output/sing.gvcf.tfrecord.gz; I0629 23:43:41.805349 139796154570496 make_examples.py:648] Overhead for preparing inputs: 0 seconds; I0629 23:43:41.821153 139796154570496 make_examples.py:648] 0 candidates (0 examples) [0.02s elapsed]; I0629 23:44:41.827408 139796154570496 make_examples.py:648] 102 candidates (110 examples) [60.01s elapsed]; I0629 23:44:45.517579 139796154570496 make_examples.py:648] 202 candidates (223 examples) [3.69s elapsed]; [E::bgzf_read] Read block operation failed with error 4 after 0 of 4 bytes; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads; reads.extend(sam_reader.query(region)); File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__; record, not_done = self._raw_next(); File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next; not_done = self._cc_iterable.PythonNext(record); ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_7g_i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:17949,error,error,17949,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,2,['error'],['error']
Availability,"aded the modified file on this public s3 bucket so you can have a look on it directly from here : ; s3://dv-testfiles/hg19.fa; s3://dv-testfiles/ENCFF528VXT.bam. There you can find the genome I used for running too. Before i created the needed files ( done in the following docker container https://hub.docker.com/r/luisas/samtools/ ) :; ```; samtools index ENCFF528VXT.bam; samtools faidx hg19.fa; bgzip -c -i hg19.fa > hg19.fa.gz; samtools faidx ""hg19.fa.gz""; ```. Then I ran in the docker container you provide :; ```; mkdir shardedExamples. time seq 0 1 | parallel --eta --halt 2 python /opt/deepvariant/bin/make_examples.zip --mode calling --ref hg19.fa --regions chr20:10,000,000-10,010,000 --reads ENCFF528VXT.bam --examples shardedExamples/examples.tfrecord@2.gz --task {}. ```. ```; /opt/deepvariant/bin/call_variants --outfile call_variants_output.tfrecord --examples shardedExamples/examples.tfrecord@2.gz --checkpoint dv2/models/model.ckpt; ```. and here the error output:; ```; WARNING: Logging before flag parsing goes to stderr.; W0307 09:54:53.415692 140603705038592 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_vZjmn7/runfiles/genomics/deepvariant/call_variants.py"", line 410, in module; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run; _sys.exit(main(_sys.argv[:1] + flags_passthrough)); File ""/tmp/Bazel.runfiles_vZjmn7/runfiles/genomics/deepvariant/call_variants.py"", line 401, in main; batch_size=FLAGS.batch_size); File ""/tmp/Bazel.runfiles_vZjmn7/runfiles/genomics/deepvariant/call_variants.py"", line 324, in call_variants; examples_filename, example_format)); ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again.; ```. Thanks a lot,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371096675:3038,error,error,3038,,https://github.com/google/deepvariant/issues/52#issuecomment-371096675,1,['error'],['error']
Availability,"after cleaning up Docker space with prune and making sure there is space on disk and rerunning. I am getting the same exact error. I feel that the docker container settings itself is the issue but not the software. i.e. maybe there is a hard limit on the temporary space in the container, as the data is generated and written in the tmp when it fails, nothing is saved to the disk where my input and output is located when it fails. It completes the process and fails before the folder is being written to disk from inside the container. I pulled it from docker pull google/deepvariant:latest-deeptrio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/400#issuecomment-750309235:124,error,error,124,,https://github.com/google/deepvariant/issues/400#issuecomment-750309235,1,['error'],['error']
Availability,"age 'run-prereq.sh complete' starting; ========== [Mon 05 Jun 2023 03:51:40 PM UTC] Stage 'Update package list' starting; ========== [Mon 05 Jun 2023 03:51:41 PM UTC] Stage 'build-prereq.sh: Install development packages' starting; Calling wait_for_dpkg_lock.; ========== [Mon 05 Jun 2023 03:51:42 PM UTC] Stage 'Install bazel' starting; /root/bin/bazel: line 220: /root/.bazel/bin/bazel-real: cannot execute binary file: Exec format error; /root/bin/bazel: line 220: /root/.bazel/bin/bazel-real: Success; ~/bazel /media/HostShared/deepvariant-r1.5; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0; 100 46.5M 100 46.5M 0 0 23.2M 0 0:00:02 0:00:02 --:--:-- 27.1M; /media/HostShared/deepvariant-r1.5; ========== [Mon 05 Jun 2023 03:51:44 PM UTC] Stage 'Install CLIF binary' starting; CLIF already installed.; ========== [Mon 05 Jun 2023 03:51:44 PM UTC] Stage 'Download and configure TensorFlow sources' starting; ========== [Mon 05 Jun 2023 03:51:44 PM UTC] Stage 'Cloning TensorFlow from github as ../tensorflow doesn't exist' starting; Cloning into 'tensorflow'...; remote: Enumerating objects: 1585302, done.; remote: Counting objects: 100% (346968/346968), done.; remote: Compressing objects: 100% (5367/5367), done.; remote: Total 1585302 (delta 342939), reused 342327 (delta 341589), pack-reused 1238334; Receiving objects: 100% (1585302/1585302), 920.91 MiB | 18.57 MiB/s, done.; Resolving deltas: 100% (1307043/1307043), done.; Updating files: 100% (29800/29800), done.; Updating files: 100% (12761/12761), done.; Note: switching to 'v2.11.0'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:6019,Down,Download,6019,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,1,['Down'],['Download']
Availability,"ake/modules/CLIFUtils.cmake ; ./INSTALL.sh; ```; After these changes, I am stuck again at building clif because of the following error:; ```; [100%] Linking CXX executable clif-matcher; /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':; matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'; /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':; matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'; collect2: error: ld returned 1 exit status; make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1; make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2; make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2; make: *** [Makefile:617: clif-matcher] Error 2; ```; I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217:6328,error,error,6328,,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217,6,"['Error', 'error']","['Error', 'error']"
Availability,"all, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the “truth” set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and I’m assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isn’t really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:6659,avail,available,6659,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['avail'],['available']
Availability,"amtools 1.9; Using htslib 1.9; Copyright (C) 2018 Genome Research Ltd. user@deepvariant:~/data$ samtools view -h ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/sorted_final_merged.bam chr20 -o chr20.bam. user@deepvariant:~/data$ samtools view -h chr20.bam | head; @HD	VN:1.4	GO:none	SO:coordinate; @SQ	SN:chrM	LN:16571	M5:6b9e15a5937653b0006de435f91578c0; @SQ	SN:chr1	LN:249250621	M5:94f0d1b1622299238a1d8a0711dd06c7; @SQ	SN:chr2	LN:243199373	M5:854e985b2e19c122b9f67f6453965693; @SQ	SN:chr3	LN:198022430	M5:8abc85e73b1c75518a03743de2c2b14b; @SQ	SN:chr4	LN:191154276	M5:2d37b4e662928cc6c58b84b2a4cc8648; @SQ	SN:chr5	LN:180915260	M5:250f4e82a213269b0a0e4aebb0468470; @SQ	SN:chr6	LN:171115067	M5:409088215d77f0bc72364b390430a5a7; @SQ	SN:chr7	LN:159138663	M5:ef15cde5c82fb860694bf8f611807459; @SQ	SN:chr8	LN:146364022	M5:8fbef8c3eaaac674cc6e690d1641464b; ```; As you can see I don't get the EOF error when viewing `chr20.bam`. I tries running make_examples with the new files and I get the same error as you got here:. > @mosh305 I do not have experience with mapping, but the README for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here.; > ...; > ; > Hope this helps!; > ; > ```; > 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; > WARNING: Logging before flag parsing goes to stderr.; > I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader; > I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs; > 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; > I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader; > I0115 00:54:33.9784",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-457253153:1431,error,error,1431,,https://github.com/google/deepvariant/issues/138#issuecomment-457253153,1,['error'],['error']
Availability,"anch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at 9ec44bd Replace C++ `#import <...>` with `#include <...>`; + git init; Reinitialized existing Git repository in /root/clif/.git/; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/737#issuecomment-1818093820:2464,echo,echo,2464,,https://github.com/google/deepvariant/issues/737#issuecomment-1818093820,2,['echo'],['echo']
Availability,"and; (cd /home/pichuan/.cache/bazel/_bazel_pichuan/01047f0bd74be1f8c2eae71c8557726c/execroot/com_google_deepvariant && \; exec env - \; PATH=/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/pichuan/bin \; PWD=/proc/self/cwd \; PYTHON_BIN_PATH=/usr/local/bin/python2.7 \; PYTHON_LIB_PATH=/usr/local/lib/python2.7/site-packages \; TF_NEED_CUDA=0 \; TF_NEED_OPENCL_SYCL=0 \; /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 -MD -MF bazel-out/k8-opt/bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/common.pic.d -fPIC -iquote external/nsync -iquote bazel-out/k8-opt/genfiles/external/nsync -iquote external/bazel_tools -iquote bazel-out/k8-opt/genfiles/external/bazel_tools -isystem external/nsync/public -isystem bazel-out/k8-opt/genfiles/external/nsync/public -isystem external/bazel_tools/tools/cpp/gcc3 -x c++ '-std=c++11' -DNSYNC_ATOMIC_CPP11 -DNSYNC_USE_CPP11_TIMEPOINT -I./external/nsync//platform/c++11 -I./external/nsync//platform/gcc -I./external/nsync//platform/x86_64 -I./external/nsync//public -I./external/nsync//internal -I./external/nsync//platform/posix '-D_POSIX_C_SOURCE=200809L' -pthread -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/nsync/internal/common.c -o bazel-out/k8-opt/bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/common.pic.o); cc1plus: error: unrecognized command line option ""-std=c++11""; cc1plus: warning: unrecognized command line option ""-Wno-maybe-uninitialized""; cc1plus: warning: unrecognized command line option ""-Wno-free-nonheap-object""; (06:15:00) INFO: Elapsed time: 0.386s, Critical Path: 0.05s; (06:15:00) FAILED: Build did NOT complete successfully; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386513685:2331,error,error,2331,,https://github.com/google/deepvariant/issues/29#issuecomment-386513685,1,['error'],['error']
Availability,"annel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct?. Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > ; > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?. If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8.; ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:; ```; $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json; {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} ; ```. If the customized_model you're using has this file, and ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/568#issuecomment-1251857213:1175,error,error,1175,,https://github.com/google/deepvariant/issues/568#issuecomment-1251857213,1,['error'],['error']
Availability,"ant the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that.; How about at least posting the commands you used?. From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty.; (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381209312:2253,error,error-free,2253,,https://github.com/google/deepvariant/issues/62#issuecomment-381209312,4,['error'],"['error-free', 'errors']"
Availability,"ant. # # Gets the nightly TF build: https://pypi.python.org/pypi/tf-nightly which is; # # necessary right now if we aren't pinning the TF source. We have observed; # # runtime failures if there's too much skew between the released TF package and; # # the source.; # if [[ ""${DV_TF_NIGHTLY_BUILD}"" = ""1"" ]]; then; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # echo ""Installing GPU-enabled TensorFlow nightly wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade tf_nightly_gpu; # else; # echo ""Installing CPU-only TensorFlow nightly wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade tf_nightly; # fi; # else; # # Use the official TF release pip package.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # echo ""Installing GPU-enabled TensorFlow ${DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION} wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade ""tensorflow-gpu==${DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION}""; # elif [[ ""${DV_USE_GCP_OPTIMIZED_TF_WHL}"" = ""1"" ]]; then; # echo ""Installing Intel's CPU-only MKL TensorFlow ${DV_GCP_OPTIMIZED_TF_WHL_VERSION} wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade ""intel-tensorflow==${DV_GCP_OPTIMIZED_TF_WHL_VERSION}""; # else; echo ""Installing standard CPU-only TensorFlow ${DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION} wheel""; pip3 install ""${PIP_ARGS[@]}"" --upgrade ""tensorflow==${DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION}""; # fi; # fi; # fi. # # A temporary fix.; # # Context: intel-tensorflow 2.7.0 will end up updating markupsafe to 2.1.1,; # # which caused the issue here: https://github.com/pallets/markupsafe/issues/286.; # # Specifically:; # # ImportError: cannot import name 'soft_unicode' from 'markupsafe'.; # # So, forcing a downgrade. This isn't the best solution, but we need it to get; # # our tests pass.; pip3 install ""${PIP_ARGS[@]}"" --upgrade 'markupsafe==2.0.1'. # ################################################################################; # # CUDA; # ################################################################################. # note_build_stage ""Install ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:1210,echo,echo,1210,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,6,['echo'],['echo']
Availability,"ant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out “complex variants” (with more than one variant at a position), but .vcf files containing those variants weren’t flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:; ```; 68759 / 72556 (94.8%) full SNP recovery; 71276 / 72556 (98.2%) partial SNP recovery; 3027 / 3648 (83.0%) full insertion recovery; 3413 / 3648 (93.6%) partial insertion recovery; 3119 / 3911 (79.7%) full deletion recovery; 3596 / 3911 (91.9%) partial deletion recovery; ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:; ```; 51417 / 54229 (94.8%) full SNP recovery; 53116 / 54229 (97.9%) partial SNP recovery; 1964 / 2391 (82.1%) full insertion recovery; 2242 / 2391 (93.8%) partial insertion recovery; 2058 / 2537 (81.1%) full deletion recovery; 2349 / 2537 (92.6%) partial deletion recovery; ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a “*partial*” recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didn’t feel comfortable showing comparisons between variant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:1718,recover,recovery,1718,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"ant/blob/r1.1/docs/deepvariant-details.md#command-for-a-cpu-only-machine-on-google-cloud-platform) to get a Ubuntu16.04 machine. ## Set up on the machine; After ssh into the machine, before start running the [PacBio tutorial](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md), I'll install things first:. ```; curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; bash Miniconda3-latest-Linux-x86_64.sh; ```; After installing conda, I logged out and re-logged in. I install Singularity:; ```; curl -O https://raw.githubusercontent.com/google/deepvariant/r1.1/scripts/install_singularity.sh; bash install_singularity.sh; ```. Here is my Singularity version:; ```; (base) pichuan@pichuan-cpu:~$ singularity --version; singularity version 3.3.0-1; ```. ## Run through PacBio tutorial; I follow the steps here:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md; and ran through all commands set up conda, and download all files. When I get to this step:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md#run-deepvariant-on-chromosome-20-alignments. I added `--call_variants_extra_args ""use_openvino=true""`. So my command is:; ```; ulimit -u 10000 # https://stackoverflow.com/questions/52026652/openblas-blas-thread-init-pthread-create-resource-temporarily-unavailable/54746150#54746150; BIN_VERSION=""1.1.0""; mkdir -p deepvariant1. singularity exec --bind /usr/lib/locale/ \; docker://google/deepvariant:${BIN_VERSION} \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref reference/GRCh38_no_alt_analysis_set.fasta \; --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \; --output_vcf deepvariant1/output.vcf.gz \; --num_shards $(nproc) \; --regions chr20 \; --call_variants_extra_args ""use_openvino=true""; ```. This actually worked for me. I'll paste some logs around the model conversion:; ```; Instructions for updating:; Use `tf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-761309014:1789,down,download,1789,,https://github.com/google/deepvariant/issues/404#issuecomment-761309014,1,['down'],['download']
Availability,"are_session(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session; sess, is_loaded_from_checkpoint = self._restore_checkpoint(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint; _restore_checkpoint_and_maybe_run_saved_model_initializers(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers; saver.restore(sess, path); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore; raise _wrap_restore_error_with_msg(; tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt; [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874:17671,error,error,17671,,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874,2,['error'],['error']
Availability,"aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testda; aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testdata/${REF}.fai"" -d ""${INPUT_DIR}""; ; ## Pull the docker image.; -sudo docker pull google/deepvariant:""${BIN_VERSION}""; +sudo docker pull dkurtaev/deepvariant:latest; ; echo ""Run DeepVariant...""; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; - google/deepvariant:""${BIN_VERSION}"" \; - /opt/deepvariant/bin/run_deepvariant \; + dkurtaev/deepvariant:latest \; + /opt/deepvariant/bin/run_deepvariant --call_variants_extra_args=use_openvino=false --make_examples_extra_args=regions=chr1 \; --model_type=WGS \; --ref=""/input/${REF}.gz"" \; --reads=""/input/${BAM}"" \; @@ -100,6 +100,6 @@ pkrusche/hap.py /opt/hap.py/bin/hap.py \; -f ""${INPUT_DIR}/${TRUTH_BED}"" \; -r ""${UNCOMPRESSED_REF}"" \; -o ""${OUTPUT_DIR}/happy.output"" \; - --engine=vcfeval; + --engine=vcfeval -l chr1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done.""; ```. Runtime:; ```; $ grep '^real' /tmp/open; real 7m20.986s; real 21m24.429s; real 6m32.705s; ```. 3. Use v1.0.0 image.; The code diff:; ```; $ git diff; diff --git a/scripts/run_wgs_case_study_docker.sh b/scripts/run_wgs_case_study_docker.sh; index 3dc9712..88fb0c1 100755; --- a/scripts/run_wgs_case_study_docker.sh; +++ b/scripts/run_wgs_case_study_docker.sh; @@ -72,7 +72,7 @@ sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; google/deepvariant:""${BIN_VERSION}"" \; - /opt/deepvariant/bin/run_deepvariant \; + /opt/deepvariant/bin/run_deepvariant --make_examples_extra_args=regions=chr1 \; --model_type=WGS \; --ref=""/input/${REF}.gz"" \; --reads=""/input/${BAM}"" \; @@ -100,6 +100,6 @@ pkrusche/hap.py /opt/hap.py/bin/hap.py \; -f ""${INPUT_DIR}/${TRUTH_BED}"" \; -r ""${UNCOMPRESSED_REF}"" \; -o ""${OUTPUT_DIR}/happy.output"" \; - --engine=vcfeval; + --engine=vcfeval -l chr1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done.""; ```. Runtime; ```; $ grep '^real",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735276044:3201,echo,echo,3201,,https://github.com/google/deepvariant/pull/363#issuecomment-735276044,1,['echo'],['echo']
Availability,"ariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_q2sdkm67/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '23']"".; E0430 18:57:45.246095 140479227369280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_uphv_tdy/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '37']"".; E0430 18:57:45.317537 139819477477184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_4750gtic/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '43']"".; E0430 18:57:45.318566 140493027030848 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_mw222qvc/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '19']"".; E0430 18:57:45.281981 139640920373056 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_087sqql0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '18']"".; E0430 18:57:45.269598 140672023549760 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_prpwm4tu/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '41']"".; E0430 18:57:45.343238 140414174025536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_dqd3ut4s/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '32']"".; E",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:11089,failure,failure,11089,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:8859,failure,failure,8859,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_q2sdkm67/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '23']"".; E0430 18:57:45.246095 140479227369280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_uphv_tdy/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '37']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:9695,failure,failure,9695,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '16']"".; E0430 18:57:45.196900 140351706515264 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles__ytoy0a6/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '4']"".; E0430 18:57:45.304501 140371551012672 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_w7jwxlqo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '28']"".; E0430 18:57:45.337900 139621533210432 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_22p2hp0z/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '45']"".; E0430 18:57:45.424449 139874966882112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_wv1oakms/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '46']"".; E0430 18:57:45.268234 140085723301696 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_g62feq4g/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '10']"".; E0430 18:57:45.190006 140494428116800 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_gsw00kpo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '12']"".; E0430 18:57:45.278714 140080891017024 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles__lr697ii/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '20']"".; E",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:2167,failure,failure,2167,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E0430 18:57:45.264230 139873562601280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_qtxrg7dl/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '6']"".; E0430 18:57:45.193969 139692519348032 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_05qe3qax/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '36']"".; E0430 18:57:45.197033 140638292031296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_75j2ynwd/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '5']"".; E0430 18:57:45.264279 139811152422720 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i060jaf0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:7187,failure,failure,7187,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '21']"".; E0430 18:57:45.245847 140159308461888 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_0ekpfvin/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '24']"".; E0430 18:57:45.283955 140581469652800 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_brxc6_sa/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '7']"".; E0430 18:57:45.303462 139795832272704 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_sfy61tb_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '29']"".; E0430 18:57:45.331091 140537432155968 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_y60taw80/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '31']"".; E0430 18:57:45.239560 139714767980352 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_v3df_cxj/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E0430 18:57:45.264230 139873562601280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_qtxrg7dl/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '6']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:5793,failure,failure,5793,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '24']"".; E0430 18:57:45.283955 140581469652800 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_brxc6_sa/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '7']"".; E0430 18:57:45.303462 139795832272704 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_sfy61tb_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '29']"".; E0430 18:57:45.331091 140537432155968 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_y60taw80/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '31']"".; E0430 18:57:45.239560 139714767980352 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_v3df_cxj/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E0430 18:57:45.264230 139873562601280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_qtxrg7dl/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '6']"".; E0430 18:57:45.193969 139692519348032 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_05qe3qax/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '36']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:6072,failure,failure,6072,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E04",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:9138,failure,failure,9138,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:8580,failure,failure,8580,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '31']"".; E0430 18:57:45.239560 139714767980352 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_v3df_cxj/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E0430 18:57:45.264230 139873562601280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_qtxrg7dl/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '6']"".; E0430 18:57:45.193969 139692519348032 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_05qe3qax/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '36']"".; E0430 18:57:45.197033 140638292031296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_75j2ynwd/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '5']"".; E0430 18:57:45.264279 139811152422720 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i060jaf0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:6908,failure,failure,6908,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '36']"".; E0430 18:57:45.197033 140638292031296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_75j2ynwd/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '5']"".; E0430 18:57:45.264279 139811152422720 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i060jaf0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:8023,failure,failure,8023,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_q2sdkm67/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '23']"".; E0430 18:57:45.246095 140479227369280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_uphv_tdy/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '37']"".; E0430 18:57:45.317537 139819477477184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_4750gtic/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '43']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:9974,failure,failure,9974,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '4']"".; E0430 18:57:45.304501 140371551012672 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_w7jwxlqo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '28']"".; E0430 18:57:45.337900 139621533210432 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_22p2hp0z/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '45']"".; E0430 18:57:45.424449 139874966882112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_wv1oakms/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '46']"".; E0430 18:57:45.268234 140085723301696 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_g62feq4g/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '10']"".; E0430 18:57:45.190006 140494428116800 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_gsw00kpo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '12']"".; E0430 18:57:45.278714 140080891017024 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles__lr697ii/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '20']"".; E0430 18:57:45.366031 140648053425984 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_9e_e2zvn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '38']"".; E",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:2446,failure,failure,2446,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_q2sdkm67/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '23']"".; E0430 18:57:45.246095 140479227369280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_uphv_tdy/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '37']"".; E0430 18:57:45.317537 139819477477184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_4750gtic/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '43']"".; E0430 18:57:45.318566 140493027030848 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_mw222qvc/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '19']"".; E0430 18:57:45.281981 139640920373056 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_087sqql0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '18']"".; E0430 18:57:45.269598 140672023549760 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_prpwm4tu/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '41']"".; E",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:10810,failure,failure,10810,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '41']"".; E0430 18:57:45.343238 140414174025536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_dqd3ut4s/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '32']"".; E0430 18:57:45.247818 140240365713216 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_8s9w7qaa/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '25']"".; E0430 18:57:45.247906 139736525375296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_8kqng5_c/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '1']"".; E0430 18:57:45.354531 139703252227904 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_47rk8xc1/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '22']"".; E0430 18:57:45.318170 140515109386048 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_4p5rc3ja/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '35']"".; E0430 18:57:45.306068 140062873229120 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xavizfpc/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '42']"".; E0430 18:57:45.268234 140590012761920 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_ovmu_l59/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '8']"".; pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:12762,failure,failure,12762,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '47']"".; E0430 18:57:45.249558 140521800120128 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_hpf7iban/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"".; E0430 18:57:45.245847 140159308461888 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_0ekpfvin/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '24']"".; E0430 18:57:45.283955 140581469652800 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_brxc6_sa/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '7']"".; E0430 18:57:45.303462 139795832272704 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_sfy61tb_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '29']"".; E0430 18:57:45.331091 140537432155968 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_y60taw80/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '31']"".; E0430 18:57:45.239560 139714767980352 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_v3df_cxj/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:5514,failure,failure,5514,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '5']"".; E0430 18:57:45.264279 139811152422720 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i060jaf0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:8302,failure,failure,8302,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '7']"".; E0430 18:57:45.303462 139795832272704 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_sfy61tb_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '29']"".; E0430 18:57:45.331091 140537432155968 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_y60taw80/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '31']"".; E0430 18:57:45.239560 139714767980352 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_v3df_cxj/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '17']"".; E0430 18:57:45.262542 140488697198400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E0430 18:57:45.264230 139873562601280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_qtxrg7dl/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '6']"".; E0430 18:57:45.193969 139692519348032 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_05qe3qax/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '36']"".; E0430 18:57:45.197033 140638292031296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_75j2ynwd/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '5']"".; E04",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:6351,failure,failure,6351,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"ariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i98_1ues/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '13']"".; E0430 18:57:45.303056 140048653686592 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_yk1hqf6a/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '39']"".; E0430 18:57:45.368143 139769855092544 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_q2sdkm67/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '23']"".; E04",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:9417,failure,failure,9417,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['failure'],['failure']
Availability,"artially owned by Google). 2) In the PrecisionFDA Truth Challenge, the HG002 truth set was characterized by NIST but these calls were fully with-held. As a result, this challenge represents the only time that a well-characterized genome was hidden from all developers and offered a unique opportunity to avoid over-fitting. To preserve the validity of this, we never train on HG002 in Illumina data. As noted above, the version of DeepVariant submitted in PrecisionFDA was early, and subsequent improvements improved accuracy both on this sample and for other instruments and PCR preparations. With these accuracy improvements, DeepVariant unambiguously outperforms other entries in both SNP and Indel:. There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes tha",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-476392585:1358,error,error,1358,,https://github.com/google/deepvariant/issues/165#issuecomment-476392585,2,['error'],['error']
Availability,"at we will decode CRAM using the reference you passed in with --ref; 2020-09-11 02:28:39.919135: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728; I0911 02:28:39.922723 140366075229952 genomics_reader.py:223] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0911 02:28:39.923217 140366075229952 genomics_reader.py:223] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0911 02:28:40.247040 140366075229952 make_examples.py:587] 6 candidates (6 examples) [0.33s elapsed]; I0911 02:28:41.745102 140366075229952 make_examples.py:587] Found 78 candidate variants; I0911 02:28:41.745359 140366075229952 make_examples.py:587] Created 86 examples. real 0m5.273s; user 0m5.898s; sys 0m3.792s. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0911 02:28:44.682443 139937686464256 call_variants.py:335] Shape of input examples: [100, 221, 6]; 2020-09-11 02:28:44.695721: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA; To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.; 2020-09-11 02:28:44.721599: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2297525000 Hz; 2020-09-11 02:28:44.724518: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5886480 executing computations on platform Host. Devices:; 2020-09-11 02:28:44.724555: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version; 2020-09-11 02:28:44.727738: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inte",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-690842263:5415,checkpoint,checkpoint,5415,,https://github.com/google/deepvariant/issues/345#issuecomment-690842263,1,['checkpoint'],['checkpoint']
Availability,"ation_set.dataset_config.pbtxt"" \; --job_name=shuffle-tfrecords \; --runner=DataflowRunner \; --staging_location=""${OUTPUT_BUCKET}/staging"" \; --temp_location=""${OUTPUT_BUCKET}/tempdir"" \; --save_main_session \; --region us-east1; ```. ```; time gcloud compute tpus create ${USER}-demo-tpu \; --network=default \; --version=2.3 \; --zone=us-central1-c; ```. # Below is the main difference from the instruction in r0.9: How to look up the TPU_IP:. Given that it seems like we didn't have the right library to properly look up `tpu_name` (`pip install cloud-tpu-client` is needed, it seems). I will try to fix this in our future Dockerfile and test it. But for now, I'll show up to manually resolve the tpu_name. First, install this:; ```; pip3 install cloud-tpu-client; ``` . And then:. ```; TPU_NAME=""${USER}-demo-tpu""; TPU_IP=$(python3 -c ""import tensorflow as tf; print(tf.distribute.cluster_resolver.TPUClusterResolver(tpu=['${TPU_NAME}'], zone='us-central1-c').get_master())""); ```; Check the IP:; ```; $ echo ${TPU_IP}; grpc://10.33.164.2:8470; ```. ```; ( time sudo docker run \; -v /home/${USER}:/home/${USER} \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/model_train \; --use_tpu \; --master=""${TPU_IP}"" \; --dataset_config_pbtxt=""${OUTPUT_BUCKET}/training_set.dataset_config.pbtxt"" \; --train_dir=""${TRAINING_DIR}"" \; --model_name=""inception_v3"" \; --number_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=512 \; --learning_rate=0.008 \; --start_from_checkpoint="""" \; ) 2>&1 | tee ""${LOG_DIR}/train.log""; ```. This now seems to be able to see the TPU. But right now I seem to be having some issue of using ${GCS_PRETRAINED_WGS_MODEL} as `--start_from_checkpoint`, so I might need to continue looking into why. And, at this point, I'm done for now. So I manually deleted the TPU:; ```; gcloud compute tpus delete ${TPU_NAME} --zone us-central1-c; ```. ---. @mattwood-codifiedgenomics Thanks for reporting this. I don't think the `--tpu_name` code path is commonly ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/469#issuecomment-871936544:6548,echo,echo,6548,,https://github.com/google/deepvariant/issues/469#issuecomment-871936544,1,['echo'],['echo']
Availability,"atures; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"") ; -- Checking for module 'protobuf'; -- Found protobuf, version 3.13.0; -- Checking for module 'libglog'; -- Found libglog, version 0.4.0; -- Looking for pthread.h; -- Looking for pthread.h - found; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed; -- Looking for pthread_create in pthreads; -- Looking for pthread_create in pthreads - not found; -- Looking for pthread_create in pthread; -- Looking for pthread_create in pthread - found; -- Found Threads: TRUE ; -- Found GTest: /usr/local/lib/cmake/GTest/GTestConfig.cmake (found version ""1.10.0"") ; -- Found PythonInterp: /usr/local/bin/python3 (found version ""3.8.10"") ; -- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.8.so (found version ""3.8.10"") ; -- Configuring done; -- Generating done; -- Build files have been written to: /root/clif/build; ```; which succeeded (and then proceed to the next step). @pioneer-pi , given that I can't reproduce this error, I'll need more information from you to understand why it failed. This is the step where your setup failed , but mine worked:. ```bash; root@pichuan-cpu:/home/pichuan/deepvariant# cd /root/clif/build; root@pichuan-cpu:~/clif/build# cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; ```. It'll be good to understand how/why it failed on your side. If you can provide more information there, I'm happy to see how I can help. And @pioneer-pi , another question is : Can you consider using our Docker? If you're trying to install on a machine, you must already have root permission. (Our ""build from source"" option only works with root permission)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785:3445,error,error,3445,,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785,1,['error'],['error']
Availability,"aviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; Python 3.8.10; pip 23.1.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); ========== [Mon 05 Jun 2023 03:51:27 PM UTC] Stage 'Install python3 packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:3121,ERROR,ERROR,3121,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,1,['ERROR'],['ERROR']
Availability,"aviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; Python 3.8.10; pip 23.1.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); ========== [Mon 05 Jun 2023 10:22:17 PM EDT] Stage 'Install python3 packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053:4147,ERROR,ERROR,4147,,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053,1,['ERROR'],['ERROR']
Availability,"b.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,; originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that.; How about at least posting the commands you used?. From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty.; (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or conta",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381209312:1372,error,error,1372,,https://github.com/google/deepvariant/issues/62#issuecomment-381209312,2,['error'],['error']
Availability,"bin/run_deepvariant \; --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****; ***** Running the command:*****; time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s; user 0m0.258s; sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300:6332,Error,Error,6332,,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300,1,['Error'],['Error']
Availability,"but the docker install commands failed:. sudo apt-get -qq -y update; E: The repository 'https://download.docker.com/linux/ubuntu buster Release' does not have a Release file. sudo apt-get -qq -y install docker-ce; E: Package 'docker-ce' has no installation candidate. So instead I ran an alternate docker installation, which succeeded (sudo apt install docker.io). I don't know if this is the ultimate problem. The first command within the docker seems to complete with no errors:. ***** Running the command:*****; time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hs37d5.fa.gz"" --reads ""/input/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --regions ""20"" --task {}. ...omitting much output... It does take 40 minutes as opposed to the advertised 8, though. I was using pre-emptible instances so perhaps this caused delay, but I did test it 3 times, and it is reliably ~40 mins each time. The second command within the docker dies, this is all the output:. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --; checkpoint ""/opt/models/wgs/model.ckpt""; I1217 09:08:41.108182 139680301201152 call_variants.py:313] Set KMP_BLOCKTIME to 0; 2020-12-17 09:08:41.511115: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA; 2020-12-17 09:08:42.039849: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz; 2020-12-17 09:08:42.070759: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5abc760 executing computations on platform Host. Devices:; 2020-12-17 09:08:42.070838: I tensorflow/compiler/xla/service/service.cc:158] St",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/399#issuecomment-749313156:1127,reliab,reliably,1127,,https://github.com/google/deepvariant/issues/399#issuecomment-749313156,1,['reliab'],['reliably']
Availability,"but you didn't notice, then the next step will fail.; Common failure modes I've seen before:; - if you were running make_examples, but abort in the middle by ctrl-c. Sometimes not all the make_examples in the background were killed. If you just re-run make_examples without killing all background make_examples first, the output might be corrupted.; - if make_examples failed completely without outputting HG002.examples.tfrecord*.gz at all, it'll also cause a failure. Our hope is that you'll notice this in the errors that make_examples displayed. If you're creating some kind of workflow yourself, you will need to make sure you check the error code of the runs. If make_examples died, you shouldn't proceed with call_variants. After my make_examples run and confirming that I have the output files, I ran call_variants:; ```; ## Run `call_variants`; ( time \; /opt/deepvariant/bin/call_variants \; --outfile ""HG002.cvo.tfrecord.gz"" \; --examples ""HG002.examples.tfrecord@${N_SHARDS}.gz"" \; --checkpoint ""model.ckpt"" \; ) 2>&1 | tee ""call_variants.log"" &; ```; When I run this on the same 64-core, 128GB RAM machine, it usually only uses about 500% CPU (instead of all of the 64 cores). This step took about 2m. I can confirm that I successfully run this step without the errors you saw. However, if I remove the files first by `rm -f HG002.examples.tfrecord*.gz` and then repeat the call_variants command above, I can see the errors you reported above:; ```; ValueError: Cannot find matching files with the pattern ""HG002.examples.tfrecord@64.gz""; ```. So, please make sure you that your make_examples step completed successfully before you proceed. (4) As you noticed so far, creating a workflow can be complicated (and mostly has nothing to do with variant caller itself). If you end up trying out the Cloud runner and has more questions, please feel free to get in touch with @nmousavi and the Cloud team. I'm sure the team will love to get your feedback if you decide to try it out. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:4777,checkpoint,checkpoint,4777,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,2,['checkpoint'],['checkpoint']
Availability,"but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; werkzeug 2.3.4 requires MarkupSafe>=2.1.1, but you have markupsafe 2.0.1 which is incompatible.; ========== [Mon 05 Jun 2023 03:51:39 PM UTC] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ========== [Mon 05 Jun 2023 03:51:40 PM UTC] Stage 'run-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:4019,ERROR,ERROR,4019,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,1,['ERROR'],['ERROR']
Availability,"but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; werkzeug 2.3.4 requires MarkupSafe>=2.1.1, but you have markupsafe 2.0.1 which is incompatible.; ========== [Mon 05 Jun 2023 10:22:30 PM EDT] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ========== [Mon 05 Jun 2023 10:22:31 PM EDT] Stage 'run-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053:5045,ERROR,ERROR,5045,,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053,1,['ERROR'],['ERROR']
Availability,"cal/lib/python3.8/site-packages/pip (python 3.8); ========== [Mon 05 Jun 2023 01:42:38 AM UTC] Stage 'Install python3 packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; werkzeug 2.3.4 requires MarkupSafe>=2.1.1, but you have markupsafe 2.0.1 which is incompatible.; ========== [Mon 05 Jun 2023 01:42:50 AM UTC] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; ========== [Mon 05 Jun 2023 01:42:51 AM UTC] Stage 'run-prereq.sh complete' starting; ```. For the other set of commands:; ```; > lsb_release -s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:8557,ERROR,ERROR,8557,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,1,['ERROR'],['ERROR']
Availability,"ckages that are installed. This behaviour is the source of the following dependency conflicts.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; ========== [Sun 04 Jun 2023 11:11:24 PM UTC] Stage 'Install TensorFlow pip package' starting; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; werkzeug 2.3.4 requires MarkupSafe>=2.1.1, but you have markupsafe 2.0.1 which is incompatible.; ========== [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install CUDA' starting; ========== [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install TensorRT' starting; ========== [Sun 04 Jun 2023 11:11:26 PM UTC] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; ========== [Sun 04 Jun 2023 11:11:27 PM UTC] Stage 'run-prereq.sh complete' starting; ```. The last time I tried running `./build-prereq.sh`, I got error on the building of Clif. llvm-11-linker-tools not available.; and now the error is:; ```; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276:3834,ERROR,ERROR,3834,,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276,1,['ERROR'],['ERROR']
Availability,"cker. ****. ***** Running the command:*****; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.293s; user 0m1.033s; sys 0m0.705s; I0910 01:14:39.661637 139749579556608 run_deepvariant.py:364] None; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>; app.run(main); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run; _run_main(main, args); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. I wonder is there any way to let me get the hidden parallel error message?. Best,; Jerry",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-689932270:4617,error,error,4617,,https://github.com/google/deepvariant/issues/345#issuecomment-689932270,1,['error'],['error']
Availability,"com/skvark/opencv-python.git; cd opencv-python/; # fetch the tags to your local repository; git fetch --all --tags --prune; # check out tag 3.4.5.20; git checkout tags/20; # load submoduel; git submodule update --init --recursive. # Dependency; pip install pyparsing; yum install qt-devel; # Build; python setup.py bdist_wheel. # Insatll; pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session; python -c ""import cv2""; ```. ## DV Prerequisite. ```bash; ####################################################################; # misc setup; ####################################################################. # development packages; yum install python2-pkgconfig zip zlib-devel unzip curl -y; # python packages; yum install python-devel python-pip python-wheel -y. ####################################################################; # python packages; ####################################################################. # python 2 required; echo ""$(python --version)""; echo ""$(pip --version)"". # Install python packages; pip install contextlib2; pip install enum34; pip install intervaltree; pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'; # pip install 'scipy==1.0' => skip as installed in TF; pip install 'oauth2client>=4.0.0'; pip install 'crcmod>=1.7'; pip install six; pip install sklearn; pip install pandas; pip install psutil; pip install --upgrade google-api-python-client. ####################################################################; # depend on opencv-python wheel - build from source; ####################################################################; pip install 'tensor2tensor>=1.9.0'. ####################################################################; # depend on - TensorFlow - 1.12 build from source; ####################################################################; pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ###########################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:16250,echo,echo,16250,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,4,['echo'],['echo']
Availability,"common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ========== [Mon 05 Jun 2023 10:22:31 PM EDT] Stage 'run-prereq.sh complete' starting; ========== [Mon 05 Jun 2023 10:22:31 PM EDT] Stage 'Update package list' starting; ========== [Mon 05 Jun 2023 10:22:32 PM EDT] Stage 'build-prereq.sh: Install development packages' starting; Calling wait_for_dpkg_lock.; ========== [Mon 05 Jun 2023 10:22:32 PM EDT] Stage 'Install bazel' starting; WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on.; Bazel 5.3.0 already installed on the machine, not reinstalling; ========== [Mon 05 Jun 2023 10:22:32 PM EDT] Stage 'Install CLIF binary' starting; CLIF already installed.; ========== [Mon 05 Jun 2023 10:22:32 PM EDT] Stage 'Download and configure TensorFlow sources' starting; HEAD is now at d5b57ca93e5 Merge pull request #58598 from tensorflow/vinila21-patch-1; You have bazel 5.3.0 installed.; Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.; 	--config=mkl 	# Build with MKL support.; 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL).; 	--config=mon",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053:6725,Down,Download,6725,,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053,1,['Down'],['Download']
Availability,"comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a “*partial*” recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didn’t feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):; ```; 39494 / 41450 (95.3%) full SNP recovery; 39678 / 41450 (95.7%) partial SNP recovery; ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and I’m not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the “*full*” SNP recovery was higher for the provided variants, but the “*partial*” SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:3215,recover,recovery,3215,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"compatible-pointer-types]; 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);; | ^~~; | |; | PyObject * {aka struct _object *}; In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,; from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,; from pandas/_libs/src/ujson/python/JSONtoObj.c:42:; /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected ‘const PyArrayObject *’ {aka ‘const struct tagPyArrayObject_fields *’} but argument is of type ‘PyObject *’ {aka ‘struct _object *’}; 1508 | PyArray_DATA(const PyArrayObject *arr); | ~~~~~~~~~~~~~~~~~~~~~^~~; pandas/_libs/src/ujson/python/JSONtoObj.c: In function ‘Object_npyArrayAddItem’:; pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: ‘PyArray_Descr’ {aka ‘struct _PyArray_Descr’} has no member named ‘elsize’; 260 | npyarr->elsize = dtype->elsize;; | ^~; pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of ‘PyArray_DATA’ from incompatible pointer type [-Wincompatible-pointer-types]; 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),; | ~~~~~~^~~~~; | |; | PyObject * {aka struct _object *}; In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,; from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,; from pandas/_libs/src/ujson/python/JSONtoObj.c:42:; /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected ‘const PyArrayObject *’ {aka ‘const struct tagPyArrayObject_fields *’} but argument is of type ‘PyObject *’ {aka ‘struct _object *’}; 1508 | PyArray_DATA(const PyArrayObject *arr); | ~~~~~~~~~~~~~~~~~~~~~^~~; pandas/_libs/src/ujson/python/JSONt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/859#issuecomment-2264852415:1163,error,error,1163,,https://github.com/google/deepvariant/issues/859#issuecomment-2264852415,1,['error'],['error']
Availability,"cp-cp27-none-linux_x86_64.whl; ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.12.0.deepvariant_gcp-cp27-none-linux_x86_64.whl; ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow; ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow; ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow; ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow; ++ export DV_INSTALL_GPU_DRIVERS=0; ++ DV_INSTALL_GPU_DRIVERS=0; +++ which python; ++ export PYTHON_BIN_PATH=/usr/bin/python; ++ PYTHON_BIN_PATH=/usr/bin/python; ++ export USE_DEFAULT_PYTHON_LIB_PATH=1; ++ USE_DEFAULT_PYTHON_LIB_PATH=1; ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'; ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'; + bazel; [bazel release 0.15.0]; Usage: bazel <command> <options> ... Available commands:; analyze-profile Analyzes build profile data.; build Builds the specified targets.; canonicalize-flags Canonicalizes a list of bazel options.; clean Removes output files and optionally stops the server.; coverage Generates code coverage report for specified test targets.; cquery Loads, analyzes, and queries the specified targets w/ configurations.; dump Dumps the internal state of the bazel server process.; fetch Fetches external repositories that are prerequisites to the targets.; help Prints help for commands, or the index.; info Displays runtime info about the bazel server.; license Prints the license of this software.; mobile-install Installs targets to mobile devices.; print_action Prints the command line args for compiling a file.; query Executes a dependency graph query.; run Runs the specified target.; shutdown Stops the bazel server.; test Builds and runs the specified test targets.; version Prints version information for bazel. Getting more help:; bazel help <command>; Prints help and op",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:9497,Avail,Available,9497,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['Avail'],['Available']
Availability,"cting a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,; A",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/135#issuecomment-450712530:1586,error,error,1586,,https://github.com/google/deepvariant/issues/135#issuecomment-450712530,1,['error'],['error']
Availability,"d (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out “complex variants” (with more than one variant at a position), but .vcf files containing those variants weren’t flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:; ```; 68759 / 72556 (94.8%) full SNP recovery; 71276 / 72556 (98.2%) partial SNP recovery; 3027 / 3648 (83.0%) full insertion recovery; 3413 / 3648 (93.6%) partial insertion recovery; 3119 / 3911 (79.7%) full deletion recovery; 3596 / 3911 (91.9%) partial deletion recovery; ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:; ```; 51417 / 54229 (94.8%) full SNP recovery; 53116 / 54229 (97.9%) partial SNP recovery; 1964 / 2391 (82.1%) full insertion recovery; 2242 / 2391 (93.8%) partial insertion recovery; 2058 / 2537 (81.1%) full deletion recovery; 2349 / 2537 (92.6%) partial deletion recovery; ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a “*partial*” recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didn’t feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:1810,recover,recovery,1810,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"d 48a66213fe; ```. - Test run command; ```sh; # BIN_VERSION=""1.0.0""; # ls -1 ${INPUT_DIR}; NA12878_S1.chr20.10_10p1mb.bam; NA12878_S1.chr20.10_10p1mb.bam.bai; test_nist.b37_chr20_100kbp_at_10mb.bed; test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; ucsc.hg19.chr20.unittest.fasta; ucsc.hg19.chr20.unittest.fasta.fai; ucsc.hg19.chr20.unittest.fasta.gz; ucsc.hg19.chr20.unittest.fasta.gz.fai; ucsc.hg19.chr20.unittest.fasta.gz.gzi. # docker run \; > -v ""${INPUT_DIR}"":""/input"" \; > -v ""${OUTPUT_DIR}"":""/output"" \; > google/deepvariant:""${BIN_VERSION}"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=/input/ucsc.hg19.chr20.unittest.fasta \; > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; > --regions ""chr20:10,000,000-10,010,000"" \; > --output_vcf=/output/output.vcf.gz \; > --output_gvcf=/output/output.g.vcf.gz \; > --intermediate_results_dir /output/intermediate_results_dir \; > --num_shards=1 \; >. Status: Downloaded newer image for google/deepvariant:1.0.0; I0911 02:28:36.697342 140021722134272 run_deepvariant.py:269] Creating a directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0911 02:28:39.900765 140366075229952 genomics_reader.py:223] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0911 02:28:39.914417 140366075229952 make_examples.py:587] Preparing inputs; I0911 02:28:39.915202 140366075229952 genomics_reader.py:223] Reading /input/NA12878_S1.chr20.10_10p1mb.b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-690842263:2832,Down,Downloaded,2832,,https://github.com/google/deepvariant/issues/345#issuecomment-690842263,1,['Down'],['Downloaded']
Availability,"d aperfmperf tsc_known_freq pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves ida arat pku ospke. > amd:~$ lscpu; > Architecture: x86_64; > CPU op-mode(s): 32-bit, 64-bit; > Byte Order: Little Endian; > CPU(s): 48; > On-line CPU(s) list: 0-47; > Thread(s) per core: 2; > Core(s) per socket: 24; > Socket(s): 1; > NUMA node(s): 3; > Vendor ID: AuthenticAMD; > CPU family: 23; > Model: 1; > Model name: AMD EPYC 7571; > Stepping: 2; > CPU MHz: 2524.374; > BogoMIPS: 4399.90; > Hypervisor vendor: KVM; > Virtualization type: full; > L1d cache: 32K; > L1i cache: 64K; > L2 cache: 512K; > L3 cache: 8192K; > NUMA node0 CPU(s): 0-7,24-31; > NUMA node1 CPU(s): 8-15,32-39; > NUMA node2 CPU(s): 16-23,40-47; > Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid amd_dcm aperfmperf tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch topoext perfctr_core vmmcall fsgsbase bmi1 avx2 smep bmi2 rdseed adx smap clflushopt sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save. When I run run_wes_case_study_docker.sh on the Intel instance make_examples.py load avg is 48, call_variants.py load avg is 36 (takes about 1.5 minutes), and the it completes in about 13-15 minutes. Using the AMD instance make_examples.py load avg is 48, call_variants.py load avg is 86 (takes about 6 minutes), and it completes in about 20-23 minutes. It looks like when using AMD it slows down considerably during the call_variants.py step.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/274#issuecomment-603439134:3000,down,down,3000,,https://github.com/google/deepvariant/issues/274#issuecomment-603439134,1,['down'],['down']
Availability,"d conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort. failed ; UnsatisfiableError: ; ```. **Second option with the label**. `conda install -c bioconda/label/cf201901 deepvariant`. Output:; ```; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort. failed ; UnsatisfiableError:; ```. **Noticed that required version is 2.7 so I removed the environment and tried to install it with this version**. `conda remove --name deepvariant --all`; `conda create -n deepvariant python=2.7 deepvariant` . Output:; ```; Collecting package metadata (repodata.json): done; Solving environment: - ; Found conflicts! Looking for incompatible packages. failed ; UnsatisfiableError: The following specifications were found to be incompatible with each other:; Output in format: Requested package -> Available versions; Package python conflicts for:; python=2.7; deepvariant -> python[version='2.7.*|>=2.7,<2.8.0a0']; deepvariant -> boost -> python[version='3.4.*|3.5.*|3.6.*|>=3.5,<3.6.0a0|>=3.8,<3.9.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.6|3.7.*']; ```. **After reading this issue: https://github.com/google/deepvariant/issues/177, I tried to constrain google-cloud-sdk version**. `conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'`. Output:; ```; Collecting package metadata (repodata.json): done; Solving environment: / Found conflicts! Looking for incompatible packages. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. Package google-cloud-sdk conflicts for:; google-cloud-sdk[version='<243.0.0']; deepvariant -> google-cloud-sdk. Package python conflicts for:; python=2.7; deepvariant -> python[version='2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/177#issuecomment-584370219:1518,Avail,Available,1518,,https://github.com/google/deepvariant/issues/177#issuecomment-584370219,1,['Avail'],['Available']
Availability,"d to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```; # install gsutil; curl https://sdk.cloud.google.com | bash; exec -l $SHELL; # verify that gsutil is working; gsutil. # install wget and bzip2, which are both needed to download miniconda; sudo yum install bzip2 wget; wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh; bash Miniconda2-latest-Linux-x86_64.sh ; source ~/.bashrc. # gsutil is failing now; gsutil; export BOTO_CONFIG=/dev/null; # gsutil should be working again; gsutil. # create new conda env, add channels, install deepvaraint; conda create -n dv python=2.7; conda activate dv; conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge; conda install -n dv deepvariant -v; ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`?; * Did you add all conda channels in the correct order?; * Could you post the entire output from running `conda install -v deepvariant`?. CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-452921108:1053,down,download,1053,,https://github.com/google/deepvariant/issues/137#issuecomment-452921108,3,"['down', 'error']","['download', 'error']"
Availability,"d version of Samtools so once I updated I tried using use the hg19.fa. I have updated and rebuilt my fai files using the command samtools faidx hg19.fa . I've set my environment variables as the following:; BIN_VERSION=""0.10.0""; BASE=""${HOME}/deepvariant-run""; INPUT_DIR=""${BASE}/input""; REF=""hg19.fa""; BAM=""2009617.cram""; OUTPUT_DIR=""${BASE}/output""; DATA_DIR=""${INPUT_DIR}/data""; OUTPUT_VCF=""2009617.vcf.gz""; OUTPUT_GVCF=""2009617.bam.g.vcf.gz""; OUTPUT_GVCF=""2009617.bam.g.vcf.gz""; Here is the command to execute deepvariant:; sudo docker run \; -v ""${DATA_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""/input/${REF}"" \; --reads=""/input/${BAM}"" \; --output_vcf=/output/${OUTPUT_VCF} \; --output_gvcf=/output/${OUTPUT_GVCF} \; --num_shards=$(nproc); and here is the new errors I'm seeing:; ValueError: Failed precondition: Cannot query without an index; parallel: This job failed:. Which eventually leads to the following errors where the process fails and ends: Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>; app.run(main); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run; _run_main(main, args); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples; --mode calling --ref ""/input/hg19.fa"" --reads ""/input/2009617.cram"" --examples ""/tmp/tmp1cb8k6ly/make_examples.tfrecord@1; 6.gz"" --gvcf ""/tmp/tmp1cb8k6ly/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/307#issuecomment-628230170:1192,error,errors,1192,,https://github.com/google/deepvariant/issues/307#issuecomment-628230170,1,['error'],['errors']
Availability,"d"" \; --gvcf ""HG002.gvcf.tfrecord@${N_SHARDS}.gz"" \; --task {} \; ) 2>&1 | tee ""make_examples.log""; ```; This took on 13m33.192s a 64-core, 128GB RAM machine. Before I proceeded with call_variants, I first checked that the output files from make_examples exist:; ```; ls HG002.examples.tfrecord*.gz | wc -l; ```; I see 64 of them here.; A common issue is that if the make_examples step failed but you didn't notice, then the next step will fail.; Common failure modes I've seen before:; - if you were running make_examples, but abort in the middle by ctrl-c. Sometimes not all the make_examples in the background were killed. If you just re-run make_examples without killing all background make_examples first, the output might be corrupted.; - if make_examples failed completely without outputting HG002.examples.tfrecord*.gz at all, it'll also cause a failure. Our hope is that you'll notice this in the errors that make_examples displayed. If you're creating some kind of workflow yourself, you will need to make sure you check the error code of the runs. If make_examples died, you shouldn't proceed with call_variants. After my make_examples run and confirming that I have the output files, I ran call_variants:; ```; ## Run `call_variants`; ( time \; /opt/deepvariant/bin/call_variants \; --outfile ""HG002.cvo.tfrecord.gz"" \; --examples ""HG002.examples.tfrecord@${N_SHARDS}.gz"" \; --checkpoint ""model.ckpt"" \; ) 2>&1 | tee ""call_variants.log"" &; ```; When I run this on the same 64-core, 128GB RAM machine, it usually only uses about 500% CPU (instead of all of the 64 cores). This step took about 2m. I can confirm that I successfully run this step without the errors you saw. However, if I remove the files first by `rm -f HG002.examples.tfrecord*.gz` and then repeat the call_variants command above, I can see the errors you reported above:; ```; ValueError: Cannot find matching files with the pattern ""HG002.examples.tfrecord@64.gz""; ```. So, please make sure you that your make_examples s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:4423,error,error,4423,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,2,['error'],['error']
Availability,"delAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064""; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub<; > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,; > or mute the thread<; > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>.; >; >; > This message contains confidential information and is intended only for; > the individual named. If you are not the named addressee you should not; > disseminate, distribute or copy this e-mail. Please notify the sender; > immediately by e-mail if you have received this e-mail by mistake and; > delete this e-mail from your system. E-mail transmission cannot be; > guaranteed to be secured or error-free as information could be intercepted,; > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses.; > The sender therefore does not accept liability for any errors or omissions; > in the contents of this message, which arise as a result of e-mail; > transmission. If verification is required please request a hard-copy; > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort; > Myers, FL 33913, http://www.neogenomics.com (2017); >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>; > .; >. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381164890:3215,error,errors,3215,,https://github.com/google/deepvariant/issues/62#issuecomment-381164890,1,['error'],['errors']
Availability,"dependency of numpy 1.14.6; OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6; # verify; python -c ""import numpy"". # dependecy of scipy 1.2.0; OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0; # verify; python -c ""import scipy"". # pip package dependencies; # pip install pip six wheel mock; pip install wheel autograd h5py==2.9.0 enum34; pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code; git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12; cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc; PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \; PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \; TF_NEED_IGNITE=""0"" \; TF_ENABLE_XLA=""0"" \; TF_NEED_OPENCL_SYCL=""0"" \; TF_NEED_ROCM=""0"" \; TF_NEED_MPI=""0"" \; TF_NEED_TENSORRT=""0"" \; TF_NEED_CUDA=""1"" \; TF_CUDA_VERSION=""10.0"" \; CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \; TF_CUDNN_VERSION=""7"" \; CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \; TF_NCCL_VERSION=""2"" \; NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \; NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \; TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \; TF_CUDA_CLANG=""0"" \; GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \; CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \; TF_SET_ANDROID_WORKSPACE=0 \; ./configure. # fix build error; vim /opt/at11.0/include/bits/floatn.h; -------------------------",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:9623,down,download,9623,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['down'],['download']
Availability,"dir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"") ; -- Checking for module 'protobuf'; -- Found protobuf, version 3.13.0; -- Checking for module 'libglog'; -- Found libglog, version 0.4.0; -- Looking for pthread.h; -- Looking for pthread.h - found; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed; -- Looking for pthread_create in pthreads; -- Looking for pthread_create in pthreads - not found; -- Looking for pthread_create in pthread; -- Looking for pthread_create in pthread - found; -- Found Threads: TRUE ; CMake Error at clif/cmake/modules/CLIFUtils.cmake:37 (find_package):; Could not find a configuration file for package ""LLVM"" that is compatible; with requested version ""11.1.0"". The following configuration files were considered but not accepted:. /usr/lib/llvm-11/lib/cmake/llvm/LLVMConfig.cmake, version: 11.0.0; /usr/lib/llvm-11/cmake/LLVMConfig.cmake, version: 11.0.0; /lib/llvm-11/cmake/LLVMConfig.cmake, version: 11.0.0. Call Stack (most recent call first):; clif/CMakeLists.txt:22 (include). -- Configuring incomplete, errors occurred!; See also ""/root/clif/build/CMakeFiles/CMakeOutput.log"".; See also ""/root/clif/build/CMakeFiles/CMakeError.log"". real	2m44.183s; user	0m18.337s; sys	0m18.865s; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276:6057,Error,Error,6057,,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276,2,"['Error', 'error']","['Error', 'errors']"
Availability,"directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```; $ build status. Checking DeepVariant build prerequisites... OK; Checking DeepVariant test environment compatibility [GPU]... OK; Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]?. ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```; $ ./build help; ...; cloudbuild Builds Docker images of DeepVariant, and ; pushes them on the Google Container Registry (gcr.io) ; ... $ ./build cloudbuild help; CPU Builds a DeepVariant Docker image for CPU usage.; GPU Builds a DeepVariant Docker image for GPU usage.; Runner Builds a DeepVariant Docker image for large-scale analysis run; using the Genomics Pipelines API. $; ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/87#issuecomment-413745335:1739,avail,available,1739,,https://github.com/google/deepvariant/issues/87#issuecomment-413745335,2,['avail'],['available']
Availability,"dnn.h /usr/local/cuda-11/include; # sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-11/lib64/; # sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-11/lib64/; # sudo chmod a+r /usr/local/cuda-11/lib64/libcudnn*; # sudo ldconfig; # fi; # # Tensorflow says to do this.; # sudo -H apt-get install ""${APT_ARGS[@]}"" libcupti-dev > /dev/null; # fi. # # If we are doing a gpu-build, nvidia-smi should be install. Run it so we; # # can see what gpu is installed.; # nvidia-smi || :; # fi. # ################################################################################; # # TensorRT; # ################################################################################. # note_build_stage ""Install TensorRT"". # # Address the issue:; # # 'dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory'; # # It's unclear whether we need this or not. Setting up to get rid of the errors.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # pip3 install ""${PIP_ARGS[@]}"" nvidia-tensorrt; # echo ""For debugging:""; # pip3 show nvidia-tensorrt; # TENSORRT_PATH=$(python3 -c 'import tensorrt; print(tensorrt.__path__[0])'); # sudo ln -sf ""${TENSORRT_PATH}/libnvinfer.so.8"" ""${TENSORRT_PATH}/libnvinfer.so.7""; # sudo ln -sf ""${TENSORRT_PATH}/libnvinfer_plugin.so.8"" ""${TENSORRT_PATH}/libnvinfer_plugin.so.7""; # export LD_LIBRARY_PATH=""${LD_LIBRARY_PATH-}:${TENSORRT_PATH}""; # sudo ldconfig; # # Just in case this still doesn't work, we link them.; # # This is a workaround that we might want to get rid of, if we can make sure; # # setting LD_LIBRARY_PATH and `sudo ldconfig`` works.; # if [[ ! -e /usr/local/nvidia/lib ]]; then; # sudo mkdir -p /usr/local/nvidia/lib; # sudo ln -sf ""${TENSORRT_PATH}//libnvinfer.so.7"" /usr/local/nvidia/lib/libnvinfer.so.7; # sudo ln -sf ""${TENSORRT_PATH}//libnvinfer_plugin.so.7"" /usr/local/nvidia/lib/libnvinfer_plugin.so.7; # fi; # fi; ```. The output for `./run-prereq.sh`:; ```; ========== This script is only maintained for Ubuntu 20.04.; ========== Load config set",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:5274,echo,echo,5274,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,2,['echo'],['echo']
Availability,"dn’t feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), and these are the statistics for the provided .vcf files (from my script):; ```; 39494 / 41450 (95.3%) full SNP recovery; 39678 / 41450 (95.7%) partial SNP recovery; ```. I am omitted the indel statistics from my script because Veritas used freebayes for variant calling (and I’m not converting the indel format, causing the indel count to be quite low, presumably because most overlapped a homopolymer of at least 2 nucleotides). **Still, maybe it is interesting that the “*full*” SNP recovery was higher for the provided variants, but the “*partial*” SNP recovery was higher for DeepVariant?** The precisionFDA comparison (for my samples) shows better results for DeepVariant than the provided VCF files (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as sho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:3545,recover,recovery,3545,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,4,['recover'],['recovery']
Availability,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2; sudo docker push localhost:5000/deepvariant:latest; SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest; ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant-${VERSION}.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \; --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz ; ```. ## GPU image; ```; VERSION=0.9.0-gpu; sudo nvidia-docker pull google/deepvariant:${VERSION}; sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest; sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2; sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest; SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest; ```. Running through Quick Start just to make sure nothing wrong:; ```; singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant-${VERSION}.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \; --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz ; ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc; For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh; and; https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/243#issuecomment-561996442:3248,error,errors,3248,,https://github.com/google/deepvariant/issues/243#issuecomment-561996442,2,['error'],['errors']
Availability,"does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_dqd3ut4s/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '32']"".; E0430 18:57:45.247818 140240365713216 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_8s9w7qaa/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '25']"".; E0430 18:57:45.247906 139736525375296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_8kqng5_c/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '1']"".; E0430 18:57:45.354531 139703252227904 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_47rk8xc1/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '22']"".; E0430 18:57:45.318170 140515109386048 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_4p5rc3ja/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '35']"".; E0430 18:57:45.306068 140062873229120 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xavizfpc/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '42']"".; E0430 18:57:45.268234 140590012761920 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_ovmu_l59/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '8']"".; parallel: This job failed:. could you provide any guidance on how to run the make_example.zip working on parallel (like create a 48 jobs)? Thanks",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:13006,error,errors,13006,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,12,"['error', 'failure']","['errors', 'failure']"
Availability,"don't know if this is the ultimate problem. The first command within the docker seems to complete with no errors:. ***** Running the command:*****; time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hs37d5.fa.gz"" --reads ""/input/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --regions ""20"" --task {}. ...omitting much output... It does take 40 minutes as opposed to the advertised 8, though. I was using pre-emptible instances so perhaps this caused delay, but I did test it 3 times, and it is reliably ~40 mins each time. The second command within the docker dies, this is all the output:. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --; checkpoint ""/opt/models/wgs/model.ckpt""; I1217 09:08:41.108182 139680301201152 call_variants.py:313] Set KMP_BLOCKTIME to 0; 2020-12-17 09:08:41.511115: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA; 2020-12-17 09:08:42.039849: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz; 2020-12-17 09:08:42.070759: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5abc760 executing computations on platform Host. Devices:; 2020-12-17 09:08:42.070838: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>; 2020-12-17 09:08:42.092135: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for ; best performance.; I1217 09:08:42.442809 139680301201152 modeling.py:560] Initializing model with random parameters; W1217 09:08:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/399#issuecomment-749313156:1443,checkpoint,checkpoint,1443,,https://github.com/google/deepvariant/issues/399#issuecomment-749313156,1,['checkpoint'],['checkpoint']
Availability,downloading http://security.debian.org/debian-security/pool/updates/main/o/openssl/libssl1.0.0_1.0.1t-1+deb8u10_amd64.deb followed by; ```; sudo dpkg --install libssl1.0.0_1.0.1t-1+deb8u10_amd64.deb; ```; seems to work on WSL debian 9,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/41#issuecomment-466661657:0,down,downloading,0,,https://github.com/google/deepvariant/issues/41#issuecomment-466661657,1,['down'],['downloading']
Availability,"dynamic_kernels	# (Experimental) Build kernels into separate shared objects.; 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API.; Preconfigured Bazel build configs to DISABLE default on features:; 	--config=nogcp 	# Disable GCP support.; 	--config=nonccl 	# Disable NVIDIA NCCL support.; Configuration finished; ========== [Mon 05 Jun 2023 04:03:16 PM UTC] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting; Found existing installation: pyparsing 3.0.9; Uninstalling pyparsing-3.0.9:; Successfully uninstalled pyparsing-3.0.9; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; Using pip 23.1.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Installing collected packages: pyparsing; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.22.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; ========== [Mon 05 Jun 2023 04:03:17 PM UTC] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting; Found existing installation: pyparsing 2.2.0; Uninstalling pyparsing-2.2.0:; Successfully uninstalled pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:9338,ERROR,ERROR,9338,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,1,['ERROR'],['ERROR']
Availability,"dynamic_kernels	# (Experimental) Build kernels into separate shared objects.; 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API.; Preconfigured Bazel build configs to DISABLE default on features:; 	--config=nogcp 	# Disable GCP support.; 	--config=nonccl 	# Disable NVIDIA NCCL support.; Configuration finished; ========== [Mon 05 Jun 2023 10:22:33 PM EDT] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting; Found existing installation: pyparsing 3.0.9; Uninstalling pyparsing-3.0.9:; Successfully uninstalled pyparsing-3.0.9; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; Using pip 23.1.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Installing collected packages: pyparsing; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.22.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; ========== [Mon 05 Jun 2023 10:22:33 PM EDT] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting; Found existing installation: pyparsing 2.2.0; Uninstalling pyparsing-2.2.0:; Successfully uninstalled pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053:8861,ERROR,ERROR,8861,,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053,1,['ERROR'],['ERROR']
Availability,"e ""/tmp/Bazel.runfiles_im0i33s_/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main; make_examples_runner(options); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner; candidates, examples, gvcfs, runtimes = region_processor.process(region); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process; reads = self.region_reads(region); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads; error_message + '\nFailed to parse BAM/CRAM file. '; ValueError: Data loss: Failed to parse SAM record; Failed to parse BAM/CRAM file. This is often caused by:; (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file.; (2) Your BAM/CRAM file could be corrupted. Please check its md5.; If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues; ```. It seems like for this particular failure mode (BAM file is truncated), the default stackt race was already clear.; But given that I mentioned different level of verbosity. I tried that next. ## Use `-v` to increase verbosity level. if you run `/opt/deepvariant/bin/make_examples --helpfull` you'll see this flag:. ```; -v,--verbosity: Logging verbosity level. Messages logged at this level or; lower will be included. Set to 1 for debug logging. If the flag was not set; or supplied, the value will be changed from the default of -1 (warning) to 0; (info) after flags are parsed.; (default: '-1'); (an integer); ```; You can try to add `-v 1`. But in this case above, my run already",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:13403,error,error,13403,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,2,['error'],['error']
Availability,"e ""/tmp/Bazel.runfiles_jqt5759c/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_jqt5759c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main; make_examples_runner(options); File ""/tmp/Bazel.runfiles_jqt5759c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner; candidates, examples, gvcfs, runtimes = region_processor.process(region); File ""/tmp/Bazel.runfiles_jqt5759c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process; reads = self.region_reads(region); File ""/tmp/Bazel.runfiles_jqt5759c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads; error_message + '\nFailed to parse BAM/CRAM file. '; ValueError: Data loss: Failed to parse SAM record; Failed to parse BAM/CRAM file. This is often caused by:; (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file.; (2) Your BAM/CRAM file could be corrupted. Please check its md5.; If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.truncated.bam --examples /tmp/tmpj5fx0phm/make_examples.tfrecord@1.gz --gvcf /tmp/tmpj5fx0phm/gvcf.tfrecord@1.gz --task 0. real 1m25.608s; user 1m28.020s; sys 0m5.611s; I0629 23:10:12.080424 139667868600064 run_deepvariant.py:416] None; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>; app.run(main); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run; _run_main(main, args); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:6716,error,error,6716,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,2,['error'],['error']
Availability,"e more of an ensemble model approach in the future, where you you want to push your data through multiple pipelines for comparison. At that point you're not even writing code anymore, but rather directing transformation among (ephemeral) datasets through an intermediate analysis language ([DSL](https://en.wikipedia.org/wiki/Domain-specific_language)) to try out different ideas upon a collection of data -- where some might contain/become golden standards. For example, now you have collections of transformed datasets streamlined as protobuf message, which can be filter-inspected as JSON as necessary for validation purposes, which you can do now such as for `CallVariantsOutput` among others:. ```; variant {; reference_bases: ""A""; alternate_bases: ""C""; calls {; info {; key: ""AD""; ...; call_set_name: ""Sample_Diag-excap51-HG002-EEogPU""; }; end: 1115835; reference_name: ""1""; start: 1115834; ...; ```. So what I'm humbly proposing is something more subtle and flexible. Imagine you open a genome browser, and search for a specific disease. It then can have you drill down to the available samples or the variation graph. For the variation graph it will allow you to see a model of transitions among samples relating the temporal behavior of subtypes of cancer. All these steps are multiple pipelines that are auto-triggered to run accordingly, or would be pre-cached results. As new samples come in, it improves the disease models, or other functional analysis. This opens doors to Personlized Medicine -- clinicians, research, or patients -- enabling integrated analysis that is centralized for different types of datasets. You already have the protobuf data-structures for initiating that, thus allowing your stored collection of pipelines to drive that integration and comparison to take place, of which DeepVariant would be one of many. Thus flexibility in the form of modularity when refactoring the codebase will allow for more fluid hierarchical analysis to take place down the line. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/21#issuecomment-353849339:2275,down,down,2275,,https://github.com/google/deepvariant/issues/21#issuecomment-353849339,3,"['avail', 'down']","['available', 'down']"
Availability,"e present on the command line: ""['/tmp/Bazel.runfiles_1k7ckjbn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '44']"".; E0430 18:57:45.264230 139873562601280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_qtxrg7dl/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '6']"".; E0430 18:57:45.193969 139692519348032 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_05qe3qax/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '36']"".; E0430 18:57:45.197033 140638292031296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_75j2ynwd/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '5']"".; E0430 18:57:45.264279 139811152422720 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i060jaf0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:7430,error,errors,7430,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability,"e present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_q2sdkm67/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '23']"".; E0430 18:57:45.246095 140479227369280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_uphv_tdy/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '37']"".; E0430 18:57:45.317537 139819477477184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_4750gtic/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '43']"".; E0430 18:57:45.318566 140493027030848 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_mw222qvc/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '19']"".; E0430 18:57:45.281981 139640920373056 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:10496,error,errors,10496,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability,"e present on the command line: ""['/tmp/Bazel.runfiles_3ci75isq/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '30']"".; E0430 18:57:45.312847 140640366352192 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_3bfx8qjn/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3']"".; E0430 18:57:45.285222 140677590058816 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_pbohkh7d/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '40']"".; E0430 18:57:45.251970 140221024618304 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_r241voor/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '0']"".; E0430 18:57:45.291264 139938218350400 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_q2sdkm67/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '23']"".; E0430 18:57:45.246095 140479227369280 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_uphv_tdy/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '37']"".; E0430 18:57:45.317537 139819477477184 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_4750gtic/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '43']"".; E0430 18:57:45.318566 140493027030848 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:10217,error,errors,10217,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability,"e present on the command line: ""['/tmp/Bazel.runfiles_9oblbsyi/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '33']"".; E0430 18:57:45.128387 140717112878912 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_gd9fj22_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '2']"".; E0430 18:57:45.149224 139802704738112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_2hbfxd92/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '16']"".; E0430 18:57:45.196900 140351706515264 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles__ytoy0a6/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '4']"".; E0430 18:57:45.304501 140371551012672 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_w7jwxlqo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '28']"".; E0430 18:57:45.337900 139621533210432 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_22p2hp0z/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '45']"".; E0430 18:57:45.424449 139874966882112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_wv1oakms/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '46']"".; E0430 18:57:45.268234 140085723301696 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:1574,error,errors,1574,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability,"e present on the command line: ""['/tmp/Bazel.runfiles_gd9fj22_/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '2']"".; E0430 18:57:45.149224 139802704738112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_2hbfxd92/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '16']"".; E0430 18:57:45.196900 140351706515264 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles__ytoy0a6/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '4']"".; E0430 18:57:45.304501 140371551012672 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_w7jwxlqo/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '28']"".; E0430 18:57:45.337900 139621533210432 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_22p2hp0z/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '45']"".; E0430 18:57:45.424449 139874966882112 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_wv1oakms/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '46']"".; E0430 18:57:45.268234 140085723301696 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_g62feq4g/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '10']"".; E0430 18:57:45.190006 140494428116800 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:1853,error,errors,1853,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability,"e present on the command line: ""['/tmp/Bazel.runfiles_qtxrg7dl/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '6']"".; E0430 18:57:45.193969 139692519348032 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_05qe3qax/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '36']"".; E0430 18:57:45.197033 140638292031296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_75j2ynwd/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '5']"".; E0430 18:57:45.264279 139811152422720 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_i060jaf0/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '27']"".; E0430 18:57:45.313135 139973217675072 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_p96gjj9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '11']"".; E0430 18:57:45.286854 139660079433536 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_fhgr5den/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '26']"".; E0430 18:57:45.266479 139743940249408 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_09rk_ns4/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '9']"".; E0430 18:57:45.246133 140107102431040 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:7709,error,errors,7709,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,2,['error'],['errors']
Availability,"e to try this on a GCE (Google Compute Engine) instance. First, when I looked at your file, I suspect it won't take much resource and time at all. And from my experiment below, it matches my expectation. Quick summary:; It took me about **24 seconds**, on a [n1-standard-1](https://cloud.google.com/compute/docs/machine-types#standard_machine_types) instance (which has **3.75GB** RAM) to run postprocess_variants on your file. Below, I will share all the steps I used to produce the result.; And, my next step (which won't be today) will be to try to run this on an AWS instance. . Here are the steps I've done:. 1. On my machine, I used this command to get a GCE instance:; ```; gcloud compute instances create ""${USER}-1"" \; --image-family ""ubuntu-1604-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-1"" \; --zone ""us-west1-b""; ```. 2. I ssh'ed into the machine using this command:; ```; gcloud compute ssh ""${USER}-1""; ```. 3. I downloaded the input file needed:; ```; # Downloading the reference file takes a while.; # It's only used for the header in postprocess_variants.; wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz; gunzip ucsc.hg19.fasta.gz; wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz; gunzip ucsc.hg19.fasta.fai.gz. # Download the output from call_variants step:; wget https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz; ```. 4. I pull the docker image, and run the command:; ```; sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.7.2. time sudo docker run \; -v ${PWD}:/data \; gcr.io/deepvariant-docker/deepvariant:0.7.2 \; /opt/deepvariant/bin/postprocess_variants \; --ref /data/ucsc.hg19.fasta \; --infile /data/call_variants_output.tfrecord.gz \; --outfile /data/output.vcf.gz; ```. As I mentioned, this took:; ```; real 0m24.779s; user 0m0.033s; sys 0m0.022s; ```. I used `top` to keep an eye on the memory usage. The highest I'v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480150395:984,down,downloaded,984,,https://github.com/google/deepvariant/issues/167#issuecomment-480150395,2,"['Down', 'down']","['Downloading', 'downloaded']"
Availability,"e when there is; # an official solution from CLIF.; # GitHub issues such as https://github.com/google/deepvariant/issues/29 has; # some relevant pointers. set -eux -o pipefail. # Figure out which linux installation we are on to fetch an appropriate version; # of CLIF binary. Note that we only support now Ubuntu (14 and 16), and Debian.; if [[ $(python -mplatform) == *""Ubuntu-16""* ]]; then; export DV_PLATFORM=""ubuntu-16""; # For ubuntu 16 we install cmake; sudo -H apt-get -y install cmake; elif [[ $(python -mplatform) == *""Ubuntu-14""* ]]; then; export DV_PLATFORM=""ubuntu-14""; # For ubuntu 14 we install cmake3; sudo -H apt-get -y install cmake3; elif [[ $(python -mplatform | grep '[Dd]ebian-\(rodete\|9.*\)') ]]; then; export DV_PLATFORM=""debian""; # For recent debian, we install cmake.; sudo -H apt-get -y install cmake; else; export DV_PLATFORM=""unknown""; exit ""unsupported platform""; fi. CLIF_DIR=/usr/local/clif; CLIF_PACKAGE=""oss_clif.${DV_PLATFORM}.latest.tgz"". # Install prereqs.; sudo -H apt-get -y install ninja-build subversion; sudo -H apt-get -y install virtualenv python-pip pkg-config; sudo -H pip install 'pyparsing>=2.2.0'; sudo -H pip install 'protobuf>=3.4'. echo === building protobufs. sudo -H apt-get install -y autoconf automake libtool curl make g++ unzip; wget https://github.com/google/protobuf/releases/download/v3.4.1/protobuf-cpp-3.4.1.tar.gz; tar xvzf protobuf-cpp-3.4.1.tar.gz; (cd protobuf-3.4.1 &&; ./autogen.sh &&; ./configure &&; make -j 32 &&; make -j 32 check &&; sudo make -j 32 install &&; sudo ldconfig). echo === building CLIF. git clone https://github.com/google/clif.git; sed -i 's/\$HOME\/opt/\/usr\/local/g' clif/INSTALL.sh; sed -i 's/-j 2//g' clif/INSTALL.sh; (cd clif && sudo ./INSTALL.sh). echo === creating package tgz. sudo find ${CLIF_DIR} -type d -exec chmod a+rx {} \;; sudo find ${CLIF_DIR} -type f -exec chmod a+r {} \;; tar czf ""${CLIF_PACKAGE}"" /usr/local/lib/libproto* ""${CLIF_DIR}"". echo === SUCCESS: package is ""${CLIF_PACKAGE}""; ; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-385130636:2899,echo,echo,2899,,https://github.com/google/deepvariant/issues/29#issuecomment-385130636,10,"['down', 'echo']","['download', 'echo']"
Availability,"e_examples not complete properly:; >; > paul@gubuntu:~/data/luisa$ wget http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > --2018-03-07 <http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam--2018-03-07> 16:20:42-- http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > Resolving dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)... 52.218.52.113; > Connecting to dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)|52.218.52.113|:80... connected.; > HTTP request sent, awaiting response... 200 OK; > Length: 357342653 (341M) [binary/octet-stream]; > Saving to: âENCFF528VXT.bamâ; >; > ENCFF528VXT.bam 100%[=========================================================>] 340.79M 1.26MB/s in 5m 17s; >; > 2018-03-07 16:25:59 (1.08 MB/s) - âENCFF528VXT.bamâ saved [357342653/357342653]; >; > paul@gubuntu:~/data/luisa$ samtools index ENCFF528VXT.bam; > [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; > [E::bgzf_read] Read block operation failed with error -1 after 143 of 246 bytes; > samtools index: failed to create index for ""ENCFF528VXT.bam""; > paul@gubuntu:~/data/luisa$; > paul@gubuntu:~/data/luisa$; > paul@gubuntu:~/data/luisa$ cd ~/deepvariant/bazel-bin; > paul@gubuntu:~/deepvariant/bazel-bin$ PYTHONPATH=. /usr/bin/python deepvariant/make_examples --mode calling --ref /home/paul/data/luisa/hg19.fa --reads /home/paul/data/luisa/ENCFF528VXT.bam --examples /home/paul/data/luisa/shardedExamples/examples.tfrecord@2.gz --regions chr20:10,000,000-10,010,000 --task 0; > WARNING: Logging before flag parsing goes to stderr.; > I0307 16:27:52.052795 140569100494592 client.py:1004] Timeout attempting to reach GCE metadata service.; > W0307 16:27:52.112967 140569100494592 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib; > [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; > Traceback (most recent call last):; > File ""/home/paul/.cache/bazel/_bazel_p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371306075:1589,error,error,1589,,https://github.com/google/deepvariant/issues/52#issuecomment-371306075,2,['error'],['error']
Availability,"e_examples_runner; candidates, examples, gvcfs, runtimes = region_processor.process(region); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process; reads = self.region_reads(region); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads; error_message + '\nFailed to parse BAM/CRAM file. '; ValueError: Data loss: Failed to parse SAM record; Failed to parse BAM/CRAM file. This is often caused by:; (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file.; (2) Your BAM/CRAM file could be corrupted. Please check its md5.; If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues; ```. It seems like for this particular failure mode (BAM file is truncated), the default stackt race was already clear.; But given that I mentioned different level of verbosity. I tried that next. ## Use `-v` to increase verbosity level. if you run `/opt/deepvariant/bin/make_examples --helpfull` you'll see this flag:. ```; -v,--verbosity: Logging verbosity level. Messages logged at this level or; lower will be included. Set to 1 for debug logging. If the flag was not set; or supplied, the value will be changed from the default of -1 (warning) to 0; (info) after flags are parsed.; (default: '-1'); (an integer); ```; You can try to add `-v 1`. But in this case above, my run already had useful logging and didn't seem to produce more useful logs. ## What if we run with Singularity?. I think you were running with Singularity, so I tried that too. I repeated the steps in https://github.com/google/deepvariant/issues/463#issuecomment-866352316 to install Singularity. And then with the same data, I ran:. ```; # Pull the image.; BIN_VERSION=1.1.0; singular",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:13702,failure,failure,13702,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,2,['failure'],['failure']
Availability,"e_session; return self._get_session_manager().prepare_session(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session; sess, is_loaded_from_checkpoint = self._restore_checkpoint(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint; _restore_checkpoint_and_maybe_run_saved_model_initializers(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers; saver.restore(sess, path); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore; raise _wrap_restore_error_with_msg(; tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt; [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874:17650,checkpoint,checkpoint,17650,,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874,2,['checkpoint'],['checkpoint']
Availability,"e_v2(filename_tensor, names, slices, dtypes); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper; op = g._create_op_internal(op_type_name, inputs, dtypes=None,; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal; ret = Operation(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__; self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor; return CheckpointReader.CheckpointReader_GetTensor(; RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore; names_to_keys = object_graph_key_mapping(save_path); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping; object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor; error_translator(e); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator; raise errors_impl.NotFoundError(None, None, error_message); tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, ano",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874:13029,checkpoint,checkpoint,13029,,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874,2,['checkpoint'],['checkpoint']
Availability,"eading state information... Done; The following packages will be REMOVED:; docker-ce-rootless-extras slirp4netns; 0 upgraded, 0 newly installed, 2 to remove and 0 not upgraded.; After this operation, 19.2 MB disk space will be freed.; Do you want to continue? [Y/n] Y; (Reading database ... 177786 files and directories currently installed.); Removing docker-ce-rootless-extras (5:24.0.2-1~ubuntu.20.04~focal) ...; Removing slirp4netns (0.4.3-1) ...; Processing triggers for man-db (2.9.1-1) ...; ```. Extra commands output:; ```; > llvm-config-11 --version; 11.0.0; > cat /usr/lib/llvm-11/lib/cmake/llvm/LLVMConfig.cmake | grep PACKAGE_VERSION; set(LLVM_PACKAGE_VERSION 11.0.0); > cat /usr/lib/llvm-11/cmake/LLVMConfig.cmake | grep PACKAGE_VERSION; set(LLVM_PACKAGE_VERSION 11.0.0); > cat /lib/llvm-11/cmake/LLVMConfig.cmake | grep PACKAGE_VERSION; set(LLVM_PACKAGE_VERSION 11.0.0); ```. Finally the output from `sudo tools/build_clif.sh` installation of CLIF (still the same error I guess):; ```; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed; -- Looking for pthread_create in pthreads; -- Looking for pthread_create in pthreads - not found; -- Looking for pthread_create in pthread; -- Looking for pthread_create in pthread - found; -- Found Threads: TRUE ; CMake Error at clif/cmake/modules/CLIFUtils.cmake:37 (find_package):; Could not find a configuration file for package ""LLVM"" that is compatible; with requested version ""11.1.0"". The following configuration files were considered but not accepted:. /usr/lib/llvm-11/lib/cmake/llvm/LLVMConfig.cmake, version: 11.0.0; /usr/lib/llvm-11/cmake/LLVMConfig.cmake, version: 11.0.0; /lib/llvm-11/cmake/LLVMConfig.cmake, version: 11.0.0. Call Stack (most recent call first):; clif/CMakeLists.txt:22 (include). -- Configuring incomplete, errors occurred!; See also ""/root/clif/build/CMakeFiles/CMakeOutput.log"".; See also ""/root/clif/build/CMakeFiles/CMakeError.log"".; ```. Do you have any suggestions?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:13117,error,error,13117,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,5,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/534#issuecomment-1102014578:2577,avail,available,2577,,https://github.com/google/deepvariant/issues/534#issuecomment-1102014578,2,['avail'],['available']
Availability,"ef_reads --vsc_min_fraction_indels ""0.12"" --task {}. /opt/deepvariant/bin/call_variants --outfile ""./call_variants_output.tfrecord.gz"" --examples ""./make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/pacbio"". /opt/deepvariant/bin/postprocess_variants --ref ""stdchroms.hg38.fa"" --infile ""./call_variants_output.tfrecord.gz"" --outfile ""./SAMPLENAME.deepVariant.vcf.gz"" --cpus ""8"" --gvcf_outfile ""./SAMPLENAME.deepVariant.g.vcf.gz"" --nonvariant_site_tfrecord_path ""./gvcf.tfrecord@8.gz"" --sample_name ""SAMPLENAME""; ```. And here are the two last commands with std out ... ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""./call_variants_output.tfrecord.gz"" --examples ""./make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/pacbio"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(; I0510 12:13:42.483308 47501039724352 call_variants.py:563] Total 1 writing processes started.; I0510 12:13:42.487790 47501039724352 dv_utils.py:370] From ./make_examples.tfrecord-00000-of-00008.gz.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0510 12:13:42.487916 47501039724352 call_variants.py:588] Shape of input examples: [100, 199, 9]; I0510 12:13:42.488451 47501039724352 call_variants.py:592] Use saved model: True; I0510 12:13:52.162126 47501039724352 dv_utils.py:370] From /opt/models/pacbio/example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0510 12:13:52.1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/818#issuecomment-2104434632:1599,mainten,maintenance,1599,,https://github.com/google/deepvariant/issues/818#issuecomment-2104434632,1,['mainten'],['maintenance']
Availability,"efix=$HOMEPATH/inst --enable-shared --disable-static; make -j20; make install. # set environment; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin; export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH; export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15; echo ""$(python --version)"". # Pip 19.0.2; wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate; $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst; #pip install --upgrade --force-reinstall pip; echo ""$(pip --version)""; pip install setuptools nose asv cython future protobuf==3.6.1 six mock; pip install --upgrade setuptools; ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash; # download source code; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz; tar -zxvf protobuf-all-3.6.1.tar.gz; cd protobuf-3.6.1/. # clean static protobuf build; make uninstall; make distclean. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static; make clean; make -j20; # optional; make -j20 check # check if protobuf build is good; # install; make install; sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig; #cd .. # verify; echo ""$(which protoc)""; echo ""$(protoc --version)""; ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash; # shar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:6223,down,download,6223,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['down'],['download']
Availability,"el to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists.; time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled""; parallel: This job failed:; sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARGET.bam --examples /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/DeepVariant_Output/examples.tfrecord@8.gz --task 0; docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists.; ERRO[0000] error waiting for container: context canceled; ```. While I wasn't specifying a specific version, thank you for pointing that out; even though comparing versions may be interesting, I should try to keep the version similar for all comparisons. Also, adding `--entrypoint` bash allows me to run Docker in interactive mode (starting in /opt/models/pacbio). ***However, running that command (with or without sudo) shows an empty file directory in ""/mnt/cdw-genome"" (within the Docker container).***. Do you know what may be causing that issue?. Thank you very much for your assistance!. Sincerely,; Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483490946:5350,Error,Error,5350,,https://github.com/google/deepvariant/issues/171#issuecomment-483490946,3,"['Error', 'error']","['Error', 'error']"
Availability,"eply.github.com>; > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <; > author@noreply.github.com>; > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62); >; > CAUTION: This email originated from outside the organization. DO NOT click; > links or open attachments unless you recognize the sender and know the; > content is safe.; >; > I think you'll want:; > tfrecord_path:; > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064""; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub<; > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,; > or mute the thread<; > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>.; >; >; > This message contains confidential information and is intended only for; > the individual named. If you are not the named addressee you should not; > disseminate, distribute or copy this e-mail. Please notify the sender; > immediately by e-mail if you have received this e-mail by mistake and; > delete this e-mail from your system. E-mail transmission cannot be; > guaranteed to be secured or error-free as information could be intercepted,; > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses.; > The sender therefore does not accept liability for any errors or omissions; > in the contents of this message, which arise as a result of e-mail; > transmission. If verification is required please request a hard-copy; > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort; > Myers, FL 33913, http://www.neogenomics.com (2017); >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-380935943:2227,error,error-free,2227,,https://github.com/google/deepvariant/issues/62#issuecomment-380935943,2,['error'],"['error-free', 'errors']"
Availability,"epvariant-custom.simg Singularity.spec. %environment; PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin; DV_GPU_BUILD=0; export PATH DV_GPU_BUILD. %apprun download_testdata; BUCKET=""gs://deepvariant""; DATA_BUCKET=""${BUCKET}/quickstart-testdata/*""; mkdir -p input; gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples; exec /opt/deepvariant/bin/make_examples \; --mode calling \; --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \; --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \; --examples output.examples.tfrecord \; --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants; exec /opt/deepvariant/bin/call_variants \; --outfile call_variants_output.tfrecord \; --examples output.examples.tfrecord \; --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants; exec /opt/deepvariant/bin/postprocess_variants \; --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \; --infile call_variants_output.tfrecord \; --outfile output.vcf. %runscript; if [ $# -eq 0 ]; then; echo '''Example Usage:. # download data to input and models; singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs; singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models; singularity run --app call_variants deepvariant-custom.simg. # postprocess variants; singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md; '''; else; exec ""$@""; fi. %post; export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)""; echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list; curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -; apt-get -y update && apt-get install -y google-cloud-sdk parallel wget; rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-458208323:2048,echo,echo,2048,,https://github.com/google/deepvariant/issues/132#issuecomment-458208323,1,['echo'],['echo']
Availability,"er combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```; 20765 / 21141 (98.2%) full SNP recovery; 20872 / 21141 (98.7%) partial SNP recovery; 243 / 258 (94.2%) full insertion recovery; 249 / 258 (96.5%) partial insertion recovery; 208 / 228 (91.2%) full deletion recovery; 213 / 228 (93.4%) partial deletion recovery; ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:; If you go to “[explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select “**func_cds**” (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:4933,recover,recovery,4933,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"ermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --regions /input/idt_capture_novogene.grch38.bed --task 3"" Error without the more informative error message.; 4. Ran again the command without num shards flag:; BIN_VERSION=""1.2.0"". ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/output"":""/output"" \; -v ""${PWD}/reference"":""/reference"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref /reference/GRCh38_no_alt_analysis_set.fasta \; --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions /input/idt_capture_novogene.grch38.bed \; --output_vcf /output/HG003.output.vcf.gz \; --output_gvcf /output/HG003.output.g.vcf.gz \; --intermediate_results_dir /output/intermediate_results_dir; ```; 5. It ran and created only three intermediate files: call_variants_output.tfrecord, gvcf.tfrecord-00000-of-00001.gz, make_examples.tfrecord-00000-of-00001.gz without any Error message. I'm copying the last lines here:. ```; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; warnings.warn('`layer.apply` is deprecated and '; INFO:tensorflow:Done calling model_fn.; I0911 15:27:04.863512 139825053296448 estimator.py:1164] Done calling model_fn.; INFO:tensorflow:Graph was finalized.; I0911 15:27:05.510090 139825053296448 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt; I0911 15:27:05.510811 139825053296448 saver.py:1298] Restoring parameters from /opt/models/wes/model.ckpt; INFO:tensorflow:Running local_init_op.; I0911 15:27:06.189059 139825053296448 session_manager.py:531] Running local_init_op.; INFO:tensorflow:Done running local_init_op.; I0911 15:27:06.217319 139825053296448 session_manager.py:534] Done running local_in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/483#issuecomment-917442547:1397,Error,Error,1397,,https://github.com/google/deepvariant/issues/483#issuecomment-917442547,1,['Error'],['Error']
Availability,"erpret real, user and sys time? Maybe it will help us to understand how to improve the pipeline. ---. Here are my steps:. 1. Build locally (see [deepvariant-build-test.md](https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-build-test.md)). After build,; ```bash; ./build_release_binaries.sh; tar -cvzf bazel-deepvariant.tar.gz bazel-deepvariant/*; tar -cvzf bazel-genfiles.tar.gz bazel-genfiles/*; ```; 2. Go to another machine (i.e. Intel DevCloud) and clone repository. Unpack the binaries; ```bash; git clone -b master_openvino https://github.com/dkurt/deepvariant --depth 1; cd deepvariant; tar -xf bazel-deepvariant.tar.gz; tar -xf bazel-genfiles.tar.gz; ```; 3. Apply some patches to resolve local paths:; ```bash; sed -i -E 's|/opt/deepvariant/bin|./bazel-genfiles/deepvariant|' scripts/run_deepvariant.py; sed -i -E 's|/opt/models/wgs/model.ckpt|model.ckpt|' scripts/run_deepvariant.py; ln -s -f $HOME/deepvariant/scripts/ bazel-deepvariant/scripts; ```; 4. Download [GNU parallel](https://launchpad.net/ubuntu/bionic/amd64/parallel/20161222-1) (if you have no root permissions); ```bash; wget http://launchpadlibrarian.net/300780258/parallel_20161222-1_all.deb ; dpkg -x parallel_20161222-1_all.deb parallel; export PATH=$HOME/parallel/usr/bin:$PATH; ```. 5. Install TensorFlow MKL-DNN; ```bash; WHEEL_NAME=tensorflow-2.0.0-cp36-cp36m-linux_x86_64.whl; wget ""https://storage.googleapis.com/penporn-kokoro/tf-mkl-2.0-py36/${WHEEL_NAME}"" -O ""/tmp/${WHEEL_NAME}""; pip3 install --upgrade ""/tmp/${WHEEL_NAME}""; ```. 6. Run; ```bash; export INPUT_DIR=""${PWD}/quickstart-testdata""; export OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p $OUTPUT_DIR. export PYTHONPATH=./bazel-genfiles:$PYTHONPATH; python3 ./bazel-deepvariant/scripts/run_deepvariant.py \; --model_type=WGS \; --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \; --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=${OUTPUT_DIR}/output.vcf.gz \; --output_gvcf=",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-723242914:1886,Down,Download,1886,,https://github.com/google/deepvariant/pull/363#issuecomment-723242914,1,['Down'],['Download']
Availability,"ersion, I don't think you should see `1.6.0rc2` in your .sif filename. Which is why I asked what command you used to that get that .sif file. You might be pulling a previous, unofficial Docker file. If so, please remake your .sif file with `1.6.0`. ). Because @alanlamsiu used the .sif file, I'll also do something similar:; So, then I ran:. ```bash; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_deeptrio-1.6.0-gpu.sif \; /opt/deepvariant/bin/deeptrio/run_deeptrio; ```. The command above gave me:; ```. ==========; == CUDA ==; ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License.; By pulling and using the container, you accept the terms and conditions of this license:; https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2023-12-05 07:43:20.303963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-12-05 07:43:24.030774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-12-05 07:43:24.033082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed pr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389:2889,avail,available,2889,,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389,2,['avail'],['available']
Availability,"es interval001.tfrecord.gz \; --min_base_quality 5 \; --dbg_min_base_quality 0 \; --vsc_min_fraction_indels 0.06 \; --vsc_min_fraction_hmer_indels 0.12 \; --vsc_min_fraction_snps 0.12 \; --vsc_min_count_snps 2 \; --ws_min_windows_distance 20 \; --min_mapping_quality 5 \; --candidate_min_mapping_quality 5 \; --max_reads_per_partition 1500 \; --aux_fields_to_keep tp,t0 \; --skip_bq_channel \; --channels hmer_deletion_quality,hmer_insertion_quality,non_hmer_insertion_quality \; --add_ins_size_channel \; --max_ins_size 10 \; --optimal_coverages 50 \; --p_error 0.005 \; --gvcf out_temp_0001_of_200_gvcf.tfrecords.gz \; ```. ### Run CallVariants. CallVariants step runs on all examples from all samples together; Before running CallVariants, all the output example files should be copied to ; the same instance and renamed in the format `examples.tfrecord-%05d-of-%05d.gz`, for example: `examples.tfrecord-00041-of-00055.gz`.; **The order of the file names should correspond to the genomic order and the first index is 00000**. . Required hardware: . * 4 CPU; * 1 GPU (nvidia-tesla-p100 or nvidia-tesla-v100 or nvidia-amper-a10); * 2.5GB RAM; * hard disk: 2 * total size of example + 2 * total size of model files. command:; ```; /opt/deepvariant/bin/call_variants \; --outfile call_variants_output.tfrecord.gz \; --examples examples.tfrecord@<fill total number of shards>.gz \; -checkpoint <model name, without the .index extension: deepvariant-ultima-germline-wgs-model-v1.2.ckpt-710000>; ```. ### Run PostProcessing:; Required hardware:. * 1 CPU; * RAM: 4GB+64*size of the output of CallVariant; * Disk: 4GB + 48*size of the output of CallVariants + size of the reference genome. command:; ```; /opt/deepvariant/bin/postprocess_variants \; --ref Homo_sapiens_assembly38.fasta \; --infile call_variants_output.tfrecord.gz \; --outfile output.vcf.gz \; --vcf_stats_report=False; ```. ## Final notes; * Running deepVariant in the docker requires ability to use GPU from the docker. See instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/711#issuecomment-1734891580:4896,checkpoint,checkpoint,4896,,https://github.com/google/deepvariant/issues/711#issuecomment-1734891580,1,['checkpoint'],['checkpoint']
Availability,"es two Python programs/tools (pyclif and pyclif_proto) which are; Python. PIP (with setup.py) creates tiny launchers for them for user; convenience, but encode build Python path and eg. --py3 option into those; launchers.; When user environment for CLIF use is different from the build environment; those launchers are not correct anymore and needs to be removed/regenerated; or otherwise ""fixed"" to reflect different conditions. On Thu, May 3, 2018 at 3:17 AM Brad Chapman <notifications@github.com>; wrote:. > Pi-Chuan and Mike;; > Thanks for all this background and help. I'm trying to fit this into the; > conda recipe bazel build for DeepVariant but am not sure how to take; > advantage of using the local anaconda python in that context. The error I'm; > seeing is that bazel can't find pyclif_proto:; >; > (17:56:01) INFO: Found 1 target...; > (17:56:01) [0 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt; > (17:56:01) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'; > (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1: //third_party/nucleus/protos:variants_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'; > Target //deepvariant:binaries failed to build; > (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1 1 input file(s) do not exist; >; > which I thought was triggered by the difficulty running pyclif without; > having the local python installed. It could also be due to not installing; > is in /usr/local/bin since I have to remain sandboxed in the work; > directory, but I did adjust the PATH to include the download location.; >; > Sorry I'm stuck here due to me limited knowledge of bazel tweaking. Either; > understanding how to handle a root install of the pre-build pyclif or; > tweaking to use the local python would be helpful. Alternatively, if you; > can already build DeepVariant ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386327937:1021,ERROR,ERROR,1021,,https://github.com/google/deepvariant/issues/29#issuecomment-386327937,2,['ERROR'],['ERROR']
Availability,"est_env=LD_LIBRARY_PATH \; --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \; --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \; --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \; --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &; bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only; bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary; bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; echo 'Expect a usage message:'; (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; ```. ## Fix DV Error. ```bash; ################################################################################; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test; # use lscpu to show the actual CPU number; ################################################################################; python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160; python -c ""import psutil;print(p/sutil.cpu_count; ())"" #160. vim deepvariant/resources.py; --------------------------------; def _get_cpu_count():; """"""Gets the number of physical cores in this machine.; Returns:; int >= 1 if the call to get the cpu_count succeeded, or 0 if not.; """"""; # return psutil.cpu_count(logical=False) or 0 ==> comment; return 20; --------------------------------. vim deepvariant/resources_test.py; --------------------------------; def test_metrics_is_ok_when_cpu_count_returns_none(self):; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environme",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:19831,Error,Error,19831,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,1,['Error'],['Error']
Availability,"esulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```; 20765 / 21141 (98.2%) full SNP recovery; 20872 / 21141 (98.7%) partial SNP recovery; 243 / 258 (94.2%) full insertion recovery; 249 / 258 (96.5%) partial insertion recovery; 208 / 228 (91.2%) full deletion recovery; 213 / 228 (93.4%) partial deletion recovery; ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:; If you go to “[explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select “**func_cds**” (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the “truth” set was defined. T",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:4982,recover,recovery,4982,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"eturn self._sess_creator.create_session(); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 902, in create_session; self.tf_sess = self._session_creator.create_session(); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 669, in create_session; init_fn=self._scaffold.init_fn); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/session_manager.py"", line 295, in prepare_session; config=config); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/session_manager.py"", line 209, in _restore_checkpoint; saver.restore(sess, checkpoint_filename_with_path); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py"", line 1315, in restore; err, ""a Variable name or other graph key that is missing""); tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. /opt/models/pacbio/model.ckpt.data-00000-of-00001; No such file or directory; 	 [[node save_1/RestoreV2 (defined at usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:629) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_8s8eyzhg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_8s8eyzhg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_8s8eyzhg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_8s8eyzhg/runfiles/com_google_deepvar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/757#issuecomment-1864800013:16057,checkpoint,checkpoint,16057,,https://github.com/google/deepvariant/issues/757#issuecomment-1864800013,1,['checkpoint'],['checkpoint']
Availability,"examples_runner(options); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner; candidates, examples, gvcfs, runtimes = region_processor.process(region); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process; reads = self.region_reads(region); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads; error_message + '\nFailed to parse BAM/CRAM file. '; ValueError: Data loss: Failed to parse SAM record; Failed to parse BAM/CRAM file. This is often caused by:; (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file.; (2) Your BAM/CRAM file could be corrupted. Please check its md5.; If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues; ```. It seems like for this particular failure mode (BAM file is truncated), the default stackt race was already clear.; But given that I mentioned different level of verbosity. I tried that next. ## Use `-v` to increase verbosity level. if you run `/opt/deepvariant/bin/make_examples --helpfull` you'll see this flag:. ```; -v,--verbosity: Logging verbosity level. Messages logged at this level or; lower will be included. Set to 1 for debug logging. If the flag was not set; or supplied, the value will be changed from the default of -1 (warning) to 0; (info) after flags are parsed.; (default: '-1'); (an integer); ```; You can try to add `-v 1`. But in this case above, my run already had useful logging and didn't seem to produce more useful logs. ## What if we run with Singularity?. I think you were running with Singularity, so I tried that too. I repeated the steps in https://github.com/google/deepvariant/issue",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:13580,error,error,13580,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,2,['error'],['error']
Availability,"examples_runner(options); File ""/tmp/Bazel.runfiles_jqt5759c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner; candidates, examples, gvcfs, runtimes = region_processor.process(region); File ""/tmp/Bazel.runfiles_jqt5759c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process; reads = self.region_reads(region); File ""/tmp/Bazel.runfiles_jqt5759c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads; error_message + '\nFailed to parse BAM/CRAM file. '; ValueError: Data loss: Failed to parse SAM record; Failed to parse BAM/CRAM file. This is often caused by:; (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file.; (2) Your BAM/CRAM file could be corrupted. Please check its md5.; If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.truncated.bam --examples /tmp/tmpj5fx0phm/make_examples.tfrecord@1.gz --gvcf /tmp/tmpj5fx0phm/gvcf.tfrecord@1.gz --task 0. real 1m25.608s; user 1m28.020s; sys 0m5.611s; I0629 23:10:12.080424 139667868600064 run_deepvariant.py:416] None; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>; app.run(main); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run; _run_main(main, args); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.6/subprocess.py"", line 311, in chec",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:6893,error,error,6893,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,2,['error'],['error']
Availability,"export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static; make clean; make -j20; make -j20 check # check if protobuf build is good; # install; make install; sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig; #cd .. # verify; echo ""$(which protoc)""; echo ""$(protoc --version)""; ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash; # download source code; wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip; mkdir bazel-0.15.0; unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0; cd bazel-0.15.0. # environment; export CPU=power8; export HOMEPATH=/home/qilibj; export JAVA_HOME=/usr/lib/jvm/java-1.8.0; export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch; PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh; rsync -avP output/bazel $HOMEPATH/inst/bin/; # verification; bazel info; ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash; # gpg public key; wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b; rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories; [root@cit1074 deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:2786,down,download,2786,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['down'],['download']
Availability,f-00030.gz; -rw-r--r-- 1 root root 52K Sep 24 15:47 make_examples.tfrecord-00000-of-00030.gz; -rw-r--r-- 1 root root 5.9K Sep 24 15:47 gvcf.tfrecord-00003-of-00030.gz; -rw-r--r-- 1 root root 5.7K Sep 24 15:47 gvcf.tfrecord-00004-of-00030.gz; -rw-r--r-- 1 root root 3.6K Sep 24 15:47 gvcf.tfrecord-00022-of-00030.gz; -rw-r--r-- 1 root root 4.5K Sep 24 15:47 gvcf.tfrecord-00025-of-00030.gz; -rw-r--r-- 1 root root 22K Sep 24 15:47 make_examples.tfrecord-00004-of-00030.gz; -rw-r--r-- 1 root root 31K Sep 24 15:47 make_examples.tfrecord-00003-of-00030.gz; -rw-r--r-- 1 root root 16K Sep 24 15:47 make_examples.tfrecord-00022-of-00030.gz; -rw-r--r-- 1 root root 6.2K Sep 24 15:47 gvcf.tfrecord-00008-of-00030.gz; -rw-r--r-- 1 root root 56K Sep 24 15:47 make_examples.tfrecord-00008-of-00030.gz; -rw-r--r-- 1 root root 7.5K Sep 24 15:47 make_examples.tfrecord-00025-of-00030.gz; -rw-r--r-- 1 root root 4.6K Sep 24 15:47 gvcf.tfrecord-00026-of-00030.gz; -rw-r--r-- 1 root root 38K Sep 24 15:47 make_examples.tfrecord-00026-of-00030.gz; -rw-r--r-- 1 root root 5.2K Sep 24 15:47 gvcf.tfrecord-00002-of-00030.gz; -rw-r--r-- 1 root root 32K Sep 24 15:47 make_examples.tfrecord-00002-of-00030.gz; -rw-r--r-- 1 root root 7.0K Sep 24 15:47 gvcf.tfrecord-00007-of-00030.gz; -rw-r--r-- 1 root root 3.0K Sep 24 15:47 gvcf.tfrecord-00024-of-00030.gz; -rw-r--r-- 1 root root 44K Sep 24 15:47 make_examples.tfrecord-00007-of-00030.gz; -rw-r--r-- 1 root root 11K Sep 24 15:47 make_examples.tfrecord-00024-of-00030.gz; -rw-r--r-- 1 root root 5.3K Sep 24 15:47 gvcf.tfrecord-00013-of-00030.gz; -rw-r--r-- 1 root root 27K Sep 24 15:47 make_examples.tfrecord-00013-of-00030.gz; -rw-r--r-- 1 root root 4.9K Sep 24 15:47 gvcf.tfrecord-00005-of-00030.gz; -rw-r--r-- 1 root root 20K Sep 24 15:47 make_examples.tfrecord-00005-of-00030.gz. ```; This is how my `free -h` is looking like right now:. ```; total used free shared buff/cache available; Mem: 125G 123G 776M 224M 933M 354M; Swap: 101G 100G 1.7G. ```. Thank you. Cheers.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/358#issuecomment-703346071:9849,avail,available,9849,,https://github.com/google/deepvariant/issues/358#issuecomment-703346071,1,['avail'],['available']
Availability,"f.tf_sess = self._session_creator.create_session(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session; return self._get_session_manager().prepare_session(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session; sess, is_loaded_from_checkpoint = self._restore_checkpoint(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint; _restore_checkpoint_and_maybe_run_saved_model_initializers(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers; saver.restore(sess, path); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore; raise _wrap_restore_error_with_msg(; tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt; [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874:17460,checkpoint,checkpoint,17460,,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874,2,['checkpoint'],['checkpoint']
Availability,"fi; +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so; +cd -; +; +export PATH=/root/.local/bin/:$PATH; +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev; +pip install pygobject; +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev; +pip install --upgrade pygobject; +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py ; +; # Configure LLVM 11 apt repository; wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \; add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main""; @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \; libllvm11 \; llvm-11 \; llvm-11-dev \; - llvm-11-linker-tools \; python3-dev \; zlib1g-dev; ; @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then; git checkout ""${CLIF_PIN}""; fi; ; +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake ; ./INSTALL.sh; ```; After these changes, I am stuck again at building clif because of the following error:; ```; [100%] Linking CXX executable clif-matcher; /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':; matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'; /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':; matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined refere",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217:5123,error,error,5123,,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217,1,['error'],['error']
Availability,"flow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; werkzeug 2.3.4 requires MarkupSafe>=2.1.1, but you have markupsafe 2.0.1 which is incompatible.; ========== [Mon 05 Jun 2023 01:42:50 AM UTC] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; ========== [Mon 05 Jun 2023 01:42:51 AM UTC] Stage 'run-prereq.sh complete' starting; ```. For the other set of commands:; ```; > lsb_release -sc; focal; > wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - ; --2023-06-05 01:38:40-- https://apt.llvm.org/llvm-snapshot.gpg.key; Resolving apt.llvm.org (apt.llvm.org)... 146.75.46.49; Connecting to apt.llvm.org (apt.llvm.org)|146.75.46.49|:443... connected.; HTTP request sent, awaiting response..",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:8916,ERROR,ERROR,8916,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,1,['ERROR'],['ERROR']
Availability,"g back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```; 20765 / 21141 (98.2%) full SNP recovery; 20872 / 21141 (98.7%) partial SNP recovery; 243 / 258 (94.2%) full insertion recovery; 249 / 258 (96.5%) partial insertion recovery; 208 / 228 (91.2%) full deletion recovery; 213 / 228 (93.4%) partial deletion recovery; ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:; If you go to “[explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select “**func_cds**” (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:4846,recover,recovery,4846,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"g; ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting; W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Falló la conexión [IP: 18.194.81.109 80]; W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Falló la conexión [IP: 18.194.81.109 80]; W: No se han podido descargar algunos archivos de índice, se han omitido, o se han utilizado unos antiguos en su lugar.; ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting; Calling wait_for_dpkg_lock.; ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting; WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on.; Bazel 3.7.2 already installed on the machine, not reinstalling; ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting; CLIF already installed.; ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting; M	tensorflow/core/kernels/mlir_generated/build_defs.bzl; HEAD está ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes; You have bazel 3.7.2 installed.; Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.; 	--config=mkl 	# Build with MKL support.; 	--config=mkl_aarch64",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279:6768,Down,Download,6768,,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279,1,['Down'],['Download']
Availability,"g_variants; for overlapping_candidates in _group_overlapping_variants(sorted_variants):; File ""/TMP_DIR/Bazel.runfiles_eyn11z72/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 106, in _group_overlapping_variants; for variant in sorted_variants:; File ""/TMP_DIR/Bazel.runfiles_eyn11z72/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 853, in _transform_call_variants_output_to_variants; canonical_variant, predictions = merge_predictions(; File ""/TMP_DIR/Bazel.runfiles_eyn11z72/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 717, in merge_predictions; raise ValueError('`call_variants_outputs` did not pass sanity check.'); ValueError: `call_variants_outputs` did not pass sanity check. real	15m9.448s; user	14m3.211s; sys	0m20.620s; I1010 03:07:07.182588 47710997727040 postprocess_variants.py:1233] Finished writing VCF and gVCF in 36.08515272140503 minutes.; I1010 03:07:07.600154 47710997727040 genomics_reader.py:222] Reading /DeepTrio/C1/F1.output.vcf.gz with NativeVcfReader; I1010 03:09:40.323815 48001616553792 postprocess_variants.py:1233] Finished writing VCF and gVCF in 38.57903414567311 minutes.; I1010 03:09:40.659351 48001616553792 genomics_reader.py:222] Reading /DeepTrio/C1/C1.output.vcf.gz with NativeVcfReader. real	45m21.485s; user	43m7.954s; sys	1m1.029s. real	47m46.669s; user	45m31.656s; sys	1m0.352s; Traceback (most recent call last):; File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 659, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 655, in main; raise Exception('One or more postprocess_variants failed.'); Exception: One or more postprocess_variants failed. **I am very confusing :Are the result files reliable?Or should I rerun DeepTrio?**",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/488#issuecomment-939618673:6575,reliab,reliable,6575,,https://github.com/google/deepvariant/issues/488#issuecomment-939618673,1,['reliab'],['reliable']
Availability,"ge.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # echo ""Installing GPU-enabled TensorFlow ${DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION} wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade ""tensorflow-gpu==${DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION}""; # elif [[ ""${DV_USE_GCP_OPTIMIZED_TF_WHL}"" = ""1"" ]]; then; # echo ""Installing Intel's CPU-only MKL TensorFlow ${DV_GCP_OPTIMIZED_TF_WHL_VERSION} wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade ""intel-tensorflow==${DV_GCP_OPTIMIZED_TF_WHL_VERSION}""; # else; echo ""Installing standard CPU-only TensorFlow ${DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION} wheel""; pip3 install ""${PIP_ARGS[@]}"" --upgrade ""tensorflow==${DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION}""; # fi; # fi; # fi. # # A temporary fix.; # # Context: intel-tensorflow 2.7.0 will end up updating markupsafe to 2.1.1,; # # which caused the issue here: https://github.com/pallets/markupsafe/issues/286.; # # Specifically:; # # ImportError: cannot import name 'soft_unicode' from 'markupsafe'.; # # So, forcing a downgrade. This isn't the best solution, but we need it to get; # # our tests pass.; pip3 install ""${PIP_ARGS[@]}"" --upgrade 'markupsafe==2.0.1'. # ################################################################################; # # CUDA; # ################################################################################. # note_build_stage ""Install CUDA"". # # See https://www.tensorflow.org/install/source#gpu for versions required.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # if [[ ""${DV_INSTALL_GPU_DRIVERS}"" = ""1"" ]]; then; # # This script is only maintained for Ubuntu 20.04.; # UBUNTU_VERSION=""2004""; # # https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_local; # echo ""Checking for CUDA...""; # if ! dpkg-query -W cuda-11-3; then; # echo ""Installing CUDA...""; # UBUNTU_VERSION=""2004""; # curl -O https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin; # sudo mv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:2166,down,downgrade,2166,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,2,['down'],['downgrade']
Availability,"gleapis.com/deepvariant/packages/tensorflow; ++ export DV_TF_NUMPY_VERSION=1.19.2; ++ DV_TF_NUMPY_VERSION=1.19.2; ++ export DV_INSTALL_GPU_DRIVERS=0; ++ DV_INSTALL_GPU_DRIVERS=0; ++ export PYTHON_VERSION=3.8; ++ PYTHON_VERSION=3.8; +++ which python3.8; ++ export PYTHON_BIN_PATH=/opt/conda/envs/py38/bin/python3.8; ++ PYTHON_BIN_PATH=/opt/conda/envs/py38/bin/python3.8; ++ export PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages; ++ PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages; ++ export USE_DEFAULT_PYTHON_LIB_PATH=1; ++ USE_DEFAULT_PYTHON_LIB_PATH=1; ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11'; ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11'; + bazel; [bazel release 5.3.0]; Usage: bazel <command> <options> ... Available commands:; analyze-profile Analyzes build profile data.; aquery Analyzes the given targets and queries the action graph.; build Builds the specified targets.; canonicalize-flags Canonicalizes a list of bazel options.; clean Removes output files and optionally stops the server.; coverage Generates code coverage report for specified test targets.; cquery Loads, analyzes, and queries the specified targets w/ configurations.; dump Dumps the internal state of the bazel server process.; fetch Fetches external repositories that are prerequisites to the targets.; help Prints help for commands, or the index.; info Displays runtime info about the bazel server.; license Prints the license of this software.; mobile-install Installs targets to mobile devices.; print_action Prints the command line args for compiling a file.; query Executes a dependency graph query.; run Runs the specified target.; shutdown Stops the bazel server.; sync Syncs all repositories specified in the workspace file; test Builds and runs the speci",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:3460,Avail,Available,3460,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,1,['Avail'],['Available']
Availability,"h both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```; 20765 / 21141 (98.2%) full SNP recovery; 20872 / 21141 (98.7%) partial SNP recovery; 243 / 258 (94.2%) full insertion recovery; 249 / 258 (96.5%) partial insertion recovery; 208 / 228 (91.2%) full deletion recovery; 213 / 228 (93.4%) partial deletion recovery; ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:; If you go to “[explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select “**func_cds**” (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https:/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:4888,recover,recovery,4888,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"h:; ```; gcloud beta compute instances create ""${USER}-centos-singularity"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image=centos-7-drawfork-v20181102 \; --image-project=eip-images \; --machine-type ""n1-standard-32"" \; --zone ""us-west1-b""; ```. 2. On the machine, I installed Singularity 2.5.2 with instructions on: https://github.com/sylabs/singularity/blob/2.5.2/INSTALL.md. 3. I copied a Singularity image that I built with [the instructions I posted before](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) on a Ubutun 16.04 machine to this CentOS 7 machine. Then I got the [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) data and run the command:; ```; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \; --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz ; ```. The run completed without an issue. My CentOS machine has:; ```; $ lsb_release ; LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; ```; ```; $ cat /etc/centos-release; CentOS Linux release 7.6.1810 (Core) ; ```. ---. From the original error message:; `ImportError: No module named _multiarray_umath`; It seems like an issue with numpy installation. But given we're using a singularity image, I am having a hard time thinking why this would be the case. (Unless it's not created correctly?). @drtamermansour ; Two questions for you:; (a) When you create the image, can you try to run it on the machine where you create it to make sure it worked there? ; (b) Do you think it'll help if either I or @williamrowell share our *simg file with you to try it out?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/178#issuecomment-487218238:1637,error,error,1637,,https://github.com/google/deepvariant/issues/178#issuecomment-487218238,1,['error'],['error']
Availability,"hat I can see the detailed information for the files..; Here is the script:; ```bash; #!/bin/bash. nthreads=32; dvsif=""/lustre/Data/toolsDB/deepvariant.sif""; ref_idx=""/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa"". wkdir=""/lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP""; bamdir=""${wkdir}/mappinged_bams""; logdir=""${wkdir}/logs""; vcfoutdir=""${wkdir}/DeepVariant_outputs"". source activate ~/.conda/envs/zjlEnv. echo -e ""ref_idx is $ref_idx\n""; if [ -f ""$ref_idx"" ];; then; echo -e ""ref_idx $ref_idx exists!\n""; which ls; echo -e ""ls -al --block=M ${ref_idx}*\n""; ls -al --block=M ${ref_idx}*; echo -e ""ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*\n""; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*; else; echo -e ""Warning!! ref_idx [$ref_idx] not exist!\n""; fi. echo -e ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif ls -al ${ref_idx}*""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif ls -al ${ref_idx}*; echo -e ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif which ls; ls -al ${ref_idx}*""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif which ls; ls -al ${ref_idx}*. ```. Here is the running output:; ```shell; /usr/bin/ls; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. -rw-rw-r-- 1 zhoujianglin zhoujianglin 3042M Apr 26 14:53 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; -rw-rw-r-- 1 zhoujianglin zhoujianglin 5985M Apr 26 15:23 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann; -rw-rw-r-- 1 zhoujianglin zhoujianglin 9725M Apr 26 15:42 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1575922269:1118,echo,echo,1118,,https://github.com/google/deepvariant/issues/653#issuecomment-1575922269,2,['echo'],['echo']
Availability,"hat are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > ; > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?. If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8.; ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:; ```; $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json; {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} ; ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the curren",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/568#issuecomment-1251857213:1519,error,errors,1519,,https://github.com/google/deepvariant/issues/568#issuecomment-1251857213,1,['error'],['errors']
Availability,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/554#issuecomment-1223132769:112,avail,available,112,,https://github.com/google/deepvariant/issues/554#issuecomment-1223132769,1,['avail'],['available']
Availability,"hether some harmonization or filtering after calls could make the resulting calls more uniform. With respect to your examples. It is often difficult to be definitive about why DeepVariant does not make certain calls. I cannot give you a reason, but for some cases I can share observations. In all cases, I will list the call followed by observation. ```; chr5 | 92696737 | chr5_92696737_C_T | C | T | 3 | . | AF=0.166667;AQ=3 | GT:DP:AD:GQ:PL:RNC | 0/1:32:17,15:5:3,0,32:.. | 0/0:27:27,0:50:0,108,1079:.. | 0/0:21:21,0:50:0,105,1049:..; ```. This looks clean. DeepTrio's GQ is low probably because it is a clear de novo and it has learned such events are rare. ```; chr5 | 24093912 | chr5_24093912_AAT_A;chr5_24093912_A_AATAT | AAT | A,AATATAT | 46 | . | AF=0.333333,0.166667;AQ=46,15 | GT:DP:AD:GQ:PL:RNC | 1/2:30:5,12,13:13:44,15,55,15,0,53:.. | 0/1:31:16,15,0:46:46,0,70,990,990,990:.. | ./.:30:27,1,0:18:0,18,45,990,990,990:II; ```; One thing I note - it looks to me like there are 3 alleles represented in the reads for the top parent: 1) there is an insertion event in-phase with a downstream HET SNP. 2) There is a reference allele in-phase with REF at that later position. 3) There is evidence for a T SNP that is also in-phase with the downstream HET variant. For the reads that are HET T, it could be interesting to see if they overlap any other variants that would suggest that they come from a copy number variant elsewhere in the genome. It may be the case that DeepTrio does not call a variant in the parent because some of the variant reads may be coming from elsewhere. ```; chr7 | 54624683 | chr7_54624683_A_AATC | A | AATC | 27 | . | AF=0.166667;AQ=27 | GT:DP:AD:GQ:PL:RNC | 0/1:39:22,16:28:27,0,48:.. | 0/0:40:40,0:50:0,120,1199:.. | 0/0:28:28,0:50:0,90,899:..; ```. This is interesting, since the evidence reported by DeepTrio doesn't match the view in the BAM. DeepTrio is saying that both parents don't have evidence for variant reads at this position. It is possible the after r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/440#issuecomment-823860823:1240,down,downstream,1240,,https://github.com/google/deepvariant/issues/440#issuecomment-823860823,2,['down'],['downstream']
Availability,"hi @kishwarshafin ,. Thank you for your quick reply. I was under the impression that DeepTrio ONT was supported due to the final comment in https://github.com/google/deepvariant/issues/715. Good to know that it is not officially supported yet. > One of the reasons for the segfault could be because of low memory? Can you let us know the command you ran and the memory you have?. The command is listed above. I've tried running with 6 threads/24GB RAM and 6 threads/128GB RAM. Both result in the same segmentation fault. > Also, if easier then if you can share the bams then I can try to run it on our end and see what's happening.; The .bams can be downloaded [here](https://downloads.molgeniscloud.org/downloads/vip/_dev/github/deepvariant_724/). Thank you for looking into the issue,; Greetings,; @dennishendriksen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/724#issuecomment-1790163392:514,fault,fault,514,,https://github.com/google/deepvariant/issues/724#issuecomment-1790163392,4,"['down', 'fault']","['downloaded', 'downloads', 'fault']"
Availability,"hi i have check the error. The error reason is I can't connect the GCP, the make_samples.py need to run ; 'htslib_gcp_oauth.init()', I remove this and install htslib in local. So build_and_test pass all. ; ![image](https://user-images.githubusercontent.com/15261087/33802638-2bf6bb2c-ddb6-11e7-963e-950660e357ff.png). ![image](https://user-images.githubusercontent.com/15261087/33802647-66a7728e-ddb6-11e7-9279-80c1c79a37e0.png). thanks everyone~",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/7#issuecomment-350528251:20,error,error,20,,https://github.com/google/deepvariant/issues/7#issuecomment-350528251,2,['error'],['error']
Availability,"hi, @akolesnikov ; In the detailed information of releases v1.6, I noticed that DV1.6 has added new models trained with Complete Genomics data, and added case studies.; I followed your doc:` https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md`; The model file was downloaded from here:; ![image](https://github.com/google/deepvariant/assets/70870741/3dee9f96-bdb6-4ece-891f-802eb4297878)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/725#issuecomment-1798035805:303,down,downloaded,303,,https://github.com/google/deepvariant/issues/725#issuecomment-1798035805,1,['down'],['downloaded']
Availability,"hi, thanks for the replies. so `--make_examples_extra_args ""ws_use_window_selector_model=false""` (since I am using `run_deepvariant`) will accomplish the same as what @akolesnikov suggests with `--nows_use_window_selector_model` ?. and I don't see much documentation on that option, is there any downside to that? (I assume it just affects run time?)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/272#issuecomment-586545236:296,down,downside,296,,https://github.com/google/deepvariant/issues/272#issuecomment-586545236,1,['down'],['downside']
Availability,"hird_party/nucleus/io/clif_postproc.py"", line 82, in __next__; record, not_done = self._raw_next(); File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next; not_done = self._cc_iterable.PythonNext(record); ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main; make_examples_runner(options); File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner; candidates, examples, gvcfs, runtimes = region_processor.process(region); File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process; reads = self.region_reads(region); File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads; error_message + '\nFailed to parse BAM/CRAM file. '; ValueError: Data loss: Failed to parse SAM record; Failed to parse BAM/CRAM file. This is often caused by:; (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file.; (2) Your BAM/CRAM file could be corrupted. Please check its md5.; If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:19984,error,error,19984,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,4,['error'],['error']
Availability,"homas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,; From a quick look of your error, it doesn't look like anything I've ever; encountered before. If you could potentially set up a reproducible setting; that I can very quickly run, I can see if I can try it out and tell you; what might could have gone wrong. We don't currently have a tutorial for; training, unfortunately. And to be honest, even if we do, it probably; wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is; > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for; > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:; > [64,27,1,3]; >; >; > I hate to keep bothering people about this. Is there documentation on all; > of this that I can refer to?; >; >; > Thanks,; > Brad Thomas; >; >; > From: Pi-Chuan Chang [mailto:notifications@github.com]; > Sent: Tuesday, April 10, 2018 1:04 PM; > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>; > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <; > author@noreply.github.com<mailto:author@noreply.github.com>>; > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62); >; > CAUTION: This email originated from outside the organization. DO NOT click; > links or open attachments unless you recognize the sender and know the; > content is safe.; >; > I think you'll want:; > tfrecord_path:; > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064""; >; > —; > You are receiving this because you authored th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381164890:1250,error,error,1250,,https://github.com/google/deepvariant/issues/62#issuecomment-381164890,1,['error'],['error']
Availability,"hon2 and pip environment; export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH; export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages; export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python; export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages; ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash; # download source code; wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz; tar -zxvf cmake-3.13.3.tar.gz; cd cmake-3.13.3. # build scirpt; ./bootstrap; make -j20; make -j20 install; export PATH=/usr/local/bin:$PATH; ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash; # download source code; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz; tar -zxvf protobuf-all-3.6.1.tar.gz; cd protobuf-3.6.1/. # clean static protobuf build; make uninstall; make distclean. # environment; export CPU=power8; export HOMEPATH=/home/qilibj; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static; make clean; make -j20; make -j20 check # check if protobuf build is good; # install; make install; sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig; #cd .. # verify; echo ""$(which protoc)""; echo ""$(protoc --version)""; ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:1494,down,download,1494,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['down'],['download']
Availability,i have excute build_and_test.sh but the other error come.; `; (py38) root@30634345fd4a:/deepvariant# ./build_and_test.sh; + source settings.sh; ++ export DV_USE_PREINSTALLED_TF=0; ++ DV_USE_PREINSTALLED_TF=0; ++ export TF_NEED_GCP=1; ++ TF_NEED_GCP=1; ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu; ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu; ++ DV_BAZEL_VERSION=5.3.0; ++ export PATH=/root/bin:/root/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/opt/conda/envs/py38/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/conda/bin:/opt/conda/envs/bio/bin:/opt/deepvariant/bin:/root/bin; ++ PATH=/root/bin:/root/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/opt/conda/envs/py38/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/conda/bin:/opt/conda/envs/bio/bin:/opt/deepvariant/bin:/root/bin; ++ export DEEPVARIANT_BUCKET=gs://deepvariant; ++ DEEPVARIANT_BUCKET=gs://deepvariant; ++ export DV_PACKAGE_BUCKET_PATH=gs://deepvariant/packages; ++ DV_PACKAGE_BUCKET_PATH=gs://deepvariant/packages; ++ export DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages; ++ DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages; ++ export DV_TF_NIGHTLY_BUILD=0; ++ DV_TF_NIGHTLY_BUILD=0; ++ [[ 0 = \1 ]]; ++ export DV_CPP_TENSORFLOW_TAG=v2.11.0; ++ DV_CPP_TENSORFLOW_TAG=v2.11.0; ++ export DV_GCP_OPTIMIZED_TF_WHL_VERSION=2.11.0; ++ DV_GCP_OPTIMIZED_TF_WHL_VERSION=2.11.0; ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=2.11.0; ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=2.11.0; ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=2.11.0; ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=2.11.0; ++ export DV_GPU_BUILD=1; ++ DV_GPU_BUILD=1; ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1; ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1; ++ ex,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:46,error,error,46,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,1,['error'],['error']
Availability,i still get the same previous errors.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/89#issuecomment-416480421:30,error,errors,30,,https://github.com/google/deepvariant/issues/89#issuecomment-416480421,1,['error'],['errors']
Availability,"i.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids. curl ${FTPDIR}/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | gunzip > reference/GRCh38_no_alt_analysis_set.fasta; curl ${FTPDIR}/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.fai > reference/GRCh38_no_alt_analysis_set.fasta.fai; ```. ```bash; mkdir -p input; HTTPDIR=https://downloads.pacbcloud.com/public/dataset/HG003/deepvariant-case-study. curl ${HTTPDIR}/HG003.GRCh38.chr20.pFDA_truthv2.bam > input/HG003.GRCh38.chr20.pFDA_truthv2.bam; curl ${HTTPDIR}/HG003.GRCh38.chr20.pFDA_truthv2.bam.bai > input/HG003.GRCh38.chr20.pFDA_truthv2.bam.bai; ```. ```bash; ulimit -u 10000; BIN_VERSION=""1.6.1""; mkdir -p deepvariant_output; ```. @Carl-labhub mentioned ""When I run it, I’m doing so from an interactive session with singularity exec"". I'm a bit confused by this. Maybe you mean `singularity shell`? So I tried:. ```bash; singularity shell --bind /usr/lib/locale/ DeepVariant_1.6.1.sif; ```; This gets into a shell mode, then I ran:. ```; Singularity> /opt/deepvariant/bin/run_deepvariant \; > --model_type PACBIO \; > --ref reference/GRCh38_no_alt_analysis_set.fasta \; > --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \; > --output_vcf deepvariant_output/output.vcf.gz \; > --num_shards $(nproc) \; > --regions chr20; ```. Directly `singularity exec` with the command (just like https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-pacbio-model-case-study.md) should be fine too. My `make_examples` step completed without any issues. It took:. ```; real 9m7.540s; user 215m38.303s; sys 6m41.297s; ```. I let the whole run finish just to be sure. --> The full run also completed without any errors. @Carl-labhub, can you check what I did above, and see what might be different on your side? And, there were previous GitHub issues that might be worth reading through to see if there are any relevant clues. For example: https://github.com/google/deepvariant/issues/677.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/812#issuecomment-2076206716:4906,error,errors,4906,,https://github.com/google/deepvariant/issues/812#issuecomment-2076206716,2,['error'],['errors']
Availability,"i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2; W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2; W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2; W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]; W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]; W: Some index files failed to download. They have been ignored, or old ones used instead.; W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2; W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2; W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2; W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2; W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/89#issuecomment-416438760:3237,down,download,3237,,https://github.com/google/deepvariant/issues/89#issuecomment-416438760,2,['down'],['download']
Availability,"iables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option.; ```; Because in our code, we use a regular expression like this:; https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start.; This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:; ```; vars_to_warm_start=['|'.join(vars_to_include)]); ```; which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model.; So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/185#issuecomment-494919509:2318,checkpoint,checkpoint,2318,,https://github.com/google/deepvariant/issues/185#issuecomment-494919509,4,"['checkpoint', 'robust']","['checkpoint', 'robustness']"
Availability,"iant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware?. 1b); With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests?. The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\); Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as below. ```; docker run -it --entrypoint bash -v /home/user/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant:0.8.0; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483448362:2718,checkpoint,checkpoint,2718,,https://github.com/google/deepvariant/issues/171#issuecomment-483448362,1,['checkpoint'],['checkpoint']
Availability,"ible there may have been something that I wouldn’t expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out “complex variants” (with more than one variant at a position), but .vcf files containing those variants weren’t flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:; ```; 68759 / 72556 (94.8%) full SNP recovery; 71276 / 72556 (98.2%) partial SNP recovery; 3027 / 3648 (83.0%) full insertion recovery; 3413 / 3648 (93.6%) partial insertion recovery; 3119 / 3911 (79.7%) full deletion recovery; 3596 / 3911 (91.9%) partial deletion recovery; ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:; ```; 51417 / 54229 (94.8%) full SNP recovery; 53116 / 54229 (97.9%) partial SNP recovery; 1964 / 2391 (82.1%) full insertion recovery; 2242 / 2391 (93.8%) partial insertion recovery; 2058 / 2537 (81.1%) full deletion recovery; 2349 / 2537 (92.6%) partial deletion recovery; ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a “*partial*” recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:1629,recover,recovery,1629,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"ike;; > Thanks for all this background and help. I'm trying to fit this into the; > conda recipe bazel build for DeepVariant but am not sure how to take; > advantage of using the local anaconda python in that context. The error I'm; > seeing is that bazel can't find pyclif_proto:; >; > (17:56:01) INFO: Found 1 target...; > (17:56:01) [0 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt; > (17:56:01) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'; > (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1: //third_party/nucleus/protos:variants_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'; > Target //deepvariant:binaries failed to build; > (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1 1 input file(s) do not exist; >; > which I thought was triggered by the difficulty running pyclif without; > having the local python installed. It could also be due to not installing; > is in /usr/local/bin since I have to remain sandboxed in the work; > directory, but I did adjust the PATH to include the download location.; >; > Sorry I'm stuck here due to me limited knowledge of bazel tweaking. Either; > understanding how to handle a root install of the pre-build pyclif or; > tweaking to use the local python would be helpful. Alternatively, if you; > can already build DeepVariant on a CentOS6 system yourself I could use the; > pre-build binaries the way we're doing now, just with the build against an; > older glibc. Thanks again for the help with this.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/29#issuecomment-386250002>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABQZ2kaD2Oo0vlzfw55tL9A65ZhknIu-ks5tutlEgaJpZM4RQhCy>; > .; >. -- ; Thanks,; --Mike",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386327937:1803,down,download,1803,,https://github.com/google/deepvariant/issues/29#issuecomment-386327937,1,['down'],['download']
Availability,"ility of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me ; docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling.; See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol; dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input; total 0; -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world; 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file; touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file; -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input; total 0; -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file; -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. Untagged: hello-world:latest; Untagged: hello-world@sha256:dcba6daec718f547568c562956fa47e1b03673dd010fe6ee58ca806767031d1c; Deleted: sha256:9c7a54a9a43cca047013b82af109fe963fde787f63f9e016fdc3384500c2823d. This gave the error you indicated, and the fix worked as well; docker volume rm dv-vol. Best,; Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1701949973:2221,error,error,2221,,https://github.com/google/deepvariant/issues/184#issuecomment-1701949973,2,['error'],['error']
Availability,image 'google/deepvariant:1.5.0' locally; 1.5.0: Pulling from google/deepvariant; 7608715873ec: Already exists ; ff9c04d6f4fd: Already exists ; ccc0633ad137: Already exists ; 31c4e73f93e5: Already exists ; 5f25a39487ec: Already exists ; 634688f8f57d: Already exists ; ce40c5e2b0ba: Already exists ; 9eaa0cfabb44: Already exists ; f71d9ff16a67: Already exists ; 27ddda9faddb: Already exists ; 6ba5fd944a25: Already exists ; bec3e4e06e4d: Already exists ; dc1469807dcc: Already exists ; ceb45df4e1ef: Already exists ; 4f6165ff322d: Already exists ; f9cefd1876c2: Already exists ; 931b80517c67: Already exists ; 7b13ecd8df6e: Already exists ; 245c9afd7ea9: Already exists ; 97c2b022ac0f: Already exists ; 4c15f3639f35: Already exists ; fa21a1eddf03: Already exists ; 6419c68a3d65: Already exists ; 8751b2539913: Already exists ; 20646815bf33: Already exists ; 25dc07245f2e: Already exists ; 6e3dea686609: Already exists ; dc216b407a52: Already exists ; c6710cf0efec: Already exists ; 6a519085af15: Already exists ; fd35c1634889: Already exists ; 0e4b2b2ad2db: Already exists ; 87e7c72faeb5: Already exists ; 690adc142e08: Already exists ; abfd217d5088: Already exists ; 30b033b0505f: Already exists ; 853ad599972a: Already exists ; f20c79af8049: Already exists ; 26703b5b7abd: Already exists ; f3b33765da79: Already exists ; c382f9fc227e: Already exists ; 3a233bad0db5: Already exists ; f6ac10e59ad4: Already exists ; 9e1d2d199a37: Already exists ; b50b4a1202e8: Already exists ; 1286a89300c9: Already exists ; 11f1b6d48e7b: Already exists ; 09154ad67b50: Already exists ; aad195d6c4df: Already exists ; f8376ea6a177: Already exists ; b44e5a321822: Already exists ; e81a72561181: Already exists ; e96d0f626428: Already exists ; bea852b4c2f5: Already exists ; 13d620954600: Already exists ; 123b4e4b7a6e: Already exists ; Digest: sha256:6a27bc877db9191c8fad0fe5f98dce6192fd4eb6392551e1a3add8d01e08af2e; Status: Downloaded newer image for google/deepvariant:1.5.0; 2023-08-22 01:54:42.917386: I tensorflow/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/700#issuecomment-1687461144:2567,Down,Downloaded,2567,,https://github.com/google/deepvariant/issues/700#issuecomment-1687461144,1,['Down'],['Downloaded']
Availability,"ine 1007, in main; FLAGS.outfile, header=header, round_qualities=True) as vcf_writer, \; File ""/tmp/Bazel.runfiles_gmddntqf/runfiles/com_google_deepvariant/third_party/nucle us/io/genomics_writer.py"", line 170, in __init__; self._writer = self._native_writer(output_path, **kwargs); File ""/tmp/Bazel.runfiles_gmddntqf/runfiles/com_google_deepvariant/third_party/nucle us/io/vcf.py"", line 316, in _native_writer; exclude_header=exclude_header); File ""/tmp/Bazel.runfiles_gmddntqf/runfiles/com_google_deepvariant/third_party/nucle us/io/vcf.py"", line 288, in __init__; writer_options); ValueError: Unknown: Could not open variants_path: /scratch/moldach/bin/quickstart-out put/output.vcf.gz. real 0m3.763s; user 0m2.899s; sys 0m0.651s; I0327 13:32:43.946818 47794500922048 run_deepvariant.py:321] None; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>; app.run(main); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run; _run_main(main, args); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/scratch/moldach/bin/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --inf ile ""/tmp/tmp63xxmwmi/call_variants_output.tfrecord.gz"" --outfile ""/scratch/moldach/bi n/quickstart-output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmp63xxmwmi/g vcf.tfrecord@1.gz"" --gvcf_outfile ""/scratch/moldach/bin/quickstart-output/output.g.vcf .gz""' returned non-zero exit status 1.; [moldach@cdr767 bin]$ ^C; [moldach@cdr767 bin]$ exit; exit; srun: error: cdr767: task 0: Exited with exit code 130; ```. Any idea what could be causing this?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-605306987:14074,error,error,14074,,https://github.com/google/deepvariant/issues/287#issuecomment-605306987,1,['error'],['error']
Availability,"ine 1268, in restore; + compat.as_text(save_path)); ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s; user	0m9.233s; sys	0m4.817s; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>; app.run(main); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run; _run_main(main, args); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1; ```; However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```; #!/usr/bin/zsh; OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model""; mkdir -p ""${OUTPUT_DIR}""; INPUT_DIR=""${PWD}""; BIN_VERSION=""0.9.0""; N_SHARDS=20; LOG_DIR=""${OUTPUT_DIR}/logs"" ; mkdir -p ""${LOG_DIR}"" ; #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3); #for SAMPLE in ""${decade[@]}""; #do; # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz; #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/268#issuecomment-586584341:3187,checkpoint,checkpoint,3187,,https://github.com/google/deepvariant/issues/268#issuecomment-586584341,1,['checkpoint'],['checkpoint']
Availability,"ine 70, in get_tensor; self, compat.as_bytes(tensor_str)); RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py"", line 1309, in restore; names_to_keys = object_graph_key_mapping(save_path); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py"", line 1627, in object_graph_key_mapping; object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor; error_translator(e); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator; raise errors_impl.NotFoundError(None, None, error_message); tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_8s8eyzhg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_8s8eyzhg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_8s8eyzhg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_8s8eyzhg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main; use_tpu=FLAGS.use_tpu,; File ""/tmp/Bazel.runfiles_8s8eyzhg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/757#issuecomment-1864800013:13271,checkpoint,checkpoint,13271,,https://github.com/google/deepvariant/issues/757#issuecomment-1864800013,1,['checkpoint'],['checkpoint']
Availability,"ing Singularity + GPU to run variant calling as well, or are you seeing this issue with training only? (I'm curious because I've tried Singularity+GPU for variant calling, and that worked fine. But I haven't personally tried Singularity+GPU training yet. So I'll first want to see if I can reproduce that issue). Hi @pichuan ,. When I run the GPU version, I got this error mesages, but it still finished SNP calling and all the output files seemed fine. == CUDA ==; CUDA Version 11.3.1; 2023-10-30 00:30:39.544727: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:40.075465: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:40.617831: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:41.161964: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:41.707151: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:42.254657: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:42.796956: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:43.322127: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:43.879132: E tensorflow/c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/722#issuecomment-1784889993:1193,error,error,1193,,https://github.com/google/deepvariant/issues/722#issuecomment-1784889993,1,['error'],['error']
Availability,"input/${REF}.gz"" \; --reads=""/input/${BAM}"" \; @@ -100,6 +100,6 @@ pkrusche/hap.py /opt/hap.py/bin/hap.py \; -f ""${INPUT_DIR}/${TRUTH_BED}"" \; -r ""${UNCOMPRESSED_REF}"" \; -o ""${OUTPUT_DIR}/happy.output"" \; - --engine=vcfeval; + --engine=vcfeval -l chr1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done."". ```. Runtime:; ```; $ grep '^real' /tmp/open; real 7m38.326s; real 15m12.564s; real 7m15.173s; ```. 2. Use your Docker image, use_openvino=false; The code diff:; ```; $ git diff; diff --git a/scripts/run_wgs_case_study_docker.sh b/scripts/run_wgs_case_study_docker.sh; index 3dc9712..78712d8 100755; --- a/scripts/run_wgs_case_study_docker.sh; +++ b/scripts/run_wgs_case_study_docker.sh; @@ -65,14 +65,14 @@ aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testda; aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testdata/${REF}.fai"" -d ""${INPUT_DIR}""; ; ## Pull the docker image.; -sudo docker pull google/deepvariant:""${BIN_VERSION}""; +sudo docker pull dkurtaev/deepvariant:latest; ; echo ""Run DeepVariant...""; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; - google/deepvariant:""${BIN_VERSION}"" \; - /opt/deepvariant/bin/run_deepvariant \; + dkurtaev/deepvariant:latest \; + /opt/deepvariant/bin/run_deepvariant --call_variants_extra_args=use_openvino=false --make_examples_extra_args=regions=chr1 \; --model_type=WGS \; --ref=""/input/${REF}.gz"" \; --reads=""/input/${BAM}"" \; @@ -100,6 +100,6 @@ pkrusche/hap.py /opt/hap.py/bin/hap.py \; -f ""${INPUT_DIR}/${TRUTH_BED}"" \; -r ""${UNCOMPRESSED_REF}"" \; -o ""${OUTPUT_DIR}/happy.output"" \; - --engine=vcfeval; + --engine=vcfeval -l chr1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done.""; ```. Runtime:; ```; $ grep '^real' /tmp/open; real 7m20.986s; real 21m24.429s; real 6m32.705s; ```. 3. Use v1.0.0 image.; The code diff:; ```; $ git diff; diff --git a/scripts/run_wgs_case_study_docker.sh b/scripts/run_wgs_case_study_docker.sh; index 3dc9712..88fb0c1 100755;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735276044:2532,echo,echo,2532,,https://github.com/google/deepvariant/pull/363#issuecomment-735276044,1,['echo'],['echo']
Availability,"installed pip-23.1.2; WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH.; Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.; Successfully installed pip-23.1.2; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; Python 3.8.10; pip 23.1.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); ========== [Mon 05 Jun 2023 01:42:38 AM UTC] Stage 'Install python3 packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; werkzeug 2.3.4 requires MarkupSafe>=2.1.1, but you have markupsafe 2.0.1 which is incompatible.; ========== [Mon 05 Jun 2023 01:42:50 AM UTC] Stage 'Install other packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:8017,ERROR,ERROR,8017,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,1,['ERROR'],['ERROR']
Availability,"installed pip-23.1.2; WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH.; Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.; Successfully installed pip-23.1.2; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; Python 3.8.10; pip 23.1.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); ========== [Mon 05 Jun 2023 03:51:27 PM UTC] Stage 'Install python3 packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:2756,ERROR,ERROR,2756,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,1,['ERROR'],['ERROR']
Availability,"installed pip-23.1.2; WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH.; Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.; Successfully installed pip-23.1.2; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; Python 3.8.10; pip 23.1.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); ========== [Mon 05 Jun 2023 10:22:17 PM EDT] Stage 'Install python3 packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053:3782,ERROR,ERROR,3782,,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053,1,['ERROR'],['ERROR']
Availability,"installed pip-23.1.2; WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH.; Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.; Successfully installed pip-23.1.2; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; Python 3.8.10; pip 23.1.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); ========== [Sun 04 Jun 2023 11:11:13 PM UTC] Stage 'Install python3 packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; ========== [Sun 04 Jun 2023 11:11:24 PM UTC] Stage 'Install TensorFlow pip package' starting; Installing standard CPU-only TensorFlow 2.11.0 wheel; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276:2411,ERROR,ERROR,2411,,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276,1,['ERROR'],['ERROR']
Availability,"ipts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out “complex variants” (with more than one variant at a position), but .vcf files containing those variants weren’t flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:; ```; 68759 / 72556 (94.8%) full SNP recovery; 71276 / 72556 (98.2%) partial SNP recovery; 3027 / 3648 (83.0%) full insertion recovery; 3413 / 3648 (93.6%) partial insertion recovery; 3119 / 3911 (79.7%) full deletion recovery; 3596 / 3911 (91.9%) partial deletion recovery; ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:; ```; 51417 / 54229 (94.8%) full SNP recovery; 53116 / 54229 (97.9%) partial SNP recovery; 1964 / 2391 (82.1%) full insertion recovery; 2242 / 2391 (93.8%) partial insertion recovery; 2058 / 2537 (81.1%) full deletion recovery; 2349 / 2537 (92.6%) partial deletion recovery; ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://precision.fda.gov/comparisons/3436). There are two numbers because a “*partial*” recovery just checks for the presence of a variant (either heterozygous or homozygous). Due to formatting differences (such as with indels), I didn’t feel comfortable showing comparisons between variant callers on my page with notes/code on my [Genos Exome sample](https://github.com/cwarden45/DTC_Scripts/tree/master/Genos_Exome), but I think this is OK when using the same variant caller on different samples. For comparison, the precisionFDA comparison for the provided .vcf files is [here](https://precision.fda.gov/comparisons/3434), a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:2056,recover,recovery,2056,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"is it possible to make this available https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-20.latest.tgz. Since I have another problem about ""Install CLIF binary"" using ubuntu 20.04. Quote from build-prereq.sh script:. # Figure out which linux installation we are on to fetch an appropriate # version of the pre-built CLIF binary. Note that we only support now Ubuntu # 14, 16, and 18.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-821553096:28,avail,available,28,,https://github.com/google/deepvariant/issues/441#issuecomment-821553096,1,['avail'],['available']
Availability,"ithub.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md. For the main DeepVariant command, I ran:. ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --intermediate_results_dir /output/intermediate_results_dir \; --num_shards=1 \; --call_variants_extra_args=""use_openvino=true"" \; 2>&1 | tee /tmp/deepvariant.log; ```. With this run above, all steps (including call_variants) completed without errors. After that run, I repeated the call_variants step:; ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/call_variants \; --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" \; --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" \; --checkpoint ""/opt/models/wgs/model.ckpt"" \; --use_openvino; ```; which worked fine too. You mentioned you used DeepVariant1.1.0 version via Docker, but you also mentioned your command was:; `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32`. Can you be more specific about how you run this command?. And, another pointer for you:; In our Dockerfile, we set these environment variables:; https://github.com/google/deepvariant/blob/r1.1/Dockerfile#L156-L157. You should probably first check whether those directories exist in your environment. And if they do exist, you'll need to set those environment variables too. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/432#issuecomment-806341687:1717,checkpoint,checkpoint,1717,,https://github.com/google/deepvariant/issues/432#issuecomment-806341687,2,['checkpoint'],['checkpoint']
Availability,"ization. DO NOT click; > links or open attachments unless you recognize the sender and know the; > content is safe.; >; > I think you'll want:; > tfrecord_path:; > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064""; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub<; > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,; > or mute the thread<; > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>.; >; >; > This message contains confidential information and is intended only for; > the individual named. If you are not the named addressee you should not; > disseminate, distribute or copy this e-mail. Please notify the sender; > immediately by e-mail if you have received this e-mail by mistake and; > delete this e-mail from your system. E-mail transmission cannot be; > guaranteed to be secured or error-free as information could be intercepted,; > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses.; > The sender therefore does not accept liability for any errors or omissions; > in the contents of this message, which arise as a result of e-mail; > transmission. If verification is required please request a hard-copy; > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort; > Myers, FL 33913, http://www.neogenomics.com (2017); >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>; > .; >. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381164890:3031,error,error-free,3031,,https://github.com/google/deepvariant/issues/62#issuecomment-381164890,1,['error'],['error-free']
Availability,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/518#issuecomment-1696738838:1752,avail,available,1752,,https://github.com/google/deepvariant/issues/518#issuecomment-1696738838,2,['avail'],['available']
Availability,"kages""; @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1; # --experimental_build_setting_api""; # Presumably it won't be needed at some later point when bazel_skylib is; # upgraded again.; -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11""; +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11""; ; function note_build_stage {; echo ""========== [$(date)] Stage '${1}' starting""; ```; ```; diff --git a/build-prereq.sh b/build-prereq.sh; index ad34e285..1fc2d203 100755; --- a/build-prereq.sh; +++ b/build-prereq.sh; @@ -41,7 +41,7 @@ source settings.sh; ; note_build_stage ""Install the runtime packages""; ; -./run-prereq.sh; +#./run-prereq.sh; ; note_build_stage ""Update package list""; ; @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {; then; echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling""; else; - pushd ~/bazel; - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh; - chmod +x bazel-*.sh; - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null; - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh; - popd; + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64; + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel; + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk; + chmod +x /usr/local/bin/bazel; + chmod +x /usr/local/bin/bazelisk; fi; }; ```; ```; diff --git a/tools/build_clif.sh b/tools/build_clif.sh; index c7c3378b..a08ab475 100755; --- a/tools/build_clif.sh; +++ b/tools/build_clif.sh; @@ -39,7 +39,7 @@ echo ========== Run this script in root mode.; CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}""; ABSL_PIN=""${ABSL_PIN-29bf8085",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217:2558,echo,echo,2558,,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217,1,['echo'],['echo']
Availability,"ke sure you're using the [-v flags](https://docs.docker.com/storage/volumes/) correctly and make sure the files are visible to it. (3) I tested with `sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.2` first and directly running the commands inside. I modified from the WES example because it's faster, but WGS should be the same. I can confirm that I was able to run the following steps without any issues:. 1. Start interactive mode so I can use command similar to yours. I'm not considering how I'm getting the data out.; ```; sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.2; ```. 2. Inside the interactive mode, run the following:; ```; MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wes_standard""; DATA_HTTP_DIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata; N_SHARDS=""64"". ## Download extra packages; sudo apt-get -y update; sudo apt-get -y install parallel; sudo apt-get -y install aria2; ## Download models, and test data; # Copy the model files to your local disk.; aria2c -c -x10 -s10 ""${MODEL_HTTP_DIR}""/model.ckpt.data-00000-of-00001; aria2c -c -x10 -s10 ""${MODEL_HTTP_DIR}""/model.ckpt.index; aria2c -c -x10 -s10 ""${MODEL_HTTP_DIR}""/model.ckpt.meta. # Copy the data; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/agilent_sureselect_human_all_exon_v5_b37_targets.bed; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz.fai; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz.gzi; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gzi; ```. Then, I ran `make_examples` similar to the way you did in your original post:; ```; ## Run `make_examples`; ( time seq",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:1934,Down,Download,1934,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,2,['Down'],['Download']
Availability,"ked fine. But I haven't personally tried Singularity+GPU training yet. So I'll first want to see if I can reproduce that issue). Hi @pichuan ,. When I run the GPU version, I got this error mesages, but it still finished SNP calling and all the output files seemed fine. == CUDA ==; CUDA Version 11.3.1; 2023-10-30 00:30:39.544727: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:40.075465: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:40.617831: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:41.161964: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:41.707151: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:42.254657: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:42.796956: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:43.322127: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:43.879132: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error; 2023-10-30 00:30:44.404755: E tensorflow/c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/722#issuecomment-1784889993:1377,error,error,1377,,https://github.com/google/deepvariant/issues/722#issuecomment-1784889993,1,['error'],['error']
Availability,"ks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1656474342:1174,repair,repair,1174,,https://github.com/google/deepvariant/issues/682#issuecomment-1656474342,1,['repair'],['repair']
Availability,"l-devel bzip2-devel libffi-devel -y; sudo yum install -y wget; sudo yum install -y python3; ```. ```; wget https://www.python.org/ftp/python/3.8.10/Python-3.8.10.tgz; tar xvfz Python-3.8.10.tgz; ```. ```; cd Python-3.8.10; ./configure --enable-optimizations; ```. ```; sudo yum install -y make; sudo make altinstall; ```. ```; [pichuan@pichuan-centos7 Python-3.8.10]$ python3.8 --version; Python 3.8.10; ```. ## Install Singularity. ```; sudo yum update -y && \; sudo yum groupinstall -y 'Development Tools' && \; sudo yum install -y \; openssl-devel \; libuuid-devel \; libseccomp-devel \; wget \; squashfs-tools \; cryptsetup; ```. ```; export VERSION=1.14.12 OS=linux ARCH=amd64; # Downloads the required Go package; wget https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz; # Extracts the archive; sudo tar -C /usr/local -xzvf go$VERSION.$OS-$ARCH.tar.gz; # Deletes the ``tar`` file; rm go$VERSION.$OS-$ARCH.tar.gz. export VERSION=3.8.4; wget https://github.com/hpcng/singularity/releases/download/v${VERSION}/singularity-${VERSION}.tar.gz; tar -xzf singularity-${VERSION}.tar.gz; pushd singularity-3.8.4; export PATH=/usr/local/go/bin:$PATH. ./mconfig; make -C builddir; sudo make -C builddir install; ```. Check version:; ```; [pichuan@pichuan-centos7 ~]$ singularity --version; singularity version 3.8.4; ```. ## Try running DeepVariant with Singularity. I followed Quick Start to get data. ```; singularity pull docker://google/deepvariant:1.4.0; # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1; ```. This worked for me. Check nump",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/610#issuecomment-1429156759:1654,down,download,1654,,https://github.com/google/deepvariant/issues/610#issuecomment-1429156759,1,['down'],['download']
Availability,"l/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result; google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --reads; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam; --ref; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/hg38_chrM.fa; --report_title MITO60_Stats --sample_name MITO60 --output_vcf; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result/deepvariant_MITO60.vcf.gz; --model_type ONT_R104. On Wed, Jun 12, 2024 at 1:02 PM JYOTI MRIDHA ***@***.***> wrote:. > Hi,; > Thanks a lot for your immediate response, i have followed the above; > instructions given by you, now the docker command is running fine, but I; > have come across a new error.; >; > *[E::hts_open_format] Failed to open file; > ""/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result""; > : Is a directory*; >; > *ValueError: UNKNOWN: Could not open variants_path:; > /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result*; >; > here i have used the same path for docker run (-v; > /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result); > and also same path for run_deepvariant (--output_vcf; > /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/829#issuecomment-2162485508:1641,error,error,1641,,https://github.com/google/deepvariant/issues/829#issuecomment-2162485508,2,['error'],['error']
Availability,"l`, as shown under the [*Pick a model*](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md#pick-a-model) section. Probably it would be easiest to pick the one that is specified by the `best_checkpoint.txt` file. $`2)`$ Regarding `.pb` files, these are serialized binary ProtoBuf formatted versions of the model with additional details, denoted as the [*TensorFlow's SavedModel format*](https://www.tensorflow.org/guide/saved_model). When performing variant calling, DeepVariant can only use `.ckpt` model files - not `.pb` files - as specified under the [*Convert model.ckpt to model.pb*](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#convert-modelckpt-to-modelpb-savedmodel-format) section. May I ask why you might need the ProtoBuf formatted file? . $`3)`$ Regarding the `model.ckpt.example_info.json` file, it is used to validate the checkpointed model's JSON file with the JSON file generated for the examples files, matching against a few specs such as channels and shape (tensor image dimensions), to ensure data and model match before performing variant calling. It should have been automatically copied over by the [`copy_over_example_info_json()` function](https://github.com/google/deepvariant/blob/r1.5/deepvariant/model_train.py#L151-L162). Basically it contains the version of DeepVariant, the tensor image shape (rows, columns, channels) and enumerated channels. There are different ones for different technologies, and below is a list of the contents for each instrument:. ##### ONT R10.4; ```Json; {""version"": ""1.5.0"", ""shape"": [100, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ```. ##### PacBio; ```Json; {""version"": ""1.5.0"", ""shape"": [100, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ```. ##### WES; ```Json; {""version"": ""1.5.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}; ```. ##### WGS; ```Json; {""version"": ""1.5.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}; ``",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1732869051:1148,checkpoint,checkpointed,1148,,https://github.com/google/deepvariant/issues/706#issuecomment-1732869051,2,['checkpoint'],['checkpointed']
Availability,"led filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldn’t expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out “complex variants” (with more than one variant at a position), but .vcf files containing those variants weren’t flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:; ```; 68759 / 72556 (94.8%) full SNP recovery; 71276 / 72556 (98.2%) partial SNP recovery; 3027 / 3648 (83.0%) full insertion recovery; 3413 / 3648 (93.6%) partial insertion recovery; 3119 / 3911 (79.7%) full deletion recovery; 3596 / 3911 (91.9%) partial deletion recovery; ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:; ```; 51417 / 54229 (94.8%) full SNP recovery; 53116 / 54229 (97.9%) partial SNP recovery; 1964 / 2391 (82.1%) full insertion recovery; 2242 / 2391 (93.8%) partial insertion recovery; 2058 / 2537 (81.1%) full deletion recovery; 2349 / 2537 (92.6%) partial deletion recovery; ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://pre",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:1379,recover,recovery,1379,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,4,['recover'],['recovery']
Availability,"les ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required.; I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required.; I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required.; I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required.; I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required.; I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required.; I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required.; I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd); /home/fci**; and I will attach screen of my home that ref file is found ; **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1303717562:1951,error,errors,1951,,https://github.com/google/deepvariant/issues/581#issuecomment-1303717562,5,"['echo', 'error']","['echo', 'errors']"
Availability,"les (but there are going to be considerably fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```; 20765 / 21141 (98.2%) full SNP recovery; 20872 / 21141 (98.7%) partial SNP recovery; 243 / 258 (94.2%) full insertion recovery; 249 / 258 (96.5%) partial insertion recovery; 208 / 228 (91.2%) full deletion recovery; 213 / 228 (93.4%) partial deletion recovery; ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:; If you go to “[explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select “**func_cds**” (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:4757,recover,recovery,4757,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"lieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You don’t have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,; Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:8452,avail,available,8452,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['avail'],['available']
Availability,"line 87, in _run_code; exec(code, run_globals); File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main; AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found.; Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main; AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found.; parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full?; parallel: Error: Change $TMPDIR with --tmpdir or use --compress.; Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s; user 0m1.215s; sys 0m0.687s. ## command-line plan B:; /share/app/singularity/3.8.1/bin/singularity exec \; --bind /usr/lib/locale/:/usr/lib/locale/ \; --bind $ccsbam:$ccsbam \; --bind $ccsbam.bai:$ccsbam.bai \; --bind $fasta:$fasta \; --bind $fasta.fai:$fasta.fai \; --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \; /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****; ***** Running the command:*****; ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300:3963,Error,Error,3963,,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300,1,['Error'],['Error']
Availability,"llowing comment](https://github.com/google/deepvariant/issues/691#issuecomment-1662968609). Make sure to create the `realigned_reads` directory first, by adding the following line to your script, below your first `mkdir` statement:. `mkdir -p ""${OUTPUT_DIR}/realigned_reads""` . After you relaunch the script, the BAM file(s) representing that region would be the one you would use in IGV. $`2)`$ Now given that, there would still be a lot of reads in that region for the allele counter to create candidates from. You have below the 1,500 maximum read depth, as noted in the following [FAQ section](https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#how-are-ad-and-dp-values-calculated), but quite a few seem to still remain. You noticed that only 490 appear supporting that position, and DeepVariant is position-specific. If the quality of the allele is low those are not used. For example, your GQ here is 5 to support the variant, and your QUAL 1.5, which tells me there is no variant and the error is 32% of it being that variant. It would also help to check your gVCF as that contains everything. Also if there are multiple deletions at the same location it determines the deletions with the highest read support, and deletes all other deletions from the allele map. $`4)`$ There are additional cutoffs for the type of candidates it selects. If you want to adjust thresholds for specific types of candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2); * vsc_min_count_indels (the default is 2); * vsc_min_fraction_snps (the default is 0.12); * vsc_min_fraction_indels (the default is 0.06); * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```; --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'; ```. You can read more details about these parameters at th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/697#issuecomment-1681008918:1595,error,error,1595,,https://github.com/google/deepvariant/issues/697#issuecomment-1681008918,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================. FAILED: //deepvariant:make_examples_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; (06:29:20) FAIL: //deepvariant:make_examples_test (shard 1 of 2) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log); (06:29:20) INFO: From Testing //deepvariant:make_examples_test (shard 1 of 2):; ==================== Test output for //deepvariant:make_examples_test (shard 1 of 2):; Traceback (most recent call last):; File ""/root/.cache/baze",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:99956,error,error,99956,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:08) FAIL: //deepvariant/realigner:aligner_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log); (06:29:08) INFO: From Testing //deepvariant/realigner:aligner_test:; ==================== Test output for //deepvariant/realigner:aligner_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/aligner_test.runfiles/com_google_deepvariant/deepvariant/realigner/aligner_test.py"", line 40, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/aligner_test.runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:14041,error,error,14041,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:08) [2,482 / 2,523] 16 / 38 tests, 2 failed; Testing //deepvariant:call_variants_test; 0s local ... (41 actions, 1 running); (06:29:09) FAIL: //deepvariant:call_variants_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log); (06:29:09) INFO: From Testing //deepvariant:call_variants_test:; ==================== Test output for //deepvariant:call_variants_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_test.runfiles/com_google_deepvariant/deepvariant/call_variants_test.py"", line 48, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:16499,error,error,16499,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:09) FAIL: //deepvariant:model_train_test (shard 3 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log); (06:29:09) INFO: From Testing //deepvariant:model_train_test (shard 3 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 3 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:18736,error,error,18736,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:09) [2,484 / 2,523] 17 / 38 tests, 3 failed; Testing //deepvariant:model_train_test [0s (9 actions)] ... (39 actions, 2 running); (06:29:09) FAIL: //deepvariant:model_train_test (shard 2 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log); (06:29:09) INFO: From Testing //deepvariant:model_train_test (shard 2 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 2 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:20891,error,error,20891,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant/labeler:customized_classes_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log); (06:29:10) INFO: From Testing //deepvariant/labeler:customized_classes_labeler_test:; ==================== Test output for //deepvariant/labeler:customized_classes_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/customized_classes_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/customized_classes_labeler_test.py"", line 41, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:32473,error,error,32473,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant/labeler:positional_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log); (06:29:10) INFO: From Testing //deepvariant/labeler:positional_labeler_test:; ==================== Test output for //deepvariant/labeler:positional_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/positional_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/positional_labeler_test.py"", line 40, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:25258,error,error,25258,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant:model_train_test (shard 1 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log); (06:29:10) INFO: From Testing //deepvariant:model_train_test (shard 1 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 1 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:28074,error,error,28074,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant:tf_utils_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log); (06:29:10) INFO: From Testing //deepvariant:tf_utils_test:; ==================== Test output for //deepvariant:tf_utils_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/tf_utils_test.runfiles/com_google_deepvariant/deepvariant/tf_utils_test.py"", line 40, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:23183,error,error,23183,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) [2,488 / 2,523] 19 / 38 tests, 5 failed; Testing //deepvariant:data_providers_test; 0s local ... (35 actions, 2 running); (06:29:10) FAIL: //deepvariant:data_providers_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log); (06:29:10) INFO: From Testing //deepvariant:data_providers_test:; ==================== Test output for //deepvariant:data_providers_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/data_providers_test.runfiles/com_google_deepvariant/deepvariant/data_providers_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:30229,error,error,30229,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:11) FAIL: //deepvariant:model_train_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log); (06:29:11) INFO: From Testing //deepvariant:model_train_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:35353,error,error,35353,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:11) FAIL: //deepvariant:model_train_test (shard 7 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log); (06:29:11) INFO: From Testing //deepvariant:model_train_test (shard 7 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 7 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:37508,error,error,37508,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) FAIL: //deepvariant:haplotypes_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log); (06:29:12) INFO: From Testing //deepvariant:haplotypes_test:; ==================== Test output for //deepvariant:haplotypes_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/haplotypes_test.runfiles/com_google_deepvariant/deepvariant/haplotypes_test.py"", line 43, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/haplotypes_test.runfiles/com_google_deepvariant/third_party/nucleus/test",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:41949,error,error,41949,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) FAIL: //deepvariant:model_eval_test (shard 8 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log); (06:29:12) INFO: From Testing //deepvariant:model_eval_test (shard 8 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 8 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-impor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:44358,error,error,44358,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) [2,492 / 2,523] 21 / 38 tests, 7 failed; Testing //deepvariant:model_eval_test [0s (10 actions)] ... (31 actions, 2 running); (06:29:12) FAIL: //deepvariant:model_eval_test (shard 1 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log); (06:29:12) INFO: From Testing //deepvariant:model_eval_test (shard 1 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 1 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/si",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:39663,error,error,39663,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:13) FAIL: //deepvariant:model_eval_test (shard 10 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log); (06:29:13) INFO: From Testing //deepvariant:model_eval_test (shard 10 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 10 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:50941,error,error,50941,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:13) FAIL: //deepvariant:model_eval_test (shard 7 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log); (06:29:13) INFO: From Testing //deepvariant:model_eval_test (shard 7 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 7 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-impor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:48792,error,error,48792,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:13) [2,495 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_eval_test [0s (8 actions)] ... (28 actions, 2 running); (06:29:13) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (06:29:13) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/sit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:46507,error,error,46507,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:14) FAIL: //deepvariant:model_eval_test (shard 3 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log); (06:29:14) INFO: From Testing //deepvariant:model_eval_test (shard 3 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 3 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-impor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:57528,error,error,57528,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:14) FAIL: //deepvariant:model_eval_test (shard 4 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log); (06:29:14) INFO: From Testing //deepvariant:model_eval_test (shard 4 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 4 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-impor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:55379,error,error,55379,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:14) [2,498 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_eval_test [0s (5 actions)] ... (25 actions, 2 running); (06:29:14) FAIL: //deepvariant:model_eval_test (shard 5 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log); (06:29:14) INFO: From Testing //deepvariant:model_eval_test (shard 5 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 5 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/sit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:53094,error,error,53094,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:15) FAIL: //deepvariant:model_eval_test (shard 2 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log); (06:29:15) INFO: From Testing //deepvariant:model_eval_test (shard 2 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 2 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-impor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:59677,error,error,59677,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:15) FAIL: //deepvariant:model_train_test (shard 4 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log); (06:29:15) INFO: From Testing //deepvariant:model_train_test (shard 4 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 4 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:64118,error,error,64118,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:15) [2,502 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test [0s (5 actions)] ... (21 actions, 2 running); (06:29:15) FAIL: //deepvariant:model_train_test (shard 9 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log); (06:29:15) INFO: From Testing //deepvariant:model_train_test (shard 9 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 9 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:61826,error,error,61826,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) FAIL: //deepvariant:model_train_test (shard 5 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log); (06:29:16) INFO: From Testing //deepvariant:model_train_test (shard 5 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 5 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:66273,error,error,66273,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) FAIL: //deepvariant:model_train_test (shard 8 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log); (06:29:16) INFO: From Testing //deepvariant:model_train_test (shard 8 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 8 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:68428,error,error,68428,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) [2,506 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test (shard 10 of 10); 0s local ... (17 actions, 2 running). FAILED: //deepvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:70583,error,error,70583,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:17) FAIL: //deepvariant/realigner/allele_count_linear:model_evaluation_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log); (06:29:17) INFO: From Testing //deepvariant/realigner/allele_count_linear:model_evaluation_test:; ==================== Test output for //deepvariant/realigner/allele_count_linear:model_evaluation_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/realigner/allele_count_linear/model_evaluation_test.py"", line 41, in <module>; from deepvariant import testdata; File ""/ro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:77127,error,error,77127,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:17) FAIL: //deepvariant:variant_caller_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log); (06:29:17) INFO: From Testing //deepvariant:variant_caller_test:; ==================== Test output for //deepvariant:variant_caller_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/variant_caller_test.runfiles/com_google_deepvariant/deepvariant/variant_caller_test.py"", line 43, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/variant_caller_test.runfiles/com_google_deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:74690,error,error,74690,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/python:allelecounter_wrap_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log); (06:29:18) INFO: From Testing //deepvariant/python:allelecounter_wrap_test:; ==================== Test output for //deepvariant/python:allelecounter_wrap_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/python/allelecounter_wrap_test.runfiles/com_google_deepvariant/deepvariant/python/allelecounter_wrap_test.py"", line 38, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:82450,error,error,82450,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/realigner/allele_count_linear:generate_trained_model_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner/allele_count_linear:generate_trained_model_test:; ==================== Test output for //deepvariant/realigner/allele_count_linear:generate_trained_model_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/generate_trained_model_test.runfiles/com_google_deepvariant/deepvariant/realigner/allele_count_linear/generate_trained_model_test.py"", line 39, in <module>; import ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:80111,error,error,80111,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/realigner/python:debruijn_graph_wrap_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner/python:debruijn_graph_wrap_test:; ==================== Test output for //deepvariant/realigner/python:debruijn_graph_wrap_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/python/debruijn_graph_wrap_test.runfiles/com_google_deepvariant/deepvariant/realigner/python/debruijn_graph_wrap_test.py"", line 38, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:84944,error,error,84944,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/realigner:window_selector_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner:window_selector_test:; ==================== Test output for //deepvariant/realigner:window_selector_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/window_selector_test.runfiles/com_google_deepvariant/deepvariant/realigner/window_selector_test.py"", line 40, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:89795,error,error,89795,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) [2,512 / 2,523] 28 / 38 tests, 14 failed; Testing //deepvariant/realigner:realigner_test; 0s local ... (11 actions, 2 running); (06:29:18) FAIL: //deepvariant/realigner:realigner_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner:realigner_test:; ==================== Test output for //deepvariant/realigner:realigner_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/realigner_test.runfiles/com_google_deepvariant/deepvariant/realigner/realigner_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-pac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:87515,error,error,87515,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:19) FAIL: //deepvariant/labeler:haplotype_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log); (06:29:19) INFO: From Testing //deepvariant/labeler:haplotype_labeler_test:; ==================== Test output for //deepvariant/labeler:haplotype_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/haplotype_labeler_test.py"", line 40, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:94692,error,error,94692,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:19) FAIL: //deepvariant:make_examples_test (shard 2 of 2) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log); (06:29:19) INFO: From Testing //deepvariant:make_examples_test (shard 2 of 2):; ==================== Test output for //deepvariant:make_examples_test (shard 2 of 2):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/deepvariant/make_examples_test.py"", line 48, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_exa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:97186,error,error,97186,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:19) FAIL: //deepvariant:pileup_image_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log); (06:29:19) INFO: From Testing //deepvariant:pileup_image_test:; ==================== Test output for //deepvariant:pileup_image_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/pileup_image_test.runfiles/com_google_deepvariant/deepvariant/pileup_image_test.py"", line 43, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/pileup_image_test.runfiles/com_google_deepvariant/third_party/nucleus/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:92289,error,error,92289,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) FAIL: //deepvariant/labeler:labeled_examples_to_vcf_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log); (06:29:20) INFO: From Testing //deepvariant/labeler:labeled_examples_to_vcf_test:; ==================== Test output for //deepvariant/labeler:labeled_examples_to_vcf_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf_test.runfiles/com_google_deepvariant/deepvariant/labeler/labeled_examples_to_vcf_test.py"", line 39, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_dee",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:103130,error,error,103130,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) FAIL: //deepvariant:modeling_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log); (06:29:20) INFO: From Testing //deepvariant:modeling_test:; ==================== Test output for //deepvariant:modeling_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/modeling_test.runfiles/com_google_deepvariant/deepvariant/modeling_test.py"", line 41, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:110070,error,error,110070,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) [2,519 / 2,523] 34 / 38 tests, 20 failed; Testing //deepvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:105986,error,error,105986,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:21) FAIL: //deepvariant/python:variant_calling_wrap_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log); (06:29:21) INFO: From Testing //deepvariant/python:variant_calling_wrap_test:; ==================== Test output for //deepvariant/python:variant_calling_wrap_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/python/variant_calling_wrap_test.runfiles/com_google_deepvariant/deepvariant/python/variant_calling_wrap_test.py"", line 38, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:112145,error,error,112145,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:21) FAIL: //deepvariant:postprocess_variants_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log); (06:29:21) INFO: From Testing //deepvariant:postprocess_variants_test:; ==================== Test output for //deepvariant:postprocess_variants_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants_test.runfiles/com_google_deepvariant/deepvariant/postprocess_variants_test.py"", line 46, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:114653,error,error,114653,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"low; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:21) INFO: Elapsed time: 14.901s, Critical Path: 13.35s; (06:29:21) INFO: 43 processes: 43 local.; (06:29:21) INFO: Build completed, 24 tests FAILED, 44 total actions; //deepvariant:allelecounter_test (cached) PASSED in 0.5s; //deepvariant:dv_vcf_constants_test (cached) PASSED in 1.7s; //deepvariant:exclude_contigs_test (cached) PASSED in 0.9s; //deepvariant:postprocess_variants_lib_test (cached) PASSED in 0.1s; //deepvariant:resources_test (cached) PASSED in 1.7s; //deepvariant:utils_test (cached) PASSED in 0.5s; //deepvariant:variant_calling_test (cached) PASSED in 0.6s; //deepvariant/environment_tests:env_smoke_test (cached) PASSED in 0.7s; //deepvariant/environment_tests:protobuf_implementation_test (cached) PASSED in 1.2s; //deepvariant/realigner:fast_pass_aligner_test (cached) PASSED in 0.6s; //deepvariant/realigner:ssw_test (cached) PASSED in 0.5s; //d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:116800,error,error,116800,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['error'],['error']
Availability,"ly fewer indels for the overall counts). Going back to _point 4_, running DeepVariant with both my provided .bam alignment (after combining the per-chromosome alignments) and BWA-MEM re-aligned reads both resulted in a set of ~7 million reads (which is closer to the total number reported in that other study for DeepVariant). However, if you emphasize precision, perhaps that somewhat matches my filtered set (in terms of the SNP counts and more noticeable indel differences for homozygous/heterozygous recovery). Namely, I can obtain higher percentages with my script if I use GATK HaplotypeCaller (with `--dontUseSoftClippedBases`)+VariantFiltration (similar to [shown here](https://github.com/cwarden45/DTC_Scripts/blob/master/run_GATK_VarScan.py), for Exome file, but not WGS, and I used GATK version 3.x instead of 4.x) and filter for on-target reads, as shown below:. ```; 20765 / 21141 (98.2%) full SNP recovery; 20872 / 21141 (98.7%) partial SNP recovery; 243 / 258 (94.2%) full insertion recovery; 249 / 258 (96.5%) partial insertion recovery; 208 / 228 (91.2%) full deletion recovery; 213 / 228 (93.4%) partial deletion recovery; ```. That being said, maximizing those recovery statistics does decrease the total number of variants, particularly the indels. Nevertheless, [the precisionFDA comparison for that GATK quality-fitered variant set](https://precision.fda.gov/comparisons/3441) indicates increased precision for the RefSeq CDS variants (but decreased sensitivity), compared to DeepVariant (or an [unfiltered GATK variant set](https://precision.fda.gov/comparisons/3442)). **6)** If you go back to the original precisionFDA results, I think this is also consistent with HG002:; If you go to “[explore results](https://precision.fda.gov/challenges/truth/results-explore)"", and select “**func_cds**” (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are hi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:4800,recover,recovery,4800,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,2,['recover'],['recovery']
Availability,"m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out?. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]; Sent: Thursday, April 12, 2018 3:34 PM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,; From a quick look of your error, it doesn't look like anything I've ever; encountered before. If you could potentially set up a reproducible setting; that I can very quickly run, I can see if I can try it out and tell you; what might could have gone wrong. We don't currently have a tutorial for; training, unfortunately. And to be honest, even if we do, it probably; wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is; > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for; > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:; > [64,27,1,3]; >; >; > I hate to keep bothering people about this. Is there documentation on all; > of this that I can refer to?; >; >; > Thanks,; > Brad Thomas; >; >; > From: Pi-Chuan Chang [mailto:notifications@github.com]; > Sent: Tuesday, April 10, 2018 1:04 PM; > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>; > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <; > author@noreply.github.com<mailto:author@noreply.github.com>>; > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62); >; > CAUTION: This email origi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381164890:1068,error,error,1068,,https://github.com/google/deepvariant/issues/62#issuecomment-381164890,1,['error'],['error']
Availability,"man_hs37d5/hs37d5.fa.pac; ```. However, If I run the follow bash script, it can not find `ref_idx` through `ls` command, whereas shell condition expression ` [ -f $ref_idx ]` return `true`.; here is the script:; ```shell; #!/bin/bash. dvsif=""/lustre/Data/toolsDB//deepvariant.sif""; ref_idx=""/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa"". wkdir=""/lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP""; bamdir=""${wkdir}/mappinged_bams""; logdir=""${wkdir}/logs""; vcfoutdir=""${wkdir}/DeepVariant_outputs"". source activate ~/.conda/envs/zjlEnv. echo -e ""ref_idx is $ref_idx\n""; if [ -f ""$ref_idx"" ];; then; echo -e ""ref_idx $ref_idx exists!\n""; which ls; echo -e ""ls -al --block=M ${ref_idx}*\n""; ls -al --block=M ""${ref_idx}*""; echo -e ""ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*\n""; ls -al --block=M ""/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*""; echo -e ""/bin/ls -al --block=M ${ref_idx}*\n""; /bin/ls -al --block=M ""${ref_idx}*"". else; echo -e ""Warning!! ref_idx [$ref_idx] not exist!\n""; fi. ls -al ""${ref_idx}*""; singularity run $dvsif ls $ref_idx. ```. Here is the running output:; ```shell; $ bash scripts/02_run_deepvariant.sh ; ref_idx is /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa. ref_idx /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa exists!. /usr/bin/ls; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. ls: cannot access /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*: No such file or directory; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. ls: cannot access /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*: No such file or directory; /bin/ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. /bin/ls: cannot access /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*: No such file or directory; ls: cannot access /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*: No such file or directory; INFO: Converting SIF file to temporary sandbox...; /u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1568200761:2302,echo,echo,2302,,https://github.com/google/deepvariant/issues/653#issuecomment-1568200761,1,['echo'],['echo']
Availability,md line: /bin/bash -ue .command.run; Jun-08 12:02:06.012 [Task submitter] INFO nextflow.Session - [55/335c47] Submitted process > pbc_varicall (1); Jun-08 12:07:05.943 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:12:06.012 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:06.076 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:16.724 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 1; name: pbc_varicall (1); status: COMPLETED; exit: 1; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:16.741 [Task monitor] ERROR nextflow.processor.TaskProcessor - Error executing process > 'pbc_varicall (1)'. Caused by:; Process `pbc_varicall (1)` terminated with an error exit status (1); Command executed:. run_deepvariant --model_type PACBIO --ref /data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta --reads /data/shared/clinical/LongRead/Data//m84011_220902_175841_Aln.bam --output_vcf /data/shared/clinical/LongRead/Data//Analysis/out_m84011_220902_175841_NFR_sif.vcf.gz --num_shards 40 --regions chr20. Command exit status:; 1. Command output:; I0608 12:13:28.741300,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308:4635,error,error,4635,,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308,2,['error'],['error']
Availability,"me/qilibj/inst/lib:$LD_LIBRARY_PATH; export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages; export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python; export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages; ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash; # download source code; wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz; tar -zxvf cmake-3.13.3.tar.gz; cd cmake-3.13.3. # build scirpt; ./bootstrap; make -j20; make -j20 install; export PATH=/usr/local/bin:$PATH; ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash; # download source code; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz; tar -zxvf protobuf-all-3.6.1.tar.gz; cd protobuf-3.6.1/. # clean static protobuf build; make uninstall; make distclean. # environment; export CPU=power8; export HOMEPATH=/home/qilibj; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static; make clean; make -j20; make -j20 check # check if protobuf build is good; # install; make install; sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig; #cd .. # verify; echo ""$(which protoc)""; echo ""$(protoc --version)""; ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-sour",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:1574,down,download,1574,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['down'],['download']
Availability,"ment-modules; source /etc/profile; module load at11.0; module unload at11.0; ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash; # download source code ; wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz; tar -zxvf Python-2.7.15.tgz; cd Python-2.7.15. # environment; export HOMEPATH=/home/qilibj; export CPU=power8. # check gcc before build, should be AT11.0; which gcc. # build; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static; make -j20; make install. # set environment; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin; export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH; export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15; echo ""$(python --version)"". # Pip 19.0.2; wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate; $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst; #pip install --upgrade --force-reinstall pip; echo ""$(pip --version)""; pip install setuptools nose asv cython future protobuf==3.6.1 six mock; pip install --upgrade setuptools; ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash; # download source code; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz; tar -zxvf protobuf-all-3.6.1.tar.gz; cd protobuf-3.6.1/. # clean static protobuf build; make uninstall; make distclean. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:5598,echo,echo,5598,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['echo'],['echo']
Availability,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(); https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition ; os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""); https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/104#issuecomment-429700976:74,Error,Error,74,,https://github.com/google/deepvariant/issues/104#issuecomment-429700976,1,['Error'],['Error']
Availability,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```; --regions ""chr20:10,000,000-10,010,000""; ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening?. Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/675#issuecomment-1629892175:1645,error,errors,1645,,https://github.com/google/deepvariant/issues/675#issuecomment-1629892175,2,"['avail', 'error']","['available', 'errors']"
Availability,must be specified in calling mode.; I0330 15:47:21.755398 140432560695040 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757477 140432560695040 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.770883 139863230490368 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.773075 139863230490368 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.754880 139747089467136 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.756903 139747089467136 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.754880 139944273491712 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757000 139944273491712 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.759158 140716713432832 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.761278 140716713432832 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.755259 140202003052288 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757451 140202003052288 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.765991 139705794897664 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.768276 139705794897664 errors.py:61] sample_name must be specified in calling mode.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/ref.fa --reads /input/sample.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@8.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --task 2. ```; I think the bam file is not corrected - would you please let me know which is the best suitable tool for aligning sequencing reads?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/435#issuecomment-810383024:1343,error,errors,1343,,https://github.com/google/deepvariant/issues/435#issuecomment-810383024,3,['error'],['errors']
Availability,"mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?. If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8.; ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:; ```; $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json; {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} ; ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense?. By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/568#issuecomment-1251857213:2318,error,error,2318,,https://github.com/google/deepvariant/issues/568#issuecomment-1251857213,1,['error'],['error']
Availability,"my command:; samtools faidx GRCh38_no_alt_analysis_set.fasta ""chr1:4655405-4655474""; I get this:; >chr1:4655405-4655474; CCCGCTCCCCGAAACGTGACCATGTGGATTCAACAGCTTTTAGGACTCAGGTGAGCGACC; CGGCCGGCGC. sorry it writes the above on the second fasta file I've downloaded from the WES run. ; On the current fasta file it writes:. >chr1:4655405-4655474; [faidx] Failed to fetch sequence in chr1:4655405-4655474. Could it be that the download of the fasta file sometimes fails?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/483#issuecomment-917355728:251,down,downloaded,251,,https://github.com/google/deepvariant/issues/483#issuecomment-917355728,2,['down'],"['download', 'downloaded']"
Availability,n below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:12:06.012 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:06.076 [Task monitor] DEBUG n.processor.TaskPollingMonitor - !! executor local > tasks to be completed: 1 -- submitted tasks are shown below; ~> TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:16.724 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 1; name: pbc_varicall (1); status: COMPLETED; exit: 1; error: -; workDir: /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711]; Jun-08 12:17:16.741 [Task monitor] ERROR nextflow.processor.TaskProcessor - Error executing process > 'pbc_varicall (1)'. Caused by:; Process `pbc_varicall (1)` terminated with an error exit status (1); Command executed:. run_deepvariant --model_type PACBIO --ref /data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta --reads /data/shared/clinical/LongRead/Data//m84011_220902_175841_Aln.bam --output_vcf /data/shared/clinical/LongRead/Data//Analysis/out_m84011_220902_175841_NFR_sif.vcf.gz --num_shards 40 --regions chr20. Command exit status:; 1. Command output:; I0608 12:13:28.741300 139794368661312 call_variants.py:462] Processed 100001 examples in 196 batches [0.087 sec per 100]; I0608 12:14:06.236101 139794368661312 call_variants.py:462] Processed 150001 examples in 293 batches [0.083 sec per 100]; I0608 12:14:43.829042 139794368661312 call_variants.py:462] Processed 20,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308:4897,error,error,4897,,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308,2,['error'],['error']
Availability,"n user environment for CLIF use is different from the build environment; those launchers are not correct anymore and needs to be removed/regenerated; or otherwise ""fixed"" to reflect different conditions. On Thu, May 3, 2018 at 3:17 AM Brad Chapman <notifications@github.com>; wrote:. > Pi-Chuan and Mike;; > Thanks for all this background and help. I'm trying to fit this into the; > conda recipe bazel build for DeepVariant but am not sure how to take; > advantage of using the local anaconda python in that context. The error I'm; > seeing is that bazel can't find pyclif_proto:; >; > (17:56:01) INFO: Found 1 target...; > (17:56:01) [0 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt; > (17:56:01) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'; > (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1: //third_party/nucleus/protos:variants_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'; > Target //deepvariant:binaries failed to build; > (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1 1 input file(s) do not exist; >; > which I thought was triggered by the difficulty running pyclif without; > having the local python installed. It could also be due to not installing; > is in /usr/local/bin since I have to remain sandboxed in the work; > directory, but I did adjust the PATH to include the download location.; >; > Sorry I'm stuck here due to me limited knowledge of bazel tweaking. Either; > understanding how to handle a root install of the pre-build pyclif or; > tweaking to use the local python would be helpful. Alternatively, if you; > can already build DeepVariant on a CentOS6 system yourself I could use the; > pre-build binaries the way we're doing now, just with the build against an; > older glibc. Thanks again for the help with this.; >; > —; > You are receiving this because you were",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386327937:1380,ERROR,ERROR,1380,,https://github.com/google/deepvariant/issues/29#issuecomment-386327937,1,['ERROR'],['ERROR']
Availability,"n-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.13.0 which is incompatible.; ========== [Mon 05 Jun 2023 01:42:51 AM UTC] Stage 'run-prereq.sh complete' starting; ```. For the other set of commands:; ```; > lsb_release -sc; focal; > wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - ; --2023-06-05 01:38:40-- https://apt.llvm.org/llvm-snapshot.gpg.key; Resolving apt.llvm.org (apt.llvm.org)... 146.75.46.49; Connecting to apt.llvm.org (apt.llvm.org)|146.75.46.49|:443... connected.; HTTP request sent, awaiting response... 200 OK; Length: 3145 (3.1K) [application/octet-stream]; Saving to: ‘STDOUT’. - 100%[===================>] 3.07K --.-KB/s in 0s . 2023-06-05 01:38:40 (48.1 MB/s) - written to stdout [3145/3145]. OK. > add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main""; Hit:1 https://download.docker.com/linux/ubuntu focal InRelease; Hit:2 https://download.sublimetext.com apt/stable/ InRelease; Hit:3 http://ports.ubuntu.com/ubuntu-ports focal InRelease; Hit:4 http://ports.ubuntu.com/ubuntu-ports focal-updates InRelease; Hit:5 http://ports.ubuntu.com/ubuntu-ports focal-backports InRelease; Hit:7 http://ports.ubuntu.com/ubuntu-ports focal-security InRelease; Hit:6 https://apt.llvm.org/focal llvm-toolchain-focal-11 InRelease; Reading package lists... Done ; root@m1ubuntu:/media/HostShared/deepvariant-r1.5# ; root@m1ubuntu:/media/HostShared/deepvariant-r1.5# sudo apt-get update; Hit:2 https://download.docker.com/linux/ubuntu focal InRelease ; Hit:3 https://download.sublimetext.com apt/stable/ InRelease ; Hit:4 http://ports.ubuntu.com/ubuntu-ports focal InRelease ; Hit:1 https://apt.llvm.org/focal llvm-toolchain-focal-11 InRelease ; Hit:5 http://ports.ubuntu.com/ubuntu-ports focal-updates InRelease; Hit:6 http://ports.ubuntu.com/ubuntu-ports focal-backports InRelease; Hit:7 http://ports.ubuntu.com/ubuntu-ports foca",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:10313,down,download,10313,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,2,['down'],['download']
Availability,"n: pip 22.2.2; Uninstalling pip-22.2.2:; Successfully uninstalled pip-22.2.2; WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH.; Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.; Successfully installed pip-22.2.2; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages); WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages); Python 3.8.10; pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible.; google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting; Installing Intel's CPU-only MKL TensorFlow 2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279:3767,ERROR,ERROR,3767,,https://github.com/google/deepvariant/issues/552#issuecomment-1219417279,1,['ERROR'],['ERROR']
Availability,"nalysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \; --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \; --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **I get the error:** ; ; ```; raise ValueError('The regions to call is empty. Check your --regions and '; ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa).; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed --task 0; ```. The error is quite descriptive, but I'm not sure how my file would be empty?; Thanks for all your help!; Amy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/527#issuecomment-1067792214:2701,error,error,2701,,https://github.com/google/deepvariant/issues/527#issuecomment-1067792214,1,['error'],['error']
Availability,"name registry registry:2; # docker push localhost:5000/deepvariant:0.7.0; # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0; #; # Then use that container image to make this customized one; # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment; PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin; DV_GPU_BUILD=0; export PATH DV_GPU_BUILD. %apprun download_testdata; BUCKET=""gs://deepvariant""; DATA_BUCKET=""${BUCKET}/quickstart-testdata/*""; mkdir -p input; gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples; exec /opt/deepvariant/bin/make_examples \; --mode calling \; --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \; --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \; --examples output.examples.tfrecord \; --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants; exec /opt/deepvariant/bin/call_variants \; --outfile call_variants_output.tfrecord \; --examples output.examples.tfrecord \; --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants; exec /opt/deepvariant/bin/postprocess_variants \; --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \; --infile call_variants_output.tfrecord \; --outfile output.vcf. %runscript; if [ $# -eq 0 ]; then; echo '''Example Usage:. # download data to input and models; singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs; singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models; singularity run --app call_variants deepvariant-custom.simg. # postprocess variants; singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md; '''; else; exec ""$@""; fi. %post; export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)""; echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-458208323:1780,checkpoint,checkpoint,1780,,https://github.com/google/deepvariant/issues/132#issuecomment-458208323,1,['checkpoint'],['checkpoint']
Availability,"necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: ; gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001; ```bash; docker run \; -v `pwd`:`pwd` -w `pwd` \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \; --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \; --model_type=WGS \; --ref=""input/data/${REF}"" \; --reads=""input/data/${BAM}"" \; --output_vcf=""output/${OUTPUT_VCF}"" \; --output_gvcf=""output/${OUTPUT_GVCF}"" \; --regions chr20 \; --num_shards=$(nproc) \; --intermediate_results_dir /output/intermediate_results_dir; ```. But I get the following error:; ```bash; I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main; commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles; check_flags(); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags; raise RuntimeError('The model files {}* do not exist. Potentially '; RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_sta",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874:1098,error,error,1098,,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874,2,['error'],['error']
Availability,"ng, it is likely that DeepTrio would call variants on; > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and; > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous; > variant calls in the non-PAR regions of chromosomeX.; > ; > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are; > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference; > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic.; > Since chromosomeX in males is inherited from the mother, we performed calling on; > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to; > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this; > recommends that variant calling should be run with both parents on the autosomal and PAR; > regions using a BED file to restrict location, and additional variant calling should be performed; > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and; > only the father’s provided for the non-PAR regions of chromosomeY.; > ; > This experiment indicates that allowing the model to infer a hemizygous chromosome through; > coverage and explicitly training for hemizygous variants is an opportunity for improvement,; > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/518#issuecomment-1045294025:2768,avail,available,2768,,https://github.com/google/deepvariant/issues/518#issuecomment-1045294025,2,['avail'],['available']
Availability,"nload.nvidia.com/compute/redist/cudnn/v8.2.0/${CUDNN_TAR_FILE}; # tar -xzvf ${CUDNN_TAR_FILE}; # sudo cp -P cuda/include/cudnn.h /usr/local/cuda-11/include; # sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-11/lib64/; # sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-11/lib64/; # sudo chmod a+r /usr/local/cuda-11/lib64/libcudnn*; # sudo ldconfig; # fi; # # Tensorflow says to do this.; # sudo -H apt-get install ""${APT_ARGS[@]}"" libcupti-dev > /dev/null; # fi. # # If we are doing a gpu-build, nvidia-smi should be install. Run it so we; # # can see what gpu is installed.; # nvidia-smi || :; # fi. # ################################################################################; # # TensorRT; # ################################################################################. # note_build_stage ""Install TensorRT"". # # Address the issue:; # # 'dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory'; # # It's unclear whether we need this or not. Setting up to get rid of the errors.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # pip3 install ""${PIP_ARGS[@]}"" nvidia-tensorrt; # echo ""For debugging:""; # pip3 show nvidia-tensorrt; # TENSORRT_PATH=$(python3 -c 'import tensorrt; print(tensorrt.__path__[0])'); # sudo ln -sf ""${TENSORRT_PATH}/libnvinfer.so.8"" ""${TENSORRT_PATH}/libnvinfer.so.7""; # sudo ln -sf ""${TENSORRT_PATH}/libnvinfer_plugin.so.8"" ""${TENSORRT_PATH}/libnvinfer_plugin.so.7""; # export LD_LIBRARY_PATH=""${LD_LIBRARY_PATH-}:${TENSORRT_PATH}""; # sudo ldconfig; # # Just in case this still doesn't work, we link them.; # # This is a workaround that we might want to get rid of, if we can make sure; # # setting LD_LIBRARY_PATH and `sudo ldconfig`` works.; # if [[ ! -e /usr/local/nvidia/lib ]]; then; # sudo mkdir -p /usr/local/nvidia/lib; # sudo ln -sf ""${TENSORRT_PATH}//libnvinfer.so.7"" /usr/local/nvidia/lib/libnvinfer.so.7; # sudo ln -sf ""${TENSORRT_PATH}//libnvinfer_plugin.so.7"" /usr/local/nvidia/lib/libnvinfer_plugin.so.7; # fi; # fi; ```. The ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:5172,error,errors,5172,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,2,['error'],['errors']
Availability,nproc command is not available on your machine. You may replace $(nproc) with the number of cores on your computer.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/596#issuecomment-1338619194:21,avail,available,21,,https://github.com/google/deepvariant/issues/596#issuecomment-1338619194,1,['avail'],['available']
Availability,"nproc=8; sudo docker run \; -v ""$(pwd):$(pwd)"" \; -w $(pwd) \; google/deepvariant:""${BIN_VERSION}"" \; run_deepvariant \; --model_type=WES \; --customized_model=model/model.ckpt \; --ref= Homo_sapiens.GRCh38.dna.alt.fa\; --reads=data/hg005_gm26107.mrna.grch38.bam\; --output_vcf=output/HG005.output.vcf.gz \; --num_shards=$(nproc) \; --regions=data/chr20_CDS_3x.bed\; --make_examples_extra_args=""split_skip_reads=true,channels=''"" \; --intermediate_results_dir output/intermediate_results_dir. the error ; ***** Running the command:*****; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required.; I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required.; I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required.; I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required.; I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required.; I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1303717562:1127,error,errors,1127,,https://github.com/google/deepvariant/issues/581#issuecomment-1303717562,1,['error'],['errors']
Availability,"nsor; return CheckpointReader.CheckpointReader_GetTensor(; RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore; names_to_keys = object_graph_key_mapping(save_path); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping; object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor; error_translator(e); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator; raise errors_impl.NotFoundError(None, None, error_message); tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874:13935,checkpoint,checkpoint,13935,,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874,2,['checkpoint'],['checkpoint']
Availability,"nsorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcuda.so.1: cannot open shared object file: No such file or directory. I additionally tried using docker to run the docker images (which worked for me with DeepVariant v.7.0.0, but not 9.0.0): ; `# Pull the deep variant docker image.; sregistry pull docker://gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}""; ​. # Test running docker interactively w/Singularity. ; BIN_VERSION=""0.9.0""; singularity shell --bind '/labs/jandr/walter/tb/test' /home/kwalter/.singularity/shub/deepvariant-docker-deepvariant:${BIN_VERSION}.simg;. /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz ; `; I got the same errors with this test. It seems like there is some issue with numpy/tensorflow in this most recent version of the image that makes it incompatible with running via Singularity. Any suggestions or advice would be great. Thank you in advance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/265#issuecomment-580549772:4154,error,errors,4154,,https://github.com/google/deepvariant/issues/265#issuecomment-580549772,1,['error'],['errors']
Availability,"nt; Dload Upload Total Spent Left Speed; 100 2518k 100 2518k 0 0 5403k 0 --:--:-- --:--:-- --:--:-- 5392k; Collecting pip; Using cached pip-23.1.2-py3-none-any.whl (2.1 MB); Installing collected packages: pip; Attempting uninstall: pip; Found existing installation: pip 23.1.2; Uninstalling pip-23.1.2:; Successfully uninstalled pip-23.1.2; WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH.; Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.; Successfully installed pip-23.1.2; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; Python 3.8.10; pip 23.1.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8); ========== [Mon 05 Jun 2023 10:22:17 PM EDT] Stage 'Install python3 packages' starting; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorflow-cpu-aws 2.11.0 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible.; tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.23.2 which is incompatible.; ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053:3508,ERROR,ERROR,3508,,https://github.com/google/deepvariant/issues/657#issuecomment-1577789053,1,['ERROR'],['ERROR']
