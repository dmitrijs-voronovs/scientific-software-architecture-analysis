quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Integrability,No further comments here. Looking forward to integrating this into PathSeq.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276202293:45,integrat,integrating,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276202293,1,['integrat'],['integrating']
Integrability,"No, this dependency is not from the main xgboost project, it's a 3rd-party library that allows you to make predictions using saved model files. At the time, the plan was to train models in python, then use this java tool to apply the trained predictor. The GQ filtering project trains using a java tool, so I have to bring in the real xgboost library.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1189369117:9,depend,dependency,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1189369117,1,['depend'],['dependency']
Integrability,"Not a bad idea, will look into that tomorrow. Note that you are using Tensorflow 1.4 or 1.5 and that from v1.6 even the; non-Intel optimized build supports only AVX capable machines. On Thu 11 Oct 2018, 21:07 droazen, <notifications@github.com> wrote:. > *@droazen* commented on this pull request.; > ------------------------------; >; > In; > src/main/java/org/broadinstitute/hellbender/tools/walkers/vqsr/CNNScoreVariants.java; > <https://github.com/broadinstitute/gatk/pull/5291#discussion_r224587026>:; >; > > @@ -198,6 +200,13 @@; > return new String[]{""No default architecture for tensor type:"" + tensorType.name()};; > }; > }; > +; > + IntelGKLUtils utils = new IntelGKLUtils();; > + if (utils.isAvxSupported() == false); > + {; > + return new String[]{CNNScoreVariants.AVXREQUIRED_ERROR};; >; > Maybe the answer is for the conda environments to set an extra environment; > variable that would allow GATK to detect which conda environment it's in.; > Then you could have a check in CNNScoreVariants that aborts the tool only; > if AVX is not present AND you're running in the Intel conda environment,; > and point the user to the non-Intel conda environment in the error message.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5291#discussion_r224587026>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG6lr8HM6ItLWqfSaTKeVY4yCp07il29ks5uj6TugaJpZM4XNHdi>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429109651:1178,message,message,1178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429109651,1,['message'],['message']
Integrability,"Not sure how java could cause this, but what version of java are you running. Above you said you ran it locally without submitting, but you didn't say whether or not that worked. Does it work locally for you ? When you use `lt` instead of `<`, is the error message exactly the same except for the `lt` ? (i.e., is it `A USER ERROR has occurred: Invalid argument 'lt'`)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6241#issuecomment-548891872:257,message,message,257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6241#issuecomment-548891872,1,['message'],['message']
Integrability,"Not sure if we have settled on a strategy for checking dependencies, but the issue will be relevant for our imminent python dependencies as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-339001813:55,depend,dependencies,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-339001813,2,['depend'],['dependencies']
Integrability,Note that I've already pushed `getRawKeyNames()` up into the interface as a default method.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6203#issuecomment-539412841:61,interface,interface,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6203#issuecomment-539412841,1,['interface'],['interface']
Integrability,Note that the PR build has failed twice in a row with:. ```; org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.ru,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:202,wrap,wrapper,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['wrap'],['wrapper']
Integrability,"Note that the error message says ""in the input callset"", which refers to your -V ${inputfile}. It means that for the sites in your callset that correspond with the sites in the training resources, your callset does not have any variants with FS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6715#issuecomment-663012883:20,message,message,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6715#issuecomment-663012883,1,['message'],['message']
Integrability,Note that we can't merge #4061 until we make a decision about how to handle a missing osx64 python dependency. But we could easily cherry-pick the trimming of the tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666988:99,depend,dependency,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666988,1,['depend'],['dependency']
Integrability,"Note that we could probably extract some code for reading and subsetting read counts for both DetermineGermlineContigPloidy and GermlineCNVCaller, see related issue #4004. There is also some duplication in the integration-test code, which is probably not worth cleaning up. @ldgauthier would you mind reviewing?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5307#issuecomment-430629093:210,integrat,integration-test,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5307#issuecomment-430629093,1,['integrat'],['integration-test']
Integrability,Now integration tested successfully [here](https://app.terra.bio/#workspaces/broad-firecloud-dsde/VS-415%20GVS%20Quickstart%20Default%20Extract%20Scatter/job_history/ff9d7466-79f1-4c96-a7b9-dd2354dc1c76).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7878#issuecomment-1147593213:4,integrat,integration,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7878#issuecomment-1147593213,1,['integrat'],['integration']
Integrability,"Now run with `--maxIndelSize 250`.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimV",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:278,wrap,wrapper,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543,1,['wrap'],['wrapper']
Integrability,"Now that htsjdk has support for indexed block-compressed FASTA, maybe the best approach is to add support also in GATK to allow this test resource to be smaller (and at the same time, check integration with other tools). @droazen - is there any plan to include support for bgzip FASTA in GATK soon? I can take that as a small project if you are interested, but I should plan it somehow to be sure about the rettirements in GATK to support them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5111#issuecomment-413436528:190,integrat,integration,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5111#issuecomment-413436528,1,['integrat'],['integration']
Integrability,"OK @droazen @davidbenjamin I think this is ready for review. Note that:. 1) I did not restore the optimization introduced by @davidbenjamin in #5466. Happy to file an issue to restore it later by adding the appropriate parameter check, if we think it's important.; 2) I only added integration tests for HC and M2, since there is only a minimal test for FilterAlignmentArtifacts at this time. But I would think that these tests are enough to show that the exposure preserves behavior (unless I somehow got extremely unlucky with the test data and parameter values...); 3) Apologies to the reviewer for the somewhat complicated commit history, which resulted from introducing/removing the TSV stuff and was more trouble than it might be worth to reorder/resolve in the final rebase. I think it would be easiest for the reviewer to look at the 4 ""bubbled up..."" commits separately when reviewing the exposure of each parameter set, but then look at the overall commit when reviewing more superficial things or the tests.; 4) I'd appreciate it if the reviewer double checked that I did not switch anything up in parameter names, doc strings, default values, etc. when introducing the 12 explicit args in AssemblyBasedCallerArgumentCollection. Lots of copying and pasting there and would be easy to screw things up, as you might imagine! Pretty sure the tests bear out that this was done correctly, but you never know. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-897081017:281,integrat,integration,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-897081017,1,['integrat'],['integration']
Integrability,OK! There was a transient dependency that bumped the `commons-math3` version. I've just pushed an update that should fix this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356135455:26,depend,dependency,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356135455,1,['depend'],['dependency']
Integrability,"OK, I experimented a bit with removing the R install from the base image and adding the R dependencies to the conda environment in a branch and rebased on that. A few issues that I've run into or that came up in discussion with @jamesemery and @cmnbroad:. -I moved all tests that depend on R into the `python` test group (which should perhaps be renamed to `conda`). Note that some of these also fall into the `spark` test group---not sure if there is any special Spark setup done for that group, but we should make sure that they don't fail if they're not run with the conda environment. -@cmnbroad mentioned that some Picard tools that depend on R may break outside of the conda environment if the user does not have the R dependencies. -When we install R in the base image, we pull in a lot of basic dependencies (e.g., build-essential, various libraries and compilers, etc.) So when the R install is removed, it looks like many tests begin failing or hanging, perhaps because they are falling back on Java implementations (e.g., AVX PairHMM tests). We need to determine the dependencies for these tests and install them separately. Here is the list of packages that get pulled in by the R install: ```autoconf automake autotools-dev binutils bsdmainutils build-essential; bzip2-doc cdbs cpp cpp-5 debhelper dh-strip-nondeterminism dh-translations; dpkg-dev fakeroot g++ g++-5 gcc gcc-5 gettext gettext-base gfortran; gfortran-5 groff-base ifupdown intltool intltool-debian iproute2; isc-dhcp-client isc-dhcp-common libalgorithm-diff-perl; libalgorithm-diff-xs-perl libalgorithm-merge-perl libarchive-zip-perl; libasan2 libasprintf-dev libasprintf0v5 libatm1 libatomic1; libauthen-sasl-perl libblas-common libblas-dev libblas3 libbz2-dev; libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libcroco3 libcurl3; libdns-export162 libdpkg-perl libencode-locale-perl libfakeroot; libfile-basedir-perl libfile-desktopentry-perl libfile-fcntllock-perl; libfile-listing-perl libfile-mimeinfo-perl libfile-stripnon",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:90,depend,dependencies,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,10,['depend'],"['depend', 'dependencies']"
Integrability,"OK, I think I accidentally removed the `getopt` dependency in #3935. Not sure why tests didn't fail as expected. EDIT: I think this is because R dependencies are cached on Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359983165:48,depend,dependency,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359983165,2,['depend'],"['dependencies', 'dependency']"
Integrability,"OK, I think things are looking good! Updated a bunch of things, including the following:. - conda 23.1.0 -> 23.10.0; in the base Docker, also disabled conda auto-updating and set the solver to the much faster libmamba (NOTE: before this PR went in, this change was actually made in https://github.com/broadinstitute/gatk/pull/8610); - python 3.6.10 -> 3.10.13; - pymc 3.1 -> 5.10.0; - theano 1.0.4 -> pytensor 2.18.1; - added pytorch 2.1.0; - removed tensorflow 1.15.0 and other CNN dependencies; - added libblas-dev to the base Docker; I think MKL versions of all packages are being used, but we should verify!. These and other packages (numpy, scipy, etc.) are all pretty much at the latest available versions for python 3.10. I've also bumped version numbers for our internal python packages. I also made all of the changes to the gCNV code to accommodate any changes introduced by PyMC/Pytensor. For the most part, these were minor renamings of `theano`/`tt`/etc. to `pytensor`/`pt`/etc. However, there were some more nontrivial changes, including to 1) model priors (since some of the distributions previously used were removed or are now supported differently), 2) the implementation of posterior sampling, 3) some shape/dimshuffle operations, and other things along these lines. Using a single test shard of 20 1kGP WES samples x 1000 intervals, I have verified determinism/reproducibility for DetermineGermlineContigPloidy COHORT/CASE modes, GermlineCNVCaller COHORT/CASE modes, and PostprocessGermlineCNVCalls. Numerical results are also relatively close to those from 4.4.0.0 for all identifiable call and model quantities (albeit far outside any reasonable exact-match thresholds, most likely due to differences in RNG, sampling, and the aforementioned priors). Some remaining TODOs:. - [x] Rebuild and push the base Docker. EDIT: Mostly covered by #8610, but this also includes an addition of `libblas-dev`.; - [x] Update expected results for integration tests, perhaps add any that might ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:483,depend,dependencies,483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,1,['depend'],['dependencies']
Integrability,"OK, added an integration test to check that MKL is enabled. If we move the conda install of these packages into the base image, then we might need to perform these checks elsewhere, e.g., in the bash script for building the image. Gotta push the base image and update the main Dockerfile. I'll merge after the weekend unless there are any more comments. Again, @droazen please be sure to highlight that R plotting will now require the conda environment in the release notes!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-622500992:13,integrat,integration,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-622500992,1,['integrat'],['integration']
Integrability,"OK, great that you already were aware of it! We can probably resolve it during the upcoming round of python dependency updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470998923:108,depend,dependency,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470998923,1,['depend'],['dependency']
Integrability,"OK, once the VariantEvalEngine PR is wrapped up I will tackle this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7030#issuecomment-759765629:37,wrap,wrapped,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7030#issuecomment-759765629,1,['wrap'],['wrapped']
Integrability,"OK, thanks @drifty914. Note that the file with num_intervals_per_scatter = 20 is a minimal test case that is run with our continuous integration tests. In real-world use, you want enough intervals in each shard to fit a denoising model---probably 5000 or more is safe. I am wondering if your issue is related to https://github.com/broadinstitute/gatk/issues/4782 and https://askubuntu.com/questions/162229/how-do-i-increase-the-open-files-limit-for-a-non-root-user. It may be that your user ulimit is not high enough for the theano compilation directory?. Let me try to put together a fix for that issue and see if it addresses yours as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960:133,integrat,integration,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960,1,['integrat'],['integration']
Integrability,"OK, thanks @droazen, that sounds sensible. Just pushed the rebase and will try to get to the rest of the changes this week. Just to clarify about running future evaluations/optimizations---I might need some pointers from whoever has been running the ""canonical"" evaluations (@michaelgatzen, maybe)? The ones I've run so far are on chr22 on the CHM mix, stratified in a few different ways (high/low complexity/confidence). We'll probably want to do something more thorough (e.g., akin to whatever is done for functional equivalence) to justify changing the defaults, I'm guessing. But we can cross those bridges once we get there!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-892034856:603,bridg,bridges,603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-892034856,1,['bridg'],['bridges']
Integrability,"OK. I found a potential solution. For this solution, we do not need to add or remove any dependencies. The only change is to the `log4j.properties` file (which configures log4j 1.x) to match the config specified in `log4j2.xml` (which configures log4j2). Now, GKL will use log4j 1.x to log, but the format will match the rest of GATK, which uses log4j2. This means that we have only one GKL for both GATK 3 and 4, at the expense of having to keep to config files, `log4j.properties` and `log4j2.xml`, in sync (which they probably should have been anyway, thought they weren't).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413:89,depend,dependencies,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413,1,['depend'],['dependencies']
Integrability,"OK. In GATK3, the sharding size is calculated in `GenomeAnalysisEngine.getShardStrategy`. Since `GenotypeGVCFs` is a RodWalker and does not use input reads (BAM file), the shard size is `1,000,000`. ; This might be more than a thread safety bug (which is easy to fix, by making `GenotypingEngine.calculateOutputAlleleSubset() ` `synchronized`). What worries me is If the cache of upstream deletions spans intervals, this code will not work since the processing is asynchronous. For example, if there are 2 threads and the removed deletion crosses the shard barrier and the downstream interval thread is first to process, it will not see the upstream removed deletion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2326#issuecomment-270467197:329,synchroniz,synchronized,329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2326#issuecomment-270467197,1,['synchroniz'],['synchronized']
Integrability,"Oh! thanks for the info. What I'm trying to do is to figure out which; reads are providing evidence for variants that are reported by HC. There; are some cases where I can't find the exact reads that support the variant; of interest, and I thought I might be able to get them from the HC bamout; file. This is relevant for single cell data where the individual reads; have info about cell barcodes so we can figure out which cells harbor the; variant. I'm not sure there's a good way to do this when the HC reassembly; defines the variant. On Tue, Feb 27, 2024 at 12:16 PM Gökalp Çelik ***@***.***>; wrote:. > Those HC tagged reads are artificially created by HaplotypeCaller Local; > Reassembly engine therefore there is really no connection to a direct read; > from the original bam but probably a connection to a whole bunch of; > supporting kmers and a debruijin graph that it belongs to.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1967219401>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX652DFCCCXO6KGTO4TYVYIH7AVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSNRXGIYTSNBQGE>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1967238092:1271,Message,Message,1271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1967238092,1,['Message'],['Message']
Integrability,"Oh, I just realized I also changed from copying in whole dbsnp vcf to streaming it with NIO. Could this be from uncompressing a vcf.gz file rather than the bam? If so I can easily switch back to copying in dbsnp. Although that error message leads me to believe the problem is still with the BAM.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317029371:233,message,message,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317029371,1,['message'],['message']
Integrability,"Oh, I meant we should fix the error message so it accurately tells you what's wrong.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6501#issuecomment-599610470:36,message,message,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6501#issuecomment-599610470,1,['message'],['message']
Integrability,"Oh, I missed that they had already tried reindexing. @ahaessly can you find out what tool and what version was used to reindex this file ? We've had several reports of this error message in the last month or two, but reindexing has usually fixed it. I had been assuming that the corrupt index files were created by older versions of GATK/Picard tools, but it would super helpful to know if current versions of either samtools or GATK/Picard is creating these, and will help determine if we need to relax this check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804930832:179,message,message,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804930832,1,['message'],['message']
Integrability,"Oh, I'm confused aren't I, this is just the standard out, not the actual return code. Never mind... Maybe we should clarify the output message though so people aren't confused.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6056#issuecomment-524554174:135,message,message,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6056#issuecomment-524554174,1,['message'],['message']
Integrability,"Oh, be sure to mention that you updated the base image and included dplyr in the commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6039#issuecomment-532818587:88,message,message,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6039#issuecomment-532818587,1,['message'],['message']
Integrability,"Oh, good point. Maybe we should add a GATKRProtectedRegistrator that first applies the GATKRegistrator and then does additional gatk-protected specific registrations? We'll have to add a way to inject the right one though as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272483079:194,inject,inject,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272483079,1,['inject'],['inject']
Integrability,"Oh, yes, it is surely not a typo, it was just my mental shortcut because of the previous messages. I use the local storage on our computing cluster. I will try to download the files once again, maybe it will solve the problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661896755:89,message,messages,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661896755,1,['message'],['messages']
Integrability,"Ok, I know @danxmoran also kicked off jobs trying those three options @droazen mentioned above, but I at least tried the first option and got this error message:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -Dsamjdk.use_async_io_write_samtools=false -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr5:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.pDg1Ou; [July 24, 2017 5:46:04 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr5:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-references/hg38/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824:153,message,message,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824,1,['message'],['message']
Integrability,"Ok, so I was able to run all the python tests using ~/.matplotlib/matplotlibrc. @mbabadi Wondering why you changed this to DO NOT MERGE. Do you have an alternative proposal ? Removing the libgcc-ng dependency doesn't solve the whole mac problem, but at least if we do remove it the workaround for the matplotlib part is easily conveyed. Also, @samuelklee @mbabadi, is there any visibility for end-users that they need to establish the conda env to run these tools (like in the doc summary, etc.). I'm guessing the failure mode for just running without the environment will be pretty cryptic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356111971:198,depend,dependency,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356111971,1,['depend'],['dependency']
Integrability,"Okay tranche filtering and training script are in. They're pure python right now but it would be simple to wrap them in java CLP via PythonScriptExecutor. These scripts add several dependencies which will probably make the already big docker quite a bit bigger. Long term I think we can get rid of most of them as we already have for inference, but we want to have some training functionality available by AGBT which is the week after next. Ready for a first round review @cmnbroad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008:107,wrap,wrap,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008,4,"['depend', 'wrap']","['dependencies', 'wrap']"
Integrability,"Old startup message:. ```; [January 9, 2018 6:01:50 AM EST] Executing as droazen@wmce6-e31 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14; Version: 4.beta.6-170-g9330d47-SNAPSHOT; HTSJDK Version: 2.13.2; Picard Version: 2.17.2; ```. New startup message:. ```; 07:02:34.565 INFO CountReads - ------------------------------------------------------------; 07:02:34.565 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.beta.6-172-g929250b-SNAPSHOT; 07:02:34.565 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 07:02:34.566 INFO CountReads - Executing as droazen@wmce6-e31 on Mac OS X v10.11.6 x86_64; 07:02:34.566 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_92-b14; 07:02:34.566 INFO CountReads - Start Date/Time: January 9, 2018 7:02:34 AM EST; 07:02:34.566 INFO CountReads - ------------------------------------------------------------; 07:02:34.566 INFO CountReads - ------------------------------------------------------------; 07:02:34.567 INFO CountReads - HTSJDK Version: 2.13.2; 07:02:34.567 INFO CountReads - Picard Version: 2.17.2; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4098#issuecomment-356266142:12,message,message,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4098#issuecomment-356266142,2,['message'],['message']
Integrability,"On second thought, just having a map-style interface to a `Funcotation` is probably sufficient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3919#issuecomment-358073991:43,interface,interface,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3919#issuecomment-358073991,1,['interface'],['interface']
Integrability,"One final thing: i'm happy to try to debug this, and was going to write a test case based on the existing GenomicsDB integration tests. However, when I try to run any integration test involving genomicsdb, I get an exception like the following. I am on windows, so perhaps this is the issue?. 09:03:37.460 FATAL GenomicsDBLibLoader - ; java.io.FileNotFoundException: File /tiledbgenomicsdb.dll was not found inside JAR.; 	at org.genomicsdb.GenomicsDBLibLoader.loadLibraryFromJar(GenomicsDBLibLoader.java:118) ~[genomicsdb-1.3.2.jar:?]; 	at org.genomicsdb.GenomicsDBLibLoader.loadLibrary(GenomicsDBLibLoader.java:55) [genomicsdb-1.3.2.jar:?]; 	at org.genomicsdb.GenomicsDBUtilsJni.<clinit>(GenomicsDBUtilsJni.java:30) [genomicsdb-1.3.2.jar:?]; 	at org.genomicsdb.GenomicsDBUtils.createTileDBWorkspace(GenomicsDBUtils.java:46) [genomicsdb-1.3.2.jar:?]; 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.overwriteCreateOrCheckWorkspace(GenomicsDBImport.java:1005) [classes/:?]; 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.onTraversalStart(GenomicsDBImport.java:661) [classes/:?]; 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1056) [classes/:?]",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-749138102:117,integrat,integration,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-749138102,2,['integrat'],['integration']
Integrability,"One more note: I did try to make the score/apply single pass when using the Java BGMM backend (since we can just cheaply score as we go, in contrast to using a file interface with python), but this seemed to slow down variant writing a bit more than expected and it came out as a wash with the two-pass approach. Didn’t seem worth the extra code at this point, but maybe we can get it working better in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1044868333:165,interface,interface,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1044868333,1,['interface'],['interface']
Integrability,"One note that might be useful (or known already to the team): simply calling `cache()` doesn't cause any action. It seems that one might need to force the computation to be done on the RDD (e.g. `count()`), for caching to work, if the predicate depends on the results of computation. (ref last comment in #1877)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1811#issuecomment-225204823:245,depend,depends,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1811#issuecomment-225204823,1,['depend'],['depends']
Integrability,"One observation that illustrates the need for care when optimizing metrics: for a few of the F1 optimizations, the haplotype-to-reference match-value parameter gets driven to its minimal value (1). Not 100% sure, but I'm guessing this might effectively boost precision by somehow cutting down on the complexity of proposed haplotypes---it depends on what the exact behavior of our SW algorithm is for negative scores. @davidbenjamin any thoughts on this behavior?. Something I don't quite understand yet is if we can impose some effective constraints on the parameters or otherwise reduce the number of independent dimensions. For example, it seems reasonable to me to fix the gap-extend penalties to -1 and let all other parameters be defined w.r.t. them. But perhaps we can also fix the match values similarly?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193:339,depend,depends,339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193,1,['depend'],['depends']
Integrability,"One of our goals for alpha (https://github.com/broadinstitute/gatk/issues/961) is actually to wrap `spark-submit` and its many options to make it easier to run hellbender tools on spark. We want users to be able to type a simple command like `./hellbender ToolName [toolArgs] --sparkMaster X`, and have hellbender figure out whether to invoke `spark-submit` or `gcloud dataproc` on their behalf, and provide sensible defaults for all relevant spark options. . Perhaps there is a way in `SparkCommandLineProgram` to detect whether an option has already been set externally, and allow the default to be overridden if it has been?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1070#issuecomment-152538633:94,wrap,wrap,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1070#issuecomment-152538633,1,['wrap'],['wrap']
Integrability,"Oof, looks like there are now a bunch of broken integration tests that check ExcessHet for whatever reason. So let's definitely decide on whether we want to make the switch to mid p-values before I go through those. EDIT: Actually, what’s SOP here? Do I have to go through and recalculate ExcessHet for *every single VCF/GenomicsDB in the repo*?. If we stick with the one-sided p-values now calculated here, then I guess one bonus is we’ll no longer have ExcessHet Phred scores of 3.0103 (which result from that short circuit returning a p-value of 0.5) everywhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892755997:48,integrat,integration,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892755997,1,['integrat'],['integration']
Integrability,"Oops! Of course! Sorry I didn't include that as well. Glad you were able; to get it off RefSeq. Thanks so much for looking into this for all of us. Much appreciated!. eric. On Thu, Jan 27, 2022 at 10:51 AM ldgauthier ***@***.***>; wrote:. > Never mind -- refseq to the rescue. I'm working on a patch now.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023359171>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AAPQ4JSI4TKOZNLDMPAACQDUYFSYXANCNFSM5L75WXOA>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023469845:621,Message,Message,621,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023469845,1,['Message'],['Message']
Integrability,"Oops, made a typo in the commit message and branch name...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6312#issuecomment-564682354:32,message,message,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6312#issuecomment-564682354,1,['message'],['message']
Integrability,"Oops. There is a warning already. I'd rather duplicate the arg and keep; the M2 one beta because I don't really trust anyone to read the logs.; Reasonable?. On Thu, Jun 6, 2019 at 2:20 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> It looks like when you added; > GVCF mode to Mutect2, you may have marked this arg as beta even though it's; > shared with the HaplotypeCaller. Perhaps it would be easiest for M2 and HC; > to just have separate -ERC arg declarations? Or you could remove the beta; > label from the argument itself, and have M2 emit a logger message saying; > that GVCF mode is beta when running with -ERC GVCF.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5988?email_source=notifications&email_token=ABSGC5GSQS3L5TB6DJY6ON3PZFINTA5CNFSM4HVGSSA2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXDXBKA#issuecomment-499609768>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABSGC5HXE6VEXHFCNLN2M6TPZFINTANCNFSM4HVGSSAQ>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5988#issuecomment-499960236:601,message,message,601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5988#issuecomment-499960236,1,['message'],['message']
Integrability,Opening a new ticket to fix the new error messages #2622,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-297140282:42,message,messages,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-297140282,1,['message'],['messages']
Integrability,"Opps, I've just realized that the SAM specs will use the US-ASCII encoding (https://github.com/samtools/hts-specs/pull/205) unless it is specified UTF-8. Maybe a method to retrieve the `String` with a provided charset should be added to the interface... Thoughts on that, @lbergelson? I think that it will be a good idea to include US-ASCII or whatever is the default in `ReadConstants` and specify that in the documentation...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3201#issuecomment-313631668:241,interface,interface,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3201#issuecomment-313631668,1,['interface'],['interface']
Integrability,"Our gradle script does a bunch of testing and packaging, so while build might work I think we had problems with getting all of tests to run correctly and the javadoc built right or something like that... We definitely recommend you use the wrapper. Is there a reason that the wrapper won't work for you?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444199543:240,wrap,wrapper,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444199543,2,['wrap'],['wrapper']
Integrability,"Overall, this looks fine, just a few minor comments. Two broader questions/issues:; - Does the test data exercise all of the code paths and edge cases?; - In general, putting the majority of testing in integration tests instead of unit tests is bad pattern. It have several bad consequences (1) it becomes less clear which cases are being tested (2) it's slower than just running unit tests and (3) it makes it unhelpful to (perhaps someday) move to a testing framework that only runs tests relevant to the code directly affected (because all integration tests must be run).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149599490:202,integrat,integration,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149599490,2,['integrat'],['integration']
Integrability,Passed integration test here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/be46efc1-38b9-48a8-953a-42b06581266a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8529#issuecomment-1798828249:7,integrat,integration,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8529#issuecomment-1798828249,1,['integrat'],['integration']
Integrability,Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/70870e97-4e58-4a55-8424-f78b0e26ac28).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8393#issuecomment-1613031872:8,Integrat,Integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8393#issuecomment-1613031872,1,['Integrat'],['Integration']
Integrability,Passing Lite Run [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/89e89bba-9647-4451-a6fc-934a7b72ed1e); Passing Classic Run [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9810bedb-dc9b-4a65-97e2-69497fbba516); Passing Integration Test [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/ea45667c-5c45-48a6-b654-2a7c8da362d7).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8269#issuecomment-1516398664:307,Integrat,Integration,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8269#issuecomment-1516398664,1,['Integrat'],['Integration']
Integrability,Passing integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9a1e766a-0735-49c0-86ee-ab55a57787ac),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1509736338:8,integrat,integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1509736338,1,['integrat'],['integration']
Integrability,Passing integration test here: https://job-manager.dsde-prod.broadinstitute.org/jobs/2b9f4dc6-d058-4803-a583-5ab76fbd71e8,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7919#issuecomment-1170209017:8,integrat,integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7919#issuecomment-1170209017,1,['integrat'],['integration']
Integrability,"Passing run of GvsCreateVATFromVDS [here](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20WGS%2010K%20Callset/job_history/7bb1410b-123c-4150-8a6b-f3d36234527a); Passing run of GvsCallsetStatistics [here](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20WGS%2010K%20Callset/job_history/ecc67d79-ecbf-41c6-bbee-52be83327d64); (both are on the AoU 10K - so need your PMI-OPS account to see). Integration test ran [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/b1f35d64-4406-4fef-a3af-e86703f36148) - had one failure, but it was in the cost tracking, so probably not a concern for this PR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8519#issuecomment-1721658082:424,Integrat,Integration,424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8519#issuecomment-1721658082,1,['Integrat'],['Integration']
Integrability,"Per discussion with @kgururaj, the proposal is to have GenomicsDB expose/document the existing protocol buffers already used internally, along with protobuf-based constructors for both GenomicsDBImporter and GenomicsDBFeatureReader.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3689#issuecomment-336962583:95,protocol,protocol,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3689#issuecomment-336962583,1,['protocol'],['protocol']
Integrability,"Per discussions with @fleharty, we are looking to significantly revamp the automated somatic CNV evaluations in preparation for benchmarking the TH prototype. The existing evaluations use a few unsupported/experimental tools and idiosyncratic/redundant classes (e.g., the `src/main/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedinterval` class this issue concerns), the functionality of which we can hopefully move to python-based validation code. . The aforementioned code was purposefully decoupled from supported CNV code, but since then it has been incorporated into `Funcotator` tools and `ValidateBasicSomaticShortMutations`, at least. @jonn-smith @davidbenjamin can we discuss a plan for cleaning this code up? Would it be easy to use an existing TSV/XSV class to handle the functionality needed for these tools?. @jonn-smith perhaps we should also discuss the plan for future `FuncotateSegments` development/integration with @fleharty.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526226506:937,integrat,integration,937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526226506,1,['integrat'],['integration']
Integrability,"Point taken on the squash, though I deliberately separated the copy of GATK3 integration tests using GATK3 data, since this would not get merged. It seems to make sense to keep that separate still?. i'll update examples, etc. i am honestly not that familiar updates to argument conventions for GATK4 - i'll give this a look but if you have more specifics that would help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433417437:77,integrat,integration,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-433417437,1,['integrat'],['integration']
Integrability,Prefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:7264,protocol,protocol,7264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['protocol'],['protocol']
Integrability,"Probably also a bug in the error message, because that's a really unhelpful message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2503#issuecomment-288235429:33,message,message,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2503#issuecomment-288235429,2,['message'],['message']
Integrability,"Probably this is to late to be of any help, but I had the exact same issue, down to the index it prints out as problematic. Maybe others will stumble upon this and find the issue here as I have. I found some pertinent info here:; https://gatk.broadinstitute.org/hc/en-us/community/posts/12862204385051-Is-it-feasible-to-use-the-extracted-vcf-gz-file-for-CombineGVCFs-and-GenotypeGVCFs. Though it seems like they never got around to a more useful stdout message. Anyway, I did as advised and split the chromosome sizes (because I'm working with barley, and the seq lengths are > 2^19). BUT- when I try indexing the bgzipped second ""halves"" of each chromosome with IndexFeatureFile, I get the same message again! When they're not bgzipped, however, it actually works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8747#issuecomment-2349595961:453,message,message,453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8747#issuecomment-2349595961,2,['message'],['message']
Integrability,Proposal: throw UserException with a better error message,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7246#issuecomment-836962267:50,message,message,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7246#issuecomment-836962267,1,['message'],['message']
Integrability,"Provider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:1976,depend,dependencies,1976,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['depend'],['dependencies']
Integrability,Pushed a commit that fixes the BigQueryUtilsUnitTest failure by upgrading several of our other Google dependencies. This may cause failures in other parts of our test suite -- we shall see.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1051087548:102,depend,dependencies,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1051087548,1,['depend'],['dependencies']
Integrability,R version 3.6 and compatible ggplot2 is needed. Compatible versions are listed in the gatkcondaenv.yml . ```; # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4; - r-backports=1.1.10; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2028583243:119,depend,dependencies,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2028583243,2,['depend'],['dependencies']
Integrability,"Ran some comparisons between funcotator and oncotator using the following data sources against a set of ~70 variants (see attached):; - achilles; - cancer_gene_census; - clinvar; - cosmic; - cosmic_fusion; - cosmic_tissue; - dna_repair_genes; - familial; - gencode; - gencode_xhgnc (Only Funcotator had this data source); - gencode_xrefseq; - hgnc; - oreganno; - simple_uniprot. While the details of the results were not compared between the two tools (unit tests are designed to do this comparison), the tools runtimes were captured (using the BSD `time` utility) over 10 iterations of annotating this data set (VCF->VCF). Full results set is attached, but the long and short of it is that depending on which timing you count by (real/user/system/user+system) **Funcotator is faster than Oncotator by anywhere from 8% to 57% and has not had any performance tuning.**. I have attached the timing measurements, as well as a gzip containing the inputs and the script I used to collect the timing information:. [benchmarking_funcotator_oncotator.tar.gz](https://github.com/broadinstitute/gatk/files/1601085/benchmarking_funcotator_oncotator.tar.gz); [BENCHMARK_funcotator_oncotator.xlsx](https://github.com/broadinstitute/gatk/files/1601079/BENCHMARK_funcotator_oncotator.xlsx)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3857#issuecomment-355068642:691,depend,depending,691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3857#issuecomment-355068642,1,['depend'],['depending']
Integrability,"Rationale for engine changes:; This tool opens a large number of feature files (TSVs, not VariantContexts) and iterates over them simultaneously. No querying, just a single pass through each.; Issue 1: When a feature file lives in the cloud, it takes unacceptably long (several seconds, typically) to initialize it. A few seconds doesn't seem like a long time, but when there are large numbers of feature files to open, it adds up. This is caused by a large number of codecs (mostly the vcf-processing codecs) opening and reading the first few bytes of the file in the canDecode method. To avoid this I've reversed the order in which we test each codec, checking first if it produces the correct subtype of Feature, and only then calling canDecode. If you don't know what specific subtype you need, you can just ask for any Feature by passing Feature.class. It's much faster that way.; Issue 2: Each open feature source soaks up a huge amount of memory. That's because text-based feature reading is optimized for VCFs, which can have enormously long lines. So huge buffers are allocated. The problem is compounded for cloud-based feature files for which we allocate a large cloud prefetch buffer. (Though that feature can be turned off, which helps a little.) But the biggest memory hog is the TabixReader, which always reads in the index, regardless of whether it's used or not. Tabix indices are very large. To avoid this, I've created a smaller, simpler FeatureReader subclass called a TextFeatureReader that loads the index only when necessary. The revisions allow the new tool to run using an order of magnitude less memory. Faster, too.; Issue 3: The code in FeatureDataSource that creates a FeatureReader is brittle, and tests for various subclasses. To allow use of the new TextFeatureReader, I added a FeatureReaderFactory interface that allows one to ask the codec for an appropriate FeatureReader.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1284340770:1832,interface,interface,1832,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1284340770,2,['interface'],['interface']
Integrability,Re-runs with PR feedback incorporated:. - [Integration](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%203%20samples/job_history/e8b6077d-a90a-4cc2-be0d-0a08cb98280a); - [Beta](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%203%20samples/job_history/52a3c02e-485b-4320-bb21-07931ecbe7dd),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1632980023:43,Integrat,Integration,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1632980023,1,['Integrat'],['Integration']
Integrability,Reader.query(BAMFileReader.java:612); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.query(SamReader.java:533); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.queryOverlapping(SamReader.java:405); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:125); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.<init>(SamReaderQueryingIterator.java:66); at org.broadinstitute.hellbender.engine.ReadsDataSource.prepareIteratorsForTraversal(ReadsDataSource.java:416); at org.broadinstitute.hellbender.engine.ReadsDataSource.iterator(ReadsDataSource.java:342); at org.broadinstitute.hellbender.engine.MultiIntervalLocalReadShard.iterator(MultiIntervalLocalReadShard.java:134); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.<init>(AssemblyRegionIterator.java:86); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:188); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); ```. and my command:; ```; gatk-4.1.7.0/gatk Mutect2 -force-active -R ~/hg19/gatk_bundle/ucsc.hg19.fasta \; -I bam/T.BQSR.reheader.bam --alleles xx.vcf -O gga.vcf -L total.site.bed -ip 200; ```; Maybe the bam file is broken? I have no idea how to debug with the error messages showed above.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4578#issuecomment-681608709:3035,message,messages,3035,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4578#issuecomment-681608709,1,['message'],['messages']
Integrability,Ready for you! I made it depend on the updated htsjdk (snapshot) and Travis is now happy.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-274583358:25,depend,depend,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-274583358,1,['depend'],['depend']
Integrability,"Reasonable point. When I get to my computer I'll check this out, but what about adding an explicit new method on the interface for getSimpleName (name TBD) that serves this function, with a default implementation. Then we no longer rely on the override of toString?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-766929973:117,interface,interface,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-766929973,1,['interface'],['interface']
Integrability,"Rebased and tweaked a few package versions, some of which are slightly different than those currently in the base (as is the version of R). Looks like `build-essential` is all you need in the base image for tests to not fallback on slow implementations, but we might want to double check that native dependencies are correct. Not really sure how urgent this is, and I have to admit I've lost track of the remaining ways R can break our builds. The possibility of a bad Travis cache (which I think was a common issue in the past) is now prevented by #6454, right?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-598996311:300,depend,dependencies,300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-598996311,1,['depend'],['dependencies']
Integrability,"Rebasing, squashing, and reorganizing files into new commits to prep for the PR, but here's a copy of the commit messages for posterity:; [commits-before-rebase.txt](https://github.com/broadinstitute/gatk/files/9210051/commits-before-rebase.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1198140001:113,message,messages,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1198140001,1,['message'],['messages']
Integrability,"Regarding intervals from the command line:. The column partition(s) is/are specified in the loader JSON file - the current functionality allows the user to not have to determine the list of contigs that overlap with a given column partition. All he/she needs to do is specify which column partition is being written to. We are ok with accepting contig intervals from the command line - in that case, it's the user's responsibility to ensure that the contig intervals are correct for the specific column partition being written to and are in the correct order. Regarding the other JSON input file, [this wiki section](https://github.com/Intel-HLS/GenomicsDB/wiki/Java-interface-for-importing-VCF-CSV-files-into-TileDB-GenomicsDB#mode-2-java-api-for-importing-variantcontext-objects) explains the why and what. This goes back to our discussions of meta-data and names. As Kushal mentioned, we can explain in more detail next week.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277348689:667,interface,interface-for-importing-VCF-CSV-files-into-TileDB-GenomicsDB,667,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277348689,1,['interface'],['interface-for-importing-VCF-CSV-files-into-TileDB-GenomicsDB']
Integrability,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:25,integrat,integration,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441,4,"['depend', 'integrat']","['dependency', 'integration']"
Integrability,"Regarding writing the SAM file, I now remember why it was created instead of using existing ones: the SV pipeline needs to be able to write to HDFS, hence cannot rely on a `File` interface&mdash;which the `ReadUtils.createCommonSAMWriter(...)` exposes. ; So the current hand rolled version in `SVFileUtils.getSAMFileWriter()` calls into `BucketUtils.createFile(...)` for that HDFS compatibility, and then makes use of the `SAMFileWriterFactory.makeBAMWriter(final SAMFileHeader header, final boolean presorted, final OutputStream stream)`, unlike `ReadUtils.createCommonSAMWriter(...)` which calls into `SAMFileWriterFactory.makeSAMOrBAMWriter(final SAMFileHeader header, final boolean presorted, final Path outputPath)`. So in short: HDFS compatibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3674#issuecomment-339391912:179,interface,interface,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3674#issuecomment-339391912,1,['interface'],['interface']
Integrability,"Reopening since even though this change fixed the immediate problem and the last cron job appears to have succeeded, its still generating 22497 ""backtrace"" messages, which is about 22400 more than I see when running the task standalone. Minimally we need to change Barclay to suppress the ""backtrace"" message that is specific to Throwable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3710#issuecomment-338205550:156,message,messages,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3710#issuecomment-338205550,2,['message'],"['message', 'messages']"
Integrability,"Responded to most of the review, but still need to add a proper integration test and fix up the pipeline test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4800#issuecomment-393337753:64,integrat,integration,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4800#issuecomment-393337753,1,['integrat'],['integration']
Integrability,Runs with @danking 's changes to import_gvs.py included:; - creation of Avro files https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/5a16077c-1981-4cc7-85f6-8462c4a9a99a; - creation of VDS using those files: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/dd699836-c9e1-4a4b-a39f-201871686bb4; - quickstart integration test run: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/0691d981-cbf3-4150-8128-58f2ce81895c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8673#issuecomment-1930637107:387,integrat,integration,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8673#issuecomment-1930637107,1,['integrat'],['integration']
Integrability,"SV tools confirmed running. With the following new error messages for all Spark tools that I've run. ```; 02:03:27.962 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.BUFFER_SIZE : 131072; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.COMPRESSION_LEVEL : 1; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.CREATE_INDEX : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.CREATE_MD5 : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.CUSTOM_READER_FACTORY :; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.REFERENCE_FASTA : null; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_CRAM_REF_DOWNLOAD : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Deflater IntelDeflater; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Inflater IntelInflater; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Initializing engine; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4769b07b] whereas object of type; log4j:ERROR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296871363:57,message,messages,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296871363,1,['message'],['messages']
Integrability,"ScoreVariantAnnotations:. Scores variant calls in a VCF file based on site-level annotations using a previously trained model. TODOs:. - [x] Integration tests. Exact-match tests for (non-exhaustive) configurations given by the Cartesian product of the following options:; * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); * non-allele-specific vs. allele-specific; * SNP-only vs. SNP+INDEL (for both of these options, we use trained models that contain both SNP and INDEL scorers as input) ; - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Double check or add behavior for handling previously filtered input, clearing present filters, etc. Future work:. - [ ] The `score_samples` method of the sklearn IsolationForest is single-threaded. See (possibly stalled) PR at https://github.com/scikit-learn/scikit-learn/pull/14001 and some workarounds using e.g. `multiprocessing` ibid.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563:141,Integrat,Integration,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563,1,['Integrat'],['Integration']
Integrability,"See latest comments in #4250. Not sure if using conda to manage R dependencies will affect the size of the image, any idea @jamesemery?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406068437:66,depend,dependencies,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406068437,1,['depend'],['dependencies']
Integrability,"See the ScatterIntervals and related tasks in the gCNV WDLs at the link above. The idea is to performs multiple runs of gCNV in shards of >10,000 intervals each across the exome. These shards can be specified by passing the set of intervals for each shard via the -L argument to GermlineCNVCaller. The gCNV model is independently fit in each shard, using the global depth and contig-level ploidy parameters determined across the whole exome in the DetermineGermlineContigPloidy step. The shards are then stitched together in the PostprocessGermlineCNVCalls step. I believe we typically run shards of 10,000 intervals for cohorts of 100-200 samples using n1-standard-8 machines, which have 30GB of memory (although looking at some recent runs, I think we've used as few as 5,000 intervals per shard). I think as few as several tens of samples could be sufficient to train a batch, but 100-200 is preferable---of course, this will depend on the specifics of your particular data set.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-407750916:929,depend,depend,929,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-407750916,1,['depend'],['depend']
Integrability,"Seems like a philosophical question. Do we want to include explicit dependencies on everything we directly depend on, or are we ok depending directly on something else's transitive dependencies. I think it's probably better to explicitly specify our direct dependencies in most cases. (I.e. I wouldn't leave out htsjdk just because we depend on hadoop-bam.) . In this case ml-lib is so closely tied to spark that it's reasonable to argue that it is specifying spark as a direct dependency. Are there any spark components that are not transitive dependencies of mllib?. I don't feel strongly about this either way. I think I'd lean towards keeping it, but I'm fine if you prefer to save the lines of code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2035#issuecomment-235058793:68,depend,dependencies,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2035#issuecomment-235058793,8,['depend'],"['depend', 'dependencies', 'dependency', 'depending']"
Integrability,"Seems still failing, what about multiple tries. ```r; dependencies = c(""naturalsort"",""ggplot2"",""gplots"",""reshape"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"", ; ""https://cran.mtu.edu"", ; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try]); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809:54,depend,dependencies,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809,4,['depend'],['dependencies']
Integrability,"Similar discussion [here](https://github.com/Microsoft/CNTK/issues/2908; ) indicates it might be an incompatibility between an old version of mkl-dnn and certain processors. I'm not sure we use mkl-dnn, but there may be some similar issue in one of our dependent libraries. We should check if there is a specific processor type that this is happening on.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6307#issuecomment-566213070:253,depend,dependent,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6307#issuecomment-566213070,1,['depend'],['dependent']
Integrability,"Since Geraldine is away till the end of the week, and we are under the Nov 23 deadline for review, I will proceed with changes. I think it useful for me to go through the motions and see what other discussion items turn up. Notes on factors I think are of interest to users re annotators:; - cohort vs sample level annotation; - InfoFieldAnnotation; - GenotypeAnnotation; - minimum number of samples, e.g. 10 for inbreedingcoefficient; - standard annotations for each tool (HC, M2 and VariantAnnotator), standard allele-specific annotations.; - StandardMutectAnnotation; - PerAlleleAnnotation; - StandardAnnotation (extends Annotation); - StandardHCAnnotation; - VariantAnnotation; - noticing `public class` vs `public final class`. Not annotating `abstract` class nor `public interface`.; - What is a reducible annotation?; - I would really find helpful the acronym for the annotation, e.g. MBQ, be listed with the annotation summary, e.g. Median base quality of bases supporting each allele.; - Annotations that are specific to a tool. E.g. DepthPerSampleHC can only be used by HaplotypeCaller and not VariantAnnotator. Doc doesn't say anything about Mutect2. ; - Not sure what VariantOverlapAnnotator does ~~but went ahead and summarized as ""Annotate ID field and attribute overlap FLAG"".~~ `did not tag`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344427246:777,interface,interface,777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344427246,1,['interface'],['interface']
Integrability,"Since Valentin's PR recently got merged, I'll try to take a look at this soon-ish. I agree with what Louis said in the PR review: LinkedHashMap all the things. Beyond that, what do you recommend @cmnbroad ? Javadoc? I feel like there used to be a Google library we used to annotate methods with contracts. It's not immediately obvious to me how to enforce this, but I'm pretty rusty on the details.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7586#issuecomment-1081861353:295,contract,contracts,295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7586#issuecomment-1081861353,1,['contract'],['contracts']
Integrability,"Since the VCF in question is malformed, the task here becomes ""make IndexFeatureFile throw a more informative error message when the file being indexed is malformed""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4184#issuecomment-358353490:116,message,message,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4184#issuecomment-358353490,1,['message'],['message']
Integrability,"Since the code isn't reviewed yet I took the liberty of adding one much push with a single change: adding a ""synchronized"" to protect against a potential data race in `SeekableByteChannelPrefetcher`. The contract for `ReadableByteChannel` (which this implements) requires `read` to be thread-safe. I don't know whether this was the cause of #2516. I haven't been able to reproduce it since, but then again even before this change it wasn't easy to trigger.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-290811886:109,synchroniz,synchronized,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-290811886,2,"['contract', 'synchroniz']","['contract', 'synchronized']"
Integrability,Since the problem disappear depending on the content of the VCF I suspect that the error message is actually misleading.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290234626:28,depend,depending,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290234626,2,"['depend', 'message']","['depending', 'message']"
Integrability,"So a couple of questions:; * Should an external developer always install the R dependencies before running `./gradlew clean test`?; * If the R dependencies are needed for testing and the rest of the code, may be worthy to install them if not present in the gradle script or should be specified that the dependencies are missing... Is there an easy way to do that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-338997058:79,depend,dependencies,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-338997058,3,['depend'],['dependencies']
Integrability,"So most of the jobs are still failing with: `The job exceeded the maximum log length, and has been terminated.` @cmnbroad @droazen What log is travis referring to? In the Travis `Job log` tab I only see < 3000 lines and other tests routinely output way more than that and pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-431840225:232,rout,routinely,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-431840225,1,['rout'],['routinely']
Integrability,So that message gets printed at the time of the stack trace. It doesn't actually mean that the program completed successfully. We may want to change that...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300259836:8,message,message,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300259836,1,['message'],['message']
Integrability,"So the long term timeline is fairly up in the air. You can check out the alpha and beta milestones for some idea of what's been prioritized. Alpha milestone is due for completion ~this week. Beta is much more up in the air and will depend at least in part on feedback from user. . Incidentally, if you're interested in CNV calling take a look at https://github.com/broadinstitute/gatk-protected/ which has some tools for CNV calling built on this engine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1198#issuecomment-160717606:232,depend,depend,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1198#issuecomment-160717606,1,['depend'],['depend']
Integrability,So... the reservoir downsampler seems to be sensitive to the state of the random number generator. Since several tests depend on the same expected output file I keep having failures. I'm resetting the seed for each test now to see if that will work.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303:119,depend,depend,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303,1,['depend'],['depend']
Integrability,Some Stan developments to be aware of:. http://andrewgelman.com/2017/06/16/stan-weekly-roundup-16-june-2017/; http://andrewgelman.com/2017/06/16/speed-parallelizing-stan-using-message-passing-interface-mpi/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2746#issuecomment-311062174:176,message,message-passing-interface-mpi,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2746#issuecomment-311062174,2,['message'],['message-passing-interface-mpi']
Integrability,"Some comments/questions for the review:; - I'll add a separate ticket to rewrite the integration tests, all of which pass and most of which are disabled since they require access to large files on the broad file system. In the meantime I need to add a couple of small tests to get the coverage back up, and would like to get the CR process started.; - I ported a bunch of support files but need feedback on whether they're in the right location.; - Somewhere I saw something that said GATK no longer supports .ped files ? If not, what should the replacement be in the tests require pedigree input?; - Is it a requirement to support Ploidy > 2 ? The current GATK tool, and thus the HB tool, do not; - I did not port the WalkerTestSpec.disableShadowVCF? Is that needed in Hellbender ?; - Are there other headers I should be applying to the output variant file ?. Command Line Arguments:; - I didn't port the GATK command line argument ""-no_cmd_line_in_header"". Should I ? And if not, should the command line args automatically be propagated to the output vcf file ? I didn't see GATK do this anywhere.; - There was one test that used --variant:dbsnp on the command line but I couldn't find the code that processed that in GATK, not sure what the means on the command line.; - I replaced ""-U LENIENT_VCF_PROCESSING"" with ""--lenient"" (testFileWithoutInfoLineInHeaderWithOverride needs this to pass).; - I replaced ""-L"" with --interval since HB seems to use -L for ""lane"" ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027:85,integrat,integration,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027,1,['integrat'],['integration']
Integrability,"Some offline discussions have led us to the conclusion that this is best handled by tools upstream. Adapters should not be simply soft-clipped, so it shouldn't be the responsibility of M2 or HC to include logic to remove adapters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6346#issuecomment-575334816:100,Adapter,Adapters,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6346#issuecomment-575334816,3,"['Adapter', 'adapter']","['Adapters', 'adapters']"
Integrability,Sorry I missed the test case. I updated the header of the test case so the pull request passes the integration tests. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072:99,integrat,integration,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072,1,['integrat'],['integration']
Integrability,"Sorry, I wasn't very clear: Spark doesn't return the user exception to the driver even as the 'cause' exception (only the exception message is preserved). So it won't be possible to do the unwrapping in the same way at the moment. I agree that #551 will help catch regressions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/574#issuecomment-113196502:132,message,message,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/574#issuecomment-113196502,1,['message'],['message']
Integrability,"Sorry, just saw your messages in the other thread. I will happily remove these.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8258#issuecomment-1480217668:21,message,messages,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8258#issuecomment-1480217668,1,['message'],['messages']
Integrability,"Sorry. I get your thinking, but I think it would be cleaner to pass the param to each of those two classes. It cleans up the dependency tree -- those two classes don't depend on any of the ReadMetadata state but for that one param -- and avoids having to have the SVReadFilter be both Java and Kryo serializable. I'd prefer it, but won't insist upon it.; Adding the filter values to the read metadata output file makes sense, though. Doesn't need to be done now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-324467678:125,depend,dependency,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-324467678,2,['depend'],"['depend', 'dependency']"
Integrability,"SortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:12 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:41:31 INFO TaskSetManager: Starting task 0.2 in stage 2.0 (TID 7, xx.xx.xx.24, executor 1, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:41:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:44322 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:41:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.24:44322 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:41:53 WARN TaskSetManager: Lost task 0.2 in stage 2.0 (TID 7, xx.xx.xx.24, executor 1): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:29642,Wrap,WrappedArray,29642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,"SortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:34 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:41:53 INFO TaskSetManager: Starting task 0.3 in stage 2.0 (TID 8, xx.xx.xx.xx, executor 3, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:41:53 INFO TaskSetManager: Lost task 1.1 in stage 2.0 (TID 6) on xx.xx.xx.24, executor 1: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 02:34 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:41:53 INFO TaskSetManager: Starting task 1.2 in stage 2.0 (TID 9, xx.xx.xx.25, executor 6, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:41:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.xx:45142 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:42:02 INFO TaskSetManager: Lost task 0.3 in stage 2.0 (TID 8) on xx.xx.xx.xx, executor 3: org.broadinst",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:32341,Wrap,WrappedArray,32341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,"Sounds good! After I get this current version of the pipeline released,; I'll explore this further. Maybe we could follow-up on slack, or meet up; at Broad at some point if you're on-site. many thanks!. Brian. On Thu, Feb 29, 2024 at 9:32 AM Gökalp Çelik ***@***.***>; wrote:. > For that purpose I would still suggest using Sample Name IDs and Read; > Group IDs along with Mutect2 to call variants therefore contribution of; > each cell to a mutation will be quantified in terms of Allele Fractions.; > Especially if you also disable downsampling it will be quite the data to; > analyze.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971271149>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX37ASEZBUTV2HCSR4TYV45W5AVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSNZRGI3TCMJUHE>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971281473:966,Message,Message,966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971281473,1,['Message'],['Message']
Integrability,"Sounds like you're asking about merging GenomicsDBs with different samples, as a different route to do incremental import. (as opposed to merging different workspaces with the same samples, but different genomic intervals). No, this is not supported.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6629#issuecomment-637021751:91,rout,route,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6629#issuecomment-637021751,1,['rout'],['route']
Integrability,State$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.fillCache(PushToPullIterator.java:71); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.advanceToNextElement(PushToPullIterator.java:58); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.<init>(PushToPullIterator.java:37); 	at org.broadinstitute.hellbender.utils.variant.writers.GVCFBlockCombiningIterator.<init>(GVCFBlockCombiningIterator.java:14); 	at org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSink.lambda$writeVariantsSingle$516343c4$1(VariantsSparkSink.java:127); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRD,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994:2191,Wrap,WrappingSpliterator,2191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994,1,['Wrap'],['WrappingSpliterator']
Integrability,Successful Integration Test Run [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/9ab365ff-743b-4d97-9c2a-6a09cf8728f4) - But note that the Exome Integration test failed for slight (and expected) difference in table sizes. I have updated the truth in gs://gvs-internal-quickstart/integration/2023-07-25-quicker/exome_weighted/table_sizes_expected.csv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1739742037:11,Integrat,Integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1739742037,3,"['Integrat', 'integrat']","['Integration', 'integration']"
Integrability,Successful Joint Calling workflow (Exome) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Beta%20Test%20ggrant/job_history/0ff13881-727f-4fdf-bde7-904559eac58f).; Successful Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/5a35adca-9f75-467c-8441-53f922ab8a7d).; A more recent integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/e0a281c5-c412-4d27-a08d-cbd169f74a1c) (two failures on slight cost differences),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8515#issuecomment-1710547302:189,Integrat,Integration,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8515#issuecomment-1710547302,2,"['Integrat', 'integrat']","['Integration', 'integration']"
Integrability,Successful Quickstart Integration here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/a7705dcb-0a9e-4667-ba88-6553ecd9cbd3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8173#issuecomment-1403754046:22,Integrat,Integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8173#issuecomment-1403754046,1,['Integrat'],['Integration']
Integrability,"Successful integration run added to the PR, and the docker images were also updated",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1729641138:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1729641138,1,['integrat'],['integration']
Integrability,Successful integration test [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/2065c1e2-c7f3-47b8-8f20-306ba24ad09f),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8345#issuecomment-1568210916:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8345#issuecomment-1568210916,1,['integrat'],['integration']
Integrability,"Sync uses the system call fsync() to synchronize contents and not sure how CIFS is erroring out. Please see my [previous comment](https://github.com/broadinstitute/gatk/issues/5342#issuecomment-433760934). Would it be possible to gather some more information using the gatk from [branch nalini_issue_5342](https://github.com/broadinstitute/gatk/tree/nalini_issue_5342)? This branch puts out additional information with errno, etc. One thing that can be done, is make an error return from the fsync() call non-fatal as it does not seem to be well supported for CIFS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453695003:37,synchroniz,synchronize,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453695003,1,['synchroniz'],['synchronize']
Integrability,"TGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:2073,wrap,wrapAndCopyInto,2073,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828,1,['wrap'],['wrapAndCopyInto']
Integrability,"Testing branch `ck_3487_port_LeftAlignAndTrimVariants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:333,wrap,wrapper,333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494,1,['wrap'],['wrapper']
Integrability,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:265,wrap,wrapper,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,1,['wrap'],['wrapper']
Integrability,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:129,depend,dependencies,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367,4,['depend'],['dependencies']
Integrability,"Thank you @SHuang-Broad. The error was gone after I copied bwaindeximage file to lustre file system, which can be accessed by all worker nodes.; The new problem is: the program started but didn't give any informative message/progress (see log below). It was stopped (Ctl-C) after 16 hours. The sequence data is regular human exome, which could be mapped in 1-2 hours in our traditional pipeline. ```; ../gatk/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; -I hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam ; -O hdfs://ln16/user/myname/gatk4test/BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /TEST/hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=720 ; --executor-cores 20 ; --executor-memory 50g ; --conf spark.driver.memory=50g; Using GATK jar /home/myname/gatk4/gatk/build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar; Running:; /opt/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --master spark://ln16:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOption; s=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.di$able=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --conf spark.cores.max=720 --executor-cores 20 --executor-memory 50g --conf spark.driver.memory=50g /home/myname/gatk4/gatk$build/libs/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:217,message,message,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['message'],['message']
Integrability,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:310,message,messages,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504,3,"['message', 'wrap']","['message', 'messages', 'wrap']"
Integrability,Thank you @lbergelson for the fix! For once a dependency conflict that turns out to be simple!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-841279259:46,depend,dependency,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-841279259,2,['depend'],['dependency']
Integrability,"Thank you @mehrzads for your contribution. It would appear that this optimization is aimed to incorporate the knowledge that we could never possibly visit a given vertex more than K times in the first K best paths. Since the graphs are prone to exponential expansion of paths this seems like an important safeguard against this exponential expansion of the graph. . Looking at the code and the algorithm behavior it is intending to copy I see that there is a degenerate case in the current code that can cause the results to be order dependent. My belief is that this code can fall over by virtue of the fact that we refuse to make new incoming edges to a given vertex if there are already too many incoming edges for that vertex. Unfortunately this heuristic doesn't strike me as being valid, because those incoming edges can have any weight, including very high weights because they are bad paths through the graph that we created at a previous step. . I think a more correct optimization would be to limit the number of edges we create LEAVING a given vertex. The logic for this is that while we may not necessarily see all of the incoming edges in the correct weight order we will necessarily see all of the leaving edges in the correct order because those paths are pulled off of the priority queue in the correct order. Thus we can safely ignore any additional paths we see leaving a given edge because by construction as they would necessarily have at least one path that is cheaper than all of the paths leaving the current node.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417:534,depend,dependent,534,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417,1,['depend'],['dependent']
Integrability,"Thank you @mwalker174 . The input bamfile is about 7 GB. If no `--bamPartitionSize` is specified, the job would stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:276,interface,interface,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['interface'],['interface']
Integrability,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:368,interface,interface,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160,2,['interface'],['interface']
Integrability,"Thank you for fast reply. @python from the same shell where you activated the conda env, and see if the command import gatktool succeeds. Yes, this works well. but when I run the command below and submit the job to HPC ;. conda activate gatk4 ; gatk CNNScoreVariants -V 21002.HaplotypeCaller.output.g.vcf.gz -R hg19.fa -O annotated.vcf. same error happened. another point is that when I run the command (gatk CNNScoreVariants -V 21002.HaplotypeCaller.output.g.vcf.gz -R hg19.fa -O annotated.vcf) without HPC by setting memory as qlogin -l s_vmem=16G -l mem_req=16G. it produces this:. Runtime.totalMemory()=2132803584; org.broadinstitute.hellbender.exceptions.GATKException: Exception waiting for ack from Python: org.broadinstitute.hellbender.exceptions.GATKException: Expected message of length 3 but only found 0 bytes; 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.waitForAck(StreamingProcessController.java:233); 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.waitForAck(StreamingPythonScriptExecutor.java:216); 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.waitForPreviousBatchCompletion(StreamingPythonScriptExecutor.java:293); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.sendBatchIfReady(CNNScoreVariants.java:416); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.firstPassApply(CNNScoreVariants.java:336); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemain",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147:779,message,message,779,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147,1,['message'],['message']
Integrability,"Thank you for the information information. That hardware seems pretty; standard. I wouldn't expect it to be causing this issue. On Wed, Jan 5, 2022, 7:08 PM greekkey ***@***.***> wrote:. > @lbergelson <https://github.com/lbergelson> OK. I will try the new; > version with my previous data as well as some new data later.; >; > My OS is Ubuntu 20.04.3 LTS 64-bit, GNOME version is 3.36.8. The major; > hardware info are Intel® Core™ i7-4770 CPU @ 3.40GHz × 8 , Intel® HD; > Graphics 4600 (HSW GT2), (memory) 31.3 GiB, (local HDD) 1.1 TB.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1006176609>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABD3RLBDEWS2JXL6P7G3YSDUUTMRJANCNFSM5KNXHR6A>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.; >; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1006183455:1182,Message,Message,1182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1006183455,1,['Message'],['Message']
Integrability,"Thank you for your review, @vruano ! I addressed each of your comments. In the process, I discovered a bug in an integration test that needed fixing, which is added as another commit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772:113,integrat,integration,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772,1,['integrat'],['integration']
Integrability,Thank you very much！------------------&nbsp;原始邮件&nbsp;------------------; 发件人:&nbsp;&quot;Louis&amp;nbsp;Bergelson&quot;<notifications@github.com&gt;; 发送时间:&nbsp;2020年8月28日(星期五) 凌晨2:26; 收件人:&nbsp;&quot;broadinstitute/gatk&quot;<gatk@noreply.github.com&gt;;; 抄送:&nbsp;&quot;duanshumeng&quot;<2315440517@qq.com&gt;;&quot;Mention&quot;<mention@noreply.github.com&gt;;; 主题:&nbsp;Re: [broadinstitute/gatk] MESSAGE: Writing failed because there is no space left on the disk or hard drive. Please make some space or specify a different location for writing output files (#6772),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6772#issuecomment-683239624:401,MESSAGE,MESSAGE,401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6772#issuecomment-683239624,1,['MESSAGE'],['MESSAGE']
Integrability,"Thank you, sir. In fact , firstly I called SNP from both parents respectively, and then combined both parents vcf files to a integrate vcf file, I want to get maternal different homozygous SNP compare to reference genome and paternal different homozygous SNP compare to reference genome, and combined both parents SNPs to a integrate biSNP.vcf file ,and then filtered heterozygote sites. Finally I submited this integrate biSNP.vcf as a input file of argument ""sites"" of GATK-3.8 ASEReaderCounter, l got normal output file of ASE reads count. But if I used argument ""variants"" of GATK-4.0 to replace ""sites"" argument of GATK-3.8, other files were not changed, it reminded me that ""the SNP site of inupt file is not het"" , so I got null result file in the end,because l filtered integrate vcf file, all SNP sites of different parents are homozygote compare to reference genome. So l want to know what kind of vcf file can be used as input file of ""variants"" argument of GATK-4.0 ASEReadCounter ? both parents g.vcf files ? Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7747#issuecomment-1084770372:125,integrat,integrate,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7747#issuecomment-1084770372,4,['integrat'],['integrate']
Integrability,"Thanks @cmnbroad - I just propose a super-fine grained scheme, but it can be a different one. I would like that for easier development using GATK4 for downstream projects, but by now I am fine with all dependencies generating quite a big jar, but I can live with it until this happen...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3900#issuecomment-348965479:202,depend,dependencies,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900#issuecomment-348965479,1,['depend'],['dependencies']
Integrability,"Thanks @davidbenjamin. . For what it is worth, here are some of my thoughts. From my perspective, it might helpful to separate the discussion into read likelihood calculation and the genotype likelihood calculation. As I understand it, sequencing error is directly relevant to the pairHMM read likelihood calculation. I guess the location where PCR error is most relevant (read likelihood vs genotype likelihood) would depend on whether the read likelihood is computing a ""fragment likelihood"" (the likely DNA sequence of the fragment being sequenced) or a ""haplotype likelihood"" (the likely source haplotype for the fragment being sequenced). In any case, as I see it, this particular issue could be interpreted as a shortcoming in only the HaplotypeCaller genotype likelihood calculation, and it would essentially be an issue of double counting. So I'm not sure that a quick fix for this issue is necessarily off the table...Maybe something like one of the following could be used just before or during the genotype likelihood calculation:; - something like `filterOverlappingReads` from Mutect2 (https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java#L326); - separate consideration of overlapping reads when calculating genotype likelihoods, as used in UnifiedGenotyper (https://github.com/broadgsa/gatk-protected/blob/aa8764d6c3de146856b174a8674fa787a6311d7c/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/genotyper/DiploidSNPGenotypeLikelihoods.java#L183). As I see it, #4958, which seems to be more related to read likelihood calculation, is where a more involved solution, with more fundamental changes, might be warranted. From my perspective (not being especially familiar with the pairHMM model), an ideal solution would transition the pairHMM from read likelihood to a ""fragment likelihood"" or ""haplotype likelihood"" when information from read pairs is available,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-443558420:419,depend,depend,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-443558420,1,['depend'],['depend']
Integrability,"Thanks @droazen & @ldgauthier. I can certainly run a bunch more iterations of the same HC run on the same data. I'm not super hopeful it will turn anything up though. I can also try selecting a bunch of the different PairHMM implementations. I can't share too much, but this issue turned up in a very high throughput (1000s of samples a day) clinical pipeline. We're going back and looking for other instances where we see an excess of that `Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null` message, and re-running those samples to see if, on re-run, they generate different outputs. I realize the AVX-specific hardware issue is perhaps a little far-fetched, though given the volume of the pipeline and the fact that it runs in a cloud environment, I think it's entirely reasonable to suspect we'll run into hardware/instance issues occasionally. And there are AVX or at least SIMD specific registers, so if one of those were to see problems that could cause the PairHMM issues, without causing issues in other software that doesn't leverage the SIMD/AVX instructions. My main question really is this: is anyone familiar enough with the Intel PairHMM implementation and interface that they could weigh in on whether or not unexpected hardware errors could result in the return of empty likelihoods from the PairHMM instead of some kind of error, exception or segfault?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6889#issuecomment-709555915:532,message,message,532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889#issuecomment-709555915,2,"['interface', 'message']","['interface', 'message']"
Integrability,"Thanks @droazen,; Additionally the dockstore integration App will need to be added this repo (as mentioned [here](https://docs.dockstore.org/en/develop/getting-started/dockstore-workflows.html#registration-with-github-apps)). . For example: ; ![Screen Shot 2020-10-14 at 11 11 04](https://user-images.githubusercontent.com/14318238/96010590-f6a15a80-0e0f-11eb-80e2-68568c18d8df.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6770#issuecomment-708478858:45,integrat,integration,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6770#issuecomment-708478858,1,['integrat'],['integration']
Integrability,"Thanks @droazen. Because you assigned it to me, I would like to know a couple of details on how this should be implemented in GATK4:. * GATK3 use to have a the `MisencodedBaseQualityReadTransformer` always on, with a switch for checking/fixing the qualities. If we follow this approach in GATK, the only change for this is to include the checking step every n reads and then #2160 will do the rest. Nevertheles, I think that it's quite dangerous to allow an user to disable it with the plugin (because the name suggest that it is only fixing the qualities), so I suggest to integrate in the read data source an iterator for checking every x reads if the qualities are misencoded, independently on the transformer.; * GATK3 throws an UserException for ""putatively misencoded"" qualities, using 60 as maximum base quality for throwing. I think that in the case of GATK4 could be more useful to use a warning if it is over 60 (I do not know what is the reasoning behind this value), and use `SAMUtils.MAX_PHRED_SCORE` for throwing. I'd be happy to implement this if there is a consensus about what to do here, so I'll wait for your ideas...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2082#issuecomment-288760814:574,integrat,integrate,574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2082#issuecomment-288760814,1,['integrat'],['integrate']
Integrability,"Thanks @kdatta. The branch builds now, but there are a couple of problems that cause several tests to fail, including some existing tests that used to pass. You can see the results [here](https://travis-ci.org/broadinstitute/gatk/jobs/221534229). - The main issue is that GenomicsDB fails to load. This causes the importer tests to fail, as well as the existing GenomicsDB integration tests. (Note that the importer tests fail with a null pointer exception, but that problem is secondary and only happens when the db fails to load, which is the root problem.) We can fix the NPE in code review, for now the main issue is fix the core problem of why genomics db fails to load. - The changes in OptionalVariantInputArgumentCollection and RequiredVariantInputArgumentCollection are causing argument name collisions in other tools, which is why ExampleIntervalWalkerIntegrationTest tests are failing in this branch. The simplest fix in the short term is to just revert the changes you made to those two classes, and remove the new VariantInputArgumentCollection class. These aren't being used by the importer tool anyway. It should be pretty easy to reproduce load issue, it happens on my laptop and and travis, but let me know if you need help or have questions about any of this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294148791:373,integrat,integration,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294148791,2,['integrat'],['integration']
Integrability,"Thanks @lbergelson! I agree that it might be good to break into more layers—could be worth talking to SV team and seeing what lessons they learned in putting together their hierarchy of images. Also, note that I pushed the install of miniconda into the base, but I did not push down the setup of the GATK conda environment itself (which takes the bulk of the time during the main-image build, as it requires lots of downloading). I think I commented elsewhere that a good strategy might be to set up the conda environment with the non-GATK python dependencies in the base, and then update the environment via a pip install of the GATK python packages in the main image. This would let us make python code changes without having to rebuild the base, but might require a bit of scripting to create a final yml for non-Docker users. I also agree that it would be nice to cut down the Travis time, might be worth taking a look at other strategies to do that—could save everyone a lot of time!. Will try to add the test you suggested sometime tomorrow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662:547,depend,dependencies,547,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662,2,['depend'],['dependencies']
Integrability,"Thanks @lbergelson. I try to not depend on this, but when we're developing tools that rely on a GATK feature not yet in a release (like i'm trying to do here), it's quite useful to have those snapshots.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8138#issuecomment-1370160247:33,depend,depend,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8138#issuecomment-1370160247,1,['depend'],['depend']
Integrability,"Thanks @mwalker174, back to you! Might need some more work depending on what you decide.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5699#issuecomment-471799446:59,depend,depending,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5699#issuecomment-471799446,1,['depend'],['depending']
Integrability,"Thanks @samuelklee , I will incorporate your conda update into this branch, now that we've dealt with the test failures!. I patched the VETS test code to include the h5diff (and diff) output in the exception messages when one of these commands fails, and switched to the existing `BaseTest` methods for running the process and capturing the output. You can see what the output looks like (when we remove the epsilon tolerance) here:. https://storage.googleapis.com/hellbender-test-logs/build_reports/8610/merge_7165443572.3/tests/testOnPackagedReleaseJar/classes/org.broadinstitute.hellbender.tools.walkers.vqsr.scalable.ScoreVariantAnnotationsIntegrationTest.html. https://storage.googleapis.com/hellbender-test-logs/build_reports/8610/merge_7165443572.3/tests/testOnPackagedReleaseJar/classes/org.broadinstitute.hellbender.tools.walkers.vqsr.scalable.TrainVariantAnnotationsModelIntegrationTest.html. As you suspected/hoped, all the differences were tiny. When you have a chance, could you please review these changes to the VETS tests and let me know if you spot any issues?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1850563977:208,message,messages,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1850563977,1,['message'],['messages']
Integrability,"Thanks @samuelklee! I don't think 5 is strictly necessary, since we should be able to use VariantFiltration with a hard filter of a VQSLOD threshold right? Or are you saying that ScoreVariantAnnotations is the tool that needs to convert between LL/sensitivity and VQSLOD cutoff? . I'm happy to work on the WDL, do most of the tools on this branch have integration tests? That's where I'll start grabbing commands.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069187834:352,integrat,integration,352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069187834,1,['integrat'],['integration']
Integrability,"Thanks a lot @davidbenjamin ; In the meantime I have compiled the master branch when I saw this issue was resolved and it worked fine. I tried also to create a pon with this fresh compiled version but I got some errors (don't remember exactly what right now). Looks like you are in the middle of changing the pipeline of pon creation by integrating GenomicsDB as an intermediate, right ? Do you think it will also be ready for this next release ? I would like to create the pon with the same GATK version. Problem is I can not fall back on an earlier version because I would definitely get the bug we are talking about in this thread :-). Perhaps we should also change our computing nodes at some point I guess :). Thanks again",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216:337,integrat,integrating,337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216,1,['integrat'],['integrating']
Integrability,"Thanks a lot for looking into this @sooheelee - I understand the pain of making the small data for the tests, so I really appreciate your work there. I have almost prepare a PR for the new port of `RealignerTargetCreator` that will have TODOs for the test data prepared by you, and with some tests using files already in the repository (for the target-creator, I guess that the validation for getting the regions to realign would be enough, because thanks to that tests I realized of a small bug due to not including all the loci in the `LocusWalker`). On the other hand, I will still fight for the `--nWayOut` not blocking the inclusion of `IndelRealigner` in the first place. My reasons are the following:; ; 1. Looking a bit into the code of GATK3, there is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:860,interface,interface,860,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231,1,['interface'],['interface']
Integrability,"Thanks a lot for taking care of this. I met different error this time. I; git clone it from the master. version info: The Genome Analysis Toolkit; (GATK) v4.1.5.0-16-gf1aea57-SNAPSHOT. I ran four samples. All return the same problem when just started the; haplotypecaller. Here is the error message.; [March 17, 2020 1:54:08 PM EDT]; org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller; done. Elapsed time: 1.09 minutes.; Runtime.totalMemory()=4182245376; java.lang.IllegalStateException: Smith-Waterman alignment failure. Cigar =; 64M40D29M with reference length 133 but expecting reference length of 413; ref =; AGCATCCGACAGCCTGGAGCAGCACCCACACCCCCAGTTGAGCAACTGATGGTCTGGAGCAGCACCCACAACCACAGGTGAACATCAGAGAGTCTGGAGCAGCGCCCACAACCCCAGGCGAGCATCTGACAGCCTGGAGCAGTGCCCAAACACCCAGGTGAGCATCTGACAGCATGGAGCAGCACCCATAGCCCAAGGTGAGCATCTGACAACCTGGAGCAGCACCCACACCCCGAGGTGAGCATCTGACCTCCCGGAGCAGGACCCATACCTCCAGGCGAGCATCTGAACCCATGGAGCAGCACCCACGCCCCCAGGCGAGCATCTGACCGAACAGAGCAGCACCCACAACCCCATGCGAGCATCTGTCAGCCTGGAACAGCACCCACAACCCCAGGTGAGCATCTGACAGC; path; AGCATCCGACAGCCTGGAGCAGCACCCACACCCCCAGTTGAGCAACTGATGGTCTGGAGCAGCACCCACAACCCCAGGTGAGCATCTGACAGC. David Benjamin <notifications@github.com> 于2020年3月17日周二 下午12:49写道：. > @phpeters <https://github.com/phpeters> I expect that the fix in #6498; > <https://github.com/broadinstitute/gatk/pull/6498> corrected both leading; > and trailing deletions, but please let us know if it did not.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6490#issuecomment-600179222>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AEORBD6XHZDY2RBOTVNGQODRH6SY3ANCNFSM4LENWAMQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6490#issuecomment-600218205:291,message,message,291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6490#issuecomment-600218205,1,['message'],['message']
Integrability,"Thanks also for this detailed report, @Stikus! The differences look small to me (mostly in the quals, which are the result of more numerically sensitive calculations), with the discrepant calls primarily being of low quality. Since the gCNV python code depends on native C/C++ code (via numpy, theano, etc.), these sorts of floating-point numerical differences might not be unexpected if there are changes in the underlying system packages or hardware. Unfortunately, we can only guarantee numerical reproducibility to this high degree within our Docker testing environment. Note also the upcoming #8561, which will also introduce changes on this level.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8619#issuecomment-1851935613:253,depend,depends,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8619#issuecomment-1851935613,1,['depend'],['depends']
Integrability,"Thanks for adding this! Incidentally, I noticed a few messages are still emitted by com.github.fommil.jni.JniLoader (which uses a different logger) in CreateReadCountPanelOfNormals when native libraries are loaded by MLlib, but probably more trouble than it's worth to clean those up. Couple of minor comments, looks fine to me but maybe engine team should chime in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-475703103:54,message,messages,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-475703103,1,['message'],['messages']
Integrability,"Thanks for adding this! Let me discuss further with @mwalker174 to understand the need and typical use cases (e.g., combining fixed-grid bins) to make sure we don't run into any gotchas downstream. I'll try to review by EOD, but in the meantime, you might want to address a few issues I see at first glance:. 1) Correct the name of the tool (PreprocessIntervals) in the commit message and description.; 2) Add descriptions of the new parameters to the tool Javadoc.; 3) Amend the corresponding WDL task and expose the new parameters in all relevant germline and somatic WDLs.; 4) We should be sure to update the relevant documentation for all germline and somatic WDLs, which emphasizes how PreprocessIntervals should be run differently for WES and WGS, if we plan on changing the default behavior of the tool in the future.; 5) Tests are failing due to a compilation warning about a redundant cast to int.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387:377,message,message,377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387,1,['message'],['message']
Integrability,"Thanks for all the help. Using the 4.2.0.0 docker resolved the problem!. On Tue, Mar 23, 2021 at 10:06 AM Chris Norman ***@***.***>; wrote:. > Oh, I missed that they had already tried reindexing. @ahaessly; > <https://github.com/ahaessly> can you find out what tool and what version; > was used to reindex this file ? We've had several reports of this error; > message in the last month or two, but reindexing has usually fixed it. I; > had been assuming that the corrupt index files were created by older; > versions of GATK/Picard tools, but it would super helpful to know if; > current versions of either samtools or GATK/Picard is creating these, and; > will help determine if we need to relax this check.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804930832>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AFO2VRJSHCFOODG56CXSO4TTFCN53ANCNFSM4ZNOBRZQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804963976:361,message,message,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804963976,1,['message'],['message']
Integrability,"Thanks for bringing this to our attention, @Tintest. I think that we may be able to address this by setting `base_compiledir` via `os.environ[""THEANO_FLAGS""]` appropriately (see http://deeplearning.net/software/theano/library/config.html). @mbabadi @cmnbroad any thoughts? . In any case, thanks for trying out the GermlineCNVCaller pipeline. You may have to tune some parameters, depending on your data type. You may find the following discussions helpful:. https://gatkforums.broadinstitute.org/gatk/discussion/11711/germlinecnvcaller-interval-merging-rule-error. https://github.com/broadinstitute/gatk/issues/4719. Note that we're still in beta, but our preliminary evaluations have demonstrated improved performance over other callers in both WES and WGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-390303432:380,depend,depending,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-390303432,1,['depend'],['depending']
Integrability,"Thanks for fixing the message! I couldn't track down the original `output.vcf` that caused the issue, and this is ancient enough that I can't even recall the context. However, because the site `1262288` only appears in our repo in the simulated gCNV test data, I suspect that this VCF was generated at some point during development of VCF output for PostprocessGermlineCNVCalls. Not sure in what way that VCF might have been invalid (I'm pretty sure the VCFs produced by that tool now are valid), but I can try to reproduce when I get a chance and will reopen if necessary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6076#issuecomment-517813352:22,message,message,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6076#issuecomment-517813352,1,['message'],['message']
Integrability,"Thanks for helping with the updates, @MartonKN! Looks like you have some failing integration tests, though. Perhaps go through and fix those up before @sooheelee takes a look? Don't forget you can run integration tests locally for those tools you've updated. It might also be worth rebasing on the most recent version of master and re-pushing your branch to make sure no other argument updates slipped in that might conflict with yours.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352525285:81,integrat,integration,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352525285,2,['integrat'],['integration']
Integrability,"Thanks for indulging me on this. To me it seems like `UnfilledReadsLikelihoods` diverges too much from `ReadsLikelihoods` to extend it. In effect it's letting `ReadsLikelihoods` sometimes be a wrapper for something that is not a `ReadsLikelihoods`. I haven't worked this out but I would hope that it's possible to construct a `ReadsLikelihoods` from a pileup. I mean, the idea of pileup calling is that you use just a single base for the likelihoods and not the whole read (via Pair-HMM), so we should be able to fill the likelihoods from the base qualities.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4865#issuecomment-396369856:193,wrap,wrapper,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4865#issuecomment-396369856,1,['wrap'],['wrapper']
Integrability,"Thanks for looking into this @cmnbroad !. * Does this issue only affect tabix indices, or all indices? . * Does it only affect `IndexFeatureFile`, or other GATK4 tools as well? . * Will an htsjdk patch be required?. * You say that the offsets are correct when indexing on the fly -- does this mean that a tabix index produced by `ApplyVQSR` on an hg38 `.vcf.gz` on-the-fly will be correct? Can you comment on https://github.com/broadinstitute/gatk/issues/2821 to confirm?. If this is the case, can you craft an integration test proving that `ApplyVQSR` creates a correct tabix index for an hg38 `.vcf.gz`? We should also probably disable tabix index creation in `IndexFeatureFile` temporarily until we can patch htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2801#issuecomment-306768554:511,integrat,integration,511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2801#issuecomment-306768554,1,['integrat'],['integration']
Integrability,"Thanks for looking into this @davidbenjamin. I followed the best practices using bwa mem, mark duplicates etc., to create these input bams for HaplotypeCaller. This is Novaseq 2 x 150 data, I ran Fastqc on the reads and everything looks really good, the only thing I can find that might explain the soft-clipping is that there's some Nextera adapter read through on a small percentage of the reads. I haven't been using -Y with bwa (I see it's used in GATK 4 wdls), so it seems like there should be less soft-clipping than normal. I'll admit these are definitely messy regions we're dealing with, but we really need to make the F5 calls for our clinical pipeline. I just tried --dont-use-soft-clipped-bases and I wasn't able to pick the SNP up in the 55-55003_F5_region.bam, but using forceActive/dontTrimActiveRegions does work on this call.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402690747:342,adapter,adapter,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402690747,1,['adapter'],['adapter']
Integrability,"Thanks for making this change! I might include more detail with the note (""Substantially improves results on FFPE samples""), for posterity---it's probably true, but we can't really say anything definitive with only N=1 and without the cross-validation procedure I mentioned on Slack. That is, the higher degree of denoising might just be an artifact of effectively removing more PCs with GC-bias correction (since I'm assuming the same number of PCs were explicitly removed in both cases), but it's possible that removing the optimal number of PCs without GC-bias correction could achieve a better result. Since our correction procedure is relatively naive, there may also be some dependence on bin size. However, I think it's probably not worth a detailed analysis, and that it's generally safe to enable correction by default.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5966#issuecomment-496933928:681,depend,dependence,681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5966#issuecomment-496933928,1,['depend'],['dependence']
Integrability,"Thanks for the explanation, I've generally not run into any memory issues with HaplotypeCaller so I think disabling it might be best in my case. I'll go ahead and close this issue now. Just as a side note (and I'm not sure if you would be interested in this), but the reason I've been digging so deeply into HaplotypeCaller behaviour is that we've been working on a rust based reimplementation of the HaplotypeCaller but geared towards metagenomic analysis. So the interface is more geared for handling many genomes all in parallel as well as adding in a bunch of metrics that microbiologists would find useful: https://github.com/rhysnewell/Lorikeet/tree/dev & https://github.com/philipc/gkl-rs. I think the work that you and the GATK team is astounding, and it has been really helpful to have all of the code so well documented and well written. Just thought I'd make you aware of the rust effort in case you had any thoughts on it. Cheers,; Rhys",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7873#issuecomment-1139184179:465,interface,interface,465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7873#issuecomment-1139184179,1,['interface'],['interface']
Integrability,"Thanks for the files. We've identified the issue as a bug in htslib - pretty straightforward fix. The mixed ploidy is not a problem in this case. But the confluence of multiploidy, number of samples and number of alternate alleles causes some locations in the combined gvcf to have very large arrays of FORMAT data. That triggers an (unforeseen) overflow in htslib. . With Thanksgiving coming up, we won't be able to get the fix out in a released GenomicsDB this week. Can try for early next week, depending on when you're next doing a GATK release @droazen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-558813259:498,depend,depending,498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-558813259,1,['depend'],['depending']
Integrability,"Thanks for the quick review, @ldgauthier!. I don't think my fix will address any non-determinism in the integration tests. I'm inclined to just do better with the new tools---there does seem to be enough duct tape in the integration tests regarding re/setting the RNG so that the exact-match tests consistently pass. As for learning how to run the WARP tests, I think that would indeed be pretty useful---for anyone that might have to update code for VQSR or the new tools in the future! Can we teach everyone to fish? Isn't this what CARROT is for?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061830649:104,integrat,integration,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061830649,4,['integrat'],['integration']
Integrability,"Thanks for the replies. Are these C/C++ tools something one could run today on a genomics db workspace, even if there isnt a formal java wrapper?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6895#issuecomment-711100739:137,wrap,wrapper,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6895#issuecomment-711100739,1,['wrap'],['wrapper']
Integrability,"Thanks for the response, @droazen! Technically, yes, that would be satisfactory & accurate... and if that's easiest, I'm fine with that. . From a user perspective though, it might be beneficial to report the first occurrence of this error, as that's most likely where I would go back to do future testing & troubleshooting. That being said, all of the overlapping intervals are already outputted to stderr, so all the information is retained regardless, and I could just look through the logs to find that first problematic interval. As an aside, I find it a bit weird that the overlapping interval message shows up as a _warning_ even when using the `-no-overlaps` option (I would assume it would be an error, not a warning). In my experience, most errors cause the program to quit immediately. So, perhaps instead, if this warning were an _error_ when using the `-no-overlaps` option, the program would stop after the first occurrence of this error... and then the error message would be accurate. Maybe that was the original intent of this code. But, again, if that requires much more testing & changes, when a quick rewording would also suffice, there's no need. If it's simply a rewording, I'm happy to make a pull request. Let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329747570:599,message,message,599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329747570,4,['message'],['message']
Integrability,"Thanks for the review @jamesemery. I've addressed your comments. A few outstanding issues:; * `ActivityProfileStateIterator` and `AssemblyRegionFromActivityProfileStateIterator` duplicate parts of `AssemblyRegionIterator`, so it would be nice to remove the code duplication. Not totally straightforward as the latter does read caching, but the first two don't (Spark shouldn't be caching reads).; * Downsampling needs more work. I would be OK doing that separately, since I've only ever seen it when running on a full genome, and the new strict code needs more work to work on a full genome (I've only got it running on an exome so far).; * There are some improvements we could make to `ReadlessAssemblyRegion` regarding Java interface design and generics, but I'm not sure what they are yet. I'm not sure if these are blockers, since the strict codepath is a new option (off by default), but would like to know what you and @jonn-smith think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5416#issuecomment-439843425:726,interface,interface,726,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5416#issuecomment-439843425,1,['interface'],['interface']
Integrability,"Thanks for the review and running those tests, @ldgauthier! Will restore the aforementioned GnarlyGenotyperIntegrationTests and update a few other exact matches in the rebase this afternoon. You also asked above if there was a theoretical reason to change the threshold. Since it seems the original was relatively arbitrary (at least from what I've been told, happy to be corrected), I think we can leave it. The new annotation is strictly larger, so we will then be slightly more conservative about keeping sites if we leave the threshold fixed. You can think of this as a slight change in the decision boundary in genotype-count space---perhaps I can add some plots to this thread this afternoon to demonstrate. In practice, what we care about is whether: 1) many sites flicker across the change in boundary after hard filtering, and/or 2) these sites result in discrepancies post-VQSR. I think the tests you ran suggest that we don't need to worry much about the second issue, and I can take a closer look later to check about the first (which will depend simply on the number of samples and the allele frequency spectrum). We can also take a basic look at how things might change with e.g. more samples using the aforementioned plots.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914471272:1052,depend,depend,1052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914471272,2,['depend'],['depend']
Integrability,"Thanks for the review, @droazen. My ideas about the ordering are the following: in #2084, I have the implementation of the fixing/checking of misencoded quals included in the read sources. So the only one that could be applied before filtering is gone if you accept that PR. Thus, I guess that the transformer could be applied after the filtering. Because transformers could be kind of demanding in computation, it will be interesting to pass directly to them filtered reads. In addition, could be included in the contract that only valid reads for the tool ensure that the read transformers don't blow up. Whatever the decision is, should I wait for addressing the comments?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-245958519:514,contract,contract,514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-245958519,1,['contract'],['contract']
Integrability,"Thanks for the review, @fleharty!. Thanks for highlighting the AVX business, which I didn't consider carefully. This was just copied from the other HC integration tests, and was in turn copied to the M2 tests---but I now realize that the style of the M2 tests is a little different in that an implementation isn't specified. But I think in both cases, we'll try to call an AVX implementation (since the M2 tests will default to `FASTEST_AVAILABLE`) and that Travis should be OK with it, at least?. @droazen can correct me if I'm wrong and let me know if he'd like further review on this branch. Otherwise I'll try to address comments and get this in before I head out on vacation next week.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-906679400:151,integrat,integration,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-906679400,1,['integrat'],['integration']
Integrability,"Thanks for trying out the tool, @ssri28. The exception message states that “List of input read-count files cannot contain duplicates,” so that would be the first thing to check. (Indeed, it looks like you specify `--input sample.counts_ESI_17.hdf5` twice.) Since we are either building a model or calling ploidy from the count files, it doesn’t make sense to allow duplicates. The support forums at https://gatkforums.broadinstitute.org/ are a better place for getting help with running the tools and diagnosing exceptions. GitHub issues should be reserved for bug reports and feature requests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543113598:55,message,message,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543113598,1,['message'],['message']
Integrability,"Thanks for your feedback, @cmnbroad. In my case, I think that `IntegrationTestSpec` is a good way of avoid complicated code to test tool results, but it is true that it have some problems (one that I had was the usage for testing programs where the outputs are determined by a prefix in the command line, but with different suffixes). I think, from the API user point of view, that a class like `IntegrationTestSpec` to facilitate program output testing (including user exceptions) will be nice for developing purposes. Nevertheless, this is just a convenience that I asked for here, but I can try to solve the issues with the `BaseTest` instead. By the way, I would love to have this interface in GATK at least for now, because several of my tools rely on the `IntegrationTestSpecs` for development...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243124889:685,interface,interface,685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243124889,5,"['Integrat', 'interface']","['IntegrationTestSpec', 'IntegrationTestSpecs', 'interface']"
Integrability,"Thanks for your reply. I try `--enable-journal` option and the following message is repeated many times. Received from stderr: [>>> ]. Sending: [vqsr_cnn.score_and_write_batch(args, model, tempFile, fifoFile, 2, 2, ''); ]. I trace the python process that is piped-forked by CNNScoreVariants. write(2, "">>> "", 4) = -1 EPIPE (Broken pipe); --- SIGPIPE {si_signo=SIGPIPE, si_code=SI_USER, si_pid=58415, si_uid=xxxx} ---; read(0, """", 1) = 0; write(2, ""\n"", 1) = -1 EPIPE (Broken pipe); --- SIGPIPE {si_signo=SIGPIPE, si_code=SI_USER, si_pid=58415, si_uid=xxxx} ---; rt_sigaction(SIGINT, {SIG_DFL, [], SA_RESTORER, 0x7f054d1fe5e0}, {0x5006d0, [], SA_RESTORER, 0x7f054d1fe5e0}, 8) = 0; close(3) = 0; write(4, ""952\n1\t121482273\tA\t[G]\t-14.449\n1\t""..., 2018) = 2018; close(4) = 0; :; close(21) = 0; exit_group(0) = ?; +++ exited with 0 +++; ; EPIPE is occured after CNNScoreVariants stops.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4696#issuecomment-384231912:73,message,message,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4696#issuecomment-384231912,1,['message'],['message']
Integrability,"Thanks for your response @droazen -- just tried it and it still does not work for me. I am able to access the bucket fine via gsutil -u {project} as expected. I wonder if this is some GCP issue because I am also unable to get Cromwell to pull down files from requester pays (via Terra, so this should be handled in theory), an issue that a colleague also has once I asked her to run this command on a different r/p bucket using her billing project and account. Also, for a different project and bucket the usual workflow I have to get Hail to read from r/p buckets seems to not work with this same error. Very confused. EDIT: https://support.terra.bio/hc/en-us/articles/4447388269851 seems to provide the most parsimonious explanation:; ```; It was determined that Google tweaked an error message causing Cromwell not to recognize buckets as requestor pays.; ```. Wonder if something similar is going on with GATK?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6179#issuecomment-1048028114:789,message,message,789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6179#issuecomment-1048028114,1,['message'],['message']
Integrability,"Thanks for your work on this @samuelklee! Testing on both wes and wgs would be ideal. For wgs we can use the gatk-sv reference panel, which is our standard (I can help with this once a docker is ready). For wes, 1kgp would work although it's definitely showing its age. Are the integration test differences large?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1804698174:278,integrat,integration,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1804698174,1,['integrat'],['integration']
Integrability,"Thanks much for this. Unfortunately running as root isn't an option since external CWL runners (like bunny, Toil, cwltool and hopefully Cromwell soon) make the decisions about the username to use and will try to mirror the runner with the external user to match user permissions on the output files. Also people trust it more when you're not trying to run as root (hence, not wanting to mess with `/etc/passwd` in the Docker container for fix Spark as well). This was using the bcbio-vc Docker image (https://github.com/bcbio/bcbio_docker#docker-images) with gatk installed via bioconda, but I don't think is image specific unless you're specifically doing something in your images to work around the problem which is doesn't sound like. Is there any chance to tweak Spark to make it less picky/dependent on the user? I'm not enough of a Spark expert to know if this is work-aroundable in a reasonable way?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-378718128:795,depend,dependent,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-378718128,1,['depend'],['dependent']
Integrability,"Thanks very much for your analysis. Job 4 does create a lot of garbage, but that appears to be inevitable whenever you are dealing with a PairRDD: You have to use a Tuple2 to represent key and value rather than using a more memory-conservative custom data object. You end up with a gazillion tiny objects that survive only during the shuffle. Too bad they didn't base PairRDD on an interface like Map.Entry. Also too bad that you cannot force a shuffle on a (plain old, non-Pair) RDD. Why not just treat it as a key-only structure and allow repartitioning? I mention this not merely to whine, but also in the faint hope that you've developed some helpful workarounds. I don't think we have enough memory to persist the reads, but we can revisit that later. Job 5 *is* doing a lot of computation. It's turning each read into kmers and testing each of those kmers to see if they exist in a large hash table. I don't think there's much opportunity for further optimization -- I knew this would be a bottleneck and tried my best to make the code efficient. The skew in task size is definitely a problem, and I'll be looking for opportunities to address that issue. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292230002:382,interface,interface,382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292230002,1,['interface'],['interface']
Integrability,"Thanks! Just to be clear, the PR is incomplete. We need to determine the additional dependencies (which were previously installed along with R) required for AVX, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-413599300:84,depend,dependencies,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-413599300,2,['depend'],['dependencies']
Integrability,"Thanks, @cmnbroad!. - You're right about gatkbase-2.1.0, that image is coming from #5026, which needs some more work. We can delete it for the time being if you think it'll cause confusion.; - Correct, I think the import statement for `reshape` in BQSR.R was always incorrect/extraneous. `reshape2` is the correct dependency for `ggplot2` (which is itself imported), and `reshape` is not explicitly used in BQSR.R. So to recap: I removed the installation of this unnecessary package, but failed to remove an unnecessary import statement since it was in an untested code path, which was then caught when users tried to run the tool. Investigation of this issue then revealed that `ggplot2` was not installed correctly in the current base image, due to a completely unrelated dependency issue.; - Good call on clearing the Travis cache. Not actually sure how to do that, do I just delete the cache at https://travis-ci.org/broadinstitute/gatk/caches for this particular branch?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408447924:314,depend,dependency,314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408447924,4,['depend'],['dependency']
Integrability,"Thanks, James! I'll check that out - I think we might be able to leverage; that. best,. Brian. On Fri, Mar 8, 2024 at 2:38 PM jamesemery ***@***.***> wrote:. > Hey @brianjohnhaas <https://github.com/brianjohnhaas>. I'm not quite sure; > i fully understand what we can change to help you here. However there is a; > feature you might not be aware of in the bamout that can help you figure; > out which reads go with what haplotype. In our bamout we assign a tag (that; > for whatever reason it looks like IGV hides by default) called the XA tag.; > If you look at an IGV bamout and color by that tag you can see what reads; > were grouped by what haplotypes. If a read has no XA tag that means it was; > non-informative about any one haplotype over a second possible contender; > and thus it was not strong evidence one way or another.; >; > Below is a screenshot of what it looks like to do this in a very simple; > case. Hopefully this answers your question? I would be happy to go deeper; > into this if you would like.; >; > Screenshot.2024-03-08.at.2.35.42.PM.png (view on web); > <https://github.com/broadinstitute/gatk/assets/16102845/7d11ff5f-418e-4826-89fc-07535648a71f>; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986302994>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX773HENZD2UVB356GDYXIHTTAVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOBWGMYDEOJZGQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986909258:1557,Message,Message,1557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986909258,1,['Message'],['Message']
Integrability,"Thanks, but I’m still not sure I understand. Haplotypecaller has the following parameters:. . Assembly-region-padding. Interval-padding. . The differences and relationships between these are not well documented on the gatk website. From what you describe below, it would seem to suggest that assembly-region-padding is doing what interval-padding is doing. But then why would there be multiple settings for the same thing?. . I just want to make sure that Assembly-region-padding is indeed adding intervals to the -L interval list itself, not just to the assembled regions. . From: droazen <notifications@github.com>; Reply-To: broadinstitute/gatk <reply@reply.github.com>; Date: Thursday, August 1, 2019 at 12:56 PM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: gevro <g.evrony@gmail.com>, Mention <mention@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Missing interval padding for HaplotypeCaller (#6071). . @gevro The HaplotypeCaller adds padding to the intervals on its own. This is controlled by the --assembly-region-padding argument, which defaults to 100 bases on either side. Note that this controls both padding around user-provided intervals, as well as padding around each individual assembly region that the HaplotypeCaller discovers. Typically a single user interval will get divided into many assembly regions, depending on where variant activity is located. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517387946:1346,depend,depending,1346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517387946,1,['depend'],['depending']
Integrability,"Thanks, that's a more useful error message I think. What version of java are you running? The current version of GATK requires java 8. It sounds like you're running a java that includes a module system which is java 9+. However, the situation is changing very soon, we are upgrading gatk to use java 17.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452483074:35,message,message,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452483074,1,['message'],['message']
Integrability,"Thanks. That’s what I thought too. But interestingly, looks like some of Agilent’s old BED files do not have such target BED files. Even though they are labeled as such, the boundaries of regions look only like probes. Specifically for the Sureselect clinical research exome and the Human all Exon v4 kits. . From: ldgauthier <notifications@github.com>; Reply-To: broadinstitute/gatk <reply@reply.github.com>; Date: Monday, August 5, 2019 at 10:08 AM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: gevro <g.evrony@gmail.com>, Author <author@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Which regions to use for exome calling_interval_list (#6080). . Calling intervals should be based on targets. The targets are the goal and the probes are the implementation. Depending on the bait design and the size of the exons, there can be regions of the targets that are not covered by baits, but still have coverage and still should be called. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6080#issuecomment-518250672:780,Depend,Depending,780,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6080#issuecomment-518250672,1,['Depend'],['Depending']
Integrability,"That is a separate matter altogether from both 1) unifying the allele-count collection tools, and 2) standardizing the format of tabular data. The most appropriate place for integration of Mutect2 SNV calls would be as input to the tumor-heterogeneity tool (along with the ModelSegments output) further downstream. This is because it is unlikely that including the SNVs as input to ModelSegments would significantly improve either segmentation or modeling there. If the allele-count collection tools are unified, I think that the only redundant work done across both pipelines would be the calling of hets from the pileups, which is extremely cheap. However, we should certainly also unify the code to do this (which I've spoken to @davidbenjamin about as well).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926:174,integrat,integration,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926,1,['integrat'],['integration']
Integrability,"That should work for both my cases. It could be nice for SelectVariants to; be able to specify whether genotypes should be called or not too. Other; tools might want the sites-only option. On Mon, Mar 4, 2019 at 12:40 PM droazen <notifications@github.com> wrote:. > *@droazen* commented on this pull request.; > ------------------------------; >; > In; > src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBUtils.java; > <https://github.com/broadinstitute/gatk/pull/4947#discussion_r262167602>:; >; > > @@ -40,7 +40,7 @@; > */; > public static GenomicsDBExportConfiguration.ExportConfiguration createExportConfiguration(final File reference, final String workspace,; > final String callsetJson, final String vidmapJson,; > - final String vcfHeader) {; > + final String vcfHeader, final boolean doGnarlyGenotyping) {; >; > @lbergelson <https://github.com/lbergelson> @ldgauthier; > <https://github.com/ldgauthier> If tools had a way to inject custom GDB; > config (eg., via an overridable method in GATKTool), and the engine used; > this config when creating the Feature Manager on startup, would that solve; > the problem here?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4947#discussion_r262167602>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdOOjGpZBu39mqk7jekA7iOzWDTFrks5vTVqFgaJpZM4U4KK0>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-469412816:954,inject,inject,954,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-469412816,1,['inject'],['inject']
Integrability,That would be a clearer error message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489#issuecomment-99104999:30,message,message,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489#issuecomment-99104999,1,['message'],['message']
Integrability,"That's not unique to out of memory errors, I think it's the result of the process being hit with a SIGKILL so there are other reasons it could happen. A message that suggests that it might be a memory issue but doesn't hide the actual error would be helpful in pointing people in the right direction.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572622465:153,message,message,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572622465,1,['message'],['message']
Integrability,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:469,interface,interfaces,469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090,6,"['interface', 'wrap']","['interfaces', 'wrapper']"
Integrability,"Thats a good idea. I don't know what our release plan is. I think we might; do one more minor release on java 8 for someone internal and then give a; bit of time before a java 17 release to let things shake out a bit. There; are a bunch of things we punted until it was merged that we want to get; done related to the update. I will put out a snapshot tonight or tomorrow; for you to test against. I wouldn't anticipate many major problems; updating although there might be some wrangling module exports which is; awfully confusing. The bulk of our issues had to do with fixing the; documentation generation and dealing with spark both of which hopefully; will just work for you. On Thu, Mar 2, 2023, 3:56 PM bbimber ***@***.***> wrote:. > @lbergelson <https://github.com/lbergelson> or @cmnbroad; > <https://github.com/cmnbroad>: would you mind kicking off a build on; > this, so I can see how DISCVR-seq builds against it? Are you planning a; > GATK release any time soon?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1452531115>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABD3RLCRVXIM5Y3O2RC6IKTW2ECP3ANCNFSM6AAAAAAQV3ZLXM>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1452540395:1295,Message,Message,1295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1452540395,1,['Message'],['Message']
Integrability,"The AlleleFrequencyCalculatorUnitTest failure is due to the fact that Genomics DB is pulling in a newer version of testNG (we were using 6.9.6, but now were getting 6.10):. ```; :dependencyInsight; org.testng:testng:6.10 (conflict resolution); \--- com.intel:genomicsdb:0.5.0-proto-3.0.0-beta-1; \--- compile. org.testng:testng:6.9.6 -> 6.10; \--- compile; ```; and 6.10 seems to have a bug in how it handles arrays in lists, which is causing the failure. So we need to add a force resolution statement for testNG in build.gradle:. `force 'org.testng:testng:6.9.6'`. We need to make sure we don't confer this issue on gatk-protected, but thats a [separate issue](https://github.com/broadinstitute/gatk-protected/issues/982).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296195599:179,depend,dependencyInsight,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296195599,1,['depend'],['dependencyInsight']
Integrability,"The Carrot run failed due to PAPI error code 9, by the way, not for any reason specific to this branch:. ```; ""executionStatus"": ""Failed"",; ""message"": ""Task BenchmarkComparison.EVALRuntimeTask:NA:4 failed. Job exit code 1. Check gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2aab3ed0-746b-451e-a7db-1c22fbb1bb29/call-CHMSampleHeadToHead/BenchmarkComparison/82289acc-83e7-49c8-acd0-9b2277166e10/call-EVALRuntimeTask/attempt-4/stderr for more information. PAPI error code 9. Please check the log file for more details: gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2aab3ed0-746b-451e-a7db-1c22fbb1bb29/call-CHMSampleHeadToHead/BenchmarkComparison/82289acc-83e7-49c8-acd0-9b2277166e10/call-EVALRuntimeTask/attempt-4/EVALRuntimeTask.log."",; ""message"": ""Workflow failed""; ""status"": ""Failed"",; ""message"": ""Task BenchmarkComparison.EVALRuntimeTask:NA:4 failed. Job exit code 1. Check gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2aab3ed0-746b-451e-a7db-1c22fbb1bb29/call-CHMSampleHeadToHead/BenchmarkComparison/82289acc-83e7-49c8-acd0-9b2277166e10/call-EVALRuntimeTask/attempt-4/stderr for more information. PAPI error code 9. Please check the log file for more details: gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2aab3ed0-746b-451e-a7db-1c22fbb1bb29/call-CHMSampleHeadToHead/BenchmarkComparison/82289acc-83e7-49c8-acd0-9b2277166e10/call-EVALRuntimeTask/attempt-4/EVALRuntimeTask.log."",; ""message"": ""Workflow failed""; ""message"": ""Workflow failed""; ```. Looks like the underlying cause is an R parsing issue:. ```; Error in parse(text = text) : <text>:1:1: unexpected '*'; 1: *; ^; Calls: ldply ... llply -> structure -> lapply -> FUN -> eval -> parse; ```. @jamesemery Have you seen that error before in the Carrot HC tests?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2153282072:141,message,message,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2153282072,5,['message'],['message']
Integrability,"The Carrot tests are failing due to issues with R dependencies unrelated to this PR. Since it might take a day to fix, we are debating whether we're comfortable merging this without seeing the full-scale Carrot HaplotypeCaller test results.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1850830178:50,depend,dependencies,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1850830178,1,['depend'],['dependencies']
Integrability,"The GATK framework depends on the WellformedReadFilter, and individual tools use additional filters for various tool-specific reasons. `--disable-tool-default-read-filters` is a pretty big hammer and should probably be labeled an `@Advanced` argument. I can't speak for Mutect specifically, but I wouldn't expect tools to run and/or produce meaningful results if all read filters are completely disabled.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-382367333:19,depend,depends,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-382367333,1,['depend'],['depends']
Integrability,The PR at googleapis/google-cloud-java#5789 makes it possible to add a BigQuery dependency without having to move to the unshaded version. This should make our lives simpler.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516181784:80,depend,dependency,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516181784,2,['depend'],['dependency']
Integrability,"The `-selectType` argument now is `--select-type`, and that's what is failing. It is true that the error message is not that useful. @cmnbroad - is this related with https://github.com/broadinstitute/barclay/issues/119, no?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4705#issuecomment-384228852:105,message,message,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4705#issuecomment-384228852,1,['message'],['message']
Integrability,"The advantage of using SLF4J is that it is a general facade, so it makes simpler to change for one logging system to other if the bound is implemented. For the most common logging systems (log4j, jul, JLC, etc.), there are this implementation and even no-op logging. One of the nice things from slf4j is that it allows to use the logging format set by the software to every library dependency, controlling the verbosity of other libraries too. . After having a look to the gradle dependencies, it seems that ADAM and Spark use slf4j. This will allow better integration with the two libraries: now the `slf4-jdk` is completely removed, and I don't know if this will blow up at some point if some of the ADAM/Spark classes try to load them. In addition, it will make GATK4 more general. Regarding features, I'm not using more that what log4j is providing, but I'm quite familiar with logback and I have a bias to use it if possible, but the GATK framework as it is implemented now ""force"" to use log4j. But anyway, I'm happy also with using log4j and I was only suggesting this for make GATK4 more general (and to come back in my work to logback, but that is just personal taste). @lbergelson, feel free to close the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259211054:382,depend,dependency,382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259211054,6,"['depend', 'integrat']","['dependencies', 'dependency', 'integration']"
Integrability,"The biggest thing for a new data source would be the latest (or dare I say; the ability to choose the version) of GENCODE. On Wed, Apr 5, 2023, 10:06 AM Jonn Smith ***@***.***> wrote:. > @robby81 <https://github.com/robby81> This still has to be merged. I've; > been pulled off onto some other projects for a bit. Some changes to the; > internals of Funcotator are needed for this tool to be most useful, so I; > was waiting until those updates were made to merge this.; >; > I can compile a new release of the data sources, but I haven't heard from; > anyone in the community that it's a priority. Can you create a new issue; > for it? Some questions around a new release: If I were to create one, what; > would the new release include? Would there be any new data sources that; > were not included before? Are any included data sources no longer useful; > and should be removed?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1497550761>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AAJMDRJS4JRSEURXGDDFK5TW7V36RANCNFSM5COZRAWA>; > .; > You are receiving this because you are subscribed to this thread.Message; > ID: ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1497616444:1210,Message,Message,1210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1497616444,1,['Message'],['Message']
Integrability,"The builds have been broken as a result of the new mechanism for constructing smaller docker images. Namely no longer is the gatk clone and dockerfile sufficient to construct the docker image which has resulted in dockerhubs automated builds feature failing to construct the image successfully. Since there are a number of dependencies that our build has (notably things like java) and the vm dockers build runs is out of our control, a better approach would appear to be constructing the image with a cron job and pushing it to dockerhub manually.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4965#issuecomment-413284005:323,depend,dependencies,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4965#issuecomment-413284005,1,['depend'],['dependencies']
Integrability,"The command lines: . gatk --java-options ""-Xmx16G"" GenotypeGVCFs --reference {genome} --variant gendb://workdir/db_{idx} --output output.vcf.gz. gatk --java-options ""-Xmx16G"" CreateSomaticPanelOfNormals --reference {genome} --germline-resource {afsource} --variant gendb://workdir/pon_db_{idx} --output pon.vcf.gz. The output vcf files from the above two steps have chromosome 10 before 7. ; GenomicsDBImport, GenotypeGVCF, or CreateSomaticPanelOfNormals did not give any error messages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1660490047:478,message,messages,478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1660490047,1,['message'],['messages']
Integrability,The command was 'java -jar gatk/gatk-package-4.1.2.0-local.jar'. It should output the help message.; The server has 256G memory. there should be a bug of linux kernel or java jvm or gatk of some version. Let's close it before I can reproduce it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6050#issuecomment-583827583:91,message,message,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6050#issuecomment-583827583,1,['message'],['message']
Integrability,The concise message is:. ```; cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle; > Configure project :; Executing: git lfs pull --include src/main/resources/large. > Task :condaStandardEnvironmentDefinition; Created standard Conda environment yml file: gatkcondaenv.yml. > Task :pythonPackageArchive; Created GATK Python package archive in /home/cb2/gatk/build/gatkPythonPackageArchive.zip. > Task :gatkDoc FAILED; Unable to find the 'javadoc' executable. Tried the java home: /usr/lib/jvm/java-11-openjdk-amd64 and the PATH. We will assume the executable can be ran in the current working folder. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org; ```. And stacktrace flag output looks like:. ```; `cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(Execu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:12,message,message,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716,1,['message'],['message']
Integrability,"The coordinates of output / input files depend on the file type. In this case it is a 1 based system because VCF is always 1 based. . From the [VCF Spec](https://samtools.github.io/hts-specs/VCFv4.2.pdf); > 2. POS - position: The reference position, with the 1st base having position 1. . Some other formats (ex: BED format) use a 0 based position. GATK reads and writes files in their matching coordinates. . Internally it converts them all to a uniform format for processing. The GATK internal format is 1 based and matches VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9029#issuecomment-2452101380:40,depend,depend,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9029#issuecomment-2452101380,1,['depend'],['depend']
Integrability,"The error message about allele sorting is unhelpful -- it's from an integration test check for exact match of output vcf against an expected vcf and the ""sort order"" error really just means there are fewer alleles in the output than expected. Since this change is what we want, the solution is just to overwrite the expected VCF. I checked all the discordant files and found nothing wrong, so this is okay. I also looked at all the output after the change `!outputNonVariants` --> `true` that I suggested, and it is definitely more correct.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582252469:10,message,message,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582252469,2,"['integrat', 'message']","['integration', 'message']"
Integrability,"The error message indicates that the recalibration tables have different dimensions, but unfortunately it doesn't say which table it was. Looking at the source for `RecalibrationTables` it looks like it's probably `readGroupTable`, since it is the only 2D table I can see in `allTables`. So the question becomes, why is the number of read groups different for different tables created by `BaseRecalibratorSparkFn`? They all have the same header, so the number of read groups should be the same. One thing to try to see if it affects the result is to set a different partition size with `--bam-partition-size`. It defaults to the HDFS block size, which is 128MB, but you could try another value (e.g. `67108864`, which is 64MB) to see if you get the same error. Otherwise to make more progress I would need to debug locally. Are the files sharable @akkellogg?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-479397018:10,message,message,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-479397018,1,['message'],['message']
Integrability,"The existing Spark interface for metrics collectors is described [here](https://github.com/broadinstitute/gatk/blob/fc66240a1a382ad803b7f83ead612f65957a644e/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/metrics/MetricsCollectorSpark.java). [Here](https://github.com/broadinstitute/gatk/blob/414cedf60d2041636f772658a6d04f470affb0f4/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/metrics/QualityYieldMetricsCollectorSpark.java) is one implementation of that interface, which in turn just delegates to the actual ""tool"" logic component that is reused for all variations of the tool (Spark, standalone, CollectMultiple, etc).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254217599:19,interface,interface,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254217599,2,['interface'],['interface']
Integrability,"The first idea that comes to my mind is using to methods: `makeReadTransformerBefore` and `makeReadTransformerAfter`, and implementations could control the order of the transformers. Other idea is create two interfaces for transform reads: `ReadRepairTransformer` and `ReadProcessingTransformer`, and make the two methods return the specific interface to do not allow one or the other to be applied before/after.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-245994894:208,interface,interfaces,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-245994894,2,['interface'],"['interface', 'interfaces']"
Integrability,"The git hash refers to the commit of GATK you have checked out in your branch as opposed to the commit of GATK that has been built in Java (and will be run on the cluster). I will clarify the error message: it means that you need to rebuild GATK to match your changes to the repository. The malformed object name is a different story, and seems like a bug. I will try to figure that out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394:198,message,message,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394,1,['message'],['message']
Integrability,"The integration tests I had for the allele-specific annotations admittedly had very small VCFs, but they were very, very gross variants. :) At the very least, the rank sums need test data that have a 0/1 sample and a 0/2 sample.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858:4,integrat,integration,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858,1,['integrat'],['integration']
Integrability,"The intervals we are passing to GenomicsDBImport are sorted by chromosomal numbers for a subset of chromosomal regions: chr 7, 8, 9, 10. ; The next step is CreateSomaticPanelOfNormals or GenotypeGVCFs depending on the pipelines. But the output for both steps all shows the problem that chr 10 is ahead of chr 7 (chr 10, 7, 8, and 9). ; Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1635962226:201,depend,depending,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1635962226,1,['depend'],['depending']
Integrability,"The master branch failed on BaseRealibratorSpark when running WGS. Try to test this branch, but got hit by a strange error message. The jar file looks right to me. @tomwhite did you have some environment variables? . ````Using GATK jar /home/genomics/Projects/TomWhitePatches/gatk/build/libs/gatk-package-4.alpha.2-230-g19db939-SNAPSHOT-spark.jar; Running:; /home/genomics/Projects/spark/bin/spark-submit --master spark://n001:7077 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --executor-memory 25G --driver-memory 5G /home/genomics/Projects/TomWhitePatches/gatk/build/libs/gatk-package-4.alpha.2-230-g19db939-SNAPSHOT-spark.jar BaseRecalibratorSpark -I hdfs://n001:54310/GATK4TEST/LargeBroadData/WGS-G94982-NA12878.bam -knownSites hdfs://n001:54310/GATK4TEST/DBSNP/dbsnp_138.hg19.vcf.gz -R hdfs://n001:54310/GATK4TEST/OldData/human_g1k_v37.2bit -O hdfs://n001:54310/GATK4TEST/LargeOutput/WGS_BQSR --sparkMaster spark://n001:7077; Picked up JAVA_TOOL_OPTIONS: -XX:+UseG1GC -XX:ParallelGCThreads=4; Picked up JAVA_TOOL_OPTIONS: -XX:+UseG1GC -XX:ParallelGCThreads=4; java.lang.ClassNotFoundException: org.broadinstitute.hellbender.Main; at java.lang.ClassLoader.findClass(ClassLoader.java:530); at org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26); at java.lang.ClassLoader.loadClass(ClassLoader.ja",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299259877:123,message,message,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299259877,1,['message'],['message']
Integrability,"The n1-standard-1 instance we'll be using has a single hyper-thread available to it from either a; 2.6 GHz Intel Xeon E5 (Sandy Bridge), 2.5 GHz Intel Xeon E5 v2 (Ivy Bridge), 2.3 GHz Intel Xeon E5 v3 (Haswell), or 2.2 GHz Intel Xeon E5 v4 (Broadwell). [Source](https://cloud.google.com/compute/docs/machine-types)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-282143266:128,Bridg,Bridge,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-282143266,2,['Bridg'],['Bridge']
Integrability,"The new pipeline is in a complete state. Nearly all tools and scripts were rewritten, many from scratch. I've tried to minimize interaction with old `tools/exome` code (notably, `ReadCountCollection` and `SegmentUtils`). There are still some improvements that can be made (especially in segment union and the subsequent modeling), but we should be ready to go for a first validation. Some notes:. WDL:; - I've moved the old pipeline to `somatic_old` folders.; - There is now just a matched-pair workflow and a panel workflow. We can add a single BAM case workflow or expand the matched-pair workflow to handle this, depending on the discussion at https://github.com/broadinstitute/gatk/issues/3657.; - WES/WGS is toggled by providing an optional target-file input.; - For all workflows, we always collect integer read counts; for WGS, these are output as both HDF5 and TSV and the HDF5 is used for subsequent input.; - For the case workflow, we always collect allelic counts at all sites and output as TSV.; - [x] We should output all data files as HDF5 by default and as TSV optionally. EDIT: This is done for `CollectFragmentCounts`.; - [x] We will need to update the workflows when @MartonKN and @asmirnov239 get `PreprocessIntervals` and `CollectReadCounts` merged, respectively. These tools will remove the awkwardness required by `PadTargets` and `CalculateTargetCoverage`/`SparkGenomeReadCounts`. Denoising:; - All parameters are exposed in the PoN creation tool (#3356).; - Without a PoN, standardization and optional GC correction are performed (#3570).; - Other than the minor point about sample mean/median being used inconsistently noted above, the denoising process is essentially exactly the same mathematically as before (""superficial"" differences include the vastly improved memory and I/O optimizations, the ability to adjust number of principal components used, the removal of redundant SVDs, the enforcement of consistent GC-bias correction).; - [ ] That said, I'll carry over this ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:616,depend,depending,616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['depend'],['depending']
Integrability,"The number of backtrace messages emitted definitely went up with the addition of the Picard sources, but the number I see when I run the gatkTabComplete task locally is dramatically lower than the number emitted when the cron job runs it. The main difference I can see is the cron job is using openjdk, whereas I'm not; the number of times the message is emitted is definitely sensitive to the order in which the sources are processed and ClassDoc and FieldDoc objects are traversed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3710#issuecomment-337692643:24,message,messages,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3710#issuecomment-337692643,2,['message'],"['message', 'messages']"
Integrability,"The one check that fails, I have restarted twice with the same error message:; ```; The job exceeded the maximum time limit for jobs, and has been terminated.; ```. The limit appears to be around 49 minutes. I have seen this type of check failure for my other PRs. Why does this keep happening and is it possible to up the time limit?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2812#issuecomment-306047630:69,message,message,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2812#issuecomment-306047630,1,['message'],['message']
Integrability,"The packages required by these tests are installed by scripts/docker/gatkbase/install_R_packages.R. Perhaps we should update the readme, which seems to indicate that the R dependencies are only used for plotting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-338992163:172,depend,dependencies,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-338992163,1,['depend'],['dependencies']
Integrability,"The previos message was written a bit quick from my phone. The concrete PR is https://github.com/samtools/htsjdk-next-beta/pull/12. @lbergelson - would like to have a look to it, or do you prefer that I open another one with the interface on top of the CIGAR part? I prefer to go step by step, as it is clearer than adding too many classes to review at once...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5267#issuecomment-428735904:12,message,message,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5267#issuecomment-428735904,4,"['interface', 'message']","['interface', 'message']"
Integrability,"The problem is that the catch block in `CommandLineProgram` is calling both `commandLineParser.usage()` and `printDecoratedUserExceptionMessage()` -- it should only be calling `commandLineParser.usage()`, and letting the catch block in `Main.mainEntry()` call `printDecoratedUserExceptionMessage()`. Otherwise there are cases where a `CommandLineException` will be caught without printing any error message. This is a bug and should be fixed. The distinction between ""errors that are the user's fault"" and ""errors that are not the user's fault"" is very important for our support team -- it allows them to deal with bug reports and forum questions much more efficiently. Whatever solution we come up with here should maintain that distinction, and clearly label errors like ""bad argument value"" as being a user error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938:399,message,message,399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938,2,['message'],['message']
Integrability,"The problem is that the package can't download any files during build due to security reasons. It has to use predefined, repeatable set of dependencies, and can't download random versions of gradle either. It has to use the ```devel/gradle``` port, and once this port has been upgraded to version 5.0 gatk became broken. ```devel/gradle4``` had to be created. Generally, indiscriminate downloads of files lead to security problems like the one that recently happened with a particular bitcoin-related node code, which was using a zillion node dependencies. One of them got infiltrated by a criminal who eventually stole bitcoins because he managed to inject his code into financial applications running on user's sites. To prevent such things from happening, all major packaging systems only use fingerprinted dependencies, and can't ""just download"" some alternative version of something during build, contrary to what devs might be expecting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444205059:139,depend,dependencies,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444205059,4,"['depend', 'inject']","['dependencies', 'inject']"
Integrability,"The reason I was getting different behavior was because my local htsjdk was built from a fork, and it had stale tags. That doesn't matter for GATK, since the GATK build.gradle uses a resolution strategy of ""force"" for htsjdk, forcing it to use the version I specified (even though it looks old due to the old tags). But the gatk-protected build.gradle doesn't have an explicit resolution strategy declared, so gradle resolves conflicts via ""pick the newest one"". Since there are newer versions available in gatk-protected via other transitive dependencies, it was choosing those over my local one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292971228:543,depend,dependencies,543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292971228,1,['depend'],['dependencies']
Integrability,"The snapshot builds get published to an artifact repository, but I don't think those are accessible from outside of Broad. The build from this morning with your branch is [here](https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot-local/org/broadinstitute/gatk/4.0.11.0-30-g9c4a27b-SNAPSHOT/) if you can access it. Otherwise, for local development, you can do the following:. - pull gatk master from today so it includes your commit; - run `git fetch --tags` (this is optional but it will give your local build a more reasonable version tag); - run `./gradlew install printVersion` to install the locally built gatk into your local machine's maven repository; - change your VariantQC gradle project to include the `maven` gradle plugin if its not already there; - add `mavenLocal()` to your projects' `repositories `closure; - change your gatk dependency to the version number printed out by 'printVersion'; - rebuild VariantQC. Having said all that, what code are you dependent on ? I expect the command line interface to VariantEval, and the VariantUtils and StratificationManager and friends classes all to undergo some refactoring and evolve a bit before the tool has the beta tag removed and the interfaces are stabilized. See https://github.com/broadinstitute/gatk/issues/5439 and https://github.com/broadinstitute/gatk/issues/5440.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440782148:852,depend,dependency,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440782148,4,"['depend', 'interface']","['dependency', 'dependent', 'interface', 'interfaces']"
Integrability,"The tests were failing for some reason, probably due to some dependency downloads failing, so I'm rerunning them. Will merge when that's done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5021#issuecomment-405984274:61,depend,dependency,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5021#issuecomment-405984274,1,['depend'],['dependency']
Integrability,"The tutorial data would be an option, except that it covers reference territory not currently in the repo. It looks like that would add nearly 1 gig just for the reference data, which I think we'd really want to avoid. Ideally we'd have just one PR for each of the (two) tools. If you want to keep `ConstrainedMateFixingManager` and `NWaySAMFileWriter` as separate PRs, thats fine, but I don't think we'd take them until we know there is, or will very soon be, code that depends on them. Certainly using `@Experimental` for the tools could make sense, once we're certain that we have a way forward for test coverage. One other note, it's very helpful to include the original GATK3 file as the first commit, as you did in this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366271857:471,depend,depends,471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366271857,1,['depend'],['depends']
Integrability,"The two main resources limiting how many gVCFs you can import at once will be memory and file handles. . I'm not sure if you mean incremental import or batch size when you mention the iterative approach. I assume the latter, but just want to clarify that there isn't any reason to break up the import using incremental import. The batch size parameter effectively does that, so you might as well import all gVCFs you have available (optionally using batch size if you're running out of memory). I'll throw out batch sizes of 50 or 100 as being reasonable, but the size of the intervals being imported will make a difference. It would be best to try to monitor how much memory is being used with those settings. There won't be a huge difference in import performance depending on the number of batches (ignoring memory issues) but if you have more than a 100 or so batches and you don't enable the `--consolidate` option you may see some query performance degradation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656376952:766,depend,depending,766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656376952,1,['depend'],['depending']
Integrability,"The user mentioned and I agree:; Since the interval list isn't a required argument listed in the GenotypeGVCFs documentation, perhaps a note could be added to the --all-sites parameter to indicate that it should be used in conjunction with a specified -L parameter. Clarifying the error message will also be a big help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480978282:287,message,message,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480978282,1,['message'],['message']
Integrability,The vulnerabilities reduced a bit but most serious once continue to be there. Dependency upkeep is really needed to iron this out these.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1544539592:78,Depend,Dependency,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1544539592,1,['Depend'],['Dependency']
Integrability,"The xbyak ""code is too big"" issue recently started happening on multiple branches (see https://github.com/broadinstitute/gatk/issues/6307), but is intermittent. I'll restart that one. The updated TF I gave you can't be checked in since its OSX specific, and needs additional work to be integrated (see https://github.com/broadinstitute/gatk/issues/6325) so it should be left out for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6330#issuecomment-567055679:286,integrat,integrated,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6330#issuecomment-567055679,1,['integrat'],['integrated']
Integrability,"There are no error messages.; The process was interrupted without any error messages.; I attached the screenshot.; I attached chr14 variant calling (completed) and chr14 variant calling; (interrupted).; In the system monitor, when I am using GATK 4.6.0.0., they are eating up; memory continuously.; When they are reaching up to 512Gb, the process was interrupted.; I tried to run this process on only 2-3 chromosomes, and I found that the; process was completed on chr 14, and the process was interrupted on the; rest of two chromosomes (interval -L).; So I rolled back to GATK 4.5.0.0, the process was normal. I can do; GenotypeGVCFs command entire chromosome simultaneously. My machine has 512Gb memory and 64 cores (5995wx AMD threadripper) dell; 7865 workstation.; Thanks; Jinu Han. On Fri, Jul 19, 2024 at 12:08 AM Gökalp Çelik ***@***.***>; wrote:. > Can you provide your logs that shows the error message?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2236819113>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AG7IXWWGPB73BXPN4Z5E4VTZM7LAFAVCNFSM6AAAAABLBRETECVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZWHAYTSMJRGM>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238806751:19,message,messages,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238806751,4,"['Message', 'message']","['Message', 'message', 'messages']"
Integrability,"There are pretty significant incompatibilities between java 8 and 11 that make it hard to run the same code on both. It affects a number of our dependencies which use features which were removed/altered from java 8 -> 11. Unfortunately despite there being significant pain in switching to 11 there aren't particularly compelling new features after 8 so there isn't much incentive for developers to move forward. That said, you CAN now run gatk on java 11 if you build it using java 11, the jars built on 8 are incompatible with 11 and vice a versa. We consider running on 11 to be a beta feature and would love to hear feedback about either success or failure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6298#issuecomment-561371535:144,depend,dependencies,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6298#issuecomment-561371535,2,['depend'],['dependencies']
Integrability,"There are tests for the CNV plotting tools, which use RScriptExecutor and uniquely require some of the R dependencies. There's also a test for the HMM code, which uses an HMM R package to generate expected results. I'd assume that tests for the other tools that use RScriptExecutor would also fail, but I don't know if they rely on any special dependencies or any particular version of R.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155:105,depend,dependencies,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155,2,['depend'],['dependencies']
Integrability,"There is GATK3 unit and integration test and could port them. BTW, I don't seen a VF unit test. I also looked at the GATK4 code an would expect the same problem would occur.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2301#issuecomment-265794458:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2301#issuecomment-265794458,1,['integrat'],['integration']
Integrability,"There is currently one failing integration test:. ```; completedicsdb.GenomicsDBImportIntegrationTest.testGenomicsDBImportFileInputsAgainstCombineGVCFWithMultipleIntervals FAILED; java.lang.AssertionError: actual is longer than expected with at least one additional element: [VC null @ chr20:17970000 Q. of type=SYMBOLIC alleles=[G*, <NON_REF>] attr={} GT=htsjdk.variant.bcf2.BCF2Codec$LazyData@134b79ab filters=; at org.testng.Assert.fail(Assert.java:93); at org.broadinstitute.hellbender.utils.test.BaseTest.assertCondition(BaseTest.java:395); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.lambda$checkGenomicsDBAgainstExpected$8(GenomicsDBImportIntegrationTest.java:326); at java.util.ArrayList.forEach(ArrayList.java:1249); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:319); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testGenomicsDBAgainstCombineGVCFs(GenomicsDBImportIntegrationTest.java:166); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testGenomicsDBImportFileInputsAgainstCombineGVCFWithMultipleIntervals(GenomicsDBImportIntegrationTest.java:107); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-386368519:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-386368519,1,['integrat'],['integration']
Integrability,"These all sound like positive improvements. Provided they don't affect performance by dramatically increasing the number of discovered haplotypes, I'm on board. Hopefully this will go a long way towards removing the dependence of calling on the active region boundaries.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-447012273:216,depend,dependence,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-447012273,1,['depend'],['dependence']
Integrability,"They are retried. You're seeing this message because it failed more than `maxChannelReopens` times. The new version which you really want to use for any test at this point is described there:; https://github.com/broadinstitute/gatk/issues/2685#issuecomment-302798685. Among other things, this new version puts in a message about 'retry failed' when it runs out of retries to eliminate the very confusion that you ran into. GenomicsDBImport opens a large number of parallel connections and as a result is getting throttled fairly heavily (by the host GCE machine if nothing else). This results in timeouts and dropped connections. One way forward is to increase the retry delays, another is to find a way to do the same work with fewer parallel open connections.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-304123753:37,message,message,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-304123753,2,['message'],['message']
Integrability,They've been working as far as I know. Or at least I haven't gotten any; failure messages. That's why I closed the ticket.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2183#issuecomment-253016704:81,message,messages,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2183#issuecomment-253016704,1,['message'],['messages']
Integrability,"They've patched the warning message to be an info message instead, but I think it will still show a stacktrace since info is our standard level.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5220#issuecomment-426729414:28,message,message,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5220#issuecomment-426729414,2,['message'],['message']
Integrability,"This PR is dependent on https://github.com/broadinstitute/gatk/pull/4571, which in turn will require https://github.com/broadinstitute/gatk/pull/7021, plus one additional PR to change all of the tests to use the new variant compare methods.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-754923888:11,depend,dependent,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-754923888,1,['depend'],['dependent']
Integrability,"This can occur in cases where there was a mixup with the samples, meaning the user intended to run a properly matched normal/tumor pair, but there is a provenance error. This is how @asmoe4 and myself hit this issue. So this is not the same use case as #5821, where they know there's a deliberate mismatch. While we're not expecting the contamination check to provide something sensible in this case, may I suggest that the tool provides a user-friendly message to help debug, rather than a stack traceback. This could happen to other people if they have an accidental mismatch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300:454,message,message,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300,2,['message'],['message']
Integrability,"This comes _extremely_ close to what I was looking for. But handling the parts that are expected to be common and those that are expected to be unique in the same way makes it very difficult for us to answer the core question that this is trying to answer: did these two samples have ""the same"" header in a meaningful way?. If you can add another column that is a flag to the vcf_header_lines table or something that allows you to mark whether or not an entry is sample-specific or common, that seems like it would be the fasted route between what is implemented here and easily answering the question we want to be able to ask. You'll likely need to keep the common and unique lines separate in processing to achieve that, though",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8321#issuecomment-1550079308:529,rout,route,529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8321#issuecomment-1550079308,1,['rout'],['route']
Integrability,"This error message is related to GATK's ability to load files on Google buckets (""gcs://bucket/file.bam""). This ability is enabled even when running locally (this aspect is intentional, because it's useful to be able to run a local GATK instance to process remote data without having to fire up a VM). As the bucket-reading code (""NIO"") initializes, it looks for credentials to use. Those can be set via an environment variable or via `gcloud auth`, as described in GATK's README. If neither of these are set, it checks whether it's currently running in a Google virtual machine (so it can figure out who owns the virtual machine that it's running on, and use those credentials). Apparently this code throws an exception if it runs out of ways to find credentials, and our code prints it out and moves on. The message is useful, for if we *were* running in a google VM and the credential-finding failed, we'd certainly like to know. Whether we need the full stack trace, now, that's a choice we have to make.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095:11,message,message,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095,2,['message'],['message']
Integrability,"This is a problem with your `R` environment -- you need to install the `gplots` package (amongst a few others, if you don't already have them). From https://gatk.broadinstitute.org/hc/en-us/articles/360035889531-What-are-the-requirements-for-running-GATK-; ```; R dependencies; Some of the GATK tools produce plots using R, so if you want to get the plots you'll need to have R and Rscript installed, as well as these R libraries: gsalib, ggplot2, reshape, gplots,; ```. Here's a quick article on installing packages in R if you're unfamiliar (https://www.r-bloggers.com/2010/11/installing-r-packages/). Note, you'll need a version of R that is compatible with these packages",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006#issuecomment-770272506:264,depend,dependencies,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006#issuecomment-770272506,1,['depend'],['dependencies']
Integrability,"This is not ready for merge -- I just want to see if tests pass with this configuration. There are still some unresolved vulnerabilities:. ```; [1/7] - pkg:maven/com.google.protobuf/protobuf-java@4.0.0-rc-2 - 3 vulnerabilities found!; [2/7] - pkg:maven/log4j/log4j@1.2.17 - 6 vulnerabilities found!; [3/7] - pkg:maven/org.codehaus.janino/janino@3.1.9 - 1 vulnerability found!; [4/7] - pkg:maven/net.minidev/json-smart@2.4.7 - 1 vulnerability found!; [5/7] - pkg:maven/org.codehaus.jettison/jettison@1.1 - 3 vulnerabilities found!; [6/7] - pkg:maven/org.eclipse.jetty/jetty-util@9.4.48.v20220622 - 1 vulnerability found!; [7/7] - pkg:maven/org.eclipse.jetty/jetty-http@9.4.48.v20220622 - 1 vulnerability found!; ```. Some of these we may be unable to resolve. Eg., the `protobuf-java` version in this branch appears to be the most recent one, but still has open vulnerabilities filed against it. The ancient log4j 1.x version is used by two of our dependencies (`hdf5-java-bindings` and `spark-mllib_2.12`), and is the most recent version. Note that this is completely unrelated to the infamous log4j 2.x vulnerability, which was patched in GATK a long time ago.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8352#issuecomment-1581408853:947,depend,dependencies,947,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8352#issuecomment-1581408853,1,['depend'],['dependencies']
Integrability,"This is super interesting - the Java 11 integration tests that are failing in this last run are exactly the same tests that have been problematic on the Java 17 branch. I looked at the failing values that were being produced on that branch (which we've updated), and they're identical to the failing values seen here. Even on the Java 17 branch, there has been some inconsistency in the failures (they usually fail, but not always).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8102#issuecomment-1329162240:40,integrat,integration,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8102#issuecomment-1329162240,1,['integrat'],['integration']
Integrability,This last set of changes is dependent on https://github.com/broadinstitute/barclay/pull/17. Once that's reviewed we'll need to snapshot or release and upgrade to Barclay.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271290203:28,depend,dependent,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271290203,1,['depend'],['dependent']
Integrability,"This likely has to do with your spark configuration. Check on the Spark job's progress through the web interface, which should be something like http://<driver_address>:4040 (see https://spark.apache.org/docs/latest/monitoring.html). . If your BAM is very small, you can also try increasing the number of partitions by reducing --bamPartitionSize.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932:103,interface,interface,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932,1,['interface'],['interface']
Integrability,"This occurs when there is an issue with the coding sequence for a given transcript in Gencode. It's a problem with the Gencode data itself. I would prefer to keep as an error so the user is more likely to see it. There is some work to be done here, though - the error message should also contain a description of an exception that was caught to produce this log statement.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4882#issuecomment-396389331:268,message,message,268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4882#issuecomment-396389331,1,['message'],['message']
Integrability,"This problem happens with the IndexFactory [methods](https://github.com/samtools/htsjdk/blob/912c28bec415c430b43515652ccaf13222b07e7b/src/main/java/htsjdk/tribble/index/IndexFactory.java#L285) that take a file. When an index is created this way, the first feature that gets returned by the [FeatureIterator](https://github.com/samtools/htsjdk/blob/912c28bec415c430b43515652ccaf13222b07e7b/src/main/java/htsjdk/tribble/index/IndexFactory.java#L401) and handed to the [indexer](https://github.com/samtools/htsjdk/blob/912c28bec415c430b43515652ccaf13222b07e7b/src/main/java/htsjdk/tribble/index/IndexFactory.java#L352) always has it's file offset as 0, even if its actually offset by a header. Whether or not the bogus index that gets generated actually works is dependent on the size of the header. When the index is created on the fly (while writing the file), the offsets are correct. The BED file issue is a slightly different problem (its first feature actually IS at offset 0), but the first feature is never returned.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2801#issuecomment-306678058:760,depend,dependent,760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2801#issuecomment-306678058,1,['depend'],['dependent']
Integrability,This release also errors out with a descriptive error message if the length of a field in the data lines does not match the length descriptor in the header - see https://github.com/broadinstitute/gatk/issues/5045.; Error out behavior as per [Laura's comment here](https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413667356),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-437140783:54,message,message,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-437140783,1,['message'],['message']
Integrability,"This seems like a compiler bug to me. It only produces a warning on some machines, and we're not sure which ones. It runs fine on travis which is running ubuntu 16.04 I think, and it runs fine on OSX. I'm not sure if producing the warning is the bug, or not producing the warning, but there's definitely a bug somewhere in one instance of the compiler. . You'll notice that the code it's referring to in the error message is NOT the code that's causing the issue, which is another manifestation of it's bugginess.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360212288:414,message,message,414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360212288,1,['message'],['message']
Integrability,"This seems like a lot of machinery (introducing two new types and a new method) just to hide the config file argument. What if we just mark it `@Hidden` (I know thats prohibited, but this is kind of a special case). The only reason it even exists is because we wanted it to appear in the command lines we display on output and embed in output files. If its `@Hidden` it will still be reflected there when it's used, but it wouldn't be displayed in tool help/usage. Its already always displayed in help as an arg for the gatk wrapper.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371570897:525,wrap,wrapper,525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371570897,1,['wrap'],['wrapper']
Integrability,"This seems to be caused by an incompatible minor update of a transitive dependency called typing_extensions that is installed as part of pymc3. . The maintainers say that their release shouldn't be picked up by package managers because it contains an instruction to only be used in 3.7+. Our version of conda is picking it up anyway though and apparently doesn't understand their package files. . It's possible upgrading the conda version in the base docker will fix this problem, but as far as I can tell we're using the most recent release of miniconda that supports python 3.6. . Ideally we can peg the version of typing_extensions to 4.1.1 somehow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7800#issuecomment-1104432972:72,depend,dependency,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7800#issuecomment-1104432972,1,['depend'],['dependency']
Integrability,"This should be doable, if not in the integration test framework, then in the new testing framework @KevinCLydon is working on.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6013#issuecomment-581493620:37,integrat,integration,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6013#issuecomment-581493620,1,['integrat'],['integration']
Integrability,This should be fixed in the next release as we are now on Picard 2.25.4 in master via #7255. If you need a docker build with an updated picard dependency I would suggest checking out our nightly builds gs://gatk-nightly-builds which should have an up-to-date version of master soon or simply waiting for the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7254#issuecomment-841405791:143,depend,dependency,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7254#issuecomment-841405791,2,['depend'],['dependency']
Integrability,This should be in the [gatk-bwamem-jni](https://github.com/broadinstitute/gatk-bwamem-jni) dependency. Maybe the artifact is not correctly packaged...but it is in the [gradle.build](https://github.com/broadinstitute/gatk/blob/master/build.gradle#L198)...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311602501:91,depend,dependency,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311602501,1,['depend'],['dependency']
Integrability,"This sounds like a good idea, but it might be tricky because much of the file reading is likely done by native code that we're just wrapping. We could do something like automatically downloading and caching the file locally and handing the cached version to the native library. Would that suit your needs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3178#issuecomment-314147710:132,wrap,wrapping,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3178#issuecomment-314147710,1,['wrap'],['wrapping']
Integrability,This was evil and insidious and we should probably file a spark bug to produce a better error message...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296821517:94,message,message,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296821517,1,['message'],['message']
Integrability,Those warning messages are totally fine. Not all variant contexts contain those 2 annotations therefore they are not counted against those sites but other parameters are counted. The results also shows that your filtering is working and variants are marked as expected.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8964#issuecomment-2312156979:14,message,messages,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8964#issuecomment-2312156979,1,['message'],['messages']
Integrability,"To add some commentary to why this is happening: It looks like multiple threads are hitting this line simultaneously and based on the overload of `ArrayList.add()` this error could be triggered by multiple calls to `ensureCapacityInternal()` inside the add method:; ```; final List<ReadsPathDataSource> readSources = new ArrayList<>(threads);; final ThreadLocal<ReadsPathDataSource> threadReadSource = ThreadLocal.withInitial(; () -> {; final ReadsPathDataSource result = new ReadsPathDataSource(readArguments.getReadPaths(), factory);; readSources.add(result);; return result;; });; ```; The fix should be simple you just have to make sure ti synchronize the initialization or swap out the readSources object to one that is itself thread safe. @vruano",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7403#issuecomment-899732721:644,synchroniz,synchronize,644,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7403#issuecomment-899732721,2,['synchroniz'],['synchronize']
Integrability,"To add, just in case it wasn't clear, note that this is almost certainly overkill for most somatic applications. However, if this is going to double as a more lightweight germline pipeline (as it is for the time being, as we are using some of the results to prototype SV integration), it might be worthwhile.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386269562:271,integrat,integration,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386269562,2,['integrat'],['integration']
Integrability,"To clarify this ticket: in `GATKTool.initializeReads()`, just check `readArguments.getReadFiles()` for files ending with a cram extension (should see if there's a canonical method in htsjdk for checking whether a file is cram) -- if you find any and we don't have a reference according to `hasReference()`, throw a `UserException` with a clear error message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/673#issuecomment-125265449:350,message,message,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/673#issuecomment-125265449,1,['message'],['message']
Integrability,"To clarify what needs to be done here:. -Add a new `--javaOptions` argument to `gatk-launch`. -When running with a packaged local jar, the value of `--javaOptions` should be injected into the command line built by `formatLocalJarCommand()`. -When running with the ""wrapper script"" (as a result of building with `./gradlew installDist` instead of `./gradlew localJar`), propagate the value of `--javaOptions` to the `JAVA_OPTS` environment variable the wrapper script expects. You can inspect the wrapper script itself by running `./gradlew installDist` and then examining `build/install/gatk/bin/gatk`. -When running on Spark, you'll need to add the `--javaOptions` to `spark.driver.extraJavaOptions` and `spark.executor.extraJavaOptions`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2694#issuecomment-305007868:174,inject,injected,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2694#issuecomment-305007868,4,"['inject', 'wrap']","['injected', 'wrapper']"
Integrability,"To clarify, the tests are being run. It appears to be a bug in how we have configured the jacocoTestReport job that gets executed inside the docker image which seems to result some missing xml files that codeCoverage uses to build its reports. Since we have our integration and cloud tests outside of the docker image the coverage didn't drop to zero. I am looking into reconfiguring the jacocoTestReport task to behave correctly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5001#issuecomment-404629551:262,integrat,integration,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5001#issuecomment-404629551,1,['integrat'],['integration']
Integrability,"To confirm, it works on Chr01 but nothing else? And can you list the; files/folders in the Chr01 genomicsdb versus say Chr02?. On Thu, Jul 27, 2023 at 6:44 PM ShirelyI ***@***.***> wrote:. > Hi mlathara,; > it doesn't work at all chromosomes but chr01,; > the contig description from the fasta is as follows and I only analyse the; > Chr***; > [image: image]; > <https://user-images.githubusercontent.com/103233242/256700966-838657ef-5f16-4c47-af85-ee89aeef3ffb.png>; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8415#issuecomment-1654851989>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHXPS2DRGZCEB36P3CS5YFLXSMKODANCNFSM6AAAAAA2IOM3Y4>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-1655054908:789,Message,Message,789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-1655054908,1,['Message'],['Message']
Integrability,"To summarize current state of discussions - we're going to have 3 repos, as originally planned (1 for the interfaces and 2 for Intel and IBM implementations, respectively). There will be a bit code duplication but many other aspects (some technical, some organizational) are massively simplified by such architecture. . @droazen @lbergelson @gspowley @paolonarvaez @frank-y-liu @t-ogasawara - please use this ticket to comment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-216545820:106,interface,interfaces,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-216545820,1,['interface'],['interfaces']
Integrability,Tools run. These error/warn messages are new.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-297048203:28,message,messages,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-297048203,1,['message'],['messages']
Integrability,"TrainVariantAnnotationsModel:. Trains a model for scoring variant calls based on site-level annotations. TODOs:. - [x] Integration tests. Exact-match tests for (non-exhaustive) configurations given by the Cartesian product of the following options:; * non-allele-specific vs. allele-specific; * SNP-only vs. SNP+INDEL (for both of these options, we use extracted annotations that contain both SNP and INDEL variants as input); * positive (training with *.annot.hdf5) vs. positive-unlabeled (training with *.annot.hdf5 and *.unlabeled.annot.hdf5); * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Refactor main code block for model training; it's a bit monolithic and procedural now.; - [x] Decide on behavior for ill-behaved annotations. E.g., all missing, zero variance. Future work:. - [ ] We could allow subsetting of annotations here, which might allow for easier treatment of ill-behaved annotations. However, I'd say enabling workflows where the set of annotations is fixed is the priority.; - [ ] We could do positive-unlabeled training more rigorously or iteratively. Right now, we essentially do a single iteration to determine negative data. This could perhaps be preceded by a round of refactoring to clean up model training and make it less procedural.; - [ ] Automatic threshold tuning could be built into the tool, see #7711. We'd probably have to introduce a ""validation"" label. Perhaps it makes sense to keep this sort of thing at the workflow level?; - [ ] In the positive-negative framework enforced by the Java code in this tool, a ""model"" is anything that assigns a score, we fit two models to different subsets of the data, and then take the difference of the two scores. While the python backend does give some freedom to specify a model, future developers may want",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369:119,Integrat,Integration,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369,1,['Integrat'],['Integration']
Integrability,Travis reported job failures from build [27940](https://travis-ci.com/broadinstitute/gatk/builds/135299602); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [27940.1](https://travis-ci.com/broadinstitute/gatk/jobs/253708933) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.1/tests/test/index.html) |; | cloud | openjdk11 | [27940.14](https://travis-ci.com/broadinstitute/gatk/jobs/253708946) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.14/tests/test/index.html) |; | integration | oraclejdk8 | [27940.11](https://travis-ci.com/broadinstitute/gatk/jobs/253708943) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.11/tests/test/index.html) |; | integration | openjdk11 | [27940.12](https://travis-ci.com/broadinstitute/gatk/jobs/253708944) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.12/tests/test/index.html) |; | integration | openjdk8 | [27940.2](https://travis-ci.com/broadinstitute/gatk/jobs/253708934) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550409459:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550409459,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [27949](https://travis-ci.com/broadinstitute/gatk/builds/135327240); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27949.11](https://travis-ci.com/broadinstitute/gatk/jobs/253773862) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27949.11/tests/test/index.html) |; | integration | openjdk11 | [27949.12](https://travis-ci.com/broadinstitute/gatk/jobs/253773863) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27949.12/tests/test/index.html) |; | integration | openjdk8 | [27949.2](https://travis-ci.com/broadinstitute/gatk/jobs/253773853) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27949.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550484410:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550484410,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [27951](https://travis-ci.com/broadinstitute/gatk/builds/135328116); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27951.11](https://travis-ci.com/broadinstitute/gatk/jobs/253775865) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27951.11/tests/test/index.html) |; | integration | openjdk11 | [27951.12](https://travis-ci.com/broadinstitute/gatk/jobs/253775866) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27951.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488826:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488826,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [27953](https://travis-ci.com/broadinstitute/gatk/builds/135328325); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [27953.12](https://travis-ci.com/broadinstitute/gatk/jobs/253776493) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27953.12/tests/test/index.html) |; | integration | oraclejdk8 | [27953.11](https://travis-ci.com/broadinstitute/gatk/jobs/253776492) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27953.11/tests/test/index.html) |; | integration | openjdk8 | [27953.2](https://travis-ci.com/broadinstitute/gatk/jobs/253776483) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27953.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488386:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488386,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [27955](https://travis-ci.com/broadinstitute/gatk/builds/135328649); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27955.11](https://travis-ci.com/broadinstitute/gatk/jobs/253777172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27955.11/tests/test/index.html) |; | integration | openjdk11 | [27955.12](https://travis-ci.com/broadinstitute/gatk/jobs/253777173) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27955.12/tests/test/index.html) |; | integration | openjdk8 | [27955.2](https://travis-ci.com/broadinstitute/gatk/jobs/253777162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27955.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550487300:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550487300,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [27983](https://travis-ci.com/broadinstitute/gatk/builds/135478554); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27983.11](https://travis-ci.com/broadinstitute/gatk/jobs/254104520) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27983.11/tests/test/index.html) |; | integration | openjdk11 | [27983.12](https://travis-ci.com/broadinstitute/gatk/jobs/254104521) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27983.12/tests/test/index.html) |; | integration | openjdk8 | [27983.2](https://travis-ci.com/broadinstitute/gatk/jobs/254104511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27983.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-551166492:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-551166492,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28043](https://travis-ci.com/broadinstitute/gatk/builds/137035017); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28043.11](https://travis-ci.com/broadinstitute/gatk/jobs/257824467) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28043.11/tests/test/index.html) |; | integration | openjdk11 | [28043.12](https://travis-ci.com/broadinstitute/gatk/jobs/257824468) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28043.12/tests/test/index.html) |; | integration | openjdk8 | [28043.2](https://travis-ci.com/broadinstitute/gatk/jobs/257824445) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28043.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-555111252:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-555111252,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28083](https://travis-ci.com/broadinstitute/gatk/builds/137456935); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28083.11](https://travis-ci.com/broadinstitute/gatk/jobs/258764558) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28083.11/tests/test/index.html) |; | integration | openjdk11 | [28083.12](https://travis-ci.com/broadinstitute/gatk/jobs/258764559) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28083.12/tests/test/index.html) |; | integration | openjdk8 | [28083.2](https://travis-ci.com/broadinstitute/gatk/jobs/258764549) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28083.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-556381618:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-556381618,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28122](https://travis-ci.com/broadinstitute/gatk/builds/137698341); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28122.4](https://travis-ci.com/broadinstitute/gatk/jobs/259308339) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.4/tests/test/index.html) |; | cloud | openjdk8 | [28122.1](https://travis-ci.com/broadinstitute/gatk/jobs/259308336) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.1/tests/test/index.html) |; | cloud | openjdk11 | [28122.14](https://travis-ci.com/broadinstitute/gatk/jobs/259308349) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.14/tests/test/index.html) |; | unit | openjdk11 | [28122.13](https://travis-ci.com/broadinstitute/gatk/jobs/259308348) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.13/tests/test/index.html) |; | integration | oraclejdk8 | [28122.11](https://travis-ci.com/broadinstitute/gatk/jobs/259308346) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.11/tests/test/index.html) |; | unit | openjdk8 | [28122.3](https://travis-ci.com/broadinstitute/gatk/jobs/259308338) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.3/tests/test/index.html) |; | integration | openjdk11 | [28122.12](https://travis-ci.com/broadinstitute/gatk/jobs/259308347) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.12/tests/test/index.html) |; | integration | openjdk8 | [28122.2](https://travis-ci.com/broadinstitute/gatk/jobs/259308337) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557361260:1052,integrat,integration,1052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557361260,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28130](https://travis-ci.com/broadinstitute/gatk/builds/137807694); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [28130.1](https://travis-ci.com/broadinstitute/gatk/jobs/259581190) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.1/tests/test/index.html) |; | cloud | openjdk11 | [28130.14](https://travis-ci.com/broadinstitute/gatk/jobs/259581203) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.14/tests/test/index.html) |; | variantcalling | openjdk8 | [28130.4](https://travis-ci.com/broadinstitute/gatk/jobs/259581193) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.4/tests/test/index.html) |; | integration | oraclejdk8 | [28130.11](https://travis-ci.com/broadinstitute/gatk/jobs/259581200) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.11/tests/test/index.html) |; | integration | openjdk11 | [28130.12](https://travis-ci.com/broadinstitute/gatk/jobs/259581201) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.12/tests/test/index.html) |; | integration | openjdk8 | [28130.2](https://travis-ci.com/broadinstitute/gatk/jobs/259581191) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557639788:845,integrat,integration,845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557639788,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28139](https://travis-ci.com/broadinstitute/gatk/builds/137849676); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28139.13](https://travis-ci.com/broadinstitute/gatk/jobs/259674809) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.13/tests/test/index.html) |; | integration | oraclejdk8 | [28139.11](https://travis-ci.com/broadinstitute/gatk/jobs/259674807) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.11/tests/test/index.html) |; | integration | openjdk11 | [28139.12](https://travis-ci.com/broadinstitute/gatk/jobs/259674808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.12/tests/test/index.html) |; | variantcalling | openjdk8 | [28139.4](https://travis-ci.com/broadinstitute/gatk/jobs/259674800) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.4/tests/test/index.html) |; | unit | openjdk8 | [28139.3](https://travis-ci.com/broadinstitute/gatk/jobs/259674799) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.3/tests/test/index.html) |; | integration | openjdk8 | [28139.2](https://travis-ci.com/broadinstitute/gatk/jobs/259674798) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557713113:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557713113,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28143](https://travis-ci.com/broadinstitute/gatk/builds/137902492); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28143.11](https://travis-ci.com/broadinstitute/gatk/jobs/259801266) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.11/tests/test/index.html) |; | unit | openjdk11 | [28143.13](https://travis-ci.com/broadinstitute/gatk/jobs/259801268) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.13/tests/test/index.html) |; | integration | openjdk11 | [28143.12](https://travis-ci.com/broadinstitute/gatk/jobs/259801267) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.12/tests/test/index.html) |; | unit | openjdk8 | [28143.3](https://travis-ci.com/broadinstitute/gatk/jobs/259801258) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.3/tests/test/index.html) |; | integration | openjdk8 | [28143.2](https://travis-ci.com/broadinstitute/gatk/jobs/259801257) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557830936:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557830936,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28145](https://travis-ci.com/broadinstitute/gatk/builds/137904160); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28145.13](https://travis-ci.com/broadinstitute/gatk/jobs/259805318) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.13/tests/test/index.html) |; | integration | oraclejdk8 | [28145.11](https://travis-ci.com/broadinstitute/gatk/jobs/259805316) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.11/tests/test/index.html) |; | integration | openjdk11 | [28145.12](https://travis-ci.com/broadinstitute/gatk/jobs/259805317) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.12/tests/test/index.html) |; | unit | openjdk8 | [28145.3](https://travis-ci.com/broadinstitute/gatk/jobs/259805308) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.3/tests/test/index.html) |; | integration | openjdk8 | [28145.2](https://travis-ci.com/broadinstitute/gatk/jobs/259805307) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557834045:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557834045,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28162](https://travis-ci.com/broadinstitute/gatk/builds/138106843); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28162.13](https://travis-ci.com/broadinstitute/gatk/jobs/260296087) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.13/tests/test/index.html) |; | integration | oraclejdk8 | [28162.11](https://travis-ci.com/broadinstitute/gatk/jobs/260296085) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.11/tests/test/index.html) |; | integration | openjdk11 | [28162.12](https://travis-ci.com/broadinstitute/gatk/jobs/260296086) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.12/tests/test/index.html) |; | unit | openjdk8 | [28162.3](https://travis-ci.com/broadinstitute/gatk/jobs/260296076) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.3/tests/test/index.html) |; | integration | openjdk8 | [28162.2](https://travis-ci.com/broadinstitute/gatk/jobs/260296074) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558291603:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558291603,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28165](https://travis-ci.com/broadinstitute/gatk/builds/138115218); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28165.11](https://travis-ci.com/broadinstitute/gatk/jobs/260315679) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28165.11/tests/test/index.html) |; | integration | openjdk11 | [28165.12](https://travis-ci.com/broadinstitute/gatk/jobs/260315680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28165.12/tests/test/index.html) |; | integration | openjdk8 | [28165.2](https://travis-ci.com/broadinstitute/gatk/jobs/260315669) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28165.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558314958:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558314958,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28167](https://travis-ci.com/broadinstitute/gatk/builds/138118033); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [28167.12](https://travis-ci.com/broadinstitute/gatk/jobs/260322542) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28167.12/tests/test/index.html) |; | integration | oraclejdk8 | [28167.11](https://travis-ci.com/broadinstitute/gatk/jobs/260322540) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28167.11/tests/test/index.html) |; | integration | openjdk8 | [28167.2](https://travis-ci.com/broadinstitute/gatk/jobs/260322530) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28167.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-558324081:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-558324081,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28277](https://travis-ci.com/broadinstitute/gatk/builds/139364724); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [28277.12](https://travis-ci.com/broadinstitute/gatk/jobs/263099166) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28277.12/tests/test/index.html) |; | integration | oraclejdk8 | [28277.11](https://travis-ci.com/broadinstitute/gatk/jobs/263099165) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28277.11/tests/test/index.html) |; | integration | openjdk8 | [28277.2](https://travis-ci.com/broadinstitute/gatk/jobs/263099156) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28277.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-561730330:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-561730330,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:424,integrat,integration,424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28535](https://travis-ci.com/broadinstitute/gatk/builds/143616436); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28535.4](https://travis-ci.com/broadinstitute/gatk/jobs/273613592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.4/tests/test/index.html) |; | integration | openjdk11 | [28535.12](https://travis-ci.com/broadinstitute/gatk/jobs/273613600) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.12/tests/test/index.html) |; | integration | oraclejdk8 | [28535.11](https://travis-ci.com/broadinstitute/gatk/jobs/273613599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.11/tests/test/index.html) |; | integration | openjdk8 | [28535.2](https://travis-ci.com/broadinstitute/gatk/jobs/273613590) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572218616:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572218616,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28547](https://travis-ci.com/broadinstitute/gatk/builds/143771509); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28547.11](https://travis-ci.com/broadinstitute/gatk/jobs/273966397) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.11/tests/test/index.html) |; | variantcalling | openjdk8 | [28547.4](https://travis-ci.com/broadinstitute/gatk/jobs/273966388) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.4/tests/test/index.html) |; | integration | openjdk11 | [28547.12](https://travis-ci.com/broadinstitute/gatk/jobs/273966398) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.12/tests/test/index.html) |; | integration | openjdk8 | [28547.2](https://travis-ci.com/broadinstitute/gatk/jobs/273966386) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572677906:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572677906,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28550](https://travis-ci.com/broadinstitute/gatk/builds/143787017); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28550.4](https://travis-ci.com/broadinstitute/gatk/jobs/274003454) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.4/tests/test/index.html) |; | integration | oraclejdk8 | [28550.11](https://travis-ci.com/broadinstitute/gatk/jobs/274003461) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.11/tests/test/index.html) |; | integration | openjdk11 | [28550.12](https://travis-ci.com/broadinstitute/gatk/jobs/274003462) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.12/tests/test/index.html) |; | unit | openjdk8 | [28550.3](https://travis-ci.com/broadinstitute/gatk/jobs/274003453) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.3/tests/test/index.html) |; | integration | openjdk8 | [28550.2](https://travis-ci.com/broadinstitute/gatk/jobs/274003452) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572729169:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572729169,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28552](https://travis-ci.com/broadinstitute/gatk/builds/143787227); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28552.11](https://travis-ci.com/broadinstitute/gatk/jobs/274004057) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.11/tests/test/index.html) |; | variantcalling | openjdk8 | [28552.4](https://travis-ci.com/broadinstitute/gatk/jobs/274004050) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.4/tests/test/index.html) |; | integration | openjdk11 | [28552.12](https://travis-ci.com/broadinstitute/gatk/jobs/274004058) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.12/tests/test/index.html) |; | integration | openjdk8 | [28552.2](https://travis-ci.com/broadinstitute/gatk/jobs/274004048) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572728974:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572728974,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28553](https://travis-ci.com/broadinstitute/gatk/builds/143787525); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28553.4](https://travis-ci.com/broadinstitute/gatk/jobs/274004800) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.4/tests/test/index.html) |; | integration | oraclejdk8 | [28553.11](https://travis-ci.com/broadinstitute/gatk/jobs/274004808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.11/tests/test/index.html) |; | integration | openjdk11 | [28553.12](https://travis-ci.com/broadinstitute/gatk/jobs/274004810) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.12/tests/test/index.html) |; | integration | openjdk8 | [28553.2](https://travis-ci.com/broadinstitute/gatk/jobs/274004798) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572730586:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572730586,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28716](https://travis-ci.com/broadinstitute/gatk/builds/145422010); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28716.11](https://travis-ci.com/broadinstitute/gatk/jobs/278054948) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28716.11/tests/test/index.html) |; | integration | openjdk11 | [28716.12](https://travis-ci.com/broadinstitute/gatk/jobs/278054949) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28716.12/tests/test/index.html) |; | integration | openjdk8 | [28716.2](https://travis-ci.com/broadinstitute/gatk/jobs/278054938) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28716.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6401#issuecomment-576845315:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6401#issuecomment-576845315,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28795](https://travis-ci.com/broadinstitute/gatk/builds/145954484); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28795.4](https://travis-ci.com/broadinstitute/gatk/jobs/279782040) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.4/tests/test/index.html) |; | integration | oraclejdk8 | [28795.11](https://travis-ci.com/broadinstitute/gatk/jobs/279782047) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.11/tests/test/index.html) |; | unit | openjdk8 | [28795.3](https://travis-ci.com/broadinstitute/gatk/jobs/279782039) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.3/tests/test/index.html) |; | integration | openjdk8 | [28795.2](https://travis-ci.com/broadinstitute/gatk/jobs/279782038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-578185465:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-578185465,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [28808](https://travis-ci.com/broadinstitute/gatk/builds/146011126); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28808.11](https://travis-ci.com/broadinstitute/gatk/jobs/279909754) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28808.11/tests/test/index.html) |; | integration | openjdk11 | [28808.12](https://travis-ci.com/broadinstitute/gatk/jobs/279909755) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28808.12/tests/test/index.html) |; | integration | openjdk8 | [28808.2](https://travis-ci.com/broadinstitute/gatk/jobs/279909745) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28808.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6417#issuecomment-578310009:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6417#issuecomment-578310009,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28853](https://travis-ci.com/broadinstitute/gatk/builds/146340414); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [28853.2](https://travis-ci.com/broadinstitute/gatk/jobs/280854279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28853.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-579107366:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-579107366,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [28922](https://travis-ci.com/broadinstitute/gatk/builds/146980249); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28922.11](https://travis-ci.com/broadinstitute/gatk/jobs/282436321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28922.11/tests/test/index.html) |; | integration | openjdk11 | [28922.12](https://travis-ci.com/broadinstitute/gatk/jobs/282436322) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28922.12/tests/test/index.html) |; | integration | openjdk8 | [28922.2](https://travis-ci.com/broadinstitute/gatk/jobs/282436309) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28922.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-580903507:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-580903507,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28928](https://travis-ci.com/broadinstitute/gatk/builds/146990377); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28928.11](https://travis-ci.com/broadinstitute/gatk/jobs/282468192) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.11/tests/test/index.html) |; | variantcalling | openjdk8 | [28928.4](https://travis-ci.com/broadinstitute/gatk/jobs/282468185) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.4/tests/test/index.html) |; | unit | openjdk11 | [28928.13](https://travis-ci.com/broadinstitute/gatk/jobs/282468194) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.13/tests/test/index.html) |; | integration | openjdk11 | [28928.12](https://travis-ci.com/broadinstitute/gatk/jobs/282468193) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.12/tests/test/index.html) |; | unit | openjdk8 | [28928.3](https://travis-ci.com/broadinstitute/gatk/jobs/282468184) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.3/tests/test/index.html) |; | integration | openjdk8 | [28928.2](https://travis-ci.com/broadinstitute/gatk/jobs/282468183) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-580926214:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-580926214,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28947](https://travis-ci.com/broadinstitute/gatk/builds/147248704); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28947.11](https://travis-ci.com/broadinstitute/gatk/jobs/283088574) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28947.11/tests/test/index.html) |; | integration | openjdk11 | [28947.12](https://travis-ci.com/broadinstitute/gatk/jobs/283088576) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28947.12/tests/test/index.html) |; | integration | openjdk8 | [28947.2](https://travis-ci.com/broadinstitute/gatk/jobs/283088564) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28947.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-581541781:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-581541781,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28980](https://travis-ci.com/broadinstitute/gatk/builds/147447359); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [28980.12](https://travis-ci.com/broadinstitute/gatk/jobs/283563549) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28980.12/tests/test/index.html) |; | integration | openjdk8 | [28980.2](https://travis-ci.com/broadinstitute/gatk/jobs/283563537) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28980.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-582121672:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-582121672,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29013](https://travis-ci.com/broadinstitute/gatk/builds/147827421); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29013.11](https://travis-ci.com/broadinstitute/gatk/jobs/284497171) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29013.11/tests/test/index.html) |; | integration | openjdk11 | [29013.12](https://travis-ci.com/broadinstitute/gatk/jobs/284497172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29013.12/tests/test/index.html) |; | integration | openjdk8 | [29013.2](https://travis-ci.com/broadinstitute/gatk/jobs/284497162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29013.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583142673:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583142673,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29015](https://travis-ci.com/broadinstitute/gatk/builds/147828086); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29015.11](https://travis-ci.com/broadinstitute/gatk/jobs/284498893) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29015.11/tests/test/index.html) |; | integration | openjdk11 | [29015.12](https://travis-ci.com/broadinstitute/gatk/jobs/284498894) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29015.12/tests/test/index.html) |; | integration | openjdk8 | [29015.2](https://travis-ci.com/broadinstitute/gatk/jobs/284498882) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29015.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583143781:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583143781,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29059](https://travis-ci.com/broadinstitute/gatk/builds/148070808); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [29059.1](https://travis-ci.com/broadinstitute/gatk/jobs/285180550) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.1/tests/test/index.html) |; | cloud | openjdk11 | [29059.14](https://travis-ci.com/broadinstitute/gatk/jobs/285180563) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.14/tests/test/index.html) |; | integration | oraclejdk8 | [29059.11](https://travis-ci.com/broadinstitute/gatk/jobs/285180560) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.11/tests/test/index.html) |; | integration | openjdk11 | [29059.12](https://travis-ci.com/broadinstitute/gatk/jobs/285180561) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.12/tests/test/index.html) |; | integration | openjdk8 | [29059.2](https://travis-ci.com/broadinstitute/gatk/jobs/285180551) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-583802851:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-583802851,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29063](https://travis-ci.com/broadinstitute/gatk/builds/148075396); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [29063.5](https://travis-ci.com/broadinstitute/gatk/jobs/285190126) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29063.5/tests/test/index.html) |; | unit | openjdk8 | [29063.3](https://travis-ci.com/broadinstitute/gatk/jobs/285190124) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29063.3/tests/test/index.html) |; | integration | openjdk8 | [29063.2](https://travis-ci.com/broadinstitute/gatk/jobs/285190123) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29063.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6448#issuecomment-583812428:628,integrat,integration,628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6448#issuecomment-583812428,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [29125](https://travis-ci.com/broadinstitute/gatk/builds/148726118); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [29125.5](https://travis-ci.com/broadinstitute/gatk/jobs/286704576) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.5/tests/test/index.html) |; | variantcalling | openjdk8 | [29125.4](https://travis-ci.com/broadinstitute/gatk/jobs/286704575) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.4/tests/test/index.html) |; | unit | openjdk8 | [29125.3](https://travis-ci.com/broadinstitute/gatk/jobs/286704574) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.3/tests/test/index.html) |; | integration | openjdk8 | [29125.2](https://travis-ci.com/broadinstitute/gatk/jobs/286704573) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6445#issuecomment-585577409:842,integrat,integration,842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6445#issuecomment-585577409,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [29157](https://travis-ci.com/broadinstitute/gatk/builds/148868090); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29157.12](https://travis-ci.com/broadinstitute/gatk/jobs/287031748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29157.12/tests/test/index.html) |; | unit | openjdk11 | [29157.14](https://travis-ci.com/broadinstitute/gatk/jobs/287031750) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29157.14/tests/test/index.html) |; | integration | openjdk11 | [29157.13](https://travis-ci.com/broadinstitute/gatk/jobs/287031749) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29157.13/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6454#issuecomment-586001111:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6454#issuecomment-586001111,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29224](https://travis-ci.com/broadinstitute/gatk/builds/149883140); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29224.12](https://travis-ci.com/broadinstitute/gatk/jobs/289430111) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.12/tests/test/index.html) |; | unit | openjdk11 | [29224.14](https://travis-ci.com/broadinstitute/gatk/jobs/289430113) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29224.4](https://travis-ci.com/broadinstitute/gatk/jobs/289430103) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.4/tests/test/index.html) |; | integration | openjdk11 | [29224.13](https://travis-ci.com/broadinstitute/gatk/jobs/289430112) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.13/tests/test/index.html) |; | integration | openjdk8 | [29224.2](https://travis-ci.com/broadinstitute/gatk/jobs/289430101) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-589296062:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-589296062,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29238](https://travis-ci.com/broadinstitute/gatk/builds/150105026); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29238.14](https://travis-ci.com/broadinstitute/gatk/jobs/289940648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.14/tests/test/index.html) |; | integration | oraclejdk8 | [29238.12](https://travis-ci.com/broadinstitute/gatk/jobs/289940646) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.12/tests/test/index.html) |; | unit | openjdk8 | [29238.3](https://travis-ci.com/broadinstitute/gatk/jobs/289940637) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.3/tests/test/index.html) |; | integration | openjdk11 | [29238.13](https://travis-ci.com/broadinstitute/gatk/jobs/289940647) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.13/tests/test/index.html) |; | integration | openjdk8 | [29238.2](https://travis-ci.com/broadinstitute/gatk/jobs/289940636) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6465#issuecomment-589866076:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6465#issuecomment-589866076,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29412](https://travis-ci.com/broadinstitute/gatk/builds/151996956); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29412.12](https://travis-ci.com/broadinstitute/gatk/jobs/295002547) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29412.12/tests/test/index.html) |; | integration | openjdk11 | [29412.13](https://travis-ci.com/broadinstitute/gatk/jobs/295002548) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29412.13/tests/test/index.html) |; | integration | openjdk8 | [29412.2](https://travis-ci.com/broadinstitute/gatk/jobs/295002537) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29412.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595341676:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595341676,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29414](https://travis-ci.com/broadinstitute/gatk/builds/151997149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29414.12](https://travis-ci.com/broadinstitute/gatk/jobs/295003009) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29414.12/tests/test/index.html) |; | integration | openjdk11 | [29414.13](https://travis-ci.com/broadinstitute/gatk/jobs/295003010) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29414.13/tests/test/index.html) |; | integration | openjdk8 | [29414.2](https://travis-ci.com/broadinstitute/gatk/jobs/295002999) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29414.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595342221:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595342221,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29416](https://travis-ci.com/broadinstitute/gatk/builds/152000044); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29416.12](https://travis-ci.com/broadinstitute/gatk/jobs/295015583) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29416.12/tests/test/index.html) |; | integration | openjdk11 | [29416.13](https://travis-ci.com/broadinstitute/gatk/jobs/295015584) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29416.13/tests/test/index.html) |; | integration | openjdk8 | [29416.2](https://travis-ci.com/broadinstitute/gatk/jobs/295015573) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29416.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595346842:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595346842,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29475](https://travis-ci.com/broadinstitute/gatk/builds/152932209); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29475.14](https://travis-ci.com/broadinstitute/gatk/jobs/297213806) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29475.14/tests/test/index.html) |; | unit | openjdk8 | [29475.3](https://travis-ci.com/broadinstitute/gatk/jobs/297213795) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29475.3/tests/test/index.html) |; | integration | openjdk8 | [29475.2](https://travis-ci.com/broadinstitute/gatk/jobs/297213794) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29475.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6498#issuecomment-598028671:629,integrat,integration,629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6498#issuecomment-598028671,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [29539](https://travis-ci.com/broadinstitute/gatk/builds/153610218); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29539.6](https://travis-ci.com/broadinstitute/gatk/jobs/298810423) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.6/tests/test/index.html) |; | python | openjdk8 | [29539.5](https://travis-ci.com/broadinstitute/gatk/jobs/298810422) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.5/tests/test/index.html) |; | variantcalling | openjdk8 | [29539.4](https://travis-ci.com/broadinstitute/gatk/jobs/298810421) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.4/tests/test/index.html) |; | unit | openjdk8 | [29539.3](https://travis-ci.com/broadinstitute/gatk/jobs/298810420) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.3/tests/test/index.html) |; | integration | openjdk8 | [29539.2](https://travis-ci.com/broadinstitute/gatk/jobs/298810419) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6507#issuecomment-599901701:1043,integrat,integration,1043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6507#issuecomment-599901701,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [29604](https://travis-ci.com/broadinstitute/gatk/builds/154146351); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29604.14](https://travis-ci.com/broadinstitute/gatk/jobs/300039008) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.14/tests/test/index.html) |; | integration | oraclejdk8 | [29604.12](https://travis-ci.com/broadinstitute/gatk/jobs/300039006) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.12/tests/test/index.html) |; | integration | openjdk11 | [29604.13](https://travis-ci.com/broadinstitute/gatk/jobs/300039007) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.13/tests/test/index.html) |; | integration | openjdk8 | [29604.2](https://travis-ci.com/broadinstitute/gatk/jobs/300038996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29682](https://travis-ci.com/broadinstitute/gatk/builds/154630422); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29682.12](https://travis-ci.com/broadinstitute/gatk/jobs/301258495) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29682.12/tests/test/index.html) |; | integration | openjdk11 | [29682.13](https://travis-ci.com/broadinstitute/gatk/jobs/301258496) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29682.13/tests/test/index.html) |; | integration | openjdk8 | [29682.2](https://travis-ci.com/broadinstitute/gatk/jobs/301258485) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29682.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602719177:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602719177,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29684](https://travis-ci.com/broadinstitute/gatk/builds/154637286); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29684.12](https://travis-ci.com/broadinstitute/gatk/jobs/301273903) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29684.12/tests/test/index.html) |; | integration | openjdk11 | [29684.13](https://travis-ci.com/broadinstitute/gatk/jobs/301273904) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29684.13/tests/test/index.html) |; | integration | openjdk8 | [29684.2](https://travis-ci.com/broadinstitute/gatk/jobs/301273893) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29684.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602739941:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602739941,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29685](https://travis-ci.com/broadinstitute/gatk/builds/154640951); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29685.12](https://travis-ci.com/broadinstitute/gatk/jobs/301286235) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29685.12/tests/test/index.html) |; | integration | openjdk11 | [29685.13](https://travis-ci.com/broadinstitute/gatk/jobs/301286236) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29685.13/tests/test/index.html) |; | integration | openjdk8 | [29685.2](https://travis-ci.com/broadinstitute/gatk/jobs/301286225) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29685.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602742528:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602742528,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29688](https://travis-ci.com/broadinstitute/gatk/builds/154646560); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29688.12](https://travis-ci.com/broadinstitute/gatk/jobs/301299237) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29688.12/tests/test/index.html) |; | integration | openjdk11 | [29688.13](https://travis-ci.com/broadinstitute/gatk/jobs/301299238) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29688.13/tests/test/index.html) |; | integration | openjdk8 | [29688.2](https://travis-ci.com/broadinstitute/gatk/jobs/301299227) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29688.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602759165:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602759165,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29804](https://travis-ci.com/broadinstitute/gatk/builds/156857783); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29804.6](https://travis-ci.com/broadinstitute/gatk/jobs/309185373) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.6/tests/test/index.html) |; | integration | oraclejdk8 | [29804.12](https://travis-ci.com/broadinstitute/gatk/jobs/309185379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.12/tests/test/index.html) |; | python | openjdk8 | [29804.5](https://travis-ci.com/broadinstitute/gatk/jobs/309185372) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.5/tests/test/index.html) |; | cloud | openjdk8 | [29804.1](https://travis-ci.com/broadinstitute/gatk/jobs/309185366) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.1/tests/test/index.html) |; | integration | openjdk11 | [29804.13](https://travis-ci.com/broadinstitute/gatk/jobs/309185380) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.13/tests/test/index.html) |; | cloud | openjdk11 | [29804.15](https://travis-ci.com/broadinstitute/gatk/jobs/309185382) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.15/tests/test/index.html) |; | integration | openjdk8 | [29804.2](https://travis-ci.com/broadinstitute/gatk/jobs/309185367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29804.4](https://travis-ci.com/broadinstitute/gatk/jobs/309185371) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606204666:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606204666,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29830](https://travis-ci.com/broadinstitute/gatk/builds/157356833); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29830.12](https://travis-ci.com/broadinstitute/gatk/jobs/310893235) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.12/tests/test/index.html) |; | integration | openjdk11 | [29830.13](https://travis-ci.com/broadinstitute/gatk/jobs/310893236) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.13/tests/test/index.html) |; | cloud | openjdk8 | [29830.1](https://travis-ci.com/broadinstitute/gatk/jobs/310893224) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.1/tests/test/index.html) |; | cloud | openjdk11 | [29830.15](https://travis-ci.com/broadinstitute/gatk/jobs/310893238) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.15/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606967314:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606967314,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29832](https://travis-ci.com/broadinstitute/gatk/builds/157562667); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29832.12](https://travis-ci.com/broadinstitute/gatk/jobs/311543311) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.12/tests/test/index.html) |; | integration | openjdk11 | [29832.13](https://travis-ci.com/broadinstitute/gatk/jobs/311543312) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.13/tests/test/index.html) |; | cloud | openjdk11 | [29832.15](https://travis-ci.com/broadinstitute/gatk/jobs/311543314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.15/tests/test/index.html) |; | cloud | openjdk8 | [29832.1](https://travis-ci.com/broadinstitute/gatk/jobs/311543300) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.1/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607339427:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607339427,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29837](https://travis-ci.com/broadinstitute/gatk/builds/157591374); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29837.12](https://travis-ci.com/broadinstitute/gatk/jobs/311628431) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29837.12/tests/test/index.html) |; | integration | openjdk11 | [29837.13](https://travis-ci.com/broadinstitute/gatk/jobs/311628432) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29837.13/tests/test/index.html) |; | integration | openjdk8 | [29837.2](https://travis-ci.com/broadinstitute/gatk/jobs/311628421) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29837.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607423696:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607423696,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29839](https://travis-ci.com/broadinstitute/gatk/builds/157593279); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29839.12](https://travis-ci.com/broadinstitute/gatk/jobs/311633272) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29839.12/tests/test/index.html) |; | integration | openjdk11 | [29839.13](https://travis-ci.com/broadinstitute/gatk/jobs/311633273) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29839.13/tests/test/index.html) |; | integration | openjdk8 | [29839.2](https://travis-ci.com/broadinstitute/gatk/jobs/311633261) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29839.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607427515:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607427515,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29842](https://travis-ci.com/broadinstitute/gatk/builds/157628713); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29842.12](https://travis-ci.com/broadinstitute/gatk/jobs/311717563) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29842.12/tests/test/index.html) |; | integration | openjdk11 | [29842.13](https://travis-ci.com/broadinstitute/gatk/jobs/311717564) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29842.13/tests/test/index.html) |; | integration | openjdk8 | [29842.2](https://travis-ci.com/broadinstitute/gatk/jobs/311717553) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29842.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607510446:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607510446,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29895](https://travis-ci.com/broadinstitute/gatk/builds/158261477); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29895.6](https://travis-ci.com/broadinstitute/gatk/jobs/313692987) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.6/tests/test/index.html) |; | python | openjdk8 | [29895.5](https://travis-ci.com/broadinstitute/gatk/jobs/313692986) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.5/tests/test/index.html) |; | integration | oraclejdk8 | [29895.12](https://travis-ci.com/broadinstitute/gatk/jobs/313692993) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.12/tests/test/index.html) |; | cloud | openjdk8 | [29895.1](https://travis-ci.com/broadinstitute/gatk/jobs/313692982) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.1/tests/test/index.html) |; | integration | openjdk11 | [29895.13](https://travis-ci.com/broadinstitute/gatk/jobs/313692994) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.13/tests/test/index.html) |; | cloud | openjdk11 | [29895.15](https://travis-ci.com/broadinstitute/gatk/jobs/313692996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.15/tests/test/index.html) |; | integration | openjdk8 | [29895.2](https://travis-ci.com/broadinstitute/gatk/jobs/313692983) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29895.4](https://travis-ci.com/broadinstitute/gatk/jobs/313692985) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608562413:625,integrat,integration,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608562413,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29897](https://travis-ci.com/broadinstitute/gatk/builds/158264975); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [29897.5](https://travis-ci.com/broadinstitute/gatk/jobs/313702266) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.5/tests/test/index.html) |; | integration | oraclejdk8 | [29897.12](https://travis-ci.com/broadinstitute/gatk/jobs/313702273) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.12/tests/test/index.html) |; | cloud | openjdk8 | [29897.1](https://travis-ci.com/broadinstitute/gatk/jobs/313702262) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.1/tests/test/index.html) |; | integration | openjdk11 | [29897.13](https://travis-ci.com/broadinstitute/gatk/jobs/313702274) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.13/tests/test/index.html) |; | integration | openjdk8 | [29897.2](https://travis-ci.com/broadinstitute/gatk/jobs/313702263) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.2/tests/test/index.html) |; | cloud | openjdk11 | [29897.15](https://travis-ci.com/broadinstitute/gatk/jobs/313702276) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.15/tests/test/index.html) |; | variantcalling | openjdk8 | [29897.4](https://travis-ci.com/broadinstitute/gatk/jobs/313702265) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608574955:424,integrat,integration,424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608574955,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29900](https://travis-ci.com/broadinstitute/gatk/builds/158267113); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29900.6](https://travis-ci.com/broadinstitute/gatk/jobs/313708020) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.6/tests/test/index.html) |; | integration | oraclejdk8 | [29900.12](https://travis-ci.com/broadinstitute/gatk/jobs/313708026) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.12/tests/test/index.html) |; | integration | openjdk11 | [29900.13](https://travis-ci.com/broadinstitute/gatk/jobs/313708027) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.13/tests/test/index.html) |; | cloud | openjdk8 | [29900.1](https://travis-ci.com/broadinstitute/gatk/jobs/313708015) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.1/tests/test/index.html) |; | integration | openjdk8 | [29900.2](https://travis-ci.com/broadinstitute/gatk/jobs/313708016) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.2/tests/test/index.html) |; | cloud | openjdk11 | [29900.15](https://travis-ci.com/broadinstitute/gatk/jobs/313708029) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.15/tests/test/index.html) |; | variantcalling | openjdk8 | [29900.4](https://travis-ci.com/broadinstitute/gatk/jobs/313708018) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608580670:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608580670,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29984](https://travis-ci.com/broadinstitute/gatk/builds/159673754); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29984.6](https://travis-ci.com/broadinstitute/gatk/jobs/317851324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.6/tests/test/index.html) |; | python | openjdk8 | [29984.5](https://travis-ci.com/broadinstitute/gatk/jobs/317851323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.5/tests/test/index.html) |; | integration | oraclejdk8 | [29984.12](https://travis-ci.com/broadinstitute/gatk/jobs/317851330) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.12/tests/test/index.html) |; | integration | openjdk11 | [29984.13](https://travis-ci.com/broadinstitute/gatk/jobs/317851331) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.13/tests/test/index.html) |; | cloud | openjdk8 | [29984.1](https://travis-ci.com/broadinstitute/gatk/jobs/317851319) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.1/tests/test/index.html) |; | cloud | openjdk11 | [29984.15](https://travis-ci.com/broadinstitute/gatk/jobs/317851333) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.15/tests/test/index.html) |; | unit | openjdk11 | [29984.14](https://travis-ci.com/broadinstitute/gatk/jobs/317851332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.14/tests/test/index.html) |; | integration | openjdk8 | [29984.2](https://travis-ci.com/broadinstitute/gatk/jobs/317851320) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29984.4](https://travis-ci.com/broadinstitute/gatk/jobs/317851322) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380:625,integrat,integration,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29988](https://travis-ci.com/broadinstitute/gatk/builds/159678058); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29988.6](https://travis-ci.com/broadinstitute/gatk/jobs/317861684) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.6/tests/test/index.html) |; | integration | oraclejdk8 | [29988.12](https://travis-ci.com/broadinstitute/gatk/jobs/317861697) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.12/tests/test/index.html) |; | python | openjdk8 | [29988.5](https://travis-ci.com/broadinstitute/gatk/jobs/317861683) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.5/tests/test/index.html) |; | integration | openjdk11 | [29988.13](https://travis-ci.com/broadinstitute/gatk/jobs/317861698) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.13/tests/test/index.html) |; | cloud | openjdk11 | [29988.15](https://travis-ci.com/broadinstitute/gatk/jobs/317861700) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.15/tests/test/index.html) |; | cloud | openjdk8 | [29988.1](https://travis-ci.com/broadinstitute/gatk/jobs/317861676) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.1/tests/test/index.html) |; | unit | openjdk11 | [29988.14](https://travis-ci.com/broadinstitute/gatk/jobs/317861699) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.14/tests/test/index.html) |; | integration | openjdk8 | [29988.2](https://travis-ci.com/broadinstitute/gatk/jobs/317861680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29988.4](https://travis-ci.com/broadinstitute/gatk/jobs/317861682) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29990](https://travis-ci.com/broadinstitute/gatk/builds/159681491); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29990.6](https://travis-ci.com/broadinstitute/gatk/jobs/317870153) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.6/tests/test/index.html) |; | integration | oraclejdk8 | [29990.12](https://travis-ci.com/broadinstitute/gatk/jobs/317870159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.12/tests/test/index.html) |; | python | openjdk8 | [29990.5](https://travis-ci.com/broadinstitute/gatk/jobs/317870152) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.5/tests/test/index.html) |; | cloud | openjdk8 | [29990.1](https://travis-ci.com/broadinstitute/gatk/jobs/317870147) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.1/tests/test/index.html) |; | cloud | openjdk11 | [29990.15](https://travis-ci.com/broadinstitute/gatk/jobs/317870162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.15/tests/test/index.html) |; | integration | openjdk11 | [29990.13](https://travis-ci.com/broadinstitute/gatk/jobs/317870160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.13/tests/test/index.html) |; | integration | openjdk8 | [29990.2](https://travis-ci.com/broadinstitute/gatk/jobs/317870149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.2/tests/test/index.html) |; | unit | openjdk11 | [29990.14](https://travis-ci.com/broadinstitute/gatk/jobs/317870161) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29990.4](https://travis-ci.com/broadinstitute/gatk/jobs/317870151) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [29992](https://travis-ci.com/broadinstitute/gatk/builds/159687710); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29992.6](https://travis-ci.com/broadinstitute/gatk/jobs/317887706) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.6/tests/test/index.html) |; | python | openjdk8 | [29992.5](https://travis-ci.com/broadinstitute/gatk/jobs/317887705) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.5/tests/test/index.html) |; | integration | oraclejdk8 | [29992.12](https://travis-ci.com/broadinstitute/gatk/jobs/317887712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.12/tests/test/index.html) |; | integration | openjdk11 | [29992.13](https://travis-ci.com/broadinstitute/gatk/jobs/317887713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.13/tests/test/index.html) |; | cloud | openjdk8 | [29992.1](https://travis-ci.com/broadinstitute/gatk/jobs/317887701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.1/tests/test/index.html) |; | cloud | openjdk11 | [29992.15](https://travis-ci.com/broadinstitute/gatk/jobs/317887715) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.15/tests/test/index.html) |; | integration | openjdk8 | [29992.2](https://travis-ci.com/broadinstitute/gatk/jobs/317887702) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.2/tests/test/index.html) |; | unit | openjdk11 | [29992.14](https://travis-ci.com/broadinstitute/gatk/jobs/317887714) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29992.4](https://travis-ci.com/broadinstitute/gatk/jobs/317887704) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065:625,integrat,integration,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30007](https://travis-ci.com/broadinstitute/gatk/builds/159946837); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk8 | [30007.3](https://travis-ci.com/broadinstitute/gatk/jobs/318548433) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30007.3/tests/test/index.html) |; | integration | openjdk8 | [30007.2](https://travis-ci.com/broadinstitute/gatk/jobs/318548432) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30007.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6544#issuecomment-612573044:422,integrat,integration,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6544#issuecomment-612573044,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30166](https://travis-ci.com/broadinstitute/gatk/builds/161861232); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30166.13](https://travis-ci.com/broadinstitute/gatk/jobs/323065577) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30166.13/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619117426:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619117426,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30170](https://travis-ci.com/broadinstitute/gatk/builds/161888712); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [30170.12](https://travis-ci.com/broadinstitute/gatk/jobs/323130022) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30170.12/tests/test/index.html) |; | integration | openjdk11 | [30170.13](https://travis-ci.com/broadinstitute/gatk/jobs/323130023) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30170.13/tests/test/index.html) |; | integration | openjdk8 | [30170.2](https://travis-ci.com/broadinstitute/gatk/jobs/323130012) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30170.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619192806:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619192806,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [30184](https://travis-ci.com/broadinstitute/gatk/builds/162226990); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [30184.12](https://travis-ci.com/broadinstitute/gatk/jobs/323827982) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30184.12/tests/test/index.html) |; | integration | openjdk11 | [30184.13](https://travis-ci.com/broadinstitute/gatk/jobs/323827983) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30184.13/tests/test/index.html) |; | integration | openjdk8 | [30184.2](https://travis-ci.com/broadinstitute/gatk/jobs/323827972) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30184.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-620008431:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-620008431,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [30367](https://travis-ci.com/broadinstitute/gatk/builds/166938202); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [30367.1](https://travis-ci.com/broadinstitute/gatk/jobs/337021781) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.1/tests/test/index.html) |; | conda | openjdk8 | [30367.5](https://travis-ci.com/broadinstitute/gatk/jobs/337021785) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.5/tests/test/index.html) |; | cloud | openjdk11 | [30367.13](https://travis-ci.com/broadinstitute/gatk/jobs/337021793) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.13/tests/test/index.html) |; | unit | openjdk11 | [30367.12](https://travis-ci.com/broadinstitute/gatk/jobs/337021792) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.12/tests/test/index.html) |; | integration | openjdk11 | [30367.11](https://travis-ci.com/broadinstitute/gatk/jobs/337021791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.11/tests/test/index.html) |; | variantcalling | openjdk8 | [30367.4](https://travis-ci.com/broadinstitute/gatk/jobs/337021784) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.4/tests/test/index.html) |; | unit | openjdk8 | [30367.3](https://travis-ci.com/broadinstitute/gatk/jobs/337021783) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.3/tests/test/index.html) |; | integration | openjdk8 | [30367.2](https://travis-ci.com/broadinstitute/gatk/jobs/337021782) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-630883022:1043,integrat,integration,1043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-630883022,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30416](https://travis-ci.com/broadinstitute/gatk/builds/168461453); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30416.11](https://travis-ci.com/broadinstitute/gatk/jobs/340668381) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30416.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-634926766:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-634926766,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30432](https://travis-ci.com/broadinstitute/gatk/builds/168636249); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30432.11](https://travis-ci.com/broadinstitute/gatk/jobs/341109053) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.11/tests/test/index.html) |; | integration | openjdk8 | [30432.2](https://travis-ci.com/broadinstitute/gatk/jobs/341109044) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.2/tests/test/index.html) |; | integration | openjdk11 | [30432.11](https://travis-ci.com/broadinstitute/gatk/jobs/341109053) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.11/tests/test/index.html) |; | integration | openjdk8 | [30432.2](https://travis-ci.com/broadinstitute/gatk/jobs/341109044) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6536#issuecomment-635559332:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6536#issuecomment-635559332,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [30435](https://travis-ci.com/broadinstitute/gatk/builds/168646579); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30435.11](https://travis-ci.com/broadinstitute/gatk/jobs/341136130) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.11/tests/test/index.html) |; | integration | openjdk8 | [30435.2](https://travis-ci.com/broadinstitute/gatk/jobs/341136121) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.2/tests/test/index.html) |; | integration | openjdk11 | [30435.11](https://travis-ci.com/broadinstitute/gatk/jobs/341136130) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.11/tests/test/index.html) |; | integration | openjdk8 | [30435.2](https://travis-ci.com/broadinstitute/gatk/jobs/341136121) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-635608349:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-635608349,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [30438](https://travis-ci.com/broadinstitute/gatk/builds/168656638); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30438.11](https://travis-ci.com/broadinstitute/gatk/jobs/341162861) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30438.11/tests/test/index.html) |; | integration | openjdk8 | [30438.2](https://travis-ci.com/broadinstitute/gatk/jobs/341162852) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30438.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-635642092:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-635642092,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30440](https://travis-ci.com/broadinstitute/gatk/builds/168676133); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30440.11](https://travis-ci.com/broadinstitute/gatk/jobs/341217438) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30440.11/tests/test/index.html) |; | integration | openjdk8 | [30440.2](https://travis-ci.com/broadinstitute/gatk/jobs/341217429) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30440.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-635722922:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-635722922,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30450](https://travis-ci.com/broadinstitute/gatk/builds/168819223); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30450.11](https://travis-ci.com/broadinstitute/gatk/jobs/341603988) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30450.11/tests/test/index.html) |; | integration | openjdk8 | [30450.2](https://travis-ci.com/broadinstitute/gatk/jobs/341603979) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30450.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-636225750:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-636225750,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30452](https://travis-ci.com/broadinstitute/gatk/builds/168836017); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30452.11](https://travis-ci.com/broadinstitute/gatk/jobs/341649474) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30452.11/tests/test/index.html) |; | integration | openjdk8 | [30452.2](https://travis-ci.com/broadinstitute/gatk/jobs/341649465) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30452.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-636272145:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-636272145,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30457](https://travis-ci.com/broadinstitute/gatk/builds/169030325); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30457.11](https://travis-ci.com/broadinstitute/gatk/jobs/342158813) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.11/tests/test/index.html) |; | integration | openjdk8 | [30457.2](https://travis-ci.com/broadinstitute/gatk/jobs/342158804) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.2/tests/test/index.html) |; | integration | openjdk11 | [30457.11](https://travis-ci.com/broadinstitute/gatk/jobs/342158813) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.11/tests/test/index.html) |; | integration | openjdk8 | [30457.2](https://travis-ci.com/broadinstitute/gatk/jobs/342158804) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6628#issuecomment-636901985:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6628#issuecomment-636901985,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [30459](https://travis-ci.com/broadinstitute/gatk/builds/169034436); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30459.11](https://travis-ci.com/broadinstitute/gatk/jobs/342168332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30459.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-636917795:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-636917795,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30475](https://travis-ci.com/broadinstitute/gatk/builds/169229345); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30475.11](https://travis-ci.com/broadinstitute/gatk/jobs/342675165) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30475.11/tests/test/index.html) |; | integration | openjdk8 | [30475.2](https://travis-ci.com/broadinstitute/gatk/jobs/342675156) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30475.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637680721:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637680721,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30477](https://travis-ci.com/broadinstitute/gatk/builds/169277901); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30477.11](https://travis-ci.com/broadinstitute/gatk/jobs/342782902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30477.11/tests/test/index.html) |; | integration | openjdk8 | [30477.2](https://travis-ci.com/broadinstitute/gatk/jobs/342782893) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30477.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637717214:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637717214,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30481](https://travis-ci.com/broadinstitute/gatk/builds/169292148); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30481.11](https://travis-ci.com/broadinstitute/gatk/jobs/342819741) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30481.11/tests/test/index.html) |; | integration | openjdk8 | [30481.2](https://travis-ci.com/broadinstitute/gatk/jobs/342819732) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30481.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6632#issuecomment-637767968:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6632#issuecomment-637767968,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30487](https://travis-ci.com/broadinstitute/gatk/builds/169311637); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30487.11](https://travis-ci.com/broadinstitute/gatk/jobs/342871642) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30487.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-637836728:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-637836728,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30489](https://travis-ci.com/broadinstitute/gatk/builds/169313463); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30489.11](https://travis-ci.com/broadinstitute/gatk/jobs/342876908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30489.11/tests/test/index.html) |; | integration | openjdk8 | [30489.2](https://travis-ci.com/broadinstitute/gatk/jobs/342876899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30489.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6559#issuecomment-637843246:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6559#issuecomment-637843246,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30494](https://travis-ci.com/broadinstitute/gatk/builds/169351481); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30494.11](https://travis-ci.com/broadinstitute/gatk/jobs/342986478) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30494.11/tests/test/index.html) |; | integration | openjdk8 | [30494.2](https://travis-ci.com/broadinstitute/gatk/jobs/342986469) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30494.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6636#issuecomment-637936325:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6636#issuecomment-637936325,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30509](https://travis-ci.com/broadinstitute/gatk/builds/169658943); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30509.11](https://travis-ci.com/broadinstitute/gatk/jobs/343744765) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30509.11/tests/test/index.html) |; | integration | openjdk8 | [30509.2](https://travis-ci.com/broadinstitute/gatk/jobs/343744756) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30509.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-639041011:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-639041011,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30624](https://travis-ci.com/broadinstitute/gatk/builds/171270341); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30624.11](https://travis-ci.com/broadinstitute/gatk/jobs/348890773) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30624.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-643784213:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-643784213,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30643](https://travis-ci.com/broadinstitute/gatk/builds/171606871); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | conda | openjdk8 | [30643.5](https://travis-ci.com/broadinstitute/gatk/jobs/349726487) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.5/tests/test/index.html) |; | unit | openjdk11 | [30643.12](https://travis-ci.com/broadinstitute/gatk/jobs/349726494) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.12/tests/test/index.html) |; | integration | openjdk11 | [30643.11](https://travis-ci.com/broadinstitute/gatk/jobs/349726493) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.11/tests/test/index.html) |; | unit | openjdk8 | [30643.3](https://travis-ci.com/broadinstitute/gatk/jobs/349726485) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.3/tests/test/index.html) |; | integration | openjdk8 | [30643.2](https://travis-ci.com/broadinstitute/gatk/jobs/349726484) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644793169:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644793169,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30644](https://travis-ci.com/broadinstitute/gatk/builds/171613538); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30644.11](https://travis-ci.com/broadinstitute/gatk/jobs/349743817) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30644.11/tests/test/index.html) |; | integration | openjdk8 | [30644.2](https://travis-ci.com/broadinstitute/gatk/jobs/349743808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30644.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-644819369:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-644819369,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30666](https://travis-ci.com/broadinstitute/gatk/builds/171680645); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30666.12](https://travis-ci.com/broadinstitute/gatk/jobs/349984895) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.12/tests/test/index.html) |; | conda | openjdk8 | [30666.5](https://travis-ci.com/broadinstitute/gatk/jobs/349984888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.5/tests/test/index.html) |; | integration | openjdk11 | [30666.11](https://travis-ci.com/broadinstitute/gatk/jobs/349984894) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.11/tests/test/index.html) |; | unit | openjdk8 | [30666.3](https://travis-ci.com/broadinstitute/gatk/jobs/349984886) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.3/tests/test/index.html) |; | integration | openjdk8 | [30666.2](https://travis-ci.com/broadinstitute/gatk/jobs/349984885) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644966563:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644966563,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30678](https://travis-ci.com/broadinstitute/gatk/builds/171691595); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30678.12](https://travis-ci.com/broadinstitute/gatk/jobs/350014518) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.12/tests/test/index.html) |; | conda | openjdk8 | [30678.5](https://travis-ci.com/broadinstitute/gatk/jobs/350014511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.5/tests/test/index.html) |; | integration | openjdk11 | [30678.11](https://travis-ci.com/broadinstitute/gatk/jobs/350014517) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.11/tests/test/index.html) |; | unit | openjdk8 | [30678.3](https://travis-ci.com/broadinstitute/gatk/jobs/350014509) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.3/tests/test/index.html) |; | integration | openjdk8 | [30678.2](https://travis-ci.com/broadinstitute/gatk/jobs/350014508) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645006687:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645006687,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30698](https://travis-ci.com/broadinstitute/gatk/builds/171852295); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30698.11](https://travis-ci.com/broadinstitute/gatk/jobs/350395411) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30698.11/tests/test/index.html) |; | variantcalling | openjdk8 | [30698.4](https://travis-ci.com/broadinstitute/gatk/jobs/350395404) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30698.4/tests/test/index.html) |; | integration | openjdk8 | [30698.2](https://travis-ci.com/broadinstitute/gatk/jobs/350395402) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30698.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645419790:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645419790,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30705](https://travis-ci.com/broadinstitute/gatk/builds/171899359); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30705.12](https://travis-ci.com/broadinstitute/gatk/jobs/350530956) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.12/tests/test/index.html) |; | conda | openjdk8 | [30705.5](https://travis-ci.com/broadinstitute/gatk/jobs/350530949) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.5/tests/test/index.html) |; | integration | openjdk11 | [30705.11](https://travis-ci.com/broadinstitute/gatk/jobs/350530955) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.11/tests/test/index.html) |; | unit | openjdk8 | [30705.3](https://travis-ci.com/broadinstitute/gatk/jobs/350530947) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.3/tests/test/index.html) |; | integration | openjdk8 | [30705.2](https://travis-ci.com/broadinstitute/gatk/jobs/350530946) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645543363:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645543363,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30712](https://travis-ci.com/broadinstitute/gatk/builds/171935407); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30712.11](https://travis-ci.com/broadinstitute/gatk/jobs/350622577) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.11/tests/test/index.html) |; | cloud | openjdk8 | [30712.1](https://travis-ci.com/broadinstitute/gatk/jobs/350622567) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.1/tests/test/index.html) |; | cloud | openjdk11 | [30712.13](https://travis-ci.com/broadinstitute/gatk/jobs/350622579) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.13/tests/test/index.html) |; | unit | openjdk11 | [30712.12](https://travis-ci.com/broadinstitute/gatk/jobs/350622578) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6612#issuecomment-645656060:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6612#issuecomment-645656060,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30869](https://travis-ci.com/broadinstitute/gatk/builds/174096694); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30869.13](https://travis-ci.com/broadinstitute/gatk/jobs/357066667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.13/tests/test/index.html) |; | integration | openjdk11 | [30869.12](https://travis-ci.com/broadinstitute/gatk/jobs/357066666) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.12/tests/test/index.html) |; | variantcalling | openjdk8 | [30869.4](https://travis-ci.com/broadinstitute/gatk/jobs/357066658) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.4/tests/test/index.html) |; | unit | openjdk8 | [30869.3](https://travis-ci.com/broadinstitute/gatk/jobs/357066657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.3/tests/test/index.html) |; | integration | openjdk8 | [30869.2](https://travis-ci.com/broadinstitute/gatk/jobs/357066656) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6113#issuecomment-653150268:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6113#issuecomment-653150268,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30892](https://travis-ci.com/broadinstitute/gatk/builds/174640358); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30892.12](https://travis-ci.com/broadinstitute/gatk/jobs/358397668) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30892.12/tests/test/index.html) |; | integration | openjdk8 | [30892.2](https://travis-ci.com/broadinstitute/gatk/jobs/358397658) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30892.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6684#issuecomment-654947147:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6684#issuecomment-654947147,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30955](https://travis-ci.com/broadinstitute/gatk/builds/175590051); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30955.12](https://travis-ci.com/broadinstitute/gatk/jobs/360964271) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30955.12/tests/test/index.html) |; | integration | openjdk8 | [30955.2](https://travis-ci.com/broadinstitute/gatk/jobs/360964260) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30955.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658304029:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658304029,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30957](https://travis-ci.com/broadinstitute/gatk/builds/175592807); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30957.12](https://travis-ci.com/broadinstitute/gatk/jobs/360970944) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30957.12/tests/test/index.html) |; | integration | openjdk8 | [30957.2](https://travis-ci.com/broadinstitute/gatk/jobs/360970934) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30957.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658313849:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658313849,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30961](https://travis-ci.com/broadinstitute/gatk/builds/175596623); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30961.12](https://travis-ci.com/broadinstitute/gatk/jobs/360981529) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30961.12/tests/test/index.html) |; | integration | openjdk8 | [30961.2](https://travis-ci.com/broadinstitute/gatk/jobs/360981519) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30961.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658331353:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658331353,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30964](https://travis-ci.com/broadinstitute/gatk/builds/175616122); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30964.12](https://travis-ci.com/broadinstitute/gatk/jobs/361032988) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30964.12/tests/test/index.html) |; | integration | openjdk8 | [30964.2](https://travis-ci.com/broadinstitute/gatk/jobs/361032978) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30964.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658402464:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658402464,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30972](https://travis-ci.com/broadinstitute/gatk/builds/175949953); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [30972.1](https://travis-ci.com/broadinstitute/gatk/jobs/361875017) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30972.1/tests/test/index.html) |; | integration | openjdk11 | [30972.12](https://travis-ci.com/broadinstitute/gatk/jobs/361875028) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30972.12/tests/test/index.html) |; | integration | openjdk8 | [30972.2](https://travis-ci.com/broadinstitute/gatk/jobs/361875018) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30972.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659640018:423,integrat,integration,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659640018,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30974](https://travis-ci.com/broadinstitute/gatk/builds/175951574); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [30974.1](https://travis-ci.com/broadinstitute/gatk/jobs/361879074) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.1/tests/test/index.html) |; | unit | openjdk11 | [30974.13](https://travis-ci.com/broadinstitute/gatk/jobs/361879086) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.13/tests/test/index.html) |; | conda | openjdk8 | [30974.5](https://travis-ci.com/broadinstitute/gatk/jobs/361879078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.5/tests/test/index.html) |; | integration | openjdk11 | [30974.12](https://travis-ci.com/broadinstitute/gatk/jobs/361879085) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.12/tests/test/index.html) |; | unit | openjdk8 | [30974.3](https://travis-ci.com/broadinstitute/gatk/jobs/361879076) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.3/tests/test/index.html) |; | integration | openjdk8 | [30974.2](https://travis-ci.com/broadinstitute/gatk/jobs/361879075) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-659647328:835,integrat,integration,835,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-659647328,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30976](https://travis-ci.com/broadinstitute/gatk/builds/175952777); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30976.12](https://travis-ci.com/broadinstitute/gatk/jobs/361882175) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30976.12/tests/test/index.html) |; | integration | openjdk8 | [30976.2](https://travis-ci.com/broadinstitute/gatk/jobs/361882165) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30976.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659661207:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659661207,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30984](https://travis-ci.com/broadinstitute/gatk/builds/176331364); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30984.12](https://travis-ci.com/broadinstitute/gatk/jobs/362887049) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30984.12/tests/test/index.html) |; | integration | openjdk8 | [30984.2](https://travis-ci.com/broadinstitute/gatk/jobs/362887038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30984.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661096333:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661096333,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30988](https://travis-ci.com/broadinstitute/gatk/builds/176344004); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30988.12](https://travis-ci.com/broadinstitute/gatk/jobs/362915950) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30988.12/tests/test/index.html) |; | integration | openjdk8 | [30988.2](https://travis-ci.com/broadinstitute/gatk/jobs/362915940) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30988.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661139174:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661139174,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31014](https://travis-ci.com/broadinstitute/gatk/builds/176929508); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31014.12](https://travis-ci.com/broadinstitute/gatk/jobs/364378637) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31014.12/tests/test/index.html) |; | integration | openjdk8 | [31014.2](https://travis-ci.com/broadinstitute/gatk/jobs/364378627) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31014.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6723#issuecomment-663219099:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6723#issuecomment-663219099,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31019](https://travis-ci.com/broadinstitute/gatk/builds/177075400); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [31019.13](https://travis-ci.com/broadinstitute/gatk/jobs/364732566) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31019.13/tests/test/index.html) |; | integration | openjdk11 | [31019.12](https://travis-ci.com/broadinstitute/gatk/jobs/364732565) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31019.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663706251:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663706251,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31021](https://travis-ci.com/broadinstitute/gatk/builds/177076345); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [31021.13](https://travis-ci.com/broadinstitute/gatk/jobs/364735420) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.13/tests/test/index.html) |; | conda | openjdk8 | [31021.5](https://travis-ci.com/broadinstitute/gatk/jobs/364735412) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.5/tests/test/index.html) |; | integration | openjdk11 | [31021.12](https://travis-ci.com/broadinstitute/gatk/jobs/364735419) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.12/tests/test/index.html) |; | unit | openjdk8 | [31021.3](https://travis-ci.com/broadinstitute/gatk/jobs/364735410) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.3/tests/test/index.html) |; | integration | openjdk8 | [31021.2](https://travis-ci.com/broadinstitute/gatk/jobs/364735409) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663710294:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663710294,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31043](https://travis-ci.com/broadinstitute/gatk/builds/177838328); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [31043.13](https://travis-ci.com/broadinstitute/gatk/jobs/366761867) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.13/tests/test/index.html) |; | conda | openjdk8 | [31043.5](https://travis-ci.com/broadinstitute/gatk/jobs/366761859) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.5/tests/test/index.html) |; | integration | openjdk11 | [31043.12](https://travis-ci.com/broadinstitute/gatk/jobs/366761866) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.12/tests/test/index.html) |; | unit | openjdk8 | [31043.3](https://travis-ci.com/broadinstitute/gatk/jobs/366761857) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.3/tests/test/index.html) |; | integration | openjdk8 | [31043.2](https://travis-ci.com/broadinstitute/gatk/jobs/366761856) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-666525725:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-666525725,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31078](https://travis-ci.com/broadinstitute/gatk/builds/178593210); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31078.12](https://travis-ci.com/broadinstitute/gatk/jobs/368742472) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31078.12/tests/test/index.html) |; | variantcalling | openjdk8 | [31078.4](https://travis-ci.com/broadinstitute/gatk/jobs/368742464) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31078.4/tests/test/index.html) |; | integration | openjdk8 | [31078.2](https://travis-ci.com/broadinstitute/gatk/jobs/368742462) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31078.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669368534:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669368534,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31080](https://travis-ci.com/broadinstitute/gatk/builds/178599096); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31080.12](https://travis-ci.com/broadinstitute/gatk/jobs/368765328) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31080.12/tests/test/index.html) |; | integration | openjdk8 | [31080.2](https://travis-ci.com/broadinstitute/gatk/jobs/368765318) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31080.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669402367:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669402367,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31110](https://travis-ci.com/broadinstitute/gatk/builds/179177202); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31110.12](https://travis-ci.com/broadinstitute/gatk/jobs/370468323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31110.12/tests/test/index.html) |; | integration | openjdk8 | [31110.2](https://travis-ci.com/broadinstitute/gatk/jobs/370468313) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31110.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-671583467:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-671583467,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31195](https://travis-ci.com/broadinstitute/gatk/builds/181151716); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [31195.14](https://travis-ci.com/broadinstitute/gatk/jobs/377065385) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31195.14/tests/test/index.html) |; | integration | openjdk8 | [31195.2](https://travis-ci.com/broadinstitute/gatk/jobs/377065373) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31195.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-679370909:426,integrat,integration,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-679370909,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31212](https://travis-ci.com/broadinstitute/gatk/builds/181345735); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31212.2](https://travis-ci.com/broadinstitute/gatk/jobs/377600452) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31212.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680182147:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680182147,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31215](https://travis-ci.com/broadinstitute/gatk/builds/181356386); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31215.2](https://travis-ci.com/broadinstitute/gatk/jobs/377629183) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31215.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680225942:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680225942,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31219](https://travis-ci.com/broadinstitute/gatk/builds/181373545); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31219.2](https://travis-ci.com/broadinstitute/gatk/jobs/377677482) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31219.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680264087:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680264087,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31232](https://travis-ci.com/broadinstitute/gatk/builds/181489744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31232.12](https://travis-ci.com/broadinstitute/gatk/jobs/377973557) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31232.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680949614:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680949614,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31239](https://travis-ci.com/broadinstitute/gatk/builds/181521398); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31239.12](https://travis-ci.com/broadinstitute/gatk/jobs/378060367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31239.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681066658:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681066658,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31247](https://travis-ci.com/broadinstitute/gatk/builds/181644287); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31247.2](https://travis-ci.com/broadinstitute/gatk/jobs/378372688) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31247.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681992455:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681992455,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31250](https://travis-ci.com/broadinstitute/gatk/builds/181656346); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31250.2](https://travis-ci.com/broadinstitute/gatk/jobs/378403341) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31250.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-682037890:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-682037890,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31337](https://travis-ci.com/broadinstitute/gatk/builds/183389891); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31337.12](https://travis-ci.com/broadinstitute/gatk/jobs/382388334) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.12/tests/test/index.html) |; | integration | openjdk8 | [31337.2](https://travis-ci.com/broadinstitute/gatk/jobs/382388324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.2/tests/test/index.html) |; | integration | openjdk8 | [31337.2](https://travis-ci.com/broadinstitute/gatk/jobs/382388324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.2/tests/test/index.html) |; | integration | openjdk11 | [31337.12](https://travis-ci.com/broadinstitute/gatk/jobs/382388334) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.12/tests/test/index.html) |; | integration | openjdk8 | [31337.2](https://travis-ci.com/broadinstitute/gatk/jobs/382388324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6799#issuecomment-688972966:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6799#issuecomment-688972966,5,['integrat'],['integration']
Integrability,Travis reported job failures from build [31339](https://travis-ci.com/broadinstitute/gatk/builds/183391027); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31339.12](https://travis-ci.com/broadinstitute/gatk/jobs/382390918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31339.12/tests/test/index.html) |; | integration | openjdk8 | [31339.2](https://travis-ci.com/broadinstitute/gatk/jobs/382390908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31339.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-688977676:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-688977676,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31347](https://travis-ci.com/broadinstitute/gatk/builds/183553091); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31347.12](https://travis-ci.com/broadinstitute/gatk/jobs/382751875) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31347.12/tests/test/index.html) |; | integration | openjdk8 | [31347.2](https://travis-ci.com/broadinstitute/gatk/jobs/382751865) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31347.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6802#issuecomment-689573574:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6802#issuecomment-689573574,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31349](https://travis-ci.com/broadinstitute/gatk/builds/183570461); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [31349.1](https://travis-ci.com/broadinstitute/gatk/jobs/382794132) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31349.1/tests/test/index.html) |; | integration | openjdk11 | [31349.12](https://travis-ci.com/broadinstitute/gatk/jobs/382794143) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31349.12/tests/test/index.html) |; | integration | openjdk8 | [31349.2](https://travis-ci.com/broadinstitute/gatk/jobs/382794133) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31349.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689627653:423,integrat,integration,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689627653,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31351](https://travis-ci.com/broadinstitute/gatk/builds/183609447); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31351.12](https://travis-ci.com/broadinstitute/gatk/jobs/382897378) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31351.12/tests/test/index.html) |; | integration | openjdk8 | [31351.2](https://travis-ci.com/broadinstitute/gatk/jobs/382897368) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31351.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689773463:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689773463,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31353](https://travis-ci.com/broadinstitute/gatk/builds/183610371); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31353.12](https://travis-ci.com/broadinstitute/gatk/jobs/382899552) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31353.12/tests/test/index.html) |; | integration | openjdk8 | [31353.2](https://travis-ci.com/broadinstitute/gatk/jobs/382899542) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31353.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689779833:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689779833,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31358](https://travis-ci.com/broadinstitute/gatk/builds/183616396); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31358.12](https://travis-ci.com/broadinstitute/gatk/jobs/382914758) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31358.12/tests/test/index.html) |; | integration | openjdk8 | [31358.2](https://travis-ci.com/broadinstitute/gatk/jobs/382914748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31358.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689804506:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689804506,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31362](https://travis-ci.com/broadinstitute/gatk/builds/183621979); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31362.12](https://travis-ci.com/broadinstitute/gatk/jobs/382955645) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31362.12/tests/test/index.html) |; | integration | openjdk8 | [31362.2](https://travis-ci.com/broadinstitute/gatk/jobs/382955635) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31362.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6718#issuecomment-689817531:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6718#issuecomment-689817531,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31384](https://travis-ci.com/broadinstitute/gatk/builds/183805923); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31384.12](https://travis-ci.com/broadinstitute/gatk/jobs/383393943) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_31384.12/tests/test/index.html) |; | integration | openjdk8 | [31384.2](https://travis-ci.com/broadinstitute/gatk/jobs/383393933) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_31384.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6806#issuecomment-690768109:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6806#issuecomment-690768109,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31394](https://travis-ci.com/broadinstitute/gatk/builds/183915996); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [31394.14](https://travis-ci.com/broadinstitute/gatk/jobs/383673641) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31394.14/tests/test/index.html) |; | integration | openjdk11 | [31394.12](https://travis-ci.com/broadinstitute/gatk/jobs/383673639) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31394.12/tests/test/index.html) |; | integration | openjdk8 | [31394.2](https://travis-ci.com/broadinstitute/gatk/jobs/383673629) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31394.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6809#issuecomment-691150417:426,integrat,integration,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6809#issuecomment-691150417,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31727](https://travis-ci.com/broadinstitute/gatk/builds/189051039); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31727.2](https://travis-ci.com/broadinstitute/gatk/jobs/397423689) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31727.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-706233780:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-706233780,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31792](https://travis-ci.com/broadinstitute/gatk/builds/189715425); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31792.13](https://travis-ci.com/broadinstitute/gatk/jobs/398842818) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_31792.13/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6881#issuecomment-707791058:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6881#issuecomment-707791058,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31957](https://travis-ci.com/broadinstitute/gatk/builds/195786303); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31957.12](https://travis-ci.com/broadinstitute/gatk/jobs/419334595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31957.12/tests/test/index.html) |; | integration | openjdk8 | [31957.2](https://travis-ci.com/broadinstitute/gatk/jobs/419334585) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31957.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-718862955:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-718862955,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31965](https://travis-ci.com/broadinstitute/gatk/builds/195873537); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31965.12](https://travis-ci.com/broadinstitute/gatk/jobs/419598303) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31965.12/tests/test/index.html) |; | integration | openjdk8 | [31965.2](https://travis-ci.com/broadinstitute/gatk/jobs/419598293) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31965.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-718895504:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-718895504,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32049](https://travis-ci.com/broadinstitute/gatk/builds/198559577); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32049.12](https://travis-ci.com/broadinstitute/gatk/jobs/429147025) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32049.12/tests/test/index.html) |; | integration | openjdk8 | [32049.2](https://travis-ci.com/broadinstitute/gatk/jobs/429147015) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32049.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-722658012:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-722658012,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32149](https://travis-ci.com/broadinstitute/gatk/builds/202173930); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32149.1](https://travis-ci.com/broadinstitute/gatk/jobs/441791105) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.1/tests/test/index.html) |; | integration | openjdk11 | [32149.12](https://travis-ci.com/broadinstitute/gatk/jobs/441791121) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.12/tests/test/index.html) |; | conda | openjdk8 | [32149.5](https://travis-ci.com/broadinstitute/gatk/jobs/441791111) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.5/tests/test/index.html) |; | unit | openjdk8 | [32149.3](https://travis-ci.com/broadinstitute/gatk/jobs/441791108) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.3/tests/test/index.html) |; | integration | openjdk8 | [32149.2](https://travis-ci.com/broadinstitute/gatk/jobs/441791106) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-729060312:423,integrat,integration,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-729060312,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32180](https://travis-ci.com/broadinstitute/gatk/builds/202787538); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32180.12](https://travis-ci.com/broadinstitute/gatk/jobs/443607068) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32180.12/tests/test/index.html) |; | integration | openjdk8 | [32180.2](https://travis-ci.com/broadinstitute/gatk/jobs/443607058) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32180.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730467975:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730467975,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32196](https://travis-ci.com/broadinstitute/gatk/builds/202875234); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32196.12](https://travis-ci.com/broadinstitute/gatk/jobs/443900497) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32196.12/tests/test/index.html) |; | integration | openjdk8 | [32196.2](https://travis-ci.com/broadinstitute/gatk/jobs/443900487) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32196.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-730608277:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-730608277,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32198](https://travis-ci.com/broadinstitute/gatk/builds/202876316); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32198.12](https://travis-ci.com/broadinstitute/gatk/jobs/443903163) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32198.12/tests/test/index.html) |; | integration | openjdk8 | [32198.2](https://travis-ci.com/broadinstitute/gatk/jobs/443903153) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32198.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730613743:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730613743,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32308](https://travis-ci.com/broadinstitute/gatk/builds/206017880); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32308.12](https://travis-ci.com/broadinstitute/gatk/jobs/452716639) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32308.12/tests/test/index.html) |; | integration | openjdk8 | [32308.2](https://travis-ci.com/broadinstitute/gatk/jobs/452716628) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32308.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-737442197:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-737442197,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32329](https://travis-ci.com/broadinstitute/gatk/builds/206640419); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32329.1](https://travis-ci.com/broadinstitute/gatk/jobs/454533901) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.1/tests/test/index.html) |; | cloud | openjdk11 | [32329.14](https://travis-ci.com/broadinstitute/gatk/jobs/454533914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.14/tests/test/index.html) |; | integration | openjdk11 | [32329.12](https://travis-ci.com/broadinstitute/gatk/jobs/454533912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.12/tests/test/index.html) |; | integration | openjdk8 | [32329.2](https://travis-ci.com/broadinstitute/gatk/jobs/454533902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.2/tests/test/index.html) |; | cloud | openjdk8 | [32329.1](https://travis-ci.com/broadinstitute/gatk/jobs/454533901) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.1/tests/test/index.html) |; | cloud | openjdk11 | [32329.14](https://travis-ci.com/broadinstitute/gatk/jobs/454533914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.14/tests/test/index.html) |; | integration | openjdk11 | [32329.12](https://travis-ci.com/broadinstitute/gatk/jobs/454533912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.12/tests/test/index.html) |; | integration | openjdk8 | [32329.2](https://travis-ci.com/broadinstitute/gatk/jobs/454533902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-738879938:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-738879938,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [32366](https://travis-ci.com/broadinstitute/gatk/builds/208141255); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [32366.13](https://travis-ci.com/broadinstitute/gatk/jobs/458419765) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.13/tests/test/index.html) |; | integration | openjdk11 | [32366.12](https://travis-ci.com/broadinstitute/gatk/jobs/458419764) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.12/tests/test/index.html) |; | conda | openjdk8 | [32366.5](https://travis-ci.com/broadinstitute/gatk/jobs/458419757) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.5/tests/test/index.html) |; | unit | openjdk8 | [32366.3](https://travis-ci.com/broadinstitute/gatk/jobs/458419755) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.3/tests/test/index.html) |; | integration | openjdk8 | [32366.2](https://travis-ci.com/broadinstitute/gatk/jobs/458419754) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-743353051:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-743353051,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32512](https://travis-ci.com/broadinstitute/gatk/builds/212721931); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk8 | [32512.3](https://travis-ci.com/broadinstitute/gatk/jobs/470580370) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.3/tests/test/index.html) |; | integration | openjdk8 | [32512.2](https://travis-ci.com/broadinstitute/gatk/jobs/470580369) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.2/tests/test/index.html) |; | cloud | openjdk11 | [32512.14](https://travis-ci.com/broadinstitute/gatk/jobs/470580381) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.14/tests/test/index.html) |; | cloud | openjdk8 | [32512.1](https://travis-ci.com/broadinstitute/gatk/jobs/470580368) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.1/tests/test/index.html) |; | unit | openjdk11 | [32512.13](https://travis-ci.com/broadinstitute/gatk/jobs/470580380) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.13/tests/test/index.html) |; | integration | openjdk11 | [32512.12](https://travis-ci.com/broadinstitute/gatk/jobs/470580379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.12/tests/test/index.html) |; | unit | openjdk8 | [32512.3](https://travis-ci.com/broadinstitute/gatk/jobs/470580370) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.3/tests/test/index.html) |; | integration | openjdk8 | [32512.2](https://travis-ci.com/broadinstitute/gatk/jobs/470580369) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-758148911:422,integrat,integration,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-758148911,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [32589](https://travis-ci.com/broadinstitute/gatk/builds/213965618); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32589.12](https://travis-ci.com/broadinstitute/gatk/jobs/473858986) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32589.12/tests/test/index.html) |; | integration | openjdk8 | [32589.2](https://travis-ci.com/broadinstitute/gatk/jobs/473858976) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32589.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7046#issuecomment-764774849:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7046#issuecomment-764774849,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32607](https://travis-ci.com/broadinstitute/gatk/builds/214188217); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32607.1](https://travis-ci.com/broadinstitute/gatk/jobs/474485135) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.1/tests/test/index.html) |; | cloud | openjdk11 | [32607.14](https://travis-ci.com/broadinstitute/gatk/jobs/474485148) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.14/tests/test/index.html) |; | integration | openjdk11 | [32607.12](https://travis-ci.com/broadinstitute/gatk/jobs/474485146) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.12/tests/test/index.html) |; | integration | openjdk8 | [32607.2](https://travis-ci.com/broadinstitute/gatk/jobs/474485136) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.2/tests/test/index.html) |; | cloud | openjdk11 | [32607.14](https://travis-ci.com/broadinstitute/gatk/jobs/474485148) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.14/tests/test/index.html) |; | cloud | openjdk8 | [32607.1](https://travis-ci.com/broadinstitute/gatk/jobs/474485135) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.1/tests/test/index.html) |; | integration | openjdk11 | [32607.12](https://travis-ci.com/broadinstitute/gatk/jobs/474485146) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.12/tests/test/index.html) |; | integration | openjdk8 | [32607.2](https://travis-ci.com/broadinstitute/gatk/jobs/474485136) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-765667586:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-765667586,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [32618](https://travis-ci.com/broadinstitute/gatk/builds/214398386); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32618.1](https://travis-ci.com/broadinstitute/gatk/jobs/475091885) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.1/tests/test/index.html) |; | cloud | openjdk11 | [32618.14](https://travis-ci.com/broadinstitute/gatk/jobs/475091898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.14/tests/test/index.html) |; | integration | openjdk11 | [32618.12](https://travis-ci.com/broadinstitute/gatk/jobs/475091896) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.12/tests/test/index.html) |; | integration | openjdk8 | [32618.2](https://travis-ci.com/broadinstitute/gatk/jobs/475091886) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-766922899:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-766922899,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32622](https://travis-ci.com/broadinstitute/gatk/builds/214430101); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32622.1](https://travis-ci.com/broadinstitute/gatk/jobs/475160500) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.1/tests/test/index.html) |; | cloud | openjdk11 | [32622.14](https://travis-ci.com/broadinstitute/gatk/jobs/475160513) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.14/tests/test/index.html) |; | integration | openjdk11 | [32622.12](https://travis-ci.com/broadinstitute/gatk/jobs/475160511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.12/tests/test/index.html) |; | integration | openjdk8 | [32622.2](https://travis-ci.com/broadinstitute/gatk/jobs/475160501) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767055706:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767055706,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32624](https://travis-ci.com/broadinstitute/gatk/builds/214440857); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32624.12](https://travis-ci.com/broadinstitute/gatk/jobs/475184731) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32624.12/tests/test/index.html) |; | integration | openjdk8 | [32624.2](https://travis-ci.com/broadinstitute/gatk/jobs/475184721) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32624.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767117162:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767117162,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32658](https://travis-ci.com/broadinstitute/gatk/builds/214909015); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32658.12](https://travis-ci.com/broadinstitute/gatk/jobs/477355523) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32658.12/tests/test/index.html) |; | integration | openjdk8 | [32658.2](https://travis-ci.com/broadinstitute/gatk/jobs/477355513) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32658.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7058#issuecomment-768431643:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7058#issuecomment-768431643,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32698](https://travis-ci.com/broadinstitute/gatk/builds/215638691); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32698.12](https://travis-ci.com/broadinstitute/gatk/jobs/479312671) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32698.12/tests/test/index.html) |; | integration | openjdk8 | [32698.2](https://travis-ci.com/broadinstitute/gatk/jobs/479312661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32698.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771066064:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771066064,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32700](https://travis-ci.com/broadinstitute/gatk/builds/215640700); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [32700.2](https://travis-ci.com/broadinstitute/gatk/jobs/479317038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32700.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771096981:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771096981,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [32714](https://travis-ci.com/broadinstitute/gatk/builds/215832180); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32714.12](https://travis-ci.com/broadinstitute/gatk/jobs/479776403) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32714.12/tests/test/index.html) |; | integration | openjdk8 | [32714.2](https://travis-ci.com/broadinstitute/gatk/jobs/479776393) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32714.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7066#issuecomment-772003143:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7066#issuecomment-772003143,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32755](https://travis-ci.com/broadinstitute/gatk/builds/216440553); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [32755.13](https://travis-ci.com/broadinstitute/gatk/jobs/481338469) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32755.13/tests/test/index.html) |; | integration | openjdk11 | [32755.12](https://travis-ci.com/broadinstitute/gatk/jobs/481338468) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32755.12/tests/test/index.html) |; | unit | openjdk8 | [32755.3](https://travis-ci.com/broadinstitute/gatk/jobs/481338459) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32755.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775371146:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775371146,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [32758](https://travis-ci.com/broadinstitute/gatk/builds/216451581); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32758.12](https://travis-ci.com/broadinstitute/gatk/jobs/481368144) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32758.12/tests/test/index.html) |; | integration | openjdk8 | [32758.2](https://travis-ci.com/broadinstitute/gatk/jobs/481368134) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32758.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775457190:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775457190,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33028](https://travis-ci.com/broadinstitute/gatk/builds/218904203); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [33028.13](https://travis-ci.com/broadinstitute/gatk/jobs/487894628) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33028.13/tests/test/index.html) |; | integration | openjdk11 | [33028.12](https://travis-ci.com/broadinstitute/gatk/jobs/487894627) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33028.12/tests/test/index.html) |; | integration | openjdk8 | [33028.2](https://travis-ci.com/broadinstitute/gatk/jobs/487894617) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33028.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-790085277:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-790085277,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33241](https://travis-ci.com/broadinstitute/gatk/builds/220390768); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33241.12](https://travis-ci.com/broadinstitute/gatk/jobs/491751868) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.12/tests/test/index.html) |; | integration | openjdk8 | [33241.2](https://travis-ci.com/broadinstitute/gatk/jobs/491751858) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.2/tests/test/index.html) |; | integration | openjdk11 | [33241.12](https://travis-ci.com/broadinstitute/gatk/jobs/491751868) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.12/tests/test/index.html) |; | integration | openjdk8 | [33241.2](https://travis-ci.com/broadinstitute/gatk/jobs/491751858) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-801174546:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-801174546,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [33277](https://travis-ci.com/broadinstitute/gatk/builds/220814326); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [33277.1](https://travis-ci.com/broadinstitute/gatk/jobs/492787754) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.1/tests/test/index.html) |; | cloud | openjdk11 | [33277.14](https://travis-ci.com/broadinstitute/gatk/jobs/492787767) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.14/tests/test/index.html) |; | unit | openjdk11 | [33277.13](https://travis-ci.com/broadinstitute/gatk/jobs/492787766) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.13/tests/test/index.html) |; | integration | openjdk11 | [33277.12](https://travis-ci.com/broadinstitute/gatk/jobs/492787765) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.12/tests/test/index.html) |; | unit | openjdk8 | [33277.3](https://travis-ci.com/broadinstitute/gatk/jobs/492787756) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.3/tests/test/index.html) |; | integration | openjdk8 | [33277.2](https://travis-ci.com/broadinstitute/gatk/jobs/492787755) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-804124554:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-804124554,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33368](https://travis-ci.com/broadinstitute/gatk/builds/221347661); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [33368.1](https://travis-ci.com/broadinstitute/gatk/jobs/494112466) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.1/tests/test/index.html) |; | cloud | openjdk11 | [33368.14](https://travis-ci.com/broadinstitute/gatk/jobs/494112479) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.14/tests/test/index.html) |; | integration | openjdk11 | [33368.12](https://travis-ci.com/broadinstitute/gatk/jobs/494112477) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.12/tests/test/index.html) |; | integration | openjdk8 | [33368.2](https://travis-ci.com/broadinstitute/gatk/jobs/494112467) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-808550699:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-808550699,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33381](https://travis-ci.com/broadinstitute/gatk/builds/221504222); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [33381.14](https://travis-ci.com/broadinstitute/gatk/jobs/494506581) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.14/tests/test/index.html) |; | cloud | openjdk8 | [33381.1](https://travis-ci.com/broadinstitute/gatk/jobs/494506568) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.1/tests/test/index.html) |; | unit | openjdk11 | [33381.13](https://travis-ci.com/broadinstitute/gatk/jobs/494506580) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.13/tests/test/index.html) |; | integration | openjdk11 | [33381.12](https://travis-ci.com/broadinstitute/gatk/jobs/494506579) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.12/tests/test/index.html) |; | unit | openjdk8 | [33381.3](https://travis-ci.com/broadinstitute/gatk/jobs/494506570) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.3/tests/test/index.html) |; | integration | openjdk8 | [33381.2](https://travis-ci.com/broadinstitute/gatk/jobs/494506569) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-809438028:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-809438028,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33441](https://travis-ci.com/broadinstitute/gatk/builds/221813707); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33441.12](https://travis-ci.com/broadinstitute/gatk/jobs/495278045) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.12/tests/test/index.html) |; | integration | openjdk8 | [33441.2](https://travis-ci.com/broadinstitute/gatk/jobs/495278035) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.2/tests/test/index.html) |; | integration | openjdk11 | [33441.12](https://travis-ci.com/broadinstitute/gatk/jobs/495278045) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.12/tests/test/index.html) |; | integration | openjdk8 | [33441.2](https://travis-ci.com/broadinstitute/gatk/jobs/495278035) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-811282668:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-811282668,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [33523](https://travis-ci.com/broadinstitute/gatk/builds/222089183); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33523.12](https://travis-ci.com/broadinstitute/gatk/jobs/495929374) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33523.12/tests/test/index.html) |; | integration | openjdk8 | [33523.2](https://travis-ci.com/broadinstitute/gatk/jobs/495929364) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33523.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813018382:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813018382,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33528](https://travis-ci.com/broadinstitute/gatk/builds/222109060); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33528.12](https://travis-ci.com/broadinstitute/gatk/jobs/495994529) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33528.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813154031:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813154031,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [33531](https://travis-ci.com/broadinstitute/gatk/builds/222109820); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33531.12](https://travis-ci.com/broadinstitute/gatk/jobs/495997078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33531.12/tests/test/index.html) |; | integration | openjdk8 | [33531.2](https://travis-ci.com/broadinstitute/gatk/jobs/495997068) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33531.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813161773:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813161773,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33698](https://travis-ci.com/broadinstitute/gatk/builds/222963404); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33698.12](https://travis-ci.com/broadinstitute/gatk/jobs/498206052) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33698.12/tests/test/index.html) |; | integration | openjdk8 | [33698.2](https://travis-ci.com/broadinstitute/gatk/jobs/498206042) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33698.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-818922214:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-818922214,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33752](https://travis-ci.com/broadinstitute/gatk/builds/223087196); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [33752.14](https://travis-ci.com/broadinstitute/gatk/jobs/498538900) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.14/tests/test/index.html) |; | cloud | openjdk8 | [33752.1](https://travis-ci.com/broadinstitute/gatk/jobs/498538887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.1/tests/test/index.html) |; | unit | openjdk11 | [33752.13](https://travis-ci.com/broadinstitute/gatk/jobs/498538899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.13/tests/test/index.html) |; | integration | openjdk11 | [33752.12](https://travis-ci.com/broadinstitute/gatk/jobs/498538898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33752.4](https://travis-ci.com/broadinstitute/gatk/jobs/498538890) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.4/tests/test/index.html) |; | unit | openjdk8 | [33752.3](https://travis-ci.com/broadinstitute/gatk/jobs/498538889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.3/tests/test/index.html) |; | conda | openjdk8 | [33752.5](https://travis-ci.com/broadinstitute/gatk/jobs/498538891) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.5/tests/test/index.html) |; | integration | openjdk8 | [33752.2](https://travis-ci.com/broadinstitute/gatk/jobs/498538888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.2/tests/test/index.html) |; | cloud | openjdk11 | [33752.14](https://travis-ci.com/broadinstitute/gatk/jobs/498538900) | [logs](https://storage.g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [33764](https://travis-ci.com/broadinstitute/gatk/builds/223104949); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [33764.13](https://travis-ci.com/broadinstitute/gatk/jobs/498596230) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_33764.13/tests/test/index.html) |; | integration | openjdk11 | [33764.12](https://travis-ci.com/broadinstitute/gatk/jobs/498596229) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_33764.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7192#issuecomment-819880055:431,integrat,integration,431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7192#issuecomment-819880055,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [33778](https://travis-ci.com/broadinstitute/gatk/builds/223218042); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [33778.1](https://travis-ci.com/broadinstitute/gatk/jobs/498881502) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.1/tests/test/index.html) |; | cloud | openjdk11 | [33778.14](https://travis-ci.com/broadinstitute/gatk/jobs/498881515) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.14/tests/test/index.html) |; | unit | openjdk11 | [33778.13](https://travis-ci.com/broadinstitute/gatk/jobs/498881514) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.13/tests/test/index.html) |; | integration | openjdk11 | [33778.12](https://travis-ci.com/broadinstitute/gatk/jobs/498881513) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33778.4](https://travis-ci.com/broadinstitute/gatk/jobs/498881505) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.4/tests/test/index.html) |; | unit | openjdk8 | [33778.3](https://travis-ci.com/broadinstitute/gatk/jobs/498881504) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-820624091:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-820624091,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [33826](https://travis-ci.com/broadinstitute/gatk/builds/223338129); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [33826.13](https://travis-ci.com/broadinstitute/gatk/jobs/499176631) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.13/tests/test/index.html) |; | integration | openjdk11 | [33826.12](https://travis-ci.com/broadinstitute/gatk/jobs/499176630) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.12/tests/test/index.html) |; | unit | openjdk8 | [33826.3](https://travis-ci.com/broadinstitute/gatk/jobs/499176621) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.3/tests/test/index.html) |; | variantcalling | openjdk8 | [33826.4](https://travis-ci.com/broadinstitute/gatk/jobs/499176622) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.4/tests/test/index.html) |; | integration | openjdk8 | [33826.2](https://travis-ci.com/broadinstitute/gatk/jobs/499176620) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-821531530:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-821531530,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33926](https://travis-ci.com/broadinstitute/gatk/builds/224016577); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [33926.14](https://travis-ci.com/broadinstitute/gatk/jobs/500776650) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.14/tests/test/index.html) |; | cloud | openjdk8 | [33926.1](https://travis-ci.com/broadinstitute/gatk/jobs/500776637) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.1/tests/test/index.html) |; | integration | openjdk11 | [33926.12](https://travis-ci.com/broadinstitute/gatk/jobs/500776648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33926.4](https://travis-ci.com/broadinstitute/gatk/jobs/500776640) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.4/tests/test/index.html) |; | integration | openjdk8 | [33926.2](https://travis-ci.com/broadinstitute/gatk/jobs/500776638) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6514#issuecomment-825820423:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6514#issuecomment-825820423,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34034](https://travis-ci.com/broadinstitute/gatk/builds/224639210); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [34034.1](https://travis-ci.com/broadinstitute/gatk/jobs/502313480) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.1/tests/test/index.html) |; | cloud | openjdk11 | [34034.14](https://travis-ci.com/broadinstitute/gatk/jobs/502313493) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.14/tests/test/index.html) |; | unit | openjdk11 | [34034.13](https://travis-ci.com/broadinstitute/gatk/jobs/502313492) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.13/tests/test/index.html) |; | integration | openjdk11 | [34034.12](https://travis-ci.com/broadinstitute/gatk/jobs/502313491) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.12/tests/test/index.html) |; | variantcalling | openjdk8 | [34034.4](https://travis-ci.com/broadinstitute/gatk/jobs/502313483) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.4/tests/test/index.html) |; | conda | openjdk8 | [34034.5](https://travis-ci.com/broadinstitute/gatk/jobs/502313484) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.5/tests/test/index.html) |; | unit | openjdk8 | [34034.3](https://travis-ci.com/broadinstitute/gatk/jobs/502313482) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.3/tests/test/index.html) |; | integration | openjdk8 | [34034.2](https://travis-ci.com/broadinstitute/gatk/jobs/502313481) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-830228734:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-830228734,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34176](https://travis-ci.com/broadinstitute/gatk/builds/225873785); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34176.12](https://travis-ci.com/broadinstitute/gatk/jobs/505251208) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34176.12/tests/test/index.html) |; | integration | openjdk8 | [34176.2](https://travis-ci.com/broadinstitute/gatk/jobs/505251198) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34176.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-840825700:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-840825700,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34203](https://travis-ci.com/broadinstitute/gatk/builds/226224930); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34203.12](https://travis-ci.com/broadinstitute/gatk/jobs/506165950) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34203.12/tests/test/index.html) |; | integration | openjdk8 | [34203.2](https://travis-ci.com/broadinstitute/gatk/jobs/506165940) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34203.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-843369362:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-843369362,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34279](https://travis-ci.com/broadinstitute/gatk/builds/226733391); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34279.12](https://travis-ci.com/broadinstitute/gatk/jobs/507507826) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34279.12/tests/test/index.html) |; | integration | openjdk8 | [34279.2](https://travis-ci.com/broadinstitute/gatk/jobs/507507816) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34279.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-847313079:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-847313079,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34296](https://travis-ci.com/broadinstitute/gatk/builds/226870023); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34296.12](https://travis-ci.com/broadinstitute/gatk/jobs/507857713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34296.12/tests/test/index.html) |; | integration | openjdk8 | [34296.2](https://travis-ci.com/broadinstitute/gatk/jobs/507857703) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34296.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-848129767:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-848129767,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34321](https://travis-ci.com/broadinstitute/gatk/builds/227013958); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34321.12](https://travis-ci.com/broadinstitute/gatk/jobs/508266496) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_34321.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-849067439:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-849067439,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [34441](https://travis-ci.com/broadinstitute/gatk/builds/228463818); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34441.12](https://travis-ci.com/broadinstitute/gatk/jobs/512421669) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.12/tests/test/index.html) |; | unit | openjdk8 | [34441.3](https://travis-ci.com/broadinstitute/gatk/jobs/512421660) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.3/tests/test/index.html) |; | variantcalling | openjdk8 | [34441.4](https://travis-ci.com/broadinstitute/gatk/jobs/512421661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.4/tests/test/index.html) |; | integration | openjdk8 | [34441.2](https://travis-ci.com/broadinstitute/gatk/jobs/512421659) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-857761857:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-857761857,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34475](https://travis-ci.com/broadinstitute/gatk/builds/228578939); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34475.12](https://travis-ci.com/broadinstitute/gatk/jobs/512727645) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34475.12/tests/test/index.html) |; | integration | openjdk8 | [34475.2](https://travis-ci.com/broadinstitute/gatk/jobs/512727635) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34475.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7303#issuecomment-858525709:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7303#issuecomment-858525709,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34532](https://travis-ci.com/broadinstitute/gatk/builds/228754848); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34532.12](https://travis-ci.com/broadinstitute/gatk/jobs/513165911) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.12/tests/test/index.html) |; | unit | openjdk8 | [34532.3](https://travis-ci.com/broadinstitute/gatk/jobs/513165902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.3/tests/test/index.html) |; | variantcalling | openjdk8 | [34532.4](https://travis-ci.com/broadinstitute/gatk/jobs/513165903) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.4/tests/test/index.html) |; | integration | openjdk8 | [34532.2](https://travis-ci.com/broadinstitute/gatk/jobs/513165901) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-859898603:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-859898603,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34651](https://travis-ci.com/broadinstitute/gatk/builds/230215055); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34651.12](https://travis-ci.com/broadinstitute/gatk/jobs/517109941) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34651.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7295#issuecomment-865183878:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7295#issuecomment-865183878,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [34916](https://app.travis-ci.com/broadinstitute/gatk/builds/232376083); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34916.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/523434656) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_34916.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7305#issuecomment-877695650:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7305#issuecomment-877695650,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [34953](https://app.travis-ci.com/broadinstitute/gatk/builds/232776802); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34953.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524527790) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34953.12/tests/test/index.html) |; | integration | openjdk8 | [34953.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524527780) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34953.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-880180901:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-880180901,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34955](https://app.travis-ci.com/broadinstitute/gatk/builds/232778439); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34955.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524531918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34955.12/tests/test/index.html) |; | integration | openjdk8 | [34955.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524531908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34955.2/tests/test/index.html) |; | integration | openjdk11 | [34955.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524531918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34955.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-880195656:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-880195656,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [34968](https://app.travis-ci.com/broadinstitute/gatk/builds/232871891); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34968.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524746057) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_34968.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7342#issuecomment-880918843:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7342#issuecomment-880918843,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [34975](https://app.travis-ci.com/broadinstitute/gatk/builds/232883183); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34975.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524775421) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34975.12/tests/test/index.html) |; | integration | openjdk8 | [34975.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524775411) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34975.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-880991859:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-880991859,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34989](https://app.travis-ci.com/broadinstitute/gatk/builds/232957715); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34989.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524971906) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34989.12/tests/test/index.html) |; | integration | openjdk8 | [34989.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524971896) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34989.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881554091:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881554091,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34993](https://app.travis-ci.com/broadinstitute/gatk/builds/232963432); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34993.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524986404) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34993.12/tests/test/index.html) |; | integration | openjdk8 | [34993.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524986393) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34993.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881599208:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881599208,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34997](https://app.travis-ci.com/broadinstitute/gatk/builds/232970936); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34997.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/525003829) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34997.12/tests/test/index.html) |; | integration | openjdk8 | [34997.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/525003819) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34997.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652786:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652786,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34999](https://app.travis-ci.com/broadinstitute/gatk/builds/232971052); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34999.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/525004179) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34999.12/tests/test/index.html) |; | integration | openjdk8 | [34999.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/525004169) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34999.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652638:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652638,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35038](https://app.travis-ci.com/broadinstitute/gatk/builds/233229631); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [35038.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731805) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.1/tests/test/index.html) |; | cloud | openjdk11 | [35038.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731818) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.14/tests/test/index.html) |; | unit | openjdk11 | [35038.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731817) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.13/tests/test/index.html) |; | integration | openjdk11 | [35038.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731816) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.12/tests/test/index.html) |; | unit | openjdk8 | [35038.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731807) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.3/tests/test/index.html) |; | variantcalling | openjdk8 | [35038.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.4/tests/test/index.html) |; | conda | openjdk8 | [35038.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731809) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.5/tests/test/index.html) |; | integration | openjdk8 | [35038.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731806) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-883544427:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-883544427,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35066](https://app.travis-ci.com/broadinstitute/gatk/builds/233352611); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [35066.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.1/tests/test/index.html) |; | cloud | openjdk11 | [35066.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.14/tests/test/index.html) |; | unit | openjdk11 | [35066.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037660) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.13/tests/test/index.html) |; | integration | openjdk11 | [35066.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037659) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.12/tests/test/index.html) |; | unit | openjdk8 | [35066.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037650) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.3/tests/test/index.html) |; | variantcalling | openjdk8 | [35066.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037651) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.4/tests/test/index.html) |; | conda | openjdk8 | [35066.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037652) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.5/tests/test/index.html) |; | integration | openjdk8 | [35066.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037649) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884405742:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884405742,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35068](https://app.travis-ci.com/broadinstitute/gatk/builds/233354016); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [35068.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041270) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.14/tests/test/index.html) |; | cloud | openjdk8 | [35068.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041257) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.1/tests/test/index.html) |; | unit | openjdk11 | [35068.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041269) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.13/tests/test/index.html) |; | integration | openjdk11 | [35068.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041268) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.12/tests/test/index.html) |; | unit | openjdk8 | [35068.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041259) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.3/tests/test/index.html) |; | conda | openjdk8 | [35068.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041261) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.5/tests/test/index.html) |; | variantcalling | openjdk8 | [35068.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041260) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.4/tests/test/index.html) |; | integration | openjdk8 | [35068.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041258) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884419815:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884419815,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35073](https://app.travis-ci.com/broadinstitute/gatk/builds/233356361); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [35073.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.1/tests/test/index.html) |; | cloud | openjdk11 | [35073.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047091) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.14/tests/test/index.html) |; | unit | openjdk11 | [35073.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047090) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.13/tests/test/index.html) |; | integration | openjdk11 | [35073.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047089) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.12/tests/test/index.html) |; | unit | openjdk8 | [35073.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.3/tests/test/index.html) |; | conda | openjdk8 | [35073.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047082) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.5/tests/test/index.html) |; | variantcalling | openjdk8 | [35073.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.4/tests/test/index.html) |; | integration | openjdk8 | [35073.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884440415:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884440415,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35075](https://app.travis-ci.com/broadinstitute/gatk/builds/233357441); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35075.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050087) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.13/tests/test/index.html) |; | integration | openjdk11 | [35075.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050086) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.12/tests/test/index.html) |; | unit | openjdk8 | [35075.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050077) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.3/tests/test/index.html) |; | integration | openjdk8 | [35075.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050076) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884464290:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884464290,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35077](https://app.travis-ci.com/broadinstitute/gatk/builds/233357592); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35077.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050451) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.13/tests/test/index.html) |; | integration | openjdk11 | [35077.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050450) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.12/tests/test/index.html) |; | unit | openjdk8 | [35077.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050441) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.3/tests/test/index.html) |; | integration | openjdk8 | [35077.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050440) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884466100:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884466100,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35104](https://app.travis-ci.com/broadinstitute/gatk/builds/233468304); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35104.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328126) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.13/tests/test/index.html) |; | integration | openjdk11 | [35104.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328125) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.12/tests/test/index.html) |; | unit | openjdk8 | [35104.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328116) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.3/tests/test/index.html) |; | integration | openjdk8 | [35104.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328115) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-885267425:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-885267425,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35151](https://app.travis-ci.com/broadinstitute/gatk/builds/233705984); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35151.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977289) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.13/tests/test/index.html) |; | integration | openjdk11 | [35151.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977288) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.12/tests/test/index.html) |; | unit | openjdk8 | [35151.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.3/tests/test/index.html) |; | integration | openjdk8 | [35151.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977278) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-886981872:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-886981872,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35153](https://app.travis-ci.com/broadinstitute/gatk/builds/233712151); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35153.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992860) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.13/tests/test/index.html) |; | integration | openjdk11 | [35153.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992859) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.12/tests/test/index.html) |; | unit | openjdk8 | [35153.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992850) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.3/tests/test/index.html) |; | integration | openjdk8 | [35153.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992849) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887032589:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887032589,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35156](https://app.travis-ci.com/broadinstitute/gatk/builds/233712370); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35156.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993410) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.13/tests/test/index.html) |; | integration | openjdk11 | [35156.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993409) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.12/tests/test/index.html) |; | unit | openjdk8 | [35156.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993400) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.3/tests/test/index.html) |; | integration | openjdk8 | [35156.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993399) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887035947:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887035947,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35159](https://app.travis-ci.com/broadinstitute/gatk/builds/233733841); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35159.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041438) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.13/tests/test/index.html) |; | integration | openjdk11 | [35159.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041437) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.12/tests/test/index.html) |; | unit | openjdk8 | [35159.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041428) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.3/tests/test/index.html) |; | integration | openjdk8 | [35159.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041427) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887209071:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887209071,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35162](https://app.travis-ci.com/broadinstitute/gatk/builds/233781027); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35162.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164191) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.13/tests/test/index.html) |; | integration | openjdk11 | [35162.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164190) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.12/tests/test/index.html) |; | unit | openjdk8 | [35162.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164181) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.3/tests/test/index.html) |; | integration | openjdk8 | [35162.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164180) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-887581627:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-887581627,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35191](https://app.travis-ci.com/broadinstitute/gatk/builds/233897916); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35191.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/527474110) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35191.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7378#issuecomment-888459910:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7378#issuecomment-888459910,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35222](https://app.travis-ci.com/broadinstitute/gatk/builds/234104192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35222.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/528002701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35222.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7355#issuecomment-889960163:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7355#issuecomment-889960163,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35263](https://app.travis-ci.com/broadinstitute/gatk/builds/234381437); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35263.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/528794786) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35263.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7389#issuecomment-891948742:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7389#issuecomment-891948742,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35281](https://app.travis-ci.com/broadinstitute/gatk/builds/234493943); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35281.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.13/tests/test/index.html) |; | integration | openjdk11 | [35281.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086897) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35281.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.4/tests/test/index.html) |; | unit | openjdk8 | [35281.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.3/tests/test/index.html) |; | integration | openjdk8 | [35281.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892730894:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892730894,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35283](https://app.travis-ci.com/broadinstitute/gatk/builds/234495207); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35283.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529090922) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35283.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35283.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529090914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35283.4/tests/test/index.html) |; | integration | openjdk8 | [35283.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529090912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35283.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892751062:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892751062,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35285](https://app.travis-ci.com/broadinstitute/gatk/builds/234495551); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35285.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529091673) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35285.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35285.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529091665) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35285.4/tests/test/index.html) |; | integration | openjdk8 | [35285.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529091663) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35285.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892753629:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892753629,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35299](https://app.travis-ci.com/broadinstitute/gatk/builds/234500111); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35299.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102784) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.13/tests/test/index.html) |; | integration | openjdk11 | [35299.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102783) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.12/tests/test/index.html) |; | unit | openjdk8 | [35299.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102774) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.3/tests/test/index.html) |; | variantcalling | openjdk8 | [35299.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102775) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.4/tests/test/index.html) |; | integration | openjdk8 | [35299.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102773) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892780628:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892780628,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35352](https://app.travis-ci.com/broadinstitute/gatk/builds/234805799); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35352.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529942933) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35352.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7381#issuecomment-894924291:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7381#issuecomment-894924291,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35359](https://app.travis-ci.com/broadinstitute/gatk/builds/234864331); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35359.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/530084737) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35359.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7396#issuecomment-895367993:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7396#issuecomment-895367993,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35408](https://app.travis-ci.com/broadinstitute/gatk/builds/235081908); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [35408.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/530725600) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35408.4/tests/test/index.html) |; | integration | openjdk8 | [35408.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/530725598) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896970810:440,integrat,integration,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896970810,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35460](https://app.travis-ci.com/broadinstitute/gatk/builds/235309831); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35460.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531318301) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35460.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898668477:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898668477,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35462](https://app.travis-ci.com/broadinstitute/gatk/builds/235310455); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35462.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531320214) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35462.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898675262:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898675262,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35466](https://app.travis-ci.com/broadinstitute/gatk/builds/235310716); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35466.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531321172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35466.12/tests/test/index.html) |; | integration | openjdk8 | [35466.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/531321162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35466.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-898680924:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-898680924,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35514](https://app.travis-ci.com/broadinstitute/gatk/builds/235493198); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35514.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531838051) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35514.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-899777125:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-899777125,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35542](https://app.travis-ci.com/broadinstitute/gatk/builds/235595824); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35542.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532100892) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35542.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35542.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/532100884) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35542.4/tests/test/index.html) |; | integration | openjdk8 | [35542.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532100882) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35542.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900593417:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900593417,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35544](https://app.travis-ci.com/broadinstitute/gatk/builds/235596805); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35544.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103274) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35544.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35544.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103266) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35544.4/tests/test/index.html) |; | integration | openjdk8 | [35544.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103264) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35544.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900601946:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900601946,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35546](https://app.travis-ci.com/broadinstitute/gatk/builds/235596899); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35546.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103522) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35546.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35546.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103514) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35546.4/tests/test/index.html) |; | integration | openjdk8 | [35546.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103512) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35546.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900603007:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900603007,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35614](https://app.travis-ci.com/broadinstitute/gatk/builds/235796214); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35614.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702729) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.13/tests/test/index.html) |; | integration | openjdk11 | [35614.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702728) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.12/tests/test/index.html) |; | unit | openjdk8 | [35614.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702719) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.3/tests/test/index.html) |; | integration | openjdk8 | [35614.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702718) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-902180244:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-902180244,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35652](https://app.travis-ci.com/broadinstitute/gatk/builds/236008516); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35652.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/533261173) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35652.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7435#issuecomment-903940281:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7435#issuecomment-903940281,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35656](https://app.travis-ci.com/broadinstitute/gatk/builds/236041444); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35656.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/533345256) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35656.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904228563:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904228563,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35662](https://app.travis-ci.com/broadinstitute/gatk/builds/236042965); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35662.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/533348915) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35662.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904245474:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904245474,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35724](https://app.travis-ci.com/broadinstitute/gatk/builds/236321310); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35724.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/534059154) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35724.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7440#issuecomment-906727232:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7440#issuecomment-906727232,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35827](https://app.travis-ci.com/broadinstitute/gatk/builds/236734529); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35827.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.13/tests/test/index.html) |; | integration | openjdk11 | [35827.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.12/tests/test/index.html) |; | unit | openjdk8 | [35827.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106150) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.3/tests/test/index.html) |; | integration | openjdk8 | [35827.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-910535218:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-910535218,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35833](https://app.travis-ci.com/broadinstitute/gatk/builds/236752487); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35833.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149111) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.13/tests/test/index.html) |; | integration | openjdk11 | [35833.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149110) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.12/tests/test/index.html) |; | unit | openjdk8 | [35833.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149101) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.3/tests/test/index.html) |; | integration | openjdk8 | [35833.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149100) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-910840432:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-910840432,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35880](https://app.travis-ci.com/broadinstitute/gatk/builds/237199054); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35880.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536209432) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35880.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7426#issuecomment-915310800:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7426#issuecomment-915310800,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35897](https://app.travis-ci.com/broadinstitute/gatk/builds/237244422); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35897.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536323693) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35897.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7457#issuecomment-915694430:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7457#issuecomment-915694430,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35935](https://app.travis-ci.com/broadinstitute/gatk/builds/237322016); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35935.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536512235) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35935.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916403114:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916403114,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35951](https://app.travis-ci.com/broadinstitute/gatk/builds/237326442); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35951.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536522087) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35951.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916440221:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916440221,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36058](https://app.travis-ci.com/broadinstitute/gatk/builds/237840259); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36058.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/537863419) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36058.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-921082427:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-921082427,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36081](https://app.travis-ci.com/broadinstitute/gatk/builds/237929248); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36081.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538089676) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36081.12/tests/test/index.html) |; | integration | openjdk8 | [36081.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/538089666) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36081.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-921944948:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-921944948,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36105](https://app.travis-ci.com/broadinstitute/gatk/builds/238044050); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36105.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538399326) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36105.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7475#issuecomment-922931171:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7475#issuecomment-922931171,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36112](https://app.travis-ci.com/broadinstitute/gatk/builds/238062338); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36112.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538446562) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36112.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-923093725:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-923093725,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36116](https://app.travis-ci.com/broadinstitute/gatk/builds/238079815); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36116.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538495506) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36116.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7477#issuecomment-923269951:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7477#issuecomment-923269951,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36174](https://app.travis-ci.com/broadinstitute/gatk/builds/238460134); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36174.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/539549145) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36174.12/tests/test/index.html) |; | integration | openjdk8 | [36174.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/539549135) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36174.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926929814:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926929814,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36176](https://app.travis-ci.com/broadinstitute/gatk/builds/238460981); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36176.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/539551561) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36176.12/tests/test/index.html) |; | integration | openjdk8 | [36176.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/539551551) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36176.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926933533:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926933533,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36275](https://app.travis-ci.com/broadinstitute/gatk/builds/239090322); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36275.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/541228649) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36275.12/tests/test/index.html) |; | integration | openjdk8 | [36275.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/541228639) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36275.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7491#issuecomment-933868301:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7491#issuecomment-933868301,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36352](https://app.travis-ci.com/broadinstitute/gatk/builds/239379640); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36352.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/542050919) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36352.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7495#issuecomment-938192993:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7495#issuecomment-938192993,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36425](https://app.travis-ci.com/broadinstitute/gatk/builds/239885552); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36425.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/543355253) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36425.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7450#issuecomment-944020627:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7450#issuecomment-944020627,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36457](https://app.travis-ci.com/broadinstitute/gatk/builds/240144608); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36457.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544058431) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/rsa_parallelize_execute_sql_36457.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7509#issuecomment-946831152:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7509#issuecomment-946831152,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36459](https://app.travis-ci.com/broadinstitute/gatk/builds/240145151); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36459.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544060034) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36459.12/tests/test/index.html) |; | integration | openjdk8 | [36459.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/544060024) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36459.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946834797:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946834797,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36461](https://app.travis-ci.com/broadinstitute/gatk/builds/240145685); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36461.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544061450) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36461.12/tests/test/index.html) |; | integration | openjdk8 | [36461.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/544061440) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36461.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946842201:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946842201,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36463](https://app.travis-ci.com/broadinstitute/gatk/builds/240151564); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36463.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544076662) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36463.12/tests/test/index.html) |; | integration | openjdk8 | [36463.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/544076652) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36463.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946896833:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946896833,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36659](https://app.travis-ci.com/broadinstitute/gatk/builds/240872073); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36659.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893308) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.1/tests/test/index.html) |; | cloud | openjdk11 | [36659.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.14/tests/test/index.html) |; | integration | openjdk11 | [36659.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893319) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.12/tests/test/index.html) |; | integration | openjdk8 | [36659.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893309) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-955060271:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-955060271,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36699](https://app.travis-ci.com/broadinstitute/gatk/builds/241035376); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36699.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546298343) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36699.1/tests/test/index.html) |; | cloud | openjdk11 | [36699.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546298356) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36699.14/tests/test/index.html) |; | integration | openjdk11 | [36699.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546298354) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36699.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957815959:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957815959,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36704](https://app.travis-ci.com/broadinstitute/gatk/builds/241045493); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36704.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319630) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.1/tests/test/index.html) |; | cloud | openjdk11 | [36704.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319643) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.14/tests/test/index.html) |; | integration | openjdk11 | [36704.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319641) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.12/tests/test/index.html) |; | integration | openjdk8 | [36704.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319631) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957942604:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957942604,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36712](https://app.travis-ci.com/broadinstitute/gatk/builds/241134777); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36712.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539784) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.1/tests/test/index.html) |; | cloud | openjdk11 | [36712.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539797) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.14/tests/test/index.html) |; | integration | openjdk11 | [36712.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539795) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.12/tests/test/index.html) |; | integration | openjdk8 | [36712.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539785) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-959840632:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-959840632,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36716](https://app.travis-ci.com/broadinstitute/gatk/builds/241142844); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36716.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560178) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.1/tests/test/index.html) |; | cloud | openjdk11 | [36716.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560192) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.14/tests/test/index.html) |; | integration | openjdk11 | [36716.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560189) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.12/tests/test/index.html) |; | integration | openjdk8 | [36716.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560179) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-960096611:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-960096611,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36725](https://app.travis-ci.com/broadinstitute/gatk/builds/241190517); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36725.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546679928) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36725.12/tests/test/index.html) |; | integration | openjdk8 | [36725.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546679918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36725.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961166918:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961166918,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36729](https://app.travis-ci.com/broadinstitute/gatk/builds/241192115); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36729.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546683875) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36729.12/tests/test/index.html) |; | integration | openjdk8 | [36729.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546683865) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36729.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961184778:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961184778,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36733](https://app.travis-ci.com/broadinstitute/gatk/builds/241200444); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36733.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546705723) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36733.12/tests/test/index.html) |; | integration | openjdk8 | [36733.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546705713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36733.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961272306:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961272306,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36735](https://app.travis-ci.com/broadinstitute/gatk/builds/241201544); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36735.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546708298) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36735.12/tests/test/index.html) |; | integration | openjdk8 | [36735.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546708288) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36735.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961283261:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961283261,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36737](https://app.travis-ci.com/broadinstitute/gatk/builds/241202305); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36737.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36737.12/tests/test/index.html) |; | integration | openjdk8 | [36737.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710269) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36737.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961293526:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961293526,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36739](https://app.travis-ci.com/broadinstitute/gatk/builds/241202374); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36739.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710447) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36739.12/tests/test/index.html) |; | integration | openjdk8 | [36739.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710437) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36739.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961291100:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961291100,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36747](https://app.travis-ci.com/broadinstitute/gatk/builds/241218893); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36747.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546762423) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36747.12/tests/test/index.html) |; | integration | openjdk8 | [36747.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546762413) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36747.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961477821:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961477821,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36844](https://app.travis-ci.com/broadinstitute/gatk/builds/241531802); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36844.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/547544565) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36844.12/tests/test/index.html) |; | conda | openjdk8 | [36844.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/547544558) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36844.5/tests/test/index.html) |; | integration | openjdk8 | [36844.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/547544555) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36844.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7559#issuecomment-965446296:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7559#issuecomment-965446296,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36923](https://app.travis-ci.com/broadinstitute/gatk/builds/241945043); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36923.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548529658) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36923.12/tests/test/index.html) |; | integration | openjdk8 | [36923.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548529648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36923.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971704225:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971704225,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36925](https://app.travis-ci.com/broadinstitute/gatk/builds/241945819); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36925.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548531508) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36925.12/tests/test/index.html) |; | integration | openjdk8 | [36925.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548531498) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36925.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971715805:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971715805,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36927](https://app.travis-ci.com/broadinstitute/gatk/builds/241946394); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36927.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548532718) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36927.12/tests/test/index.html) |; | integration | openjdk8 | [36927.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548532708) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36927.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971720500:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971720500,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36937](https://app.travis-ci.com/broadinstitute/gatk/builds/242038149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36937.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548759909) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36937.12/tests/test/index.html) |; | integration | openjdk8 | [36937.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548759899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36937.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7571#issuecomment-973153376:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7571#issuecomment-973153376,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38060](https://app.travis-ci.com/broadinstitute/gatk/builds/247666991); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38060.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747871) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.13/tests/test/index.html) |; | integration | openjdk11 | [38060.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747870) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.12/tests/test/index.html) |; | unit | openjdk8 | [38060.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747861) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.3/tests/test/index.html) |; | integration | openjdk8 | [38060.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747860) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1063589941:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1063589941,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38083](https://app.travis-ci.com/broadinstitute/gatk/builds/247786992); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38083.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563060315) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38083.12/tests/test/index.html) |; | integration | openjdk8 | [38083.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563060305) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38083.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065595863:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065595863,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38087](https://app.travis-ci.com/broadinstitute/gatk/builds/247802968); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38087.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563097964) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38087.12/tests/test/index.html) |; | integration | openjdk8 | [38087.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563097954) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38087.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065926332:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065926332,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38091](https://app.travis-ci.com/broadinstitute/gatk/builds/247852896); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38091.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/563219289) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38091.13/tests/test/index.html) |; | integration | openjdk11 | [38091.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563219288) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38091.12/tests/test/index.html) |; | unit | openjdk8 | [38091.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/563219279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38091.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1066920877:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1066920877,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38096](https://app.travis-ci.com/broadinstitute/gatk/builds/247860433); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38096.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563238843) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38096.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067068324:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067068324,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38098](https://app.travis-ci.com/broadinstitute/gatk/builds/247860511); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38098.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563239018) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38098.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067069713:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067069713,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38100](https://app.travis-ci.com/broadinstitute/gatk/builds/247864839); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [38110](https://app.travis-ci.com/broadinstitute/gatk/builds/247893700); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [38110.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325496) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.14/tests/test/index.html) |; | cloud | openjdk8 | [38110.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325483) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.1/tests/test/index.html) |; | unit | openjdk11 | [38110.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325495) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.13/tests/test/index.html) |; | integration | openjdk11 | [38110.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325494) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.12/tests/test/index.html) |; | unit | openjdk8 | [38110.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325485) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.3/tests/test/index.html) |; | variantcalling | openjdk8 | [38110.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325486) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.4/tests/test/index.html) |; | integration | openjdk8 | [38110.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325484) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1067659375:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1067659375,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38112](https://app.travis-ci.com/broadinstitute/gatk/builds/247913834); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38112.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563379132) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38112.12/tests/test/index.html) |; | integration | openjdk8 | [38112.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563379122) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38112.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1068024511:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1068024511,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38115](https://app.travis-ci.com/broadinstitute/gatk/builds/247937100); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38115.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444106) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.1/tests/test/index.html) |; | cloud | openjdk11 | [38115.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444119) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.14/tests/test/index.html) |; | unit | openjdk11 | [38115.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444118) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.13/tests/test/index.html) |; | integration | openjdk11 | [38115.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444117) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.12/tests/test/index.html) |; | unit | openjdk8 | [38115.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444108) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.3/tests/test/index.html) |; | variantcalling | openjdk8 | [38115.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444109) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.4/tests/test/index.html) |; | integration | openjdk8 | [38115.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444107) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1068358237:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1068358237,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38129](https://app.travis-ci.com/broadinstitute/gatk/builds/248000561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38129.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563600186) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38129.12/tests/test/index.html) |; | integration | openjdk8 | [38129.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563600176) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38129.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069521375:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069521375,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38164](https://app.travis-ci.com/broadinstitute/gatk/builds/248125832); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38164.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917586) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.1/tests/test/index.html) |; | cloud | openjdk11 | [38164.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.14/tests/test/index.html) |; | conda | openjdk8 | [38164.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917590) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.5/tests/test/index.html) |; | integration | openjdk8 | [38164.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917587) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.2/tests/test/index.html) |; | variantcalling | openjdk8 | [38164.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917589) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072776529:852,integrat,integration,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072776529,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38166](https://app.travis-ci.com/broadinstitute/gatk/builds/248127071); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38166.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563920785) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38166.12/tests/test/index.html) |; | integration | openjdk8 | [38166.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563920775) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38166.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1072830769:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1072830769,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38168](https://app.travis-ci.com/broadinstitute/gatk/builds/248128606); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [38168.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924706) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.14/tests/test/index.html) |; | cloud | openjdk8 | [38168.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924693) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.1/tests/test/index.html) |; | integration | openjdk8 | [38168.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924694) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.2/tests/test/index.html) |; | conda | openjdk8 | [38168.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924697) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.5/tests/test/index.html) |; | variantcalling | openjdk8 | [38168.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924696) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072841847:643,integrat,integration,643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072841847,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38170](https://app.travis-ci.com/broadinstitute/gatk/builds/248128971); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38170.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.1/tests/test/index.html) |; | cloud | openjdk11 | [38170.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925524) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.14/tests/test/index.html) |; | conda | openjdk8 | [38170.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925515) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.5/tests/test/index.html) |; | integration | openjdk8 | [38170.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925512) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.2/tests/test/index.html) |; | variantcalling | openjdk8 | [38170.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925514) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072847450:852,integrat,integration,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072847450,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38174](https://app.travis-ci.com/broadinstitute/gatk/builds/248186522); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38174.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564065551) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38174.12/tests/test/index.html) |; | integration | openjdk8 | [38174.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564065541) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38174.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074044045:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074044045,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38177](https://app.travis-ci.com/broadinstitute/gatk/builds/248191891); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38177.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564080035) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38177.12/tests/test/index.html) |; | integration | openjdk8 | [38177.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564080025) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38177.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074141420:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074141420,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38179](https://app.travis-ci.com/broadinstitute/gatk/builds/248192670); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38179.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564082094) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38179.12/tests/test/index.html) |; | integration | openjdk8 | [38179.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564082084) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38179.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074156376:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074156376,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38183](https://app.travis-ci.com/broadinstitute/gatk/builds/248198988); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38183.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564098711) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38183.12/tests/test/index.html) |; | integration | openjdk8 | [38183.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564098701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38183.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074271488:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074271488,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38185](https://app.travis-ci.com/broadinstitute/gatk/builds/248205358); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38185.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564114801) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38185.12/tests/test/index.html) |; | integration | openjdk8 | [38185.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564114791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38185.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074353651:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074353651,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38187](https://app.travis-ci.com/broadinstitute/gatk/builds/248207168); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38187.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564119758) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38187.12/tests/test/index.html) |; | integration | openjdk8 | [38187.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564119748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38187.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074389896:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074389896,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38191](https://app.travis-ci.com/broadinstitute/gatk/builds/248213511); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38191.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564136597) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38191.12/tests/test/index.html) |; | integration | openjdk8 | [38191.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564136587) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38191.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074495163:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074495163,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38203](https://app.travis-ci.com/broadinstitute/gatk/builds/248266948); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38203.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564269407) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38203.12/tests/test/index.html) |; | integration | openjdk8 | [38203.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564269397) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38203.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1075494924:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1075494924,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38216](https://app.travis-ci.com/broadinstitute/gatk/builds/248313687); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38216.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383062) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.13/tests/test/index.html) |; | integration | openjdk11 | [38216.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383061) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.12/tests/test/index.html) |; | unit | openjdk8 | [38216.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383052) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.3/tests/test/index.html) |; | integration | openjdk8 | [38216.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383051) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1076366765:439,integrat,integration,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1076366765,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38225](https://app.travis-ci.com/broadinstitute/gatk/builds/248338488); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38225.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564447801) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38225.12/tests/test/index.html) |; | integration | openjdk8 | [38225.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564447791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38225.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1076776102:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1076776102,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38233](https://app.travis-ci.com/broadinstitute/gatk/builds/248387440); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38233.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564566861) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38233.12/tests/test/index.html) |; | integration | openjdk8 | [38233.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564566851) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38233.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7733#issuecomment-1077790207:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7733#issuecomment-1077790207,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38284](https://app.travis-ci.com/broadinstitute/gatk/builds/248554579); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38284.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972333) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.13/tests/test/index.html) |; | integration | openjdk11 | [38284.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.12/tests/test/index.html) |; | cloud | openjdk8 | [38284.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.1/tests/test/index.html) |; | cloud | openjdk11 | [38284.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972334) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.14/tests/test/index.html) |; | unit | openjdk8 | [38284.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081073154:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081073154,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38286](https://app.travis-ci.com/broadinstitute/gatk/builds/248555577); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38286.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564975067) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38286.12/tests/test/index.html) |; | integration | openjdk8 | [38286.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564975057) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38286.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1081135051:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1081135051,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38293](https://app.travis-ci.com/broadinstitute/gatk/builds/248569068); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38293.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565009924) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38293.12/tests/test/index.html) |; | integration | openjdk8 | [38293.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565009914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38293.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7664#issuecomment-1081368863:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7664#issuecomment-1081368863,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38297](https://app.travis-ci.com/broadinstitute/gatk/builds/248597167); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38297.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077614) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.13/tests/test/index.html) |; | integration | openjdk11 | [38297.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077613) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.12/tests/test/index.html) |; | cloud | openjdk8 | [38297.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.1/tests/test/index.html) |; | cloud | openjdk11 | [38297.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077615) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.14/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081845776:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081845776,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38312](https://app.travis-ci.com/broadinstitute/gatk/builds/248621240); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38312.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565138626) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38312.12/tests/test/index.html) |; | integration | openjdk8 | [38312.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565138616) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38312.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1082317832:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1082317832,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38347](https://app.travis-ci.com/broadinstitute/gatk/builds/248689004); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38347.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565306999) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38347.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7746#issuecomment-1083594910:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7746#issuecomment-1083594910,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38393](https://app.travis-ci.com/broadinstitute/gatk/builds/248813440); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38393.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618194) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.1/tests/test/index.html) |; | cloud | openjdk11 | [38393.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618207) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.14/tests/test/index.html) |; | conda | openjdk8 | [38393.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618198) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.5/tests/test/index.html) |; | integration | openjdk8 | [38393.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618195) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.2/tests/test/index.html) |; | variantcalling | openjdk8 | [38393.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618197) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1086251277:852,integrat,integration,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1086251277,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38445](https://app.travis-ci.com/broadinstitute/gatk/builds/248902356); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38445.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565826830) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38445.12/tests/test/index.html) |; | integration | openjdk8 | [38445.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565826820) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7750#issuecomment-1087979534:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7750#issuecomment-1087979534,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38522](https://app.travis-ci.com/broadinstitute/gatk/builds/249024354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38522.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566140964) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38522.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1090476624:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1090476624,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38567](https://app.travis-ci.com/broadinstitute/gatk/builds/249037237); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [38567.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/566174075) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38567.2/tests/test/index.html) |; | conda | openjdk8 | [38567.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/566174078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38567.5/tests/test/index.html) |; | variantcalling | openjdk8 | [38567.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/566174077) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38567.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1090792544:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1090792544,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38623](https://app.travis-ci.com/broadinstitute/gatk/builds/249089579); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38623.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566299427) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38623.12/tests/test/index.html) |; | integration | openjdk8 | [38623.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/566299417) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38623.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7752#issuecomment-1091967282:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7752#issuecomment-1091967282,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38735](https://app.travis-ci.com/broadinstitute/gatk/builds/249251446); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38735.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566697912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38735.12/tests/test/index.html) |; | integration | openjdk11 | [38735.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566697912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38735.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7713#issuecomment-1095535534:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7713#issuecomment-1095535534,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38745](https://app.travis-ci.com/broadinstitute/gatk/builds/249258011); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38745.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566714710) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38745.12/tests/test/index.html) |; | integration | openjdk8 | [38745.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/566714700) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38745.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7773#issuecomment-1095668751:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7773#issuecomment-1095668751,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38757](https://app.travis-ci.com/broadinstitute/gatk/builds/249261923); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38757.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566724825) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38757.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7772#issuecomment-1095767061:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7772#issuecomment-1095767061,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38788](https://app.travis-ci.com/broadinstitute/gatk/builds/249322535); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38788.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566886037) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38788.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7776#issuecomment-1097243112:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7776#issuecomment-1097243112,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38872](https://app.travis-ci.com/broadinstitute/gatk/builds/249441958); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38872.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/567177790) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38872.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7784#issuecomment-1099583851:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7784#issuecomment-1099583851,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38983](https://app.travis-ci.com/broadinstitute/gatk/builds/249657082); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38983.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/567712058) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38983.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7801#issuecomment-1104482113:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7801#issuecomment-1104482113,1,['integrat'],['integration']
Integrability,"Two high level questions/concerns about the implementation… . 1. I think when things are parallelized, we then lose the retries. In order to do that, we might need to get a little more python async-y than I was originally thinking. The retries are pretty important to recover from transient errors in BQ. 2. I think perhaps the ordering/dependecies are lost between queries? It looks like we fire them all off and then wait for them all to complete. But really we need to wait for the vet_new queries to finish before launching the pet queries since they depend on data from the vet_new. If vet_new hasn't started this would fail… but if vet_new has created the table we'll just get the wrong results",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7505#issuecomment-944301753:337,depend,dependecies,337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7505#issuecomment-944301753,2,['depend'],"['depend', 'dependecies']"
Integrability,"USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:01:51.713 INFO SortSam - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 18:01:51.713 INFO SortSam - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:01:51.713 INFO SortSam - Defaults.USE_CRAM_REF_DOWNLOAD : false; 18:01:51.713 INFO SortSam - Deflater IntelDeflater; 18:01:51.713 INFO SortSam - Initializing engine; 18:01:51.713 INFO SortSam - Done initializing engine; 18:02:01.512 INFO SortSam - Shutting down engine; [December 7, 2016 6:02:01 PM AST] org.broadinstitute.hellbender.tools.picard.sam.SortSam done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=1911029760; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/xerial/snappy/LoadSnappy; 	at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:86); 	at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:52); 	at htsjdk.samtools.util.TempStreamFactory.getSnappyLoader(TempStreamFactory.java:42); 	at htsjdk.samtools.util.TempStreamFactory.wrapTempOutputStream(TempStreamFactory.java:74); 	at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:223); 	at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:166); 	at htsjdk.samtools.SAMFileWriterImpl.addAlignment(SAMFileWriterImpl.java:192); 	at org.broadinstitute.hellbender.tools.picard.sam.SortSam.doWork(SortSam.java:52); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:62); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); Caused by: java.lang.ClassNotFoundException: org.xerial.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2299#issuecomment-265469924:2090,wrap,wrapTempOutputStream,2090,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2299#issuecomment-265469924,1,['wrap'],['wrapTempOutputStream']
Integrability,"Ugh, there's some wierd bug with one of our dependencies not understanding java version id's with 4 parts. The install java action must have just moved from installing 11.0.16 too 11.0.16.1 behind our back. It sounds like we have to update Jetty or something manually. ```; java.lang.ExceptionInInitializerError; at org.eclipse.jetty.webapp.WebInfConfiguration.findAndFilterContainerPaths(WebInfConfiguration.java:185); at org.eclipse.jetty.webapp.WebInfConfiguration.preConfigure(WebInfConfiguration.java:155); at org.eclipse.jetty.webapp.WebAppContext.preConfigure(WebAppContext.java:485); at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:521); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:131); at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:113); at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:131); at org.eclipse.jetty.server.Server.start(Server.java:[42](https://github.com/broadinstitute/gatk/actions/runs/3499912997/jobs/5862011952#step:10:43)7); at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:105); at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61); at org.eclipse.jetty.server.Server.doStart(Server.java:394); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1155); at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:181); at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:885); at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(Nam",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8098#issuecomment-1320505279:44,depend,dependencies,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8098#issuecomment-1320505279,1,['depend'],['dependencies']
Integrability,Unfortunate that the commit message is incorrect (2.5.0 vs 2.15.0). Might it be worth fixing up the commit history?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7600#issuecomment-993113043:28,message,message,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7600#issuecomment-993113043,1,['message'],['message']
Integrability,"Unfortunately I don't think it's practical to try to enforce that ""only the arg parser can throw `CommandLineException`"" -- there's too much downstream code and too many tools that do so already, so it would be a bit painful to treat it as a bug. Instead I think what we should do is:. * Make sure that barclay uses a separate exception class for internal errors that are not the user's fault. This internal exception class should not be usable outside of barclay (perhaps we can make it package-private?).; * Catch `CommandLineException` in GATK and present it as a user error (output should say ""A USER ERROR HAS OCCURRED"").; * Move the `printDecoratedUserExceptionMessage()` call for caught `CommandLineExceptions` from `CommandLineProgram.parseArgs()` to `Main.mainEntry()`, to ensure that a message always gets printed for `CommandLineException`. As @cmnbroad said, this will have to wait until after the holiday break (most of us are going to be away until early January).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268828854:796,message,message,796,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268828854,2,['message'],['message']
Integrability,Unfortunately we can't merge this until we get the corresponding Barclay changes released in Barclay and integrated into GATK.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311:105,integrat,integrated,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311,1,['integrat'],['integrated']
Integrability,"Unit and integration tests are now all passing on openjdk11. The build does not however work on Java 8, since the javadoc compilation has been commented out. This will need to be made conditional on the Java version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-529514256:9,integrat,integration,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-529514256,1,['integrat'],['integration']
Integrability,"Update: I wrote an integration test in my branch that runs M2 with ; `--kmer-size 1 --dont-increase-kmer-sizes-for-cycles`. It still calls the given alleles, whereas in master it does not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571:19,integrat,integration,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571,1,['integrat'],['integration']
Integrability,"Updated with [this](https://github.com/SHuang-Broad/JNIFermiLite). @cwhelan would you mind taking a brief look and see what improvements can be made to the interface?; @lbergelson I also added you as a contributor so later if we decide to make use of fermi-lite in the SV pipeline, you'll be in control. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2072#issuecomment-237125901:156,interface,interface,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2072#issuecomment-237125901,1,['interface'],['interface']
Integrability,"Used to be used. Used to be tested through an integration test that is no longer, I guess. Merge away. @lbergelson",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074:46,integrat,integration,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074,1,['integrat'],['integration']
Integrability,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:123,message,message,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504,4,"['depend', 'message']","['dependencies', 'dependent', 'message']"
Integrability,"Using the latest version of ADAM (which has a Scala 2.12 version) fixes the 2bit failures. I also added a fix for the `java.nio.ByteBuffer.clear()` problem. All unit tests are passing, and the only integration test failures are the `Could not serialize lambda` problems. It should be possible to fix these by making the relevant classes implement `Serializable` (like in https://github.com/samtools/htsjdk/pull/1408).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527483090:198,integrat,integration,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527483090,2,['integrat'],['integration']
Integrability,"Usually when we see silent failures like what's happening in singularity, it's due to an out of memory error that results in the JVM process being rudely killed before it can output an error message. It's possible that's what's happening there. If you're running in a container with a limited memory pool, you have to be sure to set the java memory explicitly with -Xmx, but also be sure to leave some memory left over for the system and for native code invoked by java. For example, if you have a container with 8G of memory available I would set -Xmx7g to leave a bit of overhead available. . I think trying with a newer release of java 17 is a good idea.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8988#issuecomment-2386655253:191,message,message,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8988#issuecomment-2386655253,1,['message'],['message']
Integrability,"VariantQC is a tool we made that is somewhat analogous to FastQC. Given an input VCF, it runs VariantEval to generate various summary tables of data, and then makes an HTML report (borrowing a lot from the tool MultiQC) summarizing that VCF. . I wrote this originally by forking GATK3 and wrote a new walker that internally called and run VariantEval. That was never the final plan. I dont know what this will need to look like in GATK4 yet. I'm fine with the expectation that GATK4 VariantEval will evolve and we'd need to update our code wrapping it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440806347:540,wrap,wrapping,540,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440806347,1,['wrap'],['wrapping']
Integrability,"Very funny! Closing, since this is clearly meant as a joke. Let's discuss after alpha ways to actually slim down our dependencies.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1120#issuecomment-157435278:117,depend,dependencies,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1120#issuecomment-157435278,1,['depend'],['dependencies']
Integrability,"We found an issue with the way GKL was freeing an internal data structure. The issue was exposed by the `IntelInflaterIntegrationTest`, which uses the Inflater API in a different way than HTSJDK and GATK. We've fixed that issue and the GATK integration tests pass. We're releasing GKL 0.4.1 now and will update this PR when 0.4.1 is available in Maven Central.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282325096:241,integrat,integration,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282325096,1,['integrat'],['integration']
Integrability,"We have [a researcher reporting that even when running locally, they are getting messages related to the GCS](https://gatkforums.broadinstitute.org/gatk/discussion/13015/failed-to-detect-whether-we-are-running-on-google-compute-engine#latest), which they find puzzling. > WARNING: Failed to detect whether we are running on Google Compute Engine. plus what looks like an error stacktrace in the middle of the stdout. Is this intentional?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818:81,message,messages,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818,1,['message'],['messages']
Integrability,"We have another researcher asking about this feature at <https://gatkforums.broadinstitute.org/gatk/discussion/14299/gatk4-variantannotator-de-novo-ped-workshop-1809#latest>. If annotating de novos will not be a feature, then please can we remove the option and/or update the error message to be more informative? Would appreciate it. Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4987#issuecomment-439235429:282,message,message,282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4987#issuecomment-439235429,1,['message'],['message']
Integrability,We need to wait for google cloud dependency updates in order for the fix to be incorporated into gatk.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-442117552:33,depend,dependency,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-442117552,1,['depend'],['dependency']
Integrability,We should patch to give a better error message as well...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553004443:39,message,message,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553004443,1,['message'],['message']
Integrability,"We'd also need a good integration test that reads in a VCF containing genotypes using `SelectVariants` with `--sites-only`, writes it out, reads it back in using `VariantContextTestUtils.readEntireVCFIntoMemory()`, and asserts that the genotypes are gone. The test should probably live someplace like `GATKToolIntegrationTest` or `FeatureSupportIntegrationTest` -- don't put it in `SelectVariantsIntegrationTest`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4763#issuecomment-388453987:22,integrat,integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4763#issuecomment-388453987,1,['integrat'],['integration']
Integrability,"We'd prefer something tightly integrated with our main test suite in travis, and reserve jenkins for long-running/nightly tests. Having to deal with two CI environments for pull requests is too cumbersome.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287474520:30,integrat,integrated,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287474520,1,['integrat'],['integrated']
Integrability,"We'd really like to be able to move forward to newer java versions. Unfortunately we have a pretty long list of dependencies which don't support any version newer than 8 yet. In particular, our dependency on Spark is problematic. Spark is stuck on java 8 because of issues with scala on java 9+ as well as issues with their dependencies. As I understand it, Java 9+ made changes to various methods which were widely used by libraries that do low level memory management. It also deprecated some forms of cross package reflection. Spark makes heavy use of both of those things so I think there having trouble updating. . So... we'd like to update, I have no idea when will be able to. Probably not for at least a year.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353:112,depend,dependencies,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353,3,['depend'],"['dependencies', 'dependency']"
Integrability,"We're seeing a lot of failures of the form:. ```; com.google.cloud.storage.StorageException: 806222273987-uilktks3j6i7962rp0v7nusveer58497@developer.gserviceaccount.com does not have serviceusage.services.use access to project 685190392835.; Caused by:; shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""806222273987-uilktks3j6i7962rp0v7nusveer58497@developer.gserviceaccount.com does not have serviceusage.services.use access to project 685190392835."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""806222273987-uilktks3j6i7962rp0v7nusveer58497@developer.gserviceaccount.com does not have serviceusage.services.use access to project 685190392835.""; }; ```. It looks like it now requires some new permission for the service accounts but our existing service account doesn't have that permission.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-511986926:410,message,message,410,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-511986926,2,['message'],['message']
Integrability,We've definitely seen similar problems before with accented characters. Might be system dependent since I can't reproduce the issue... What OS are you building on?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367406877:88,depend,dependent,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367406877,1,['depend'],['dependent']
Integrability,"Well, I guess that part of the contract for GATKTool is that GATK tools should report progress as they go. I agree that the ProgressMeter should be made more flexible and allow reporting of progress in terms of things other than genomic location.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577262636:31,contract,contract,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577262636,1,['contract'],['contract']
Integrability,What I'm saying is that the tarball that github auto-publishes is missing important files that are managed by git-lfs. So you need to fetch those somehow. They're not gradle dependencies and gradle doesn't know how to localize them without using git-lfs which relies on the git directory. If you have a mechanism for localizing those (and for setting the version manually) then it would be possible get rid of the git repo requirement. If you don't then there's no point in overriding the check.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584455736:174,depend,dependencies,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584455736,1,['depend'],['dependencies']
Integrability,What is the progress on this @cmnbroad? Is this waiting for the new Barclay plugin interface?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-282995363:83,interface,interface,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-282995363,1,['interface'],['interface']
Integrability,"What is the timeline for removing pysam, PyVCF, etc. dependencies (#4465)? I think we agreed to abide by certain rules when we started python development, but I don't know who is responsible for enforcing them...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-387139875:53,depend,dependencies,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-387139875,1,['depend'],['dependencies']
Integrability,"What we saw recently wasn't the reference itself, but rather our AF-only gnomAD resource lifted-over to the hg38 reference. The error only came up for sites that reached genotyping, which depends on the specific tumor sample as well as the lack of evidence in the normal. That's why it only appeared in some tumor-normal combinations. That being said, it might be something else. If you are able to share the unfiltered vcf file and the vcf.stats file it would be the most direct way to debug.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478310143:188,depend,depends,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478310143,1,['depend'],['depends']
Integrability,What's the protocol for getting this PR merged - @meganshand are you the right reviewer?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6872#issuecomment-710701299:11,protocol,protocol,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6872#issuecomment-710701299,1,['protocol'],['protocol']
Integrability,"When the MultiVariantWalker is integrated with VQSR, we need to make sure to update the code that populates the output header to match the way GATK3 did it with multiple inputs (mostly affects ApplyVQSR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2114#issuecomment-246357129:31,integrat,integrated,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2114#issuecomment-246357129,1,['integrat'],['integrated']
Integrability,"When you merge, be sure to update the commit comment and message to reflect the fact that it's been replaced instead of deprecated and that the default behavior is the opposite of what it used to be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318688481:57,message,message,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318688481,1,['message'],['message']
Integrability,"When you run a tool, a message with the bundled versions should show in the log.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4733#issuecomment-386247582:23,message,message,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4733#issuecomment-386247582,1,['message'],['message']
Integrability,"While a minor issue, moving to `slf4j-api` as the logging API and `slf4j-log4jxx` as the implementation would help with interoperability. For example, I'm working on a proposal for a separate library for conversions between formats, and currently the API passes in a slf4j `Logger` and an enum similar to `ValidationStringency`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-261286474:120,interoperab,interoperability,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-261286474,1,['interoperab'],['interoperability']
Integrability,"While most jobs have been failing with an error like the above, chr8 gave the following. Does this also suggest a memory issue, based on Z_MEM_ERROR: https://zlib.net/manual.html?. 07 Nov 2020 08:34:25,100 DEBUG: 08:34:24.941 INFO GenomicsDBImport - Done importing batch 3/4; 07 Nov 2020 08:34:29,847 DEBUG: 08:34:29.847 INFO GenomicsDBImport - Importing batch 4 with 33 samples; 08 Nov 2020 10:46:27,095 DEBUG: [TileDB::utils] Error: (gzip_handle_error) Cannot decompress with GZIP: inflateInit error: Z_MEM_ERROR; 08 Nov 2020 10:46:27,280 DEBUG: [TileDB::Codec] Error: Could not compress with .; 08 Nov 2020 10:46:27,285 DEBUG: [TileDB::ReadState] Error: Cannot decompress tile.; 08 Nov 2020 10:47:00,459 DEBUG: 10:47:00.458 erro NativeGenomicsDB - pid=16931 tid=17036 VariantStorageManagerException exception : Error while consolidating TileDB array 8$1$145679320; 08 Nov 2020 10:47:00,473 DEBUG: TileDB error message : ; 08 Nov 2020 10:47:00,487 DEBUG: terminate called after throwing an instance of 'std::exception'; 08 Nov 2020 10:47:00,492 DEBUG: what(): std::exception; 08 Nov 2020 10:47:37,511 WARN : process exited with non-zero value: 134",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724231609:913,message,message,913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724231609,1,['message'],['message']
Integrability,"While producing combined VariantContext objects in GenomicsDB, combine operations must be specified for the INFO fields through the vid object. Some of the commonly used fields (*RankSum, DP) are handled by the GenomicsDB code. If an INFO field does not have a combine operation (in the vid or in the GenomicsDB source code), then the combine operation ignores the field (producing the message above). Note that the data is still imported into GenomicsDB - the combine operation (query) ignores these fields. A new query with the fixed vid will return the field. GATK CombineGVCFs ignores MLEAC, MLEAF and DS fields. HaplotypeScore and InbreedingCoeff have no data in the gVCFs (any gVCF we have seen). Other fields like ExcessHet are combined using median operation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293635317:386,message,message,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293635317,1,['message'],['message']
Integrability,"While we normally don't recommend ignoring that wrapper, this seems like a good reason to do so. . The wrapper is pretty simple, most of what it's doing is some munging of the input to allow it to be more standardized in several different gatk use cases. The only thing I can think of that you would want to be sure to copy is that it sets a number of properties. . We set these spark `--conf` properties with the wrapper. I don't actually know how important some of them are anymore. If it works without them then you're probably good.; ```; ""spark.kryoserializer.buffer.max"" : ""512m"",; ""spark.driver.maxResultSize"" : ""0"",; ""spark.driver.userClassPathFirst"" : ""false"",; ""spark.io.compression.codec"" : ""lzf"",; ""spark.executor.memoryOverhead"" : ""600"",; ""spark.driver.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK,; ""spark.executor.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK; ```. These are htsjdk properties we want to set for spark. ; ```; EXTRA_JAVA_OPTIONS_SPARK= ""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true "" \; ""-Dsamjdk.use_async_io_read_samtools=false "" \; ""-Dsamjdk.use_async_io_write_samtools=false "" \; ""-Dsamjdk.use_async_io_write_tribble=false "" \; ""-Dsamjdk.compression_level=2 ""; ```. If you can get this value into your spark environment variables it prevents and anying warning output. `SUPPRESS_GCLOUD_CREDS_WARNING=true`. Let us know how it works for you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6198#issuecomment-539073054:48,wrap,wrapper,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6198#issuecomment-539073054,6,['wrap'],['wrapper']
Integrability,"With the exception of the HMM package, all of our R dependencies are available through the conda R or bioconda channels; the HMM package is available only through a user's custom channel. However, the HMM package is only used to generate truth for testing the Java HMM code by @vruano (which is currently unused, but we thought was worth keeping around). I'm sure we could easily rewrite the tests to load the truth from a file. I think we should get rid of the install_R_packages.R script altogether and just roll all of these dependencies into the conda environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920:52,depend,dependencies,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920,2,['depend'],['dependencies']
Integrability,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:772,protocol,protocol,772,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156,3,['protocol'],['protocol']
Integrability,With updated command:. > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.so; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: warning: you do not have execution permission for `./libtiledbgenomicsdb.so'; > linux-vdso.so.1 (0x00007ffca79df000); > libpthread.so.0 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libpthread.so.0 (0x00007f146cb0c000); > libz.so.1 => not found; > libuuid.so.1 => not found; > librt.so.1 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/librt.so.1 (0x00007f146c902000); > libm.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libm.so.6 (0x00007f146c5fd000); > libc.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libc.so.6 (0x00007f146c25f000); > /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib64/ld-linux-x86-64.so.2 (0x000055ddfd95d000); > + md5sum libtiledbgenomicsdb.so; > 83007be5ce8b0c832b539b21b6c0d68d libtiledbgenomicsdb.so,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392:323,depend,dependencies,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392,2,['depend'],['dependencies']
Integrability,With which frequency will you make point-releases? I'm afraid that incompatibilities will make me stick to an unreleased GATK4 dependency!. I am preparing a PR at this moment to try to get it in!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297676:127,depend,dependency,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297676,1,['depend'],['dependency']
Integrability,"Without the curl command, gcloud build failed with this error message: The command '/bin/sh -c apt-get --assume-yes install git-lfs' returned a non-zero code: 100",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6842#issuecomment-696904831:62,message,message,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6842#issuecomment-696904831,1,['message'],['message']
Integrability,Would it be possible to update the `gatktool` bioconda repo to ensure that all python dependencies are well installed to run CNNScoreVariants ? It would be really helpful and easier to manage a GATK conda environment.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1735565877:86,depend,dependencies,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1735565877,1,['depend'],['dependencies']
Integrability,"Wow, thanks for the detailed comments so far, @davidbenjamin! But perhaps let's quickly chat before you go any further?. There are a lot of things you commented on---temporary integration tests using local files, lots of code/arguments/etc. intentionally copied verbatim over from VQSR/tranches, and entire tools (the ""monolithic"" GMMVariantTrain and ScikitLearnVariantTrain)---that are rather in flux or will be scrapped/cleaned up shortly. That said, the comments on the code inherited from VQSR will certainly be useful in this process!. But it might save you some time if we could chat so I can give you a rough orientation and perhaps point out where the vestigial VQSR code remains. I think focusing discussion on the high level design of the tools that are likely to stay would also be most useful at this stage. Feel free to throw something on my calendar!. In the end, I think we will probably just retain the BGMM backend + the versions of the tools in the ""scalable"" package. I left the ""monolithic"" GMMVariantTrain and ScikitLearnVariantTrain tools in this branch so I could do one round of tieout. That tieout came out OK, so I think we'll abandon the monolithic tools, along with all the associated code outside of the scalable package. If it helps, I can go ahead and remove that stuff from this draft PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1029393942:176,integrat,integration,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1029393942,1,['integrat'],['integration']
Integrability,Yeah - the integration tests cover this case. I had some trouble adding unit tests for this because of #5356 .,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5357#issuecomment-432873687:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5357#issuecomment-432873687,1,['integrat'],['integration']
Integrability,"Yeah, I don't like these new interface methods -- they make `GATKRead` significantly worse. We should cache `isUnmapped`, etc. in the adapter to accomplish the same thing, as @lbergelson suggests. Not that hard, and we can just unconditionally invalidate the cached values (using `Boolean` fields set to null) whenever the read is mutated in any way in order to simplify the logic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282:29,interface,interface,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282,2,"['adapter', 'interface']","['adapter', 'interface']"
Integrability,"Yeah, being able to print multiple lines of errors at once is nice for the users. Most tools don't do that though. The ones that do can wrap the multiple errors into a single exception with a multiline message. Will changing the method signature and moving the call up into the try block fix the problem your having?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255848690:136,wrap,wrap,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255848690,2,"['message', 'wrap']","['message', 'wrap']"
Integrability,"Yeah, it's definitely confusing, we should look into changing it for the future. We definitely do recommend using our launcher script though, which handles it for you. . It was tricky to enable both spark-submit and standalone running spark through the jar without having a way to inject the spark master as a command line argument, but there's probably a better way of handling it then the way we do. . I'm keeping this issue open, but since it's a pretty easy workaround I don't know when we'll be able to fix it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-302179455:281,inject,inject,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-302179455,1,['inject'],['inject']
Integrability,"Yep, I created https://github.com/broadinstitute/gatk/issues/2715 this morning to ask Intel to add a helpful error message in this case. Glad to hear that you can work around the issue for now by using `-V`!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301540412:115,message,message,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301540412,1,['message'],['message']
Integrability,"Yep, antares58 is me. Elizabeth Lee. Sent with [Proton Mail](https://proton.me/) secure email. ------- Original Message -------; On Tuesday, November 22nd, 2022 at 7:14 AM, Anthony Dias-Ciarla ***@***.***> wrote:. > Hi ***@***.***(https://github.com/antares58) ,; >; > We created this ticket for one of our users on the GATK forum, [Elizabeth Lee](https://gatk.broadinstitute.org/hc/en-us/community/posts/9761457082907-JointGenotyping-ImportGvcfs-terminates-without-an-active-exception).; >; > In the interest of clarity, are you responding on her behalf? Are you the cluster admin? If you are not related to the original user, we will need to create a separate ticket.; >; > Thank you in advance for any clarity that you can provide!; >; > Best,; > Anthony; >; > —; > Reply to this email directly, [view it on GitHub](https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1323834544), or [unsubscribe](https://github.com/notifications/unsubscribe-auth/AWNKFIEGLOGOYBSTJEDLUF3WJTPNBANCNFSM6AAAAAARQLF3GE).; > You are receiving this because you were mentioned.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1336529947:112,Message,Message,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1336529947,2,['Message'],['Message']
Integrability,"Yep, sorry. Just learned that as you were closing it. On Tue, Aug 14, 2018 at 11:51 AM, Louis Bergelson <notifications@github.com>; wrote:. > It's useful to put something like fixes #5104 in the commit message. That; > way it automatically closes the issue and shows a link from the PR to the; > Issue.; >; > —; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412920923>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AoMkWAqeYbmnX12i6s9k_5bEWy149CPFks5uQvITgaJpZM4UyozK>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412923593:202,message,message,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412923593,2,['message'],['message']
Integrability,"Yep, that will definitely cause a crash - variable length fields need a length value stored while fixed length fields don't. I can add checks for this scenario in GenomicsDB. Please let me know if the following make sense:; Header says that the field F is a fixed length field with length = N. In the data section, if; * length(F) < N - pad with missing values, no error message, continue; * length(F) > N - error, throw exception and print descriptive error message",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407501684:371,message,message,371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407501684,2,['message'],['message']
Integrability,"Yep, the new jar fetches and prints the TileDB error message",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4753#issuecomment-387935793:53,message,message,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4753#issuecomment-387935793,1,['message'],['message']
Integrability,"Yes - trying to run the integration test so that I can update the outputs, but keep getting transient docker pull errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8655#issuecomment-1898811668:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8655#issuecomment-1898811668,1,['integrat'],['integration']
Integrability,"Yes PathSeq has generally been used with longer reads in the past and also with BWA. I suspect with the shorter reads, novel splice sites are getting missed by PathSeq. You could turn down the match threshold to 16 (half the read length) to help this further, or even hard-filter any aligned read, but you do risk losing some microbial reads at this length. . You're also right that in your case, using the mate information would be useful, but this would not be appropriate, for example, when there are host-pathogen chimeras, such as virus integration events.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-652638341:542,integrat,integration,542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-652638341,1,['integrat'],['integration']
Integrability,Yes please! I'd also find this incredibly useful. @lbergelson any thoughts on how hard it would be to generate a separate build artifact for the local reassembly code that didn't have too many dependencies?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-340717669:193,depend,dependencies,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-340717669,1,['depend'],['dependencies']
Integrability,"Yes! I am so relieved to have all of this python dependency wrangling done. Perhaps not the sexiest work, but still very important -- thank you @asmirnov239 !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8094#issuecomment-1322447041:49,depend,dependency,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8094#issuecomment-1322447041,1,['depend'],['dependency']
Integrability,"Yes, Hadoop-BAM uses the NIO API to do file merging, whereas in GATK we were using the Hadoop APIs (and therefore the GCS<->HDFS adapter) to do it. It looks like there are a couple of things needed in GCS-NIO to use the NIO API for this.; 1. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1450 so that we don't have to special-case `gs` URIs to remove everything except the scheme and host when looking up the filesystem (see https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L40); 2. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/813 to support path matching (https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L90). There may be more, as I stopped there. The best way forward is probably to go back to the old code in GATK while the deficiencies in GCS-NIO are fixed and then released. The stacktrace I got for 1 was:. ```; java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://gatk-demo-tom/TEST/markdups.parts/_SUCCESS; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:54); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); ```. And for 2:. ```; java.lang.UnsupportedOperationException; 	at com.google.cloud.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050:129,adapter,adapter,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050,1,['adapter'],['adapter']
Integrability,"Yes, I messed up the commit message and wrote that it ""resolves issue 5433"" instead of ""resolves issue #5433"". Without the hash I guess github assumes it's stupid meatbag language and ignores it. The bug should be fixed so I'm closing the issue manually. Sorry to leave this hanging the last month, and thanks for pointing it out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5433#issuecomment-449899779:28,message,message,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5433#issuecomment-449899779,1,['message'],['message']
Integrability,"Yes, I ran option 3, 5 times (using the older version not latest master). Of those 5, 3 failed. One of the failures was: `java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: All reopens failed`. The other two were both the non-negative error message:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr6:1+ --use_jdk_deflater --use_jdk_inflater; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.4ZS1WV; [July 24, 2017 5:48:10 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr6:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:302,message,message,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472,1,['message'],['message']
Integrability,"Yes, definitely pin h5py in this case. Not 100% sure what form the alert should take or what manual interventions should be required when it’s triggered, but perhaps we can discuss at the next dependency meeting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6955#issuecomment-725021274:193,depend,dependency,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6955#issuecomment-725021274,1,['depend'],['dependency']
Integrability,"Yes, if you have Version Control integration enabled, you can select the branch, and then any commit, or group of commits, in order to see the diffs. So once its read, I'll be able to look at just the diffs between the initial GATK3 commit and your commit(s) right from within IntelliJ.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-416341795:33,integrat,integration,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-416341795,1,['integrat'],['integration']
Integrability,"Yes, let me know if they should go in this repo or the wrapper repo.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318243071:55,wrap,wrapper,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318243071,1,['wrap'],['wrapper']
Integrability,"Yes, of course :) It can be a challenge to get good error messages out of Spark, but perhaps we could have some kind of up-front check in GATK4 for a Spark version mismatch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290761293:58,message,messages,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290761293,1,['message'],['messages']
Integrability,"Yes, thank you for jogging my memory @bbimber. @davidbenjamin adding something to that extend in the BadArgumentException message would be helpful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-558740872:122,message,message,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-558740872,1,['message'],['message']
Integrability,"Yes, that seems to be working as intended. You'll see that in your first log, the following lines indicate that convergence has been reached after 2 iterations:. ````; 09:40:44.924 INFO MultidimensionalModeller - Smoothing iteration: 2; 09:40:44.924 INFO MultidimensionalModeller - Number of segments before smoothing iteration: 398; 09:40:44.924 INFO MultidimensionalModeller - Number of segments after smoothing iteration: 398; ````. Therefore, when you set N >= 3, the behavior is the same as when N = 2. In your second log, only one iteration goes by before we refit again. This refit yields posteriors that are sufficiently different from the approximation used when no refitting is performed so that additional smoothing needs to be performed before convergence. You'll see that in the second case, we end up with fewer segments. Whether or not this smoother result (which takes longer to arrive at, since refitting is expensive) is desired will depend on the goals of the analysis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4683#issuecomment-382807646:952,depend,depend,952,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4683#issuecomment-382807646,1,['depend'],['depend']
Integrability,"Yes, that's the error message. You should see [this part of the GenomicsDB](https://github.com/Intel-HLS/GenomicsDB/blob/stack_ovf_fix/src/main/cpp/src/genomicsdb/variant_storage_manager.cc#L540) code that retries the function when an error is detected. So, you don't need to be concerned by those error messages. They are annoying though and I will disable them from being printed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407440149:22,message,message,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407440149,2,['message'],"['message', 'messages']"
Integrability,"Yes, the same error message was reported in https://github.com/broadinstitute/gatk/issues/5094. It was supposedly fixed by a patch to the Pipelines API. GCS-NIO has support for a list of retriable codes in the `CloudStorageConfiguration`, see there:. https://github.com/googleapis/google-cloud-java/blob/master/google-cloud-clients/google-cloud-contrib/google-cloud-nio/src/main/java/com/google/cloud/storage/contrib/nio/CloudStorageConfiguration.java. I think GATK calls this somewhere. It certainly should.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548517465:20,message,message,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548517465,1,['message'],['message']
Integrability,"Yes, this issue is not yet fully resolved. We intend to make additional progress in reducing vulnerabilities in our dependencies in the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1546114646:116,depend,dependencies,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1546114646,1,['depend'],['dependencies']
Integrability,"Yes, this looks very similar to what I'm seeing. The VariantSparkSinkUnitTests run fine on their own. When the whole test suite is run though, an OOM error is thrown when VariantSparkSinkUnitTests run:. java.lang.OutOfMemoryError: GC overhead limit exceeded; at org.gradle.internal.remote.internal.hub.MethodInvocationSerializer$MethodInvocationReader.read(MethodInvocationSerializer.java:120); at org.gradle.internal.remote.internal.hub.MethodInvocationSerializer$MethodInvocationReader.read(MethodInvocationSerializer.java:99); at org.gradle.internal.serialize.kryo.TypeSafeSerializer$1.read(TypeSafeSerializer.java:34); at org.gradle.internal.remote.internal.hub.InterHubMessageSerializer$MessageReader.read(InterHubMessageSerializer.java:66); at org.gradle.internal.remote.internal.hub.InterHubMessageSerializer$MessageReader.read(InterHubMessageSerializer.java:52); at org.gradle.internal.remote.internal.inet.SocketConnection.receive(SocketConnection.java:78); at org.gradle.internal.remote.internal.hub.MessageHub$ConnectionReceive.run(MessageHub.java:250); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 13:37 DEBUG: [kryo] Read object reference 986: reference=GRCh37.3; Test: Test method testWritingToFileURL[0](/Users/cnorman/projects/gatk/src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf, .vcf)(org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSinkUnitTest) produced standard out/err: 13:37 DEBUG: [kryo] Read object reference 203: contig=<ID=20,length=63025520,assembly=b37>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-287857575:692,Message,MessageReader,692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-287857575,4,['Message'],"['MessageHub', 'MessageReader']"
Integrability,"Yes, we can pretty easily detect this exit code and generate an error message suggesting it might be an OOM issue. I'll make a PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572769179:70,message,message,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572769179,1,['message'],['message']
Integrability,"You mean you saw an **informative** error message rather than an **uninformative** one, I assume? :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3745#issuecomment-364168059:42,message,message,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3745#issuecomment-364168059,1,['message'],['message']
Integrability,"You're totally right about the assembly failures. As we talked about in person yesterday, I worry about biasing the; likelihoods when genotyping positions near homVar variants. For the; record, the conclusion of that conversation was to inject the GGA allele; into the five best assembled haplotypes, though I'm open to something less; heuristic than ""best five"" if anyone has a good idea. (I don't want to; double the number of haplotypes by adding the GGA allele into all of them). On Thu, Apr 4, 2019 at 2:19 PM David Benjamin <notifications@github.com>; wrote:. > Update: I wrote an integration test in my branch that runs M2 with; > --kmer-size 1 --dont-increase-kmer-sizes-for-cycles. It still calls the; > given alleles, whereas in master it does not.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdF1sCpAlqKNa6S_qlL_ypNX_A0eGks5vdkI7gaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626:237,inject,inject,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626,2,"['inject', 'integrat']","['inject', 'integration']"
Integrability,"Your solution doesn't address your third listed drawback to the current; approach, though I'm not sure there's any way to do that that wouldn't; require a pretty dramatic change. It's not obvious to me why we wanted the given alleles in the graph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:622,inject,injecting,622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767,1,['inject'],['injecting']
Integrability,"Yup, as you might recall from some discussions with @bhanugandham and @mwalker174, getting automated pipeline-level CNV evaluations up and running was highest on my list before I handed over the role and went on paternity leave. I think these tests would be more useful than unit/integration tests for correctness, but they would almost certainly have to run on CARROT. That said, the current level of unit/integration test coverage is a bit different from that for the somatic tools, because 1) it's difficult to run gCNV in any useful way on Travis infrastructure, and 2) we hadn't decided on a framework/convention for python unit tests at the time the production code went in (although I think @ldgauthier has added some python unit tests by now). So we currently only have plumbing WDL/integration tests on very small data for gCNV---and these only test that the tools run, not for correctness. For somatic CNV, we have unit tests for correctness on small simulated data (e.g., for things like segmentation and modeling classes), but integration tests don't cover correctness (and it would be pretty redundant to use the same simulated data for integration, so I'd rather put effort towards pipeline-level tests on real data). It might be good for you and @mwalker174 to review the current level of testing coverage and understand where things need to be shored up---happy to discuss more.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7261#issuecomment-859563124:280,integrat,integration,280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7261#issuecomment-859563124,5,['integrat'],['integration']
Integrability,"[Apache Thrift](https://github.com/apache/thrift) looks like a plausible alternative to py4j. It might be possible to automate the generation of thrift wrappers. But, at the heart of any of these systems is essentially an RPC mechanism, not a binary interface, and ill suited to high-frequency function calls.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4938#issuecomment-1304217213:152,wrap,wrappers,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4938#issuecomment-1304217213,2,"['interface', 'wrap']","['interface', 'wrappers']"
Integrability,"_Is there any way to get it to use fewer partitions in a case like this where there are lots of intervals ?_; No - see the PR message https://github.com/broadinstitute/gatk/pull/4645#issue-180678162. The multi-interval support in GenomicsDBImport tool is purely for convenience. For scalability with a large number of intervals and samples, you should use multiple processes, each writing to a small (1?) number of intervals. **_Somewhat more concerning is that when with 8000 intervals, I see a different failure mode. First I see lots (thousands) of these messages:_**; The first set of messages are spurious debug messages - no error in reality. I'll provide a jar without these messages. The second set of messages are a result of too many file handles open per process - your system is limiting the number of file handles opened by a single process. Again, this goes back to the previous statement.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407228434:126,message,message,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407228434,6,['message'],"['message', 'messages']"
Integrability,"__ _ _(_)_ __ __ _ \ \ \ \; ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \; \\/ ___)| |_)| | | | | || (_| | ) ) ) ); ' |____| .__|_| |_|_| |_\__, | / / / /; =========|_|==============|___/=/_/_/_/; :: Spring Boot :: (v2.3.0.RELEASE). 2020-05-29 15:14:30.695 INFO 12904 --- [ main] com.luz.push.PushApplication : Starting PushApplication on DESKTOP-05L3FQL with PID 12904 (C:\project\push\target\classes started by Sweet in C:\project\push); 2020-05-29 15:14:30.712 INFO 12904 --- [ main] com.luz.push.PushApplication : No active profile set, falling back to default profiles: default; 2020-05-29 15:14:32.088 WARN 12904 --- [ main] o.m.s.mapper.ClassPathMapperScanner : No MyBatis mapper was found in '[com.luz.push]' package. Please check your configuration.; 2020-05-29 15:14:32.662 INFO 12904 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8282 (http); 2020-05-29 15:14:32.675 INFO 12904 --- [ main] o.a.coyote.http11.Http11NioProtocol : Initializing ProtocolHandler [""http-nio-8282""]; 2020-05-29 15:14:32.676 INFO 12904 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]; 2020-05-29 15:14:32.677 INFO 12904 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]; 2020-05-29 15:14:32.802 INFO 12904 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext; 2020-05-29 15:14:32.802 INFO 12904 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1944 ms; 2020-05-29 15:14:32.899 INFO 12904 --- [ main] com.luz.push.utils.GcmUtils : start init gcm server; 2020-05-29 15:14:33.029 WARN 12904 --- [ main] c.g.a.oauth2.ComputeEngineCredentials : Failed to detect whether we are running on Google Compute Engine. java.net.SocketException: Network is unreachable: connect; 	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method); 	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackP",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:11941,Protocol,ProtocolHandler,11941,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['Protocol'],['ProtocolHandler']
Integrability,"```; ./gatk --version; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk --version; The Genome Analysis Toolkit (GATK) v4.0.12.0-1-g10aa8c7-SNAPSHOT; ```. This is different than the output of the tool --version...; ```; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk PrintReads --version; Version:4.0.12.0-1-g10aa8c7-SNAPSHOT; Tool returned:; 0; ```. I can change this to be that version, or we can change barclay to do it differently and provide more info. It might be useful to print the library versions with both commands as well.. that's printed during the normal run...; ```; 14:19:57.172 INFO PrintReads - HTSJDK Version: 2.18.1; 14:19:57.173 INFO PrintReads - Picard Version: 2.18.16; ```. @cmnbroad What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272:34,wrap,wrapper,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272,2,['wrap'],['wrapper']
Integrability,`mvn clean` did not help although I do see its output logged properly. Let's ignore the `external-example` build issue as it is not present in 3.8-1 (as I managed to build it now). I care therefore only about the `rm: missing operand` message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4686#issuecomment-383194874:235,message,message,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4686#issuecomment-383194874,1,['message'],['message']
Integrability,"a:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:6969,Message,MessageHubBackedObjectConnection,6969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,a](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvUm9idXN0QnJlbnRTb2x2ZXJVbml0VGVzdC5qYXZh) | | |; | [...ute/hellbender/utils/solver/RobustBrentSolver.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvUm9idXN0QnJlbnRTb2x2ZXIuamF2YQ==) | | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvVW5pdmFyaWF0ZVNvbHZlclNwZWNpZmljYXRpb25zLmphdmE=) | | |; | [...der/utils/solver/SynchronizedUnivariateSolver.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvU3luY2hyb25pemVkVW5pdmFyaWF0ZVNvbHZlci5qYXZh) | | |; | [...r/utils/solver/UnivariateSolverJobDescription.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvVW5pdmFyaWF0ZVNvbHZlckpvYkRlc2NyaXB0aW9uLmphdmE=) | | |; | ... and [22 more](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7918#issuecomment-1168977988:4543,Synchroniz,SynchronizedUnivariateSolver,4543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7918#issuecomment-1168977988,1,['Synchroniz'],['SynchronizedUnivariateSolver']
Integrability,"abadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 01:42:05 2017 -0500. hybrid ADVI abstract argument collection w/ flexible default values; hybrid ADVI argument collection for contig ploidy model; hybrid ADVI argument collection for germline denoising and calling model. commit 56e21bf955d3dc0c52aceb384f28cf6173959de0; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 23:18:39 2017 -0500. rewritten python-side coverage metadata table reader using pandas to fix the issues with comment line; change criterion for cohort/case based on whether a contig-ploidy model is provided or not; simulated test files for ploidy determination tool; proper integration test for ploidy determination tool and all edge cases; updated docs for ploidy determination tool. commit 7fa104b2e9170770cfc5b338835e41215d7fd39c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 18:43:17 2017 -0500. kabab case for gCNV-related tools; removed short args (this also partially affected PlotDenoisedCopyRatios and PlotModeledSegments and their integration tests). commit f02cb024331a986213cfd9fae2da706bbc5ddbd9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 18:02:40 2017 -0500. synced with mb_gcnv_python_kernel. commit 2963bbf8c90418d9b88545c93771ae51cf542db9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 11:38:05 2017 -0500. Fixing typo in travis.yml. commit 6cf589999c716ec66404eb0a2ae4310dd130a772; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 11:13:58 2017 -0500. editable, full path. commit d998f2d5c2b33dd41e291be9bfeaea72fe479b8a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:56:24 2017 -0500. revert Dockerfile, change yml. commit 930d7486b7d2cf918fcb16dd03394bb9c9f0611b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:34:46 2017 -0500. more Dockerfile. commit 94112131526b514ef254bcc2c50a239dbae35aa1; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:25:13 2017",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:8122,integrat,integration,8122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['integrat'],['integration']
Integrability,ader.<init>(SnappyLoader.java:52); 	at htsjdk.samtools.util.TempStreamFactory.getSnappyLoader(TempStreamFactory.java:42); 	at htsjdk.samtools.util.TempStreamFactory.wrapTempOutputStream(TempStreamFactory.java:74); 	at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:223); 	at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:166); 	at com.github.discvrseq.walkers.BackportLiftedVcf.apply(BackportLiftedVcf.java:156); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at com.github,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333579182:1519,wrap,wrapAndCopyInto,1519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333579182,1,['wrap'],['wrapAndCopyInto']
Integrability,advanced isn't integrated either,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2130#issuecomment-248046609:15,integrat,integrated,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2130#issuecomment-248046609,1,['integrat'],['integrated']
Integrability,allerUtils.java:246); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:493); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1326(HaplotypeCallerSpark.java:223); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:213); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.ap,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149:2788,Wrap,Wrappers,2788,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149,1,['Wrap'],['Wrappers']
Integrability,ance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hadoop_bam.BAMRecordReader.nextKeyValue(BAMRecordReader.java:225); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182); 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:7433,wrap,wrapAndCopyInto,7433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['wrap'],['wrapAndCopyInto']
Integrability,"and likely to require some iteration so I'd be ok with starting with just the minimal ""porting"" changes to keep things simple, and then doing a code hygiene pass at the end. The ""porting"" changes should include things like updated javadoc, GATK4-style command line arguments, updating of outdated GATK3 terminology such as ""ROD"", Utils.nonNull assertions, etc. The finals and curly braces can wait for a separate pass (we will want to do those in this PR though). If you're not sure what to include or not just ask. I like the idea of keeping the GATK3 tests working as we go along. We should make a clear distinction between the old and new tests though. Ideally the GATK3 tests would be in a separate commit that we can just delete at the end, but that can get unwieldy if the files in the commit need to change as we go along. Alternatively you could isolate them into a separate directory. They should either be disabled or made dependent on a test method (see the `@Test` annotation properties `enabled` and `dependsOn`) that is easily toggled so they can be run locally, but don't run on the CI server. Otherwise the CI server build will always fail. In general, its really helpful to have the first commit in the PR contain the completely unmodified GATK3 source files. It makes it much easier for the reviewer to see what changed for the port. I noticed that you have 2 new plugins included in this. I'm not sure if that was suggested by someone on the GATK team (I'm wondering if we want to go down that path...) but I can tell you that the existing plugins required an enormous amount of test development and review iteration. If we do decide to make them plugins, I think it would be a good idea to do so in a separate PR. Also, if we choose to make an AbstractPlugin base class, we may want that to live in the Barclay repo. As @magicdgs points out, master already has your previous commits, so you should start by rebasing on that. Ideally, the branch would have the following commits bef",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352:1155,depend,dependent,1155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352,4,['depend'],"['dependent', 'dependsOn']"
Integrability,and sometimes I get:. ```; java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:170); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:3; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271423848:1031,protocol,protocol,1031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271423848,3,['protocol'],['protocol']
Integrability,"anslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.apache.hadoop.ipc.Client.call(Client.java:1475); 	at org.apache.hadoop.ipc.Client.call(Client.java:1412); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229); 	at com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:255); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191); 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102); 	at com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source); 	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1226); 	... 28 more; 18/10/06 09:45:36 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:10242,protocol,protocolPB,10242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocolPB']
Integrability,are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1249,protocol,protocol,1249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,2,['protocol'],['protocol']
Integrability,"ations are described as early as [VCF v4.1 specs](https://samtools.github.io/hts-specs/) and expanded upon in v4.3 specs. I think @jonn-smith you refer to MAF-format functional annotations. Yes? Here we are discussing much less complex variant call level annotations like genotype that would have a few associated numerical values, e.g. 10th, 50th, and 90th confidence interval allele fractions AND copy ratio value for each CN segment. . One last thing of interest towards visualization. I've been reminded recently of some open-source software that is a standard in visualizing somatic data for the biologist in the Cancer Genetics field--[CBioPortal](http://www.cbioportal.org/index.do?cancer_study_id=blca_mskcc_solit_2014&Z_SCORE_THRESHOLD=2.0&RPPA_SCORE_THRESHOLD=2.0&data_priority=0&case_set_id=blca_mskcc_solit_2014_cnaseq&gene_list=RB1%2520RBL1%2520RBL2%2520CCNA1%2520CCNB1%2520CDK1%2520CCNE1%2520CDK2%2520CDC25A%2520CCND1%2520CDK4%2520CDK6%2520CCND2%2520CDKN2A%2520CDKN2B%2520MYC%2520CDKN1A%2520CDKN1B%2520E2F1%2520E2F2%2520E2F3%2520E2F4%2520E2F5%2520E2F6%2520E2F7%2520E2F8%2520SRC%2520JAK1%2520JAK2%2520STAT1%2520STAT2%2520STAT3%2520STAT5A%2520STAT5B&geneset_list=+&tab_index=tab_visualize&Action=Submit&genetic_profile_ids_PROFILE_MUTATION_EXTENDED=blca_mskcc_solit_2014_mutations&genetic_profile_ids_PROFILE_COPY_NUMBER_ALTERATION=blca_mskcc_solit_2014_cna) (I plugged in some data--try clicking on the different tabs). They are Dockerized and their repo is at https://github.com/cBioPortal/cbioportal. They do a good job bridging the gap between genomics data and what the biologist is interested in. Their CNA visualization currently takes GISTIC-type data. For segmented CNs, they use a JavaScript version of IGV. It's worth checking out and perhaps enabling GATK users to visualize their somatic data with CBioPortal. . I'd like for us to save all our time for the interesting questions and leverage the hard work of others towards questions such as standarization and visualization.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386386120:2653,bridg,bridging,2653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386386120,1,['bridg'],['bridging']
Integrability,auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Connection refused (Connection refused); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsPr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:1500,protocol,protocol,1500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843,1,['protocol'],['protocol']
Integrability,"avadoc.doclet](https://docs.oracle.com/en/java/javase/11/docs/api/jdk.javadoc/jdk/javadoc/doclet/package-summary.html). The javadoc tools in `org.broadinstitute.hellbender.utils.help` may need to be re-written (and it's not clear if it's possible to support Java 8 and Java 11 simultaneously).; * Travis build. Getting this to build and test on Java 11 in addition to the current builds may be fairly involved as the matrix is already quite complicated. (The current PR just changes Java 8 to Java 11 for testing purposes - we'd need a way of getting both to run.). The vast majority of tests are passing on Java 11, the following are failing:; * Missing `TwoBitRecord` (from ADAM); * `ReferenceMultiSparkSourceUnitTest`; * `ImpreciseVariantDetectorUnitTest`; * `SVVCFWriterUnitTest`; * `DiscoverVariantsFromContigAlignmentsSAMSparkIntegrationTest`; * `StructuralVariationDiscoveryPipelineSparkIntegrationTest`; * `SvDiscoverFromLocalAssemblyContigAlignmentsSparkIntegrationTest`; * `java.lang.NoSuchMethodError: java.nio.ByteBuffer.clear()Ljava/nio/ByteBuffer;`; * `SeekableByteChannelPrefetcherTest`; * `GatherVcfsCloudIntegrationTest`; * `Could not serialize lambda`; * `ExampleAssemblyRegionWalkerSparkIntegrationTest`; * `PileupSparkIntegrationTest`; * Native HMM library code caused the tests to crash on my Mac:; ```; Running Test: Test method testLikelihoodsFromHaplotypes[0](org.broadinstitute.hellbender.utils.pairhmm.VectorLoglessPairHMM@6282d367, true)(org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest); dyld: lazy symbol binding failed: can't resolve symbol __ZN13shacc_pairhmm9calculateERNS_5BatchE in /private/var/folders/cj/wyp4zgw17vj4m9qdmddvmcc80000gn/T/libgkl_pairhmm13775554937319419112.dylib because dependent dylib #1 could not be loaded; dyld: can't resolve symbol __ZN13shacc_pairhmm9calculateERNS_5BatchE in /private/var/folders/cj/wyp4zgw17vj4m9qdmddvmcc80000gn/T/libgkl_pairhmm13775554937319419112.dylib because dependent dylib #1 could not be loaded; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359:2504,depend,dependent,2504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359,4,['depend'],['dependent']
Integrability,"b UI at http://xx.xx.xx.xx:4040; 18/04/24 17:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:42:02 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/gatk-package-4.0.3.0-spark.jar, byteCount=138618122, body=FileSegmentManagedBuffer{file=/scratch/home/int/eva/username/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-spark.jar, offset=0, length=138618122}} to /xx.xx.xx.25:57139; closing connection; java.io.IOException: Connection reset by peer; at sun.nio.ch.FileChannelImpl.transferTo0(Native Method); at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428); at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493); at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608); at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139); at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121); at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287); at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237); at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802); at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorat",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:37226,protocol,protocol,37226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['protocol'],['protocol']
Integrability,"bgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded; >; > 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported; >; > 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; >; > 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded; >; > 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; >; > Since the calculation takes quite long, I checked the WARN messages of the; > output above. Especially the last one about the AVX instruction set where; > it says that a *MUCH* slower implementation will be used. From the few; > WARN messages it seems like the root cause is the failure to load libgkl; > and that again seems to be related to my platform. Does anyone know more; > about this issue or how to work around it?; >; > Best regards,; > Robert; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6794>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AAKOLMAQSKLJ5N7SHDOJQ7DSEESQFANCNFSM4QZASPYQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600:6483,message,messages,6483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600,2,['message'],['messages']
Integrability,bmRlci91dGlscy9SL1JTY3JpcHRFeGVjdXRvci5qYXZh) | `80.282% <0%> (-8.451%)` | `17% <0%> (-3%)` | |; | [...g/broadinstitute/hellbender/utils/io/Resource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9SZXNvdXJjZS5qYXZh) | `55.556% <0%> (-7.407%)` | `6% <0%> (-1%)` | |; | [...llbender/tools/walkers/bqsr/AnalyzeCovariates.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQW5hbHl6ZUNvdmFyaWF0ZXMuamF2YQ==) | `67.593% <0%> (-4.63%)` | `29% <0%> (-1%)` | |; | [...ute/hellbender/utils/recalibration/RecalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL1JlY2FsVXRpbHMuamF2YQ==) | `89.407% <0%> (-3.814%)` | `52% <0%> (-1%)` | |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `90.909% <0%> (-3.209%)` | `2% <0%> (+1%)` | |; | [...te/hellbender/tools/spark/sv/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkludGVydmFsLmphdmE=) | `85.507% <0%> (-1.993%)` | `64% <0%> (+28%)` | |; | [...walkers/bqsr/AnalyzeCovariatesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQW5hbHl6ZUNvdmFyaWF0ZXNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `92.063% <0%> (-1.783%)` | `22% <0%> (-2%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-404596846:2425,integrat,integration,2425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-404596846,1,['integrat'],['integration']
Integrability,browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:1853,Message,MessageLoop,1853,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491,1,['Message'],['MessageLoop']
Integrability,bstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<ini,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1468,protocol,protocol,1468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,buildRequest(HttpRequestFactory.java:93); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:333); ... 17 more; Caused by: java.net.UnknownHostException: metadata; at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); at sun.net.www.http.HttpClient.New(HttpClient.java:308); at sun.net.www.http.HttpClient.New(HttpClient.java:326); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:104); ... 27 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412904420:6756,protocol,protocol,6756,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412904420,4,['protocol'],['protocol']
Integrability,"c 5 12:51:17 2017 -0500. Updates to handle SAM header changes from sl_wgs_acnv_headers and updates to mb_gcnv_python_kernel. commit d02d04df684a2820308a1d1c2bfda4b7d1c5f05e; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Nov 13 12:52:33 2017 -0500. Added CLIs and WDL for python gCNV pipeline. commit 66ed74b68375d43514ef84658e7a6c771ed9053c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Nov 15 01:50:03 2017 -0500. Polished code, ready for review; ; gCNV computational kernel (initial release); ; renaming gammas_s to psi_s to uniformity (sample-specific unexplained variance); ; renamed determine_ploidy_and_depth.py to cohort_determine_ploidy_and_depth.py; finite-temperature forward-backward algorithm; in the ploidy model, replaced alpha_j (NB over-dispersion) with psi_j (unexplained variance) for uniformity. Also, added the possibility of sample-specific unexplained variance in the germline contig ploidy model; ; updated I/O routines and CLIs according to team discussion; ; updated I/O routines and CLIs according to team discussion; ; changed the output layout of the ploidy determination tool; refactored parts of io.py; upped the version to 0.3 as it is not backwards compatible anymore; ; case ploidy determination tool from a given ploidy model; major code cleanup and refactoring of I/O module; refactoring of common CLI script snippets; ; removed all ""targets""; some code cleanup; ; pad flat class bitmask w/ a given padding value in the hybrid q_c_expectation_mode; option to disable annealing and keep the temperature fixed; ; bugfix in finite-temperature forward-backward; further refactoring of model I/O; ; the option to take a previously trained model as starting point in cohort CLI; the option to take previous calls as a starting point in cohort CLI; ; option to save and load adamax moments; ; import/export adamax bias correction tensor; ; refactoring related to fancy opt I/O; added average ploidy column to read depth; updated docs of hybrid ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:10911,rout,routines,10911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,4,['rout'],['routines']
Integrability,"c. to `pytensor`/`pt`/etc. However, there were some more nontrivial changes, including to 1) model priors (since some of the distributions previously used were removed or are now supported differently), 2) the implementation of posterior sampling, 3) some shape/dimshuffle operations, and other things along these lines. Using a single test shard of 20 1kGP WES samples x 1000 intervals, I have verified determinism/reproducibility for DetermineGermlineContigPloidy COHORT/CASE modes, GermlineCNVCaller COHORT/CASE modes, and PostprocessGermlineCNVCalls. Numerical results are also relatively close to those from 4.4.0.0 for all identifiable call and model quantities (albeit far outside any reasonable exact-match thresholds, most likely due to differences in RNG, sampling, and the aforementioned priors). Some remaining TODOs:. - [x] Rebuild and push the base Docker. EDIT: Mostly covered by #8610, but this also includes an addition of `libblas-dev`.; - [x] Update expected results for integration tests, perhaps add any that might be missing. EDIT: These were generated on WSL Ubuntu 20.04.2, we'll see if things pass on 22.04. Note that changing the ARD priors does change the *names* of the expected files, since the transform is appended to the corresponding variable name. DetermineGermlineContigPloidy and PostprocessGermlineCNVCalls are missing exact-match tests and should probably have some, but I'll leave that to someone else.; - [x] Update other python integration tests.; - [x] Clean up some of the changes to the priors.; - [x] Clean up some TODO comments that I left to track code changes that might result in changed numerics. I'll try to go through and convert these to PR comments in an initial review pass.; - [x] Test over multiple shards on WGS and WES. Probably some scientific tests on ~100 samples in both cohort and case mode would do the trick. We should also double check runtime/memory performance (I noted ~1.5x speedups, but didn't measure carefully; I also want to m",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:1955,integrat,integration,1955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,1,['integrat'],['integration']
Integrability,calibrator.java:542); at java.util.ArrayList.forEach(ArrayList.java:1251); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.consumeQueuedVariants(VariantRecalibrator.java:542); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.apply(VariantRecalibrator.java:521); at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532:7079,wrap,wrapAndCopyInto,7079,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532,1,['wrap'],['wrapAndCopyInto']
Integrability,ccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:635); Caused by: java.io.FileNotFoundException: File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInst,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:6025,protocol,protocol,6025,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocol']
Integrability,cf2.BCF2Codec.decode(BCF2Codec.java:134); at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:58); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:181); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextFeature(FeatureIntervalIterator.java:98); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextNovelFeature(FeatureIntervalIterator.java:74); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.next(FeatureIntervalIterator.java:62); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.next(FeatureIntervalIterator.java:24); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:490); at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574113941:2330,wrap,wrapAndCopyInto,2330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574113941,1,['wrap'],['wrapAndCopyInto']
Integrability,"cker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(App",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1041,wrap,wrapper,1041,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,clearing the milestone - our alpha does not depend on this pull req.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/936#issuecomment-151705716:44,depend,depend,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/936#issuecomment-151705716,1,['depend'],['depend']
Integrability,codeFuncotationFactory.java:1083); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:3175,wrap,wrapAndCopyInto,3175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,1,['wrap'],['wrapAndCopyInto']
Integrability,"consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the estimation, then transform back. EDIT: Just removed kernel density estimation for now, partly due to #3599 as well.; - Hmm, actually still a tiny bit of residual bias. This is apparent e.g. in WGS normals. I think focusing on a new allele-fraction model rather than t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5988,Integrat,Integration,5988,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['Integrat'],['Integration']
Integrability,contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:232); 	... 22 more; Caused by: java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:541); 	at shaded.cloud_nio.com.google.api.client.goog,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7339,protocol,protocol,7339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,"cotationFactory.createDefaultFuncotationsOnVariant(GencodeFuncotationFactory.java:499); 22 Jun 2023 14:54:27,163 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:217); 22 Jun 2023 14:54:27,164 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 22 Jun 2023 14:54:27,166 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); 22 Jun 2023 14:54:27,167 DEBUG: 		at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197); 22 Jun 2023 14:54:27,168 DEBUG: 		at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179); 22 Jun 2023 14:54:27,170 DEBUG: 		at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625); 22 Jun 2023 14:54:27,171 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509); 22 Jun 2023 14:54:27,172 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499); 22 Jun 2023 14:54:27,174 DEBUG: 		at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:921); 22 Jun 2023 14:54:27,175 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 22 Jun 2023 14:54:27,177 DEBUG: 		at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682); 22 Jun 2023 14:54:27,178 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); 22 Jun 2023 14:54:27,180 DEBUG: 		at com.github.discvrseq.walkers.ExtendedFuncotator.enqueueAndHandleVariant(ExtendedFuncotator.java:209); 22 Jun 2023 14:54:27,181 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226:2793,wrap,wrapAndCopyInto,2793,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226,1,['wrap'],['wrapAndCopyInto']
Integrability,cotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:239); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForSegment$2(FuncotatorEngine.java:223); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForSegment(FuncotatorEngine.java:226); at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:191); at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:59); at org.broadinstitute.hellbender.engine.FeatureWalker.lambda$traverse$0(FeatureWalker.java:99); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:647); at org.broadinstitute.hellbender.engine.FeatureWalker.traverse(FeatureWalker.java:97); at o,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314:3062,wrap,wrapAndCopyInto,3062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314,2,['wrap'],['wrapAndCopyInto']
Integrability,ctPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1553,protocol,protocol,1553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,cvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `96.296% <0.000%> (-3.704%)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TVkludGVydmFsLmphdmE=) | `90.000% <0.000%> (-2.857%)` | :arrow_down: |; | [...ute/hellbender/tools/spark/utils/IntHistogram.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay91dGlscy9JbnRIaXN0b2dyYW0uamF2YQ==) | `86.335% <0.000%> (-2.484%)` | :arrow_down: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `93.333% <0.000%> (-0.784%)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `66.818% <0.000%> (-0.455%)` | :arrow_down: |; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=com,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7951#issuecomment-1189612695:3418,integrat,integration,3418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7951#issuecomment-1189612695,1,['integrat'],['integration']
Integrability,"d=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1})``. This is has something to do with your input file. If I am wrong and this is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:2017,depend,dependency,2017,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143,1,['depend'],['dependency']
Integrability,"dException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:34 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:41:53 INFO TaskSetManager: Starting task 0.3 in stage 2.0 (TID 8, xx.xx.xx.xx, executor 3, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:41:53 INFO TaskSetManager: Lost task 1.1 in stage 2.0 (TID 6) on xx.xx.xx.24, executor 1: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 02:34 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:41:53 INFO TaskSetManager: Starting task 1.2 in stage 2.0 (TID 9, xx.xx.xx.25, executor 6, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:41:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.xx:45142 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:42:02 INFO TaskSetManager: Lost task 0.3 in stage 2.0 (TID 8) on xx.xx.xx.xx, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 2]; 18/04/24 17:42:02 ERROR TaskSetManager: Task 0 in stage 2.0 failed 4 times; aborting job; 18/04/24 17:42:02 INFO TaskSchedulerImpl: Cancelling stage 2; 18/04/24 17:42:02 INFO TaskSchedulerImpl: Stage 2 was cancelled; 18/04/24 17:42:02 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at PSFilter.java:125) failed in 117.782 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:32931,Wrap,WrappedArray,32931,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,de(AsciiFeatureCodec.java:70); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:181); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextFeature(FeatureIntervalIterator.java:98); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextNovelFeature(FeatureIntervalIterator.java:74); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.next(FeatureIntervalIterator.java:62); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.next(FeatureIntervalIterator.java:24); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ; at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:490) ; at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broad,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574329688:3747,wrap,wrapAndCopyInto,3747,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574329688,1,['wrap'],['wrapAndCopyInto']
Integrability,deFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.Refe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:3647,wrap,wrapAndCopyInto,3647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,1,['wrap'],['wrapAndCopyInto']
Integrability,"disabled; 11:57:50.898 INFO GenomicsDBImport - Initializing engine; 11:57:52.588 INFO FeatureManager - Using codec BEDCodec to read file file:///mnt/isilon/experiment/resources/final_mm10_exon.bed; 11:57:53.791 INFO IntervalArgumentCollection - Processing 199895151 bp from intervals; 11:57:53.825 WARN GenomicsDBImport - A large number of intervals were specified. Using more than 100 intervals in a single import is not recommended and can cause performance to suffer. It is recommended that intervals be aggregated together.; 11:57:53.837 INFO GenomicsDBImport - Done initializing engine; 11:57:54.037 INFO GenomicsDBImport - Vid Map JSON file will be written to /mnt/isilon/experiment/18075-01/aligned/variant_calling/genomics_db/vidmap.json; 11:57:54.037 INFO GenomicsDBImport - Callset Map JSON file will be written to /mnt/isilon/experiment/18075-01/aligned/variant_calling/genomics_db/callset.json; 11:57:54.037 INFO GenomicsDBImport - Complete VCF Header will be written to /mnt/isilon/experiment/18075-01/aligned/variant_calling/genomics_db/vcfheader.vcf; 11:57:54.037 INFO GenomicsDBImport - Importing to array - /mnt/isilon/experiment/18075-01/aligned/variant_calling/genomics_db/genomicsdb_array; 11:57:54.038 INFO ProgressMeter - Starting traversal; 11:57:54.038 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 12:05:27.926 INFO GenomicsDBImport - Starting batch input file preload; 12:05:29.246 INFO GenomicsDBImport - Finished batch preload; 12:05:29.246 INFO GenomicsDBImport - Importing batch 1 with 4 samples; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : Error while syncing array chr10$3119692$3120841 to disk; TileDB error message :; ```. The filesystem is being mounted at boot time in /etc/fstab as follows:; ```; //server/share /mnt/isilon cifs uid=user,credentials=/home/user/.smbcredentials,domain=THE_DOMAIN,iocharset=utf8,sec=ntlm,vers=3.0 0 0; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453590820:4502,message,message,4502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453590820,1,['message'],['message']
Integrability,dle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1278,wrap,wrapper,1278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['wrap'],['wrapper']
Integrability,"e GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use directly something like the Spring framework, but I think that it is quite complicated for API users without knowledge of Spring (like me).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:2301,interface,interface,2301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['interface'],['interface']
Integrability,e are running on Google Compute Engine.; java.net.NoRouteToHostException: No route to host (Host unreachable); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.goo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417:1443,protocol,protocol,1443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417,3,['protocol'],['protocol']
Integrability,"e canonical name for this metric actually is, but it doesn't appear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservatively filtered as truth, which will bias us towards high scores and the peaks of the positive distribution. Perhaps we can also experiment with just treating training/truth on an equal footing (I think the distinction between the two is somewhat blurry in the original VQSR design, anyway). Perhaps @davidbenjamin has some thoughts? I see some related stuff going on in ThresholdCalculator, but I have to admit that I can't tell whether that's used in a similar PU context. Also note that depending on the model used, we might not have well calibrated posteriors---the IsolationForest simply outputs scores in a unit interval, and we simply report the differe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:1716,depend,dependence,1716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,2,['depend'],['dependence']
Integrability,"e spec"". Third, although I don't know in detail about the different execution ; environments you are trying to support, there is a general strategy that ; I haven't seen discussed in these threads.; Perhaps it's impractical, but I'll mention it anyway. It seems like ; another approach would be to create (internal to the implementation) a ; ""header tag"" that could be efficiently serialized; and passed as part of the SAMRecord when you need to distribute it. The ; header tag could be used by the receiver to reattach the SAMRecord to ; its header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and complexity of the header tag might also depend on the ; execution environment. If the execution environment only supports a ; small finite number of headers, the header tag could be a small integer, ; or in a different execution environment it could be; a unique hash of the header or something like that. Memory footprint in ; the receiver is minimized because many SAMRecords can all share the same ; header object.; This requires more work to support in each execution environment, but it ; seems like it could be efficient and allows application code written to ; operate on SAMRecords to be portable; across different execution environments without having to contend with ; the possible presence of headerless SAMRecords. -Bob. On 9/17/15 4:28 PM, droazen wrote:. > @davidadamsphd https://github.com/davidadamsphd, @lbergelson ; > https://github.com/lbergelson, and myself met for an hour or two ; > just now to discuss this issue, and after reviewing all the options I ; > think we were convinced by the following argument:; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:2038,depend,depend,2038,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,1,['depend'],['depend']
Integrability,e.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:232); 	... 22 more; Caused by: java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleCl,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7269,protocol,protocol,7269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,"e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1642,depend,dependency,1642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['depend'],['dependency']
Integrability,e.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://st,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1333,integrat,integration,1333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,1,['integrat'],['integration']
Integrability,eGenotypes(ReferenceConfidenceVariantContextMerger.java:543); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:310); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:136); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:423); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:134); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-571886057:6242,wrap,wrapAndCopyInto,6242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-571886057,1,['wrap'],['wrapAndCopyInto']
Integrability,"ePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and link by `EVENT`; - [ ] we are making a choice that treats duplication expansion as insertion. If decide to treat `DUP` as a separate 1st class type, we need to ; - [ ] shift the left breakpoint to the ri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:2183,integrat,integration,2183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021,2,['integrat'],['integration']
Integrability,eReads(AssemblyBasedCallerUtils.java:246); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:493); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1326(HaplotypeCallerSpark.java:223); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:213); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149:2754,Wrap,Wrappers,2754,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149,1,['Wrap'],['Wrappers']
Integrability,ead.State: RUNNABLE; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	- locked <0x0000000584a63348> (a java.net.SocksSocketImpl); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1190,protocol,protocol,1190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,eam.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180:7469,protocol,protocol,7469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180,1,['protocol'],['protocol']
Integrability,ed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:113);,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1341,protocol,protocol,1341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,2,['protocol'],['protocol']
Integrability,efConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:543); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:310); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:136); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:423); at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:134); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6357#issuecomment-581619640:9382,wrap,wrapAndCopyInto,9382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6357#issuecomment-581619640,2,['wrap'],['wrapAndCopyInto']
Integrability,"endencies to the conda environment in a branch and rebased on that. A few issues that I've run into or that came up in discussion with @jamesemery and @cmnbroad:. -I moved all tests that depend on R into the `python` test group (which should perhaps be renamed to `conda`). Note that some of these also fall into the `spark` test group---not sure if there is any special Spark setup done for that group, but we should make sure that they don't fail if they're not run with the conda environment. -@cmnbroad mentioned that some Picard tools that depend on R may break outside of the conda environment if the user does not have the R dependencies. -When we install R in the base image, we pull in a lot of basic dependencies (e.g., build-essential, various libraries and compilers, etc.) So when the R install is removed, it looks like many tests begin failing or hanging, perhaps because they are falling back on Java implementations (e.g., AVX PairHMM tests). We need to determine the dependencies for these tests and install them separately. Here is the list of packages that get pulled in by the R install: ```autoconf automake autotools-dev binutils bsdmainutils build-essential; bzip2-doc cdbs cpp cpp-5 debhelper dh-strip-nondeterminism dh-translations; dpkg-dev fakeroot g++ g++-5 gcc gcc-5 gettext gettext-base gfortran; gfortran-5 groff-base ifupdown intltool intltool-debian iproute2; isc-dhcp-client isc-dhcp-common libalgorithm-diff-perl; libalgorithm-diff-xs-perl libalgorithm-merge-perl libarchive-zip-perl; libasan2 libasprintf-dev libasprintf0v5 libatm1 libatomic1; libauthen-sasl-perl libblas-common libblas-dev libblas3 libbz2-dev; libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libcroco3 libcurl3; libdns-export162 libdpkg-perl libencode-locale-perl libfakeroot; libfile-basedir-perl libfile-desktopentry-perl libfile-fcntllock-perl; libfile-listing-perl libfile-mimeinfo-perl libfile-stripnondeterminism-perl; libfont-afm-perl libfontenc1 libgcc-5-dev libgdbm3 libgettextpo-dev; libget",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:1078,depend,dependencies,1078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,2,['depend'],['dependencies']
Integrability,ent&utm_campaign=pr+comments&utm_term=broadinstitute) | Coverage Δ | |; |---|---|---|; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `94.595% <ø> (-0.142%)` | :arrow_down: |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `96.296% <ø> (-3.704%)` | :arrow_down: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `93.333% <ø> (-0.784%)` | :arrow_down: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `69.710% <100.000%> (+0.225%)` | :arrow_up: |; | [...er/tools/spark/sv/evidence/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1188387745:2253,integrat,integration,2253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1188387745,1,['integrat'],['integration']
Integrability,ent.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 15 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:8606,protocol,protocol,8606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['protocol'],['protocol']
Integrability,ent.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 50 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:6900,protocol,protocol,6900,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['protocol'],['protocol']
Integrability,ent.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 68 more; ```. Also,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:10388,protocol,protocol,10388,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['protocol'],['protocol']
Integrability,"er: Missing parents: List(ShuffleMapStage 6); 18/04/24 17:40:04 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[19] at mapToPair at PSFilter.java:125), which has no missing parents; 18/04/24 17:40:04 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.2 KB, free 366.0 MB); 00:45 DEBUG: [kryo] Write: byte[]; 18/04/24 17:40:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KB, free 366.0 MB); 18/04/24 17:40:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.xx:42081 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:40:04 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 18/04/24 17:40:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[19] at mapToPair at PSFilter.java:125) (first 15 tasks are for partitions Vector(0, 1)); 18/04/24 17:40:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks; 00:45 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:40:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, xx.xx.xx.25, executor 2, partition 0, PROCESS_LOCAL, 6010 bytes); 00:45 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:40:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4, xx.xx.xx.23, executor 5, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:40:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (xx.xx.xx.24:44437) with ID 1; 18/04/24 17:40:21 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.24:44322 with 366.3 MB RAM, BlockManagerId(1, xx.xx.xx.24, 44322, None); 18/04/24 17:40:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (xx.xx.xx.24:44439) with ID 4; 18/04/24 17:40:27 INFO BlockManagerMasterEndp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:22658,Wrap,WrappedArray,22658,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,"erDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitut",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:7115,Message,MessageHubBackedObjectConnection,7115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,"ergelson please comment on the following proposal. The proposal is that we would spin off native PairHMM as a separate project/repo on github and host AVX code there and have alternative implementations extend that project/repo (by creating repos that depend on the AVX one). . In other words, now we have 1 repo, broadinstitute/gatk. After the proposed change we'll have 3 repos (all BSD licensed):; 1) broadinstitute/gatk; 2) broadinstitute/nativePairHMM-AVX; 2) broadinstitute/nativePairHMM-PPC. We will duplicate the native code (AVX and PPC will be separate copies of C++ files etc) to simplify the testing burden. The parties interested in working on a specific architecture will contribute code directly to the respective architecture-specific repo and gatk will take occasional updates of those repos. The gatk repo will depend on the other two. The PPC repo will depend on the AVX repo (and any other native repos will depend on the AVX one). The avx and ppc repos will have their own build systems and unit tests against the new interface. The AVX repo will expose something like the following Java API (to be worked out in detail). ```; //Used to copy references to byteArrays to JNI from reads; public final class JNIReadDataHolderClass {; public byte[] readBases = null;; public byte[] readQuals = null;; public byte[] insertionGOP = null;; public byte[] deletionGOP = null;; public byte[] overallGCP = null;; }. //Used to copy references to byteArrays to JNI from haplotypes; public final class JNIHaplotypeDataHolderClass {; public byte[] haplotypeBases = null;; }. public interface NativePairHMMKernel extends AutoCloseable { . /**; * Function to initialize the fields of JNIReadDataHolderClass and JNIHaplotypeDataHolderClass from JVM.; * C++ code gets FieldIDs for these classes once and re-uses these IDs for the remainder of the program. Field IDs do not; * change per JVM session; *; * @param readDataHolderClass class type of JNIReadDataHolderClass; * @param haplotypeDataHolder",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864:1101,interface,interface,1101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864,1,['interface'],['interface']
Integrability,erver.java:2489). ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Failed to read bam header from /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:237); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:488); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:468,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:3108,protocol,protocol,3108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocol']
Integrability,es(FeatureContext.java:163); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:115); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:253); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:180); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:6567,wrap,wrapAndCopyInto,6567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['wrap'],['wrapAndCopyInto']
Integrability,es(FeatureContext.java:163); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:115); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:253); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:180); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:5924,wrap,wrapAndCopyInto,5924,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963,2,['wrap'],['wrapAndCopyInto']
Integrability,"ess, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of mana",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1265,wrap,wrappers,1265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['wrap'],['wrappers']
Integrability,ethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:175); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:157); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:404); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:46); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:55); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6086#issuecomment-519578293:3706,Message,MessageHubBackedObjectConnection,3706,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6086#issuecomment-519578293,6,['Message'],"['MessageHub', 'MessageHubBackedObjectConnection']"
Integrability,"executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25208,Wrap,Wrappers,25208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"fixed it by forcing the installation of numpy in the pip section, in order to bypass biopython dependencies resolution that grabs the last numpy available. patch is trivial. ```; gatkcondaenv.yml 2019-10-08 15:34:52.000000000 +0000; +++ gatkcondaenv2.yml 2020-01-21 16:17:06.777123115 +0000; @@ -21,6 +21,7 @@; - xz=5.2.3=0; - zlib=1.2.11=0; - pip:; + - numpy==1.13.3; - biopython==1.70; - bleach==1.5.0; - cycler==0.10.0; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396#issuecomment-576770330:95,depend,dependencies,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396#issuecomment-576770330,1,['depend'],['dependencies']
Integrability,"font{; line-height: 1.6;; }; ul,ol{; padding-left: 20px;; list-style-position: inside;; }. ; the following graph is one site info of final filtered gvcf file. I noticed in the red  GQ is 45(relatively high), but I find AD and DP is zero(0,0;0).; ; ; ; ; ; besides, I also have another problem, why I find the site-261733 diappeared. I don't find it in the ref position.why? ,can you help me .; your bestdengziguang; ; ; ; ; ***@***.***; ; ; . ; ---- Replied Message ----; ; ; ; ; ; From ; ; ; ***@***.***>; ; ; ; ; ; Date ; ; ; 11/15/2022 04:39; ; ; ; ; To ; ; ; ; ; ***@***.***>; ; ; ; ; ; ; Cc ; ; ; ; ***@***.***>; ,; ; ; ***@***.***>; ; ; ; ; ; ; Subject ; ; ; Re: [broadinstitute/gatk] In the gvcf file, Does anyone know what this info means? (Issue #8081); ; ; ; ; ; Is there any phasing info for sites that look like that, i.e. PID and PGT tags? HaplotypeCaller will assign a lot of confidence to variants that are phased with variants that have good support. It's also possible that reads used to assemble the haplotype graph aren't high enough quality to count towards the AD, and I believe the DP here is sum(AD). (In contrast, the INFO DP for the site is based on all of the reads seen.) Here the GQ is still shockingly high. I really hate how our genotyping model behaves for haploids, but that's not the entire problem.; Do you have the reads that go with this GVCF? I could give you a more satisfactory explanation if I saw the data, even just an IGV screenshot of the area. —Reply to this email directly, view it on GitHub, or unsubscribe.You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8081#issuecomment-1314706114:458,Message,Message,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8081#issuecomment-1314706114,2,['Message'],['Message']
Integrability,forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.util.concurrent.ExecutionException: org.broadinstitute.hellbender.exceptions.GATKException: Expected message of length 3 but only found 0 bytes; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.waitForAck(StreamingProcessController.java:228); 	... 26 more; Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Expected message of length 3 but only found 0 bytes; 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.getBytesFromStream(StreamingProcessController.java:261); 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.lambda$waitForAck$0(StreamingProcessController.java:208); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). but if I change memory as below: it works. ; q,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147:3543,message,message,3543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147,1,['message'],['message']
Integrability,"fter which the usual modelling and smoothing steps are performed. For the 75% tumor + 25% normal mixture, this yields 122 segments (up from 83):; ![N-25-T-75-SJS modeled](https://user-images.githubusercontent.com/11076296/76558618-015bd180-6474-11ea-996a-48d39770149b.png). For the 25% tumor + 75% normal mixture, this yields 105 segments (up from 50):; ![N-75-T-25-SJS modeled](https://user-images.githubusercontent.com/11076296/76560726-34a05f80-6478-11ea-9027-a54726c46b9e.png). One could imagine that smoothing could be disabled (so that all samples retain the common segmentation after modeling) or made more aggressive (so that private events don't get inadvertently introduced into other samples due to noise, perhaps), depending on the use case. It looks like the joint segmentation allows some additional events to be resolved, although I haven't done any rigorous evaluations. We could probably cook up some evaluations using simulated toy data or in silico mixtures, but there's really no reason why this shouldn't work decently well, especially if the kernel-segmentation method works well on a single sample for your data. It would also be interesting to understand at which point changing segmentation parameters on a single sample can no longer yield the same performance as joint segmentation on a fixed number of samples; however, this is probably a function of various S/N ratios, and it might not be easy to characterize this behavior outside of toy data. The segmentation parameter space is big enough to make this unwieldy even for toy data, too. Perhaps we can get some feedback from test users---not only on performance, but also on the structure of the new workflow. It might also be worth gauging whether a new WDL is warranted. Otherwise, we just need to add some unit tests for correctness of the multisample-segmentation backend class, integration tests for plumbing of the new tool, and perhaps address some of the issues mentioned above. Then I'd say this is good to go.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823:2996,integrat,integration,2996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823,2,['integrat'],['integration']
Integrability,g.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:137); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:113); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:496); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:387); at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:892); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385137363:5847,wrap,wrapAndCopyInto,5847,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385137363,1,['wrap'],['wrapAndCopyInto']
Integrability,g.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1025); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(Da,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:2057,wrap,wrapAndCopyInto,2057,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,1,['wrap'],['wrapAndCopyInto']
Integrability,"gatk-4.4.0.0 out there and still, `gatk HaplotypeCaller --sample-name 7-Wu-FF ...` bails on me with:. `A USER ERROR has occurred: Argument --sample_name has a bad value: Specified name does not exist in input bam files`. Indeed, there is not `@RG` line at all, how how about adding an extra error/warning message somewhere more above in the code path?. ```; $ samtools view -H 7-Wu-FF.sorted.bam; @HD VN:1.6 SO:coordinate; @SQ SN:7-Wu-FF LN:443; @PG ID:bwa PN:bwa VN:0.7.17-r1188 CL:bwa mem -t 32 -o exact_matches/7-Wu-FF.sam 7-Wu-FF.fasta 7-Wu-FF_R1.fastq.gz 7-Wu-FF_R2.fastq.gz; @PG ID:samtools PN:samtools PP:bwa VN:1.17 CL:samtools sort 7-Wu-FF.sorted.bam 7-Wu-FF.sam; @PG ID:samtools.1 PN:samtools PP:samtools VN:1.17 CL:samtools view -H 7-Wu-FF.sorted.bam; $; ```. Like others I agree that if there are no samples found by GATK then *all* data should be used. I also think that `@SQ SN:` is enough for a sanity check. No need for `@RG SN:` tag. Finally, fix the `--sample_name` with `--sample-name` in the error message output, the old syntax with an underscore is not accepted anymore.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6501#issuecomment-1832051700:305,message,message,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6501#issuecomment-1832051700,2,['message'],['message']
Integrability,"ger:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 0, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28110,Wrap,Wrappers,28110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"ger:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 WARN TaskSetManager:66 - Lost task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 2, start 131325815, span 181534, expected MD5 c240a972d49aa89fb57dae94d1d90d36; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:29135,Wrap,Wrappers,29135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"gic, I prefer not to do it this way, because we can add more logics in the future, and capturing/resolving these BND's that are not suitable for _THIS PARTICULAR_ logic. I guess in general my personal preference is to put less algorithm-related information in VCF for analysts (less reading for them), and produce add on files for tool developers. What's your thoughts?. > Does this even have to be a spark tool? It looks like you are just reading the variants into a parallel spark context, filtering, and then collecting them to actually process them. Why not just make this a non-spark tool and process it all in memory on one node?. Answer: Agree. It doesn't have to be, at least in theory, and it probably is going to be faster as we don't need to incur the Spark overhead for such a typically small job. But (I'm saying too many buts....) up to this point all SV tools are under the package `hellbender.tools.spark.sv`, so I'm following suit here. Note the two classes's main interface methods mentions nothing about RDDs (that's on purpose). ; On the other hand, this is an engineering question I believe, and it depends on whether we want to put as much of discovery code as possible into `StructuralVariationDiscoveryPipelineSpark` (the last commit actually hooks the two classes into it, so a single invocation of the tool produces more variants), or we go wdl in pipelining the whole process. -------. All in all, I think the comments and critics are generally about the ""filtering""/""classifying"" part, and the most serious concern about it is false negatives. Am I understanding correctly? If so, given that the filtering step is only picking the BND's that are suitable to the linking logic, I can imagine the false negative problem be solved in the future by other logics (e.g. more relaxed requirement on pair matching, or not even requiring matching INV55/INV33 pairs, etc.) In fact, that's what I'm planning on.; Another part of the problem is how much I can accomplish in this single",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929:6140,interface,interface,6140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929,2,['interface'],['interface']
Integrability,"gments` optionally takes denoised copy ratio and/or allelic counts, `PlotModeledSegments` outputs only the corresponding plots appropriately.; - I added a dependency on the R package `data.table` to slightly speed up the reading of input files.; - Setting `pch="".""` also sped up the generation of scatter plots.; - Plotting now takes a couple of minutes, most of which is I/O (#3554).; - AAF (rather than MAF) is now plotted for allele fraction (#2957). Other:; - I've introduced a `LocatableCollection` class to unify how allelic counts, copy ratios, and segments are stored and read/written from/to TSV (#2836). Intervals are always output in lexicographical order for now, to be consistent with the old coverage collection (#2951). Once @asmirnov239's `CollectReadCounts` is in, we can change everything over to ordering determined by the sequence dictionary.; - Column headers and log2 copy ratio output have been standardized throughout (#2886).; - [x] I've also introduced a `NamedSampleFile` abstract class to tag files that have `#SAMPLE_NAME=...` as the first comment line. For `CollectAllelicCounts`, this simply uses code borrowed from `GetSampleName`. We should unify the reading and storing of sample names at some point (#2910).; - [x] We will need to replace `SimpleReadCountCollection` (which currently serves as the interface between the old coverage collection files and the new code) with one of these subclasses when `CollectReadCounts` is in. We can also change `NamedSampleFile` depending on what he's implemented.; - [x] We should eventually write proper SAM headers with useful tags to all TSV and HDF5 files generated by our tools that represent annotated intervals that can be associated with a single sample. Documentation:; - [x] I need to update class javadoc and example invocations throughout. The initial PR will already be quite massive, so I'll leave this until later. Perhaps @sooheelee might want to be involved?; - [ ] I will update the white paper at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:10316,interface,interface,10316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,4,"['depend', 'interface']","['depending', 'interface']"
Integrability,gnomADaccuracyTest.SynDip.vcf.gz; 	at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:281); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:262); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:64); 	at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:70); 	at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.readNextRecord(TribbleIndexedFeatureReader.java:372); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:353); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:314); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359849134:1519,wrap,wrapAndCopyInto,1519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359849134,1,['wrap'],['wrapAndCopyInto']
Integrability,googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://stor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1557,integrat,integration,1557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,1,['integrat'],['integration']
Integrability,"gradle builds the dependency cache archive while online, and then builds a package using this archive while offline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584455056:18,depend,dependency,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584455056,1,['depend'],['dependency']
Integrability,"gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(Buffere",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1109,wrap,wrapper,1109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,"gumentParser.java:384); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.parseArgs(CommandLineProgram.java:217); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:191); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:733); > 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); > 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); > 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); > 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala). Actually, I just re-checked and i'm not sure my solution `--conf 'spark.submit.deployMode=cluster'` works well. I'm currently testing it. My current command is:; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --sparkRunner SPARK --sparkMaster yarn --conf 'spark.submit.deployMode=cluster' --javaOptions -Dmapr.library.flatclass. I need the `-Dmapr.library.flatclass` because our spark is using a mapr filesystem and I was getting error about JNI library linkage.; However, the paths of files are given with `hdfs://spark01:7222` because I get a protocol error when I set `maprfs://` instead. Don't bother with it right now, I'm going to open another issue about it :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452:2490,protocol,protocol,2490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452,1,['protocol'],['protocol']
Integrability,h.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCrede,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1154,protocol,protocol,1154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,1,['protocol'],['protocol']
Integrability,"hat I'm thinking about, is two pass:; one pass for splitting them up into the 3 classes,; then another pass on each of those 3 RDD's to turn them into VariantContext's.; Any better idea?. Reply by @cwhelan ; > That would be better, and yeah you don't have to do it in this PR.; In theory you could make the keys for the groupByKey() (ie NovelAdjacencyAndAltHaplotype, CpxVariantCanonicalRepresentation, right?) all inherit from the same superclass and do a single group by, couldn't you? Then you could do everything in a single pass. Reply by @SHuang-Broad; > Yes, that is what I'm planning but I'm not sure yet about how to approach that (I actually tried it, before putting in the above comment, and quickly ran into the problem of mixing Java serialization and Kryo serialization, so a larger re-structuring might be needed, and not just a inheritance structure). ------------; ### On the problem of having a confusing TODO for ; `boolean SimpleChimera.isCandidateInvertedDuplication()`. The todo message. > TODO: 5/5/18 Note that the use of the following predicate is currently obsoleted by; {@link AssemblyContigWithFineTunedAlignments#hasIncompletePictureFromTwoAlignments()}; because the contigs with this alignment signature is classified as ""incomplete"",; hence will NOT sent here for constructing SimpleChimera's.; But we may want to keep the code (and related code in BreakpointComplications) for future use. Comment by @cwhelan ; > I'm a bit confused by this comment: this method is still being called in several places, so how is it obsolete?. Reply by @SHUANG-Broad (also copied to update the ""TODO"" message; > this predicate is currently used in two places (excluding appearance in comments): `BreakpointComplications.IntraChrStrandSwitchBreakpointComplications`, where it is use to test if the input simple chimera indicates an inverse tandem duplication and trigger the logic for inferring duplicated region; and `BreakpointsInference.IntraChrStrandSwitchBreakpointInference`, where",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:2134,message,message,2134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,2,['message'],['message']
Integrability,"he code is in `CommandLineProgram`:. ```java; /**; *; * @return true if command line is valid; */; protected boolean parseArgs(final String[] argv) {. commandLineParser = new CommandLineArgumentParser(this, getPluginDescriptors());; try{; final boolean ret = commandLineParser.parseArguments(System.err, argv);; commandLine = commandLineParser.getCommandLine();; if (!ret) {; return false;; }; final String[] customErrorMessages = customCommandLineValidation();; if (customErrorMessages != null) {; for (final String msg : customErrorMessages) {; System.err.println(msg);; }; commandLineParser.usage(System.err, false);; return false;; }; return true;; } catch (final CommandLineException e){; //The CommandLineException is treated specially - we display help and no blow up; commandLineParser.usage(System.err, true);; printDecoratedUserExceptionMessage(System.err, e);; //rethrow e - this will be caught upstream and the right exit code will be used.; //we don't exit here though - only Main.main is allowed to call System.exit.; throw e;; }; }; ```. I think that GATK should discourage the usage of `CommandLineException` outside the Barclay engine or `customCommandLineValidation()`, and no wrapping the exception to `UserException` because it is related with the parsing. For instance, `MissingArgument` could be considere also an user exception, and almost all `CommandLineException` except the internal ones. I had the same problem when `CommandLineException` was part of `UserException` and I changed to use that one only to parts of the code related with arg parsing. That's why I included in the try-catch block the `customCommandLineValidation()` in #2226. I think that it makes more sense like this, because command line exceptions (e.g., bad or missing args) are printed with the usage of the tool, indicating why the argument is wrong and refering to the help; on the other hand, an user exception is more related with malformed files or other requirements not related with arg parsing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268660546:1373,wrap,wrapping,1373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268660546,1,['wrap'],['wrapping']
Integrability,hod); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cl,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180:7300,protocol,protocol,7300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180,1,['protocol'],['protocol']
Integrability,hodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:635); Caused by: java.io.FileNotFoundException: File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:5868,protocol,protocolPB,5868,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocolPB']
Integrability,"htsjdk is included in the GenomcisDB fat jar, maybe that's why getting pulled in from there. GenomicsDB class paths should be okay as long as htsjdk is in the path. @droazen , is it okay to make this change in the latest GenomicsDB import PR? The version dependency has changed anyway.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292582744:255,depend,dependency,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292582744,1,['depend'],['dependency']
Integrability,"i.e. uses updated kebab syntax. --- . ## CalcMetadataSpark . 1. Revise one-line summary to something like:; Collects read metrics relevant to structural variant discovery. - Notice the lack of a period at the end above.; - Not statistics but metrics?. 2. Overview and Notes could use finessing but let's leave this for next year. One thing to do now is move this statement up top:; This tool is used in development and should not be of interest to most researchers. 3. I think this tool fits under the DiagnosticsAndQCProgramGroup.java.; 4. The tool takes a SAM/BAM/CRAM and calculates fragment length statistics...; 5. ""This is the first step in the workflow""--> makes it sound like this tool is necessary in the SV workflow but you say otherwise in the debugging sentence. I find this confusing. 6. I'm noticing that the example command does not have spark options despite the tool being a Spark tool. For such cases, it would be helpful to state, e.g. ""This tool can run in both Spark and non-Spark modes, depending on if --sparkMaster is set."" Then include a second example command that shows how to utilize Spark. There is an example from ChrisW in <https://github.com/broadinstitute/gatk/issues/3853>:. ```; 	-- \; --sparkRunner GCS \; --cluster my-dataproc-spark-cluster; ```. ---; ## DiscoverVariantsFromContigAlignmentsSAMSpark. 1. ""Parse"" is vague. How about: ; Parses aligned contig assemblies of genomic breakpoints and calls structural variants. And `6. ` from above. ---; ## ExtractOriginalAlignmentRecordsByNameSpark. 1. Subsets reads by names; 2. I think you mean FilterSamReads (Picard) and not PrintReads. AFAIK, PrintReads cannot subset based on a list of read names. Rather FilterSamReads can do so as long as the reads are queryname-sorted. So then it would be good to distinguish this tool from FilterSamReads by saying (assuming true) ""Unlike FilterSamReads, this tool can take any sort-order, e.g. unsorted, to subset target reads.""; 3. ReadDataProgramGroup.java. And `6. ` fr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451:1342,depend,depending,1342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451,2,['depend'],['depending']
Integrability,"ies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; -",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:2316,depend,dependencies,2316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['depend'],['dependencies']
Integrability,if there is a mismatch between VCF header name and sample map name... an helpful error message would be nice. Checking 1000s of VCFs to find an error would be a pain,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301532660:87,message,message,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301532660,1,['message'],['message']
Integrability,iltering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePip,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1654,wrap,wrapAndCopyInto,1654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887,1,['wrap'],['wrapAndCopyInto']
Integrability,"implementation is different from the one in `ReadWindowWalker`: first, the overlap between windows is only in one direction; second, `SlidingWindowWalker` is more like a reference/interval walker, from the beginning of the reference (or interval) till the end, it walks in overlapping windows. One example is the following (window-size 10, window-step 5, the - represent the window):. ```; Reference: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; Windows1: _ _ _ _ _ _ _ _ _ _; Windows2: _ _ _ _ _ _ _ _ _ _; Windows3: _ _ _ _ _ _ _ _ _ _; Windows4: _ _ _ _ _ _ _ _ _ _; Windows5: _ _ _ _ _ _ _ _ _ _; ```. Of course, after having a look to `ReadWindowWalker` I think that several things could be improved in my implementation for a general `SlidingWindowWalker`:; - Apply function similar to the `ReadWindowWalker`, with `ReadWindow` being empty if reads are not provided.; - Three window options: `windowSize` (the actual size of the window), `windowStep` (how much advance for the following window) and `windowPadding` (how much extend the window in both directions). Using this abstraction, `ReadWindowWalker` could be implemented setting `windowSize=windowStep`, and the problem that I need to solve could be implemented setting `windowPadding=0`. The simplest way to acomplish this is to use the current implementation of `ReadWindowWalker` to develop a `SlidingWindowWalker` adding three abstract methods for the three parameters (`getWindowSize()`, `getWindowStep()` and `getWindowPadding()`, and implement `ReadWindowWalker` as a extension of this interface setting `getWindowStep()` to return `getWindowSize()` and `requiresReads()` to true. I can do this once the PR #1567 is accepted and generate the two interfaces (to be sure that the integration with the HC engine is working as expected with the changes), or just implement the `SlidingWindowWalker` and you can include it in the HC PR, or update afterwards to avoid redundancy in the code. What do you think, @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775:2154,interface,interface,2154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775,3,"['integrat', 'interface']","['integration', 'interface', 'interfaces']"
Integrability,in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://stor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1112,integrat,integration,1112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,1,['integrat'],['integration']
Integrability,"in"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$Ht",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1375,wrap,wrapper,1375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,"inatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37271,Wrap,Wrappers,37271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"inatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:37023,Wrap,Wrappers,37023,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,ine.java:162); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:596); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1(HaplotypeCallerSpark.java:282); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:760); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230:2033,Wrap,Wrappers,2033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230,1,['Wrap'],['Wrappers']
Integrability,ine.java:210); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.calculateGenotypes(GenotypeGVCFs.java:266); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:201); at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:149); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:984); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928:3328,wrap,wrapAndCopyInto,3328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928,2,['wrap'],['wrapAndCopyInto']
Integrability,integration run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/534011af-6909-49b4-b451-a0604eafb447,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7901#issuecomment-1155658697:0,integrat,integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7901#issuecomment-1155658697,1,['integrat'],['integration']
Integrability,integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1781,integrat,integration,1781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,4,['integrat'],['integration']
Integrability,ionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.Te,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:1869,Message,MessageHub,1869,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858,1,['Message'],['MessageHub']
Integrability,"ions here, which might allow for easier treatment of ill-behaved annotations. However, I'd say enabling workflows where the set of annotations is fixed is the priority.; - [ ] We could do positive-unlabeled training more rigorously or iteratively. Right now, we essentially do a single iteration to determine negative data. This could perhaps be preceded by a round of refactoring to clean up model training and make it less procedural.; - [ ] Automatic threshold tuning could be built into the tool, see #7711. We'd probably have to introduce a ""validation"" label. Perhaps it makes sense to keep this sort of thing at the workflow level?; - [ ] In the positive-negative framework enforced by the Java code in this tool, a ""model"" is anything that assigns a score, we fit two models to different subsets of the data, and then take the difference of the two scores. While the python backend does give some freedom to specify a model, future developers may want to go beyond the framework itself. For example, more traditional classification frameworks, etc. could be explored. As an intermediate step, one could perhaps use the positive/negative scores from the current framework in a more sophisticated way (e.g., using them as features), rather than just taking their difference. This sort of future work could be developed completely independently of the codebase associated with the current training tool (or done externally in python), but should still be able to make use of the extract and score tools, since the contracts should be relatively general. EDIT: I think I will go ahead and ablate the positive-negative option, as this adds a lot of overly complicated code for little benefit. So Java code in this tool will only be responsible for selecting variant types---and we may even want to move that functionality into backends in the future. To start, BGMM and IsolationForest backends will be positive-only, and custom Python backends will have the unlabeled annotations passed directly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369:2561,contract,contracts,2561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369,1,['contract'],['contracts']
Integrability,"ire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/decoders (currently held in the Collection corresponding to each Record) to a single Tribble codec. This codec should not depend upon the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:2121,depend,depend,2121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082,1,['depend'],['depend']
Integrability,"is is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByOrientationBias`` (with the possible exception of the bgzip VCF). These issues are all in its dependencies, which are part of the engine/picard-ports.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:2256,depend,dependencies,2256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143,3,['depend'],"['dependencies', 'dependency']"
Integrability,"is there a haplotype-based prior that uses the alignment of the haplotype; to the reference? A prior that depends on the alignment might be better; than a flat pro-reference prior. On Thu, May 31, 2018 at 9:34 AM, ldgauthier <notifications@github.com>; wrote:. > I found the data from yet another example of this behavior (see poorly; > aligned reads in the bamout -- somehow the big fat deletion is preferred; > over the reference):; > [image: dlbcl-c_d_pair13 nkap x_119059262 frame_shift_del; > ctctcttcttggttaaaggatgcaaggg_-]; > <https://user-images.githubusercontent.com/6578548/40785072-7fdff344-64b5-11e8-8539-78267b9a2950.png>; >; > tumor exome: /seq/picard_aggregation/C1637/c_D_pair13_Dx/v3/c_D_pair13_; > Dx.bam; > normal exome: /seq/picard_aggregation/C1637/RICOVER_134_N/v2/RICOVER_134_; > N.bam; > M2 tumor bam: /xchip/cga_home/stewart/Cancer/DLBCL/M2/test/c_D_; > pair13_Dx.bam; > M2 normal bam: /xchip/cga_home/stewart/Cancer/DLBCL/M2/test/RICOVER_; > 134_N.bam; > M2 combined bam: /xchip/cga_home/stewart/Cancer/DLBCL/M2/test/DLBCL-c_; > D_pair13.M2_validation_bam.bam; > I can't guarantee the data is still around and I don't have the exact; > intervals, but if it doesn't reproduce in the latest GATK4 M2 then we can; > forget about it. If it does reproduce then it would put my mind at ease if; > the prior fixes this case too (and you could let Chip know that it got; > fixed 2.5 years later :-P); >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393531485>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0qP335PYrMmALyjp96ZdOw_hv03Mks5t3_FQgaJpZM4UUW5o>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393559160:106,depend,depends,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393559160,1,['depend'],['depends']
Integrability,java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:541); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:474); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientReq,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7560,protocol,protocol,7560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:361); 	at org.broadinstitute.hellbender.cmdline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1727,protocol,protocol,1727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRCaWFzVGVzdC5qYXZh) | `86.179% <0%> (+0.813%)` | `44% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `69.583% <0%> (+0.833%)` | `60% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.862% <0%> (+0.862%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `93.194% <0%> (+1.047%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> (ø)` | :arrow_down: |; | [...e/hellbender/tools/spark/sv/utils/SVFileUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkZpbGVVdGlscy5qYXZh) | `29.67% <0%> (+1.099%)` | `7% <0%> (ø)` | :arrow_down: |; | ... and [506 more](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4621#issuecomment-378027085:3674,Integrat,IntegrationTestSpec,3674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4621#issuecomment-378027085,1,['Integrat'],['IntegrationTestSpec']
Integrability,"just curious, is deTin model already part of the GATK4 MuTect2 algorithm, or it has not been integrated yet?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3088#issuecomment-1887867443:93,integrat,integrated,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3088#issuecomment-1887867443,1,['integrat'],['integrated']
Integrability,"k.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:25919,Wrap,Wrappers,25919,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"ke a Microsoft bug than a GATK one though. It seems crazy that each layer pull has to be a separate web request and there's no batch api for it? Multi layer docker builds are pretty standard from what I understand. . It sounds like your suggestions are talking about 2 slightly different issues to me. 1. Too many layers:. We typically have squashed the GATK docker images, but we recently switched to building our release images with google cloud build. Since squash is *STILL* an experimental feature in docker we've had trouble getting it to work there. Since the size reduction was pretty minimal from squashing we figured it would be ok to not prioritize it. It's definitely possible for us to consolidate various layers in the build. Or manually squash the images. We can take a look for our next release. Wide workflows on azure are something we need to support. 2. Docker size reduction:; I've spend a lot of time looking at this in the past. Our docker image is huge, but it's mostly due to the massive size of our python and R dependencies. I've done a bunch of work reducing temporary files in independent layers and using multiple stages to reduce the size. There's not much low hanging fruit left there. Similarly, moving to alpine is tricky an has limited benefit. GATK packages a number of C libraries which do not work out of the box on alpine due to the different C runtime. (At least that was the case the last time I investigated it a few years ago. ) I suspect there's a way to port things so they work on it, but it's not something we can do now. It also wouldn't be much of a help, the base image is completely dwarfed by piles of python and R dependencies which are very difficult to safely trim. Anyway, that's the state of things. We've considered a java only image for a while which would be much smaller than the current one. (although still fat by most docker standards...). We've never released one publicly because it seemed like it might cause confusion, but it's a rea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427:1123,depend,dependencies,1123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427,1,['depend'],['dependencies']
Integrability,ket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1677,protocol,protocol,1677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,lateGenotypes(GenotypingEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:162); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:596); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1(HaplotypeCallerSpark.java:282); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:760); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230:1841,Wrap,WrappingSpliterator,1841,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230,1,['Wrap'],['WrappingSpliterator']
Integrability,lbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:324); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:304); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapP,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5979#issuecomment-498620174:2087,wrap,wrapAndCopyInto,2087,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5979#issuecomment-498620174,1,['wrap'],['wrapAndCopyInto']
Integrability,lbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:173); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); > at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.Iterator.forEachRemaining(Iterator.java:116); > at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); > at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); > at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); > at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); > at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); > at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); > at org.b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975:18767,wrap,wrapAndCopyInto,18767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975,1,['wrap'],['wrapAndCopyInto']
Integrability,lbender.tools.walkers.filters.VariantFiltration.matchesFilter(VariantFiltration.java:453); 	at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.filter(VariantFiltration.java:407); 	at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.apply(VariantFiltration.java:354); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6789#issuecomment-686118887:2520,wrap,wrapAndCopyInto,2520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6789#issuecomment-686118887,1,['wrap'],['wrapAndCopyInto']
Integrability,le-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAcce,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1212,Wrap,WrapperExecutor,1212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['Wrap'],['WrapperExecutor']
Integrability,lkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:131); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:106); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker$$Lambda$110/1374115041.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:163); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-716640444:9394,wrap,wrapAndCopyInto,9394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-716640444,1,['wrap'],['wrapAndCopyInto']
Integrability,llion parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogle,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:1160,protocol,protocol,1160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156,1,['protocol'],['protocol']
Integrability,ls.java:283); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.AlleleSubsettingUtils.subsetAlleles(AlleleSubsettingUtils.java:92); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:296); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:162); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:596); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1(HaplotypeCallerSpark.java:282); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); 	a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230:1499,Wrap,WrappingSpliterator,1499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230,1,['Wrap'],['WrappingSpliterator']
Integrability,ltering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-29T18:18:04.002441351Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-29T18:18:04.002446409Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-29T18:18:04.002493533Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-29T18:18:04.002503311Z 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 2019-10-29T18:18:04.002508016Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002512520Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002574562Z 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 2019-10-29T18:18:04.002625341Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 2019-10-29T18:18:04.002635077Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002683298Z 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 2019-10-29T18:18:04.002692496Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 2019-10-29T18:18:04.002697751Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002731707Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:3559,wrap,wrapAndCopyInto,3559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['wrap'],['wrapAndCopyInto']
Integrability,ltering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-30T13:35:51.795607447Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-30T13:35:51.795775473Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-30T13:35:51.795944490Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-30T13:35:51.796108757Z 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 2019-10-30T13:35:51.796277399Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.796441683Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.796940319Z 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 2019-10-30T13:35:51.797119562Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 2019-10-30T13:35:51.797275911Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.797439525Z 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 2019-10-30T13:35:51.797567816Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 2019-10-30T13:35:51.797740910Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.797896360Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-30T13:35:51.798060735Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:3560,wrap,wrapAndCopyInto,3560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227,1,['wrap'],['wrapAndCopyInto']
Integrability,"mmm... that said, I think this must fail using the right error message, don't you think? @droazen.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290743500:63,message,message,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290743500,1,['message'],['message']
Integrability,"n Tools; #; # Only update this environment if there is a *VERY* good reason to do so!; # If the build is broken but could be fixed by doing something else, then do that thing instead.; # Ensuring the correct environment for canonical (or otherwise reasonable) usage of our standard Docker takes precedence over edge cases.; # If you break the environment, you are responsible for fixing it and also owe the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely nec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:1300,depend,dependencies,1300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,4,['depend'],['dependencies']
Integrability,"n a new `--segments` argument:. ```; gatk ModelSegments; --normal-allelic-counts normal.allelicCounts.tsv (equivalently, we could omit this and adjust minimum-total-allele-count-case, as is done in the WDL); --allelic-counts normal.allelicCounts.tsv; --denoised-copy-ratios normal.denoisedCR.tsv; --segments joint-segmentation.interval_list; -O .; --output-prefix normal. gatk ModelSegments; --normal-allelic-counts normal.allelicCounts.tsv; --allelic-counts tumor-1.allelicCounts.tsv; --denoised-copy-ratios tumor-1.denoisedCR.tsv; --segments joint-segmentation.interval_list; -O .; --output-prefix tumor-1. ...; ```. Each scatter of ModelSegments will run as before, aside from skipping the segmentation step in favor of using the joint segmentation. We will repeat the het-genotyping step, but this is cheap and it's probably better to repeat it to make sure filtering is applied consistently. It would also require more changes to the command line to specify where to output the hets for each sample during multisample segmentation and to skip genotyping in each scatter, if we were to go that route. There are many possible combinations of inputs that need to be tested, but the same is already true of the current ModelSegments. Furthermore, there are slight wrinkles when running in tumor-only mode (i.e., when `--normal-allelic-counts` are not available). Because each sample is genotyped indiviudally, each may yield a different set of hets (in contrast to genotyping in matched-normal mode, in which the normal determines the set of hets used in all samples). We will thus have to take the intersection of these hets before performing multisample segmentation. Unfortunately, we will not be able to re-perform this intersection in each scatter, since we will no longer have access to the hets from the other samples. However, we *will* ultimately intersect the hets from each sample with the joint segmentation before modeling, which may be a rough proxy for the intersection of hets from a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549:2490,rout,route,2490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549,1,['rout'],['route']
Integrability,"n chr1:10254; skipping that record. Set --max-indel-length >= 204; 12:55:32.502 INFO LeftAlignAndTrimVariants - Reference allele is too long (207) at position chr1:10276; skipping that record. Set --max-indel-length >= 207; 12:55:32.536 INFO ProgressMeter - unmapped 0.0 295 178787.9; 12:55:32.536 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 12:55:32.536 INFO LeftAlignAndTrimVariants - 133 variants trimmed; 12:55:32.536 INFO LeftAlignAndTrimVariants - 10 variants skipped because the reference allele was too long. The longest had a reference allele length of 245. To not skip these variants set --max-indel-length >= 245; 12:55:32.536 INFO LeftAlignAndTrimVariants - 0 variants left aligned; 12:55:32.542 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 12:55:32 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLib",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:5770,message,messages,5770,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,1,['message'],['messages']
Integrability,"n't find the file, but the file is on the local file system. ```; ls -la /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; -rw-rw-r--. 1 test test 4668988887 Oct 4 11:27 /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; ```. Here is SPARK information. ```; A USER ERROR has occurred: Failed to read bam header from; /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Failed to read bam header from /hom",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:1288,protocol,protocolPB,1288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocolPB']
Integrability,"nHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.<init>(ReadThreadingAssembler.java:81); 	at org.bro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:7261,Message,MessageHub,7261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHub']
Integrability,nMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:5016,wrap,wrapAndCopyInto,5016,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,1,['wrap'],['wrapAndCopyInto']
Integrability,"nager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 WARN TaskSetManager:66 - Lost task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 3, start 97885291, span 192458, expected MD5 ef90368731b6e0be845bc82cd92b0c6a; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:30299,Wrap,Wrappers,30299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"naging and querying Supplementary alignment; > information from read alignment records:; >; > Some of the things that I think smell:; >; > 1.; >; > Querying: implemented in htsjdk consists in forging artificial; > SAMRecords that contain only the alignment info in the SA tag element... It; > seems to me that it makes more sense to create class to hold this; > information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder; > already has defined a private inner class with that in mind ""SARead"" so why; > not flesh it out and make it public.; > 2.; >; > Writing: currently SATagBuilder gets attached to a read, parsing its; > current SA attribute content into SARead instances. It provides the; > possibility adding additional SAM record one by one or clearing the list.; > ... then it actually updates the SA attribute on the original read when a; > method (setTag) is explicitly called.; >; > I don't see the need to attach the SATag Builder to a read... it could; > perfectly be free standing; the same builder could be re-apply to several; > reads for that matter and I don't see any gain in hiding the read SA tag; > setting process,... even if typically this builder output would go to the; > ""SA"" tag, perhaps at some point we would like to also write SA coordinate; > list somewhere else, some other tag name or perhaps an error message... why; > impose this single purpose limitation?; >; > I suggest to drop the notion of a builder for a more general custom; > ReadAlignmentInfo (or whatever name) list. Such list could be making; > reference to a dictionary to validate its elements, prevent duplicates,; > keep the primary SA in the first position... etc.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3324>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZft11VTCtCHT_xr89kPL7hMFYQyhks5sQNghgaJpZM4Ofpkb>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323:2115,message,message,2115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323,2,['message'],['message']
Integrability,ncodeFuncotationFactory.java:2465); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:953); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:812); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:796); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:473); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:474); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:529); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:8139,wrap,wrapAndCopyInto,8139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['wrap'],['wrapAndCopyInto']
Integrability,ncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:529); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Ite,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:9649,wrap,wrapAndCopyInto,9649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['wrap'],['wrapAndCopyInto']
Integrability,ncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Ite,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:4685,wrap,wrapAndCopyInto,4685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,1,['wrap'],['wrapAndCopyInto']
Integrability,"nd other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4. # other python dependencies; these should be removed after functionality is moved into Java code; - biopython=1.76; - pyvcf=0.6.8; - bioconda::pysam=0.15.3 # using older conda-installed versions may result in libcrypto / openssl bugs. # pip installs should be avoided, as pip may not respect the dependencies found by the conda solver; - pip:; - gatkPythonPackageArchive.zip; ```. It seems to successfully create the environment. I'd still recommend updating the information on your README.md and the file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:3197,depend,dependencies,3197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,8,['depend'],['dependencies']
Integrability,"nds for identifying the copy-neutral state.; - [ ] @MartonKN is going to work on an improved caller for his next project. This caller should also make simple calls (not full allelic copy number, but just `0`, `+`, `-`), but should also take advantage of the copy-ratio and minor-allele fraction posteriors estimated by `ModelSegments` to generate quality scores. Plotting:; - Other than the allele-fraction model, the limiting factor was the original plotting code (some plotting runs originally took several hours for a single WGS sample...) We can now make plotting much faster with the ordering enforced by `TSVLocatableCollection` (see below).; - There are now two plotting tools, `PlotDenoisedCopyRatios` and `PlotModeledSegments`. This is in contrast to the old `PlotSegmentedCopyRatio` and `PlotACNVResults`.; - Because `ModelSegments` optionally takes denoised copy ratio and/or allelic counts, `PlotModeledSegments` outputs only the corresponding plots appropriately.; - I added a dependency on the R package `data.table` to slightly speed up the reading of input files.; - Setting `pch="".""` also sped up the generation of scatter plots.; - Plotting now takes a couple of minutes, most of which is I/O (#3554).; - AAF (rather than MAF) is now plotted for allele fraction (#2957). Other:; - I've introduced a `LocatableCollection` class to unify how allelic counts, copy ratios, and segments are stored and read/written from/to TSV (#2836). Intervals are always output in lexicographical order for now, to be consistent with the old coverage collection (#2951). Once @asmirnov239's `CollectReadCounts` is in, we can change everything over to ordering determined by the sequence dictionary.; - Column headers and log2 copy ratio output have been standardized throughout (#2886).; - [x] I've also introduced a `NamedSampleFile` abstract class to tag files that have `#SAMPLE_NAME=...` as the first comment line. For `CollectAllelicCounts`, this simply uses code borrowed from `GetSampleName`. W",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:9138,depend,dependency,9138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['depend'],['dependency']
Integrability,net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); 	at com.luz.push.utils.GcmUtils.init(GcmUtils.java:31); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:14064,protocol,protocol,14064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,3,['protocol'],['protocol']
Integrability,"ng?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > —; > You",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:1004,contract,contract,1004,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725,1,['contract'],['contract']
Integrability,ngine.java:152); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:135); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:283); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); 	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:502); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1014180059:8973,wrap,wrapAndCopyInto,8973,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1014180059,2,['wrap'],['wrapAndCopyInto']
Integrability,"no. I didn't have time to look at the integration tests :-(. On Tue, Jan 12, 2021 at 3:17 PM droazen <notifications@github.com> wrote:. > @yfarjoun <https://github.com/yfarjoun> What do you want to do with this; > one? Are the issues with the tests resolved?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/6453#issuecomment-758914892>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AAU6JUVKOVTKSAHQK3SROIDSZSU33ANCNFSM4KUTOOYA>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6453#issuecomment-758946298:38,integrat,integration,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6453#issuecomment-758946298,1,['integrat'],['integration']
Integrability,nstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.WellformedReadFilter.test(WellformedReadFilter.java:77); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.lambda$getReads$e4b35a40$1(GATKSparkTool.java:213); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool$$Lambda$93/2063469002.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:2382,wrap,wrapAndCopyInto,2382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['wrap'],['wrapAndCopyInto']
Integrability,nt.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:361); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); 	at org.broadinstitute.hellbender.cmdline.Comman,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1850,protocol,protocol,1850,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,"ntReads cannot subset based on a list of read names. Rather FilterSamReads can do so as long as the reads are queryname-sorted. So then it would be good to distinguish this tool from FilterSamReads by saying (assuming true) ""Unlike FilterSamReads, this tool can take any sort-order, e.g. unsorted, to subset target reads.""; 3. ReadDataProgramGroup.java. And `6. ` from above. ---; ## FilterLongReadAlignmentsSAMSpark. 1. In the one-line summary, I'm not clear on what is meant by ""Filters"". Based on the result file, seems like it collects metrics on each contig alignment.; 2. ; 3. If metrics, then DiagnosticsAndQCProgramGroup.java. And `6. ` from above. ---; ## FindBadGenomicKmersSpark. 1. The term ""copy number"" should be reserved in reference to CNV analyses. So instead, how about:; Identify sequence contexts that occur at high frequency in a reference; 2. Please define a kmer. If only a reference fasta is required (as listed under Inputs) great. But if the tool also depends on a FAI index and DICT dictionary, please do include them. Also, it would be good to provide an example of how such information is used in SV discovery, e.g. ""the resulting file can be given to FindBreakpointEvidenceSpark, which will then ignore such sequence contexts during analysis."" Also would be good to mention that the default kmer size (--k-size 51) is optimized for human if indeed this is the case.; 3. ReferenceProgramGroup.java. And `6. ` from above. ---; ## FindBreakpointEvidenceSpark. 1. Assembles and aligns contigs of genomic breakpoint regions associated with structural variants ; 2. Overview and Notes could use finessing but let's leave this for next year. One thing to include is a reference to FermiLite for those seeking more information. A publication would be best. And `6. ` from above. ---; ## StructuralVariationDiscoveryPipelineSpark. 1. Runs the structural variant discovery workflow on a single sample in Spark ; 2. Fyi we sanction a ""Caveats"" section, which is likely more appropri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451:2945,depend,depends,2945,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451,2,['depend'],['depends']
Integrability,oadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:306); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:243); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); 	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEnt,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053:6499,wrap,wrapAndCopyInto,6499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053,1,['wrap'],['wrapAndCopyInto']
Integrability,oadinstitute/gatk/jobs/498538899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.13/tests/test/index.html) |; | integration | openjdk11 | [33752.12](https://travis-ci.com/broadinstitute/gatk/jobs/498538898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33752.4](https://travis-ci.com/broadinstitute/gatk/jobs/498538890) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.4/tests/test/index.html) |; | unit | openjdk8 | [33752.3](https://travis-ci.com/broadinstitute/gatk/jobs/498538889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.3/tests/test/index.html) |; | conda | openjdk8 | [33752.5](https://travis-ci.com/broadinstitute/gatk/jobs/498538891) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.5/tests/test/index.html) |; | integration | openjdk8 | [33752.2](https://travis-ci.com/broadinstitute/gatk/jobs/498538888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.2/tests/test/index.html) |; | cloud | openjdk11 | [33752.14](https://travis-ci.com/broadinstitute/gatk/jobs/498538900) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.14/tests/test/index.html) |; | cloud | openjdk8 | [33752.1](https://travis-ci.com/broadinstitute/gatk/jobs/498538887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.1/tests/test/index.html) |; | unit | openjdk11 | [33752.13](https://travis-ci.com/broadinstitute/gatk/jobs/498538899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.13/tests/test/index.html) |; | integration | openjdk11 | [33752.12](https://travis-ci.com/broadinstitute/gatk/jobs/498538898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_337,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234:1675,integrat,integration,1675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234,1,['integrat'],['integration']
Integrability,obReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 41 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:5558,protocol,protocol,5558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['protocol'],['protocol']
Integrability,obReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9046,protocol,protocol,9046,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['protocol'],['protocol']
Integrability,ocate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1123,wrap,wrapper,1123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['wrap'],['wrapper']
Integrability,ocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:113); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(Google,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1432,protocol,protocol,1432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,2,['protocol'],['protocol']
Integrability,od); 	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); 	at com.google.auth.oauth,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:13881,protocol,protocol,13881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,3,['protocol'],['protocol']
Integrability,"of the expected files, since the transform is appended to the corresponding variable name. DetermineGermlineContigPloidy and PostprocessGermlineCNVCalls are missing exact-match tests and should probably have some, but I'll leave that to someone else.; - [x] Update other python integration tests.; - [x] Clean up some of the changes to the priors.; - [x] Clean up some TODO comments that I left to track code changes that might result in changed numerics. I'll try to go through and convert these to PR comments in an initial review pass.; - [x] Test over multiple shards on WGS and WES. Probably some scientific tests on ~100 samples in both cohort and case mode would do the trick. We should also double check runtime/memory performance (I noted ~1.5x speedups, but didn't measure carefully; I also want to make sure the changes to posterior sampling didn't introduce any memory issues). @mwalker174 will ping you when a Docker is ready! Might be good to loop in Isaac and/or Jack as well.; - [x] Perhaps add back the fix for 2-interval shards in https://github.com/broadinstitute/gatk/pull/8180, which I removed since the required functionality wasn't immediately available in Pytensor. Not sure if this actually broke things though---need to check. (However, I don't actually think this is a very important use case to support...); - [x] Delete/deprecate/etc. CNN tools/tests as appropriate. Note that this has to be done concurrently, since we remove Tensorflow. @droazen perhaps I can take a first stab at this in a subsequent commit to this PR once more of the gCNV dust settles and/or has undergone a preliminary review? EDIT: Disabled integration/WDL tests. We should add some deprecation messages to the tools---we can note that they should still work in previous environments but will be untested. I might set up a separate PR for deletion, to be done at the appropriate time (but I call dibs on this, can't have @davidbenjamin overtaking my all-time record for number of lines deleted 😛).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:3800,integrat,integration,3800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,2,"['integrat', 'message']","['integration', 'messages']"
Integrability,"ollapsed it into a single class for several reasons:; - Inheriting from a more generic traversal type caused usability issues and confusion with respect to the command-line arguments. The `ReadWindow` was the unit of processing for the superclass, but for `AssemblyRegionWalker` it was the unit of I/O and `AssemblyRegion` was the unit of processing, and I couldn't update the docs for `ReadWindowWalker` to clear up the confusion without mentioning `AssemblyRegion`-specific concepts.; - The `ReadShard` / `ReadWindow` was/is **only** there to prove that we can shard the data without introducing calling artifacts, and to provide a unit of parallelism for the upcoming Spark implementation. It's not something we really want to expose to users as a prominent knob, and we may hide it completely in the future once the shard size is tuned for performance.; - Inheriting from a more abstract walker type caused a number of other problems as well: methods that should have been final in the supertype could no longer be made final, with the result that tool implementations could inappropriately override engine initialization/shutdown routines. Also, there were issues with the progress meter, since both the supertype traversal and subtype traversal needed their own progress meter for their different units of processing. Ultimately it was just too awkward and forced, and the read shard is something that we eventually want to make an internal/encapsulated implementation detail anyway. GATK3 made the mistake, I think, of using long, confusing inheritance chains for its walker types, with the result that you got awkward and forced relationships like `RodWalker` inheriting from `LocusWalker`. It's better, I think, to make each traversal as standalone as possible, especially given the simplicity of writing a new walker type in GATK4. For all of these reasons we don't want `AssemblyRegionWalker` to inherit from a more abstract traversal type -- it's just going to be its own standalone thing",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513:1660,rout,routines,1660,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513,1,['rout'],['routines']
Integrability,ollowing jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16321393716) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16321393852) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.12/tests/test/index.html) |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347530908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | unit | 11 | [6016742374.13](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347531468) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.13/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347531169) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.12/tests/test/index.html) |; | unit | 11 | [6016742374.13](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16362542517) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.13/tests/test/index.html) |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16362542090) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16362542310) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1698045984:1202,integrat,integration,1202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1698045984,2,['integrat'],['integration']
Integrability,on channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:1066,protocol,protocol,1066,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156,1,['protocol'],['protocol']
Integrability,"on localhost (executor driver) (4/4); 17/05/05 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 17/05/05 17:03:58 INFO DAGScheduler: ResultStage 2 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) finished in 10.370 s; 17/05/05 17:03:58 INFO DAGScheduler: Job 1 finished: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 16.702399 s; 17/05/05 17:03:58 INFO SparkUI: Stopped Spark web UI at http://172.30.0.122:46483; 17/05/05 17:03:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/05/05 17:03:59 INFO MemoryStore: MemoryStore cleared; 17/05/05 17:03:59 INFO BlockManager: BlockManager stopped; 17/05/05 17:03:59 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/05/05 17:03:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/05/05 17:03:59 INFO SparkContext: Successfully stopped SparkContext; [May 5, 2017 5:03:59 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=799080448; 17/05/05 17:03:59 INFO ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); 17/05/05 17:03:59 INFO ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Shutdown hook called before final status was reported.); 17/05/05 17:03:59 INFO ApplicationMaster: Deleting staging directory hdfs://ip-172-30-0-86.ec2.internal:8020/user/hadoop/.sparkStaging/application_1493961816416_0010; 17/05/05 17:03:59 INFO ShutdownHookManager: Shutdown hook called; 17/05/05 17:03:59 INFO ShutdownHookManager: Deleting directory /mnt1/yarn/usercache/hadoop/appcache/application_1493961816416_0010/spark-223a9e8b-0fe9-41f0-8bed-f843978f1882; 17/05/05 17:03:59 INFO ShutdownHookManager: Deleting directory /mnt/yarn/usercache/hadoop/appcache/application_1493961816416_0010/spark-573a9c53-e268-4f3b-8907-1f35e5839788; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046:18568,message,message,18568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046,2,['message'],['message']
Integrability,"onPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1169,wrap,wrapper,1169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,"onScriptExecutor.java:121); at; org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:411); at; org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:288); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). Kindly give your inputs.. Thanks; Sridhar. On Thu, 17 Oct 2019 at 16:05, samuelklee <notifications@github.com> wrote:. > Thanks for trying out the tool, @ssri28 <https://github.com/ssri28>. The; > exception message states that “List of input read-count files cannot; > contain duplicates,” so that would be the first thing to check. Since we; > are either building a model or calling ploidy from the count files, it; > doesn’t make sense to allow duplicates.; >; > The support forums at https://gatkforums.broadinstitute.org/ are a better; > place for getting help with running the tools and diagnosing exceptions.; > GitHub issues should be reserved for bug reports and feature requests.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6217?email_source=notifications&email_token=AKXA3TRWNVROQOYIKTK4XITQPA5XDA5CNFSM4JBWKHV2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBPUC7Q#issuecomment-543113598>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AKXA3TSNIGY7IC4Q2V4IVWLQPA5XDANCNFSM4JBWKHVQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543122687:4916,message,message,4916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543122687,1,['message'],['message']
Integrability,onnection refused); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at sha,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:1685,protocol,protocol,1685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843,1,['protocol'],['protocol']
Integrability,"onsolidated with---@jamesemery thoughts? Again, let me reiterate that it seems that many of these parameter values were chosen arbitrarily (or, if not, that the procedure for choosing them has been lost). As a start, you can see the results of some optimizations I did on the CHM mix on slide 15 at https://docs.google.com/presentation/d/1zGuquAZWSUQ-wNxp8D6HhGNjIaFcV0_X9WAS4LODbEo/edit?usp=sharing Here, I optimized over haplotype-to-reference + read-to-haplotype SW parameters on various metrics after variant normalization using vcfeval. These optimizations were done using the Bayesian optimization framework I prototyped long ago (see https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer and https://docs.google.com/presentation/d/1t5WOAEOMp0xAzJgpKbP68BUnclNYfIVRrDSL9wl1-3A/edit?usp=sharing); this entailed running parameter scans using a local Cromwell on my desktop. Probably this optimization work could be redone relatively easily using the Neptune framework put together by @dalessioluca, which was still in development at the time I did this work. Happy to share the resources and scripts I used if we go down this route; they are pretty lightweight. See more discussion starting here: https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566. Alternatively, we could merge this branch to expose the parameters now and punt on consolidating/optimizing them. I'm not completely convinced we should even do the former unless we are going to follow through on the latter, but happy to defer to others. Finally, note also there is one code optimization that I removed, since it makes assumptions on the SW parameter values that might not be valid for non-default values. I'll highlight this with a comment below. We can restore it if we add code to check whether the assumptions hold, but I'd be curious to see in which cases the optimization makes a big difference. See https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707870344.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471:2428,rout,route,2428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471,1,['rout'],['route']
Integrability,"ools `CallVariantsFromAlignedContigsSpark` and `CallVariantsFromAlignedContigsSAMSpark` share a significant part of workflow. Conceptually, what happens is:; 1. turn `AlignmentRegion`'s (produced by another tool in difference formats that must be parsed) into `AssembledBreakpoint`'s;; 2. extract `BreakpointAllele` from a `AssembledBreakpoint`, and group the `AssembledBreakpoint`'s by each of their `BreakpointAllele`;; 3. filter `BreakpointAllele`'s;; 4. for each `BreakpointAllele` that survived the filter, filter its supporting `AssembledBreakpoint`'s then create an `VariantContext`;; 5. write VCF. In both of the tools, these steps are accomplished in almost the same way, involving the following functions. ``` java; public static Iterable<AssembledBreakpoint> assembledBreakpointsFromAlignmentRegions(final byte[] contigSequence,; final Iterable<AlignmentRegion> alignmentRegionsIterable,; final Integer minAlignLength);. public static Tuple2<BreakpointAllele, Tuple2<Tuple2<String,String>, AssembledBreakpoint>> keyByBreakpointAllele(final Tuple2<Tuple2<String,String>, AssembledBreakpoint> breakpointIdAndAssembledBreakpoint);. public static Boolean inversionBreakpointFilter(final Tuple2<BreakpointAllele, Tuple2<Tuple2<String,String>,AssembledBreakpoint>> breakpointAlleleTuple2Tuple2);. public static VariantContext filterBreakpointsAndProduceVariants(final Tuple2<BreakpointAllele, Iterable<Tuple2<Tuple2<String,String>, AssembledBreakpoint>>> assembledBreakpointsPerAllele,; final Broadcast<ReferenceMultiSource> broadcastReference);; ```. The concept is general enough that a separate class (potentially having its own shallow class hierarchy for different types of SV's) is extracted and provide a single interface like `callVariants()`.; And if the afore-mentioned functions could be moved from `ContigAligner` to here, all of them can be packed in the extracted class/interface.; Then different callers for different SV types could just override (or whatever technique) when fit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240138574:1761,interface,interface,1761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240138574,2,['interface'],['interface']
Integrability,ools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955:6269,wrap,wrapAndCopyInto,6269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955,5,['wrap'],['wrapAndCopyInto']
Integrability,"orcement of consistent GC-bias correction).; - [ ] That said, I'll carry over this TODO from above: Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - The only major difference is we no longer make a QC PoN or check for large events. This was performed awkwardly in the old pipeline, so I'd rather not port it over. Eventually we will do all denoising with the gCNV coverage model anyway.; - Pre/tangent-normalization copy ratio are now referred to as standardized/denoised copy ratio.; - [x] Old code is still used for GC-bias correction in `CreateReadCountPanelOfNormals`, and we still use the `AnnotateTargets` tool. We should port this over (possibly as part of `PreprocessIntervals`) at some point (actually, I think we will be forced to, since `PreprocessIntervals` will output a Picard interval list, and `AnnotateTargets` outputs a target file).; - [x] Integration tests are still needed for `CreateReadCountPanelOfNormals`. These might not test for correctness, but we could possibly compare to old PoNs. Segmentation/modeling:; - Instead of separate tools for copy-ratio segmentation (`PerformSegmentation`) and allele-fraction segmentation/union/modeling (`AllelicCNV`), there is now just a single segmentation/modeling tool (`ModelSegments`).; - Input is denoised copy ratio and/or allelic counts. If only one input is provided, then we only model only the corresponding quantity.; - There is no separate allele-fraction workflow. Unlike the old approach, we do not perform any genotyping or modeling before doing kernel segmentation.; - [x] Old code and classes are used for segment union. We should port or possibly replace this with a simple method that uses kernel segmentation. EDIT: Actually, just tried running a WGS sample and this is still a major bottleneck. EDIT 2: Hmm...actually doesn't seem to be an issue on my desktop (compared to my laptop, on which the run hangs ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:2887,Integrat,Integration,2887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['Integrat'],['Integration']
Integrability,org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:10908,wrap,wrapAndCopyInto,10908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['wrap'],['wrapAndCopyInto']
Integrability,org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:5944,wrap,wrapAndCopyInto,5944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,1,['wrap'],['wrapAndCopyInto']
Integrability,org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.regenotypeVC(GenotypeGVCFsEngine.java:185); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:135); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:283); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:423); at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135301848:5595,wrap,wrapAndCopyInto,5595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135301848,2,['wrap'],['wrapAndCopyInto']
Integrability,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2345,protocol,protocol,2345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,3,"['protocol', 'wrap']","['protocol', 'wrapper']"
Integrability,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:2181,integrat,integration,2181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115,2,['integrat'],['integration']
Integrability,otationFactory.java:1086); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFac,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:2468,wrap,wrapAndCopyInto,2468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,1,['wrap'],['wrapAndCopyInto']
Integrability,other than manually testing this---is there a test I can write to include this? Maybe add it to the QS integration test?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7844#issuecomment-1125299078:103,integrat,integration,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7844#issuecomment-1125299078,1,['integrat'],['integration']
Integrability,"ould like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I added something else in https://github.com/samtools/htsjdk/issues/520",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:1238,interface,interface,1238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940,4,"['depend', 'interface']","['depending', 'interface']"
Integrability,ounds for length 1; > 44 at java.base/jdk.internal.util.Preconditions.outOfBounds(Preconditions.java:64); > 45 at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckIndex(Preconditions.java:70); > 46 at java.base/jdk.internal.util.Preconditions.checkIndex(Preconditions.java:266); > 47 at java.base/java.util.Objects.checkIndex(Objects.java:359); > 48 at java.base/java.util.ArrayList.get(ArrayList.java:427); > 49 at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$27(SomaticGenotypingEngine.java:389); > 50 at java.base/java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:248); > 51 at java.base/java.util.stream.SliceOps$1$1.accept(SliceOps.java:200); > 52 at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625); > 53 at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509); > 54 at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499); > 55 at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:575); > 56 at java.base/java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); > 57 at java.base/java.util.stream.DoublePipeline.toArray(DoublePipeline.java:571); > 58 at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getGermlineAltAlleleFrequencies(SomaticGenotypingEngine.java:390); > 59 at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getNegativeLogPopulationAFAnnotation(SomaticGenotypingEngine.java:363); > 60 at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:166); > 61 at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:336); > 62 at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:304); > 63 at org.broadinstitute.hellbender.engine.AssemblyRegionWal,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1597198632:5609,wrap,wrapAndCopyInto,5609,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1597198632,1,['wrap'],['wrapAndCopyInto']
Integrability,"ozygous genotypes failing two-tailed binomial test (example below); q .. select genotypes using -i/-e options; and the new genotype can be one of:; . .. missing (""."" or ""./."", keeps ploidy); 0 .. reference allele (e.g. 0/0 or 0, keeps ploidy); c:GT .. custom genotype (e.g. 0/0, 0, 0/1, m/M, overrides ploidy); m .. minor (the second most common) allele (e.g. 1/1 or 1, keeps ploidy); M .. major allele (e.g. 1/1 or 1, keeps ploidy); p .. phase genotype (0/1 becomes 0|1); u .. unphase genotype and sort by allele (1|0 becomes 0/1); Usage: bcftools +setGT [General Options] -- [Plugin Options]; Options:; run ""bcftools plugin"" for a list of common options. Plugin options:; -e, --exclude <expr> Exclude a genotype if true (requires -t q); -i, --include <expr> include a genotype if true (requires -t q); -n, --new-gt <type> Genotypes to set, see above; -t, --target-gt <type> Genotypes to change, see above. Example:; # set missing genotypes (""./."") to phased ref genotypes (""0|0""); bcftools +setGT in.vcf -- -t . -n 0p. # set missing genotypes with DP>0 and GQ>20 to ref genotypes (""0/0""); bcftools +setGT in.vcf -- -t q -n 0 -i 'GT=""."" && FMT/DP>0 && GQ>20'. # set partially missing genotypes to completely missing; bcftools +setGT in.vcf -- -t ./x -n . # set heterozygous genotypes to 0/0 if binom.test(nAlt,nRef+nAlt,0.5)<1e-3; bcftools +setGT in.vcf -- -t ""b:AD<1e-3"" -n 0. # force unphased heterozygous genotype if binom.test(nAlt,nRef+nAlt,0.5)>0.1; bcftools +setGT in.vcf -- -t ./x -n c:'m/M'; ```; I was always wondering if GATK will have a plugin interface where people can code their own using groovy, kotlin, javascript or python plugins to extend some of the functionality where developers may not reach immediately. Personally I use htsjdk extensively (and sometimes pysam) to code a new personal tool each time I need something that I cannot find exactly what I look for. But a generic gatk plugin interface would be really useful and may provide means to extend the community support.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501:1930,interface,interface,1930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501,2,['interface'],['interface']
Integrability,p.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:2399,wrap,wrapper,2399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,5,"['Wrap', 'wrap']","['WrapperExecutor', 'wrapper']"
Integrability,p: |; | [...er/tools/picard/analysis/CollectGcBiasMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvYW5hbHlzaXMvQ29sbGVjdEdjQmlhc01ldHJpY3MuamF2YQ==) | `0.794% <0%> (+0.794%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.847% <0%> (+0.847%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `67.347% <0%> (+1.02%)` | `34% <0%> (+1%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> (ø)` | :arrow_down: |; | [...e/conversion/allelicbalancecaller/CNLOHCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9jb252ZXJzaW9uL2FsbGVsaWNiYWxhbmNlY2FsbGVyL0NOTE9IQ2FsbGVyLmphdmE=) | `96.283% <0%> (+1.115%)` | `95% <0%> (+3%)` | :arrow_up: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.737% <0%> (+1.117%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...itute/hellbender/tools/picard/vcf/LiftOverVcf.java](h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200:2874,Integrat,IntegrationTestSpec,2874,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200,1,['Integrat'],['IntegrationTestSpec']
Integrability,patch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```. Unlikely to be related to this branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6652#issuecomment-672024253:5016,Message,MessageHubBackedObjectConnection,5016,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6652#issuecomment-672024253,6,['Message'],"['MessageHub', 'MessageHubBackedObjectConnection']"
Integrability,peCallerGenotypingEngine.java:162); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:596); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1(HaplotypeCallerSpark.java:282); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:760); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrRe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230:1999,Wrap,Wrappers,1999,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230,1,['Wrap'],['Wrappers']
Integrability,"periment with the LL score discussed there (see https://www.aaai.org/Papers/ICML/2003/ICML03-060.pdf for the original paper---although note that despite the paper's high citation count, I'm not sure what the canonical name for this metric actually is, but it doesn't appear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservatively filtered as truth, which will bias us towards high scores and the peaks of the positive distribution. Perhaps we can also experiment with just treating training/truth on an equal footing (I think the distinction between the two is somewhat blurry in the original VQSR design, anyway). Perhaps @davidbenjamin has some thoughts? I see some related stuff going on in ThresholdCalculator, but I have to admit that I can't tell whether that's used in a ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:1678,interface,interfaces,1678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,2,['interface'],['interfaces']
Integrability,"ppear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservatively filtered as truth, which will bias us towards high scores and the peaks of the positive distribution. Perhaps we can also experiment with just treating training/truth on an equal footing (I think the distinction between the two is somewhat blurry in the original VQSR design, anyway). Perhaps @davidbenjamin has some thoughts? I see some related stuff going on in ThresholdCalculator, but I have to admit that I can't tell whether that's used in a similar PU context. Also note that depending on the model used, we might not have well calibrated posteriors---the IsolationForest simply outputs scores in a unit interval, and we simply report the difference between the positive and the negative scores, for example.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:2557,depend,depending,2557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,2,['depend'],['depending']
Integrability,"ption of the columns (each being of form; tract_name.column_name). There's nothing at all sophisticated about this; format, but it's pretty generalizable and easy to parse (and create). An; example; >; > # hgIntegrator: database=hg38 region=genome Wed Apr 18 11:15:34 2018; >; > #gap.chrom gap.chromStart gap.chromEnd gap.type; >; > chr1 0 10000 telomere; >; > chr1 207666 257666 contig; >; > chr1 297968 347968 contig; >; > chr1 535988 585988 contig; >; > chr1 2702781 2746290 scaffold; >; >; For what it's worth, your description of your approach sounds like a; sensible one to me.; I am concerned about the size of the data and how we'd access it. I've; chosen the tracts I have because they are small enough to jam into; resources. On Tue, May 1, 2018 at 8:06 AM samuelklee <notifications@github.com> wrote:. > @TedBrookings <https://github.com/TedBrookings> which formats are you; > using, in particular?; >; > In the CNV package, I've taken pains to unify how tabular data are; > represented in Java, depending on whether each record is Locatable or; > whether the collection of records can be associated with a sample name or; > sequence dictionary. This allows us to represent records that extend; > Locatable with multidimensional numerical or non-numerical annotations; > along with some metadata (sample name and sequence dictionary) with a; > minimum of boilerplate. There are also base methods for producing interval; > trees, etc.; >; > However, this unification effort was a quick push I made before release,; > so some polishing or redesigning may be warranted. We may also want to add; > more forms of metadata, etc. if other teams would require more features.; > Another downside is that this code lacks the indexing, NIO support, etc.; > that some of the other standardized/Tribble formats enjoy. For CNV data,; > this isn't a huge issue, but I think it would be nice to unify how we; > represent such data GATK-wide. As I said above, I don't think VCF is the; > correct answer, but",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551:1519,depend,depending,1519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551,1,['depend'],['depending']
Integrability,"r gradle; build.gradle. 3. Significant changes to existing code to support/invoke new filter; - add arguments for XGBoostEvidenceFilter, changes for scaling density filter by coverage; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/StructuralVariationDiscoveryArgumentCollection.java; - replace calls to BreakpointDensityFilter with calls to BreakpointFilterFactory; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSpark.java; - input coverage-scaled thresholds, convert to absolute internally. Allow thresholds to be double instead of int; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilter.java; - getter functions added to calculate properties for XGBoostEvidenceFilter. Also fromStringRep() and helper constructors added for testing; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointEvidence.java; - updates to tests reflecting changes to these interfaces; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilterTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSparkUnitTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/FindBreakpointEvidenceSparkIntegrationTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/SVIntegrationTestDataProvider.java. 4. Added code; - factory to call appropriate BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointFilterFactory.java; - simple helper class to hold feature vectors for classifier; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/EvidenceFeatures.java; - implement classifier-based BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/XGBoostEvidenceFilter.java; - unit test for classifier filter; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477:1741,interface,interfaces,1741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477,2,['interface'],['interfaces']
Integrability,r/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(Nati,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1204,wrap,wrapper,1204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['wrap'],['wrapper']
Integrability,ractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:541); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:474); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:591); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:436); 	... 29 more; `; Thanks for your time!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7771,protocol,protocol,7771,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,"raction model only models hets, we perform a `GetHetCoverage`-like binomial genotyping step (and output the results) before modeling. However, instead of assuming the null hypothesis of het (f = 0.5) and accepting a site when we cannot reject the null, we assume the null hypothesis of hom (f = error rate or 1 - error rate) and accept a site when we can reject the null. This entire process is very similar to what @davidbenjamin does in https://github.com/broadinstitute/gatk/pull/3638. We should consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains i",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5463,Depend,Depending,5463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['Depend'],['Depending']
Integrability,"ralVariationDiscoveryArgumentCollection.java; - replace calls to BreakpointDensityFilter with calls to BreakpointFilterFactory; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSpark.java; - input coverage-scaled thresholds, convert to absolute internally. Allow thresholds to be double instead of int; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilter.java; - getter functions added to calculate properties for XGBoostEvidenceFilter. Also fromStringRep() and helper constructors added for testing; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointEvidence.java; - updates to tests reflecting changes to these interfaces; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilterTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSparkUnitTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/FindBreakpointEvidenceSparkIntegrationTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/SVIntegrationTestDataProvider.java. 4. Added code; - factory to call appropriate BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointFilterFactory.java; - simple helper class to hold feature vectors for classifier; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/EvidenceFeatures.java; - implement classifier-based BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/XGBoostEvidenceFilter.java; - unit test for classifier filter; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/XGBoostEvidenceFilterUnitTest.java. 5. Added resources; - Genome tracts; src/main/resources/large/hg38_centromeres.txt.gz; src/main/resources/large/hg38_gaps.txt.gz; src/main/resources/large/hg38_umap_s100.txt.gz; - Classifier binary file; src/main/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477:2024,integrat,integration,2024,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477,2,['integrat'],['integration']
Integrability,"raph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gnOkE-d_AeAqXpO8zpxks5vdVvfgaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:1438,inject,injected,1438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767,1,['inject'],['injected']
Integrability,"re falling back on Java implementations (e.g., AVX PairHMM tests). We need to determine the dependencies for these tests and install them separately. Here is the list of packages that get pulled in by the R install: ```autoconf automake autotools-dev binutils bsdmainutils build-essential; bzip2-doc cdbs cpp cpp-5 debhelper dh-strip-nondeterminism dh-translations; dpkg-dev fakeroot g++ g++-5 gcc gcc-5 gettext gettext-base gfortran; gfortran-5 groff-base ifupdown intltool intltool-debian iproute2; isc-dhcp-client isc-dhcp-common libalgorithm-diff-perl; libalgorithm-diff-xs-perl libalgorithm-merge-perl libarchive-zip-perl; libasan2 libasprintf-dev libasprintf0v5 libatm1 libatomic1; libauthen-sasl-perl libblas-common libblas-dev libblas3 libbz2-dev; libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libcroco3 libcurl3; libdns-export162 libdpkg-perl libencode-locale-perl libfakeroot; libfile-basedir-perl libfile-desktopentry-perl libfile-fcntllock-perl; libfile-listing-perl libfile-mimeinfo-perl libfile-stripnondeterminism-perl; libfont-afm-perl libfontenc1 libgcc-5-dev libgdbm3 libgettextpo-dev; libgettextpo0 libgfortran-5-dev libgfortran3 libgomp1 libhtml-form-perl; libhtml-format-perl libhtml-parser-perl libhtml-tagset-perl; libhtml-tree-perl libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl; libhttp-message-perl libhttp-negotiate-perl libio-html-perl; libio-socket-ssl-perl libipc-system-simple-perl libisc-export160 libisl15; libitm1 libjpeg-dev libjpeg-turbo8-dev libjpeg8-dev liblapack-dev liblapack3; liblsan0 liblwp-mediatypes-perl liblwp-protocol-https-perl liblzma-dev; libmail-sendmail-perl libmailtools-perl libmnl0 libmpc3 libmpfr4 libmpx0; libncurses5-dev libnet-dbus-perl libnet-http-perl libnet-smtp-ssl-perl; libnet-ssleay-perl libpaper-utils libpaper1 libpcre16-3 libpcre3-dev; libpcre32-3 libpcrecpp0v5 libperl5.22 libpipeline1 libpng12-dev libquadmath0; libreadline-dev libreadline6-dev libsigsegv2 libstdc++-5-dev; libsys-hostname-long-perl libtcl8.6 libtext-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:2308,message,message-perl,2308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,6,"['mediat', 'message', 'protocol']","['mediatypes-perl', 'message-perl', 'protocol-https-perl']"
Integrability,"ree reads. For other; mutations, maybe there's less than 10 reads corresponding to less than 10; cells, and it can vary pretty dramatically. The total number of cells; represented in a single sample can be thousands to tens of thousands,; usually - but could be many more as the tech advances. My hack for it at the moment is to encode both the cell barcode and the UMI; information into the read name. Then, for each variant, I query the reads; that overlap that variant in the bam file and analyze each read for; supporting the variant or the REF allele - then I can count the reads; according to the specific cells and also deal with any UMI redundancy per; cell. This works pretty well except for the cases where the HC reassembly; provides evidence for the variant and I can't track it to the originally; aligned reads. Also, mostly I think the difficulty here relates to indels; around homopolymers with our pacbio long isoform reads in our rna-seq; variant pipeline that leverages the gatk rna-seq protocol with HC. On Thu, Feb 29, 2024 at 8:58 AM Gökalp Çelik ***@***.***>; wrote:. > Since each cell has a barcode wouldn't it be nice to use them as their; > Read Group ID and Sample Name within the BAM so that variant callers will; > distinguish each cell from their Sample Name and produce a multisample VCF; > for that variant site. Once IDs and Sample Names are split per cell you may; > be able to color them differently in IGV to even visually observe those; > events.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971203108>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX6LYHUXDUMGDU3AIFLYV4ZZLAVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSNZRGIYDGMJQHA>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971223953:1982,Message,Message,1982,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971223953,1,['Message'],['Message']
Integrability,ree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...bender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `70.968% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `92.617% <100%> (+0.531%)` | `33 <1> (+1)` | :arrow_up: |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <100%> (+1.429%)` | `2 <0> (ø)` | :arrow_down: |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <92.857%> (ø)` | `12 <12> (?)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <94.286%> (ø)` | `11 <11> (?)` | |; | [...nstitute/hellbender/utils/clipping/ClippingOp.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9DbGlwcGluZ09wLmphdmE=) | `84.365% <0%> (+1.629%)` | `91% <0%> (+2%)` | :arrow_up: |; | [...stitute/hellbender/utils/clipping/ReadClipper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310:1867,Adapter,AdapterTrimTransformer,1867,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310,1,['Adapter'],['AdapterTrimTransformer']
Integrability,riateList.recordAllValuesInStorage(StandardCovariateList.java:133); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527); 	at org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:145); 	at org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:27); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6242#issuecomment-592005237:8987,wrap,wrapAndCopyInto,8987,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6242#issuecomment-592005237,1,['wrap'],['wrapAndCopyInto']
Integrability,ribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:356); at htsjdk.tribble.readers.SynchronousLineReader.readLine(SynchronousLineReader.java:51); at htsjdk.tribble.readers.LineIteratorImpl.advance(LineIteratorImpl.java:24); at htsjdk.tribble.readers.LineIteratorImpl.advance(LineIteratorImpl.java:11); at htsjdk.samtools.util.AbstractIterator.next(AbstractIterator.java:57); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:70); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:181); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-575277936:2372,wrap,wrapAndCopyInto,2372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-575277936,1,['wrap'],['wrapAndCopyInto']
Integrability,"ributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterIn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1281,wrap,wrapper,1281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,"rimVariants - 0 variants left aligned; 12:55:32.542 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 12:55:32 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/au",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:6335,wrap,wrapper,6335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,1,['wrap'],['wrapper']
Integrability,rk.SparkSharder$5.computeNext(SparkSharder.java:293); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder$5.computeNext(SparkSharder.java:281); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.TransformedIterator.hasNext(TransformedIterator.java:43); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at org.broadinstitute.hellbender.utils.iterators.PushTo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994:1486,Wrap,WrappingSpliterator,1486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994,1,['Wrap'],['WrappingSpliterator']
Integrability,"rk/bwa/BwaSpark.java#L47) launches `BwaSparkEngine` as follows:. ```; final BwaSparkEngine engine = new BwaSparkEngine(bwaArgs.numThreads, bwaArgs.fixedChunkSize, referenceFileName);; ```. and launches the alignment as follows:. ```; final JavaRDD<GATKRead> reads = engine.alignWithBWA(ctx, unalignedReads, readsHeader);; ```. That in turn calls the `align()` method within [BwaSparkEngine.java](https://github.com/broadinstitute/gatk/blob/9fb4d756afbbad58a7e709e2e9fd308983ad255b/src/main/java/org/broadinstitute/hellbender/tools/spark/bwa/BwaSparkEngine.java#L72):. ```; final JavaRDD<String> samLines = align(shortReadPairs);; ```. which then instantiates a new [BwaMem](https://github.com/broadinstitute/gatk/blob/9fb4d756afbbad58a7e709e2e9fd308983ad255b/src/main/java/org/broadinstitute/hellbender/tools/spark/bwa/BwaSparkEngine.java#L101) object:. ```; final BwaMem mem = new BwaMem(index);; ```. Since the BWA implementation at [lindenb/jbwa](https://github.com/lindenb/jbwa) is basically a direct call to Heng's BWA as a library, the BWA option for verbosity is set by the `-v` argument as noted [here](http://bio-bwa.sourceforge.net/bwa.shtml#3):. ```; -v INT Control the verbose level of the output. This option has not been fully supported ; throughout BWA. Ideally, a value 0 for disabling all the output to stderr; 1 for ; outputting errors only; 2 for warnings and errors; 3 for all normal messages; 4 or ; higher for debugging. When this option takes value 4, the output is not SAM. [3] ; ```. This is used in Heng's [bwamem.c](https://github.com/lh3/bwa/blob/5961611c358e480110793bbf241523a3cfac049b/bwamem.c#L1224-L1226) file - and several other places - which generates the printout you see, as follows:. ```; if (bwa_verbose >= 3); fprintf(stderr, ""[M::%s] Processed %d reads in %.3f CPU sec, %.3f real sec\n"", __func__, n, cputime() - ctime, realtime() - rtime);; }; ```. So I would just adjust the verbosity via the arguments to the level that is preferable. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2054#issuecomment-235675398:1628,message,messages,1628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2054#issuecomment-235675398,1,['message'],['messages']
Integrability,"roadinstitute.hellbender.tools.walkers.variantutils...; 2022-08-16T22:45:53.6079174Z Constructing Javadoc information...; 2022-08-16T22:45:53.6079564Z [search path for source files: src/main/java]; 2022-08-16T22:45:53.6082788Z [search path for class files: /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/classes,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/zipfs.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/dnsns.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunjce_provider.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/icedtea-sound.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/nashorn.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/java-atk-wrapper.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunec.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunpkcs11.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/cldrdata.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/jaccess.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/localedata.jar,/gatk/gatk-package-unspecified-SNAPSHOT-local.jar,/jars/gatk-package-4.2.6.1-50-g40182c7-SNAPSHOT-testDependencies.jar,/jars/gatk-package-4.2.6.1-50-g40182c7-SNAPSHOT-test.jar]; 2022-08-16T22:45:53.6382333Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6383952Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:4: error: package com.google.common.base does not exist; 2022-08-16T22:45:53.6523417Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:3: error: package com.google.common.annotations does not exist",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:1531,wrap,wrapper,1531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['wrap'],['wrapper']
Integrability,"roxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.<init>(ReadThreadingAssembler.java:81); 	at org.broadinstitute.hellb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:7284,Message,MessageHub,7284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHub']
Integrability,rrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:66); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:984); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:2979,wrap,wrapAndCopyInto,2979,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887,1,['wrap'],['wrapAndCopyInto']
Integrability,ryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:232); 	... 22 more; Caused by: java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googlea,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7196,protocol,protocol,7196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,"s case with HaplotypeCallerSpark). Any idea on how to extend the size?. The errors are:. `org.broadinstitute.hellbender.exceptions.UserException: Max size of locatable exceeded. Max size is 5000, but locatable size is 8638. Try increasing shard size and/or padding. Locatable: Contig1:65711-74348; 	at org.broadinstitute.hellbender.engine.spark.SparkSharder$5.computeNext(SparkSharder.java:293); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder$5.computeNext(SparkSharder.java:281); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.TransformedIterator.hasNext(TransformedIterator.java:43); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994:1144,Wrap,WrappingSpliterator,1144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994,1,['Wrap'],['WrappingSpliterator']
Integrability,s in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3092731818.10](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333411) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.10/tests/test/index.html) |; | cloud | 11 | [3092731818.11](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333541) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.11/tests/test/index.html) |; | unit | 11 | [3092731818.13](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.13/tests/test/index.html) |; | integration | 11 | [3092731818.12](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333644) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.12/tests/test/index.html) |; | conda | 8 | [3092731818.3](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004627834) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.3/tests/test/index.html) |; | unit | 8 | [3092731818.1](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004627636) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.1/tests/test/index.html) |; | integration | 8 | [3092731818.0](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004627523) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.0/tests/test/index.html) |; | variantcalling | 8 | [3092731818.2](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004627749) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252803679:1668,integrat,integration,1668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252803679,1,['integrat'],['integration']
Integrability,s in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3092905417.10](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691605) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.10/tests/test/index.html) |; | cloud | 11 | [3092905417.11](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.11/tests/test/index.html) |; | unit | 11 | [3092905417.13](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691976) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.13/tests/test/index.html) |; | integration | 11 | [3092905417.12](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691810) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.12/tests/test/index.html) |; | unit | 8 | [3092905417.1](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004926160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.1/tests/test/index.html) |; | conda | 8 | [3092905417.3](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004926443) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.3/tests/test/index.html) |; | variantcalling | 8 | [3092905417.2](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004926310) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.2/tests/test/index.html) |; | integration | 8 | [3092905417.0](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004926053) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252832367:1911,integrat,integration,1911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252832367,1,['integrat'],['integration']
Integrability,s in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3291375153.10](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447220) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.10/tests/test/index.html) |; | cloud | 11 | [3291375153.11](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.11/tests/test/index.html) |; | unit | 11 | [3291375153.13](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447526) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.13/tests/test/index.html) |; | integration | 11 | [3291375153.12](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447422) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.12/tests/test/index.html) |; | unit | 8 | [3291375153.1](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425749385) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.1/tests/test/index.html) |; | conda | 8 | [3291375153.3](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425749598) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.3/tests/test/index.html) |; | variantcalling | 8 | [3291375153.2](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425749495) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.2/tests/test/index.html) |; | integration | 8 | [3291375153.0](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425749244) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1285871268:1911,integrat,integration,1911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1285871268,1,['integrat'],['integration']
Integrability,s in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3300297321.10](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444638536) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.10/tests/test/index.html) |; | unit | 11 | [3300297321.13](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444638791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.13/tests/test/index.html) |; | cloud | 11 | [3300297321.11](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444638641) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.11/tests/test/index.html) |; | conda | 8 | [3300297321.3](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444856356) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.3/tests/test/index.html) |; | integration | 11 | [3300297321.12](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444638712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.12/tests/test/index.html) |; | unit | 8 | [3300297321.1](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444856205) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.1/tests/test/index.html) |; | variantcalling | 8 | [3300297321.2](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444856277) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.2/tests/test/index.html) |; | integration | 8 | [3300297321.0](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444856114) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1287425480:1192,integrat,integration,1192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1287425480,2,['integrat'],['integration']
Integrability,s in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3300316784.10](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679663) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.10/tests/test/index.html) |; | cloud | 11 | [3300316784.11](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679780) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.11/tests/test/index.html) |; | unit | 11 | [3300316784.13](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679952) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.13/tests/test/index.html) |; | integration | 11 | [3300316784.12](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679868) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.12/tests/test/index.html) |; | conda | 8 | [3300316784.3](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444871971) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.3/tests/test/index.html) |; | unit | 8 | [3300316784.1](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444871800) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.1/tests/test/index.html) |; | variantcalling | 8 | [3300316784.2](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444871887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.2/tests/test/index.html) |; | integration | 8 | [3300316784.0](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444871682) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1287429116:1911,integrat,integration,1911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1287429116,1,['integrat'],['integration']
Integrability,"s where results changed:. - For the snpeff test, since the behavior on this branch seems more correct to me than master, I tried running the GATK4 test case inputs with GATK3, and it produces exactly the same results as this branch does. So I think that issue was introduced by the original GATK4 port, and is fixed in this branch.; - The rest of the tests with changed results don't seem to hit your breakpoint, though. So I think we need to figure out why they changed, and maybe also compare them with GATK3 (which can be a pain because the output format is slightly different).; - As you mentioned, you changed the reference for testEvalTrackWithoutGenotypesWithSampleFields, which seems to have only affected the number of loci processed. So I'm unclear why that change was necessary. If the test truly should have been failing without this change, will it still fail if the change is reverted ? If not, can we fix it, and either way there should be a negative test for that case. A few other general comments:. - I changed this PR to `draft` mode for now, which just better categorizes it for our internal workflow purposes. When its ready for a detailed code review we can remove the `draft` status.; - The `HashMap<FeatureInput<VariantContext>, HashMap<String, Collection<VariantContext>>>` can be wrapped in a class with just a couple of methods, so we don't have to manifest that long type all over the place.; - I know this PR still in an interim state, but passing the VariantWalker in as an argument to the comp methods doesn't seem like a step forward to me. If we can't solve that problem completely in this PR (which is fine, I'm all for trying to contain this), are those changes necessary ? Perhaps that part should just wait for the next round.; - Any new classes/methods should use `final` for variables and parameters wherever applicable, and public classes and methods should have javadoc.; - Finally, I'm curious if you've tried any perf testing on this branch ? Is it better ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744689987:1380,wrap,wrapped,1380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744689987,1,['wrap'],['wrapped']
Integrability,"s.java:278); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:83); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289). Nov 24, 2018 6:05:09 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.NoRouteToHostException: No route to host (Host unreachable); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.ww",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417:3773,rout,route,3773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417,2,['rout'],['route']
Integrability,s/498538890) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.4/tests/test/index.html) |; | unit | openjdk8 | [33752.3](https://travis-ci.com/broadinstitute/gatk/jobs/498538889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.3/tests/test/index.html) |; | conda | openjdk8 | [33752.5](https://travis-ci.com/broadinstitute/gatk/jobs/498538891) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.5/tests/test/index.html) |; | integration | openjdk8 | [33752.2](https://travis-ci.com/broadinstitute/gatk/jobs/498538888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.2/tests/test/index.html) |; | cloud | openjdk11 | [33752.14](https://travis-ci.com/broadinstitute/gatk/jobs/498538900) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.14/tests/test/index.html) |; | cloud | openjdk8 | [33752.1](https://travis-ci.com/broadinstitute/gatk/jobs/498538887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.1/tests/test/index.html) |; | unit | openjdk11 | [33752.13](https://travis-ci.com/broadinstitute/gatk/jobs/498538899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.13/tests/test/index.html) |; | integration | openjdk11 | [33752.12](https://travis-ci.com/broadinstitute/gatk/jobs/498538898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33752.4](https://travis-ci.com/broadinstitute/gatk/jobs/498538890) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.4/tests/test/index.html) |; | conda | openjdk8 | [33752.5](https://travis-ci.com/broadinstitute/gatk/jobs/498538891) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.5/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234:2506,integrat,integration,2506,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234,1,['integrat'],['integration']
Integrability,"serialization/spec/class.html#a4100):. _If not specified by the class, the value returned is a hash computed from the class's name, interfaces, methods, and fields using the Secure Hash Algorithm (SHA) as defined by the National Institute of Standards._. Now when I look at the `java.io.ObjectStreamClass.java` file for 64-bit JDK7 and JDK8 - from src.zip - both have the same code for the following parts after performing a `diff` - I didn't list all of the lines of code since they are quite long:. ```; public long getSerialVersionUID() {; // REMIND: synchronize instead of relying on volatile?; if (suid == null) {; suid = AccessController.doPrivileged(; new PrivilegedAction<Long>() {; public Long run() {; return computeDefaultSUID(cl);; }; }; );; }; return suid.longValue();; }; ... private static long computeDefaultSUID(Class<?> cl) {; ...very long code which can be inspected via the src.zip file...; }; ```. So looking at the code portions of `computeDefaultSUID()` and I notice in our instance `ReadFilter` is a interface, which gets defined later via [ReadFilterLibrary.java](https://github.com/broadinstitute/hellbender/blob/62ef76ba60951c562a0d4c39189aa3f01f27f8d3/src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilterLibrary.java) or via `new ReadsFilter(readFilter, header)`, in either of these instances the fields would be different, based on this portion of `computeDefaultSUID` when looking at declared fields:. ```; Field[] fields = cl.getDeclaredFields();; MemberSignature[] fieldSigs = new MemberSignature[fields.length];; for (int i = 0; i < fields.length; i++) {; fieldSigs[i] = new MemberSignature(fields[i]);; }; ```. Therefore the `SUID` would be different based on the fields it would have. Please let me know if I misinterpreted something. @jean-philippe-martin I would be happy to help out, but even when I try a small test like this I get an error - I probably am performing something incorrectly. Below are the steps I performed using the codebase fro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499:1333,interface,interface,1333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499,1,['interface'],['interface']
Integrability,"similar same error message with ; `gatk HaplotypeCallerSpark -R ref.fa -I input.GatherBamFiles.bam -O output.g2.vcf.gz`. OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); gatk 4.1.8.1 . ```; 07:16:06.169 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 07:16:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.5 MB, free 57.3 GB); 20/08/15 07:16:06 INFO SparkUI: Stopped Spark web UI at http://e1c-050:4041; 20/08/15 07:16:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 07:16:06 INFO MemoryStore: MemoryStore cleared; 20/08/15 07:16:06 INFO BlockManager: BlockManager stopped; 20/08/15 07:16:06 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 07:16:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 07:16:06 INFO SparkContext: Successfully stopped SparkContext; 07:16:06.412 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 7:16:06 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=102900432896; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:67); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617:19,message,message,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617,2,['message'],['message']
Integrability,sjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:208); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hadoop_bam.BAMRecordReader.nextKeyValue(BAMRecordReader.java:225); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182); 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:7151,Wrap,Wrappers,7151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Wrap'],['Wrappers']
Integrability,"sorry, this is duplicate of #5336 ; I posted twice due to confusion related to [recent github issues](https://status.github.com/messages)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5337#issuecomment-431858746:128,message,messages,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5337#issuecomment-431858746,1,['message'],['messages']
Integrability,ssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:91); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:246); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:493); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1326(HaplotypeCallerSpark.java:223); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:213); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149:2598,Wrap,WrappingSpliterator,2598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149,1,['Wrap'],['WrappingSpliterator']
Integrability,ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protoco,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1443,Wrap,WrapperExecutor,1443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['Wrap'],['WrapperExecutor']
Integrability,"ssorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42166,Wrap,Wrappers,42166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['Wrap'],['Wrappers']
Integrability,stitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:907); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:861); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:5266,wrap,wrapAndCopyInto,5266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,1,['wrap'],['wrapAndCopyInto']
Integrability,stitute.hellbender.tools.walkers.GenotypeGVCFsEngine.regenotypeVC(GenotypeGVCFsEngine.java:185); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:135); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:283); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:490); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1159695894:6408,wrap,wrapAndCopyInto,6408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1159695894,1,['wrap'],['wrapAndCopyInto']
Integrability,stractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	- locked <0x0000000584a63348> (a java.net.SocksSocketImpl); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.go,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1285,protocol,protocol,1285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,t java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.ru,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085:4801,wrap,wrapAndCopyInto,4801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085,1,['wrap'],['wrapAndCopyInto']
Integrability,"t org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47); at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:140); ... 34 more; Caused by: org.gradle.process.internal.ExecException: A problem occurred starting process 'command 'javadoc''; at org.gradle.process.internal.DefaultExecHandle.execExceptionFor(DefaultExecHandle.java:237); at org.gradle.process.internal.DefaultExecHandle.setEndStateInfo(DefaultExecHandle.java:214); at org.gradle.process.internal.DefaultExecHandle.failed(DefaultExecHandle.java:364); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:87); at org.gradle.internal.operations.CurrentBuildOperationPreservingRunnable.run(CurrentBuildOperationPreservingRunnable.java:42); ... 3 more; Caused by: net.rubygrapefruit.platform.NativeException: Could not start 'javadoc'; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:27); at net.rubygrapefruit.platform.internal.WrapperProcessLauncher.start(WrapperProcessLauncher.java:36); at org.gradle.process.internal.ExecHandleRunner.startProcess(ExecHandleRunner.java:98); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:71); ... 4 more; Caused by: java.io.IOException: Cannot run program ""javadoc"" (in directory ""/home/cb2/gatk""): error=2, No such file or directory; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:25); ... 7 more; Caused by: java.io.IOException: error=2, No such file or directory; ... 8 more. * Get more help at https://help.gradle.org. BUILD FAILED in 1s; 5 actionable tasks: 1 executed, 4 up-to-date; `; ```; I'm open to it being a lot of things. For context, I'm just setting up GATK on a new Linux virtual machine, so some dependencies may not exist.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:13242,Wrap,WrapperProcessLauncher,13242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716,3,"['Wrap', 'depend']","['WrapperProcessLauncher', 'dependencies']"
Integrability,tFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:333); 	... 24 more; Caused by: java.net.UnknownHostException: metadata; 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:104); 	... 34 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-411503423:8104,protocol,protocol,8104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-411503423,4,['protocol'],['protocol']
Integrability,"tFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 18/04/24 17:40:52 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 01:33 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:40:52 INFO TaskSetManager: Starting task 0.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 4, partition 0, PROCESS_LOCAL, 6010 bytes); 01:33 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:40:52 INFO TaskSetManager: Starting task 1.1 in stage 2.0 (TID 6, xx.xx.xx.24, executor 1, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:41:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:49115 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:41:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.24:49115 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:41:31 WARN TaskSetManager: Lost task 0.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 4): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilt",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:27045,Wrap,WrappedArray,27045,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,"tPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-890235307]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:179); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 50 more; ```. I'll rerun without using NIO for the dbsnp vcf and I'll try to look through the other 7 error messages to see if anything is different from those above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:15796,message,messages,15796,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963,1,['message'],['messages']
Integrability,"tarted to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1511,wrap,wrapper,1511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['wrap'],['wrapper']
Integrability,"tash@broadinstitute.org>; Date: Thu Dec 7 02:50:19 2017 -0500. update WDL scripts. commit 12bcfa192ee6fa6da21239ebf5b513633efe974f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:47:33 2017 -0500. significant updates to GermlineCNVCaller; integration tests for GermlineCNVCaller w/ sim data in both run modes. commit 151416a4af735ca721bd75e4b54a780c17ac9397; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 01:42:05 2017 -0500. hybrid ADVI abstract argument collection w/ flexible default values; hybrid ADVI argument collection for contig ploidy model; hybrid ADVI argument collection for germline denoising and calling model. commit 56e21bf955d3dc0c52aceb384f28cf6173959de0; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 23:18:39 2017 -0500. rewritten python-side coverage metadata table reader using pandas to fix the issues with comment line; change criterion for cohort/case based on whether a contig-ploidy model is provided or not; simulated test files for ploidy determination tool; proper integration test for ploidy determination tool and all edge cases; updated docs for ploidy determination tool. commit 7fa104b2e9170770cfc5b338835e41215d7fd39c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 18:43:17 2017 -0500. kabab case for gCNV-related tools; removed short args (this also partially affected PlotDenoisedCopyRatios and PlotModeledSegments and their integration tests). commit f02cb024331a986213cfd9fae2da706bbc5ddbd9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 18:02:40 2017 -0500. synced with mb_gcnv_python_kernel. commit 2963bbf8c90418d9b88545c93771ae51cf542db9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 11:38:05 2017 -0500. Fixing typo in travis.yml. commit 6cf589999c716ec66404eb0a2ae4310dd130a772; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 11:13:58 2017 -0500. editable, full path. commit d998f2d5c2b33dd41e291b",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:7729,integrat,integration,7729,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['integrat'],['integration']
Integrability,"te(ResolveCachingStateStep.java:90); at org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:48); at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:69); at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47); at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:140); ... 34 more; Caused by: org.gradle.process.internal.ExecException: A problem occurred starting process 'command 'javadoc''; at org.gradle.process.internal.DefaultExecHandle.execExceptionFor(DefaultExecHandle.java:237); at org.gradle.process.internal.DefaultExecHandle.setEndStateInfo(DefaultExecHandle.java:214); at org.gradle.process.internal.DefaultExecHandle.failed(DefaultExecHandle.java:364); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:87); at org.gradle.internal.operations.CurrentBuildOperationPreservingRunnable.run(CurrentBuildOperationPreservingRunnable.java:42); ... 3 more; Caused by: net.rubygrapefruit.platform.NativeException: Could not start 'javadoc'; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:27); at net.rubygrapefruit.platform.internal.WrapperProcessLauncher.start(WrapperProcessLauncher.java:36); at org.gradle.process.internal.ExecHandleRunner.startProcess(ExecHandleRunner.java:98); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:71); ... 4 more; Caused by: java.io.IOException: Cannot run program ""javadoc"" (in directory ""/usr/bin/gatk""): error=2, No such file or directory; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:25); ... 7 more; Caused by: java.io.IOException: error=2, No such file or directory; ... 8 more",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-590387973:12115,Wrap,WrapperProcessLauncher,12115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-590387973,2,['Wrap'],['WrapperProcessLauncher']
Integrability,terGencodeFuncotationsByTranscript(GencodeFuncotationFactory.java:281); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:338); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:138); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:113); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.lambda$enqueueAndHandleVariant$0(Funcotator.java:502); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:504); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:399); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:109); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(Abst,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886:1189,wrap,wrapAndCopyInto,1189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886,1,['wrap'],['wrapAndCopyInto']
Integrability,"terMutectCalls - Starting first pass through the variants; 22:58:28.484 INFO FilterMutectCalls - Shutting down engine; [January 6, 2019 10:58:28 PM SGT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2141192192; java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; 	at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$10(Mutect2FilteringEngine.java:207); 	at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); 	at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); 	at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085:3610,wrap,wrapAndCopyInto,3610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085,1,['wrap'],['wrapAndCopyInto']
Integrability,terator.hasNext(AbstractIterator.java:138); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.TransformedIterator.hasNext(TransformedIterator.java:43); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.fillCache(PushToPullIterator.java:71); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.advanceToNextElement(PushToPullIterator.java:58); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.<init>(PushToPullIterator.java:37); 	at org.broadinstitute.hellbender.utils.variant.writers.GVCFBlockCombiningIterator.<ini,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994:1849,Wrap,WrappingSpliterator,1849,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994,1,['Wrap'],['WrappingSpliterator']
Integrability,teringEngine.getIntArrayTumorField(Mutect2FilteringEngine.java:235); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyMedianFragmentLengthDifferenceFilter(Mutect2FilteringEngine.java:106); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:228); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.apply(FilterMutectCalls.java:113); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:5301,wrap,wrapAndCopyInto,5301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787,1,['wrap'],['wrapAndCopyInto']
Integrability,th.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.NoRouteToHostException: No route to host (Host unreachable); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsPr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417:1349,protocol,protocol,1349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417,3,['protocol'],['protocol']
Integrability,"this for a first workflow to target?. 1) Run ExtractVariantAnnotations on a training set of chromosomes. You can keep training/truth labels as in Best Practices, for now.; 2) Run TrainVariantAnnotationsModel on that. We'll use the truth scores generated here for any sensitivity conversions---i.e., we'll be calibrating scores only to the truth sites that are contained in the training set of chromosomes.; 3) Use the trained model to run a single shard of ScoreVariantAnnotations on a validation set of chromosomes.; 4) Run some variation of the above script on the resulting outputs to determine SNP and INDEL score thresholds for optimizing the corresponding LL scores. We can also add some code to the script to use the truth scores from step 2 to convert these score thresholds into truth-sensitivity thresholds.; 5) Provide these truth-sensitivity thresholds to ScoreVariantAnnotations and use them to hard filter. Evaluate on a test set of chromosomes. If all looks good, we can later move steps 3-4 into the train tool and automate the passing of sensitivities in 5 via outputs in the model directory. This will let us keep the basic interface of ScoreVariantAnnotations the same, but we'll have to add a few basic parameters to TrainVariantAnnotationsModel to control the train/validation split. So I think all this branch is missing is step 5---we'll simply need to add command-line parameters for the SNP/INDEL sensitivity thresholds and then do the hard filtering in the VCF writing method highlighted above. Do you think you can handle implementing that in this branch, and then the rest at the WDL level? I can help with the python script for the LL stuff (or anything else), if needed. Not sure if you got a chance to check out what your collaborators are doing in the methods you're looking to compare against, but it would be good to understand if this basic scheme for train/validation/test splitting can be replicated over there. You'll want to compare apples to apples, after all!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068345084:1221,interface,interface,1221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068345084,2,['interface'],['interface']
Integrability,"this should fix #3724, I've tested it locally by building a maven project with the following pom; ```; <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""; xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"">; <modelVersion>4.0.0</modelVersion>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk-downstream-test</artifactId>; <packaging>jar</packaging>; <version>1.0-SNAPSHOT</version>; <name>gatk-downstream-test</name>; <url>http://maven.apache.org</url>; <repositories>; <repository>; <snapshots />; <id>snapshots</id>; <name>libs-snapshot</name>; <url>https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot</url>; </repository>; </repositories>; <dependencies>; <dependency>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk</artifactId>; <version>4.beta.6-15-g62e339f-SNAPSHOT</version>; </dependency>; <dependency>; <groupId>junit</groupId>; <artifactId>junit</artifactId>; <version>3.8.1</version>; <scope>test</scope>; </dependency>; </dependencies>; </project>; ```. This didn't build correctly with the current gatk, but builds with this patch, (note that the snapshot version will be different if you download and build this yourself). @Vzzarr Is it possible for you to build this locally and test it with your project?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3742#issuecomment-339059340:760,depend,dependencies,760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3742#issuecomment-339059340,6,['depend'],"['dependencies', 'dependency']"
Integrability,"tionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.Conc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:7027,Message,MessageHubBackedObjectConnection,7027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,titute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.WellformedReadFilter.test(WellformedReadFilter.java:77); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.lambda$getReads$e4b35a40$1(GATKSparkTool.java:213); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool$$Lambda$93/2063469002.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:2100,Wrap,Wrappers,2100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Wrap'],['Wrappers']
Integrability,titute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:137); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:113); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:496); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:387); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:918); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391421032:6741,wrap,wrapAndCopyInto,6741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391421032,1,['wrap'],['wrapAndCopyInto']
Integrability,to(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:504); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:399); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:109); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:107); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:994); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886:2186,wrap,wrapAndCopyInto,2186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886,1,['wrap'],['wrapAndCopyInto']
Integrability,"too long (225) at position chr1:10178; skipping that record. Set --reference_window_stop >= 225 ; INFO 10:49:23,200 LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --reference_window_stop >= 221 ; INFO 10:49:23,201 LeftAlignAndTrimVariants - Reference allele is too long (223) at position chr1:10218; skipping that record. Set --reference_window_stop >= 223 ; INFO 10:49:23,203 LeftAlignAndTrimVariants - Reference allele is too long (212) at position chr1:10229; skipping that record. Set --reference_window_stop >= 212 ; INFO 10:49:23,203 LeftAlignAndTrimVariants - Reference allele is too long (216) at position chr1:10231; skipping that record. Set --reference_window_stop >= 216 ; INFO 10:49:23,205 LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10237; skipping that record. Set --reference_window_stop >= 204 ; INFO 10:49:23,205 LeftAlignAndTrimVariants - Reference allele is too long (209) at position chr1:10238; skipping that record. Set --reference_window_stop >= 209 ; INFO 10:49:23,208 LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10254; skipping that record. Set --reference_window_stop >= 204 ; INFO 10:49:23,214 LeftAlignAndTrimVariants - Reference allele is too long (207) at position chr1:10276; skipping that record. Set --reference_window_stop >= 207 ; 0 variants were aligned; INFO 10:49:23,402 ProgressMeter - done 638.0 0.0 s 10.6 m 0.0% 0.0 s 0.0 s ; INFO 10:49:23,402 ProgressMeter - Total runtime 0.41 secs, 0.01 min, 0.00 hours ; ------------------------------------------------------------------------------------------; Done. There were 1 WARN messages, the first 1 are repeated below.; WARN 10:49:22,065 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091:4464,message,messages,4464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091,1,['message'],['messages']
Integrability,tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotations(GencodeFuncotationFactory.java:487); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotations(GencodeFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:387); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:316); at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157:9110,wrap,wrapAndCopyInto,9110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157,1,['wrap'],['wrapAndCopyInto']
Integrability,"true; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Deflater: IntelDeflater; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Inflater: IntelInflater; 13:15:05.204 INFO FuncotatorDataSourceDownloader - GCS max retries/reopens: 20; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Requester pays: disabled; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Initializing engine; 13:15:05.205 INFO FuncotatorDataSourceDownloader - Done initializing engine; 13:15:05.205 INFO FuncotatorDataSourceDownloader - Germline data sources selected.; 13:15:05.207 INFO FuncotatorDataSourceDownloader - Collecting expected checksum...; 13:19:33.264 INFO FuncotatorDataSourceDownloader - Shutting down engine; [November 18, 2023 1:19:33 PM CST] org.broadinstitute.hellbender.tools.funcotator.FuncotatorDataSourceDownloader done. Elapsed time: 4.48 minutes.; Runtime.totalMemory()=1967128576; code: 0; message: All 3 retries failed. Waited a total of 14000 ms between attempts; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: All 3 retries failed. Waited a total of 14000 ms between attempts; 	at com.google.cloud.storage.contrib.nio.CloudStorageRetryHandler.handleRetryForStorageException(CloudStorageRetryHandler.java:135); 	at com.google.cloud.storage.contrib.nio.CloudStorageRetryHandler.handleStorageException(CloudStorageRetryHandler.java:115); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:253); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:110); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:90); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:390); 	at com.google.cloud.storage.contrib.nio.CloudStorageF",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:2877,message,message,2877,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['message'],['message']
Integrability,"tually tried it, before putting in the above comment, and quickly ran into the problem of mixing Java serialization and Kryo serialization, so a larger re-structuring might be needed, and not just a inheritance structure). ------------; ### On the problem of having a confusing TODO for ; `boolean SimpleChimera.isCandidateInvertedDuplication()`. The todo message. > TODO: 5/5/18 Note that the use of the following predicate is currently obsoleted by; {@link AssemblyContigWithFineTunedAlignments#hasIncompletePictureFromTwoAlignments()}; because the contigs with this alignment signature is classified as ""incomplete"",; hence will NOT sent here for constructing SimpleChimera's.; But we may want to keep the code (and related code in BreakpointComplications) for future use. Comment by @cwhelan ; > I'm a bit confused by this comment: this method is still being called in several places, so how is it obsolete?. Reply by @SHUANG-Broad (also copied to update the ""TODO"" message; > this predicate is currently used in two places (excluding appearance in comments): `BreakpointComplications.IntraChrStrandSwitchBreakpointComplications`, where it is use to test if the input simple chimera indicates an inverse tandem duplication and trigger the logic for inferring duplicated region; and `BreakpointsInference.IntraChrStrandSwitchBreakpointInference`, where it is used for breakpoint inference. The problem is, the contig will not even be sent here, because `AssemblyContigWithFineTunedAlignments.hasIncompletePictureFromTwoAlignments()` defines a simple chimera that has strand switch and the two alignments overlaps on reference as ""incomplete"", so in practice the two uses are not going to be triggered. But when we come back later and see what can be extracted from such ""incomplete"" contigs, these code could be useful again. So it is kept. ------------; ### On the problem of writing out SAM records of ""Unknown"" contigs efficiently. First round comment by @cwhelan ; > This seems like a very inef",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:2748,message,message,2748,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,2,['message'],['message']
Integrability,tute.hellbender.Main.main(Main.java:233); ```; and ; ```; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCrede,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:4327,protocol,protocol,4327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,1,['protocol'],['protocol']
Integrability,tute.hellbender.engine.FeatureDataSource.getCodecForFea; tureInput(FeatureDataSource.java:324); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:304); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855:2937,wrap,wrapAndCopyInto,2937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855,1,['wrap'],['wrapAndCopyInto']
Integrability,tute.hellbender.tools.walkers.vqsr.CNNScoreVariants.sendBatchIfReady(CNNScoreVariants.java:416); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.firstPassApply(CNNScoreVariants.java:336); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147:2227,wrap,wrapAndCopyInto,2227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147,1,['wrap'],['wrapAndCopyInto']
Integrability,tute/gatk/actions/runs/5906500357); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5906500357.10](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16022649132) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.10/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906500357.12](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16022649351) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906500357.11](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16022649238) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.11/tests/testOnPackagedReleaseJar/index.html) |; | conda | 17.0.6+10 | [5906500357.3](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343655) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.3/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906500357.1](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343343) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.1/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [5906500357.2](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343497) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906500357.0](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343147) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684393146:1840,integrat,integration,1840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684393146,1,['integrat'],['integration']
Integrability,tute/gatk/actions/runs/5906807871); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5906807871.10](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16023558278) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.10/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906807871.12](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16023558558) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906807871.11](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16023558444) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906807871.1](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024178952) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.1/tests/testOnPackagedReleaseJar/index.html) |; | conda | 17.0.6+10 | [5906807871.3](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024179175) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.3/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [5906807871.2](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024179060) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906807871.0](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024178803) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684420305:1840,integrat,integration,1840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684420305,1,['integrat'],['integration']
Integrability,twork is unreachable: connect; 	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method); 	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); 	at com.google.auth.oauth2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:13786,protocol,protocol,13786,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,3,['protocol'],['protocol']
Integrability,uVGVzdC5qYXZh) | `90.909% <0%> (-0.758%)` | `5% <0%> (ø)` | |; | [...ellbender/tools/walkers/vqsr/CNNScoreVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50cy5qYXZh) | `79.736% <0%> (-0.709%)` | `45% <0%> (ø)` | |; | [...ls/walkers/varianteval/util/EvaluationContext.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnRldmFsL3V0aWwvRXZhbHVhdGlvbkNvbnRleHQuamF2YQ==) | `75.676% <0%> (-0.64%)` | `12% <0%> (ø)` | |; | [...te/hellbender/utils/runtime/ProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `56.338% <0%> (-0.606%)` | `8% <0%> (ø)` | |; | [...der/utils/solver/SynchronizedUnivariateSolver.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvU3luY2hyb25pemVkVW5pdmFyaWF0ZVNvbHZlci5qYXZh) | `81.609% <0%> (-0.413%)` | `11% <0%> (ø)` | |; | [...ools/walkers/haplotypecaller/graphs/TestGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvVGVzdEdyYXBoLmphdmE=) | `89.286% <0%> (-0.369%)` | `6% <0%> (ø)` | |; | [...spark/sv/utils/SingleSequenceReferenceAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TaW5nbGVTZXF1ZW5jZVJlZmVyZW5jZUFsaWduZXIuamF2YQ==) | `80.556% <0%> (-0.266%)` | `16% <0%> (ø)` | |; | [...gine/spark/datasources/ReadsSparkSinkUnitTest.java](https://codecov.io/gh/broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-506021220:2740,Synchroniz,SynchronizedUnivariateSolver,2740,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-506021220,1,['Synchroniz'],['SynchronizedUnivariateSolver']
Integrability,"uent; at least 10 samples must have called genotypes; 13:41:00.528 INFO ProgressMeter - unmapped 0.0 37 4277.5; 13:41:00.528 INFO ProgressMeter - Traversal complete. Processed 37 total variants in 0.0 minutes.; 13:41:00.580 INFO GenotypeGVCFs - Shutting down engine; [October 26, 2023 at 1:41:00 PM CEST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=285212672; ```; ```; ##source=HaplotypeCaller; ##bcftools_viewVersion=1.16+htslib-1.16; ##bcftools_viewCommand=view -c1 output.vcf; Date=Thu Oct 26 13:41:08 2023; ##bcftools_annotateVersion=1.16+htslib-1.16; ##bcftools_annotateCommand=annotate -x INFO,FORMAT/SB,FORMAT/PL; Date=Thu Oct 26 13:41:08 2023; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT CGAAGAGGTAGGTGCGAG-1; chr19 55910646 . AC A 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9:15:99:0|1:55910646_AC_A:55910646; chr19 55910648 . AAATCCCCC A 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9:15:99:0|1:55910646_AC_A:55910646; chr19 55910653 . CCCCAT *,C 227.84 . . GT:AD:DP:GQ:PGT:PID:PS 1|2:0,9,6:15:99:1|0:55910646_AC_A:55910646; chr19 55910675 . T C 30.64 . . GT:AD:DP:GQ 0/1:13,2:15:38; ```. The relevant parts of the output. HaplotypeCaller:; ```; chr19 55910648 AAATCCCCC A,<NON_REF> GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9,0 :15:99:0|1:55910646_AC_A:55910646; chr19 55910653 CCCCAT *,C,<NON_REF> GT:AD:DP:GQ:PGT:PID:PS 2|1:0,9,6,0:15:99:1|0:55910646_AC_A:55910646; ```; GenotypeGVCFs:; ```; chr19 55910648 AAATCCCCC A GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9 :15:99:0|1:55910646_AC_A:55910646; chr19 55910653 CCCCAT *,C GT:AD:DP:GQ:PGT:PID:PS 1|2:0,9,6 :15:99:1|0:55910646_AC_A:55910646; ```. I understand that; - PID/PGT can only encode phasing for biallelic variants, ; - so PID/PGT + unphased GT can not be used to infer the correctly phased GT in general; - but only (and only maybe) in this case PID/PGT + wrongly phased GT can be used to infer the correctly phased GT (because the mangeling of the GT might depend on PGT). is this correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195:21567,depend,depend,21567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195,1,['depend'],['depend']
Integrability,"ur input file. If I am wrong and this is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByOrientationBias`` (with the possible exception of the bgzip VCF). These issues are all in its dependencies, which a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:2170,wrap,wrapped,2170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143,1,['wrap'],['wrapped']
Integrability,"ureInput;. public CodecWrapper(FeatureCodec<FEATURE_TYPE, SOURCE> childCodec, FeatureInput<FEATURE_TYPE> featureInput); {; this.childCodec = childCodec;; this.featureInput = featureInput;; }. @Override; public Feature decodeLoc(SOURCE source) throws IOException {; return childCodec.decodeLoc(source);; }. @Override; public FEATURE_TYPE decode(SOURCE source) throws IOException {; FEATURE_TYPE feature = childCodec.decode(source);. //Either look for marker class or otherwise poke in FeatureInput here:; if (feature instanceof VariantContext); {; feature = new FeatureInputAwareVariantContext(feature, featureInput);; }. return feature;; }. @Override; public FeatureCodecHeader readHeader(SOURCE source) throws IOException {; return childCodec.readHeader(source);; }. @Override; public Class<FEATURE_TYPE> getFeatureType() {; return childCodec.getFeatureType();; }. @Override; public SOURCE makeSourceFromStream(InputStream bufferedInputStream) {; return childCodec.makeSourceFromStream(bufferedInputStream);; }. @Override; public LocationAware makeIndexableSourceFromStream(InputStream inputStream) {; return childCodec.makeIndexableSourceFromStream(inputStream);; }. @Override; public boolean isDone(SOURCE source) {; return childCodec.isDone(source);; }. @Override; public void close(SOURCE source) {; childCodec.close(source);; }. @Override; public boolean canDecode(String path) {; return childCodec.canDecode(path);; }; }. public static interface FeatureInputAware<FEATURE_TYPE extends Feature>; {; public FeatureInput<FEATURE_TYPE> getFeatureInput();; }. public static class FeatureInputAwareVariantContext extends VariantContext implements FeatureInputAware<VariantContext>; {; private FeatureInput<VariantContext> featureInput;. public FeatureInputAwareVariantContext(VariantContext parent, FeatureInput<VariantContext> featureInput); {; super(parent);; this.featureInput = featureInput;; }. @Override; public FeatureInput<VariantContext> getFeatureInput() {; return featureInput;; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823546766:2178,interface,interface,2178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823546766,1,['interface'],['interface']
Integrability,"utput from chr1. The output shows the Maximum resident set size (kbytes): **2630440**. Using GATK jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar defined in environment variable GATK_LOCAL_JAR; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx200g -Xms16g -jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reader-threads 4 --overwrite-existing-genomicsdb-workspace; Command being timed: ""gatk --java-options -Xmx200g -Xms16g GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reader-threads 4 --overwrite-existing-genomicsdb-workspace""; User time (seconds): 270716.45; System time (seconds): 1723.34; Percent of CPU this job got: 99%; Elapsed (wall clock) time (h:mm:ss or m:ss): 76:08:24; Average shared text size (kbytes): 0; Average unshared data size (kbytes): 0; Average stack size (kbytes): 0; Average total size (kbytes): 0; Maximum resident set size (kbytes): 2630440; Average resident set size (kbytes): 0; Major (requiring I/O) page faults: 5; Minor (reclaiming a frame) page faults: 206030721; Voluntary context switches: 11129822; Involuntary context switches: 176522; Swaps: 0; File system inputs: 627981312; File system outputs: 466730160; Socket messages sent: 0; Socket messages received: 0; Signals delivered: 0; Page size (bytes): 4096; Exit status: 0. ```. So using the import on reblocked gvcfs using --bypass-feature-reader was the fastest way to import our 3500 gVCFs and minimize memory.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687:3022,message,messages,3022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687,4,['message'],['messages']
Integrability,"utputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37305,Wrap,Wrappers,37305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"utputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:37057,Wrap,Wrappers,37057,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,va heap space; 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:208); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hadoop_bam.BAMRecordReader.nextKeyValue(BAMRecordReader.java:225); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182); 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:7118,Wrap,Wrappers,7118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Wrap'],['Wrappers']
Integrability,va.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1467,Wrap,WrapperExecutor,1467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['Wrap'],['WrapperExecutor']
Integrability,va:260); at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:286); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:519); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLin,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901:2485,wrap,wrapAndCopyInto,2485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901,1,['wrap'],['wrapAndCopyInto']
Integrability,"very little GATK experience. The problem is that you've got AMD libraries on a PowerPC machine. I don't; know if GATK makes PowerPC libraries available natively, but you should be; able to get the source code and compile it yourself. Note that this will not fix the problem of your machine architecture; lacking the AVX instruction set. That's a hardware issue. But it should; (okay, *might*) get rid of the warnings about missing .so files. As an aside, I'm curious whether PowerPC architecture has an instruction; set similar to AVX. This is something I might actually be able to; contribute to the project so I'm excited by the prospect!. -Dan. On Fri, Sep 4, 2020, 11:53 AM R-obert <notifications@github.com> wrote:. > Hello,; >; > I'm trying to use GATK4 (4.1.8.1) on an Ubuntu (16.04) machine. The; > machine is a ""PowerLinux"" machine and I'm guessing that the most relevant; > info for the following problem is that it is a ppc64le system. When I use; > HaplotypeCaller, I see the following messages on the screen:; >; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100; >; > 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600:1032,message,messages,1032,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600,1,['message'],['messages']
Integrability,"when trying to build GATK fully I get this error:; ```; > Task :gatkDoc FAILED; Execution optimizations have been disabled for task ':gatkDoc' to ensure correctness due to the following reasons:; - Gradle detected a problem with the following location: '/home/jeremie/GATK/build/classes/java/main'. Reason: Task ':gatkDoc' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/home/jeremie/GATK/build/resources/main'. Reason: Task ':gatkDoc' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/jeremie/GATK/build/tmp/gatkDoc/javadoc.options'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.gradle.org/7.3.2/userguide/command_line_interface.html#sec:command_line_warnings. Execution optimizations have been disabled for 1 invalid unit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1202544500:428,depend,dependency,428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1202544500,4,['depend'],"['dependency', 'depending']"
Integrability,xception: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:541); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:474); 	at shaded.cloud_nio.com.googl,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7468,protocol,protocol,7468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,"y COHORT/CASE modes, GermlineCNVCaller COHORT/CASE modes, and PostprocessGermlineCNVCalls. Numerical results are also relatively close to those from 4.4.0.0 for all identifiable call and model quantities (albeit far outside any reasonable exact-match thresholds, most likely due to differences in RNG, sampling, and the aforementioned priors). Some remaining TODOs:. - [x] Rebuild and push the base Docker. EDIT: Mostly covered by #8610, but this also includes an addition of `libblas-dev`.; - [x] Update expected results for integration tests, perhaps add any that might be missing. EDIT: These were generated on WSL Ubuntu 20.04.2, we'll see if things pass on 22.04. Note that changing the ARD priors does change the *names* of the expected files, since the transform is appended to the corresponding variable name. DetermineGermlineContigPloidy and PostprocessGermlineCNVCalls are missing exact-match tests and should probably have some, but I'll leave that to someone else.; - [x] Update other python integration tests.; - [x] Clean up some of the changes to the priors.; - [x] Clean up some TODO comments that I left to track code changes that might result in changed numerics. I'll try to go through and convert these to PR comments in an initial review pass.; - [x] Test over multiple shards on WGS and WES. Probably some scientific tests on ~100 samples in both cohort and case mode would do the trick. We should also double check runtime/memory performance (I noted ~1.5x speedups, but didn't measure carefully; I also want to make sure the changes to posterior sampling didn't introduce any memory issues). @mwalker174 will ping you when a Docker is ready! Might be good to loop in Isaac and/or Jack as well.; - [x] Perhaps add back the fix for 2-interval shards in https://github.com/broadinstitute/gatk/pull/8180, which I removed since the required functionality wasn't immediately available in Pytensor. Not sure if this actually broke things though---need to check. (However, I don't ac",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:2434,integrat,integration,2434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,1,['integrat'],['integration']
Integrability,yep! I should have that wrapped up soon. testing the updated WDL now,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-848993767:24,wrap,wrapped,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-848993767,1,['wrap'],['wrapped']
Integrability,yet another message to support reverting to good old ./. for missing genotypes and 0/0 for homozygous reference.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1935719294:12,message,message,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1935719294,1,['message'],['message']
Integrability,👍 to this with the understanding that we may be removing `IntegrationTestSpec` in the future.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-245958527:58,Integrat,IntegrationTestSpec,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-245958527,1,['Integrat'],['IntegrationTestSpec']
Modifiability, (ø)` | `0 <0> (?)` | |; | [...dinstitute/hellbender/engine/GATKToolUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2xVbml0VGVzdC5qYXZh) | `91.017% <100%> (+0.473%)` | `71 <0> (ø)` | :arrow_down: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `83.846% <100%> (+0.252%)` | `49 <2> (ø)` | :arrow_down: |; | [...GATKPlugin/GATKReadFilterPluginDescriptorTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yVGVzdC5qYXZh) | `88.62% <50%> (-1.76%)` | `48 <1> (+1)` | |; | [...Plugin/GATKAnnotationPluginDescriptorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yVW5pdFRlc3QuamF2YQ==) | `88.235% <63.158%> (-1.43%)` | `58 <1> (+1)` | |; | [...rg/broadinstitute/hellbender/utils/ClassUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9DbGFzc1V0aWxzLmphdmE=) | `86.842% <75%> (+1.128%)` | `21 <2> (+2)` | :arrow_up: |; | [...ine/GATKPlugin/GATKAnnotationPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `76.875% <83.333%> (+0.293%)` | `57 <3> (ø)` | :arrow_down: |; | [.../tools/walkers/haplotypecaller/RefVsAnyResult.java](https://codecov.io/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523:2809,Plugin,Plugin,2809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523,1,['Plugin'],['Plugin']
Modifiability," - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5880,Config,ConfigFactory,5880,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability," --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:48:31.693 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.693 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 13:48:31.693 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:48:31.694 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:48:31.694 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:48:31.694 INFO CountReadsSpark - Start Date/Time: December 21, 2018 1:48:31 PM EST; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.694 INFO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:1691,variab,variables,1691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,2,"['config', 'variab']","['configured', 'variables']"
Modifiability," 2018; >; > #gap.chrom gap.chromStart gap.chromEnd gap.type; >; > chr1 0 10000 telomere; >; > chr1 207666 257666 contig; >; > chr1 297968 347968 contig; >; > chr1 535988 585988 contig; >; > chr1 2702781 2746290 scaffold; >; >; For what it's worth, your description of your approach sounds like a; sensible one to me.; I am concerned about the size of the data and how we'd access it. I've; chosen the tracts I have because they are small enough to jam into; resources. On Tue, May 1, 2018 at 8:06 AM samuelklee <notifications@github.com> wrote:. > @TedBrookings <https://github.com/TedBrookings> which formats are you; > using, in particular?; >; > In the CNV package, I've taken pains to unify how tabular data are; > represented in Java, depending on whether each record is Locatable or; > whether the collection of records can be associated with a sample name or; > sequence dictionary. This allows us to represent records that extend; > Locatable with multidimensional numerical or non-numerical annotations; > along with some metadata (sample name and sequence dictionary) with a; > minimum of boilerplate. There are also base methods for producing interval; > trees, etc.; >; > However, this unification effort was a quick push I made before release,; > so some polishing or redesigning may be warranted. We may also want to add; > more forms of metadata, etc. if other teams would require more features.; > Another downside is that this code lacks the indexing, NIO support, etc.; > that some of the other standardized/Tribble formats enjoy. For CNV data,; > this isn't a huge issue, but I think it would be nice to unify how we; > represent such data GATK-wide. As I said above, I don't think VCF is the; > correct answer, but certainly it could fit into whatever framework we come; > up with.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468>,; > or",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551:1710,extend,extend,1710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551,1,['extend'],['extend']
Modifiability, <0> (?)` | |; | [...ils/optimization/PersistenceOptimizerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplclVuaXRUZXN0LmphdmE=) | `2% <0%> (ø)` | `1 <0> (?)` | |; | [...utils/downsampling/DownsamplingMethodUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRG93bnNhbXBsaW5nTWV0aG9kVW5pdFRlc3QuamF2YQ==) | `3.448% <0%> (ø)` | `1 <0> (?)` | |; | [...yper/StandardCallerArgumentCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvblVuaXRUZXN0LmphdmE=) | `4.098% <0%> (ø)` | `2 <0> (?)` | |; | [...lbender/utils/mcmc/ParameterizedStateUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlcml6ZWRTdGF0ZVVuaXRUZXN0LmphdmE=) | `14.286% <0%> (ø)` | `2 <0> (?)` | |; | [...itute/hellbender/engine/ProgressMeterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlclVuaXRUZXN0LmphdmE=) | `1.282% <0%> (ø)` | `1 <0> (?)` | |; | [...broadinstitute/hellbender/utils/UtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9VdGlsc1VuaXRUZXN0LmphdmE=) | `0.206% <0%> (ø)` | `1 <0> (?)` | |; | [...eVcfWithExpectedAlleleFractionIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750:2068,Parameteriz,ParameterizedStateUnitTest,2068,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750,1,['Parameteriz'],['ParameterizedStateUnitTest']
Modifiability," burden. The parties interested in working on a specific architecture will contribute code directly to the respective architecture-specific repo and gatk will take occasional updates of those repos. The gatk repo will depend on the other two. The PPC repo will depend on the AVX repo (and any other native repos will depend on the AVX one). The avx and ppc repos will have their own build systems and unit tests against the new interface. The AVX repo will expose something like the following Java API (to be worked out in detail). ```; //Used to copy references to byteArrays to JNI from reads; public final class JNIReadDataHolderClass {; public byte[] readBases = null;; public byte[] readQuals = null;; public byte[] insertionGOP = null;; public byte[] deletionGOP = null;; public byte[] overallGCP = null;; }. //Used to copy references to byteArrays to JNI from haplotypes; public final class JNIHaplotypeDataHolderClass {; public byte[] haplotypeBases = null;; }. public interface NativePairHMMKernel extends AutoCloseable { . /**; * Function to initialize the fields of JNIReadDataHolderClass and JNIHaplotypeDataHolderClass from JVM.; * C++ code gets FieldIDs for these classes once and re-uses these IDs for the remainder of the program. Field IDs do not; * change per JVM session; *; * @param readDataHolderClass class type of JNIReadDataHolderClass; * @param haplotypeDataHolderClass class type of JNIHaplotypeDataHolderClass; */; void jniInitializeClassFields(Class<JNIReadDataHolderClass> readDataHolderClass, Class<JNIHaplotypeDataHolderClass> haplotypeDataHolderClass);. /**; * Real compute kernel; */; void jniComputeLikelihoods(int numReads, int numHaplotypes, JNIReadDataHolderClass[] readDataArray,; JNIHaplotypeDataHolderClass[] haplotypeDataArray, double[] likelihoodArray, int maxNumThreadsToUse);. /**; * Print final profiling information from native code. ; */; default void close() { jniClose(); }. void jniClose();; }; ```. and a class that implements those as native methods",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864:1680,extend,extends,1680,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864,1,['extend'],['extends']
Modifiability," for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!?[0m. 16:58:10.116 INFO PrintVariantsSpark - Initializing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalB",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4692,config,configuration,4692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['config'],['configuration']
Modifiability," log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.L",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5397,variab,variable,5397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['variab'],['variable']
Modifiability," really know what's happening. We wouldn't expect gatk4 haplotype caller to be that much slower. . It looks like they're running beta2 which is kind of old as well. Can you ask them what exact version they're using?. Can you ask if they have the log (stdout + stderr) for the gatk4 non-spark run? I can't tell what pairhmm they're actually running with and the logs would help with that. . Can you also find out what sort of hardware they're running on? Specifically, is it an intel machine with support for AVX?. A good setting for` --nativePairHmmThreads` is probably 4-8, you won't see any improvement after that. I also noticed that they're setting -XX:+UseParallelGC -XX:ParallelGCThreads=32 for the gatk3. They would be better off setting it to 2-4 threads. Performance gets worse beyond that typically from what I've seen. They can set the same thing for gatk4 using`--javaOptions ' -XX:+UseParallelGC -XX:ParallelGCThreads=4'`. Their spark configuration looks wrong in a number of ways which is probably a big part of why they're not seeing any improvement. In general you want executors with ~4-8 cores and at least 4g of memory per core. I don't know how much memory their nodes have, and I don't know if they're running with autoscaling turned on, but I suspect they're only allocating 1 executor on 1 node and then it's thrashing memory because it's trying to run 32 threads at once. Spark tuning for haplotype caller is going to be complicated though and I don't know how to do it will yet, we will be revisiting it in the next quarter probably. They're also running withs spark 2.1.0, we currently require spark 2.0.2 which is an unfortunately specific version, we're planning on upgrading to spark 2.2.+ in the next quarter. . You should make it clear to them that the results will not be the same between 3, 4, and 4-spark yet and that 4 is in rapid state of flux and has known performance issues that we're planning on working soon. Even so though, that slowdown they're seeing is bi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-332879964:971,config,configuration,971,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-332879964,2,['config'],['configuration']
Modifiability," should definitely provide defaults for typical data types in *documentation*.) And in the end, I think it is beneficial for users that wish to tweak knobs to do some work to understand what those knobs actually do (even if just at a basic level). The other downside of option 2 is that it might not be immediately obvious from the command line what parameters are being used. For example, if a user chooses a set of defaults but then overrides some of them, we should make it so they don't have to go digging through the logs to see what parameters are actually used in the end. Nor should they have to go back and check what the defaults were for whatever version of the jar they were using at the time. Option 2 might also make it easier to inadvertently override parameters, etc. via command-line typos or copy-and-paste errors---it's much more straightforward to require and check that every parameter is specified once and fallback to a default if not, as we do now. Not to say that we couldn't get around any of these issues in Barclay, but I think it'll require some thought and careful design. Would be interested to hear Engine team's opinions. Finally, one point that I think will become more relevant as our tools and pipelines become more flexible and parameterized: I think we should start thinking of ""Best Practices Recommendations"" less as ""here is the best set of parameters to use with your data"" and more as ""here is *how to find* the best set of parameters to use with your data (for a given truth set, sensitivity requirement, etc.)"". After all, if we are putting together pipelines to do hyperparameter optimization, there is no reason not to share them with the community. This would also relax the requirement that the defaults in the WDL (which have to be kept in sync with those in the GATK jar) represent some sort of Best Practices Recommendation, which is awkward in exactly scenarios like the one you highlight. @vdauwera @LeeTL1220 @sooheelee might have some thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385584289:1603,flexible,flexible,1603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385584289,2,"['flexible', 'parameteriz']","['flexible', 'parameterized']"
Modifiability," tool, MosaicHunter. The option you suggest looks great. Do you mean that I should establish the GATK 4 developing environment and develop the MosaicHunterFilter tool? I may do that when I have some time. I found the document of GATK 4 at https://github.com/broadinstitute/gatk. Do you have any further advices?. Best regards,; Adam Yongxin Ye; Center for Bioinformatics; Peking University. At 2018-07-07 01:43:05, ""Geraldine Van der Auwera"" <notifications@github.com> wrote:. Hi @Yyx2626, I'm Geraldine, you may remember me from the Beijing training. It was great visiting your team! I'm sorry it took me so long to follow up on this discussion, and I want to thank you again for reaching out to us about integrating the tool that you developed into GATK. We are certainly very interested in providing this enhancement to the research community, and we are now ready to talk about the next steps. After examining your paper and the source code in Github, we think that the most efficient way to integrate the functionality you developed would be to adapt the filtering parts of your tool to run on the output of Mutect2. So this would be a standalone tool that you would run after Mutect2, much like the current FilterMutectCalls tool. If the results are comparable to your current tool, then we would take that into the official distribution of GATK. If somehow that integration does not yield satisfactory results, then we would look at integrating the entire tool, though we're hoping it won't be necessary, so we can avoid maintaining duplicate functionality for some of the boilerplate data transformations. David @davidbenjamin can provide some advice on how to implement this in GATK4; in brief you would need to write some code that applies the filters you developed to a variant context. Let us know if this is an option you'd like to explore; we'd be happy to help. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349:1275,adapt,adapt,1275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349,1,['adapt'],['adapt']
Modifiability," unnecessary copies of the data (now fixed: https://github.com/cloudera/spark-dataflow/pull/60), which caused OOM errors when trying to broadcast the 3GB reference data. With this fixed, I ran a [pipeline called JoinReferencesDataflow](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/tools/dataflow/pipelines/JoinReferencesDataflow.java) on a small cluster that broadcasts the reference as a dataflow view. The code is a modified version of CountReadsDataflow that simply sends the view, and then doesn't use it, so we can see the cost of doing a broadcast (See the rest of the code in this branch: https://github.com/tomwhite/hellbender/tree/hadoop-references). JoinReferencesDataflow took 2 min 25s to run, of which 18s were for reading the reference from the local filesystem in the driver. For comparison, CountReadsDataflow took 17s on the same cluster. So broadcasting the reference takes less than 2 minutes. Note that this was just for one task, but Spark has [an efficient protocol for sending broadcast variables](http://www.cs.berkeley.edu/~agearh/cs267.sp10/files/mosharaf-spark-bc-report-spring10.pdf), which scales well with the number of nodes, so the approach looks feasible. Having said all that, we might still want to use the sharding approach, in order to share more code between the Google and Spark dataflow implementations. One way this could work would be to generalize `RefAPISource` and `RefAPIMetadata` to support reading reference data from a [ReferenceHadoopSource](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/engine/dataflow/datasources/ReferenceHadoopSource.java), which is in line with @droazen's last comment. Am I right in thinking that the read pipeline work is being completed in https://github.com/broadinstitute/hellbender/tree/da_read_pipeline? Is that at a point where I could try with pipeline on Spark, or should I wait until it's merged?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353:1189,variab,variables,1189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353,1,['variab'],['variables']
Modifiability," values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:39:19 INFO SparkContext: Running Spark version 2.2.0; 18/04/24 17:39:19 WARN NativeCodeLoader: Unable to load native-hadoop lib",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:6071,Config,ConfigFactory,6071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability," we'd just want to let the user be able to specify the theano directory (rather than dump things in `~/.theano` unexpectedly). We should think about whether this should be opt-in, i.e., should we preserve the original behavior of using `~/.theano` by default?; > ; > @mwalker174 opinions? @droazen or engine team, thoughts on what the policy should be for python/R scripts doing this sort of thing? Is it generally true that the GATK leaves no trace, other than producing the expected output?. Dear samuelklee,. Thank you very much for you reply. I also found this problem last night. It seems that the problem is originally from Theano and Pymc3, rather than GATK 4.0. Some similar problems have been reported just like (1) https://github.com/pymc-devs/pymc3/issues/1463 (2) https://stackoverflow.com/questions/52270853/how-to-get-rid-of-theano-gof-compilelock and (3) https://groups.google.com/forum/#!topic/theano-users/eJ2vl2PUTk4. Last night, I have already tried to reset base_compiledir for theano, through two ways: (1) creating a ~/.theanorc file just like you suggested (2) modifying the file ~/.bashrc for my login node, by adding a line: export THEANO_FLAGS=""base_compiledir=/scratch/gatk-user1/z-Temp/z-Temp-Theano-$chr"". However, the truth is that, in our cluster, when I submit the 25 jobs (for each chromosomes), they are assigned to different computer nodes randomly. It means that I have to set THEANO environment variable for each corresponding random computer nodes respectively, which is quite difficult for me, as the nodes are random assigned. So, now I'm going to add lines like below to the ~/.theanorc in my login node, to see what will happen. Maybe It will work.; #######; [global]; config.compile.timeout = 100000 ; ######. However, I'm really appreciate it if some one in your team can help to add a function to specify a temporary directory for the theano directory, which can be bound to the corresponding node shared by other GATK threads. Thank you and Best regards.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548557073:2522,variab,variable,2522,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548557073,2,"['config', 'variab']","['config', 'variable']"
Modifiability," what intervals were used for the jobs. I tried using running GenomicsDBImport with -L over a small region, or I ran SelectVariants on the gVCF first (which behaves a little differently), and then used that subset gVCF as input to GenomicsDBImport, where GenomicsDBImport is given the entire contig as the interval. The resulting workspaces will be slightly different, with the latter containing information over a wider region (GenomicsDBIport truncates start/end of the input records to just the target interval). . So if either of these workspaces is passed to GenotypeGVCFs, using --only-output-calls-starting-in-intervals and -L 1:1050-1150:. I think any upstream padding doesnt matter. If you have a multi-nucleotide polymorphism that starts upstream of 1050 but spans 1050, this job wouldnt be responsible for calling that. The prior job, which has an interval set upstream of this one should call it. I think GenomicsDbImport's behavior is fine here. If you have a multi-NT variant that starts within 1050-1150, but extends outside (i.e. deletion or insertion starting at 1148), this could be a problem. The GenomicsDB workspace created with the interval 1:1050-1150 lacks the information to score that, right? The workspace created using the more permissive SelectVariants->GenomicsDBImport contains that downstream information and presumably would make the same call as if GenotypeGVCFs was given the intact chromosome as input, right?. However, it seems that if I simply create the workspace with a reasonably padded interval (adding 1kb should be more than enough for Illumina, right?), and then run GenotypeGVCFs with the original, unpassed interval, then the resulting workspace should contain all available information and GenotypeGVCFs should be able to make the same call as if it was given a whole-chromosome workspace as input. . Does that logic seem right? . ```; # The Input gVCF; 1	1040	.	A	<NON_REF>	.	.	END=1046	GT:DP:GQ:MIN_DP:PL	0/0:15:24:14:0,24,360; 1	1047	.	T	<NON_REF>	.	",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221558244:1618,extend,extends,1618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221558244,2,['extend'],['extends']
Modifiability,"!?[0m. 16:58:10.116 INFO PrintVariantsSpark - Initializing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 19/02/18 16:58:25 INFO org.apache.h",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4786,config,configure,4786,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['config'],['configure']
Modifiability,"![IMG_9960](https://user-images.githubusercontent.com/11076296/95899038-ee88e280-0d5d-11eb-86bf-272687eb9ac0.jpg). Decided to just sit down and go through the exercise of threading all of the parameter sets by hand after biffing it once. Reproducing above; might be helpful for the reviewer if this goes in, but they may want to independently check it. (Is there a way I could've gotten IntelliJ to do this for me?). I would hope that we could do some refactoring to simplify this a bit, if not model ablation or consolidation of parameters, but I won't attempt it for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816:452,refactor,refactoring,452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816,2,['refactor'],['refactoring']
Modifiability,"![weighted](https://user-images.githubusercontent.com/11076296/97032266-8ab9a300-152f-11eb-8d73-148ff99963be.png). Here is the result of optimizing for sensitivity in the high-confidence, low-compexity region of chr22 in CHM, allowing haplotype-to-reference and read-to-haplotype (match, mismatch, gap open) to range over ([1, 20], [-20, -1], [-20, -1]) and fixing gap extend penalties to -1. The optimal (match, mismatch, gap open) parameters found in this run appear to be:. haplotype-to-reference: 2, -8, -19; read-to-haplotype: 1, -4, -3. I wouldn't put much stock in interpreting these parameters or their exact values for now, but it does appear that the match values and the haplotype-to-reference gap-open penalty might be saturating the bounds of the search. Plots of the type suggested by @dalessioluca might be more illuminating. Compare with default performance:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 9.000 4003 4019 494 1036 0.8905 0.7944 0.8397; None 4009 4025 511 1030 0.8873 0.7956 0.8390; ````. That the corresponding curve with a precision/sensitivity endpoint of (0.8873, 0.7956) above isn't at the top of the pack means that we could squeeze out some extra calls by varying the SW parameters. Of course, this doesn't account for negative impact elsewhere. One could imagine writing a loss where this sensitivity is optimized while putting minimum constraints on precision, sensitivity, and/or F1 in the high-confidence, high-complexity regions (the assumption being the truth set is complete in those regions), or some weightings/variations thereof. EDIT: Actually, looks like overall performance in the high-confidence region improves:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692:369,extend,extend,369,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692,1,['extend'],['extend']
Modifiability,"""fs.gs.project.id"", value);; }; }. if (working_dir.empty()) {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", ""/"");; } else {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", working_dir.c_str());; }. // Default buffer sizes are huge in the GCS connector. GenomicsDB reads/writes in smaller chunks,; // so the buffer size can be made a little smaller.; hdfsBuilderConfSetStr(builder, ""fs.gs.io.buffersize.write"", ""262144"");. hdfsFS hdfs_handle = hdfsBuilderConnect(builder);; free(value);; return hdfs_handle;; }; ```. This is the error from Travis logs-; ```; Running Test: Test method testWriteToAndQueryFromGCS(org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest); hdfsBuilderConnect(forceNewInstance=1, nn=gs://hellbender-test-logs, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:210); at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:75); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1826); Caused by: com.google.api.client.http.HttpResponseException: 404 Not Found; {""error"":""invalid_request"",""error_description"":""Service account not enabled on this instance""}; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1072); at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:159); at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:493); at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:208); ... 77 more; [GenomicsDB::StorageManagerConfig] Error: Error getting hdfs connection: Connection refused.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888:2017,config,configure,2017,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888,1,['config'],['configure']
Modifiability,"## First, add variables to HelpConstants.java ; at <https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/help/HelpConstants.java>. These need to be under _group definitions_ as well as under _supercategory_. E.g.:; ```; public final static String DOC_CAT_READFILTERS = ""Read Filters"";; public final static String DOC_CAT_READFILTERS_SUMMARY = ""Read Filters used by the engine to select reads to be included for analysis"";; ...; // supercat Utilities; groupToSuperCategory.put(DOC_CAT_READFILTERS, DOC_SUPERCAT_UTILITIES);; ```. - group name variable and descriptor: DOC_CAT_ANNOTATORS = ""Annotation Modules""; - group summary variable and descriptor: DOC_CAT_ANNOTATORS_SUMMARY = ""Annotations available to HaplotypeCaller, Mutect2 and VariantAnnotator""; - super category: Utilities (same group as read filters). This is now in <https://github.com/broadinstitute/gatk/pull/3835/commits/320b64a0391b751f4a738100fe854d243b02f2b4>. ---; ## SOP ; https://github.com/broadinstitute/gatk/pull/3835. [1] Add feature tag and define elements to all annotation modules in <https://github.com/broadinstitute/gatk/tree/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator>. E.g. the tag looks thus:; ```; @DocumentedFeature(groupName=HelpConstants.DOC_CAT_READFILTERS, groupSummary=HelpConstants.DOC_CAT_READFILTERS_SUMMARY, summary = ""Keep only reads that are first of pair""); ```; - group name variable: DOC_CAT_ANNOTATORS; - group summary variable: DOC_CAT_ANNOTATORS_SUMMARY; - summary specific to the annotation module. ### For copy-pasting:; ```; @DocumentedFeature(groupName=HelpConstants.DOC_CAT_ANNOTATORS, groupSummary=HelpConstants.DOC_CAT_ANNOTATORS_SUMMARY, summary = """"); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344383546:14,variab,variables,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344383546,5,['variab'],"['variable', 'variables']"
Modifiability,"(As part of your final review @cmnbroad, you should open a ticket to eventually refactor the `MendelianViolation` class)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-404576289:80,refactor,refactor,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-404576289,1,['refactor'],['refactor']
Modifiability,"**The following work has been done:**; - We performed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:649,variab,variable,649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502,1,['variab'],['variable']
Modifiability,"- Add a CLI flag `--exclude-field-name` which can be specified multiple times.; For example `... --exclude-field-name Clinvar_bar --exclude-field-name Clinvar_foo ...`. We will specify the column names with the full field name: `<datasourcename>_<fieldname>`. For now, we specify via an `exclude`. If nothing is specified, then show everything. - Make sure that this new parameter is integrated into the config file framework as implemented by #4581",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943:404,config,config,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943,1,['config'],['config']
Modifiability,- Picard Version: 2.18.16; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 11:33:26.276 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:33:26.276 INFO CountReadsSpark - Deflater: IntelDeflater; 11:33:26.276 INFO CountReadsSpark - Inflater: IntelInflater; 11:33:26.276 INFO CountReadsSpark - GCS max retries/reopens: 20; 11:33:26.276 INFO CountReadsSpark - Requester pays: disabled; 11:33:26.277 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 -,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:4625,config,configuration,4625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['config'],['configuration']
Modifiability,- Picard Version: 2.18.16; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:35:11.511 INFO CountReadsSpark - Deflater: IntelDeflater; 13:35:11.511 INFO CountReadsSpark - Inflater: IntelInflater; 13:35:11.512 INFO CountReadsSpark - GCS max retries/reopens: 20; 13:35:11.512 INFO CountReadsSpark - Requester pays: disabled; 13:35:11.512 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 -,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:4364,config,configuration,4364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['config'],['configuration']
Modifiability,"------------------------------------------------------------------------------------; // arguments for debugging / developing the haplotype caller; @@ -634,12 +635,11 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if ( emitReferenceConfidence() ) {; ; if (SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES); - throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and Genotyping Giving Alleles at the same time"");; + throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and GENOTYPE_GIVEN_ALLELES at the same time"");; ; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_EMITTING = -0.0;; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_CALLING = -0.0;; ; -; // also, we don't need to output several of the annotations; annotationsToExclude.add(""ChromosomeCounts"");; annotationsToExclude.add(""FisherStrand"");; @@ -651,6 +651,9 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if (!SCAC.annotateAllSitesWithPLs); logger.info(""All sites annotated with PLs forced to true for reference-model confidence output"");; SCAC.annotateAllSitesWithPLs = true;; + } else if ( ! doNotRunPhysicalPhasing ) {; + doNotRunPhysicalPhasing = true;; + logger.info(""Disabling physical phasing, which is supported only for reference-model confidence output"");; }; ; if ( SCAC.AFmodel == AFCalcFactory.Calculation.EXACT_GENERAL_PLOIDY ); @@ -678,7 +681,7 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if( SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES && consensusMode ); throw new UserException(""HaplotypeCaller cannot be run in both GENOTYPE_GIVEN_ALLELES mode and in consensus mode. Please choose one or the other."");; ; - genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, tryPhysicalPhasing);; + genotypingEngine = new HaplotypeCallerGenotypingEngi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:3039,extend,extends,3039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237,1,['extend'],['extends']
Modifiability,".codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar PrintReadsSpark -I /gatk4/output.bam -O /gatk4/output_3.bam --sparkMaster yarn-client; Warning: Master yarn-client is deprecated since 2.0. Please use master ""yarn"" with specified deploy mode instead.; 18:11:33.604 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 18:11:33.737 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 13, 2017 6:11:33 PM CST] PrintReadsSpark --output /gatk4/output_3.bam --input /gatk4/output.bam --sparkMaster yarn-client --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 13, 2017 6:11:33 PM CST] Executing as hdfs@mg on Linux 3.10.0-514.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:1672,variab,variables,1672,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,4,"['config', 'variab']","['configured', 'variables']"
Modifiability,".java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646204>:; >; > > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Interval(si.getContig(), si.getStart(), si.getEnd())).forEach(intervalList::add);; > +; > + // sort intervals according to their coordinates and unique them (i.e. delete duplicates); > + intervalList.uniqued();; > +; > + // pad all elements of intervalList; > + intervalList = intervalList.padded(padding,padding);; > +; > + // merge those that intersect after padding; > + intervalList = IntervalList.intersection(intervalList, intervalList);; > +; > + // break the intervals up to bins -- the last bin in each interval can be shorter than the others; > + IntervalList bins = new IntervalList(sequenceDictionary);; > + int bin_start, bin_end;; > + Interval new_bin;; >; > Agreed, but *if* you didn't inline it, you would want to declare it; > inside the loop. In Java you pretty much always try to give variables the; > most local scope possible.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646252>:; >; > > +; > + // merge those that intersect after padding; > + intervalList = IntervalList.intersection(intervalList, intervalList);; > +; > + // break the intervals up to bins -- the last bin in each interval can be shorter than the others; > + IntervalList bins = new IntervalList(sequenceDictionary);; > + int bin_start, bin_end;; > + Interval new_bin;; > + for(Interval in : intervalList) {; > + bin_start = in.getStart();; > + bin_end = Math.min(bin_start + widthOfBins - 1, in.getEnd());; > + while(bin_start < in.getEnd()) {; > + new_bin = new Interval(in.getContig(), bin_start, bin_end);; > + bins.add(new_bin);; > + bin_start += widthOfBins;; > + bin_end = Math.min(bin_start + widthOfBins - 1, in.getEnd());; >; > If you move bin_e",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:9676,variab,variables,9676,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211,1,['variab'],['variables']
Modifiability,.txt; > 12:28:19.227 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/Cosmic.db -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/cosmic/hg38/Cosmic.db; > 12:28:19.401 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_tissue.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/cosmic_tissue/hg38/cosmic_tissue.tsv; > 12:28:19.487 INFO DataSourceUtils - Setting lookahead cache for data source: chr1_a_bed : 100000; > 12:28:19.495 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/chr1_a_bed.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_a_bed/hg38/chr1_a_bed.tsv; > 12:28:19.500 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_a_bed/hg38/chr1_a_bed.config; > 12:28:19.505 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/chr1_a_bed.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_a_bed/hg38/chr1_a_bed.tsv; > 12:28:19.507 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/chr1_a_bed.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_a_bed/hg38/chr1_a_bed.tsv; > WARNING 2020-07-21 12:28:19 AsciiLineReader Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; > 12:28:19.512 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_fusion.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/cosmic_fusion/hg38/cosmic_fusion.tsv; > 12:28:19.522 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/genco,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975:13476,config,config,13476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975,1,['config'],['config']
Modifiability,/commit/2bb2f50996e5e826268145d426e8edd697f9a46f?src=pr&el=desc) will **increase** coverage by `0.319%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4445 +/- ##; ===============================================; + Coverage 79.156% 79.475% +0.319% ; - Complexity 16583 17182 +599 ; ===============================================; Files 1049 1050 +1 ; Lines 59510 60950 +1440 ; Branches 9747 10190 +443 ; ===============================================; + Hits 47106 48440 +1334 ; - Misses 8620 8690 +70 ; - Partials 3784 3820 +36; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4445?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `77.703% <ø> (+5.764%)` | `62 <0> (+17)` | :arrow_up: |; | [...stitute/hellbender/utils/config/ConfigFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb25maWcvQ29uZmlnRmFjdG9yeS5qYXZh) | `76.398% <100%> (-0.036%)` | `45 <3> (ø)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-40%)` | `1% <0%> (-2%)` | |; | [...nder/cmdline/PicardCommandLineProgramExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1BpY2FyZENvbW1hbmRMaW5lUHJvZ3JhbUV4ZWN1dG9yLmphdmE=) | `60% <0%> (-10%)` | `4% <0%> (+1%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4445#issuecomment-368063117:1229,config,config,1229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4445#issuecomment-368063117,2,"['Config', 'config']","['ConfigFactory', 'config']"
Modifiability,"015f-0a1b-f1bd-00002ce33928 ; on database directory /tmp/spark-98953d35-8594-4907-b4a5-0870f1d17b3e/metastore with class loader sun.misc.Launcher$AppClassLoader@5c647e05 ; Loaded from file:/opt/cloudera/parcels/CDH-5.12.1-1.cdh5.12.1.p0.3/jars/derby-10.11.1.1.jar; java.vendor=Oracle Corporation; java.runtime.version=1.8.0_91-b14; user.dir=/opt/Software/gatk; os.name=Linux; os.arch=amd64; os.version=3.10.0-514.el7.x86_64; derby.system.home=null; Database Class Loader started - derby.database.classpath=''; 17/10/11 14:25:33 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.1.0-cdh5.12.1; 17/10/11 14:25:33 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException; SQL context available as sqlContext. **./gradlew bundle**; **[root@com1 gatk]# ./gradlew bundle; when I executed the command ”./gradlew bundle”， it appeared the error in the last ，did this matter？**. .......; [loading ZipFileIndexFileObject[/root/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.6.5/d50be1723a09be903887099ff2014ea9020333/jackson-databind-2.6.5.jar(com/fasterxml/jackson/databind/annotation/JsonSerialize$Inclusion.class)]]; [loading ZipFileIndexFileObject[/root/.gradle/caches/modules-2/files-2.1/org.apache.logging.log4j/log4j-core/2.5/7ed845de1dfe070d43511fab1784e6c4118398/log4j-core-2.5.jar(org/apache/logging/log4j/core/config/plugins/PluginVisitorStrategy.class)]]; [done in 5759 ms]; 1 error; :gatkTabComplete FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkTabComplete'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/opt/Software/gatk/build/tmp/gatkTabComplete/jadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 7.431 secs",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240:3362,config,config,3362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240,3,"['Plugin', 'config', 'plugin']","['PluginVisitorStrategy', 'config', 'plugins']"
Modifiability,"1) Runtime Block. Generally diskpace, memory, and docker image would be the main cloud runtime attributes to have for a task. Maybe give them default values, so that users can change them in the json if they would like. ; 2) Variable declaration placement. Not absolutely necessary but thought it might help reduce the number of lines in the wdl. Here is an example where the task declares a variable that is not in the call or workflow block: [here](https://github.com/gatk-workflows/seq-format-conversion/blob/0f4abf107950769ffd891770db18c9691e720314/cram-to-bam.wdl#L79). Here is a wdl doc about it [(link)](https://support.terra.bio/hc/en-us/articles/360037485511-Add-Variables) though its old. Hard to find a direct statement about it in the wdl 1.0 spec but this section hints at it [link](https://github.com/openwdl/wdl/blob/master/versions/1.0/SPEC.md#declared-inputs-defaults-and-overrides).; 3. Input naming. Ahh. that makes sense. I often see `input_file` being used in wdls so that could work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-615216274:225,Variab,Variable,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-615216274,3,"['Variab', 'variab']","['Variable', 'Variables', 'variable']"
Modifiability,"16T00:09:07.4038957Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4039323Z location: class CountingReadFilter; 2022-08-16T00:09:07.4039849Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T00:09:07.4040311Z @VisibleForTesting; 2022-08-16T00:09:07.4040921Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4041294Z location: class CountingVariantFilter; 2022-08-16T00:09:07.4054361Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4060164Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T00:09:07.4060614Z @VisibleForTesting; 2022-08-16T00:09:07.4061233Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4061591Z location: class ReadFilter; 2022-08-16T00:09:07.4083439Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4092135Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4107682Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4116317Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4117746Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4124264Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T00:09:07.4124816Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:12207,config,config,12207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,2,"['Config', 'config']","['ConfigFactory', 'config']"
Modifiability,"16T22:45:53.8024147Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8024320Z location: class CountingReadFilter; 2022-08-16T22:45:53.8024635Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T22:45:53.8024772Z @VisibleForTesting; 2022-08-16T22:45:53.8025036Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8025212Z location: class CountingVariantFilter; 2022-08-16T22:45:53.8032154Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8035089Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T22:45:53.8035234Z @VisibleForTesting; 2022-08-16T22:45:53.8035505Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8035658Z location: class ReadFilter; 2022-08-16T22:45:53.8087327Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8103864Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8113680Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8117654Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8118430Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8124030Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T22:45:53.8124383Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:14245,config,config,14245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,2,"['Config', 'config']","['ConfigFactory', 'config']"
Modifiability,"19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:39:19 INFO SparkContext: Running Spark version 2.2.0; 18/04/24 17:39:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/04/24 17:39:19 INFO SparkContext: Submitted application: PathSeqPipelineSpark; 18/04/24 17:39:20 INFO SecurityManager: Changing view acls ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:6305,Config,ConfigFactory,6305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"3 general classes: simple -> SimpleNovelAdjacency, complex -> ComplexVariantCanonicalRepresentation, and unknown -> SAM records of the contigs); and a groupBy() operation is necessary in the middle using these objects as keys; due to the fact that different contigs may produce the same variant; So what I'm thinking about, is two pass:; one pass for splitting them up into the 3 classes,; then another pass on each of those 3 RDD's to turn them into VariantContext's.; Any better idea?. Reply by @cwhelan ; > That would be better, and yeah you don't have to do it in this PR.; In theory you could make the keys for the groupByKey() (ie NovelAdjacencyAndAltHaplotype, CpxVariantCanonicalRepresentation, right?) all inherit from the same superclass and do a single group by, couldn't you? Then you could do everything in a single pass. Reply by @SHuang-Broad; > Yes, that is what I'm planning but I'm not sure yet about how to approach that (I actually tried it, before putting in the above comment, and quickly ran into the problem of mixing Java serialization and Kryo serialization, so a larger re-structuring might be needed, and not just a inheritance structure). ------------; ### On the problem of having a confusing TODO for ; `boolean SimpleChimera.isCandidateInvertedDuplication()`. The todo message. > TODO: 5/5/18 Note that the use of the following predicate is currently obsoleted by; {@link AssemblyContigWithFineTunedAlignments#hasIncompletePictureFromTwoAlignments()}; because the contigs with this alignment signature is classified as ""incomplete"",; hence will NOT sent here for constructing SimpleChimera's.; But we may want to keep the code (and related code in BreakpointComplications) for future use. Comment by @cwhelan ; > I'm a bit confused by this comment: this method is still being called in several places, so how is it obsolete?. Reply by @SHUANG-Broad (also copied to update the ""TODO"" message; > this predicate is currently used in two places (excluding appearance in com",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:1977,inherit,inheritance,1977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,2,['inherit'],['inheritance']
Modifiability,"39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.REFERENCE_FASTA : null; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5184,Config,ConfigFactory,5184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:39:19 INFO SparkContext: Running Spark version 2.2.0; 18/04/24 17:39:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/04/24 17:39:19 INFO SparkContext: Submitted application: Pat",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:6227,Config,ConfigFactory,6227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L1NWQ2x1c3Rlci5qYXZh) | `89.773% <0.000%> (-0.881%)` | :arrow_down: |; | [...tools/walkers/sv/JointGermlineCNVSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/7863/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L0pvaW50R2VybWxpbmVDTlZTZWdtZW50YXRpb24uamF2YQ==) | `86.047% <0.000%> (-0.752%)` | :arrow_down: |; | [...der/tools/walkers/sv/SVClusterIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7863/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L1NWQ2x1c3RlckludGVncmF0aW9uVGVzdC5qYXZh) | `99.496% <0.000%> (-0.004%)` | :arrow_down: |; | [...itute/hellbender/tools/LocalAssemblerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7863/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Mb2NhbEFzc2VtYmxlclVuaXRUZXN0LmphdmE=) | `92.448% <0.000%> (ø)` | |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/7863/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `97.368% <0.000%> (+0.035%)` | :arrow_up: |; | ... and [2 more](https://codecov.io/gh/broadinstitute/gatk/pull/7863/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7863#issuecomment-1133159561:4974,Adapt,AdaptiveChainPruner,4974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7863#issuecomment-1133159561,1,['Adapt'],['AdaptiveChainPruner']
Modifiability,3Zxc3IvVHJhbmNoZS5qYXZh) | `62.921% <0%> (-7.349%)` | `18% <0%> (ø)` | |; | [.../hellbender/tools/walkers/vqsr/TrancheManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...ols/walkers/contamination/ContaminationRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblJlY29yZC5qYXZh) | `87.302% <0%> (-2.698%)` | `9% <0%> (+4%)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> (ø)` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> (ø)` | `12% <0%> (?)` | |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <0%> (+1.429%)` | `2% <0%> (ø)` | :arrow_down: |; | [...s/spark/pathseq/PSBuildReferenceTaxonomyUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTQnVpbGRSZWZlcmVuY2VUYXhvbm9teVV0aWxzLmphdmE=) | `90.541% <0%> (+1.579%)` | `80% <0%> (+41%)` | :arrow_up: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054:3054,Adapt,AdapterTrimTransformer,3054,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054,1,['Adapt'],['AdapterTrimTransformer']
Modifiability,"4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 670, in __call__; no_recycling=[]); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 955, in make_thunk; no_recycling); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/op.py"", line 858, in make_c_thunk; output_storage=node_output_storage); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cc.py"", line 1217, in make_thunk; keep_lock=keep_lock); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cc.py"", line 1157, in __compile__; keep_lock=keep_lock); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cc.py"", line 1623, in cthunk_factory; module = get_module_cache().module_from_key(; File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cc.py"", line 48, in get_module_cache; return cmodule.get_module_cache(config.compiledir, init_args=init_args); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 1587, in get_module_cache; _module_cache = ModuleCache(dirname, **init_args); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 703, in __init__; self.refresh(); File ""/usr/local/Anaconda/envs_app/gatk/4.1.2.0/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 794, in refresh; files = os.listdir(root); FileNotFoundError: [Errno 2] No such file or directory: '/spin1/home/linux/sangj2/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.5.1804-Core-x86_64-3.6.2-64/tmpyvtzjxzm'; 00:50:23.369 DEBUG ScriptExecutor - Result: 1; 00:50:23.370 INFO GermlineCNVCaller - Shutting down engine; [October 29, 2019 12:50:23 AM EDT] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 0.72 minutes.; Runtime.totalMemory()=2335703040; org.broadinstitute.hel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-547440019:6545,config,config,6545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-547440019,1,['config'],['config']
Modifiability,49s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.4435974Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T00:09:07.4436105Z @VisibleForTesting; 2022-08-16T00:09:07.4436380Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4436641Z location: class CommandLineProgram; 2022-08-16T00:09:07.4436930Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:120: error: cannot find symbol; 2022-08-16T00:09:07.4437094Z @VisibleForTesting; 2022-08-16T00:09:07.4437369Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4437519Z location: class FeatureInput<T>; 2022-08-16T00:09:07.4437725Z where T is a type-variable:; 2022-08-16T00:09:07.4437925Z T extends Feature declared in class FeatureInput; 2022-08-16T00:09:07.4438276Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:251: error: cannot find symbol; 2022-08-16T00:09:07.4438417Z @VisibleForTesting; 2022-08-16T00:09:07.4438677Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4438873Z location: class PosteriorProbabilitiesUtils; 2022-08-16T00:09:07.4439223Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:271: error: cannot find symbol; 2022-08-16T00:09:07.4439362Z @VisibleForTesting; 2022-08-16T00:09:07.4439618Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4439806Z location: class PosteriorProbabilitiesUtils; 2022-08-16T00:09:07.4465668Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/DefaultGATKVariantAnnotationArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:20843,variab,variable,20843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['variab'],['variable']
Modifiability,"64e; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 08:04:19 2017 -0500. mkl. commit 43e2a65201286161fcd5bfe7dbb21ae888e19dac; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 06:56:20 2017 -0500. added cpu argument for germline tasks. commit 4433a62c2173c7f29d0f264c084bbaf2f6738782; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 02:45:38 2017 -0500. revert travis yml forks; verbose logging germline wdl. commit ae05801e33c37b3bf2685fba202032a270804873; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 00:55:14 2017 -0500. updated somatic PoNs for PreprocessIntervals drop Ns. commit cff64984d9fb42364001bda4c73d54cf68d85a5c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:37:24 2017 -0500. sudo travis yml. commit 89025941febd2089d426cfa1e0f0aa6a6712e2a9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:23:22 2017 -0500. travis/Docker config update (g++-6, Miniconda3); python test group assignment. commit 31f96398106c2b8577b8c25d110abea3ebe7f836; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:44:53 2017 -0500. WDL test bugfix. commit 9b2fb820536ec355bea0256471bd093d547f5c99; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:20:36 2017 -0500. update WDL test JSON files. commit e3d97644d1a2c40a5c364a96f8b67246154179c9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:18:14 2017 -0500. assertions in inference task base; removed a ASCII > 128 character in log messages. commit 526cf92e623a3bbd5f9d375132b6ca046fc47620; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:03:04 2017 -0500. redirect tqdm progress bar to python logger. commit 2e45bd30968b921fae225de3901fb97ece690b0c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:45:49 2017 -0500. more arg related fixes. commit bb89a3bb338d88199881e8aca65f656f2acd7c0a; Author: ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:4206,config,config,4206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['config'],['config']
Modifiability,6f6105708ded7f86c96c830781; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:35:33 2017 -0500. annotated intervals kebab case; updated germline WDL workflows. commit 29cc6234dbfb8db12559217a650c6ceb170c5797; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:15:28 2017 -0500. cleanup test files. commit 08a35bb4e65eceb735adcd41a91132e9a34d2b66; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:50:19 2017 -0500. update WDL scripts. commit 12bcfa192ee6fa6da21239ebf5b513633efe974f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:47:33 2017 -0500. significant updates to GermlineCNVCaller; integration tests for GermlineCNVCaller w/ sim data in both run modes. commit 151416a4af735ca721bd75e4b54a780c17ac9397; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 01:42:05 2017 -0500. hybrid ADVI abstract argument collection w/ flexible default values; hybrid ADVI argument collection for contig ploidy model; hybrid ADVI argument collection for germline denoising and calling model. commit 56e21bf955d3dc0c52aceb384f28cf6173959de0; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 23:18:39 2017 -0500. rewritten python-side coverage metadata table reader using pandas to fix the issues with comment line; change criterion for cohort/case based on whether a contig-ploidy model is provided or not; simulated test files for ploidy determination tool; proper integration test for ploidy determination tool and all edge cases; updated docs for ploidy determination tool. commit 7fa104b2e9170770cfc5b338835e41215d7fd39c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 18:43:17 2017 -0500. kabab case for gCNV-related tools; removed short args (this also partially affected PlotDenoisedCopyRatios and PlotModeledSegments and their integration tests). commit f02cb024331a986213cfd9fae2da706bbc5ddbd9; Author: Mehrtash Babadi <mehrtash@broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:7178,flexible,flexible,7178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['flexible'],['flexible']
Modifiability,"7:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5750,Config,ConfigFactory,5750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...hellbender/utils/haplotype/HaplotypeBAMWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvSGFwbG90eXBlQkFNV3JpdGVyLmphdmE=) | `97.531% <0%> (-0.546%)` | `15% <0%> (+5%)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `68.595% <0%> (-0.092%)` | `29% <0%> (+5%)` | |; | [...r/transformers/BaseQualityClipReadTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQmFzZVF1YWxpdHlDbGlwUmVhZFRyYW5zZm9ybWVyLmphdmE=) | `100% <0%> (ø)` | `19% <0%> (+5%)` | :arrow_up: |; | [...hellbender/utils/haplotype/SAMFileDestination.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvU0FNRmlsZURlc3RpbmF0aW9uLmphdmE=) | `100% <0%> (ø)` | `6% <0%> (+3%)` | :arrow_up: |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> (ø)` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> (ø)` | `12% <0%> (?)` | |; | ... and [14 more](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377:3668,Adapt,AdapterTrimTransformer,3668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377,1,['Adapt'],['AdapterTrimTransformer']
Modifiability,":19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5941,Config,ConfigFactory,5941,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"; 16:58:10.116 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:58:10.116 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:58:10.116 INFO PrintVariantsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:58:10.116 INFO PrintVariantsSpark - Deflater: IntelDeflater; 16:58:10.116 INFO PrintVariantsSpark - Inflater: IntelInflater; 16:58:10.116 INFO PrintVariantsSpark - GCS max retries/reopens: 20; 16:58:10.116 INFO PrintVariantsSpark - Requester pays: disabled; 16:58:10.116 WARN PrintVariantsSpark - . ?[1m?[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: PrintVariantsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!?[0m. 16:58:10.116 INFO PrintVariantsSpark - Initializing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:3977,config,configuration,3977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['config'],['configuration']
Modifiability,"= ""Split intervals into sub-interval files."",; > + oneLineSummary = ""Split intervals into sub-interval files."",; > + programGroup = VariantProgramGroup.class; > +); > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; >; > @samuelklee <https://github.com/samuelklee> is the boss of the copy; > number code, but personally I don't see the need to be extremely concise; > with short names and would prefer width.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646054>:; >; > > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; > + public static final String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; >; > binWidth would be a more readable variable name. There's nothing wrong; > with the command line argument and the variable being identical.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646097>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = tr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:1526,extend,extends,1526,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211,2,"['extend', 'variab']","['extends', 'variable']"
Modifiability,"=Code) impl. [IOUtils](https://github.com/broadinstitute/gatk/blob/94ac626218e073b77156a3eff076003d26be318c/src/main/java/org/broadinstitute/hellbender/utils/io/IOUtils.java#L535). Today, org.apache.hadoop.fs.{FileSystem, Path} is much broadly used in the Big Data world, and most of vendors of distribution storage provider already provide impl of org.apache.hadoop.fs.{FileSystem, Path} include AWS, Google and Alibaba. There are huge customers of Hadoop already work on hadoop.fs for years, if GAKT on spark could rely on org.apache.hadoop.fs.{FileSystem, Path} , I guess GAKT could acquire more existing customers of Hadoop on Cloud much faster . . Maybe we could consider migrating java.nio.file.FileSystem impl to org.apache.hadoop.fs.{FileSystem, Path} impl in [SparkContextFacto]r(https://github.com/broadinstitute/gatk/blob/73f2a62bee52518b57a985717770ed3a64d83243/src/main/java/org/broadinstitute/hellbender/engine/spark/SparkContextFactory.java), otherwise we could support both nio and hadoop thru env variable, Let me know your thought!. ```; scala> stringRdd.saveAsTextFile(""oss://eric-new/testwrite10""). scala> val stringRdd = sc.parallelize(Seq(""Test String"")); stringRdd: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[4] at parallelize at <console>:24. scala> stringRdd.saveAsTextFile(""oss://eric-new/testwrite11""); ```. ``` oss nio is missing; 18/01/03 17:13:13 INFO NewHadoopRDD: Input split: oss://eric-new/resources/NA12878.chr17_69k_70k.dictFix.bam:1632-3770875903; 18/01/03 17:13:13 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0); java.nio.file.ProviderNotFoundException: Provider ""oss"" not found; 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:341); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:143); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:226); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.crea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-354989381:1659,variab,variable,1659,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-354989381,1,['variab'],['variable']
Modifiability,"> > @mcovarr @koncheto-broad Do all these files exist as they are here in the ah_var_store branch currently?; > ; > Yes, delta the refactoring required to separate the VCF writing into a subclass. Would it be easier/preferable for you all to move those changes into the var store branch and I'll work on the PGEN stuff there instead of in master?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8355#issuecomment-1634754805:131,refactor,refactoring,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8355#issuecomment-1634754805,1,['refactor'],['refactoring']
Modifiability,> @davidbenjamin Can I assume that you didn't change NearbyKmerErrorCorrector (other than renaming and refactoring). Yes you can.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6470#issuecomment-592715339:103,refactor,refactoring,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6470#issuecomment-592715339,1,['refactor'],['refactoring']
Modifiability,"> @mcovarr @koncheto-broad Do all these files exist as they are here in the ah_var_store branch currently?. ~Yes, delta the refactoring required to separate the VCF writing into a subclass.~; Yes!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8355#issuecomment-1634742056:124,refactor,refactoring,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8355#issuecomment-1634742056,1,['refactor'],['refactoring']
Modifiability,"> A fix for another often-reported issue where Mutect2 could emit MNPs despite --max-mnp-distance being 0, causing downstream errors in GenomicsDB about MNPs not being supported. Is this fix is only dedicated to the Mutect2 module and not extended for the HaplotypeCaller/HaplotypeCallerSpark/CombineGVCFs functions?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-671790528:239,extend,extended,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-671790528,1,['extend'],['extended']
Modifiability,"> First, if a datasource config has a space in it, throw an error and tell the user to remove the space. Yes, but trim trailing and leading spaces first. Do this when initializing the datasource. So if a config file specifies a leading or trailing whitespace, it is discarded. > Second - remove spaces from funcotation field names when outputting the funcotations (could still happen with XSVs with spaces in column headers). Actually, since we know the output field names before we do any work, I would recommend doing something similar as above (i.e. Remove trailing or leading spaces and throw error if any other spaces are found).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5937#issuecomment-507304973:25,config,config,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5937#issuecomment-507304973,2,['config'],['config']
Modifiability,"> For some reason, the environment variable is not getting passed to GenomicsDB at all. To help debug the issue, can you do the following and see if any consolidation lock is created at all?; > ; > ```; > find /path/to/genomicsdb_workspace -name "".__consolidation_lock""; > ```; > ; > Also, what type of Posix filesystem is your GenomicsDB workspace? Is it NFS or Lustre? How is file locking configured on the system?. Thank you nalinigans.I want to confirm that 'genomicsdb_workspace’ is the result of GenomicsDBImport like; > -[ 201] callset.json; -[4.0K] chr22$1$50818468; |-[4.0K] __3d7b0c29-9d8b-4748-a08a-c1e0a9136cf647572466251520_1590412882146; ||-[133K] AD.tdb; ||-[ 54K] AD_var.tdb; ||-[3.2M] ALT.tdb; ||-[ 77K] ALT_var.tdb; ||-[ 85K] BaseQRankSum.tdb; ||-[192K] __book_keeping.tdb.gz; ||-[4.1M] __coords.tdb; ||-[1011K] DP_FORMAT.tdb; ||-[114K] DP.tdb; ||-[3.5M] END.tdb; ||-[108K] ExcessHet.tdb; ||-[ 64K] FILTER.tdb; ||-[ 0] FILTER_var.tdb; ||-[1.1M] GQ.tdb; ||-[2.9M] GT.tdb; ||-[120K] GT_var.tdb; ||-[ 64K] ID.tdb; ||-[ 0] ID_var.tdb; ||-[ 64K] InbreedingCoeff.tdb; ||-[1.0M] MIN_DP.tdb; ||-[128K] MLEAC.tdb; ||-[ 32K] MLEAC_var.tdb; ||-[128K] MLEAF.tdb; ||-[ 36K] MLEAF_var.tdb; ||-[ 82K] MQRankSum.tdb; ||-[ 98K] PGT.tdb; ||-[5.8K] PGT_var.tdb; ||-[ 99K] PID.tdb; ||-[ 15K] PID_var.tdb; ||-[2.9M] PL.tdb; ||-[3.5M] PL_var.tdb; ||-[ 77K] PS.tdb; ||-[143K] QUAL.tdb; ||-[163K] RAW_MQandDP.tdb; ||-[ 84K] ReadPosRankSum.tdb; ||-[3.2M] REF.tdb; ||-[655K] REF_var.tdb; ||-[174K] SB.tdb; ||-[ 0] __tiledb_fragment.tdb; |-[ 535] __array_schema.tdb; |-[4.0K] genomicsdb_meta_dir; | -[ 60] genomicsdb_meta_a793298a-95f2-475e-b10b-726695483e3a.json; -[ 0] __tiledb_workspace.tdb; -[ 33K] vcfheader.vcf; -[ 39K] vidmap.json. If yes, I regret that I did not find "".__consolidation_lock"" in my resultfile.; And I'm sorry I don't know what type my GenomicsDB workspace is, but I guess it is lustre，Hope this information can help you：; > Filesystem Type Size Used Avail Use% Mounted on; /dev/sda3 ext",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6627#issuecomment-637578697:35,variab,variable,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6627#issuecomment-637578697,2,"['config', 'variab']","['configured', 'variable']"
Modifiability,"> Hi @icemduru Looks like your slurm workload manager was configured to have a limit of 48GBs of maximum process memory size per execution. Your java instance is set with -Xmx45G which will cover most of this limit and leaves only a handful of memory space for the native GenomicsDB library. Native libraries work above the heapsize so it is better for you to set your -Xmx to a more sensible size of 8~12GB and leave rest of the memory space to the native library to use.; > ; > Keep in mind that this memory limit on slurm could be set per user not per task therefore you may need to run a single contig at a time or maybe 2 of them simultaneously. Otherwise slurm may interefere with all the tasks and cancel all your jobs.; > ; > One final reminder. We strongly recommend users to set th; [slurm-22680938.out_text.txt](https://github.com/user-attachments/files/16608314/slurm-22680938.out_text.txt); e temporary directory to somewhere else other than /tmp. Slurm workload manager interferes with this preference and sometimes results in premature termination of the gatk processes due to deletion of extracted native library and accessory files.; > ; > I hope this helps. Thank you for your help, but unfortunately it didn't resolve the issue. I've already tried allocating 10GB of memory using the -Xmx10g flag and redirecting the temporary directory away from /tmp. However, GATK is still attempting to consume more than 48GB of RAM, resulting in the termination of my run.; [slurm-22680938.out_text.txt](https://github.com/user-attachments/files/16608325/slurm-22680938.out_text.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2287941632:58,config,configured,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2287941632,1,['config'],['configured']
Modifiability,"> How can F be a probability when it takes on negative values?. It's the probability of alleles being IBD *provided that inbreeding is the only source of deviation from HWE* and in the limit of infinite sample size washing out statistical noise. Under these assumptions it's always positive. How about I rewrite the docs to be much, much clearer about this?. > Also, I've never heard of it being called the Fixation Score. I hadn't heard of it, either, but Wikipedia told me so: https://en.wikipedia.org/wiki/F-statistics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5768#issuecomment-470249511:304,rewrite,rewrite,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5768#issuecomment-470249511,2,['rewrite'],['rewrite']
Modifiability,"> If you have a multi-NT variant that starts within 1050-1150, but extends outside (i.e. deletion or insertion starting at 1148), this could be a problem. The GenomicsDB workspace created with the interval 1:1050-1150 lacks the information to score that, right?. GenomicsDB does store the END as a separate attribute for the interval, so the information is present even if the GenomicsDB array region does not span that far. The other questions I will leave it to @droazen and/or @mlathara to answer. Hopefully, you are able to make progress.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1231929214:67,extend,extends,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1231929214,1,['extend'],['extends']
Modifiability,"> OK, looks like you can get around the compiler lock issues by pointing each invocation of GermlineCNVCaller to a different compilation directory. For example, invoke `gatk` by; > ; > `THEANORC=PATH/TO/THEANORC_# gatk GermlineCNVCaller ...`; > ; > This uses the `THEANORC` environment variable to set the `.theanorc` configuration file to `PATH/TO/THEANORC_#` for this instance of GATK (where you should fill in `#` appropriately). Each `PATH/TO/THEANORC_#` should be a file containing the following:; > ; > ```; > [global]; > base_compiledir = PATH/TO/COMPILEDIR_#; > ```; > ; > Where again, `#` is filled in appropriately. The goal is to point each GermlineCNVCaller instance to a different compilation directory. @xysj1989 can you let me know if this works for you?; > ; > This is a bit of a hack. We could probably avoid this by changing the GATK code to use a specified or temporary directory for the theano directory without too much effort.; > ; > However, there is an upside to using a non-temporary directory to avoid recompilation of the model upon subsequent runs. In this case, we'd just want to let the user be able to specify the theano directory (rather than dump things in `~/.theano` unexpectedly). We should think about whether this should be opt-in, i.e., should we preserve the original behavior of using `~/.theano` by default?; > ; > @mwalker174 opinions? @droazen or engine team, thoughts on what the policy should be for python/R scripts doing this sort of thing? Is it generally true that the GATK leaves no trace, other than producing the expected output?. Dear samuelklee,. Thank you very much for you reply. I also found this problem last night. It seems that the problem is originally from Theano and Pymc3, rather than GATK 4.0. Some similar problems have been reported just like (1) https://github.com/pymc-devs/pymc3/issues/1463 (2) https://stackoverflow.com/questions/52270853/how-to-get-rid-of-theano-gof-compilelock and (3) https://groups.google.com/forum/#!topic/t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548557073:286,variab,variable,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548557073,2,"['config', 'variab']","['configuration', 'variable']"
Modifiability,"> Overall the refactoring looks good and makes sense… but I'm not seeing how this fixes the problem of eating exceptions we saw during a recent run. Can you explain what was happening before, and how the new code addresses it?. Sure! This code (besides refactoring so that it was only in one place) aims to fix two issues:; 1. if query results in an error, it gets run three more times and then, because of `while len(retry_delay) > 0`, it doesn’t run again and the `raise err` line never gets executed, so no error is ever raised; 2. if the query fails for a reason that has no chance of being fixed by a retry (eg. 404), it will still run three more times. I probably missed some errors that should be ""retry-able"" (maybe `Aborted `? `BadGateway`? `Cancelled `? [full list here](https://googleapis.dev/python/google-api-core/latest/exceptions.html)), but I still think it makes sense to not treat all errors the same.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7480#issuecomment-930239576:14,refactor,refactoring,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7480#issuecomment-930239576,2,['refactor'],['refactoring']
Modifiability,"> Still interested in the reference sample increase results. I wrote a unit test for that. QUAL decreases slowly as ref samples increase (e.g. one million ref samples decrease QUAL by about log_10 10^6 = 6), which I believe is the correct behavior. Overwhelming evidence that a variant is rare _ought_ to make any genotyper more skeptical about it. Note that this will only lose variants with very weak evidence. As for the command line unification that @vruano suggested, I put in a few hours and it's trickier than expected. If we use `pnrm` then we have to add an instance of `AFCalculatorImplementation`, which would need a `Supplier<AlleleFrequencyCalculator>`. But unlike the old exact model `AFCalculator`s the new one knows the heterozygosity priors (needed for Dirichlet prior pseudocounts) and needs to get those in its constructor. But this would mean that `AFCalculatorImplementation` would have to know about the heterozygosity command line arguments which would would in turn demand that it be refactored as something other than an `Enum`. As inelegant as the current hack of having a separate argument that overrides `pnrm` is, I think it's actually cleaner than the alternative.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-242264411:1008,refactor,refactored,1008,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-242264411,1,['refactor'],['refactored']
Modifiability,"> The constructors (some of them anyway) use the args during constructor execution. That's a theoretical problem but in this case they dont. Anyway, I restored my earlier code to special-case CommandLineException and throw that. . You may have seen this, but there was a failure in AlleleFrequencyQCTest, which I addressed here: https://github.com/broadinstitute/gatk/pull/6973/commits/8a9f5db6eccbc82600f8ec46e7656bcf92bedf5b. The general change is to stop stashing two variables locally within AlleleFrequency, which allows AlleleFrequencyQC to set their values later.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827880315:471,variab,variables,471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827880315,1,['variab'],['variables']
Modifiability,"> The new changes to the base image Dockerfile look good to me, @kevinpalis ! Can you tell us how many layers we have total after these changes? Is there any value in pursuing a full squash, or do you think that with this patch most users' issues will be resolved?. @droazen , the total layers is now down to **16** (from 44). I honestly don't see the value of doing a full squash, mainly because if we are hosting this in a premium ACR, the limit is 10,000 readOps per minute. So with 16 layers, you get around 625 pulls per minute. Also, this will be able to still take advantage of parallel pulls (default is 3, but at most 16 threads in this case, I believe) as opposed to one big layer which will not download in parallel. There's the potential of that being a lot slower and subsequent jobs falling into the same ""minute"" because others are not done, making it easier to hit that 10k readOps limit. Lastly, people using GATK outside data pipelines will not be able to take advantage of layer caching too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8808#issuecomment-2102891281:103,layers,layers,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8808#issuecomment-2102891281,3,['layers'],['layers']
Modifiability,"> While we're at it, can we rename all of the ""is_xxx"" variables?. @takutosato Agreed. I renamed them all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4238#issuecomment-360180392:55,variab,variables,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4238#issuecomment-360180392,1,['variab'],['variables']
Modifiability,"> Yes, GenotypeGVCFs prunes alleles that lack sufficient evidence. The force output intervals only guarantees that the site is emitted, but it may be emitted as monomorphic. OK, but I think my test shows that's not happening. In the --force-output-intervals case of testForceOutputNonRef(), all VCs in actualVC2 are not polymorphic. Despite this, some of them have alternate alleles? see the new test case I added at GenotypeGVCFsIntegrationTest line 614",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-577501077:320,polymorphi,polymorphic,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-577501077,1,['polymorphi'],['polymorphic']
Modifiability,"> Yes, setting the GATK_LOCAL_JAR and/or GATK_SPARK_JAR environment variables will cause the gatk script to use that jar, instead of looking in its directory for a jar. The naming of the jar itself also doesn't matter if you use the environment variable method. @droazen I think this leaves one more question: what about running locally? Since cromwell doesn't take in the docker image in that case (right?) wouldn't we need to pass in a pass to the gatk script?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3968#issuecomment-353610830:68,variab,variables,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3968#issuecomment-353610830,2,['variab'],"['variable', 'variables']"
Modifiability,"> number code, but personally I don't see the need to be extremely concise; > with short names and would prefer width.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646054>:; >; > > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; > + public static final String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; >; > binWidth would be a more readable variable name. There's nothing wrong; > with the command line argument and the variable being identical.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646097>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = true,; > + minValue = 0; > + ); > + private int padding = 0;; >; > This tool extends GATKTool, which means that it inherits an; > IntervalArgumentCollection that already includes a padding argument. A; > new one is not needed. BTW @samuelklee <https://github.com/samuelklee>; > does this come up elsewhere in the CNV code? It could be a holdover from; > the days of porting ReCapSeg when",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:2146,variab,variable,2146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211,1,['variab'],['variable']
Modifiability,"> user chooses a set of defaults but then overrides some of them, we should; > make it so they don't have to go digging through the logs to see what; > parameters are actually used in the end. Nor should they have to go back; > and check what the defaults were for whatever version of the jar they were; > using at the time. Option 2 might also make it easier to inadvertently; > override parameters, etc. via command-line typos or copy-and-paste; > errors---it's much more straightforward to require and check that every; > parameter is specified once and fallback to a default if not, as we do now.; > Not to say that we couldn't get around any of these issues in Barclay, but; > I think it'll require some thought and careful design. Would be interested; > to hear Engine team's opinions.; >; > Finally, one point that I think will become more relevant as our tools and; > pipeline become more flexible and parameterized: I think we should start; > thinking of ""Best Practices Recommendations"" less as ""here is the best set; > of parameters to use with your data"" and more as ""here is *how to find*; > the best set of parameters to use with your data (for a given truth set,; > sensitivity requirement, etc.)"". After all, if we are putting together; > pipelines to do hyperparameter optimization, there is no reason not to; > share them with the community.; >; > This would also relax the requirement that the defaults in the WDL (which; > have to be kept in sync with those in the GATK jar) represent some sort of; > Best Practices Recommendation, which is awkward in exactly scenarios like; > the one you highlight.; >; > @vdauwera <https://github.com/vdauwera> @LeeTL1220; > <https://github.com/LeeTL1220> @sooheelee <https://github.com/sooheelee>; > might have some thoughts.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385584289>,; > or mute the thread; > ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385677379:1970,flexible,flexible,1970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385677379,2,"['flexible', 'parameteriz']","['flexible', 'parameterized']"
Modifiability,">--af_of_alleles_not_in_resource: is this allele frequency used only in certain contexts, e.g. with matched normal analyses, or towards tumor sample variant alleles, etc.? I need to add to the doc details how this argument factors into calculations. This is the population AF assigned to a variant not found in the germline resource and is inversely proportional to the number of samples used to create that resource. For example, gnomAD contains about 16,000 wgs samples, or 32,000 homologs per locus. Thus the AF of an allele not found in gnomAD is probably 1/32,000 or less. This is useful because it lets us use absence from the germline resource as evidence that an allele is *not* a germline variant. >I need a sentence or two describing the new algorithmic improvement on the new Mutect2 integration over uncertainty. Since allele depths (ADs) are subject to statistical error -- i.e. the exact number of reads for an allele is a random variable -- alleles' allele fractions are not known. Previously, M2 estimated allele fractions ffrom the ADs and proceeded with the likelihoods calculation. Now M2 uses nifty math to account for the uncertainty in the allele fraction when calculating likelihoods. In statistical language (which *will* be familiar to a decent-sized minority of users) we marginalize over allele fractions instead of using a maximum likelihood estimate. >The WDLs do not include use of a contamination.table and so I did not include it in the commands. Is this something we want to nudge users to use, i.e. should I put in a sentence in the documentation section about the new tool CalculateContamination?. `CalculateContamination` is invoked inside the `Filter` task in mutect2.wdl. We want users to use the new tool. You might mention that in the interest of speed you can pass it `-L 1` to use only variants on chromosome 1, which gives a very good estimate in a couple of minutes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306107618:944,variab,variable,944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306107618,1,['variab'],['variable']
Modifiability,"@AJDCiarla . Ah, I see. Ok, so the reason was the following: I didn't use any 3rd party blockers or add-ons, but the Firefox has built-in ""enhanced tracking protection"" which I had to disable for it to work. I guess it's because of cross-site tracking required for this zendesk provider. ; Sorry, this was the first time it actually broke a website in 1-2 years of usage, so I didn't expect to be a culprit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8115#issuecomment-1337288833:139,enhance,enhanced,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8115#issuecomment-1337288833,1,['enhance'],['enhanced']
Modifiability,"@Aqoolare Hello. There are a a few things going on here. The `unrecognized runtime attribute keys` warning is coming from cromwell. It's telling you that the cromwell **local** backend doesn't understand those keys, which is true. That means it's just ignoring them. I think the actual problem is different though. You're running the spark tool in spark local mode, which in this case isn't configured to use the correct amount of cores or memory. I think the intent of this wdl script was that it would be run in a container on a cluster and the container would restrict the cores and memory options. In any case, it's not configured correctly for what you need. I would skip running cromwell and just invoke gatk directly since this wdl only executes a single job. Since this is going to run spark in local mode you need to specify the number of cores using the `--spark-master` argument, and set the memory using the `--java-options ""-Xmx""` arguments. For example:. ```; gatk ReadsPipelineSpark ; --java-options ""-Xmx16G"" ; --spark-master 'local[8]'; --I yourbam.; ... etc; ```. The above command is specifying to use 8 (that's what the local[**8**] means) cores for spark and give it 16G of memory. Your job was accidentally using 200 cores so it doesn't surprise me that it would run into memory issues. Using spark with more than 16ish cores in a single process is going to bog down a lot. I think 8 is a good starting place to try. If you want to go wider you should really look into running a proper cluster (or using dataproc), but there's pretty heavy diminishing returns. Try 8 or 16 and tune the memory from there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7796#issuecomment-1108913771:391,config,configured,391,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7796#issuecomment-1108913771,2,['config'],['configured']
Modifiability,"@DanishIntizar Hello! Thank you for this pr. This is great to see an official plugin from amazon available. I appreciate that you took the time to make it an optional include. I think if we're going to include it we might as well just add it as one of our normal dependencies though. Assuming there aren't any dependency conflicts it **should** (always a risky statement) be independent from everything else. . Thanks also for identifying the different issues you mentioned. It's expected that it won't work with most picard tools as you discovered, but we're actively in the process of updating more of them too support Paths instead of Files so that will slowly improve. The second issue is more worrisome. We regularly use an equivalent provider with google to read reference files through the exact same code, so I suspect there is either some sort of mismatched assumptions in the way they are handling things. Maybe something strange with the Path.resolve methods or the like. (Or in in the much worse potential case a bug in their look ahead caching.). I'd like to look into that before we'd merge this. Ideally we would have tests for this. Are there any public AWS paths we could read from without any secret authentication?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8672#issuecomment-1930094721:78,plugin,plugin,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8672#issuecomment-1930094721,1,['plugin'],['plugin']
Modifiability,"@DarioS ; In general we don't see this kind of behavior. Can you provide the names of these threads and the command line you are using the run M2?. One possibility is that you are running in a JVM configured with a small amount of RAM. . Consider running the JVM with -Xms2G -Xmx5G, this should be sufficient for most M2 runs. I typically run with lower amounts of RAM for a single core, but there may be something about your data that is requiring a larger amount than what we normally see. Is there anything unusual about your data?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7156#issuecomment-803595912:197,config,configured,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7156#issuecomment-803595912,1,['config'],['configured']
Modifiability,@DarioS Thanks for reporting this. It seems like there is an object in the tool which accumulates a record for every variant in the -V input. Since you're using gnomad it's very large. This is a design issue and seems like it should be fixed to stream the output instead of accumulating it all in memory and then dumping it at the end. @davidbenjamin I aimed this at you since it seems like it's your tool. From a lazy glance it seems like it should be doable to rewrite it to stream output instead of keeping it all in memory.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7606#issuecomment-1004309450:463,rewrite,rewrite,463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7606#issuecomment-1004309450,1,['rewrite'],['rewrite']
Modifiability,"@KPS-Malpe To start it would be useful to know what commandline you used, what version of GATK you're using, basic configuration info like that. If you could include the output of the commands you ran that could also be pertinent. It is interesting that not all the intervals you specified in your bed file show up in the Genomicsdb workspace. Along the lines of the question asked by @droazen, I presume you checked that the missing intervals do actually have data in the gvcfs?. Lastly, you could try running SelectVariants on the Genomicsdb workspace -- that should return the data that was ingested into the genomicsdb, i.e., matching the input gvcfs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7952#issuecomment-1196207156:115,config,configuration,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7952#issuecomment-1196207156,1,['config'],['configuration']
Modifiability,"@LeeTL1220 . This seems to be running into a cromwell / WDL error:. ```; java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); ```. Isn't cromwell supposed to handle `gs://` URLs for localizing files? Do you have any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556:762,config,configure,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556,1,['config'],['configure']
Modifiability,"@LeeTL1220 It sounds like you're suggesting two things. . First, if a datasource config has a space in it, throw an error and tell the user to remove the space. . Second - remove spaces from funcotation field names when outputting the funcotations (could still happen with XSVs with spaces in column headers). Is this correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5937#issuecomment-507298072:81,config,config,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5937#issuecomment-507298072,1,['config'],['config']
Modifiability,"@MattMcL4475 We've merged a PR that reduces the number of layers in our docker image from 44 down to 16: https://github.com/broadinstitute/gatk/pull/8808. See comments on that PR for reasons why this approach might be preferable to a full squash. If there are still too many layers for your use case, please feel free to reopen this ticket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-2103231924:58,layers,layers,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-2103231924,2,['layers'],['layers']
Modifiability,@PlatonB I agree that this would be a nice feature. We're currently refactoring GATK to use a new type for tool inputs that may eventually enable us to support stdin as an input. @cmnbroad Can you comment on the feasibility of adding stdin support once the path migration is complete?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6749#issuecomment-679301688:68,refactor,refactoring,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749#issuecomment-679301688,1,['refactor'],['refactoring']
Modifiability,@RWilton I agree that this is a confusing filter and maybe should be renamed... As I have said this is a specific utility is for SVs where they might only want to look at long range read pairs not HaplotypeCaller. In that context I would say that the nuance about TLEN vs left aligned start position is a relatively small one. I agree with you that it would be useful to have some functionality for filtering out highly distant read pairs form our short variant calling as an option. I would have to think on whether its better to refactor this filter to be more general or to make a second filter that is the reverse of this one. . @RWilton can you make an issue ticket and describe what you would want out of such a filter for HaplotypeCaller? I would put some thought into the case where the TLEN field has not been populated since it often isn't (especially since the cases where TLEN might not get computed overlaps with discordant/distant mates which are part of the target for such a filter).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1104014142:531,refactor,refactor,531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1104014142,1,['refactor'],['refactor']
Modifiability,"@SHuang-Broad can you create two new issues, for 1) the error you saw on one of the runs about the missing bwa index file -- maybe we could verify that it's there on all the nodes or do retries and 2) the variability in the number of kmers found and variants discovered? You can assign the latter one to @tedsharpe .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294157463:205,variab,variability,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294157463,1,['variab'],['variability']
Modifiability,@SHuang-Broad does this refactor to the inversion filter look better?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-243196129:24,refactor,refactor,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-243196129,1,['refactor'],['refactor']
Modifiability,@SHuang-Broad refactored some code in response to your comments. how does this look now?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-243457466:14,refactor,refactored,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-243457466,1,['refactor'],['refactored']
Modifiability,"@Stikus Yes, this is expected, and is mentioned in the release notes for 4.1.8.0:. * More flexible matching of dbSNP variants during variant annotation (#6626); * Add all dbsnp id's which match a particular variant to the variant's id, instead of just the first one found in the dbsnp vcf.; * Be less brittle to variant normalization issues, and match differing variant representations of the same underlying variant. This is implemented by splitting and trimming multiallelics before checking for a match, which I suspect are the predominant cause of these types of matching failures. For more details see the original pull request here: https://github.com/broadinstitute/gatk/pull/6626",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6690#issuecomment-653119026:90,flexible,flexible,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6690#issuecomment-653119026,1,['flexible'],['flexible']
Modifiability,"@Stikus right, if you take a look at the PR, you’ll see that only defaults for certain arguments of the FilterIntervals, DetermineGermlineContigPloidy, and GermlineCNVCaller tools were changed. So if you just manually specify the old values for these arguments, hopefully that should reproduce your previous results. Take care to make the appropriate changes to both COHORT and CASE modes for the latter two tools. It’s possible that this could be easily done in some kind of config file, e.g., if your pipeline is implemented in WDL you could just make the appropriate changes to your JSON config files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1857781749:476,config,config,476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1857781749,2,['config'],['config']
Modifiability,"@TedBrookings which formats are you using, in particular? If there is a format out there that nicely fits our needs, we should adopt it. In the CNV package, I've taken pains to unify how tabular data are represented in Java, depending on whether each record is Locatable or whether the collection of records can be associated with a sample name or sequence dictionary. This allows us to represent records that extend Locatable with *multidimensional numerical or non-numerical annotations* along with some metadata (sample name and sequence dictionary) with a minimum of boilerplate. There are also base methods for producing interval trees, etc. This pretty much satisfies all of the CNV team's needs (and is, in my opinion, a necessary improvement over the horrowshow of read/write utility methods for each file format that we had previously...). However, this unification effort was a quick push I made before release, so some polishing or redesigning may be warranted. We may also want to add more forms of metadata, etc. if other teams would require more features. Another downside is that this code lacks the indexing, NIO support, etc. that some of the other standardized/Tribble formats enjoy. For CNV data, this isn't a huge issue, but I think it would be nice to unify how we represent such data GATK-wide. As I said above, I don't think VCF is the correct answer, but certainly it could fit into whatever framework we adopt or come up with.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468:410,extend,extend,410,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468,1,['extend'],['extend']
Modifiability,"@Unip0rn Thank you for the pr. I'm not sure I understand what you're trying to do here though. currently when I run `./gatk --list` it prints the list of gatk tools. ex:; ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the --",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:442,adapt,adapters,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030,1,['adapt'],['adapters']
Modifiability,@Z-Zen It wouldn't be to hard to make the precision of the numbers configurable. How would you propose to be able to specify it that would be best for you? What is the use case in which you need more decimal places?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7699#issuecomment-1054457277:67,config,configurable,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7699#issuecomment-1054457277,1,['config'],['configurable']
Modifiability,"@akiezun Instead of adding these overloads would we see the same speedup if we cached the result of isUnmapped and isPaired in the adapter? That would have the downside of complicating the adapter but it might avoid adding these strange methods to the interface. . If caching seems like a bad alternative, I think maybe these methods should have names that make it clear that they're some sort of performance hack and you should generally prefer the standard ones. 'getContigUnsafe` for instance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235101307:131,adapt,adapter,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235101307,2,['adapt'],['adapter']
Modifiability,"@akiezun Yes, it's true that there's no way to prevent that, short of doing deep copies every time a read is wrapped in an adapter. But we can make it clear in the GATKRead contract that the backing reads should not be directly modified after wrapping within an adapter, and if they are they need to be re-wrapped in a new adapter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235291718:123,adapt,adapter,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235291718,6,['adapt'],['adapter']
Modifiability,"@ambarishK Could you provide your WDL script and point us to which tasks were configured with a GATK docker, which steps run, and which steps fail?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5906#issuecomment-583802837:78,config,configured,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5906#issuecomment-583802837,1,['config'],['configured']
Modifiability,"@apete Thanks for the PR! That's really helpful to update and any svd improvements are definitely something we want. . It's failing to build though, because it can't locate `ojalgo-extensions-1.0.0`. I get the following error:; ```; Build file '/Users/louisb/Workspace/gatk/build.gradle' line: 511. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Could not resolve all dependencies for configuration ':runtime'.; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; Required by:; project :; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://repo1.maven.org/maven2/org/ojalgo/ojalgo-commons-math3/1.0.0/ojalgo-commons-math3-1.0.0.pom; > Could not find org.ojalgo:ojalgo-extensions:1.0.0.; Searched in the following locations:; https://repo1.maven.org/maven2/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://repo1.maven.org/maven2/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; https://jcenter.bintray.com/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://jcenter.bintray.com/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; file:/Users/louisb/.m2/repository/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; file:/Users/louisb/.m2/repository/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://jcenter.bintray.com/org/ojalgo/ojalgo-commons-math3/1.0.0/ojalgo-commons-math3-1.0.0.pom; > Could not find org.ojalgo:ojalgo-extensions:1.0.0.; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-351825206:412,config,configuration,412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-351825206,1,['config'],['configuration']
Modifiability,"@asmirnov239 I think that some of the optimizations that @vruano made to the postprocessing step concern the config JSONs, gCNV version, and interval list output added in #5176. These take a lot of time to localize when the number of shards is large but, aside from the interval list, aren't really used for anything, correct?. Were these just added for debugging purposes, or for reproducibility/provenance? Let's revisit whether it's necessary to pass these files on when we merge @vruano's changes into the canonical WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-472862393:109,config,config,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-472862393,1,['config'],['config']
Modifiability,"@asmirnov239 I'm getting the same error on Terra when bam files and their indices are not in the same location. I'm running https://github.com/broadinstitute/gatk/blob/4.1.7.0/scripts/mutect2_wdl/mutect2_pon.wdl. The workflow input for bam index seems to be just a placeholder, if you follow the variables along the wdl it's never actually used.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487#issuecomment-1697767879:296,variab,variables,296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487#issuecomment-1697767879,1,['variab'],['variables']
Modifiability,@asmirnov239 and Jack Fu are currently developing tests using Talkowski-SV truth that will ultimately cover #5633. Should be adapted to fit into whatever framework arises from #4630.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-459834130:125,adapt,adapted,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-459834130,1,['adapt'],['adapted']
Modifiability,"@bbimber I did start to take a look at this today. We'd probably take many of the peripheral classes from GATK3 as they are (though there will be some exceptions, i.e., `VariantEvalUtils` calls `System.exit`, which we wouldn't want to do). And in some cases we may want to make tickets for places where we want to do refactoring, like we did for MendelianViolations. The code will need to conform to GATK4 in some areas (use hyphen-separated argument names, updated javadoc where it's GATK3-specific, etc). The easiest way to do this would be to add a commit with the raw GATK3 code as I mentioned above. We would then focus on reviewing the diffs, instead of line-by-line for all of the code. I can add that commit if you like - we'd just need to coordinate since I would have to push to your branch. Also, FYI, I'll be away all of next week so I won't be able to do any more on this until I return.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-413988997:317,refactor,refactoring,317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-413988997,1,['refactor'],['refactoring']
Modifiability,"@bbimber Nice to virtually meet you too. I think we've probably interacted once or twice in the past as well. I'm glad to hear you're planning on using and extending Funcotator! It would be great if you could push back the useful changes you make. FYI - come the new year, I'm going to be refactoring several things in the Funcotator core that will make it much more extensible (mostly around GTF parsing). I'm also going to fix a few bugs involving variants that span transcript and contig boundaries. It's been a long time coming - I've just been working on a set of high-priority tasks that needed my attention. Also - Funcotator is production-ready for human data, so it should basically be ""guaranteed stable"" (modulo certain known issues like the ones I referenced above).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1355036390:156,extend,extending,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1355036390,2,"['extend', 'refactor']","['extending', 'refactoring']"
Modifiability,"@bbimber The `GATKAnnotationPluginDescriptor` uses the GATK config file to find packages that contain annotation classes, and will automatically discover annotation classes that are in packages listed there (see [this](https://github.com/broadinstitute/gatk/blob/f4996564f0abe02b6a202eaff402c2f3fa044633/src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKAnnotationPluginDescriptor.java#L46) and [this](https://github.com/broadinstitute/gatk/blob/master/src/main/resources/org/broadinstitute/hellbender/utils/config/GATKConfig.properties#L77)).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-720551282:60,config,config,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-720551282,2,['config'],['config']
Modifiability,"@bbimber This looks like a good change, but I don't think it'll solve the problem. The `XsvLocatableTableCodec` works differently than other codecs. It was essentially created for Funcotator datasources, and it expects to be given a `.config` file rather than the XSV file itself. For example, if you wanted to index the Oreganno data source file, you'd need to first create a funcotator configuration file adjacent to it, and then use `IndexFeatureFile` to index the config file rather than the tsv. This is not a good design (my fault), but it's how the tool operates as of right now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591483042:235,config,config,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591483042,3,['config'],"['config', 'configuration']"
Modifiability,"@bbimber This this looks pretty good now - I don't have any new substantive comments. We just need to get the other PRs in and the tests passing and this should be good to go. There is one outstanding thing that would be nice, but I'll leave it up to you as to whether you want to address it. `VariantStratifier` and it's subclasses still have `initialize` methods that take no arguments. As far as I can tell, this is unnecessary now that they are required to have a constructor that take a `VariantEvalEngine`. If you feel so inclined, the `initialize` content can be moved into the constructors, and the initialize method, and call to it, can be eliminated (BTW, the constructors in those classes should be moved to be after the variable declarations). Overall, though, I think this PR makes a pretty big improvement to the state of things. Thanks for doing it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-775474714:732,variab,variable,732,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-775474714,1,['variab'],['variable']
Modifiability,@bbimber You also have the option of bundling your custom config file inside your DISCVRseq jar -- that way you don't need to supply it on the command line,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-720615025:58,config,config,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-720615025,1,['config'],['config']
Modifiability,"@bhanugandham As a side note, you shouldn't be running GATK4 using `java -jar` directly. You should use the included `gatk` launcher script, which sets a lot of important configuration settings, some of which have a major effect on tool performance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485873403:171,config,configuration,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485873403,1,['config'],['configuration']
Modifiability,"@bhanugandham This message itself is harmless and won't affect results directly, but it can mask warning/error messages coming from Jexl (such as missing variable names!). I wouldn't expect a user to see it when running from a normal installation, and I'm not sure why it seems to be intermittent. I'll need to do some debugging.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4637#issuecomment-439434139:154,variab,variable,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4637#issuecomment-439434139,1,['variab'],['variable']
Modifiability,"@byoo Thanks, we will fix that one ASAP. By the way, we are doing a big refactoring of Mutect2 filtering, which won't change the outputs but will improve the internal software engineering so that we can write better unit tests to catch these sorts of things.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452851947:72,refactor,refactoring,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452851947,1,['refactor'],['refactoring']
Modifiability,"@byoo We run the M2 wdl without modification on a Broad SGE cluster for our internal evaluations all the time. A cromwell config file for SGE is required, but that's the case for every backend. You *do* need to supply a gatk docker image string as an input, but it is ignored. Please feel free to share your input json and config file if it doesn't work for you. I can't say I'm skilled enough to catch anything subtle, but I can check for obvious differences.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358960833:122,config,config,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358960833,2,['config'],['config']
Modifiability,"@ccastane9, looks like a memory issue. Some questions -. 1. What are the sizes of the book-keeping files in your GenomicsDB workspace? Try running `find /ECA3_GenomicsDB_260 -name __book_keeping.tdb.gz -ls`.; 2. Is /ECA3_GenomicsDB_260 on NFS or another shared Posix FS? Can you try running GenotypeGVCFs with `--genomicsdb-shared-posixfs-optimizations` turned on?; 3. What does your hardware configuration look like, memory wise?; 3. What are your `-Xmx` and `-Xms` java options?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-754244432:393,config,configuration,393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-754244432,1,['config'],['configuration']
Modifiability,"@chandrans @chapmanb @ldgauthier The `-ploidy` argument is one of several arguments inherited from `AssemblyRegionWalker` that apply only to `HaplotypeCaller` and do nothing in `Mutect2`. (We should refactor this once the engine team's workload lightens enough to review lower-priority things like this.) The `GT` field emitted by Mutect is just the concatenation of all called alleles -- 0/1, 0/1/2, 0/1/2/3 etc -- and doesn't imply anything about the ploidy. Maybe we should get rid of it entirely since `AF` is so much more informative. I like the idea of splitting multiallelics into multiple lines. It would make filtering a lot easier. @LeeTL1220 do you have an opinion?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330401348:84,inherit,inherited,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330401348,2,"['inherit', 'refactor']","['inherited', 'refactor']"
Modifiability,@chapmanb As far as I know Spark (and Hadoop) needs the user name to submit a job. Can you set the `SPARK_USER` environment variable to the user you would like to use (even if it is not in /etc/passwd)? You should be able to pass it to Docker with the `-e` option. (I haven't tried this to see if it works.),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-379226226:124,variab,variable,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-379226226,1,['variab'],['variable']
Modifiability,"@chapmanb Do you have any control over the `docker run` command? If you do, you could mount `/etc/passwd`/`/etc/shadow` as external resources into the container (as described here, for example: `https://stackoverflow.com/questions/33013444/can-not-add-new-user-in-docker-container-with-mounted-etc-passwd-and-etc-shado`) . This seems slightly less awful than the workarounds you linked to above. It seems to me, however, that running as a user not present in `/etc/passwd` could cause quite a few things to fail, not just Spark. Perhaps you should file a bug report against these CWL runners? They should really be configuring the runtime environment in the container properly for the username they force you to run under! If they are trying to mirror the external user within the container, they should probably mount the external `passwd` file into the container on your behalf when executing `docker run`. @tomwhite Do you happen to know of a workaround on the Spark side to prevent it from doing a username lookup?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-379060749:615,config,configuring,615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-379060749,1,['config'],['configuring']
Modifiability,"@chapmanb Singularity's default configuration has a line ""config passwd = yes"" and that will create a user entry in the /etc/passwd automatically. So it I understand the issue, spark would automatically find the user running the container in the /etc/passwd file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-382483335:32,config,configuration,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-382483335,2,['config'],"['config', 'configuration']"
Modifiability,"@chatchawit Thanks. From the stack trace it looks like another issue that I'm actually currently working on. I'm not sure when it will be done, but I'm going through it as part of fixing #4739 (it's an aggravating bug that will require some refactoring).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391468128:241,refactor,refactoring,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391468128,1,['refactor'],['refactoring']
Modifiability,"@cmnbroad , I've done the suggested refactoring and documentation changes.; Can you take a look again please? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4981#issuecomment-405582729:36,refactor,refactoring,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4981#issuecomment-405582729,1,['refactor'],['refactoring']
Modifiability,"@cmnbroad - I agree that we can add it as an `@Advanced` agument/filter, and clarify in the documentaion (javadoc for barclay-generated pages and in the argument itself) the purpose of this filter, but I would like to have this as a general purpose filter in `ReadTools` and thus picked by the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5367#issuecomment-434579278:294,plugin,plugin,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5367#issuecomment-434579278,1,['plugin'],['plugin']
Modifiability,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:75,config,configurable,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,2,['config'],"['configurable', 'configuring']"
Modifiability,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:202,config,configuration,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828,5,['config'],['configuration']
Modifiability,"@cmnbroad - what is the timeframe for a common CLP class? Because in the meantime it would be nice to be able to add picard tools, and anyway the common CLP would require refactoring in `Main`. So is it too much problem if I add a temporary method to add single picard tools?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4660#issuecomment-384224234:171,refactor,refactoring,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4660#issuecomment-384224234,1,['refactor'],['refactoring']
Modifiability,"@cmnbroad : first - would it be possible to kick off travis tests? i refactored this and dont seem to be able to do that. Second, yes, I was trying to reorder and condense the commits but clearly didnt work. I think the problem was trying to put your GATK3 commit first (which would seem to make sense). in any case, I just recreated this, putting a pristine GATK3 first, following a consolidated set of my commits with 1) the limited core changes, 2) the meat of the VariantEval port, and 3) A separate commit with a port of GATK3 VariantEvalIntegrationTest which is useful for validation but should not be merged. To your points:. 1) I substantially cut down the incoming large files, mostly by limiting the intervals of new large VCFs. 2) On the plugin: this was discussed above, and I initially also pointed out this should ultimately go into Barclay. You are actually the one who proposed staging it in GATK. I am not entirely sure I understand the reticence on plugins; however, my goal is to get VariantEval ported by touching as little of it as possible. This is already sucking up a ton of time. I flipped VariantEvalUtils to gather a list of classes from the appropriate package instead of a full-on plugin. That should satisfy that concern?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431913735:69,refactor,refactored,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431913735,8,"['plugin', 'refactor']","['plugin', 'plugins', 'refactored']"
Modifiability,"@cmnbroad : if getStratifierClasses() is the only sticking point, we can drop that. . Stepping back: as you probably know we have a tool, VariantQC, which basically sets up a number of instances of VariantEval and uses them to aggregate data as it iterates a VCF. this allows the tool to capture data aggregated/stratified at multiple levels with one pass through the VCF. . There are two related aims:. 1) my tool needs to know the allowable stratification classes. Instead of copy/paste the reflection code to find classes, this PR was exposing that getter as a public method. I'm not sure I understand why this is a sticking point, but we can remove this without that much problem for me. Like we discussed earlier, VariantEval should get refactored into a walker class and some kind of VariantEvalEngine class, and this refactor might be a time to address my concern here. This is not actively blocking us. I could also make this a protected getter on VariantEval if the public aspect is what you dont like. 2) The remaining changes serve a different purpose. Most VariantEvaluator classes are 'dumb' in that they are instantiated with no configuration and always aggregate the same fields. In our tool, we wanted to let the user specify a list of INFO fields to aggregate (i.e. we dont know the target until runtime). We wrote an InfoFieldAggregator class, which is instantiated with the name of an INFO field. This lets our code create multiple instances of that VariantEvaluator, potentially summarizing different fields. The remaining changes are designed to enable this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5998#issuecomment-502946807:742,refactor,refactored,742,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5998#issuecomment-502946807,3,"['config', 'refactor']","['configuration', 'refactor', 'refactored']"
Modifiability,"@cmnbroad @lbergelson The cram index looks like it has all the info required to generate the splits without using the CramContainerIterator to look at the cram file directly. . Could using the crai index for splits be a potential solution to the glacially slow cram split generation? ; ; CRAM index. A CRAM index is a gzipped tab delimited file containing the following columns:; 1. Sequence id; 2. Alignment start; 3. Alignment span; 4. **Container start byte offset in the file**; 5. Slice start byte offset in the container data (‘blocks’); 6. Slice bytes; Each line represents a slice in the CRAM file. Please note that all slices must be listed in index file. In Hadoop-bam this code could read the crai instead of the cram to find the container boundaries. public List<InputSplit> getSplits(List<InputSplit> splits, Configuration conf); throws IOException {; // update splits to align with CRAM container boundaries; List<InputSplit> newSplits = new ArrayList<InputSplit>();; Map<Path, List<Long>> fileToOffsets = new HashMap<Path, List<Long>>();; for (InputSplit split : splits) {; FileSplit fileSplit = (FileSplit) split;; Path path = fileSplit.getPath();; List<Long> containerOffsets = fileToOffsets.get(path);; if (containerOffsets == null) {; containerOffsets = getContainerOffsets(conf, path);; fileToOffsets.put(path, containerOffsets);; }; long newStart = nextContainerOffset(containerOffsets, fileSplit.getStart());; long newEnd = nextContainerOffset(containerOffsets, fileSplit.getStart() +; fileSplit.getLength());; long newLength = newEnd - newStart;; if (newLength == 0) { // split is wholly within a container; continue;; }; FileSplit newSplit = new FileSplit(fileSplit.getPath(), newStart, newLength,; fileSplit.getLocations());; newSplits.add(newSplit);; }; return newSplits;; }",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699:822,Config,Configuration,822,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699,1,['Config'],['Configuration']
Modifiability,"@cmnbroad Back to you with a few nitpicks. Ready to merge when those are addressed. . I think there might be a few places that the metrics could be profitably refactored, but maybe we should wait until more exist to do so. The finish(..., ..., ...) methods seem like they should maybe be incorporated in to the base class somehow. Not necessarily as part of this PR though. Also, I noticed that MetricsCollectorSpark.saveMetrics() has a no-op default implementation. Why is that? It seems like it should be abstract.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2049#issuecomment-236974957:159,refactor,refactored,159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2049#issuecomment-236974957,1,['refactor'],['refactored']
Modifiability,"@cmnbroad Back you with a minor refactoring request. It seems to me that GATKTool should try and close it's own writers, but maybe there's a reason not to that I'm missing?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2046#issuecomment-237007660:32,refactor,refactoring,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2046#issuecomment-237007660,1,['refactor'],['refactoring']
Modifiability,"@cmnbroad Chris, could you update `Miniconda2` to `Mininconda3` in the docker config? here's the sh bundle + MD5:; ```; ENV CONDA_URL https://repo.continuum.io/miniconda/Miniconda3-4.3.30-Linux-x86_64.sh; ENV CONDA_MD5 = ""0b80a152332a4ce5250f3c09589c7a81""```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350194001:78,config,config,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350194001,1,['config'],['config']
Modifiability,"@cmnbroad Hope you had a good break. As you might have seen above, I refactored out VariantEvalEngine, which I think will address some of the problems, like passing the walker around, which you didnt like in the PR. . I might not have as good an eye over tests as you, but I believe the failures mostly relate to the change to set 'source' on the VCs. As you probably know, that means it's passed into the resulting VCF, and will change test expectations in some cases. You said someone at GATK was looking into that, but I would be happy to take a stab if your team has ideas on how to address this. If I'm missing test failures beyond that I can take a look.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-754015497:69,refactor,refactored,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-754015497,1,['refactor'],['refactored']
Modifiability,"@cmnbroad I agree disabling some of the functionality should probably be done, I'll consider that a review comment. As to generalizing this disabling of the founderIDs, I would ere on the side of not doing it, since at the very least right now all the pedigree arguments are being populated by the plugin manager and not the annotations. I wouldn't know what to do in the case where the user asked for a pedigree annotation that did take founderIDs and one that didn't, how should that be resolved? As of right now the pedigree file and founderIDs get merged which seems sensible for other tools. Perhaps emit a warning for PossibleDenovo?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463278863:298,plugin,plugin,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463278863,1,['plugin'],['plugin']
Modifiability,@cmnbroad I moved this message so it runs during the actual task execution rather than at configuration time.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881:90,config,configuration,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881,1,['config'],['configuration']
Modifiability,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:12,refactor,refactored,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432,2,['refactor'],['refactored']
Modifiability,"@cmnbroad I responded to your comments, what do you want to about names? Do you think we should refactor the haplotype caller tests to run with all the types of I also bumped to a more stable looking version of native bindings while I was at it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3600#issuecomment-331546971:96,refactor,refactor,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3600#issuecomment-331546971,1,['refactor'],['refactor']
Modifiability,"@cmnbroad I see. The ""CI"" variable does seem brittle, especially since I'm not strictly sure where it is set. I think a somewhat safer place would be to add some global test flag to the docker image would be to add it to the run_unit_tests.sh script. That way we know it is getting triggered exactly before we run the tests in just the docker environment. Is there some way of detecting what conda environment is active outside of conda.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354:26,variab,variable,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354,1,['variab'],['variable']
Modifiability,"@cmnbroad OK - I think I addressed your review and also added a sizable amount of 'final', including to pre-existing code. . I did not do the refactor of eval/comp/gold-standard from VariantEvalArgumentCollection back into VariantEval. I see your point and am not totally opposed to it, but put a question on that thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-749844101:142,refactor,refactor,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-749844101,1,['refactor'],['refactor']
Modifiability,"@cmnbroad OK, considerable progress here. I was able to adjust behavior such that only two tests have changed behavior from GATK4/master. I think this is now correct. One instance of changed behavior is the Snpeff/overlap one we discussed above. The second is the one where we now provide the full genome as REF, not the truncated genome. I think this difference is justified since the tool now requires a reference, and the prior version was arguably too lenient on validation of contigs. Anyway, this branch now also removes by debugging code and comments. I think it is ready for a review. To some other questions you had above:. 1) The HashMap<FeatureInput<VariantContext>, HashMap<String, Collection<VariantContext>>> can be wrapped in a class with just a couple of methods, so we don't have to manifest that long type all over the place. I realize that's non-optimal, but this isnt anything I introduced here. I would really like to keep this PR as limited as we can, and address some larger refactoring in a different PR, once we've migrated to MultiVariantWalkerGroupedOnStart. 2) I know this PR still in an interim state, but passing the VariantWalker in as an argument to the comp methods doesn't seem like a step forward to me. If we can't solve that problem completely in this PR (which is fine, I'm all for trying to contain this), are those changes necessary ? Perhaps that part should just wait for the next round. As noted above, I'd like to propose this as iterative, with a second PR coming soon. I did this b/c it moved us toward not needing to pass around the walker. It minimizes the code that has access to the walker (as opposed to setting it after creating the instance of the Evaluator, etc. Yes, it exposes it for two methods, but those classes no longer hang on to it. I would like to ultimately remove this entirely. 3) To re-iterate testEvalTrackWithoutGenotypesWithSampleFields: the input file, noGenotypes.vcf, has a header dictionary with the full set of contigs, and ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747619130:998,refactor,refactoring,998,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747619130,1,['refactor'],['refactoring']
Modifiability,"@cmnbroad OK, so I see that I can supply a custom --gatk-config file on the command line, and I suppose I would also provide my other JAR on the classpath with my additional VariantAnnotation classes? That is useful, but also a little unclean given I am already building our DISCVRseq JAR, which includes the GATK4 dependency. I'm still inclined to make our tool that extends GATK's VariantAnnotation, and override makeVariantAnnotations(). I could either manipulate GATKAnnotationPluginDescriptor, or make my own to scan the expected package(s). It seems pretty surgical and less would be required of the user to run it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-720610784:57,config,config,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-720610784,2,"['config', 'extend']","['config', 'extends']"
Modifiability,"@cmnbroad OK, thanks. I need to do more investigation, but my initial thoughts/investigation were two-fold:. 1) Our main use-case if our VariantQC tool, which makes several instances of VariantEval in kind of a hacky way and calls apply() on them. Therefore refactoring a VariantEvalEngine out of VariantEval has value on this front, even if tricky. 2) From what I could tell, the worst perf is the iteration pattern. Using something like MultiVariantWalkerGroupedOnStart would be a big savings and avoid re-querying the component VCFs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5439#issuecomment-720617033:258,refactor,refactoring,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5439#issuecomment-720617033,1,['refactor'],['refactoring']
Modifiability,"@cmnbroad OK, that's what I was afraid of. Has your group given thought to how barclay might attempt to de-convolute ""identical"" arguments defined across diverse plugins like this? . Anyway, I can try to follow the pattern of pedigree. I was trying to avoid special-casing these arguments, but I am already making my own PluginDescriptor anyway. My use-case is effectively to have a VariantAnnotator that supports more annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7213#issuecomment-823493118:162,plugin,plugins,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7213#issuecomment-823493118,2,"['Plugin', 'plugin']","['PluginDescriptor', 'plugins']"
Modifiability,@cmnbroad Thank you for your help with this branch. I will be happy to give a speedy review to your proposed refactoring branch once this gets in.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-472576463:109,refactor,refactoring,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-472576463,1,['refactor'],['refactoring']
Modifiability,@cmnbroad Thank you! I confirmed the speedup is not contigent on the environment variables.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476850732:81,variab,variables,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476850732,1,['variab'],['variables']
Modifiability,"@cmnbroad The path to the c++ compiler can be specifically provided to theano by setting `theano.config.cxx` in python scripts, or by creating a `.theanorc` in the home directory, or by setting the environmental variable `THEANO_FLAGS=cxx=<path_to_g++>,...`. If a working c++ compiler exists and provided to theano, it is fair to assume that the graph _will_ compile. If the c++ compiler is not explicitly specified, theano will try to discover it. It first tries to execute `g++ -v` in the present environment and if it succeeds, it resolves the absolute path to the executable. On darwin, it further searches for `clang++` and on Win32, it looks for a working mingw gcc setup. We could _enforce_ the presence of a c++ compiler at the beginning of all python scripts and throw an exception and an informative message instead of numpy/python fallback. If we do so, the integration tests (and all gCNV CLI tools) will fail and will force the user to install a c++ compiler. In your opinion, is this fail-fast strategy a better approach, given that python fallback runs 2~3 orders of magnitude slower?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350193484:97,config,config,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350193484,2,"['config', 'variab']","['config', 'variable']"
Modifiability,"@cmnbroad Worth a try. Do we understand the underlying issue, though? If it's just the static initializer in `BaseTest`, perhaps we could refactor that into a `@BeforeSuite`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330888023:138,refactor,refactor,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330888023,1,['refactor'],['refactor']
Modifiability,"@cmnbroad and @jonn-smith Thanks! It now says ""First-time contributors need a maintainer to approve running workflows"" - does something else need to be approved? I'm not actually a first-time GATK contributor, but I'm not sure how that logic is determined/enforced. I dont have merge privileges' either. @jonn-smith: good to virtually meet you. As I alluded to above, my goal is to extend funcotator to make a new output format that more or less takes the annotations and writes them as discrete INFO fields, rather than the concatenated string. This PR will hopefully largely unblock us. As this develops, do you have any interest in us trying to contribute features back into GATK, or should be just keep separate. There may also be a handful of more minor extensions as we use this more, such as adding a config option to include/exclude specific VCF INFO fields, rather than always transfer 100% of them (which appears to be behavior today, but I just reviewed briefly). Obviously these would be case-by-case, but I'm happy to try to push features back here if you have interest/time in reviewing them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1353346614:382,extend,extend,382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1353346614,2,"['config', 'extend']","['config', 'extend']"
Modifiability,"@cmnbroad could the failing WDL test simply be due to some Spark configuration issue, rather than memory? Locally, for both 1) the WDL test within the Docker and 2) CreateReadCountPanelOfNormalsIntegrationTest using 17.0.3 without the Docker, I seem to hit the exception discussed here: https://stackoverflow.com/questions/72724816/running-unit-tests-with-spark-3-3-0-on-java-17-fails-with-illegalaccesserror-cl. Not sure why CreateReadCountPanelOfNormalsIntegrationTest seems to pass in the CI environments, but perhaps it'll be more obvious to you?. Just for context, note that this tool relies on the Spark MLlib implementation of PCA.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1409180990:65,config,configuration,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1409180990,2,['config'],['configuration']
Modifiability,"@cmnbroad hi chris - sorry to ping you directly here, but does GATK have someone watching PRs? we're hoping to extend funcotator and this PR has some very minor changes from private->protected to enable that. is this something GATK would consider?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1352245629:111,extend,extend,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8124#issuecomment-1352245629,1,['extend'],['extend']
Modifiability,@cmnbroad rebased and reverted the dockerfile. Tests pass locally. I'm also running a test in the cloud to see the impact of environment variables on speedup.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476752829:137,variab,variables,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476752829,1,['variab'],['variables']
Modifiability,"@cmnbroad thanks for the review. I think addressed all comments except the arguments/weights simplification, which I would prefer to save for the PEP8 refactor we discussed. Back to you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5175#issuecomment-426366833:151,refactor,refactor,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5175#issuecomment-426366833,2,['refactor'],['refactor']
Modifiability,"@cmnbroad 👍 to adding an advanced command line option for it. . @magicDGS Our goal is to make it unnecessary for normal users to ever need to see a stacktrace. We're definitely not at the point yet where every UserException produces either a) the complete information necessary to debug, or even b) the correct information. We're trying to fix all those cases, but there's a lot of possible failure modes between cloud access, spark, filesystem plugins, etc, so it's going to be an issue for a while. . I don't think it will hurt the user experience to have an extra commandline argument for it. Printing the stacktrace when debug is on isn't a bad idea, but I think it's better to have finer grained control over it. . The other issue is that it's easier to explain to an unsophisticated user how to set an extra commmand line argument rather than trying to get them to set the environment variable which well be helpful for our support team when they're trying to debug someone's problem. (especially since setting the environment variables may be different on a spark cluster than on a local run).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285390394:445,plugin,plugins,445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285390394,6,"['plugin', 'variab']","['plugins', 'variable', 'variables']"
Modifiability,"@cmnbroad, that's not wholly unreasonable, but i'd like to push back on a number of these points. . 1) First - would GATK consider simply letting us take over VariantEval and maintain as a GATK4-based tool in another repo? My understanding from GATK4 issues is that plan was to never migrate VariantEval (i think in favor of other picard/gatk QC tools). There is a bit of a conflict between keeping a lean core engine and having all these tools built off it. I would think there's an argument for keeping your core engine and the many tools built off it separated (GATK3 seemed to include some dead tools, for example). I appreciate we're the ones pushing this migration, but I hope on the other side you can appreciate the bar is pretty significant on our time. . 2) What new plugins are you talking about? VariantStratification and VariantEvaluator are part of GATK3's VariantEval? Yeah, I wrote a base PluginDescriptor class patterned on how ReadFilters work. It probably should exist in a more core position in code. While there's some good ideas in the argument-parsing/plugin code of GATK/Barlcay, frankly seems like much of it isnt fully developed yet, which is why I kept this separated at the moment. . 3) Be aware, the GATK3 tests depend on ~30GB of files. I dont know the limits of git lfs, but I did not currently have plans to check those in. I assumed I would convert these to use GATK4 chr20/21 data for a final commit, but felt there was a lot of value in using unaltered GATK3 data to confirm parity (and it was during the migration).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407123968:777,plugin,plugins,777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407123968,5,"['Plugin', 'plugin']","['PluginDescriptor', 'plugin', 'plugins']"
Modifiability,"@cwhelan , I've addressed the comments in this commit. It's not very small due to the refactoring of `SVTYPE` and dealing with the new edge case cigars like `10S10I10M`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2376#issuecomment-278405353:86,refactor,refactoring,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2376#issuecomment-278405353,1,['refactor'],['refactoring']
Modifiability,@cwhelan I've made the suggested refactoring for breakpoint adjustment code.; Do you want to take a look again?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3571#issuecomment-338003549:33,refactor,refactoring,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3571#issuecomment-338003549,1,['refactor'],['refactoring']
Modifiability,"@cwhelan Thanks for the review! And I apologize for not clearly stating what problem is getting fixed here. I've addressed the comments in separate commit, changed the implementation, made more improvements that were discovered while reviewing the variants ; (https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest/tree/master/Evaluation/Analysis/masterVSfeature/notes.xlsx); The implemented fixes are:; * for removing the hard-coded/explicit mentioning of ""chr"" in non-canonical versions, it is now fixed in 5eff782e4d582d516004fba2cee7535d984b1540; * for contigs whose alignments paint ambiguous picture, i.e. multiple alignment configurations offer equally good explanation:; 	1. if only one configuration has all alignment with MQ above a specified threshold, it is favored; this is implemented in ecc31f5fbec4e524b401fc9474a3a1b7ab08c561; 	2. if one configuration has alignment to non-canonical chromosome that explains the contig better than would-be-event-inducing mappings to canonical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:639,config,configurations,639,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522,4,['config'],"['configuration', 'configurations']"
Modifiability,"@david-wb @popboy126 I'm having trouble reproducing the shutdown issue on our own cluster, I sometimes get the message `Shutdown hook called before final status was reported.` but the job status is SUCCEEDED. This happens if I run with the System.exit(0) or not. Could one of you test with this branch and let me know if it solves your issue? I think my cluster configuration must be different then yours in some way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125:362,config,configuration,362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125,1,['config'],['configuration']
Modifiability,@david-wb Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368:21,plugin,plugin,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368,2,['plugin'],['plugin']
Modifiability,"@davidadamsphd Sure, here is a quick guide to the code:. -`BaseRecalibratorSpark` is the standalone BQSR tool, and calls into the `BaseRecalibratorSparkFn` (which is also called from `ReadsPipelineSpark`). -`ApplyBQSRSpark` is the standalone ApplyBQSR tool, and calls into the `ApplyBQSRSparkFn` (also called from `ReadsPipelineSpark`). -Integration tests for the above are in `BaseRecalibratorSparkIntegrationTest` and `ApplyBQSRSparkIntegrationTest`. -Almost all other changes in the branch are related to the BQSR engine refactoring, which I summarize below:; - We pulled out the guts of the walker `BaseRecalibrator` tool, combined it with all of the code from the former `RecalibrationEngine` class (now deleted) to make a new `BaseRecalibrationEngine` class under `utils/recalibration`.; - We stripped out all copies of the code in `BaseRecalibrationEngine` from the walker, dataflow, and spark versions of BQSR, and modified them to call into `BaseRecalibrationEngine`.; - We moved all auxiliary classes needed by the `BaseRecalibrationEngine` (eg., the covariates, etc.) into `utils/recalibration`.; - We refactored the argument collections. Now there is a single shared `RecalibrationArgumentCollection` that contains **only** the parameters for the `BaseRecalibrationEngine` itself, and this argument collection is exposed by all 3 versions of the tool. Input/output arguments have been removed from this argument collection and put into the individual implementations of BQSR, since they vary between the walker, dataflow, and spark versions of the tool. This eliminates awkward problems such as having both a `knownSites` argument AND a `BQSRKnownVariants` exposed at the same time, with only 1 of them usable for a given version of a tool. The dataflow-only `BaseRecalibrationArgumentCollection` has been deleted completely as no longer needed.; - We tweaked the names of some tool arguments to enforce consistency between the 3 versions of the tool as well as the rest of hellbender (eg.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073:524,refactor,refactoring,524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073,1,['refactor'],['refactoring']
Modifiability,"@davidbenjamin ; This will make the WDL default to producing a MAF from Funcotator instead of a VCF. There is no flag to switch between the two, so if you know of people that still want VCF output, please speak up now... Can you review the WDL and autotest-WDL changes? This has been tested in FireCloud and looks good (minus an issue that I have already filed), though I had to manually review. The Method configuration in FireCloud still uses the GATK jar override for this. Just in case you wanted to run it. Otherwise, we should blank out that parameter. As a reminder, I tested:; - mutect2.wdl: manually on local backend and FireCloud; - mutect2_nio.wdl: manually on FireCloud. Please review both WDL files. @jonn-smith Could you review the rest? I.e. the bug fixes. Apologies that I did not split these into two PRs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4941#issuecomment-402846788:407,config,configuration,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4941#issuecomment-402846788,1,['config'],['configuration']
Modifiability,"@davidbenjamin @droazen unfortunately the new PON does not make up for the precision loss introduced in v4.1.9.0.; In v4.4.0.0 we get just 2 fewer FP SNVs in our performance evaluation, compared to the old PON.; Benchmarking results in WES tumor-normal mode, HCC1395 benchmark, and:. - v4.1.8.1 (last release with high SNV precision), v4.1.9.0 (first release affected by precision drop), v4.4.0.0 (current release); - oldPON: 1000g_pon.hg38.vcf.gz, newPON: mutect2-hg38-pon.vcf.gz; ![FD_TN_4181_FD_TN_4181_oldPON_FD_TN_4181_newPON_FD_TN_4190_FD_TN_4190_oldPON_FD_TN_4190_newPON_FD_TN_4400_FD_TN_4400_oldPON_FD_TN_4400_newPON](https://user-images.githubusercontent.com/15612230/236126940-9fc26627-260a-43c2-b409-69fbcec6ad47.png). Any chance to get this issue fixed? With Mutect3 not being available and v4.1.8.1 being affected by the log4j vulnerability, it is quite regrettable to be stuck with inferior precision. Extended methods, code, and data to reproduce the issue are here: ; [https://github.com/ddrichel/Mutect2_calling_performance_bug](https://github.com/ddrichel/Mutect2_calling_performance_bug)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1534177043:916,Extend,Extended,916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1534177043,1,['Extend'],['Extended']
Modifiability,"@davidbenjamin @jamesemery As discussed in person, we should consider the possibility that this behavior is by design, and the band pass filter is deliberately being centered on the base before the high-quality soft clip begins (since this code is inherited from GATK3). Let's talk about this before hitting merge on this one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470257519:248,inherit,inherited,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470257519,1,['inherit'],['inherited']
Modifiability,"@davidbenjamin @takutosato this involves a bit of a refactor of the ConcordanceWalker classes, so would appreciate a review from one of you for that part of the PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7328#issuecomment-867612076:52,refactor,refactor,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7328#issuecomment-867612076,1,['refactor'],['refactor']
Modifiability,@davidbenjamin Can I assume that you didn't change `NearbyKmerErrorCorrector` (other than renaming and refactoring),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6470#issuecomment-592679911:103,refactor,refactoring,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6470#issuecomment-592679911,1,['refactor'],['refactoring']
Modifiability,@davidbenjamin Have you had a chance to think about this one yet? Do you think it will be possible to refactor so that doubles are not used as keys? @frank-y-liu was asking about this today.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-434011333:102,refactor,refactor,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-434011333,1,['refactor'],['refactor']
Modifiability,@davidbenjamin I have refactored this branch to account for changes to the codebase adjacent to this code. In the interest of not possibly harming any of the old results I have made this a toggle and I have also made the setting apply symmetrically to tails and heads and added a few simple tests in the existing framework.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6113#issuecomment-640870830:22,refactor,refactored,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6113#issuecomment-640870830,2,['refactor'],['refactored']
Modifiability,"@davidbenjamin I looked into this more. From what I can tell, when a site is polymorphic, GenotypeGVCFs is going to trim to found alleles. Under normal conditions, when a site is not polymorphic, it doesnt get output. When output is forced (--force-output-interverals or output-all-sites), then the VC is just output as-is. This PR initially fixed the bug in removeNonRefAlleles(). I think GenotypeGVCFs should also prune unused alleles. If the site is not polymorphic, by definition I think that means removing all ALTs? I just checked in a few tweaks:. 1) I switched from the original test gVCF data I added to use an existing gVCF from GATK. This has the advantage of containing actual callable sites, not adding new data, and contains existing multi-allelic sites. . 2) I added code to GenotypeGVCFs so unused alleles will be trimmed as part of removeNonRefAlleles. I could understand if you want to change the name of that method now. This is currently always true; however, I could see a rationale for making --retain-unused-alleles-from-force-output-sites as a command line argument (i'd argue to default to false).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-577859097:77,polymorphi,polymorphic,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-577859097,3,['polymorphi'],['polymorphic']
Modifiability,"@davidbenjamin I think so, but I didn't test beyond the cases at the ends of chromosomes so it's possible that I didn't fix it completely. . I can come back to this after I review your adaptive pruning PR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3944#issuecomment-443735719:185,adapt,adaptive,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3944#issuecomment-443735719,1,['adapt'],['adaptive']
Modifiability,@davidbenjamin I think that this issue will be addressed by the AFCalculator refactoring one way or another (e.g. by lifting up the max-alt-allele restrictions or simply avoid adding the NON-REF allele before calling the AFCalculator).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1858#issuecomment-221770394:77,refactor,refactoring,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1858#issuecomment-221770394,1,['refactor'],['refactoring']
Modifiability,"@davidbenjamin I thought you had implemented something a little more sophisticated initially, but then reverted to the ReCapSeg caller for some reason?. Anything that is relatively simple to implement yet sufficiently more principled than the ReCapSeg caller would be reasonable for this rewrite. Thought you might've had something that fit the bill originally, but maybe I'm remembering wrong. If so, then we can try leaving it as is for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324142206:288,rewrite,rewrite,288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324142206,2,['rewrite'],['rewrite']
Modifiability,@davidbenjamin I will review this today. Thanks for doing this refactoring.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5840#issuecomment-477185044:63,refactor,refactoring,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5840#issuecomment-477185044,1,['refactor'],['refactoring']
Modifiability,"@davidbenjamin I've significantly refactored the production code, see the last commit. Most of this refactoring was to done make the code for the accounting of different modes (SNP/INDEL/both x BGMM/python x non/allele-specific) more minimal and straightforward. I've also combined the score/apply steps using the TwoPassVariantWalker. There's still lots of documentation, cleanup, and hardening/validation to be done, but most of the key methods and design choices have been documented, so I think it could be worth a quick review at this stage. Again, no need to nitpick code-style details, etc. (unless you really want to!) In the meantime, I'm going to do some more testing/tieout to make sure the refactor didn't break anything. This covers ~1800 LOC, which is roughly 50% of the equivalent VQSR code. Even modulo the remaining work just mentioned, which may add a few hundred LOC, I think this is a decent improvement---additional functionality, stability, etc. notwithstanding!. There's stubs for adding the truth-sensitivity conversion you proposed---should be pretty straightforward. I think it should also still be pretty easy for future pushes to add features like extraction/downsampling of unlabeled data, etc., but please do keep an eye out for design choices that may ultimately be constraining.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1044836946:34,refactor,refactored,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1044836946,3,['refactor'],"['refactor', 'refactored', 'refactoring']"
Modifiability,@davidbenjamin Interesting. In #6634 I added a fix similar to this as now HC is holding onto bases that were clipped by the various layers of low edge and low quality end removal code in the form of soft clips. I suspect your fix might be a little more elegant than mine. Could we hold off on merging this for a bbit to save ourselves the trouble when we try to rebase?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6792#issuecomment-692226336:132,layers,layers,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6792#issuecomment-692226336,1,['layers'],['layers']
Modifiability,"@davidbenjamin It's actually worth exploring, I think -- with a Spark implementation it is much easier for end-users running the GATK directly to run with multiple cores. Multi-process interval-based parallelism is only trivial when using a pipeline runner. . There is already a beta `HaplotypeCallerSpark` implementation -- it would probably be pretty easy to adapt it to call into a `Mutect2Engine` instead of a `HaplotypeCallerEngine`, I think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-379885003:361,adapt,adapt,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-379885003,1,['adapt'],['adapt']
Modifiability,"@davidbenjamin LODs are fixed, but I'm not super happy with them. They fluctuate a lot, making for a big GVCF. How easy would it be to modify the likelihood calculation to integrate over all AFs greater than some threshold of interest? I'm hoping that would produce more stability. Just to give you an idea of the fluctuation, below are some lines from my integration test VCF where I block anything less than -2 and between -2 and 0. I tried a few other thresholds, but it's just a lot of variability. I have a hunch it has to do with the minimum base quality in the pileup. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT NA12878; chrM 1 . G <NON_REF> . . END=4 GT:DP:MIN_DP:TLOD 0/0:67:48:-1.958e+00; chrM 5 . A <NON_REF> . . END=5 GT:DP:MIN_DP:TLOD 0/0:107:107:-2.033e+00; chrM 6 . C <NON_REF> . . END=6 GT:DP:MIN_DP:TLOD 0/0:123:123:-1.603e+00; chrM 7 . A <NON_REF> . . END=8 GT:DP:MIN_DP:TLOD 0/0:135:135:-2.138e+00; chrM 9 . G <NON_REF> . . END=9 GT:DP:MIN_DP:TLOD 0/0:138:138:-1.975e+00; chrM 10 . T <NON_REF> . . END=13 GT:DP:MIN_DP:TLOD 0/0:178:154:-2.226e+00; chrM 14 . T <NON_REF> . . END=15 GT:DP:MIN_DP:TLOD 0/0:208:205:-1.974e+00; chrM 16 . A <NON_REF> . . END=23 GT:DP:MIN_DP:TLOD 0/0:259:218:-2.424e+00; chrM 24 . A <NON_REF> . . END=25 GT:DP:MIN_DP:TLOD 0/0:312:310:-8.945e-01; chrM 26 . C <NON_REF> . . END=26 GT:DP:MIN_DP:TLOD 0/0:317:317:-2.509e+00; chrM 27 . C <NON_REF> . . END=27 GT:DP:MIN_DP:TLOD 0/0:335:335:-1.962e+00; chrM 28 . A <NON_REF> . . END=50 GT:DP:MIN_DP:TLOD 0/0:492:343:-2.821e+00; chrM 51 . T <NON_REF> . . END=51 GT:DP:MIN_DP:TLOD 0/0:700:700:-3.808e-01; chrM 52 . T <NON_REF> . . END=63 GT:DP:MIN_DP:TLOD 0/0:822:722:-2.943e+00; chrM 64 . C <NON_REF> . . END=64 GT:DP:MIN_DP:TLOD 0/0:909:909:-1.492e+00; chrM 65 . T <NON_REF> . . END=86 GT:DP:MIN_DP:TLOD 0/0:1064:938:-3.065e+00; chrM 87 . A C,<NON_REF> . . DP=942;ECNT=8;POP_AF=5.000e-08,5.000e-08;TLOD=-2.463e+00,-2.668e+00 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_PO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-437501517:490,variab,variability,490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-437501517,1,['variab'],['variability']
Modifiability,"@davidbenjamin Looks like the variable for this arg is `final` and `static`. It probably should be neither, but making it non-static looks it it would require retaining a reference to `M2FiltersArgumentCollection` in `Mutect2FilteringEngine`. I'll leave it to you to figure out the right fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5978#issuecomment-498667359:30,variab,variable,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5978#issuecomment-498667359,1,['variab'],['variable']
Modifiability,"@davidbenjamin Since this issue was related to changes from one of your refactoring PRs, would you mind reviewing this branch and adding a quick unit test? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8445#issuecomment-1658659432:72,refactor,refactoring,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8445#issuecomment-1658659432,1,['refactor'],['refactoring']
Modifiability,"@davidbenjamin This branch seems to have a lot of unrelated refactoring bundled in with the substantive fix for `Mutect2`, and some of this refactoring seems problematic to me (eg., deletion of some downsampler API methods that will be needed when `ReadWalker` downsampling is ported). . Since mixing refactoring into the same PR as behavioral changes is asking for trouble as a general rule, could I ask you to strip out everything except the substantive change to `PositionalDownsampler` from this PR? Happy to do a quick review once this is done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787:60,refactor,refactoring,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787,3,['refactor'],['refactoring']
Modifiability,@davidbenjamin This is the issue I was talking about -- the relevant code is in `MannWhitneyU`:. ```; double sumOfAllSmallerBins = histo.get(testStatU).getValue() / 2.0;. for (final Histogram.Bin<Double> bin : histo.values()) {; if (bin.getId() < testStatU) sumOfAllSmallerBins += bin.getValue();; }. return sumOfAllSmallerBins / histo.getCount();; ```. Where `testStatU` is a double. This has caused issues like the one reported in https://github.com/broadinstitute/gatk/pull/5190. I'm wondering whether the class can be refactored to not use a double as a key.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422126933:522,refactor,refactored,522,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422126933,1,['refactor'],['refactored']
Modifiability,"@davidbenjamin This seems to now be a problem for `PalindromeArtifactClipReadTransformer` as well. In cases where there are soft clips you can miscalculate the `adaptorBoundary`. For mitochondria this causes edge case problems if you're on the end of the contig. I suppose for that specific case it could be fixed in `PalindromeArtifactClipReadTransformer` directly, but it makes more sense to happen in `getAdaptorBoundary` (if cost was no issue).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-413975723:161,adapt,adaptorBoundary,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-413975723,1,['adapt'],['adaptorBoundary']
Modifiability,"@davidbenjamin comparing [better error bars for samples with small contamination](https://github.com/broadinstitute/gatk/pull/7003) version to master 4.2.0.0. - running on large set of probably considered as a small panel with high read depth.; percent of observations with all compared variables equal 88%, values unequal 12%. We can conclude that over all the Zero contamination remains Zero contamination but with non zero stdError (accepted after the binary searched). . **only 0.5%** of samples which were reported zero on version 4.2.0.0 are now reported as non zero contamination when the stdError was not accepted and the min maf iteration continued. ### Need to distinguish between **true zero contamination** ie was not found after running all maf iterations over all strategies (HOMO ALT,REF,UNSCRUPULOUS_HOM_REF) to a zero contamination after accepting stdError of Zero contamination of a single strategy. it is about **15%** of samples which will be reported non zero if continuing the maf iterations . @itaibeno to test on larger panel and report here. @davidbenjamin - could you consider running all maf iterations and report contamination per strategy,minMaf and loci if exists?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-856187340:287,variab,variables,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-856187340,1,['variab'],['variables']
Modifiability,"@davidbenjamin, @fleharty agree with the implementation of PR #7003. ; I'm running that version comparing to samples previously reported 0 contamination and 0 std error.; will update here. One concern on the math Eq37 - Eq.42 calculate std (chi).; the math not taking into account the sample size (n) i.e number of homs.; note that we are starting with GetPileupSummaries output ~5k loci , ; filterSitesByCoverage keep ~300 loci ; filter segments + MAF keep variable number of loci depend on panel size etc. this number can vary and the question should the implementation will take it into account? i.e. reject the sample if n<NUM_LOCI (5,10,50???). **Thinking on the end user observing the Pair( contamination,stdError) and his interpretation on that...** . Probably adding the number of homs sites + strategy to final output as well as listing the pileups for the homsites will let the end user better understand the sample contamination output or even to find contaminant of a batch. **suggesting the following update to output file:**; sample	contamination	error; TUMOR	0.019245855721094312	0.0036809520099731763. sample, **strategy, n_loci,** contamination, error; TUMOR,HOM_ALT,M. list of homosites used; **contig	position	ref_count	alt_count	other_alt_count	allele_frequency**; PileupSummary1; PileupSummary2; ...; PileupSummaryM",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-833821730:458,variab,variable,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-833821730,1,['variab'],['variable']
Modifiability,"@davidbenjamin, looks like you may be able to use `AF` when `AD` is missing at least for `VCFCodec`. Check the output of SelectVariants in the [comment](https://github.com/broadinstitute/gatk/issues/6744#issuecomment-674291742) above, looks like `AF` is being correctly handled by `VCFCodec`, whereas `BCFCodec` still suffers from all elements getting dropped after encountering the missing value `.`. As for using `GERMQ` annotation, no combination is specified to GenomicsDB, so it gets dropped from being included in the `INFO` fields currently. If you want to specify the combination(choose from `none`, `sum`, `mean`, `median`, `element_wise_sum`, `concatenate` or `histogram_sum`), see [examples in GenomicsDBUtils.java](https://github.com/broadinstitute/gatk/blob/356a9ddb50f1467717e87ee6c5ef1c2f084694d3/src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBUtils.java#L51) to extend this to `GERMQ`. Also see outstanding PR #6514 for adding reasonable combination defaults for known info fields.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-680149610:902,extend,extend,902,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-680149610,1,['extend'],['extend']
Modifiability,"@droazen , I got a genomicsdb.jar from @kgururaj and just tried out the GenomicsDB cloud tests. The call stack that I got from my test run in nalini_new_genomicsdb_jar branch mentions that we do need the **fs.gs.project.id** hadoop configuration set. The google service json I use for our internal testing has this key, but the Hellbender service json does not. . Any ideas on how to get this key for the tests? Would this value be HELLBENDER_TEST_PROJECT? How is it being made available to the spark cloud tests for example? I do see it being configured in src/main/java/org/broadinstitute/hellbender/engine/spark/SparkContextFactory.java. ```; hdfsBuilderConnect(forceNewInstance=1, nn=gs://hellbender-test-logs, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:; java.io.IOException: Must supply a value for configuration setting: **fs.gs.project.id**; 	at com.google.cloud.hadoop.util.ConfigurationUtil.getMandatoryConfig(ConfigurationUtil.java:39); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createOptionsBuilderFromConfig(GoogleHadoopFileSystemBase.java:2185); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1832); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1013); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:976); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-427509641:232,config,configuration,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-427509641,6,"['Config', 'config']","['ConfigurationUtil', 'configuration', 'configure', 'configured']"
Modifiability,"@droazen - a proposal for that, which will be great for my toolkit too, is to make `GATKTool` params an argument collection which defaults to the ones in the tool now, but can be change in a tool-basis. For example, if I have a `VariantWalker` which does not use any read-source, disabling all params for reads will be nice for re-use the `VariantWalker` interface without allowing the user to pass something that it is not used at all. It is not enough to provide a way to require or not a source, but to completely remove from the command line the ability to get that argument. I guess that's what it is required also for the CNV tools (correct me if I am wrong, @samuelkle), to be able to change that behaviour and to being able to provide custom documentation/arguments (re-factor the reads input `-I` to be other kind of input). I did something similar for the `ReadFilter` plugin to change the documentation and hide some arguments in my tools using it. Let me know if I can help with something in this direction, because it will be useful for me too...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358254662:879,plugin,plugin,879,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358254662,1,['plugin'],['plugin']
Modifiability,"@droazen - any news about thi one? I would like to have some control over the CLP class arguments, such as the config-file one. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-365624479:111,config,config-file,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-365624479,1,['config'],['config-file']
Modifiability,@droazen - maybe for the patch of the upplication implementation it might be worthy to have a look to [epam/htsjdk-s3-plugin `S3SeekableStream`](https://github.com/epam/htsjdk-s3-plugin/blob/master/S3HtsjdkPlugin/src/main/java/com/epam/cmbi/s3/S3SeekableStream.java). I will suggest that at the original issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3708#issuecomment-375368881:118,plugin,plugin,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3708#issuecomment-375368881,2,['plugin'],['plugin']
Modifiability,@droazen :man_facepalming: I wish we had thought of this ahead of time so we could have done the appropriate commit message rewrites...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2814#issuecomment-306012234:124,rewrite,rewrites,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2814#issuecomment-306012234,1,['rewrite'],['rewrites']
Modifiability,"@droazen @cmnbroad Thanks this is helpful. Having @Arguments in the plugin helps. There is one blocker I'm not seeing a way around. In GATK3 the VariantAnnotation and GenotypeAnnotation classes were passed the GATK3 equivalent of FeatureContext. My use case is annotating genoype concordance between the VCF being annotated and another VCF. Within annotate(), I think I would like to call something like featureContext.getValues() in order to query any variants in my reference VCF for this site. Is there another solution to accomplish this kind of thing from within VariantAnnotation.annotate()? . For example:. ```. public class GenotypeConcordance extends GenotypeAnnotation {; public static final String KEY = ""GTD"";; public static final String D_KEY = ""REF_GT"";. @Argument(doc=""Reference genotypes VCF"", fullName = ""reference-genotypes-vcf"", shortName = ""rg"", optional = true); public FeatureInput<VariantContext> referenceVcf = null;. @Override; public List<String> getKeyNames() {; return Arrays.asList(KEY, D_KEY);; }. @Override; public void annotate(ReferenceContext ref, VariantContext vc, Genotype g, GenotypeBuilder gb, AlleleLikelihoods<GATKRead, Allele> likelihoods) {; if (referenceVcf == null) {; throw new IllegalArgumentException(""Must provide a VCF with reference genotypes!"");; }. if (g.isFiltered() || g.isNoCall()) {; return;; }; ; //TODO: how to accomplish this?; List<VariantContext> list = featureContext.getValues(referenceVcf);; if (list == null || list.isEmpty()){; return;; }. for (VariantContext c : list){; Genotype refGenotype = c.getGenotype(g.getSampleName());; if (refGenotype != null && !refGenotype.isFiltered() && !refGenotype.isNoCall()) {; if (!refGenotype.sameGenotype(g)) {; gb.attribute(KEY, ""1"");; gb.attribute(D_KEY, refGenotype.getGenotypeString());; }; else {; gb.attribute(KEY, ""0"");; }. }; }; }. @Override; public List<VCFFormatHeaderLine> getDescriptions() {; return Arrays.asList(; new VCFFormatHeaderLine(KEY, 1, VCFHeaderLineType.Integer, ""Flags g",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-749243236:68,plugin,plugin,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-749243236,2,"['extend', 'plugin']","['extends', 'plugin']"
Modifiability,"@droazen @sooheelee Anything involving adaptors is not my forte but here goes my best shot. The basic idea of `getAdaptorBoundary` is to find the end of the insert, that is, where the original fragment ends and the adaptor begins. Since the 5' ends of the paired reads define the bounds of a fragment, its approach is to look for the start of the forward strand mate if our read is on the reverse strand, or the end of a reverse strand mate if our read is on the forward strand. This protects us from the possibility of a read longer than its insert. So far, so good, I think. One possible source of error is that these boundaries are determined by the *alignment* starts of the paired reads. This might clip too much if a read has a soft-clipped end and it turns out that these soft-clipped bases were e.g. a real insertion. Then the soft-clipped bases would be considered part of the adaptor. However, this can't do the more harmful thing of failing to clip an adaptor as far as I can tell. So it looks to me like the only issue is the edge case of falsely soft-clipped bases in very short inserts, in which case we hard clip the soft clips and in theory could lose some sensitivity. . That said, @sooheelee may have something else in mind, and @yfarjoun will have a better-informed opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963:39,adapt,adaptors,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963,4,['adapt'],"['adaptor', 'adaptors']"
Modifiability,"@droazen How hard would it be to have a plug-in framework for fragment-based likelihoods parallel to what we already have for read likelihoods? It would be nice to specify all annotations with `-A`. Barring that, it won't be hard to write some fragment-based likelihoods and hard-code them into M2 and HC, but it seems clumsy to do so.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-576800907:40,plug-in,plug-in,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-576800907,1,['plug-in'],['plug-in']
Modifiability,"@droazen I had put in https://github.com/broadinstitute/gatk/issues/3899 over a week ago and just now assigned you to decide if we want to consider instituting a symlink/environmental variable `gatk` that is callable from anywhere in the Docker. . As someone with a newbie perspective, it is easier for me to grasp `gatk` represents the script to which I must provide the path to (e.g. ~/Downloads/gatk/gatk) than to understand that `./gatk` must be run in a particular folder.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3911#issuecomment-350787427:184,variab,variable,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3911#issuecomment-350787427,1,['variab'],['variable']
Modifiability,@droazen I responded to your comments. I've additionally some changes to the readme to include information about the test environment variables. Let me know if there are horrible spelling errors that I somehow missed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278802390:134,variab,variables,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278802390,1,['variab'],['variables']
Modifiability,@droazen I think the BCF code is broken here too. The problem is fundamental to htsjdk. CombineVariants almost certainly has the same or similar problems because it's fundamental to combining vcfs and the fact that htsjdk doesn't handle partially empty lists. Bcftools likely has similar issues. Or loading the correct output from bcftools will recreate the issuue. What about fixing the combine operation so it can substitute default missing values with a per attribute configuration for what value to substitute?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-677814646:471,config,configuration,471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-677814646,1,['config'],['configuration']
Modifiability,"@droazen I think we should try out codecov. I've played with it a little bit and it seems like it would be an improvement over the abysmal coveralls at the very least. At the most it seems like it might be actually useful during pull requests because it seems like it can produce a useful view of newly covered and uncovered lines. It might need some configuration to be maximally useful with minimal spam, and it's hard to know exactly what configuration it should be set with until we have it set up in master. It reports lower overall code coverage than coveralls did because it includes a notion of ""partial coverage""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2167#issuecomment-247643957:351,config,configuration,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2167#issuecomment-247643957,2,['config'],['configuration']
Modifiability,"@droazen I've finally been able to move ahead on this and have a question on what to expect for plugins that define arguments. I have two plugins that each share an argument. I created an ArgumentCollection class to define that argument, and then added this @ArgumentCollection to each plugin. Something like:. ```. public class GenotypeConcordanceBySite extends PedigreeAnnotation implements InfoFieldAnnotation { ​; ​@ArgumentCollection; ​public GenotypeConcordanceArgumentCollection args = new GenotypeConcordanceArgumentCollection();. ​. .etc......; }. Gpublic class GenotypeConcordance extends PedigreeAnnotation implements InfoFieldAnnotation {; ​@ArgumentCollection; ​public GenotypeConcordanceArgumentCollection args = new GenotypeConcordanceArgumentCollection();. . etc......; }. public class GenotypeConcordanceArgumentCollection {; ​@Argument(doc=""Reference genotypes VCF"", fullName = ""reference-genotypes-vcf"", shortName = ""rg"", optional = true); ​public FeatureInput<VariantContext> referenceVcf = null;; }. ```. When I run VariantAnnotator with both plugins, I get an error from within Barclay about arguments with duplicate names. . Ideally these plugins would not be aware of each other (since they can be used independently). Is there a way to define arguments that might be declared in different plugins, but are somehow resolved as identical and therefore allowed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-794444380:96,plugin,plugins,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-794444380,8,"['extend', 'plugin']","['extends', 'plugin', 'plugins']"
Modifiability,@droazen OK - the tests in `DataSourceUtilsUnitTest` pass for me locally. I had to substantially refactor the tests and I added some log messages and some `final` modifiers to clean up some other Intellij warnings.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6807#issuecomment-694956600:97,refactor,refactor,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6807#issuecomment-694956600,1,['refactor'],['refactor']
Modifiability,"@droazen Thank you for the confirmation that HaplotypeCaller performs separate filtering passes on the read mapping qualities, and that the code on line 729 of HaplotypeCallerEngine.java (method ```filterNonPassingReads()``` ) is indeed executing subsequent to the ```MappingQualityReadFilter```. May I suggest, however, that MAPQ values less than 20 might not necessarily lead to an increase in FP variant calls? My understanding is that HaplotypeCaller uses MAPQ values only in a nonparametric rank sum test, in which case MAPQ is treated as an ordinal. This seems appropriate since the magnitude of a MAPQ value depends both on the data and on the computational model the read aligner uses to calculate it. With this in mind, a set of mappings with MAPQ in a lower range (e.g., ```--minimum-mapping-quality 10``` and a correspondingly lower ```--maximum-mapping-quality``` as well) might very well be appropriate for variant calling. So changing the semantics of ```MappingQualityReadFilter``` or parameterizing the currently-hardwired MAPQ range would enable additional control without affecting performance. @jamesemery I will watch for the HaplotypeCaller update that implements that functionality. And if you have a moment, could you please point me to the code that might be adversely affected by decreasing the low-end MAPQ threshold? I might have some ideas about that (or not!)... Thanks again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6854#issuecomment-701512278:1000,parameteriz,parameterizing,1000,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6854#issuecomment-701512278,1,['parameteriz'],['parameterizing']
Modifiability,"@droazen a few minor tests I missed, but this should be good to go otherwise. I did the refactor for Evoquer and I think everything else has been addressed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-514690456:88,refactor,refactor,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-514690456,1,['refactor'],['refactor']
Modifiability,"@droazen and @cmnbroad: i completely understand that this is outside the main GATK dev cycle and priorities; however, do you have any guess as to when you might be able to review? I dont know how active development is, but I'd especially like to get that change in VariantWalker and MultiVariantWalker (which are currently really simple refactors) in before other development on them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-378318089:337,refactor,refactors,337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-378318089,2,['refactor'],['refactors']
Modifiability,"@droazen sure. This PR updates both `BucketUtils.getPathOnGcs` and `IOUtils.getPath` (the latter indirectly) to create a Google Cloud Storage filesystem with a default reopen set to 3. Anyone opening the given `Path` (or even a `Path` derived from it, e.g. via `subpath`) will have the retries enabled. `addPrefetcher` wraps an existing `Path`, so it inherits the underlying `Path`'s retry behavior. Classes within htsjdk that create a `Path` from a String, without using our utility code, would indeed not set retries and errors on those files would not get the benefit of our extra retry. The exception to that is the Spark code path with `NioBam`: this goes via `ReadsIterable`, which also sets the retries. My understanding is that the normal way to open BAMs for tools always creates the `Path` object when parsing the command line, as in e.g. `ReadInputArgumentCollection::GetReadIndexPaths()`. That code path that calls `IOUtils.getPath` (and thus sets the retries). I would expect that the added support for VCF follows the same style, though it looks like it doesn't. If there's a code path that I missed where you think we need retries then please let me know so I can add it!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-289585791:351,inherit,inherits,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-289585791,1,['inherit'],['inherits']
Modifiability,"@droazen, I have introduced --genomicsdb-use-vcf-codec argument defaulting to false. This will allow the user to choose between VCFCodec and BCF2Codec for GenomicsDB streams. ```; --genomicsdb-use-vcf-codec:Boolean; Use VCF Codec Streaming for data from GenomicsDB Default value: true. Possible values:; {true, false} ; ```. Also, hooked --max-genotype-count arg from GenotypeGVCFs/GnarlyGenotyper to GenomicsDB Export Configuration and introduced --genomicsdb-max-genotype-count to be used by tools like SelectVariants that do not use the Genotype ArgumentCollection. This will help with Issue #6275. ```; --genomicsdb-max-genotype-count:Integer; Maximum number of genotypes to consider at any site Default value: 1024.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6305#issuecomment-583536862:419,Config,Configuration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6305#issuecomment-583536862,1,['Config'],['Configuration']
Modifiability,"@droazen, we have a free GCS account, so it is possible that Hadoop requires extra configuration for authenticating/connecting with the HELLBENDER travis service account. Can anyone help here? This the code we have for connecting to GCS via Hadoop. ```; hdfsFS gcs_connect(struct hdfsBuilder *builder, const std::string& working_dir) {; char *gcs_creds = getenv(""GOOGLE_APPLICATION_CREDENTIALS"");; if (gcs_creds) {; value = parse_json(gcs_creds, ""project_id""); // free value after hdfsBuilderConnect as it is shallow copied.; if (value) {; hdfsBuilderConfSetStr(builder, ""google.cloud.auth.service.account.enable"", ""true"");; hdfsBuilderConfSetStr(builder, ""google.cloud.auth.service.account.json.keyfile"", gcs_creds);; hdfsBuilderConfSetStr(builder, ""fs.gs.project.id"", value);; }; }. if (working_dir.empty()) {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", ""/"");; } else {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", working_dir.c_str());; }. // Default buffer sizes are huge in the GCS connector. GenomicsDB reads/writes in smaller chunks,; // so the buffer size can be made a little smaller.; hdfsBuilderConfSetStr(builder, ""fs.gs.io.buffersize.write"", ""262144"");. hdfsFS hdfs_handle = hdfsBuilderConnect(builder);; free(value);; return hdfs_handle;; }; ```. This is the error from Travis logs-; ```; Running Test: Test method testWriteToAndQueryFromGCS(org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest); hdfsBuilderConnect(forceNewInstance=1, nn=gs://hellbender-test-logs, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:210); at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:75); at com.google.cloud.hadoop.fs.gcs.GoogleHadoo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888:83,config,configuration,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888,1,['config'],['configuration']
Modifiability,"@felixm3 The bioconda environment doesn't actually configure the gatk conda environment (it installs gatk, but not the python dependencies required for CNNScoreVariants). You need to set up the gatk conda environment, as described in the Python Dependencies section in the README.md file: https://github.com/broadinstitute/gatk#readme.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1275000632:51,config,configure,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1275000632,1,['config'],['configure']
Modifiability,"@frank-y-liu As discussed in person, I think this is actually a symptom of https://github.com/broadinstitute/gatk/issues/4290 (using a double value as a key in a map get operation), in which case always returning 0.0 when a `get()` fails is not the right solution. I think we should instead refactor `MannWhitneyU` to not use doubles as keys -- I'll see if I can recruit a volunteer for that task.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5190#issuecomment-422108543:291,refactor,refactor,291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5190#issuecomment-422108543,1,['refactor'],['refactor']
Modifiability,"@frank-y-liu I ran using the scripts in https://github.com/broadinstitute/gatk/tree/tw_spark_eval/q4_spark_eval, so no extra ENV variables. What happens if you try to run a small job using a GATK Spark JAR built from master? Do you get the same error?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299503397:129,variab,variables,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299503397,1,['variab'],['variables']
Modifiability,"@frank-y-liu Yes, I think it's not only fragile, but the direct cause of the error you're seeing. @davidbenjamin has agreed to attempt a refactor of the class when he has some free time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422444261:137,refactor,refactor,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422444261,1,['refactor'],['refactor']
Modifiability,"@freeseek No option currently, but after #5831 goes in and Mutect2 groups paired reads together I intend to refactor our annotation engine to account for this. That way we can have both read-based annotations and pair-based annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-523617830:108,refactor,refactor,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-523617830,1,['refactor'],['refactor']
Modifiability,"@freeseek This is a regrettable but temporary regression done for the sake of making Mutect2 much more principled ultimately. Let me try to explain with a timeline. * ~6 months ago: Mutect2 throws away one read whenever mates overlap. This reduces sensitivity unnecessarily, especially for indels, and messes up several annotations, although it does make the ADs come out right.; * ~3 months ago: we no longer throw out reads, and instead modify base and indel quals of overlapping mates to account for the possibility of PCR error. This improves sensitivity and strand, orientation, and position annotations, but it *is* a genuine regression in AD.; * [in 2nd round of code review, probably merged in a week]: Mutect2's `ReadLikelihoods` matrix forces mates to support the same haplotype and the entire likelihood framework is rewritten to allow pairs (or indeed, arbitrary groups of reads) as the atomic unit of data.; * [next step, 1 - 2 months?]: rewrite the annotations engine to accept read likelihoods for some annotations and pair likelihoods for others (such as AD).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-524138917:951,rewrite,rewrite,951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-524138917,1,['rewrite'],['rewrite']
Modifiability,"@gbrandt6 The online docs have a `meta` tag with a `description` attribute that contains the php code:. `<meta name=""description"" content=""include '../../../../common/include/common.php'; include_once '../../../config.php'; $module = modules::GATK; $name =..."" /><meta property=""og:image"" content=""https://theme.zdassets.com/theme_assets/2378360/ceb967563bfc35b9ab52ba13c0f5c4d870dff930.png"" />; `. but that `meta` tag isn't generated by the doc build process (the raw doc files produced by the build have no `meta` tags). So these must be introduced by whatever transformation is done as part of publishing. The raw templates used by the build do contain a `php` tag that contains the php code that winds up in the meta tag. It may be that the solution involves adding meta tags to the raw templates used by the build, but determining what changes need to be made requires someone with knowledge of the publish process. Ideally we would nominate someone from comms who understands that process, and have them also be the steward of the templates used by the build (I'm happy to give a tutorial on the doc build if that helps). It would also help with other questions such as whether we even need that php code in the templates...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7024#issuecomment-757975499:211,config,config,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7024#issuecomment-757975499,1,['config'],['config']
Modifiability,"@gudeqing I think you are referrring to the calls to `GetPileupSummaries`, where we have both `-L` and `-V` arguments with the same variable. This is actually not redundant, though I admit it is clumsy. This is a consequence of `GetPileupSummaries` being written as a GATK `LocusWalker`, which is necessary for optimal performance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7731#issuecomment-1154211085:132,variab,variable,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7731#issuecomment-1154211085,1,['variab'],['variable']
Modifiability,"@igordot It used to exist because `AssemblyBasedCallerArgumentCollection` used to extend `StandardCallerArgumentCollection`, causing `Mutect2` to have a bunch of `HaplotypeCaller` arguments that it didn't use. This was fixed in PR #5758. `FilterMutectCalls` also lost a few arguments as part of a huge change to the entire filtering model in PR #5688. I'm working on a blog post about this but for now the Mutect2 docs at https://github.com/broadinstitute/gatk/blob/master/docs/mutect/mutect.pdf are up-to-date and more user-friendly than they used to be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478008792:82,extend,extend,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478008792,2,['extend'],['extend']
Modifiability,"@jacobrh91 Thanks for the report! I believe this is the result of our (still-incomplete) transition to using a GATK configuration file for certain toolkit-wide settings. Could you please try making a copy of `src/main/resources/org/broadinstitute/hellbender/utils/config/GATKConfig.properties`, editing the `samjdk.use_async_io_read_samtools` line in that file to have a value of `true` rather than `false`, pass in the edited config file to GATK via the `--gatk-config-file` argument, and see if the setting gets changed at runtime?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571:116,config,configuration,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571,4,['config'],"['config', 'config-file', 'configuration']"
Modifiability,"@jamesemery - I think that the rebase is done. I'd like to have this in as soon as it can be, to avoid the extra-work of rebasing due to new tests or refactoring of them.... Thank you in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-338990541:150,refactor,refactoring,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-338990541,1,['refactor'],['refactoring']
Modifiability,"@jamesemery - we should get this merge as soon as possible to avoid conflicts that pop up in every round of comments. Once this is in, I can go to the open PRs to point out the conflicts and the new structure (e.g., change the new tests to extend `GATKBaseTest`). I added a new commit addressing the issues and I will rebase to resolve conflicts again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340724214:240,extend,extend,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340724214,1,['extend'],['extend']
Modifiability,"@jamesemery Back to you, at long last. I adopted your suggestion of a proper search that doesn't revisit already-seen vertices and came up with a better way of seeding the ""good"" subgraph that is safe from your STR concern. As far as code is concerned it's a total rewrite — you can pretend the first PR commit doesn't exist. The new criterion for seeding the search is chains with good log odds on both ends and which are incident on a vertex with multiple good out-edges or multiple good in-edges. The rationale is that the adjacency of two bad edges may have good log odds (Suppose a bad edge comes in and two bad edges come out. One is a new error on top of the original error and one is the continuation of the original error) but two have two outgoing edges with good log odds requires an actual real variant. On our M2 validations this essentially no effect on sensitivity and a mild reduction in false positives. I will leave it to you (or to me when I don't have to work like a vampire) to investigate how well it interacts with junction trees. As a first step I wrote a basic unit test for the basic pathology of the old method.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6520#issuecomment-624265441:265,rewrite,rewrite,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6520#issuecomment-624265441,1,['rewrite'],['rewrite']
Modifiability,"@jamesemery Great, thanks for checking. Could you do a review pass on this when you get a chance? It's not clear that the approach taken here of sending the owner config file around is what we want....it seems like instead we need a way to load the owner config from the launcher script itself.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4653#issuecomment-420055188:163,config,config,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4653#issuecomment-420055188,4,['config'],['config']
Modifiability,"@jamesemery I agree - all access (read and write) to `GenotypeLikelihoodCalculators` instance variables needs to be synchronized to make it safe. I think it would be sufficient to make `getInstance()` and `calculateGenotypeCountUsingTables()` synchronized. @droazen, are you concerned about performance for the Spark case? For the walker version, presumably the access is single-threaded, and hence [uncontended, which is very cheap](https://books.google.co.uk/books?id=mzgFCAAAQBAJ&pg=PA230&lpg=PA230&dq=java+uncontended+synchronization+goetz&source=bl&ots=7W4J807faW&sig=YALE1qdWoAUELPqLRhIedz-bZ20&hl=en&sa=X&ved=2ahUKEwj4jJeko8zdAhXVFsAKHazkBrcQ6AEwB3oECAIQAQ#v=onepage&q=java%20uncontended%20synchronization%20goetz&f=false). Another option would be to maintain a separate instance of `GenotypeLikelihoodCalculators` per genotyping engine. The size of the table is ploidy * alleles, so not too large?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-423546586:94,variab,variables,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-423546586,1,['variab'],['variables']
Modifiability,"@jamesemery I see how the returned `SortedSet` in the existing code is not sorted with respect to the resulting trimming bounds, but I don't see how it leads to a bug. Here's my commented version of the code in `AssemblyRegionTrimmer::trim` that the `SortedSet` of all variation events gets passed to:. ```; for (final VariantContext vc : variantsInRegion) {; int padding = assemblyRegionArgs.snpPaddingForGenotyping;; if (vc.isIndel()) {; padding = assemblyRegionArgs.indelPaddingForGenotyping;; // omitting a few lines where STRs get additional padding; }. // seems to me like if this is the second event and it's an indel then minStart could extend; // past the padding of a previous SNP event; minStart = Math.min(minStart, Math.max(vc.getStart() - padding,1));; maxEnd = Math.max(maxEnd, vc.getEnd() + padding);; }. final SimpleInterval paddedVariantSpan = new SimpleInterval(region.getContig(), minStart, maxEnd).intersect(region.getPaddedSpan());; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645509421:645,extend,extend,645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645509421,1,['extend'],['extend']
Modifiability,"@jamesemery I think this is because the annotation plugin, which has the pedigree arg, hasn't been integrated with the tools yet (second part of https://github.com/broadinstitute/gatk/issues/3287) ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4604#issuecomment-376905093:51,plugin,plugin,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4604#issuecomment-376905093,1,['plugin'],['plugin']
Modifiability,"@jamesemery Oh I see ! My bad , sorry, I messed-up something when the boundaries of the exons where extended by 100bp. Thank you for your time !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7289#issuecomment-856179216:100,extend,extended,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7289#issuecomment-856179216,1,['extend'],['extended']
Modifiability,"@jamesemery and now the overview of the more complex changes:. - `AssemblyResultSet`: the code for adding and removing haplotypes based on pileup alleles has become a `void` method of this class, where it belongs. Here and elsewhere I introduce snappy variable and function named referring to ""good"" and ""bad"" alleles, which I find visually much clearer. The code is basically the same as before but somewhat streamified. I extracted a `makeHaplotypeWithInsertedEvent` method to eliminate some code duplication between GGA and pileup force-calling.; - `HaplotypeCallerEngine` and `Mutect2Engine`: Force-calling alleles are split into biallelic `Events`. Duplicated code for finding all pileup events, then sifting them into good event to force-call and bad events to remove is extracted as `PileupBasedAlleles.goodAndBadPileupEvents`. Computing `allVariationEvents` is much simpler because 1) it now uses `Event` instead of `VariantContext` and 2) `Event` overrides `equals` and `hashCode`.; - `PileupBasedAlleles`: `getPileupVariantContexts` and sorting into good and bad pileup variants has been unified into `goodAndBadPileupEvents()`. It has additionally been somewhat rewritten for conciseness. Also, instead of the somewhat kludgy method of making `VariantContext` with four temporary attributes, then filtering based on those attributes, it calculates the filtering status immediately and uses `Events`. Also fixed the somewhat-misleading use of the word `alt` to mean `SNP`.; - `AssemblyBasedCallerUtils`: `applyPileupEventsAsForcedAlleles`, along with several helper methods that it calls, has been moved into `AssemblyResultResult`, where it is now a void member method.; - `GATKVariantContextUtils` mainly just using `Event` instead of `VariantContext`, which simplifies the code for splitting a `VariantContext` into biallelics. After going through this exercise I realize that it's not actually so much. The diff's bark is worse than its bite. The overwhelming majority of changes are eit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574175702:252,variab,variable,252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574175702,2,['variab'],['variable']
Modifiability,"@jamesemery sorry to bug on this topic, but I'm hoping to make a push early this year to fully migrate my lab off GATK3 . I looked more closely at the specific annotations we need to migrate. I decided that I will implement our walker, 'DiscvrVariantAnnotator', which is basically a light wrapper around VariantAnnotation. This will make it easier to spike in custom annotations. In that walker, I will override makeVariantAnnotations(). I will make a new marker interface for EngineAwareAnnotation, and test that on all the Annotation classes, and use this to inject FeatureManager. So no core GATK changes needed. I did find one thing I'd like to propose. You probably know PedigreeAnnotation is special-cased in GATK. Annotations that use it have automatic argument validation and have the SampleDB injected. Currently, PedigreeAnnotation is a subclass of InfoFieldAnnotation, so isnt available to GenotypeAnnotations. There doesnt appear to be a solid reason why. I tried to fix that and my best idea is the proposal here: #7041 . The core idea is to convert InfoFieldAnnotation and GenotypeAnnotation to interfaces. This is generally a trivial switch in existing code. With that, it becomes possible for classes that currently extend PedigreeAnnotation (which I switched to no longer extend InfoFieldAnnotation) to simply PedigreeAnnotation and implement InfoFieldAnnotation. This makes it possible for future classes to extend PedigreeAnnotation and implement GenotypeAnnotation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063:1232,extend,extend,1232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063,6,['extend'],['extend']
Modifiability,"@jamesemery the use of padding is a little confusing. One use of padding is for providing extra reference bases around the reads. This is the case in `ReadWalkerSpark`, for example. When the whole reference is available via the Spark files mechanism (which is what this PR is about) then there is no need for padding (and in the case of `ReadWalkerSpark`, no need for sharding at all). Therefore it makes sense to remove the use of padding in these cases. Another use of padding was for providing more reads around an area of interest in assembly region/haplotype caller tools. This is no longer the case though, since the refactoring that @droazen did in `HaplotypeCaller` in #4031. However, `HaplotypeCallerSpark` has not been updated to reflect the changes from that refactoring, so it's probably best not to change the padding in that class. I've reverted the change there for this reason. The locus walkers never had any need for padding, except for padding reference bases in `LocusWalkerSpark`, mentioned above. I've added a comment in the code to clarify this. Hopefully that makes more sense now. Please let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426274932:623,refactor,refactoring,623,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426274932,2,['refactor'],['refactoring']
Modifiability,@jason-weirather I see the error in the config file - this is definitely a bug in the data source release. There will need to be another data sources release to fix this and another data sources bug. I expect that this will be released by end of week. I will run through some additional tests on hg38 data to see if I can duplicate the null pointer exception.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798:40,config,config,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798,1,['config'],['config']
Modifiability,"@jean-philippe-martin Agree that we probably shouldn't refactor `IntegrationTest` as part of this PR, but it looks like some other tests are failing now. The PR build failures are [here](https://travis-ci.com/broadinstitute/gatk/builds/97887212). There are some CRAN mirror problems that are affecting all builds at the moment, but there are also some failures that are fallout from the `IntegrationTest` changes. See [this](https://travis-ci.com/broadinstitute/gatk/jobs/171535202). The previous (`XReadLines`) code was gzip aware, but the new code is not, which is causing the test failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456645889:55,refactor,refactor,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456645889,1,['refactor'],['refactor']
Modifiability,@jean-philippe-martin If the connector could configure itself with default credentials that would be amazing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-386388889:45,config,configure,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-386388889,1,['config'],['configure']
Modifiability,@jean-philippe-martin It looks like `ReferenceDataSourceUnitTest` is what's covering the `engine.ReferenceFileSource` functionality. It should be easy to adapt one of those tests to run in jmfs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3921#issuecomment-349752680:154,adapt,adapt,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3921#issuecomment-349752680,1,['adapt'],['adapt']
Modifiability,"@jean-philippe-martin Possibly we were using the GCS<->HDFS adapter previously, and something changed in the code to make us use NIO here instead? (possibly https://github.com/HadoopGenomics/Hadoop-BAM/pull/111?)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265002735:60,adapt,adapter,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265002735,1,['adapt'],['adapter']
Modifiability,"@jean-philippe-martin Sorry, the baby was not very asleep last night so I may be slightly less coherent than usual... . I see how you heard that, but it wasn't what I meant. What I mean was that we should eventually move the information about how to set -DSTACK_TRACE_ON_USEREXCEPTION into the top level UserException message to make it discoverable, and remove it from the comment it's in now. Lets do that in a different PR though since it's sort of orthogonal and the best thing to do might be to integrate it as a regular commandline option instead of an environment variable. Separately from that, I was wondering if we should catch StorageExceptions at the top level and handle them specially. If we're going to do that I think we could just add them to the UserException catch block and have them be treated the same way, no need for special handling.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285152468:571,variab,variable,571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285152468,1,['variab'],['variable']
Modifiability,"@jean-philippe-martin Travis runs the cloud tests using a service account on a non gcs machine. (at least I assume it's not a gcs vm, I think they use amazon cloud although that could have changed...) All we do to log in is:. ```; gcloud config set project broad-dsde-dev;; gcloud auth activate-service-account --key-file servicekey.json; ```. @kcibul Where you connecting from the broad network? I've had problems connecting to gcs from home because of IP restrictions on the broad projects. Maybe your gsutil has some configuration setup to do tunneling but gatk doesn't? Sort of a long shot since I would expect both to not work if either doesn't.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282406671:238,config,config,238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282406671,2,['config'],"['config', 'configuration']"
Modifiability,@jean-philippe-martin Would it make sense to change the default `maxChannelReopens` to 3? There will inevitably be code paths that construct their own Path objects. Would it be easy to add the ability to configure these settings globally rather than per-Path? Should we create a ticket for that?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-308756943:204,config,configure,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-308756943,1,['config'],['configure']
Modifiability,"@jean-philippe-martin Yeah, I'm seeing that. I suspect it's because we aren't passing the environment variables correctly to the docker tests so it's exploding with an unhelpful error during test initialization.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740:102,variab,variables,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740,1,['variab'],['variables']
Modifiability,"@jfarrell Do you recognize ""scc"" as a local host name ? ""hdfs:///project/casa/gcad/adsp.cc/sv"" looks reasonable enough as a file URI, except that the hadoop file system provider requires an authority component (the part of the uri between the second and third slash: ""hdfs://authority-component/..."") be provided in such URIs. Since you didn't include one as part of the hdfs path on the command line, it looks like transform along the way resulted in one being added (the authority component looks like ""host:port""), resulting in the port number -1. So I'm not clear if its a configuration issue, or a bad code code path, or both. But I would suggest trying an hdfs path with a valid authority component (one that works with the hadoop shell). @SHuang-Broad I do see some code paths in `StructuralVariationDiscoveryPipelineSpark` that call `Paths.get directly`, rather than `IOUtils.getPath()`. I would also suggest replacing the direct calls to `makeSAMOrBAMWriter` in `SVFileUtils` with the GATK wrapper code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-493980166:577,config,configuration,577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-493980166,2,['config'],['configuration']
Modifiability,"@jkobject Here's an update for you on this issue, as promised: we've tested the patch in https://github.com/broadinstitute/gatk/pull/7730 extensively on both our local machines and on a clean Google Cloud VM, and found it to work perfectly with all kinds of requester pays inputs to GATK (fastas, bams, vcfs, interval_lists, etc.). We now believe that the test failures in the PR are artifacts of some configuration issue in our Travis CI test environment, and that the PR does actually fix requester pays support in GATK. We are considering merging and releasing the branch as-is, and dealing with the issues in our test suite post-release. It would make us more confident doing this if you could test the branch out as well on your end and confirm whether it works for you. You can do this using the following commands:. ```; git clone https://github.com/broadinstitute/gatk.git gatk; cd gatk; git fetch; git checkout -b lb_refix_requester_pays origin/lb_refix_requester_pays; ./gradlew clean installDist; ./gatk <a GATK command that failed for you previously>; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1079421576:402,config,configuration,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716#issuecomment-1079421576,1,['config'],['configuration']
Modifiability,"@jkobject This problem has to do with indels and predicted protein change sequences. I'm starting a refactor of how the predicted protein changes get created. When that's complete, this issue will be fixed. In the meantime, can you post the stack trace and share the example workspace you mention in #6289 ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1181815133:100,refactor,refactor,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1181815133,1,['refactor'],['refactor']
Modifiability,"@jonn-smith Can you be more specific? If we come back to this ticket in 3 months, we won't remember exactly how it needs to be refactored.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4550#issuecomment-375061877:127,refactor,refactored,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4550#issuecomment-375061877,1,['refactor'],['refactored']
Modifiability,"@jonn-smith Can you please chime in here as well to tell us whether it's currently possible to override a single system property setting in Owner on the command line, or is `--gatk-config-file` currently the only way?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367412275:181,config,config-file,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367412275,1,['config'],['config-file']
Modifiability,"@jonn-smith, I did see XsvLocatableTableCodec and the .config file path, but this does not appear to work. To be clear this is something like:; ```; gatk IndexFeatureFile -I ./hg19/testTextSource.config; ```; In IndexFeatureFile (https://github.com/broadinstitute/gatk/blob/abe8148bda234edf6bd00fa51df44d456e8e2641/src/main/java/org/broadinstitute/hellbender/tools/IndexFeatureFile.java#L118), it does identify the correct codec; however, it then calls:. IndexFactory.createDynamicIndex(featurePath.toPath(), ...). where featurePath is the config file. This calls IndexFactory to open a lineReader on the config file (not the backing data source): https://github.com/samtools/htsjdk/blob/6d3fc7bc1f613ecfce1c22d368f3ae17cb86823d/src/main/java/htsjdk/tribble/index/IndexFactory.java#L598. . This then fails during XsvLocatableTableCodec.readActualHeader(), since this is trying to read the config file, not the TXT file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591678472:55,config,config,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591678472,10,['config'],['config']
Modifiability,@kcibul @cmnbroad This should hopefully fix the problems you've both been seeing. . It turned out we weren't logging into docker on the wdl test branches because they don't set DOCKER_TEST but they still build docker images. I was confused about how that variable was used.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7256#issuecomment-841391272:255,variab,variable,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7256#issuecomment-841391272,1,['variab'],['variable']
Modifiability,@kdatta It shouldn't cause any problems for you. It was a local configuration issue. If your already set up to download the lfs files these should just work.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288540859:64,config,configuration,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288540859,1,['config'],['configuration']
Modifiability,"@kdatta Right, you shouldn't assume that all the input vcfs have the same header. Ideally, you'd have your tool extend `GATKTool`, take as an `@Argument` a `List<FeatureInput<VariantContext>>`, and then call the inherited method `getHeaderForFeatures( final FeatureInput<T> featureDescriptor )` to get at each input's header.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-280412809:112,extend,extend,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-280412809,2,"['extend', 'inherit']","['extend', 'inherited']"
Modifiability,"@koncheto-broad this is one of the VQSR-lite PRs you will want to eventually rebase on. It's still awaiting review (I was waiting until the dust from updating to Java 17 in #8035 settles), but if anyone from your team wants to take a first crack, feel free! Not too many code changes, so hopefully it should be pretty manageable. Just so it's all in one place: your #8157 GVS branch is currently rebased on #7954, which contains the ""serial SNP-then-indel"" version of the Joint Genotyping WDL (written by Megan for Ultima) and the Java code for the tools. Some minor updates were made to the Java code in #8049 and the WDL was rewritten by me to do SNPs and indels in a single pass in #8074. (EDIT: I was originally confused here, the WDL that was replaced in this PR simply ran SNPs and indels separately, rather than serially—thanks to George for correcting me here.). The PR here makes relatively minor updates to both the Java code and the WDL and might require very minor updates to GVS code or JSON configurations. And finally, the larger PR at #8132 adds a Pure Java BGMM backend. As we discussed during my mobbing presentation, this is provided merely as a convenience for those users that might not be able to control their python environment (hopefully a small number, these days!), so getting it merged is probably less urgent and should not affect any GVS work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8131#issuecomment-1414056344:1005,config,configurations,1005,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8131#issuecomment-1414056344,2,['config'],['configurations']
Modifiability,"@laserson the `SAMRecord` vs. Google `Read` is a loooooong story.; The super-short version:; We had a bunch of utilities written for `SAMRecord` that @droazen refactored over months to take the GATKRead interface. As it happens, the SAM spec and the GA4GH spec are not 100% compatible. So, it's not possible to losslessly convert from A -> B -> A (where A is `SAMRecord` or Google `Read`). The cases where it doesn't work are edge cases, but they exist. Second, @jean-philippe-martin found that converting to Google `Read` was fairly expensive. Between those two points, I think we're probably better off with SAM-backed reads. (Also, right now the Google `Read` is serialized via JSON, so it's not that small anyway.). @tomwhite and @jean-philippe-martin, I think adding the header back will be fine for us engineers working on the engine, but it will make for a poorer user experience for newcomers and Comp Bios to burden them with having to care about what happens with shuffles (when they just want to prototype something). . That said, I think this is probably the best approach we have at our disposal. If we do, we need to do an excellent job of throwing errors if users try to perform actions that would require the header. The error message should explain what really happened and ideally point to some documentation we write explaining the stripping of the header and how to fix it. If this error occurs, it needs to be simple for anyone to fix it. @droazen @lbergelson, what do you two think? (also @laserson, do you have any ideas or thoughts on the header since we're probably stuck with `SAMRecord`?)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141086025:159,refactor,refactored,159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141086025,1,['refactor'],['refactored']
Modifiability,"@lbergelson & I think @tedsharpe 's proposal above re: attributes sounds reasonable (including a whitelist of attributes to copy, optionally configurable via the command line). The rest of the proposal sounds reasonable as well, modulo one or two comments which @lbergelson will add below.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3666#issuecomment-337006792:141,config,configurable,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3666#issuecomment-337006792,1,['config'],['configurable']
Modifiability,"@lbergelson - In gradle, I first resolve with maven central and then with your artifactory:. ```gradle; repositories {; mavenCentral(); maven {; url ""https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/""; }; }; ```. In the case of maven, for several repositories this should be done following [this](https://maven.apache.org/guides/mini/guide-multiple-repositories.html). I think that the configuration for the repositories should look like this (if I remember correctly):. ```xml; <repositories>; <repository>; <id>central</id>; <name>Maven Repository Switchboard</name>; <layout>default</layout>; <url>http://repo1.maven.org/maven2</url>; <snapshots>; <enabled>false</enabled>; </snapshots>; </repository>; <repository>; <id>snapshots</id>; <snapshots>; <enabled>true</enabled>; </snapshots>; <name>libs-snapshot</name>; <url>https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot</url>; </repository>; </repositories>; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340482852:398,config,configuration,398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340482852,2,['config'],['configuration']
Modifiability,"@lbergelson ; now: 3.9GB (without ~0.3-5 GB extra off from the base image changes currently in the branch); then: 5.22GB; A moderate but not irrelevant reduction in size. With these changes some more drastic changes will be easier, namely trying to slice down the python packages or refactoring the build jars should be easier. I intend to open another PR to upgrade the base image shortly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4955#issuecomment-400749796:283,refactor,refactoring,283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4955#issuecomment-400749796,1,['refactor'],['refactoring']
Modifiability,"@lbergelson @droazen @kgururaj ; 1. I was playing around with the test codes in GATK and did not push GenomicsDB tests in this PR. Will push it in the next commit.; 2. This is at the top of our discussion list for next week. GenomicsDB interfaces use these JSON files today which contain input configuration, list of samples, mapping between sample IDs and TileDB row indexes and stream ids for the input VCFs. If this tool takes the list of VCFs and intervals as input, we'd have to recreate JSON files internally and pass it to GenomicsDB. I wanted to avoid this for now as we are thinking about overhauling the input methodology completely in GenomicsDB with protocol buffers, but this is going to take a while. Also, we need to decide what's the best way to maintain the callset mappings.; 3. Will let you know asap. -Kushal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277320579:294,config,configuration,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277320579,1,['config'],['configuration']
Modifiability,"@lbergelson @droazen Both of you committed changes to the Dockerfile recently, but as far as I can tell they are not security related. Should I keep this PR at [4.2.4.1](https://hub.docker.com/layers/broadinstitute/gatk/4.2.4.1/images/sha256-421d2fb2cc869249cef3f4d7a77289256d295b04ba623096228e0e5fd42939e9?context=explore)?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7611#issuecomment-1048281865:193,layers,layers,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7611#issuecomment-1048281865,1,['layers'],['layers']
Modifiability,"@lbergelson @droazen Just noticed the M2 WDL test is failing here---is this similar to the CNV WDL failures you were seeing just before release?. ````; No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.; Check the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received; The build has been terminated; ````. If so, this is definitely something I've seen more frequently lately. Not sure what the remedy is, but would probably be worth looking into soon so we don't lose too much time to intermittent failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166:331,config,configuration,331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166,1,['config'],['configuration']
Modifiability,"@lbergelson @droazen, what's about a `GATKConf` class containing settable values? Defaults are the current ones and it's up to the API user if a configuration file or hardcoded solution is implemented, or even command line if they need it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2156#issuecomment-265244675:145,config,configuration,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2156#issuecomment-265244675,1,['config'],['configuration']
Modifiability,@lbergelson Are you happy with this branch as-is or do you want further refactoring as @takutosato hinted at above?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6512#issuecomment-607394558:72,refactor,refactoring,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6512#issuecomment-607394558,1,['refactor'],['refactoring']
Modifiability,"@lbergelson Hi, I want to inform you that I have solved the problem. It is because the JAVA version that the master and the worker used are different. It is solved by adding the JAVA_HOME path to the spark configuration file. It is not really a GATK problem, sorry for that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-307204194:206,config,configuration,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-307204194,1,['config'],['configuration']
Modifiability,"@lbergelson I moved the ""disable"" toggle to the `ProgressMeter` constructors, and made it `final` so that it won't change over the lifetime of the object. I agree that extracting an interface, etc., would be nicer, but I think such a larger refactor can wait for a future PR. For now, this fixes the currently-broken `disableProgressMeter()` method in a way that involves the least-invasive changes to the tools / traversals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7354#issuecomment-881711125:241,refactor,refactor,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7354#issuecomment-881711125,1,['refactor'],['refactor']
Modifiability,"@lbergelson I've refactored this PR to just keep the switch to using non-interactive mode in the gcloud installer, which I think is worth merging to guard against future issues. Can you re-review?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6974#issuecomment-733884778:17,refactor,refactored,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6974#issuecomment-733884778,1,['refactor'],['refactored']
Modifiability,@lbergelson Looks like we have a failure in `BigQueryUtilsUnitTest`:. ```; testQueryWithStorageAPI; java.lang.IllegalStateException: getTransportChannel() called when needsExecutor() is true; 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:194); 	at com.google.api.gax.rpc.ClientContext.create(ClientContext.java:241); 	at com.google.cloud.bigquery.storage.v1beta1.stub.EnhancedBigQueryStorageStub.create(EnhancedBigQueryStorageStub.java:108); 	at com.google.cloud.bigquery.storage.v1beta1.BigQueryStorageClient.<init>(BigQueryStorageClient.java:144); 	at com.google.cloud.bigquery.storage.v1beta1.BigQueryStorageClient.create(BigQueryStorageClient.java:125); 	at com.google.cloud.bigquery.storage.v1beta1.BigQueryStorageClient.create(BigQueryStorageClient.java:116); 	at org.broadinstitute.hellbender.utils.bigquery.StorageAPIAvroReader.<init>(StorageAPIAvroReader.java:51); 	at org.broadinstitute.hellbender.utils.bigquery.StorageAPIAvroReader.<init>(StorageAPIAvroReader.java:45); 	at org.broadinstitute.hellbender.utils.bigquery.BigQueryUtils.executeQueryWithStorageAPI(BigQueryUtils.java:394); 	at org.broadinstitute.hellbender.utils.bigquery.BigQueryUtils.executeQueryWithStorageAPI(BigQueryUtils.java:370); 	at org.broadinstitute.hellbender.utils.bigquery.BigQueryUtilsUnitTest.testQueryWithStorageAPI(BigQueryUtilsUnitTest.java:74); ```. I suspect we need to bump our BigQuery dependency in this PR as well -- I'll attempt it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1051025679:441,Enhance,EnhancedBigQueryStorageStub,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1051025679,2,['Enhance'],['EnhancedBigQueryStorageStub']
Modifiability,"@lbergelson Sorry to be unclear---this isn't a GATK issue. For Cromwell, you can configure various options for each backend. For example, if you are running on a local backend with Docker, you can set a `submit-docker` attribute to specify the string that runs the Docker container; so to solve the above problem, you'd set this to include `--shm-size` and set it accordingly. However, according to @jsotobroad, you're not allowed such an attribute when submitting to Google cloud. If that's the case, then this is more of an issue with the Cromwell/Google Pipelines interface than the data.table package (although, as the discussion in the GitHub issue above shows, it'd be a simple fix on the data.table end, so I'm not sure why it's not addressed yet...) Changing the R script to get around the issue in this particular case is not unacceptably ugly, but you could imagine we might run into a similar problem in the future if anything else exceeds the 64MB /dev/shm limit and also cannot specify tmpfs. So perhaps we should take a look at the underlying issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691:81,config,configure,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691,2,['config'],['configure']
Modifiability,"@lbergelson There aren't too many incompatible changes between Spark 1.x and Spark 2.x, but there are some, and that required us to further parameterize our build and release. Feel free to borrow from our scripts if you go down that route. I'll keep an eye out for your new patch to review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-261284201:140,parameteriz,parameterize,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-261284201,1,['parameteriz'],['parameterize']
Modifiability,"@lbergelson When you get a chance. I think it was your last review that pushed me over the edge to refactor the barclay docgen code. So this now has additional commits that reflect that. One has the changes based on your general code review comments; one has the substantial changes due to refactoring (small changes to just 3 files I think); one has the annotation changes based on that; and one has the change to build.gradle for the barclay snapshot, which I need on this branch but will remove once I rebase. My apologies if its confusing. Le me know if you have questions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-278820155:99,refactor,refactor,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-278820155,2,['refactor'],"['refactor', 'refactoring']"
Modifiability,@lbergelson With that assuming that last commit didn't break everything I think thats all the comments at least explicitly punted on. Its running all the tests. I intend to open issues on merge of this for two lingering problems: ; 1. figuring out how to get fork-pr branches to work without crashing ; 2. refactoring the wdl tests to use the docker image that is being built for docker images (note this is probably contingent on our answer for 1 since currently the docker upload and pull path breaks without secrets...),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7754#issuecomment-1098463662:306,refactor,refactoring,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7754#issuecomment-1098463662,1,['refactor'],['refactoring']
Modifiability,"@lbergelson You're right, it would be easier to read that way, but it leaves a dangling ""Optional Arguments"" string in the output even when there are no optional arguments. If you're still not sold I can rewrite it to iterate once to count the optional args, but this is a cheap, simple way to get the right output.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/566#issuecomment-112561579:204,rewrite,rewrite,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/566#issuecomment-112561579,1,['rewrite'],['rewrite']
Modifiability,"@lbergelson and @droazen - back to you and thank you for considering this when I know that you are about to release. Please, feel free to modify the PR, rebase to test if there is any incompatibility and/or revert commits. I would like to have this for the released version to be able to remove the configuration argument, which might be confusing for my users, and to been able to use `java.nio.Path` as a temp directory. Thanks in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-355948112:299,config,configuration,299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-355948112,1,['config'],['configuration']
Modifiability,"@lbergelson and @ldgauthier have confirmed that GATK CombineGVCFs (the predecessor to GenomicsDB) also had this same limit, so GenomicsDB is not doing anything radically new here. This ticket is just to ensure that the limit is configurable if it already isn't",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2687#issuecomment-300271189:228,config,configurable,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2687#issuecomment-300271189,1,['config'],['configurable']
Modifiability,@lbergelson can you review - it's a simple enhancement to the CompareBaseQualities tool,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1773#issuecomment-214757716:43,enhance,enhancement,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1773#issuecomment-214757716,1,['enhance'],['enhancement']
Modifiability,"@lbergelson sorry for my late response. I'm currently on vacations but I will try to respond (with some delay) any question.; So, what I'm seeing here (using Github web without having a proper dev env) is that for each interval, it's going to call (in parallel) sample reader function from the configuration =>; ```; final Map<String, FeatureReader<VariantContext>> sampleToReaderMap =; this.config.sampleToReaderMapCreator().apply(; this.config.getSampleNameToVcfPath(), updatedBatchSize, index); ; ```; That's is the first difference from previous implementation. If whatever you have in that function consume lots of memory, that's an issue.; Regarding the thread pool, I'm not seeing it's being starved by chromosome parallel import but it might use extra memory to execute since there is a high load of threads use due to the number of parallel imports.; Worker threads can execute only one task at the time, but the ForkJoinPool doesn’t create a separate thread for every single subtask. Instead, each thread in the pool has its own double-ended queue (or deque, pronounced deck) **which stores tasks**. Those are the two things I'm seeing right now without having the chance to debug :(.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-387810542:294,config,configuration,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-387810542,3,['config'],"['config', 'configuration']"
Modifiability,"@lbergelson, I don't think that this solution will help in this case, because another error when trying to use `CommandLineProgramTest`is that it extends `BaseTest`, which loads directly a `GenomeLocParser` for a reference that is not present and it blows up in every test. Regarding the `Main` class, because you point it out here, I would like to have some control over `Main` and how it manages things like errors or logging header. Basically all the things that I'm facing at the moment are, apart of this error using the testing framework, is that the framework have tons of mentions to the GATK itself (error messages pointing to the GATK manual page or bundle tools), and little control over which of them should be expose to the final user. Only as an example, I would like to output a line with the name and version of my software and a short notice about the usage of the GATK framework and which version I'm using (for easier maintenance, and contribution if a bug is found).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242802278:146,extend,extends,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242802278,1,['extend'],['extends']
Modifiability,"@lbergelson. Our simple s3 nio library is not currently open source, but we would be willing to make it so after testing it properly. We found that to get the s3 nio library work with GATK, a few minor changes needed to be made in the GATK source. This is especially true for the spark tools because, on AWS EMR Spark clusters, s3 uris can be treated exactly as if they are HDFS uris. Therefore, it was not quite as simple for us to just add the s3 nio library to the classpath and have everything work as expected. For that reason we put the project on hold until GATK is closer to release. Thanks,; David. ________________________________; From: Louis Bergelson <notifications@github.com>; Sent: Monday, July 31, 2017 11:57 AM; To: broadinstitute/gatk; Cc: David Brown; Mention; Subject: Re: [broadinstitute/gatk] update com.google.guava version (#3102). @david-wb<https://github.com/david-wb> Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABxO-d5XTtUyeAI0GzCFLP5eVGYiyQJEks5sThWegaJpZM4N31U->.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834:907,plugin,plugin,907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834,4,['plugin'],['plugin']
Modifiability,"@ldgauthier 's error sounds like what I saw before when trying to run the joint genotyping pipeline. When I spoke about it with @ruchim she said that based on some experiments she did and conversations with the production team she thought it was a symptom VM's running under PAPI; Slack excerpt:. ```; rmunshi [9:59 AM]; Last night I reached out to the Pipelines API folks; I ran a script that outputs the external IP address of the VM every 5 mins; and I see that after about ~17 hours, the request fails with. `curl: (6) Could not resolve host: metadata.google.internal` (edited); ```. So we decided that there's an effective limit of about 17 hours for VMs managed by PAPI at which point either the network configuration or metadata process server on the VMs changes, causing these failures. I worked around the issue by increasing my scatter interval count such that no tasks took longer than the ~17 hours that seems to be the critical point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412938932:710,config,configuration,710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412938932,1,['config'],['configuration']
Modifiability,"@ldgauthier ; My thinking on not doing the larger tests was that the native code hasn't changed for this support, so performance and functionality shouldn't see anything unexpected. Additionally, we technically do ""incremental import"" whenever the import is batched currently. We're just extending that same paradigm to extend beyond the case where the initial GenomicsDBImport command is used. Of course, all of this is not to say I don't want to do the larger tests...just wondering if we could capture that in a separate issue? @droazen mentioned that there's a tentative plan for a new GATK release this week and we would like to have this feature in there, if you agree. We'll work in parallel on the performance testing you requested. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-518327043:288,extend,extending,288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-518327043,2,['extend'],"['extend', 'extending']"
Modifiability,@ldgauthier @davidbenjamin please take a look. . Don't allow the number of lines changed intimidate you... (most are in test resource files). The first commit contains the actual main code changes. . The second and third commits update the test resources (where most of the changed lines come from) and test code. . The very last commit changes the default radius to 2... I was planning to set it to 0 since it is more parsimonious (less complex configuration) but it may well affect sensitivity and certainly changes the PL/QUAL values so I guess set the value two the current 2 (for PLs) is a safer and more conservative approach until we evaluate what is the optimal value for this parameter. . Perhaps @davidbenjamin would like to have a different default for Mutec. This is last minute change and may break some of the integration test so bear with me if that is the case. However I think you can start reviewing the code at this point.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-516992042:446,config,configuration,446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-516992042,1,['config'],['configuration']
Modifiability,"@ldgauthier @jamesemery If `PossibleDeNovo` can't work with just founderIDs, then the constructor that takes a set of founderIDs should be removed (??) Or better yet, should the base `Pedigree` class be refactored to make more explicit the distinction between annotation subclasses that require the full pedigree and those that just require the founderIDs (perhaps as a separate PR) ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463263757:203,refactor,refactored,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463263757,1,['refactor'],['refactored']
Modifiability,"@ldgauthier Also, try running with the prebuilt jars (https://github.com/broadinstitute/gatk/releases/download/4.1.8.1/gatk-4.1.8.1.zip) and/or the latest docker image to eliminate your local build environment as a variable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663152910:215,variab,variable,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663152910,1,['variab'],['variable']
Modifiability,"@ldgauthier As discussed in person, could you please pull out a `GnarlyGenotyperEngine` with a `VariantContext finalizeGenotypes(VariantContext)` public entry point, so that we can do gnarly genotyping in BigQuery? You can see the version @jonn-smith wrote here: . https://github.com/broadinstitute/gatk/blob/jts_bigquery_spark_example/src/main/java/org/broadinstitute/hellbender/tools/evoquer/GnarlyGenotyperEngine.java. (But note that the version above does not exactly match the latest version of your code -- it's just an example of the refactoring we'll need in this branch). I think once this is done, and the few comments I add just now are addressed, and this branch is updated to the latest and greatest version of your tool, this can be merged",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-495344843:541,refactor,refactoring,541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-495344843,1,['refactor'],['refactoring']
Modifiability,"@ldgauthier I think at some point we removed example JSONs in both the CNV and M2 WDL directories. I believe the reasoning was that those JSONs were mostly non-informative templates that could just as easily be generated with `womtool inputs`; since they were also not tested (in contrast to the JSONs used by the Travis WDL tests), they had to be kept in sync manually. @davidbenjamin @LeeTL1220 can correct me if I'm wrong. In contrast, providing Jack's hyperparameters for WES via JSONs will actually be informative! However, we will inevitably run into some issues touched upon in https://github.com/broadinstitute/gatk/issues/4719. I agree that it would be desirable to set some default WES/WGS hyperparameters in the featured workspace. However, I hope this wouldn't require two separate workspaces for WES/WGS or any shenanigans like that. Ideally, this sort of thing could be covered at the tool level with argsets, as mentioned in that issue. @droazen any updates there?. In any case, I'm not sure having the JSON in this repo and not covered by any tests is what we want. ; Maybe @bshifaw can chime in? Are the featured workspaces covered by tests elsewhere? What is the current SOP for taking workflows from this repo, turning them into featured workspaces, and populating their configurations?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-505971851:1290,config,configurations,1290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-505971851,1,['config'],['configurations']
Modifiability,"@ldgauthier Let me know once you've had the chance to do that `GnarlyGenotyperEngine` refactoring discussed above, and I'd be happy to give this a (hopefully) final look.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-499240904:86,refactor,refactoring,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-499240904,1,['refactor'],['refactoring']
Modifiability,"@ldgauthier Some parts of taking splitting MNPs at the end of HaplotypeCaller are easy: breaking eg one DNP at position n into a SNP at n and a SNP at n + 1, letting the SNPs inherit the PLs, AF, and AD (okay, this isn't quite right because a read might end in the middle of the MNP, but close enough) of the parent MNP. . . but the general problem of splitting annotations seems like it might be too tricky. I'm leaning toward instead just modifying `AssemblyBasedCallerGenotypingEngine.phaseCalls()`. It seems that this phasing relies very heavily on perfect phasing or anti-phasing and that even one questionable haplotype with incorrect phasing can spoil things. I would guess that we could improve the phasing by making some simple guess as to which haplotypes are real. Basically, the problem is that while HaplotypeCaller imposes ploidy on alleles, it does not do so on haplotypes, and so phasing information is diluted. With your permission I would like to merge this PR and open a new issue for improving `phaseCalls`. After all, the issue is fixed in M2, and HC now has a perfectly good MNP mode, with the caveat that it doesn't interact nicely with GVCF mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-384836262:175,inherit,inherit,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-384836262,2,['inherit'],['inherit']
Modifiability,"@ldgauthier Tests are still failing because I haven't updated test vcfs. Before I do so could I get your opinion? Here's a summary of the rationale behind each commit:. * fa34758 When we get to `realignReadToBestHaplotype` we have discarded bases outside of the assembly region but we still have hard clips in the read Cigar. This change forces us to keep those Cigar elements after realigning to the best haplotype so that we know how far past the assembly window the read extended.; * 6af7ad4 After the above change, `BaseQualityRankSum` was liable to look for discarded bases in the hard-clipped part of the read. This fixes that.; * 952d217 The `Clipping` annotation doesn't do anything. It counts the number of hard clips, but pre-this PR there are no hard clips because those bases don't get realigned to the best haplotype and post-this PR the ""hard clips"" are just bases outside the assembly region. As a placeholder I'm setting it to zero (note how this doesn't break any tests!) but really I think we should just get rid of it.; * This PR introduced some off-by-one errors in the depth annotation (but not the ADs). While looking into this I found an apparent bug where some reads that don't overlap a variant get counted in the depth. The issue was that we were counting clipped bases in the overlap. I don't think this is correct because by this point in the code we have unclipped soft clips and gone through local reassembly. Therefore, anything clipped here is a part of the read we truly don't believe belongs anywhere near the assembly region. This change alone breaks the tests with a few off-by-one DP fields.; * 8c51c0a Uses hard clips in the Cigar to correct read position annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4956#issuecomment-400755806:474,extend,extended,474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4956#issuecomment-400755806,1,['extend'],['extended']
Modifiability,"@ldgauthier Well, there is always the `@ExperimentalFeature` tag if you think it's appropriate in this case. But if @meganshand did a pass to clean up / refactor the old code, `@BetaFeature` might be the right label....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8933#issuecomment-2261126897:153,refactor,refactor,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8933#issuecomment-2261126897,1,['refactor'],['refactor']
Modifiability,"@ldgauthier defer to you on this, but agree that it seems confusing/misleading, especially in the case of large ref blocks with highly variable depth",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7185#issuecomment-824151659:135,variab,variable,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7185#issuecomment-824151659,1,['variab'],['variable']
Modifiability,"@lucidtronix . Thanks for the explanation. Here are a few lines with the FILTER and INFO fields. Let me know if you need a larger subset. I would guess that since DP is the total depth for 5000 subjects instead of just 1 that would likely be the culprit. Maybe average depth across samples could be used for a replacement variable when there are multiple samples. . ```; VQSRTrancheSNP99.70to99.80 AC=8;AF=0.0008391;AN=9532;BaseQRankSum=-0.915;CNN_1D=-16.118;ClippingRankSum=0;DP=177452;ExcessHet=3.0267;FS=6.543;InbreedingCoeff=-0.002;MLEAC=8;MLEAF=0.0008391;MQ=71.41;MQRankSum=0.005;NEGATIVE_TRAIN_SITE;QD=10.23;ReadPosRankSum=0.483;SOR=1.039;VQSLOD=-3.08;culprit=MQRankSum; VQSRTrancheSNP99.70to99.80 AC=62,81;AF=0.006477,0.008462;AN=9570;BaseQRankSum=0.398;CNN_1D=-16.118;ClippingRankSum=0;DP=196764;ExcessHet=2.802;FS=0;InbreedingCoeff=-0.0026;MLEAC=61,67;MLEAF=0.006373,0.007;MQ=68.23;MQRankSum=-0.961;NEGATIVE_TRAIN_SITE;QD=3.96;ReadPosRankSum=-0.318;SOR=0.666;VQSLOD=-5.206;culprit=MQRankSum; VQSRTrancheSNP99.70to99.80 AC=117;AF=0.012;AN=9574;BaseQRankSum=0;CNN_1D=-16.118;ClippingRankSum=0;DP=203481;ExcessHet=1.8042;FS=0.593;InbreedingCoeff=0.0034;MLEAC=117;MLEAF=0.012;MQ=55.51;MQRankSum=1.32;NEGATIVE_TRAIN_SITE;QD=6.25;ReadPosRankSum=0.087;SOR=0.642;VQSLOD=-5.629;culprit=MQRankSum; VQSRTrancheSNP99.70to99.80 AC=21;AF=0.002193;AN=9574;BaseQRankSum=0;CNN_1D=-16.118;ClippingRankSum=0;DP=209533;ExcessHet=3.1253;FS=0;InbreedingCoeff=-0.0027;MLEAC=21;MLEAF=0.002193;MQ=57.8;MQRankSum=1.19;NEGATIVE_TRAIN_SITE;QD=4.35;ReadPosRankSum=-0.075;SOR=0.695;VQSLOD=-5.57;culprit=DP; VQSRTrancheSNP99.80to99.90 AC=1;AF=0.0001044;AN=9572;BaseQRankSum=-2.379;CNN_1D=-16.118;ClippingRankSum=0;DP=212253;ExcessHet=3.0108;FS=0;InbreedingCoeff=-0.0003;MLEAC=1;MLEAF=0.0001044;MQ=186.25;MQRankSum=0.084;QD=0.28;ReadPosRankSum=-0.743;SOR=0.798;VQSLOD=-17.7;culprit=MQ; VQSRTrancheSNP99.80to99.90 AC=5214;AF=0.545;AN=9570;BaseQRankSum=-1.071;CNN_1D=-16.118;ClippingRankSum=0;DP=276543;ExcessHet=160;FS=10.66;",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5101#issuecomment-412996579:322,variab,variable,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5101#issuecomment-412996579,1,['variab'],['variable']
Modifiability,"@lucidtronix Are the environment variables that you added to the Docker env essential to realize the speed 2x improvement ? I'm reluctant to just add them to the Docker env without understanding what they're doing and whether/how they impact other components. i.e., changing OPEN_MP thread affinity/pinning params etc. might impact the native Intel PairHMM implementation (also @samuelklee will these impact CNV) ? Another option is reduce the scope of them and set them only for the specific tool(s), possibly exposed as command line arguments. The ScriptExecutor has control over the python process' environment and could easily propagate them to the so they only affect the particular Python process. But the values would have to be provided somehow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475614790:33,variab,variables,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475614790,1,['variab'],['variables']
Modifiability,"@lucidtronix Could you try this branch out by running your CNN tool and confirming that it runs to completion, produces correct output, and doesn't time out? It would be helpful if you could run it in a configuration that prior to this PR would reliably time out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4757#issuecomment-388099208:203,config,configuration,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4757#issuecomment-388099208,1,['config'],['configuration']
Modifiability,"@lucidtronix It would be great to get this into the upcoming release later this week, but see my questions above about the intent of the environment variable settings, and whether they're essential to achieve the speedup. Setting OPEN_MP_NUM_THREADS for the entire docker will potentially impact the native PairHMM code, so we'll either need to remove these, narrow the scope to tool/WDL, or better understand the intent/impact of these on the native code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476605177:149,variab,variable,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476605177,1,['variab'],['variable']
Modifiability,@lucidtronix Probably something's up with my configuration...; `; $ gcc -v; Using built-in specs.; COLLECT_GCC=gcc; COLLECT_LTO_WRAPPER=/Users/markw/anaconda/envs/py27/bin/../libexec/gcc/x86_64-apple-darwin11.4.2/4.8.5/lto-wrapper; Target: x86_64-apple-darwin11.4.2; Configured with: ./configure --prefix=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --with-gxx-include-dir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/gcc/include/c++ --bindir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/bin --datarootdir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/share --libdir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/lib --with-gmp=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --with-mpfr=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_147764901285,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391065177:45,config,configuration,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391065177,3,"['Config', 'config']","['Configured', 'configuration', 'configure']"
Modifiability,"@lydiarck - Not yet our priorities shifted and I haven't had time to address this. . @jnktsj That's great to hear! I'm surprised because this is the first I've heard of it. If you have some time, I'd love to discuss it with you (and / or Niall and / or Carrie). I'm particularly interested in how you will incorporate new versions of the software as updates are made. Things are starting to slow down, so I should *actually* be able to start taking a look next or the following week. It's going to require refactoring several things deep in the Funcotator Engine, which is why it hasn't happened yet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-913047919:506,refactor,refactoring,506,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-913047919,1,['refactor'],['refactoring']
Modifiability,"@magicDGS Args like the config file that are truly optional (have no default value at all) do not show up in the command line or headers unless they're populated with some value. It should be pretty easy for ReadTools (which I think already has a common base class for its tools), to ensure a config file is never accepted by just precluding it via custom command line validation, or arg preprocessing. BTW, all tools built with GATK already have numerous common args that may or may not apply in a given tool context. For example, all of the ReadWalkers have a `--lenientVCFProcessing` arg. So I'm not even sure we need to make this hidden, since it will hide it from gatk users. My 2 cents. Others may feel differently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371819413:24,config,config,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371819413,2,['config'],['config']
Modifiability,"@magicDGS Can you move the make*Transformer methods up to GATKTool (at some point we'll have a plugin at that level), and then also integrate these with AssemblyRegionWalker ? We'll want to do the Spark tools as well, but we leave that for a separate PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-289924338:95,plugin,plugin,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-289924338,1,['plugin'],['plugin']
Modifiability,@magicDGS Do you have an example of something you need to configure that doesn't work well with java properties?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307798804:58,config,configure,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307798804,1,['config'],['configure']
Modifiability,"@magicDGS Esotericsoftware's minLog is used by Esotericsoftware's kryo. So, they would have to extend the class.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2751#issuecomment-315767184:95,extend,extend,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2751#issuecomment-315767184,1,['extend'],['extend']
Modifiability,"@magicDGS I agree that a fully implemented AbstractPluginDescritor class is a good idea. Why not do this in a separate PR, and would this be most appropriate in Barclay? I would be happy to take a stab or let you. We should look at the usage pattern of ReadFilters, VariantEval's two plugins, VariantAnnotation and perhaps others I'm not thinking about.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407469692:284,plugin,plugins,284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407469692,1,['plugin'],['plugins']
Modifiability,"@magicDGS I like your idea of making `TwoPassReadWalker` more configurable, with the ability to specify different filters/transformers/intervals per-pass, provided that tools that don't need this level of configuration don't have to override any additional methods.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4849#issuecomment-394446988:62,config,configurable,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4849#issuecomment-394446988,2,['config'],"['configurable', 'configuration']"
Modifiability,"@magicDGS I like your suggestion of factoring out a CountingFilter class that can be reused for both filter types. Ideally, I think we should first get https://github.com/broadinstitute/gatk/pull/2218/files in first (it has some minor changes to CountingReadFilter). Hopefully that will be soon. In the meantime, if you're so inclined, you might try doing the CountingFilter refactoring as part of this PR (which still needs tests), since you'll have two clients for it. That will definitely require some careful refactoring of the existing classes in order to retain the current CountingFilter behavior).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-261546961:375,refactor,refactoring,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-261546961,2,['refactor'],['refactoring']
Modifiability,"@magicDGS I made the return type `List<Object>` because the existing consumers that I know of (clp and docgen) have no explicit knowledge of the actual type used for any given plugin descriptor. The proper way to handle this would be to use the bounded type `List<? super T>`; if you just make it `List<T>`, then casual consumers like the clp would get a compile error for this:. List<Object> plugins = descriptor.getDefaultInstances();. However, other similar methods in the descriptor class aren't bounded (a couple of them should be); and I didn't want to include that change in the docgen PR so I stayed consistent with the existing methods. I really should fix this in a separate PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2362#issuecomment-276224076:176,plugin,plugin,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2362#issuecomment-276224076,2,['plugin'],"['plugin', 'plugins']"
Modifiability,"@magicDGS I'd strongly prefer not to introduce a read filter descriptor hierarchy if we can avoid it, as it will be tricky to get right, and add complexity. We definitely need to be able to extend the package list used by the descriptor to find plugins, but as you point out we'll be able to use the configuration mechanism for that. For before/after-analysis filters, I expect that we'll just add that directly to the existing plugin once we resolve https://github.com/broadinstitute/gatk/pull/2085 (which I hope to get to this week). I think the rest of the cases can be addressed by overriding makeReadFilter and providing custom behavior of filter merging. If this turns out to be something truly common, we could consider allowing the tool to inject an argument collection into the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-274970451:190,extend,extend,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-274970451,5,"['config', 'extend', 'plugin']","['configuration', 'extend', 'plugin', 'plugins']"
Modifiability,"@magicDGS I'm still missing why this wouldn't work for downstream projects (as long as they load Main or some Main-derived class). I think the owner config issue is different; for locale, we need to always force US. Can you verify this, or maybe provide more details about what case doesn't work ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324622945:149,config,config,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324622945,1,['config'],['config']
Modifiability,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:353,variab,variable,353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259,4,['variab'],['variable']
Modifiability,"@magicDGS My take on these: I think the read filter plugin descriptor shouldn't be removed, since it also does filter merging, header propagation, etc. which need to be done even if you want to disable user command line control. (Also, if you remove it I would expect you'd get an NPE). So I would say that we should update the doc to say that you shouldn't remove it from the list, and should override `makeReadFilter` in the case where you want finer control. I know we talked a lot about the transformer issue a while back; I think the intention was that we would do the integration with the rest of the tool types as part of https://github.com/broadinstitute/gatk/issues/2160, but @droazen may recall differently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4651#issuecomment-381279453:52,plugin,plugin,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4651#issuecomment-381279453,1,['plugin'],['plugin']
Modifiability,@magicDGS Perhaps a better solution to this problem would be to refactor the -L code to be able to handle queryname sorted files (we could produce a very similar filter to your filter and add it to the traversal early),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5367#issuecomment-435175872:64,refactor,refactor,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5367#issuecomment-435175872,1,['refactor'],['refactor']
Modifiability,"@magicDGS Rather than have a special case for doc-only args, I think we should close this PR and include the config file arg as part of the arg collection you added in https://github.com/broadinstitute/gatk/pull/3998.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-377341373:109,config,config,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-377341373,1,['config'],['config']
Modifiability,"@magicDGS Sorry for the delay on these AssemblyRegion-related PRs. There is an effort at the Broad right now to validate the GATK4 `HaplotypeCaller` against the GATK3 version. Until this is complete, we're not accepting even minor changes to code on the critical path for the `HaplotypeCaller`, except for bug fixes that arise from the validation work. It's still possible that as a result of this validation work `AssemblyRegionWalker` may get refactored/altered to address problems discovered, so until we have a final version that produces acceptable results for `HaplotypeCaller` (and we're not quite there yet) other changes to that part of the codebase will have to wait. Sorry for the inconvenience -- once GATK4's `HaplotypeCaller` gets the official stamp of approval we will certainly find a way to get all of your changes in. In the mean time we have to ask you to be patient a little longer!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2371#issuecomment-287447471:445,refactor,refactored,445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2371#issuecomment-287447471,1,['refactor'],['refactored']
Modifiability,"@magicDGS The GATK versioning scheme is not related to the API -- it is targeted at end users rather than projects using GATK as a library. Here's a slide that explains it:. <img width=""824"" alt=""gatk_versioning"" src=""https://user-images.githubusercontent.com/798637/38042254-e5bb85a4-3281-11e8-8d83-017bb6b73fda.png"">. As the slide mentions, we have given some thought to supplementing the main version number with an ""API version number"", but we'd have to more clearly define what constitutes the official public API for the GATK before doing so. On a side note, now that we're in general release it may be easier for you to get PRs for things like new walker types merged into the GATK proper, particularly if they are fairly self-contained and don't involve refactoring lots of engine classes. I was planning to ask whether you wanted to resurrect your `SlidingWindowWalker` PR at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4603#issuecomment-376946968:762,refactor,refactoring,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4603#issuecomment-376946968,2,['refactor'],['refactoring']
Modifiability,"@magicDGS The HaplotypeCaller traversal has undergone some changes in the past few weeks to improve performance and bring the output of the tool closer to GATK3. There is now an `AssemblyRegionWalker` that divides the intervals into active and inactive regions, in a greatly simplified version of the GATK3 traversal. Initially, I did plan on having `AssemblyRegionWalker` extend the former `ReadWindowWalker`, or an adapted version of your `SlidingWindowWalker`, and I did implement it like this at first, but ultimately I collapsed it into a single class for several reasons:; - Inheriting from a more generic traversal type caused usability issues and confusion with respect to the command-line arguments. The `ReadWindow` was the unit of processing for the superclass, but for `AssemblyRegionWalker` it was the unit of I/O and `AssemblyRegion` was the unit of processing, and I couldn't update the docs for `ReadWindowWalker` to clear up the confusion without mentioning `AssemblyRegion`-specific concepts.; - The `ReadShard` / `ReadWindow` was/is **only** there to prove that we can shard the data without introducing calling artifacts, and to provide a unit of parallelism for the upcoming Spark implementation. It's not something we really want to expose to users as a prominent knob, and we may hide it completely in the future once the shard size is tuned for performance.; - Inheriting from a more abstract walker type caused a number of other problems as well: methods that should have been final in the supertype could no longer be made final, with the result that tool implementations could inappropriately override engine initialization/shutdown routines. Also, there were issues with the progress meter, since both the supertype traversal and subtype traversal needed their own progress meter for their different units of processing. Ultimately it was just too awkward and forced, and the read shard is something that we eventually want to make an internal/encapsulated implementation d",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513:373,extend,extend,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513,2,"['adapt', 'extend']","['adapted', 'extend']"
Modifiability,"@magicDGS The problem with exposing the datasources to walkers is that they would be able to invalidate the entire traversal. For example, a `ReadWalker` could alter the traversal intervals on the reads datasource mid-way through traversal from within `apply()`, or it could cause the reads iterator used by the engine to get closed by issuing a separate `iterator()` call on the datasource, which would cause the rest of the traversal to fail. This is why I feel strongly that the datasource objects should not be directly accessible to walker-based tools. Note that it's still possible for walkers to create their own, separate datasources without reaching into the ones used by the engine, or a tool author can extend `GATKTool` directly rather than one of the walker base classes and have the freedom to access everything (which was not possible before this PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4964#issuecomment-401423305:714,extend,extend,714,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4964#issuecomment-401423305,1,['extend'],['extend']
Modifiability,"@magicDGS This seems like a good idea. I have a few comments.; 1. It seems like there should be an analogous function to `getPackageList()` where you set the list of individual classes, maybe `getNamedToolList()`.; 2. It seems like there's a design flaw in the `Main` class. I thought that the intent was that people could inherit from `Main` and override `getPackageList()` in order to substitute their own packages. But for some reason `getPackageList()` is static which is preventing that from happening. I think we should make it non-static which would allow a subclass of main to just override `getPackageList` and `getNamedToolList()`. What does your derived main class look like now?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2204#issuecomment-255832583:323,inherit,inherit,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2204#issuecomment-255832583,1,['inherit'],['inherit']
Modifiability,"@magicDGS We like the idea of making this configurable. We're not sure that this is the best mechanism for doing so though. We've been thinking about possibly including a standardized mechanism for configuring properties, i.e. some property file in the jar that could then be overridden by downstream projects. We don't know a great mechanism for doing that though. . Do you have any thoughts? Maybe using something like [commons-configuration](https://commons.apache.org/proper/commons-configuration/userguide/user_guide.html). It seems like we have a number of places that need this sort of configuration, and it would be good if we had a standard way of doing so instead of relying on little hacks for each instance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2156#issuecomment-265240247:42,config,configurable,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2156#issuecomment-265240247,5,['config'],"['configurable', 'configuration', 'configuring']"
Modifiability,"@magicDGS We talked about this a bit today. I think we should get https://github.com/broadinstitute/gatk/pull/4469 finished and merged, and then rebase this on top of that. Then we should put the remaining arguments, including the ""doc-only"" config file arg, as well as the special arguments collection, into the interface and default implementation class that you've defined here. Then we can do a detailed review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-377344569:242,config,config,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-377344569,1,['config'],['config']
Modifiability,"@magicDGS We talked with our ops people and it looks like we periodically purge anything older than 60 days, so this snapshot is gone. We're going to try to streamline what we upload, which will then allow us to extend the retention time for these things. Hopefully in the meantime you can rebuild what you need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4565#issuecomment-375725088:212,extend,extend,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4565#issuecomment-375725088,1,['extend'],['extend']
Modifiability,"@magicDGS We will definitely be keeping the `GATKRead` interface around for the foreseeable future. When the HTSJDK 3.0 interfaces materialize we'll re-evaluate, but it's possible that we would continue to code against `GATKRead` even then, as our `SAMRecord` -> `GATKRead` adapter layer does some useful caching, and having our own interface has certain advantages (as well as disadvantages).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854:274,adapt,adapter,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854,1,['adapt'],['adapter']
Modifiability,"@magicDGS We've inherited customCommandLineValidation() from picard, but it never really caught on as a way to do things in GATK. The fact that it's output is inconsistent with the rest of the command line parsing is an accident and should be fixed. . I think the right thing to do here would be to make `customCommandLineValidation()` into a `void` method that either throws a `CommandLineException` or doesn't. It will take some changes to a few tools but it will make things less confusing in the long run. Then you can move the call to customCommandLineValidation to just after the call to `parseArgs` like you've done, but we can remove the custom code to print error messages since it will just be handled by the regular exception handling.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255845846:16,inherit,inherited,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255845846,1,['inherit'],['inherited']
Modifiability,"@magicDGS Yes, I think this should be closed in favor of a PR to make `ReadTransformers` into plugins after the merge of https://github.com/broadinstitute/gatk/pull/2085. The plugin framework implemented by @cmnbroad allows for plugin classes to themselves contain command-line arguments, so you could add an argument directly to the `MisencodedBaseQualityReadTransformer` to control whether misencoded quals should be fixed or generate an error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245992067:94,plugin,plugins,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245992067,3,['plugin'],"['plugin', 'plugins']"
Modifiability,"@magicDGS is correct that no annotations are tagged as `@DocumentedFeature` yet, but thats just because nobody has done it. The plugin (which I think @jamesemery is planning to implement soon), is a completely separate issue - the `@DocumentedFeature` annotations can be added either way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-342823633:128,plugin,plugin,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-342823633,1,['plugin'],['plugin']
Modifiability,"@magicDGS, is this the same Mac as the one in #1985? Assuming yes, this crash happens because AVX is not supported. We had a check for AVX in GKL 0.2.0, but the call was removed by mistake in 0.3.0. . Sorry about that, we'll fix it in the next GKL release. In the meantime, you can use the workaround from #2302 and define this environment variable: `export GKL_USE_LIB_PATH=1`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-267115817:340,variab,variable,340,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-267115817,1,['variab'],['variable']
Modifiability,@magicDGS. It looks like there's some sort of compilation error here:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/walkers/markduplicates/MarkDuplicatesGATKIntegrationTest.java:180: error: incompatible types: inference variable T has incompatible bounds; ((GATKDefaultCLPConfigurationArgumentCollection) markDuplicatesGATK.configArgs).TMP_DIR = CollectionUtil.makeList(outputDir);; ^; equality constraints: String; lower bounds: File; where T is a type-variable:; T extends Object declared in method <T>makeList(T...); /gatk/src/test/java/org/broadinstitute/hellbender/tools/walkers/markduplicates/MarkDuplicatesGATKIntegrationTest.java:256: error: incompatible types: inference variable T has incompatible bounds; ((GATKDefaultCLPConfigurationArgumentCollection) markDuplicatesGATK.configArgs).TMP_DIR = CollectionUtil.makeList(outputDir);; ^; equality constraints: String; lower bounds: File; where T is a type-variable:; T extends Object declared in method <T>makeList(T...); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-355606477:236,variab,variable,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-355606477,8,"['config', 'extend', 'variab']","['configArgs', 'extends', 'variable']"
Modifiability,"@magicdgs Do you get all your dependencies from there, or only gatk? I assumed you had multiple repos configured so that it first resolves from central and then from artifactory. I'm not sure how to configure that sanely in maven, although I'm sure it's doable to someone who is less ignorant of maven then me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340474332:102,config,configured,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340474332,2,['config'],"['configure', 'configured']"
Modifiability,"@magicdgs You could include this filter in ReadTools and the plugin would discover it - after all, thats part of the purpose of plugins ;-). Anyway, at a minimum we should make sure the doc clearly explains when/how to use this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5367#issuecomment-434681393:61,plugin,plugin,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5367#issuecomment-434681393,4,['plugin'],"['plugin', 'plugins']"
Modifiability,"@mbabadi I've updated my PR to use miniconda3. @mbabadi @lucidtronix @samuelklee I think we should aim for tools that at least run out-of-box, without depending on any out-of-band configuration other than the conda env. On top of that we can provide guidance/configs for users on how to enable further optimizations, like g++. Does that sound like an achievable goal ?. As for the docker, we're going to have strike the right balance between image bloat and performance(including test performance). I think we're around 4+ gig now, and counting. Before the Python integration we were at 1.9G, and trying to find ways to reduce it. So lets see where we wind up but keep that in mind. Finally, we need to find a way to install the (GATK) python package(s) without depending on access to the GATK repo. Right now I think the gCNV branch has a ""pip install from source"" added to the conda env .yml. That will work on the docker at the moment (and thus on travis), but that won't work for non-docker users how don't have source/repo access. Also, one of the proposals to reduce the size of the docker is to remove the repo clone that is currently there. My proposal is that we change the gradle build to create an archive/zip of the python source (this would include the VQSR-CNN package code as well as gCNV kernel). We can then copy that on to the docker image, and pip-install it from the copy. That would retain the ability to always run travis tests based on the code in the repo, and also keep the nightly docker image in sync. We'll also have deliver the archive as an artifact somehow (perhaps including PyPi) for non-docker users.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350303277:180,config,configuration,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350303277,4,['config'],"['configs', 'configuration']"
Modifiability,"@mbabadi You can directly register more classes by adding them in GATKRegistrator. It doesn't fix the problem of needing custom configuration, but that's how we've been dealing with custom serializers, just put them all in all the time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272290322:128,config,configuration,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272290322,1,['config'],['configuration']
Modifiability,"@mcovarr Follow-up on the codecov thing. Apparently codecov is just not configured correctly? I asked at an Engine Team meeting and it looks like we're just not excluding test files for some reason, so that explains why it's calling out my test file as not covered. We could change it to ignore that directory, since it makes sense to not check for test coverage on test files, but I'm hesitant to include it here because it's sort of outside the scope of this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2000123077:72,config,configured,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2000123077,1,['config'],['configured']
Modifiability,"@mcovarr added two tests (and refactored a dataprovider, because I'm a good person) -- take another look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7864#issuecomment-1152529144:30,refactor,refactored,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7864#issuecomment-1152529144,1,['refactor'],['refactored']
Modifiability,"@mdayii I'd suggest that you search the gatk [forum](https://gatk.broadinstitute.org/hc/en-us/community/topics) for similar topics, or post this issue there, to see if anyone there can help with your configuration.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-896003059:200,config,configuration,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-896003059,1,['config'],['configuration']
Modifiability,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:425,polymorphi,polymorphic,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414,2,['polymorphi'],['polymorphic']
Modifiability,@mr-c I'm sorry this PR was forgotten about. Could you explain what it does? None of us are familiar with the `JAVAPATH` environment variable and googling didn't reveal anything useful.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3866#issuecomment-453586187:133,variab,variable,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3866#issuecomment-453586187,1,['variab'],['variable']
Modifiability,"@munrosa @ldgauthier Possible breakthrough. . First, what's definitely true about the het at 169510380 in 55_55003_F5region.bam when I reproduce the bug with `-L chr1:169510380 -ip 100`:. * The variant is considered active and triggers assembly, as it should.; * For every kmer size there are non-unique kmers in the reference, so it increases up to k = 85, the last attempt at which the engine relaxes the unique kmers requirement. (See `ReadThreadingAssembler` line 425).; * Once it reaches this kmer size, there are cycles in the graph and so no assembly is returned. (See `ReadThreadingAssembler` line 464). Thus no alt haplotype is discovered and the variant is missed. I believe there are two possible solutions.; * The assembly engine looks for cycles before pruning, but this order could be switched with no ill effects. In the case of this het there are no cycles after pruning because the apparent cycle was a poorly-supported path due to sequencing error. Here regular pruning works but the new `--adaptive-pruning` option would give a bit more security against false cycles.; * We don't actually have to check for cycles, especially in the last, desperate kmer attempt. Well, we do with the current recursive implementation of `KBestHaplotypeFinder`, but we *don't* in the Dijkstra's algorithm implementation currently under review: #5462. (Technical note: @ldgauthier I know I promised that this PR gives entirely equivalent results to the existing implementation, but technically this is only true if the existing implementation finishes in finite time. Due to the greedy -- but optimal -- nature of Dijkstra's algorithm, cycles do not cause issues). Personally, I am in favor of *both* solutions -- looking for cycles after pruning, and waiving the no-cycle requirement on the last attempt. They are complementary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-446465913:1009,adapt,adaptive-pruning,1009,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-446465913,1,['adapt'],['adaptive-pruning']
Modifiability,"@mwalker174 Hi Mark, I've refactored the code significantly, would you take a look again? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-386752928:26,refactor,refactored,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-386752928,1,['refactor'],['refactored']
Modifiability,"@mwalker174 Is encountering the same problem in the wild. He's reporting that it goes away if you specify the environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY. he's seeing the warning message:; ```; 16:55:09.480 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; ```; which *should* only appear during tests, so something is strange.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894:122,variab,variables,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894,3,"['config', 'variab']","['configured', 'variables']"
Modifiability,"@nalinigans: We now believe this is actually a GenomicsDB issue (or possibly an issue in the JNI layer.). @gokalpcelik was able to reproduce this problem on a set of 330 whole exomes. He found that if he ran GenotypeGenotypeGVCs from a GenomicsDB the memory usage climbed up to 10s of GB, but the java heap memory remained constant. He then tested firt extracting the combined GVCF from genomics db and then running GenotypeGVCFs and saw that memory usage for GenotypeGVCFs remained constant at 1 G. So we think this is probably a GenomicsDB issue. . GenomicsDBImport > GenotypeGVCFs ---- Memory ramps up immediately to 10s of gigabytes; GenomicsDBImport > SelectVariants to GVCF > GenotypeGVCFs ---- Memory is fixed at 1.1 GB. He can fill in more detail about the exact configuration if it helps.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2432001934:771,config,configuration,771,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2432001934,1,['config'],['configuration']
Modifiability,"@olavurmortensen, looks like TILEDB_DISABLE_FILE_LOCKING=1 did not get passed to the tool. Did you use `export TILEDB_DISABLE_FILE_LOCKING=1` as the command to set the environment variable?; If you have and see the issue, please try the attached zip that contains a shared library with some debug/tracing messages, so we can pinpoint the issue a little more.; [libgenomicsdb.zip](https://github.com/broadinstitute/gatk/files/2922767/libgenomicsdb.zip); To use the zip, from a bash shell:. ```; %: tar zxf libgenomicsdb.zip; %: export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; %: export TILEDB_DISABLE_FILE_LOCKING=1; %: gatk --java-options ""-Xmx4g -Xms4g"" GenomicsDBImport ...; ```; Please attach the log if you still see the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5740#issuecomment-468989614:180,variab,variable,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5740#issuecomment-468989614,1,['variab'],['variable']
Modifiability,"@olavurmortensen, yes please file a new issue. Please include your OS/platform version, your command, all the logs, any core dumps and steps to create a CIFS mount with your configuration in the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-468371003:174,config,configuration,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-468371003,1,['config'],['configuration']
Modifiability,"@olavurmortensen, yes, this has been tested on our systems and the fix will only mitigate NFS type of issues. However, there is improved logging of system errors now and we would like your inputs with logs and the exact NFS/CIFS configuration if you still run into issues to help us further debug what is happening. Please note that TILEDB_DISABLE_FILE_LOCKING env variable has to be set to 1 when doing the GenomicsDBImport.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946:229,config,configuration,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946,2,"['config', 'variab']","['configuration', 'variable']"
Modifiability,@psfoley The branch is failing tests after your latest commit with the error:. ```; > Could not resolve all dependencies for configuration ':runtime'.; > Could not find com.intel:genomicsdb:0.9.2-proto-3.0.0-beta-1+uuid-static.; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965:125,config,configuration,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965,1,['config'],['configuration']
Modifiability,"@rdbremel This got missed in the churn of issues. Does this happen repeatedly or is it a 1 time occurrence? We've seen similar issues in the past and tried to wrap them all in layers of retries, but sometimes things slip through.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-547962085:176,layers,layers,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-547962085,1,['layers'],['layers']
Modifiability,"@rickymagner I'd recommend postponing any further refactoring for future PRs post-release, in the interests of checkpointing this feature -- assuming that we're confident the feature works as intended and there are no side effects in other HaplotypeCaller codepaths. If the new argument is not already marked as Experimental, perhaps it should be until it's seen some more usage?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1847920221:50,refactor,refactoring,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1847920221,1,['refactor'],['refactoring']
Modifiability,@ronlevine @lbergelson Have you guys thought about the Spark case - I don't think this will capture logging output from Spark workers unless the settings get propagated through the config (we also don't propagate the verbosity IIRC). It might be a little misleading to allow specification of a file for Spark tools if it doesn't capture all of the output.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2751#issuecomment-315897839:181,config,config,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2751#issuecomment-315897839,1,['config'],['config']
Modifiability,"@ronlevine I know this a port from gatk3, but I think theres a bit of refactoring that can be done. It seems like it's more complicated than it needs to be. Could you take a look and see? In particular I'm not sure why things get converted to a bitset, it looks like you should just be able to derive the indecies directly and avoid creating a bitset. If I'm missing some detail and it can't be simplified let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1852#issuecomment-242102049:70,refactor,refactoring,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1852#issuecomment-242102049,1,['refactor'],['refactoring']
Modifiability,"@ronlevine, I think that the following should work for output the Esotericsoft's MinLog to write to a file:; * Implement in `LoggerUtils` a class extending `com.esotericsoftware.minlog.Log.Logger` that overrides the print method to append to the provided file.; * Use`Log.setLogger()` with an instance of that class.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2751#issuecomment-315706353:146,extend,extending,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2751#issuecomment-315706353,1,['extend'],['extending']
Modifiability,"@samuelklee ; My understanding: the code that **can** (and I think should) be borrowed from VCF is `CHROM`, `POS`, `ID`, `INFO`, with `END` from `INFO` extracted to be its own column. ; Then; * `FILTER` can be optional.; * `QUAL` can be optional but it is a nice-to-have feature as a quick-glance confidence measure, if that applies.; * `FORMAT` is going to be hard, because I understand the complaint that they can be wasting space, but I have seen VCF files that have rows with different numbers of fields in `FORMAT`, and that is spec-compliant. If this flexibility is allowed, i.e. allowing sample specific information to be missing on several rows, then the `FORMAT` column can be shared. Recap: only `REF`, `ALT` are missing, which is not much code I believe. I think VCF just happens to have a name that starts with V. Stripping out the `REF`, `ALT`, it is quite flexible for describing any annotated interval (OK, 0-length is up for debate) on a piecewise linear coordinate. And I just made myself sound like a VCF-lover. I simply think much of it can be reused.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481753416:870,flexible,flexible,870,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481753416,2,['flexible'],['flexible']
Modifiability,"@samuelklee @lucidtronix @asmirnov239 @davidbenjamin This is a good time for all of us to decide on GATK-style python coding (how much type hinting? how much documentation? etc.). I am adding you to this thread so that we can all have a say. **Code style**: The standard practice is to strictly follow [PEP-0008](https://www.python.org/dev/peps/pep-0008/). The python plugin for IntelliJ IDEA (=PyCharm) bark loudly when one deviates, which is pretty useful. **Docstring style**: I have written most of it in reST-style. In retrospect, perhaps [NumPyStyle](https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt) would have been a better choice. If I have time now, I will switch. Definitely at some point. You may want to wait until I check the I tick off ""fill in missing docs"" and ""further code cleanup"" boxes before you take a look at the code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344508765:368,plugin,plugin,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344508765,1,['plugin'],['plugin']
Modifiability,"@samuelklee DRAGEN STRE model doesn't actually make any alterations to the smith waterman parameters or how they work, it just works by adjusting the indel gap penalties that are used for the PairHMM. At one point we were concerned about SW parameters being different with dragen but as it turns out the biggest visible effect of the SW parameters on the output (the alignment we perform after haplotypes discovery) is irrelevant since they don't realign their reads internally. We kept the default gatk alignment behavior and thus the SW parameters that are used (for dangling head recovery which I believe are the old arguments) still match. As far as unifying the parameters I suspect it could be done though one wonders if there aren't risks where the different contexts in which we use the parameters will not perform as well with a unified set. Speculation on my part though. I agree with David that we should be cautious about making changes that will affect the HaplotypeCaller before November. . I support including an argument in any case (possibly multiple) to include the SW parameters. I would actually advocate we read these files in as tables of parameters where you simply point to on the command line to configure new parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705611993:1221,config,configure,1221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705611993,2,['config'],['configure']
Modifiability,"@samuelklee I'm not making any changes to the CNV collection classes. I; think none of this PR affects those classes. On Thu, Mar 1, 2018 at 4:19 PM, samuelklee <notifications@github.com> wrote:. > Sorry @droazen <https://github.com/droazen> @LeeTL1220; > <https://github.com/leetl1220>, can you give me a bit more context?; > @LeeTL1220 <https://github.com/leetl1220> is no longer using any of the; > CNV-specific collections classes that I had hoped might be Tribble-ized in; > the future, so I'm OK with any decisions you guys make that is specific to; > his classes (does @jonn-smith <https://github.com/jonn-smith> have an; > opinion?) I think that moving towards storing the config in the header is a; > good thing, in general.; >; > If we need to make corresponding changes to the CNV-specific collections; > classes, then we should talk more. Not all of those collections describe; > locatables, so I'm not sure how we could fit them in the Tribble framework.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369734330>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkzoWV1fcDEucTdcNZ_DggL0UW4M9ks5taGXhgaJpZM4Ru2it>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369735007:681,config,config,681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369735007,1,['config'],['config']
Modifiability,"@samuelklee If there are CNV tools that can't comfortably extend `GATKTool` as things stand now, then I think that we should adjust `GATKTool` to be more flexible until they can do so. This would help with certain long-term goals that the engine team has (such as all tools supporting NIO for all inputs, consistent sequence dictionary validation, etc.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358040921:58,extend,extend,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358040921,2,"['extend', 'flexible']","['extend', 'flexible']"
Modifiability,"@samuelklee It wasn't just a rebase, it was a complete rewrite because the old code had since become completely entangled with DRAGEN code. But I did it! Everything is passing, the code is dramatically simpler, and it's even a bit faster. I have done my best to make a coherent commit history. I would recommend reviewing one commit at a time in side-by-side diff mode. Note that some commits rip out old code and replace it with pseudocode, deferring the new code to a later commit. Other commits tell a story of what all the different caches meant in order to motivate the simpification of later commits. The baroqueness of the old code was motivated by three considerations:; * cache-friendliness -- traversing all arrays by incrementing the innermost index, reads. This is absolutely essential.; * flattening 3D arrays into 1D arrays. This was a premature optimization.; * Precomputing addition operations -- this was misguided. The DRAGEN code relied on these caches in a rather complex way, which fortunately turned out not to be necessary and which could be dramatically simplified. My notes on tracking all the variables from the parent genotype calculator down to the DRAGEN calculator are in this google doc: https://docs.google.com/document/d/1v6s57mUAwfj38nL3VdktjA059kYBkJfokq18IDy79E8/edit?usp=sharing. Good luck and don't hesitate to ask me to explain anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1023647476:55,rewrite,rewrite,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1023647476,4,"['rewrite', 'variab']","['rewrite', 'variables']"
Modifiability,@samuelklee Removed references to union and replaced with combine; @droazen Undid the IDE formatting changes.; @droazen Refactored to use `IntervalUtils.compareLocatables(....)`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3713#issuecomment-338739173:120,Refactor,Refactored,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3713#issuecomment-338739173,1,['Refactor'],['Refactored']
Modifiability,"@samuelklee Yes, setting the `GATK_LOCAL_JAR` and/or `GATK_SPARK_JAR` environment variables will cause the gatk script to use that jar, instead of looking in its directory for a jar. The naming of the jar itself also doesn't matter if you use the environment variable method.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3968#issuecomment-351734787:82,variab,variables,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3968#issuecomment-351734787,2,['variab'],"['variable', 'variables']"
Modifiability,@samuelklee correct me if I'm wrong - I should manually pass old default values to this set of commands?; ```; /soft/gatk-4.5.0.0/gatk PreprocessIntervals -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa --padding 0 -L chr1:10000-35000 -L chr22:198477-20003000 -imr OVERLAPPING_ONLY -O /outputs/gatk_intervals.interval_list. /soft/gatk-4.5.0.0/gatk AnnotateIntervals -L /outputs/gatk_intervals.interval_list -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -imr OVERLAPPING_ONLY -O /outputs/gatk_intervals.interval_list.annotated.tsv. /soft/gatk-4.5.0.0/gatk CollectReadCounts -I /inputs/E07002_normal_alignment.bam -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY -O /outputs/E07002_normal_alignment.bam.counts.hdf5; /soft/gatk-4.5.0.0/gatk CollectReadCounts -I /inputs/E07002_tumor_alignment.bam -R /ref/GRCh38.d1.vd1/GRCh38.d1.vd1.fa -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY -O /outputs/E07002_tumor_alignment.bam.counts.hdf5. /soft/gatk-4.5.0.0/gatk DetermineGermlineContigPloidy -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY --contig-ploidy-priors /outputs/a_valid_ploidy_priors_table.tsv.copy.tsv --output /outputs/COHORT_runDir --output-prefix COHORT --input /outputs/E07002_normal_alignment.bam.counts.hdf5 --input /outputs/E07002_tumor_alignment.bam.counts.hdf5. /soft/gatk-4.5.0.0/gatk GermlineCNVCaller --run-mode COHORT -L /outputs/gatk_intervals.interval_list --interval-merging-rule OVERLAPPING_ONLY --annotated-intervals /outputs/gatk_intervals.interval_list.annotated.tsv --contig-ploidy-calls /outputs/COHORT_runDir/COHORT-calls --input /outputs/E07002_normal_alignment.bam.counts.hdf5 --input /outputs/E07002_tumor_alignment.bam.counts.hdf5 --output /outputs/COHORT_runDir --output-prefix COHORT; ```. Or I can change some config file to skip this manual part?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1857396943:1870,config,config,1870,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1857396943,1,['config'],['config']
Modifiability,"@samuelklee os.environ would probably work, though it might be easier to set `theano.config.base_compiledir` directly so you don't have to worry about clobbering any other flags.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-390648848:85,config,config,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-390648848,1,['config'],['config']
Modifiability,"@samuelklee, thanks for the update and suggestion. I moved CollectAllelicCounts to the `Coverage Analysis` category. CollectFragmentCounts isn't on the list currently so I added it to the same. I hope I'm not missing a bunch of other new tools given I missed this one. . @yfarjoun ; - You are now in charge of deciding whether we should include authorship in code. What the Comms team wants is for authorship to NOT show up in the gatkDoc/javaDoc. If you want to keep them, author lines should be at the bottom and formatted so they do not show up in the documentation. Geraldine is fine with completely removing them if you prefer that. There is a format trick that has javaDoc skip the author line and @vdauwera would know this or I can get you what I see in other docs. Let either of us know.; - I can help you test your changes. I think the categories are good to go now so I will need to put these into both Picard and GATK HelpConstants.java, with the latter being a placeholder until the new Picard release is incorporated into the next GATK release, with variables that then must be included in each tool doc. I will find an example in a bit. Which tool do you want to test? @cmnbroad can explain the engineering details in engineering lingo if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349404645:1063,variab,variables,1063,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349404645,1,['variab'],['variables']
Modifiability,"@samuelklee: @LeeTL1220 and I just had a discussion about the writer aspect of this branch, and we agreed on the following:. 1. Lee will introduce a new header type to encapsulate the information that's currently passed in individually to the `writeHeader()` method in `AnnotatedIntervalWriter`. This makes the interface cleaner and more future-proof, since the signature will just become `writeHeader(AnnotatedIntervalHeader)`. 2. Lee will start writing out 3 additional structured header lines (as comment lines) to every header, declaring the names of the chrom, start, and stop columns. These will not be respected on input yet (he will still be relying on a config file to get the names of these 3 columns), but it's the first step in the direction of storing all necessary schema information in the header of each file, rather than separately from each file. 3. Lee will file a github issue to eventually use these 3 header lines on input, when they are present, to get the names of the chrom/start/stop columns (possibly still with a fallback to a separate config file if they aren't, but that is a point we can debate in a future PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369709447:663,config,config,663,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369709447,2,['config'],['config']
Modifiability,"@sooheelee . Here is my command:. ```; singularity exec gatk.simg test.pbs; ```; Here is test.pbs:. ```; gatk DetermineGermlineContigPloidy \; -L filtered.interval_list \; --input A1.count.hdf5 --input A2.count.hdf5 \; --contig-ploidy-priors contig_ploidy_priors_homo_sapiens.tsv \; --interval-merging-rule OVERLAPPING_ONLY \; --output out \; --output-prefix exomeseq \; --verbosity DEBUG \; --mean-bias-standard-deviation 0.01 \; --mapping-error-rate 0.01 \; --global-psi-scale 0.001 \; --sample-psi-scale 0.0001; ```. Here is the error message and I think the python environment has been activated by Singularity. The task failed when it tried to create directory of '/root/.theano'. ```; 17:03:28.891 INFO DetermineGermlineContigPloidy - Initializing engine; 17:03:28.896 DEBUG ScriptExecutor - Executing:; 17:03:28.896 DEBUG ScriptExecutor - python; 17:03:28.896 DEBUG ScriptExecutor - -c; 17:03:28.896 DEBUG ScriptExecutor - import gcnvkernel. Traceback (most recent call last):; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configdefaults.py"", line 1738, in filter_compiledir; os.makedirs(path, 0o770) # read-write-execute for user and group; File ""/opt/miniconda/envs/gatk/lib/python3.6/os.py"", line 210, in makedirs; makedirs(head, mode, exist_ok); File ""/opt/miniconda/envs/gatk/lib/python3.6/os.py"", line 220, in makedirs; mkdir(name, mode); PermissionError: [Errno 13] Permission denied: '/root/.theano'; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-433477833:1051,config,configdefaults,1051,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-433477833,1,['config'],['configdefaults']
Modifiability,"@sooheelee As an initial attempt to address this without too much refactoring, what about a two-step process where the user runs M2 with all samples eg `-I normal.bam -I tumor1.bam -I tumor2.bam -tumor sample1 -tumor sample2` (this would require a small code change to specify `-tumor` more than once) and then uses the common set of variants in GGA mode (PR #4601) on each sample individually?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4327#issuecomment-376960734:66,refactor,refactoring,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4327#issuecomment-376960734,1,['refactor'],['refactoring']
Modifiability,"@sooheelee It looks like split2_8.vcf.gz and split3_8.vcf.gz were generated with GATK 3 M2. In GATK 4 we only emit calls that are within the unpadded read shards, which I believe do not extend past the input intervals. Thus, as long as `SplitIntervals` returns disjoint subintervals (which it does), different scatters of M2 should produce disjoint calls. Could you try to reproduce the issue with GATK 4 M2?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-314866090:186,extend,extend,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-314866090,1,['extend'],['extend']
Modifiability,"@sooheelee We evaluated the S3 plugin, but found that it always localizes the entire file, which defeats the purpose of NIO. We are currently assessing how difficult it would be to patch the existing plugin. Issue is here: https://github.com/Upplication/Amazon-S3-FileSystem-NIO2/issues/103",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3708#issuecomment-374610893:31,plugin,plugin,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3708#issuecomment-374610893,2,['plugin'],['plugin']
Modifiability,"@sooheelee You are right, the python environment is not activated automatically. However, I manually activated the environment and then run my test.pbs, I still got the error. ```; [shengq2@cqs1 singularity]$ singularity shell gatk.simg; Singularity: Invoking an interactive shell within container...; Singularity gatk.simg:/scratch/cqs/softwares/singularity> source activate gatk; (gatk) Singularity gatk.simg:/scratch/cqs/softwares/singularity> sh test.pbs. ...; 21:27:03.205 INFO DetermineGermlineContigPloidy - Initializing engine; 21:27:03.210 DEBUG ScriptExecutor - Executing:; 21:27:03.210 DEBUG ScriptExecutor - python; 21:27:03.210 DEBUG ScriptExecutor - -c; 21:27:03.210 DEBUG ScriptExecutor - import gcnvkernel. Traceback (most recent call last):; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configdefaults.py"", line 1738, in filter_compiledir; os.makedirs(path, 0o770) # read-write-execute for user and group; File ""/opt/miniconda/envs/gatk/lib/python3.6/os.py"", line 210, in makedirs; makedirs(head, mode, exist_ok); File ""/opt/miniconda/envs/gatk/lib/python3.6/os.py"", line 220, in makedirs; mkdir(name, mode); PermissionError: [Errno 13] Permission denied: '/root/.theano'; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-433548346:825,config,configdefaults,825,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-433548346,1,['config'],['configdefaults']
Modifiability,"@sooheelee [Commenting on the forum discussion] `--alleles`, `--genotyping-mode`, and `--consensus` are inherited from a common parent class of Mutect2 and HaplotypeCaller and are inactive in GATK 4 Mutect2. I should fix this misleading situation. @cbao-bi's use case is important and the work-around that I gave on the forum is not satisfactory. I'm convinced that it's worth doing it right. Let me tentatively guess that I can put in a good force-calling mode within two months.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4555#issuecomment-375935335:104,inherit,inherited,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4555#issuecomment-375935335,1,['inherit'],['inherited']
Modifiability,"@srikarchamala We haven't heard from enough people to make this a priority. However, we are doing a big refactoring to make all of the Mutect2 annotations and filters inherently multiallelic so that splitting with external tools before or after FilterMutectCalls ought not to cause problems.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-570229469:104,refactor,refactoring,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-570229469,1,['refactor'],['refactoring']
Modifiability,"@t-ogasawara @frank-y-liu @gspowley @paolonarvaez @droazen @lbergelson please comment on the following proposal. The proposal is that we would spin off native PairHMM as a separate project/repo on github and host AVX code there and have alternative implementations extend that project/repo (by creating repos that depend on the AVX one). . In other words, now we have 1 repo, broadinstitute/gatk. After the proposed change we'll have 3 repos (all BSD licensed):; 1) broadinstitute/gatk; 2) broadinstitute/nativePairHMM-AVX; 2) broadinstitute/nativePairHMM-PPC. We will duplicate the native code (AVX and PPC will be separate copies of C++ files etc) to simplify the testing burden. The parties interested in working on a specific architecture will contribute code directly to the respective architecture-specific repo and gatk will take occasional updates of those repos. The gatk repo will depend on the other two. The PPC repo will depend on the AVX repo (and any other native repos will depend on the AVX one). The avx and ppc repos will have their own build systems and unit tests against the new interface. The AVX repo will expose something like the following Java API (to be worked out in detail). ```; //Used to copy references to byteArrays to JNI from reads; public final class JNIReadDataHolderClass {; public byte[] readBases = null;; public byte[] readQuals = null;; public byte[] insertionGOP = null;; public byte[] deletionGOP = null;; public byte[] overallGCP = null;; }. //Used to copy references to byteArrays to JNI from haplotypes; public final class JNIHaplotypeDataHolderClass {; public byte[] haplotypeBases = null;; }. public interface NativePairHMMKernel extends AutoCloseable { . /**; * Function to initialize the fields of JNIReadDataHolderClass and JNIHaplotypeDataHolderClass from JVM.; * C++ code gets FieldIDs for these classes once and re-uses these IDs for the remainder of the program. Field IDs do not; * change per JVM session; *; * @param readDataHolderClass class",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864:265,extend,extend,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864,1,['extend'],['extend']
Modifiability,"@takutosato This is needed to rev gatk public, which in turn is needed for the Mutect2 refactoring I'm working on. Can you review?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2239#issuecomment-257135814:87,refactor,refactoring,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2239#issuecomment-257135814,1,['refactor'],['refactoring']
Modifiability,@tedsharpe @SHuang-Broad I've tried to address your comments -- want to have a another look? . Due to issues in the class I backed out my usage and refactoring of SATagAlignmentBuilder and SATagAlignment and just went with my own simple little parser.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2684#issuecomment-301569060:148,refactor,refactoring,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2684#issuecomment-301569060,2,['refactor'],['refactoring']
Modifiability,@tedsharpe How much effort do you think it would be to adapt the current BWA bindings to bwa-mem2?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7014#issuecomment-758176744:55,adapt,adapt,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7014#issuecomment-758176744,1,['adapt'],['adapt']
Modifiability,"@tedsharpe not sure if this is what you meant.; Also, I think the ""ultimate"" solution might be marking `SVInterval` not final, but allows it to be extended, and child classes should name themselves with convention baked in.; What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5157#issuecomment-418886943:147,extend,extended,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5157#issuecomment-418886943,1,['extend'],['extended']
Modifiability,"@tomwhite After spending some time searching for this feature for my testing purposes, it would be helpful to expose the NIO adapter toggle directly from the command line in this branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5138#issuecomment-418494235:125,adapt,adapter,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5138#issuecomment-418494235,1,['adapt'],['adapter']
Modifiability,"@tomwhite I think the general goal of unifying the Spark/non-Spark tool hierarchies is worthwhile, but I don't like the idea of all tools having `if (sparkArgs.useSpark) {} else {}` boilerplate. If we do this, we should have separate abstract methods that get called automatically in the Spark/non-Spark cases. I also think we should wait to perform this refactoring until later in the quarter, after the Spark evaluation, and after we've standardized more on `Path` for inputs/outputs, as it will break a lot of downstream code in gatk-protected -- and we don't want to break all the tools more than once if we can help it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254228946:355,refactor,refactoring,355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254228946,1,['refactor'],['refactoring']
Modifiability,"@tomwhite Like we discussed this morning, we can and should get rid of the broadcast code but we should ideally first get some sort of plot we can point to in order to justify the change. This will also be useful for future presentations of our performance improvements. The plot would ideally be a comparison between the new distribution strategy and broadcasting compared across a variable number of cores, so the performance improvement can be better understood.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5127#issuecomment-416327226:383,variab,variable,383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5127#issuecomment-416327226,1,['variab'],['variable']
Modifiability,@tomwhite What do you think about this change? Do you need a scala 10 build of gatk? We could parameterize the build so that it can build both if necessary.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-260671311:94,parameteriz,parameterize,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-260671311,1,['parameteriz'],['parameterize']
Modifiability,"@tovanadler Review complete. Looks good, just a few comments. I have a few comments about the organization of duplicate marking. I think you've inherited some very old style code that could maybe use some refactoring. I think we do need to also include the histogram and the metrics headers. Those could be done in a separate ticket though. I'm a bit worried that the test is indeterministic. Unless I overlooked something which is likely, it seems like it might depend on the ordering of a PCollection which is undefined. This isn't problematic for the actual metric file, but might be for the tests. What do you think about reorganizing to output an annotation on only 1 of the ""best"" reads with the count of all optical duplicates in it's group. That would simplify the code, and since we only care about the global count it wouldn't change the information content.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126762958:144,inherit,inherited,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126762958,2,"['inherit', 'refactor']","['inherited', 'refactoring']"
Modifiability,"@tushu1232 Sorry for the delay. I'm looking into this. I think you've hit a serious bug in the gatk-launch script. Do you have $GATK_LOCAL_JAR set in your environment? . It looks like the case where a local jar is explicitly specified results in the environment variables not being properly defined, which means you end up hitting #2026. ; If they were properly defined you should be seeing the line `Snappy is disabled via system property` included in your standard out. . I've opened #2316 to deal with the issue. Until that's fixed though, the workaround is to invoke the jars directly and add `-Dsnappy.disable=true`. i.e. `java -Dsnappy.disable=true -jar $GATK_LOCAL_JAR SortSam --input BAM_BWA/SRR2.sorted.bam --output hpcinfra/hadoop/test.bam --SORT_ORDER queryname`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119418:262,variab,variables,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119418,1,['variab'],['variables']
Modifiability,"@vdauwera note that this modifies the path of the CNV methods doc (which is mostly out of date, but is still linked to in some Comms materials) from docs/CNVs/CNV-methods.pdf to docs/CNV/archived/archived-CNV-methods.pdf. The extended abstract on gCNV is a very technical description of the probabilistic model, but it might be worth referencing it for interested users until a preprint or publication is available.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5732#issuecomment-467976599:226,extend,extended,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5732#issuecomment-467976599,1,['extend'],['extended']
Modifiability,"@vdauwera when running spark tools through the gatk-launch-soon-to-be-just-gatk script, you use a `--` to separate arguments to the specific tool you're running from arguments that describe what sort of Spark setup you're trying to submit the job to. The most important of these is probably `sparkRunner`, which says what type of spark cluster you're using: `LOCAL` indicates that you want to simulate a spark cluster on your local machine using multithreading; `SPARK` indicates that you want to submit to a configured, dedicated spark cluster, in which case you have to pass the url to the master node, and `GCS` indicates that you want to use a cluster managed by Google Cloud Dataproc, in which case you need the name of the cluster. See https://github.com/broadinstitute/gatk#running-gatk4-spark-tools-on-a-spark-cluster for more info. Day-to-day on the SV team we primarily use dataproc, so the example command I was going to use for one tool looks like:. ```; ./gatk ParallelCopyGCSDirectoryIntoHDFSSpark \; --input-gcs-path gs://my-bucket/my-data-directory/ \; --output-hdfs-directory hdfs://my-dataproc-spark-cluster-m:8020/my-data \; -- \; --sparkRunner GCS \; --cluster my-dataproc-spark-cluster; ```. I wasn't sure if it was cool to use the GCS/dataproc version or if we'd rather not tie ourselves to GCP in the examples. In this particular case I feel like it might be appropriate since it's a GCS-specific tool, but my question was more about our general strategy.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349358724:509,config,configured,509,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349358724,1,['config'],['configured']
Modifiability,"@vilay-nference Thank you for doing this work. It's nitpicky annoying stuff to figure out.; ; I have one additional request. Instead of addding additional direct implementation dependencies, could we specify the transtive version requirements in a [gradle constraints block](https://docs.gradle.org/current/userguide/dependency_constraints.html)? . That will: ; 1. make it clear that we don't rely on these directly; 2. prevent us from keeping them around if we do something like remove hadoop in the future; 3. lets us rewrite those force blocks to instead define minimum versions so if the libraries move forward in the future we're not accidentally holding on a to an old version",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2297074810:520,rewrite,rewrite,520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2297074810,2,['rewrite'],['rewrite']
Modifiability,"@vilay-nference Were you able to get this configuration to pass tests on your end? I've attempted to incorporate your changes into https://github.com/broadinstitute/gatk/pull/8998, but I'm running into issues with hadoop and protobuf incompatibilities. I see the same problem with your branch when I try to run tests on it. (I also can't run tests without disabling -Werror on your branch since there are still some unresolved deprecation and other minor issues). Errors look like this:. ```; Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.security.proto.SecurityProtos [in thread ""IPC Server handler 1 on default port 64812""]; 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.<clinit>(ClientNamenodeProtocolProtos.java); ```. and you can easily trigger one by running `ParallelCopyGCSDirectoryIntoHDFSSparkIntegrationTest`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2412827680:42,config,configuration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2412827680,1,['config'],['configuration']
Modifiability,"@vruano What happens if you make your tool extend `GATKSparkTool` directly, rather than `VariantWalkerSpark`, then do the following in your `runTool()` method?. ```; final VariantsSparkSource variantsSource = new VariantsSparkSource(ctx);; final List<SimpleInterval> intervals = hasIntervals() ? getIntervals() : IntervalUtils.getAllIntervalsForReference(getBestAvailableSequenceDictionary());; final JavaRDD<VariantContext> variants = variantsSource.getParallelVariantContexts(vcf, intervals);; ```. And then do a `variants.mapPartitions()` call on the resulting `variants` RDD to process each variant?. Also, at-mentioning @tomwhite here to comment on the `VariantWalkerSpark` issue, since he wrote that class.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290236139:43,extend,extend,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290236139,1,['extend'],['extend']
Modifiability,@vruano You could extend `CommandLineProgram` rather than `GATKTool`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-576783251:18,extend,extend,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-576783251,1,['extend'],['extend']
Modifiability,@vruano in addition to refactoring MAthUtils I also engaged in a few boy scout rule activities.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2235#issuecomment-256973513:23,refactor,refactoring,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2235#issuecomment-256973513,1,['refactor'],['refactoring']
Modifiability,@vruano refactoring is done -- back to you,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-841279671:8,refactor,refactoring,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-841279671,1,['refactor'],['refactoring']
Modifiability,"@wangdy12 .I get the same issue: when use HaplotypeCallerSpark on a cluster, It lose a lot of variable sites and the result jitter to the same input bam. and running on local mode, the result is good.; But I fix the code according to your way. It does not work and get the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4231#issuecomment-371410958:94,variab,variable,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4231#issuecomment-371410958,1,['variab'],['variable']
Modifiability,"@wujh2017 Did you set up the appropriate conda environment as described in the README?. > Python 3.6.2, along with a set of additional Python packages, are required to run some tools and workflows. GATK uses the Conda package manager to establish and manage the environment and dependencies required by these tools. The GATK Docker image comes with this environment pre-configured. In order to establish an environment suitable to run these tools outside of the Docker image, the conda gatkcondaenv.yml file is provided. To establish the conda environment locally, Conda must first be installed. Then, create the gatk environment by running the command conda env create -n gatk -f gatkcondaenv.yml (developers should run ./gradlew createPythonPackageArchive, followed by conda env create -n gatk -f scripts/gatkcondaenv.yml from within the root of the repository clone). To activate the environment once it has been created, run the command source activate gatk. See the Conda documentation for additional information about using and managing Conda environments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4389#issuecomment-364748538:370,config,configured,370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4389#issuecomment-364748538,1,['config'],['configured']
Modifiability,"@xaviloinaz here's that feature you requested for configurable ordering of funotations via `VariantClassifications`. It's basically what we talked about - you supply a TSV file with `VARIANT_CLASSIFICATION SEVERITY`, and Funcotator will respect that new order. . Let me know if this won't work for what you wanted to do.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7673#issuecomment-1040805481:50,config,configurable,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7673#issuecomment-1040805481,1,['config'],['configurable']
Modifiability,"@xysj1989 We primarily run this workflow using the WDL on Terra. In this case, each GermlineCNVCaller shard is run on a separate VM using the GATK Docker. Hopefully, we can always at least guarantee that this default mode of running the workflow is functional and covered by tests. However, if you'd like to instead run multiple instances of GermlineCNVCaller locally, you may need to make sure certain environment variables are set appropriate. For example, I think you can address (2) above (the location of the temporary theano directory) by either setting environment variables or modifying your Theano configuration (see http://deeplearning.net/software/theano/library/config.html) appropriately. You may also want to check the GermlineCNVCaller task in the WDL to see how other variables are set there. Let me look into whether you can also address (1) in this way, or if this will require a GATK code change, and get back to you. (Of course, if you figure it out before me, please follow up!) Thanks again for bringing this to our attention.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548007200:415,variab,variables,415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548007200,5,"['config', 'variab']","['config', 'configuration', 'variables']"
Modifiability,"@yfarjoun I'm not understanding... If we're on the reverse strand, then we reach the adaptor at the 5' end of the forward strand i.e. at one `getMateStart() + 1`, which is what the code does now. If we're on the forward strand the equivalent logic would be `getMateEnd() + 1`, but no such method exists, so we use `read.getStart() + abs(read.getFragmentLength())`. Why is this not equivalent?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358740758:85,adapt,adaptor,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358740758,1,['adapt'],['adaptor']
Modifiability,"A comment from @ldgauthier:. The threshold for PLs to be considered uninformative is the same between GATK3 and 4, but the stack when it gets called is a little bit different. It might be changes in subsetting again because the methods that evaluate the ""informativeness"" in GATK3 are called updateGenotypeAfterSubsetting and createGenotypesWithSubsettedLikelihoods, which appear to have been refactored into AlleleSubsettingUtils in GATK4. I could see how if we calculate the sum before subsetting in GATK4 then it's smaller and uninformative, but that's speculation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2712#issuecomment-305601294:393,refactor,refactored,393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2712#issuecomment-305601294,1,['refactor'],['refactored']
Modifiability,"A few minor issues:. - [x] Change `--resource <blah>` to `--resource:<blah>` in tool-level documentation. EDIT: Added to the sl_lite_overlap branch mentioned below.; - [x] The VCF writer in VariantRecalibrator has a few conditionals to allow for VCF headers without contig lines, we could do the same for the writer in LabeledVariantAnnotationsWalker. EDIT: Added to the sl_lite_overlap branch mentioned below.; - [ ] Double check whether we should worry about any differences in extraction on test data (provided via email) from https://gatk.broadinstitute.org/hc/en-us/community/posts/7974912707099-VariantRecalibrator-IndexOutOfBoundsException. Probably nothing to worry about, and at least the error messaging in the new tools is more informative.; - [x] We could change the strategy for checking for resource overlaps to require allele-level matching (rather than only matching on start position, as was inherited from VQSR). A quick test on malaria shows that this can reduce the number of overlaps by O(10%), but performance doesn't really change too much. Branch is already open at https://github.com/broadinstitute/gatk/tree/sl_lite_overlap; - [ ] Expand the exact-match tests to cover some of these strategies, which were added separately in #8049 and merged to make a release deadline.; - [x] Catch the exception in https://github.com/broadinstitute/gatk/blob/fd782504d18b56dbc266c2b3bb4eb32f21916776/src/main/java/org/broadinstitute/hellbender/tools/walkers/vqsr/scalable/LabeledVariantAnnotationsWalker.java#L389 and throw the same message that is thrown in AS mode. Added in #8074.; - [x] Add message to the score tool that the scores HDF5 file will not be out when the input VCF is empty (such a message is already emitted about the annotations HDF5 file). Added in #8074.; - [ ] Megan suggested in the review of #8074 that dynamic disk sizing could be added to the WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1222787946:909,inherit,inherited,909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1222787946,1,['inherit'],['inherited']
Modifiability,"A fix I found for this issue is to modify `start_session_get_args_and_model` function in models.py from this:. ```; def start_session_get_args_and_model(intra_ops, inter_ops, semantics_json, weights_hd5=None, tensor_type=None):; K.clear_session(); K.get_session().close(); cfg = K.tf.ConfigProto(intra_op_parallelism_threads=intra_ops, inter_op_parallelism_threads=inter_ops); cfg.gpu_options.allow_growth = True; K.set_session(K.tf.Session(config=cfg)); return args_and_model_from_semantics(semantics_json, weights_hd5, tensor_type). ```. To this:. ```; import tensorflow as tf. def start_session_get_args_and_model(intra_ops, inter_ops, semantics_json, weights_hd5=None, tensor_type=None):; tf.keras.backend.clear_session(); tf.keras.backend.get_session().close(); cfg = tf.ConfigProto(intra_op_parallelism_threads=intra_ops, inter_op_parallelism_threads=inter_ops); cfg.gpu_options.allow_growth = True; tf.keras.backend.set_session(tf.Session(config=cfg)); return args_and_model_from_semantics(semantics_json, weights_hd5, tensor_type). ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-839720987:284,Config,ConfigProto,284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-839720987,4,"['Config', 'config']","['ConfigProto', 'config']"
Modifiability,A holdover for this is currently in place where we detect if no funcotations were produced at all. In that case we warn the user that they may have configured the reference version and data sources incorrectly.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4978#issuecomment-503219497:148,config,configured,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4978#issuecomment-503219497,1,['config'],['configured']
Modifiability,"A logger with configurable verbosity would be great, but low priority is fine. This is a very low priority issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-300304840:14,config,configurable,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-300304840,1,['config'],['configurable']
Modifiability,"A user reported this same issue and the error message does not give any location information in GATK 4.1.9.0 with VariantRecalibrator. ; [Link to the forum post](https://gatk.broadinstitute.org/hc/en-us/community/posts/360074618292-New-version-of-GATK-leads-to-VariantRecalibrator-error-?page=1#community_comment_360013419291).; Here is the message:; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantRecalibrator -V temp/vatiant_germline/sites.only.vcf.gz -O temp/vatiant_germline/recaliberation.indel.vcf --tranches-file temp/vatiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz --use-allele-specific-annotations -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz. 14:58:10.389 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 12, 2020 2:58:10 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:58:10.555 INFO VariantRecalibrator - --------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532:837,polymorphi,polymorphic,837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532,1,['polymorphi'],['polymorphic']
Modifiability,"According to this paper https://www.nature.com/articles/s41467-018-03590-5. it is: ""Each resulting qualified captured library with the SureSelect Human; All Exon kit (Aglient) was then loaded on *BGISEQ-5000 *sequencing; platforms, and we performed high-throughput sequencing for each captured; library. High-quality reads were aligned to the human reference genome; (GRCh37) using the Burrows-Wheeler Aligner (BWA v0.7.15) software. All; genomic variations, including single-nucleotide polymorphisms and InDels; were detected by *HaplotypeCaller of GATK *(v3.0.0).; "". On Wed, Dec 12, 2018 at 3:18 PM Louis Bergelson <notifications@github.com>; wrote:. > @yfarjoun <https://github.com/yfarjoun> Do you know if BGI's sequencing; > is compatible with our tools without any special treatment?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446729153>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0mujY7YzxUJ-6IPU8B7jPiZWQuzMks5u4WR3gaJpZM4ZQNxZ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514:487,polymorphi,polymorphisms,487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514,1,['polymorphi'],['polymorphisms']
Modifiability,"Actually what you said is correct: it is very painful to extend the `Main` class and use the current implementation. The simplest `Main` class that I'm using it's not extending the GATK one just because of the static methods (see the code [here](https://github.com/magicDGS/thaplv/blob/master/src/main/java/org/magicdgs/thaplv/Main.java)), that's why I would like to include this change. In few minutes I will commit the changes that you propose, including the method and the change from static. Thanks for the feedback, @lbergelson!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2204#issuecomment-255841430:57,extend,extend,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2204#issuecomment-255841430,4,['extend'],"['extend', 'extending']"
Modifiability,"Actually, just ran a WGS sample with 250bp bins that took ~4 hours to plot...pretty ridiculous! The R code is neither efficient nor well written, so I'm inclined to completely rewrite plotting in python (for ACNV, as well).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3554#issuecomment-329195610:176,rewrite,rewrite,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3554#issuecomment-329195610,1,['rewrite'],['rewrite']
Modifiability,"Added a few comments of my own -- requested that you refactor to check the index modification time in the `FeatureDataSource` constructors, rather than in the sequence dictionary validation routines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324:53,refactor,refactor,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324,1,['refactor'],['refactor']
Modifiability,"Additional feedback from the user for the mutect2 workflow. > ""Of note, it is really difficult and not really 'user-friendly' to have to predict disc space and runtime for Funcotator, which seem to depend (based on calculations you copied above from other Functotator workflows) on outputs of Mutect2 (eg vcf sizes), when here Mutect and Funcotator and bundled together. So I cannot see output of Mutect to predict values for Funcotator - especially not when I get to run this over hundreds of samples. It is also pricey to have jobs failing because of this. It would be much better to have these variables encoded, so that the algorithm uses Mutect outputs to predict memory etc. that it will need to run Funcotator downstream. If this is really how things work (and this is my current understanding), I really do not know how to estimate this for many samples without 'trial and error' that is both costly and it will take extremely long time....""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6680#issuecomment-651354230:597,variab,variables,597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680#issuecomment-651354230,2,['variab'],['variables']
Modifiability,"Agree with that, but also it will be nice to be able to configure it if used outside the AnnotationEngine - the same for other usages of OneShotLogger...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3828#issuecomment-345246188:56,config,configure,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3828#issuecomment-345246188,1,['config'],['configure']
Modifiability,"Agree with those above arguing that VCF isn't appropriate for this purpose, and would be a very bad fit. I certainly support the goal of adopting a single unified, standard format for tabular data throughout the GATK, however, and would ideally favor a solution at the HTSJDK/tribble level to get all the benefits that that provides, such as support for NIO and indexing (even if it means that engine team has to extend tribble to support records that are not `Locatable`). . We're happy to help with any efforts in the direction of unification, and would be eager to participate in any methods-wide discussions on this topic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-387100399:413,extend,extend,413,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-387100399,1,['extend'],['extend']
Modifiability,Agreed! And also with default value stored in the configuration file.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3471#issuecomment-324070716:50,config,configuration,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3471#issuecomment-324070716,1,['config'],['configuration']
Modifiability,"Ah the ""Tool Docs Index"" link thing is because I left out the extension on purpose; our php server is configured to grab whatever file is present with that basename, with a rule of precedence in case there are several with different extensions (which is useful because of reasons). But locally the browser doesn't know to do that. I'm putting in some logic to handle this, thanks for pointing it out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311098545:102,config,configured,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311098545,1,['config'],['configured']
Modifiability,"Ah, ok, so you would extend `Main` anyway even if we had a way to control which packages it looks in? That's good to know. Can you not use base test because of that GenomeLocParser? We should fix that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242816026:21,extend,extend,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242816026,1,['extend'],['extend']
Modifiability,Almost all of the CNV tools extend `CommandLineProgram` unless they are walkers or otherwise need to use `-L`.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-357534210:28,extend,extend,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-357534210,1,['extend'],['extend']
Modifiability,"Also as part of the mock-up, we should actually package the mock config files inside of our jar, load them off the classpath, and test file-based override ability.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353:65,config,config,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353,1,['config'],['config']
Modifiability,Also some tests for collection classes. Refactoring may avoid code duplication here.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3916#issuecomment-352080910:40,Refactor,Refactoring,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3916#issuecomment-352080910,1,['Refactor'],['Refactoring']
Modifiability,"Also, a necessary functionality is fragment-based counts. Perhaps a good starting point is bringing back Valentin's GATKReadPair which was removed as a part of XHMM-related code cleanup. Eventually, it is also useful to have the option of collecting various summary statistics and empirical distribution for features such as insert length, mapping quality, the position with respect to bins. Other things to consider are summary of orphan reads, reads with mates on other contigs, and reads with multiple alternate alignments. This requires a bit of good software engineering but it's a necessary one-time investment. This is a relatively high-priority refactoring given the growing interest in running gCNV on large datasets (gnomAD, gen psy cohort, TCGA).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3153#issuecomment-310507118:653,refactor,refactoring,653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3153#issuecomment-310507118,1,['refactor'],['refactoring']
Modifiability,"Also, could you provide at what level is the logging configured @jjfarrell ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373807025:53,config,configured,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373807025,1,['config'],['configured']
Modifiability,"Also, the cloud tests should be skipped by default (ie., in the case of no environment variables set).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279083759:87,variab,variables,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279083759,1,['variab'],['variables']
Modifiability,"Also, we might want to write some tests for gatk-launch, since it's starting to have lots of different invocation configurations and I find that any line of python code I don't actually run tends to have some horrible error that a compiler would have complained about.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2090#issuecomment-239881662:114,config,configurations,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2090#issuecomment-239881662,1,['config'],['configurations']
Modifiability,"Although I was again wrong by static-blocks and inheritance (see https://github.com/broadinstitute/gatk/issues/3483), I think that in the case of the tests is better to make overridable this config - thus, I keep it open.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5013#issuecomment-405101030:48,inherit,inheritance,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5013#issuecomment-405101030,2,"['config', 'inherit']","['config', 'inheritance']"
Modifiability,"And as an addition to the above case, I have found this problematic representation of alleles also in variable sites in newly generated vcf files (gatk version 4.3.0.0):; NC_041772.1 40006060 . GAC G,AAC; NC_041772.1 40006061 . A T,G,C,*; NC_041772.1 40006062 . C T,*",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8030#issuecomment-1420899124:102,variab,variable,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8030#issuecomment-1420899124,1,['variab'],['variable']
Modifiability,AnnotationBaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9SZWR1Y2libGVBbm5vdGF0aW9uQmFzZVRlc3QuamF2YQ==) | `2.439% <0%> (-90.244%)` | `1 <0> (-8)` | |; | [...ferenceConfidenceVariantContextMergerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1JlZmVyZW5jZUNvbmZpZGVuY2VWYXJpYW50Q29udGV4dE1lcmdlclVuaXRUZXN0LmphdmE=) | `2.881% <0%> (-94.239%)` | `1 <0> (-25)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `70.115% <0%> (ø)` | `18 <1> (ø)` | :arrow_down: |; | [...er/tools/walkers/GenotypeGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.704% <0%> (-80.408%)` | `2 <0> (-37)` | |; | [...haplotypecaller/HaplotypeCallerEngineUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmVVbml0VGVzdC5qYXZh) | `3.704% <0%> (-92.593%)` | `1 <0> (-5)` | |; | [...Plugin/GATKAnnotationPluginDescriptorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yVW5pdFRlc3QuamF2YQ==) | `7.219% <0%> (-81.016%)` | `4 <0> (-54)` | |; | ... and [1286 more](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476235495:3841,Plugin,Plugin,3841,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476235495,1,['Plugin'],['Plugin']
Modifiability,"Another con of hacky solution is that it may make calling replicates in T/N configuration difficult. I have not confirmed this, though, so it may not be an issue at all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3265#issuecomment-315085428:76,config,configuration,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3265#issuecomment-315085428,1,['config'],['configuration']
Modifiability,"Another permutation on this: i dont know if you'll like hooking into the codec, but one could wrap the codec and create a FeatureInputAwareVariantContext. This would go into FeatureDataSource, and would potentially allow Features to be 'aware' of their owning FeatureInput. The code below is not final and needs work, but this or the patch might give an idea:. [FeatureInputAwareVariantContext.patch.txt](https://github.com/broadinstitute/gatk/files/6346205/FeatureInputAwareVariantContext.patch.txt). ```; public static class CodecWrapper<FEATURE_TYPE extends Feature, SOURCE> implements FeatureCodec<FEATURE_TYPE, SOURCE>; {; private final FeatureCodec<FEATURE_TYPE, SOURCE> childCodec;; private final FeatureInput<FEATURE_TYPE> featureInput;. public CodecWrapper(FeatureCodec<FEATURE_TYPE, SOURCE> childCodec, FeatureInput<FEATURE_TYPE> featureInput); {; this.childCodec = childCodec;; this.featureInput = featureInput;; }. @Override; public Feature decodeLoc(SOURCE source) throws IOException {; return childCodec.decodeLoc(source);; }. @Override; public FEATURE_TYPE decode(SOURCE source) throws IOException {; FEATURE_TYPE feature = childCodec.decode(source);. //Either look for marker class or otherwise poke in FeatureInput here:; if (feature instanceof VariantContext); {; feature = new FeatureInputAwareVariantContext(feature, featureInput);; }. return feature;; }. @Override; public FeatureCodecHeader readHeader(SOURCE source) throws IOException {; return childCodec.readHeader(source);; }. @Override; public Class<FEATURE_TYPE> getFeatureType() {; return childCodec.getFeatureType();; }. @Override; public SOURCE makeSourceFromStream(InputStream bufferedInputStream) {; return childCodec.makeSourceFromStream(bufferedInputStream);; }. @Override; public LocationAware makeIndexableSourceFromStream(InputStream inputStream) {; return childCodec.makeIndexableSourceFromStream(inputStream);; }. @Override; public boolean isDone(SOURCE source) {; return childCodec.isDone(source);; }. @Overrid",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823546766:553,extend,extends,553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823546766,1,['extend'],['extends']
Modifiability,"Another thing that just come to my mind is to rely on [SLF4J](https://www.slf4j.org/) for logging - downstream projects can configure which logger they want to use, and they can have their own ways of setting logging verbosity. If the logging system from HTSJDK wants to be maintain, it can also add a simple implementation of SLF4J with the verbosity levels that are in the current implementation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288:124,config,configure,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288,2,['config'],['configure']
Modifiability,"Apart of the amount of work in both Barclay and GATK, I think that this shouldn't be implemented for 2 reasons:. * After #3486, some tools are hidden from the command line (and they will be most likely undocumented too). If the bash-completion works with undocumented tools that are hidden from the command line, there will appear anyway after pressing tab-tab. If that tools are treated in a different way, then it requires even more work - Barclay does not use the omitFromCommandLine at all, and that means that GATK should extend the bash-completion to take it into account.; * If a tool can bash-complete but it does not show in the online help pages (the main source for help, taking into account that in the CLI is a bit messy when the parameter space grows), then it will be really difficult to really understand how the tool work. Even if it shows the parameters with tab-tab, the only way of checking what the meaning of each of them is look at the CLI help. Because the bash-completion is a sub-type of help-doclet, it should require the `@DocumentedFeature` annotation: that is the marker interface in Barclay for mark classes as parsed/added to the ""help"" generated by doclets....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758:527,extend,extend,527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758,2,['extend'],['extend']
Modifiability,"As an aside, I downloaded the gnomAD VCFs locally using gsutil, modified the `gnomAD_exome.config` to refer to them and it works:. ```; $ cat gnomAD_exome.config; name = gnomAD_exome; version = 2.1; src_file = gnomad.exomes.r2.1.sites.liftoverToHg38.INFO_ANNOTATIONS_FIXED.vcf.gz; # src_file = gs://broad-public-datasets/funcotator/gnomAD_2.1_VCF_INFO_AF_Only/hg38/gnomad.exomes.r2.1.sites.liftoverToHg38.INFO_ANNOTATIONS_FIXED.vcf.gz; # [...]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-723357333:91,config,config,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-723357333,2,['config'],['config']
Modifiability,"As an update here, we're currently planning an upgrade to the library that we use to read bams into spark. As part of that upgrade we're going to try to fix the issue that requires 2 separate filesystem plugins for some things to work. That should enable people with hdfs file system plugins to work with gatk without a matching NIO plugin. There's no definite timeline, but hopefully within the next quarter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-375371782:203,plugin,plugins,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-375371782,3,['plugin'],"['plugin', 'plugins']"
Modifiability,"As determined by @davidadamsphd , the `Copyable` interface idea won't work:. The recommendation from the Dataflow team was to make a narrow API and do the copying part of the API. I started down this route, and I think it might be doable for things like the walker interface. The idea is to make a Copyable interface and have our interfaces extend that. . However, we have unsafe code already in the engine. I tried to make this SafeDoFn approach, however it became clear quickly that we'd have a combinatorial explosion of classes because we don't just have `DoFn<GATKRead,POut>`, but also `<Iterable<GATKRead>,POut>`, and many others. So, this approach will not work for the engine. I then tried to make a general purpose solution (using coders to write to bytes and then recreate a new class). This doesn't work for a few reasons, most critical is that the coder registry isn't Serializable, so that can't be passed down deep enough to get this to work. While working on this, I chatted with someone on the Dataflow team who is working on the verification on the direct runner. He has a PR out and likely going to get it approved soon. So, for the engine, we could always test using the direct runner and know for sure there are not issues (once we can use his code). However, there are two downsides:. 1) We will need to wait for a cut of the SDK (which looking at their previous clip is likely ~ two weeks away). . 2) I don't know if we want the direct runner test as our general purpose solution. Can we expect Comp Bios to always test with the direct runner first? Will they write anything more complex than functions that use the Walker interface?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/702#issuecomment-127403661:341,extend,extend,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/702#issuecomment-127403661,1,['extend'],['extend']
Modifiability,"As discussed elsewhere, all IGV does is ignore the column headers and take the last column, see https://software.broadinstitute.org/software/igv/SEG. Let's have ModelSegments output two LegacySegmentCollection files with column headers `[SAMPLE, CONTIG, START, END, COPY_RATIO_POSTERIOR_50/MINOR_ALLELE_FRACTION_POSTERIOR_50]`, one for CR_50 (.cr.igv.seg) and the other for MAF_50 (.af.igv.seg). Methods can be added to ModeledSegmentCollection to create these LegacySegmentCollections. LegacySegmentCollection can inherit from AbstractSampleCollection and the write method can be overridden to suppress the SAM-style header, although documentation should be added to explain this idiosyncrasy. Should be no more than a day's work. @LeeTL1220 feel free to take this one if you have time, otherwise I'm happy to take care of it after some more high priority issues.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5037#issuecomment-407150546:515,inherit,inherit,515,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5037#issuecomment-407150546,1,['inherit'],['inherit']
Modifiability,"As discussed with @lbergelson, I tested this patch manually on my local machine as well as on a clean Google Cloud VM and found it to work perfectly in all cases. I believe that the test failures here are artifacts of some configuration issue with the Travis CI VM environment, rather than indicative of a real problem. I'll see if I can recruit an external user who ran into the requester pays issue to test this branch for additional confirmation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1079415266:223,config,configuration,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1079415266,1,['config'],['configuration']
Modifiability,"As long as we are rolling with a single common environment across all tools, perhaps we could have a documentation annotation for tools that require it?. As I said in #4125, I vote against allowing users to configure their own environment. I really see no benefit to anyone---it's much easier on the users to just use the yml, and it's definitely much easier on us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4127#issuecomment-357037432:207,config,configure,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4127#issuecomment-357037432,1,['config'],['configure']
Modifiability,At some point we deleted the lines in question because the variables are `false` by default.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4259#issuecomment-379872013:59,variab,variables,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4259#issuecomment-379872013,1,['variab'],['variables']
Modifiability,"Authorization settings for the connector are described here: https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/gcs/conf/gcs-core-default.xml#L50. @jamesemery have you been able to get the connector working?. @droazen what configuration improvements did you have in mind?. Also, I'm not sure what the difference between `google.cloud.auth.service.account.json.keyfile` and `fs.gs.auth.service.account.json.keyfile` is (if any).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500755373:239,config,configuration,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500755373,1,['config'],['configuration']
Modifiability,"BTW, I wouldn't bother looking at the diff. It's a complete rewrite.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5413#issuecomment-438805556:60,rewrite,rewrite,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5413#issuecomment-438805556,1,['rewrite'],['rewrite']
Modifiability,Back to you @lbergelson. I think that we can wait for the htsjdk release for refactoring `CachingIndexedFastaSequenceFile`.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2243#issuecomment-271819769:77,refactor,refactoring,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2243#issuecomment-271819769,1,['refactor'],['refactoring']
Modifiability,"Barclay doesn't have any way to recognize those args as being the same. However, the Pedigree annotation classes already have this problem - its the reason that `pedigreeFile` and `founderIDs` were lifted into `GATKAnnotationPluginDescriptor`, and are not included in the individual annotations - `GATKAnnotationPluginDescriptor` distributes them to the annotation classes as necessary. Its not ideal, but it works. Can you extend that pattern ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7213#issuecomment-823482350:424,extend,extend,424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7213#issuecomment-823482350,1,['extend'],['extend']
Modifiability,"Based on gs://broad-gotc-test-results/staging/joint_genotyping/exome/scientific/2021-09-03-11-25-15/gather_vcfs_low_memory/small_callset_high_threshold.vcf.gz (from the console output) there are slightly fewer variants filtered with ExcessHet now, which is expected since you said it was an across-the-board shift. Expected (old) has 4335 and actual (new) has 4133 -- no new things, just some now pass. If you can calculate a new equivalent threshold I'd rather use that, but otherwise I'm not overly concerned about the changes. I'm not concerned about the Jenkins call caching unless it's for the GenotypeGVCFs task where ExcessHet actually gets calculated. For the ReducibleAnnotation comments, if you just revert your changes (statics, visibility, etc.) and open an issue I'm fine with that. Admittedly this could be another target for refactoring.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-921160043:840,refactor,refactoring,840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-921160043,1,['refactor'],['refactoring']
Modifiability,"Bayesian GMM:. This is essentially an exact port of the sklearn implementation, but only allowing for full covariance matrices. I think it might be good for those in the Bishop reading group to take a look during review. I decided to split this off into its own branch (just updated the existing branch https://github.com/broadinstitute/gatk/tree/sl_sklearn_bgmm_port) and only include stubs for the BGMM backend in the above tools. This is so we can prioritize merging the IsolationForest implementation for @meganshand. We can easily add this module back when it's been reviewed separately. TODOs:. - [x] Class-level docs.; - [x] Method-level docs. I think pointers back to the original sklearn code will suffice for most methods, but I've also included some parameter descriptions. Also note that I've retained original sklearn comments throughout the implementation and have also commented on mathematical expressions where it might be helpful.; - [x] Unit tests. There's already test data (generated using Pyro) checked in and the results match the sklearn implementation to high precision, I just need to write numerical checks. There are also already unit tests for static utility methods. Future work:; - [ ] Expanding unit tests to cover more of the interface. These initial unit tests will almost certainly not completely cover the possibilities allowed by the interface, e.g. warm starts. Could be a good exercise for other developers. EDIT: At least one test of warm starts has been added.; - [ ] As mentioned in the prototyping discussion, expanding this implementation to properly include marginalization might be of future interest. However, I think a very strong case would have to made before proceeding, as I think closely matching the sklearn implementation has obvious benefits for maintainability.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948712:1802,maintainab,maintainability,1802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948712,1,['maintainab'],['maintainability']
Modifiability,"Bcftools setGT plugin is probably the best way of fixing this issue currently. ; ```; bcftools plugin setGT -h ; About: Sets genotypes. The target genotypes can be specified as:; ./. .. completely missing (""."" or ""./."", depending on ploidy); ./x .. partially missing (e.g., ""./0"" or "".|1"" but not ""./.""); . .. partially or completely missing; a .. all genotypes; b .. heterozygous genotypes failing two-tailed binomial test (example below); q .. select genotypes using -i/-e options; and the new genotype can be one of:; . .. missing (""."" or ""./."", keeps ploidy); 0 .. reference allele (e.g. 0/0 or 0, keeps ploidy); c:GT .. custom genotype (e.g. 0/0, 0, 0/1, m/M, overrides ploidy); m .. minor (the second most common) allele (e.g. 1/1 or 1, keeps ploidy); M .. major allele (e.g. 1/1 or 1, keeps ploidy); p .. phase genotype (0/1 becomes 0|1); u .. unphase genotype and sort by allele (1|0 becomes 0/1); Usage: bcftools +setGT [General Options] -- [Plugin Options]; Options:; run ""bcftools plugin"" for a list of common options. Plugin options:; -e, --exclude <expr> Exclude a genotype if true (requires -t q); -i, --include <expr> include a genotype if true (requires -t q); -n, --new-gt <type> Genotypes to set, see above; -t, --target-gt <type> Genotypes to change, see above. Example:; # set missing genotypes (""./."") to phased ref genotypes (""0|0""); bcftools +setGT in.vcf -- -t . -n 0p. # set missing genotypes with DP>0 and GQ>20 to ref genotypes (""0/0""); bcftools +setGT in.vcf -- -t q -n 0 -i 'GT=""."" && FMT/DP>0 && GQ>20'. # set partially missing genotypes to completely missing; bcftools +setGT in.vcf -- -t ./x -n . # set heterozygous genotypes to 0/0 if binom.test(nAlt,nRef+nAlt,0.5)<1e-3; bcftools +setGT in.vcf -- -t ""b:AD<1e-3"" -n 0. # force unphased heterozygous genotype if binom.test(nAlt,nRef+nAlt,0.5)>0.1; bcftools +setGT in.vcf -- -t ./x -n c:'m/M'; ```; I was always wondering if GATK will have a plugin interface where people can code their own using groovy, kotlin, javascr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501:15,plugin,plugin,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501,4,"['Plugin', 'plugin']","['Plugin', 'plugin']"
Modifiability,"Because the `reference` variable is package private. If I want to call apply() from onTraversalSuccess, it needs to be protected—will push a commit to shortly to show you what I mean.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6512#issuecomment-618045813:24,variab,variable,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6512#issuecomment-618045813,1,['variab'],['variable']
Modifiability,"Because you implemented the original plugin descriptor, can you have a look @cmnbroad?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-274528407:37,plugin,plugin,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-274528407,1,['plugin'],['plugin']
Modifiability,Being handled in a refactoring branch. I can take it out and make a small PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3224#issuecomment-313876142:19,refactor,refactoring,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3224#issuecomment-313876142,1,['refactor'],['refactoring']
Modifiability,"BucketUtils was a solution before we had Filesystem providers. It's stuck around as a parallel set of code because we couldn't trust the providers at first. In the long run it should be removed and replaced entirely by `Files` operations. We need to test that all the functionality exists / works as expected though, and it hasn't been a high priority to do so. Particularly, I'm not sure we have a lot of faith in the HDFS NIO plugin, so we may need to keep around special cases for that. It could definitely at least be simplified a lot though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020:428,plugin,plugin,428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020,2,['plugin'],['plugin']
Modifiability,But that smoke test doesn't actually test any new functionality. The variable was there in the WDL before and was already being used - it just had no default value.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-483668246:69,variab,variable,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-483668246,1,['variab'],['variable']
Modifiability,"By doing the following, I was able to get a JointGenotyping result for my 343 samples:; - increased the amount of memory allocated to the Java heap in ImportGvcfs to 50000m; - modified the runtime attributes for all the joint genotyping tasks to match the format that Cromwell accepts for HPC environments (https://cromwell.readthedocs.io/en/stable/tutorials/HPCIntro/#specifying-the-runtime-attributes-for-your-hpc-tasks); - increasing the runtime memory attribute for ImportGvcfs and GenotypeGvcfs from 26000 MiB to 60 G; - executing the workflow with the following sbatch parameters:; nodes=4; ntasks=32; mem=248g; tmp=429G; - manually tar'ing up all the genomicsdb directories from the execution directories of all 10 shards of ImportGvcfs after they successfully completed GenomicsDBImport and failed with the error message: ; pure virtual method called ; terminate called without active exception; - running an abbreviated version of JointGenotyping which started at GenotypeGvcfs and executed the remainder of the JointGenotyping workflow unchanged.; ; I think this pretty clearly demonstrates that, whatever is going on, it occurs between GenomicsDBImport's successful creation of genomicsdb and the tar -cf of same. The failure is 100% reproducible with a number of different runtime configurations. The error messages are from C++ and seem to be occurring at the point where native C++ code is handing execution back to Java.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1314069533:1293,config,configurations,1293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1314069533,2,['config'],['configurations']
Modifiability,"By the way, I can take this one. I'm planning to do a big PR with a workaround with some of the problems of the plugin that I found to discuss them there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2397#issuecomment-278248114:112,plugin,plugin,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2397#issuecomment-278248114,1,['plugin'],['plugin']
Modifiability,"By the way, I thought @vdauwera was opposed to using optional inputs in this way at some point (see #3657). Was that question ever decided? (I'm still of the opinion that they *should* be used in this way, but this is one of the reasons I didn't for this iteration of the WDL.). To be clear, the pair WDL right now does not allow all of the workflow paths (tumor-only, no PoN, etc.) that the new tools make possible. It only allows the one that we will most likely run in production (matched-normal + PoN). We should probably make the WDL a little more flexible to cover the most common use cases, but I'm fine if it doesn't completely expose all of the possible workflow paths---this would probably just make the WDL harder to maintain. Users can write their own WDLs in this case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362696132:553,flexible,flexible,553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362696132,2,['flexible'],['flexible']
Modifiability,"CKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:35:11.508 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:35:11.508 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:35:11.508 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:35:11.509 INFO CountReadsSpark - Start Date/Time: January 9, 2019 1:35:09 PM EST; 13:35:11.509 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.509 INF",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:2095,variab,variables,2095,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,4,"['config', 'variab']","['configured', 'variables']"
Modifiability,"Can you give a bit more information here? If I'm understanding correctly, it's not clear that the same issue is at play here. The original issue was that duplicate/incomplete fragments were causing queries to the workspace to fail. . In this latest instance, it seems you are appending additional samples to the existing workspace. Is that right? If so,; - are you seeing the same/similar error? That is, it's a core dump? Can you share the error messages, any logs, core dump files etc?; - did you clean up the workspace before importing? That is, remove the incomplete fragment @nalinigans identified and the duplicated ones?. My first instinct is that even if the incomplete/duplicated fragments weren't cleaned up, the incremental import shouldn't have an issue -- at least not till it gets to the consolidate phase, which only happens after all batches are imported. Sounds like you were seeing an issue at batch 3 of 4, so might have something to do with the samples in that batch...or some other import issue. You mentioned that previous imports to this particular contig failed -- were those just transient failures that worked when rerun, or was there some configuration that you changed to get that to work?. For completeness, the way I identified duplicate fragments was to do an md5sum check on some of the internal files. If any pair of fragments have the same md5sum they are likely duplicates. So, from the workspace directory, something like:. ```; find . -name ""ALT.tdb"" -exec md5sum {} \;|sort; ```; That will highlight the fragments that are potentially duplicate. To confirm that the fragments are indeed duplicates, you'll then want to take that list of potentially duplicate fragments and check that all corresponding files within each pair of potentially duplicate fragments actually have the same md5sum. I have a crude bash script that I can share if you want.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722541707:1166,config,configuration,1166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722541707,2,['config'],['configuration']
Modifiability,"Cannot this use directly `TableReader`? Maybe it should include a `Path` constructor and being refactored a bit... Another option could be the picard `BasicInputParser`, `TabbedInputParser` or `TabbedTextFileWithHeaderParser`...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3757#issuecomment-340715685:95,refactor,refactored,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3757#issuecomment-340715685,1,['refactor'],['refactored']
Modifiability,Closing. I will open a PR between today and tomorrow with all the workaround for this plugin (before the change in Barclay). We can discuss in the new one the details in a better way.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2359#issuecomment-278244313:86,plugin,plugin,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2359#issuecomment-278244313,2,['plugin'],['plugin']
Modifiability,"Co-assigning to @jonn-smith, since it's likely to be implemented using the new OWNER configuration facility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3610#issuecomment-331978713:85,config,configuration,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3610#issuecomment-331978713,1,['config'],['configuration']
Modifiability,"Considering that this PR has lasted through my absence and the holiday season, I want to take the chance of summarizing the concerns you have issued here:. --------. Resolved as requested (or at least made efforts to):. * documenting the logic and methods; documented. * emit VCF instead of custom file format; emit both VCF custom file format now. * bug in determining if alignment signature satisfies `allMiddleAlignmentsDisjointFromAlphaOmega`; bug fixed in commit b4f7568b03b91eb77d256bcfe8117001bce040ec. --------. Unresolved yet:; the fact that gap split happens after the alignment configuration scoring step is considered backwards. I agree in principle but due to AS and MQ were used in the scoring step, and split-copy leads to technically wrong AS & MQ, I originally decided to score first, then split. Splitting the gapped alignments was introduced originally to have a centralized logic in inferring type and location of the events. . The tension is that AS is used in the scoring but becomes practically useless after that. >> Correct, but I am having thoughts about this now (not to pick only one—that; would be wrong—but to ditch them altogether probably under some condition; and redo the alignment step), exactly because of this behavior I observe.; Think about the case where one originating gapped (say insertion); alignment, after splitting, has one of the two children contained in; another alignment (not its sibling, that's impossible) in terms of their; read span. Now the originating gapped alignment probably should be filtered; out, or not, because if we keep it, an insertion would be called but; apparently there are alternative explanations due to the other alignment.; I'm not sure how to deal with this case, and if this scenario is common; enough. It probably is the case that such alignments happen mostly in STR; regions, so getting the exact alignments correct there is no easy task.; ; > Is that enough of a concern to worry about. In such a case I feel like we; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-354976980:589,config,configuration,589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-354976980,2,['config'],['configuration']
Modifiability,"Currently the code for the config file parsing will override values passed in on the command-line, so that explains one reason this is happening. The fix should be pretty straightforward.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367715460:27,config,config,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367715460,1,['config'],['config']
Modifiability,"DK Defaults.REFERENCE_FASTA : null; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5535,Config,ConfigFactory,5535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:39:19 INFO SparkContext: Running Spark version 2.2.0; 18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:6007,Config,ConfigFactory,6007,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"Dear all,. I am a bit confused why GATK uses `[0,1,2]` for the `GT` files, even though VCF specifications clearly state that the `GT` field is `encoded as allele values separated by either of / or |`. They even say that for `diploid calls examples could be 0/1, 1 | 0, or 1/2, etc`. As it is right now, if I read a VCF from GATK CNV germline pipeline through `bcftools`, the `GT` field is changed to `-65`:; ```; 1 17345376 CNV_1_17345376_161326630 N <DUP> 101.19 . END=161326630 GT:CN:NP:QA:QS:QSE:QSS -65:3:13:11:101:3:18. 1 161332119 CNV_1_161332119_161332223 N <DEL> 3.19 . END=161332223 GT:CN:NP:QA:QS:QSE:QSS -65:1:1:3:3:3:3. 1 193091331 CNV_1_193091331_241683022 N <DUP> 268.21 . END=241683022 GT:CN:NP:QA:QS:QSE:QSS -65:3:27:34:268:36:3. 2 96919546 CNV_2_96919546_96931119 N . 62.93 . END=96931119 GT:CN:NP:QA:QS:QSE:QSS -65:2:3:38:63:38:63. 3 10183532 CNV_3_10183532_69928534 N . 469.93 . END=69928534 GT:CN:NP:QA:QS:QSE:QSS -65:2:22:31:470:19:75. 3 69986973 CNV_3_69986973_70014399 N <DUP> 10.12 . END=70014399 GT:CN:NP:QA:QS:QSE:QSS -65:3:8:4:10:4:10; ```. Any reason to not use the standaed `GT` format?. I have also noticed that GATK outputs some non-variable SVs to the VCF without any ALT allele. Why not remove them if they are actually not SVs, if `GT=0` and `CN=2`?. thanks,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-621738904:1164,variab,variable,1164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-621738904,2,['variab'],['variable']
Modifiability,"Do you think that this is really necessary for a normal user? I mean, usually `UserException` should have a well-defined message String for point to the user what happened. If the stack traces are necessary, are for debugging and I think that the final user won't benefit for having an extra argument. In addition, it is in the repository README, which made it discoverable for developers and it is what it is really meant for (I guess). Other option may be to print the stack trace for `UserException`only if the verbosity is set to DEBUG, and that will get rid of the environmental variable....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285282288:584,variab,variable,584,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285282288,1,['variab'],['variable']
Modifiability,Doing some additional refactoring and rebasing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-557828837:22,refactor,refactoring,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-557828837,1,['refactor'],['refactoring']
Modifiability,"Done with my review. Thanks for doing this much-needed refactor! The BaseRecal stuff looks sound, but I have some other feedback that we should discuss/address.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142750080:55,refactor,refactor,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142750080,1,['refactor'],['refactor']
Modifiability,"EATE_MD5 : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.CUSTOM_READER_FACTORY :; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.REFERENCE_FASTA : null; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - g",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5066,Config,ConfigFactory,5066,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['Config'],"['ConfigFactory', 'Configuration']"
Modifiability,"Evaluation of THCA/STAD/LUAD TCGA WGS/WES CR concordance with SNP arrays was implemented on FC last summer and showed good performance. For WES, comparisons against GATK CNV and CODEX showed comparable to highly improved performance, respectively, with minimal parameter tuning. WGS comparisons were unavailable due to limitations of competing tools. This evaluation will be expanded to include CR/MAF concordance against PanCanAtlas ABSOLUTE results. Some curation of the samples could be performed; some batch effects were observed in some LC WGS LUAD samples. Comparisons to other tools will probably be removed for ease of maintenance. Will be adapted to fit into whatever framework arises from #4630; same goes for HCC1143 and CRSP validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697:648,adapt,adapted,648,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697,1,['adapt'],['adapted']
Modifiability,"Even if I'll refactore it to be void, the part that I changed is need it: there is no other part which handle the `CommandLineException` and if the `customCommandLineValidation()` throws the exception no error is printed in the terminal. I guess that returning a `String[]` in Picard is done to output several errors in the command line to avoid the user to re-run with another bug not reported. Nevertheless, I prefer you approach. I'm changing now the code in this PR to add what you suggested. Thanks again for make my development smoother, @lbergelson!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255847377:13,refactor,refactore,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255847377,1,['refactor'],['refactore']
Modifiability,"FC was fine with previous model of having normal input bams/bais be optional parameters. I don't think FC would let you do a pair missing a sample. Typically, in FC, you would create two method configurations, one for tumor-only and one for pair. Then the former would be run on samples and the latter run on pairs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-352624267:194,config,configurations,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-352624267,1,['config'],['configurations']
Modifiability,"FYI, if you set the environment variable TILEDB_DISABLE_FILE_LOCKING=1 before running any GenomicsDB tool, it doesn't try to lock files on POSIX filesystems (Lustre, NFS, xfs, ext4 etc)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4753#issuecomment-437188003:32,variab,variable,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4753#issuecomment-437188003,1,['variab'],['variable']
Modifiability,"Finally getting around to this @fleharty, apologies! Decided to punt on most of your requests, but hopefully my reasoning is acceptable. Perhaps we can also get it in by release and @takutosato can use this version of ModelSegments in his CRSP evaluations (and maybe even verify there are no changes from the previous version in typical, single-sample copy-ratio + allele-fraction use---since from that perspective all code changes should just be a refactor---if he has time).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-857808000:449,refactor,refactor---if,449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-857808000,1,['refactor'],['refactor---if']
Modifiability,"Finally got the test passing in travis (silly error from refactoring previous stuff). Ready to go, @droazen!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-384608688:57,refactor,refactoring,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-384608688,1,['refactor'],['refactoring']
Modifiability,"Finished refactoring the production code as detailed above, just need to add some tests. Results are exactly the same as before in single-sample mode---except for allele-fraction-only mode. This is because I refactored all existing segmenters (there were separate ones for copy-ratio-only, allele-fraction-only, and copy-ratio + allele-fraction) as special cases of a single multisample segmenter; however, the Gaussian kernel in the old allele-fraction-only segmenter was missing a normalization factor that is now present in the new multisample segmenter. Thus, users who previously ran in allele-fraction-only mode will have to retune parameters to achieve the same level of sensitivity. I expect that this will be a very small number of users (if any---note that allele-fraction-only mode isn't even exposed in the WDL), but we can probably mention it in the release notes. Might need to update a figure, etc. as well in the tutorial.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611833344:9,refactor,refactoring,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611833344,2,['refactor'],"['refactored', 'refactoring']"
Modifiability,First candidate is Apache Configuration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307472726:26,Config,Configuration,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307472726,1,['Config'],['Configuration']
Modifiability,"First cut at a rewrite seems to be working fine and is much, much leaner. Building a small PoN with 4 simulated normals with 5M bins each, CombineReadCounts took ~1 min, CreatePanelOfNormals (with no QC) took ~4.5 minutes (although ~1 minute of this is writing target weights, which I haven't added to the new version yet) and generated a 2.7GB PoN, and NormalizeSomaticReadCounts took ~8 minutes (~7.5 minutes of which was spent composing/writing results, thanks to overhead from ReadCountCollection). In comparison, the new CreateReadCountPanelOfNormals took ~1 minute (which includes combining read-count files, which takes ~30s of I/O) and generated a 520MB PoN, and DenoiseReadCounts took ~30s (~10s of which was composing/writing results, as we are still forced to generate two ReadCountCollections). Resulting PTN and TN copy ratios were identical down to 1E-16 levels. Differences are only due to removing the unnecessary pseudoinverse computation. Results after filtering and before SVD are identical, despite the code being rewritten from scratch to be more memory efficient (e.g., filtering is performed in place)---phew!. If we stored read counts as HDF5 instead of as plain text, this would make things much faster. Perhaps it would be best to make TSV an optional output of the new coverage collection tool. As a bonus, it would then only take a little bit more code to allow previous PoNs to be provided via -I as an additional source of read counts. Remaining TODO's:. - [x] Allow DenoiseReadCounts to be run without a PoN. This will just perform standardization and optional GC correction. This gives us the ability to run the case sample pipeline without a PoN, which will give users more options and might be good enough if the data is not too noisy.; - [x] Actually, I'm not sure why we take perform SVD on the intervals x samples matrix and take the left-singular vectors. <s>Typically, SVD is performed on the samples x intervals matrix and the right-singular vectors are taken, ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351:15,rewrite,rewrite,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351,2,['rewrite'],['rewrite']
Modifiability,"Fixed for filtering in #5498. `Mutect2` itself will be trickier because a lot of unused arguments are a result of `SomaticGenotypingEngine`'s inheritance. This will involve significant refactoring, but the genotyping classes will make more sense.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5352#issuecomment-445517991:142,inherit,inheritance,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5352#issuecomment-445517991,2,"['inherit', 'refactor']","['inheritance', 'refactoring']"
Modifiability,Fixed missing end-of-line backslashes in commands and made a few additional enhancements to the doc text,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2781#issuecomment-309632487:76,enhance,enhancements,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2781#issuecomment-309632487,1,['enhance'],['enhancements']
Modifiability,"Fixing womtool is a bit more complicated, since it affects FireCloud method configuration parameters as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362118499:76,config,configuration,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362118499,1,['config'],['configuration']
Modifiability,"For some reason, the environment variable is not getting passed to GenomicsDB at all. To help debug the issue, can you do the following and see if any consolidation lock is created at all? ; ```; find /path/to/genomicsdb_workspace -name "".__consolidation_lock""; ```; Also, what type of Posix filesystem is your GenomicsDB workspace? Is it NFS or Lustre? How is file locking configured on the system?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6627#issuecomment-637237653:33,variab,variable,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6627#issuecomment-637237653,2,"['config', 'variab']","['configured', 'variable']"
Modifiability,"For the second point (file format) I would prefer something different than Java Properties, because for lists will be a bit messy (separated by comma in Apache Configuration). Maybe YML or JSON will be better for this purpose?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307729448:160,Config,Configuration,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307729448,1,['Config'],['Configuration']
Modifiability,"Found a serious bug in this PR: `passesEmitThreshold()` was calling `passesCallThreshold(configuration.genotypeArgs.STANDARD_CONFIDENCE_FOR_CALLING)` instead of `passesCallThreshold(conf)`, which caused `STANDARD_CONFIDENCE_FOR_CALLING` to get compared against itself! Pushing a fix for this now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-286781671:89,config,configuration,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-286781671,1,['config'],['configuration']
Modifiability,"Given that this helps you out, but doesn't change the behavior of our tools, it's pretty much a refactor from our end and I'm happy to give it a 👍",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2534#issuecomment-334156894:96,refactor,refactor,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2534#issuecomment-334156894,1,['refactor'],['refactor']
Modifiability,"Glad you were able to resolve your issue. Not sure if this is specific to the CNV tool or if the exception caused by the Spark configuration is more general. Tagging engine team @droazen, but closing for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686#issuecomment-467510488:127,config,configuration,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686#issuecomment-467510488,1,['config'],['configuration']
Modifiability,"HI @lbergelson - ; I'm working on a bug/warning in the variant calling workflow where it's complaining about not finding a logger:. `21:04:59.525 INFO ProgressMeter - Starting traversal; 21:04:59.526 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; log4j:WARN No appenders could be found for logger (io.grpc.netty.shaded.io.netty.util.internal.logging.InternalLoggerFactory).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 21:05:10.018 INFO ProgressMeter - chr1:4642050 0.2 205000 1172992.6`. I found that if I had gatk's build.gradle NOT exclude the log4j.properties file I get rid of that warning, so I'm trying to understand the issue [here](https://github.com/broadinstitute/gatk/blob/33bda5e08b6a09b40a729ee525d2e3083e0ecdf8/build.gradle#L441): (where you found log4j.properties clashed with log4j2.xml) . James Emery is on the git blame for that, but he thinks that's because of the refactoring he did. Thanks in advance - I'm not sure if there's something else I should be doing with the xml version of that file to avoid this warning.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7778#issuecomment-1098029722:1023,refactor,refactoring,1023,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7778#issuecomment-1098029722,1,['refactor'],['refactoring']
Modifiability,"HTSJDK Defaults.CUSTOM_READER_FACTORY :; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.REFERENCE_FASTA : null; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBU",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5129,Config,ConfigFactory,5129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using googl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5612,Config,ConfigFactory,5612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"Ha, this PR was much tinier than I expected -- feet are barely damp. My ""wishlist"" would include a much bigger refactor because I made a mess in Java7 and didn't have the time to clean up (especially with generics) after we switched in Java8. I'm still tinkering with the rank sum tests though, so it's not worth tackling the refactor until those are good to go. :+1:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2657#issuecomment-299206702:111,refactor,refactor,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2657#issuecomment-299206702,2,['refactor'],['refactor']
Modifiability,"Hello @SZLux,. This looks suspiciously like #3050. I suspect this isn't a PathSeq issue, but to be sure can you please try to run another GATK Spark tool such as CountReadsSpark? If that does not work, it's likely an issue with your configuration or Spark/Java versions being incompatible. . What kind of environment are you running in? My suspicion is you are running on a cluster and have the correct Spark/Java version on the driver (master node) but perhaps not on the workers.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383712768:233,config,configuration,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383712768,1,['config'],['configuration']
Modifiability,"Hello @cmnbroad. My current solution satisfy all the constraints and it's not too complicated, although is not as simple as a common generic class that just need to be extended. Have a look and if you like it I can implement some tests for `CountingVariantFilter`; if not, I could come back to a separate `CountingVariantFilter` with its own and/or/negate inner classes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-272482490:168,extend,extended,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-272482490,2,['extend'],['extended']
Modifiability,"Hello @nalinigans,. As part of gatk-sv pipeline we are using GATK : v4.1.8.1 which doesn't have bypass-feature-reader option. Also, we didn’t capture strace for the run with just ""--genomicsdb-shared-posixfs-optimizations"" so wont be able to share the FUTEX process counts. So after using v4.2.4.1 we get below results. 	- Using ""--genomicsdb-shared-posixfs-optimizations"" & ""--bypass-feature-reader"" the process took 118 mins.; ""FUTEX_WAIT_PRIVATE, 0, NULL"" : 1266. 	- Using ""--genomicsdb-shared-posixfs-optimizations"" & ""--bypass-feature-reader"" and ; TILEDB_UPLOAD_BUFFER_SIZE=5242880 as env variable the process took 113 mins.; 	""FUTEX_WAIT_PRIVATE, 0, NULL"" : 3. 	- Even using 10 MB as buffer size resulted in same execution time of 113 mins.; 	- Using a buffer size bigger i.e. 50 MBs caused the process to run slower so we aborted it. Please let us know if we can improve it further.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7646#issuecomment-1040947845:595,variab,variable,595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7646#issuecomment-1040947845,1,['variab'],['variable']
Modifiability,"Hello, . I have the same problem, . path_input_file=/work/gr-fe/archive/sample_repository/all_exome_gvcfs_hg38/FVH/exomes #patient GVCF; path_name_individu=/work/gr-fe/sboutry/excalibur/input/11_12_23_gvcf_FVH/patient_name.txt; path_output=/work/gr-fe/sboutry/excalibur/input/11_12_23_gvcf_FVH/patient_data.vcf.gz; tmp_folder=/scratch/sboutry/logs/combine_gvcf_file; nbr_groups=2. #Path to database and programs; REF=/work/gr-fe/saadat/Reference_Genome/GRCH38_no_alt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa.gz; BCFTOOLS=/work/gr-fe/sboutry/tools/bcftools/install/bin/bcftools; export BCFTOOLS_PLUGINS=/work/gr-fe/sboutry/tools/bcftools/bcftools/plugins; TABIX=/work/gr-fe/sboutry/tools/tabix/tabix-0.2.6/tabix; GATK=/work/gr-fe/sboutry/tools/gatk/gatk-4.2.2.0/gatk. cd ${path_input_file}. ${GATK} --java-options ""-Xmx180G -XX:ParallelGCThreads=36"" CombineGVCFs -R ${REF} --variant ${path_name_individu} -O ${path_output}/patient_data.g.vcf.gz. where all my files are like this . JL0015.g.vcf.gz; JL0016.g.vcf.gz; JL0017.g.vcf.gz; JL0018.g.vcf.gz; JL0019.g.vcf.gz; JL0020.g.vcf.gz; JL0182.g.vcf.gz; JL0183.g.vcf.gz; JL0184.g.vcf.gz; JL0185.g.vcf.gz; JL0186.g.vcf.gz; JL0234.g.vcf.gz; JL0278.g.vcf.gz; JL0412.g.vcf.gz; JL0417.g.vcf.gz; JL0515.g.vcf.gz. A USER ERROR has occurred: Cannot read file:///work/gr-fe/sboutry/excalibur/input/11_12_23_gvcf_FVH/patient_name.txt because no suitable codecs found. Thanks a lot for any help . Best, . Simon",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8255#issuecomment-1918989841:652,plugin,plugins,652,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8255#issuecomment-1918989841,1,['plugin'],['plugins']
Modifiability,Here's another one with our exact problem (solved largely by putting the config onto HDFS). http://progexc.blogspot.com/2014/12/spark-configuration-mess-solved.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322554798:73,config,config,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322554798,2,['config'],"['config', 'configuration-mess-solved']"
Modifiability,"Here's some old code that uses SamLocusIterator (from tfennel) that AllelicCapseg can adapt for now. From Tim:; ""They key to making this nice and simple is the SamLocusIterator class, which given a BAM file and a list of intervals, will give you pileups at each position in the intervals, filtered how you want them, and even provide convenience methods to access the exact base per read that is piled up at the site etc. The really nice things about doing it this way is that the constructor to SamLocusIterator takes a simple parameter to tell it whether to use an index/query mechanism (similar to what you're doing now) or to just read the BAM serially up until the last interval is reached and output the loci of interest. Running the below with ~100k sites on a standard exome (15GB or so) without using the index took only about 15 minutes."". ```; public void pileup(final File bam, final IntervalList intervals, final int minQ, final File outputFile) {; final int MAX_INTERVALS_FOR_INDEX = 25000; // just a guess, not sure what the right number is. final SamLocusIterator iterator = new SamLocusIterator(new SAMFileReader(bam), intervals, intervals.size() < MAX_INTERVALS_FOR_INDEX);; iterator.setEmitUncoveredLoci(false);; iterator.setQualityScoreCutoff(minQ);. final BufferedWriter out = IoUtil.openFileForBufferedWriting(outputFile); // will automatically gzip if filename ends with .gz; try {; while (iterator.hasNext()) {; final SamLocusIterator.LocusInfo locus = iterator.next();; int a=0, c=0, g=0, t=0;. for (final SamLocusIterator.RecordAndOffset rec : locus.getRecordAndPositions()) {; switch (rec.getReadBase()) {; case 'A' : ++a; break;; case 'C' : ++c; break;; case 'G' : ++g; break;; case 'T' : ++t; break;; }; }. out.append(locus.getSequenceName() + ""\t"" + locus.getPosition() + ""\t"" + a + ""\t"" + c + ""\t"" + g + ""\t"" + t + ""\t"");; }. out.close(); ; }; catch (IOException ioe) { throw new RuntimeIOException(ioe); }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/335#issuecomment-88102420:86,adapt,adapt,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/335#issuecomment-88102420,1,['adapt'],['adapt']
Modifiability,"Hey @bbimber I will have to think on this. The most simple solution might be to add a feature context side input for the annotation in question but looking at how that code is threaded in the variant callers it would take a little bit of work to add it to those tools and probably introduce some complicated questions, (like for example: what is the correct featurecontext to send to annotate a variant that only covers one base of the site in question where the feature context object exists?). Its possible to do something like that for variant annotator a little bit more easily but i guess the question comes down to this: How generalized do you think this annotation will be? Does it need to be annotatable with variant annotator or could you write a separate tool that does the variant -> variant association and calculates the annotation without using the plugin framework? If it needs to be generalizable I would agree with @droazen that the easiest approach would be to add the side input as an argument and make the annotation object responsible for querying the feature context. This is inelegant but might be preferable to putting the entire walker context into the `annotate()` function.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754249851:863,plugin,plugin,863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754249851,2,['plugin'],['plugin']
Modifiability,"Hey @magicDGS, since I'm on the forum documentation side of things, I'm not familiar with a plugin. Is this something @cmnbroad typically takes care of?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-342820936:92,plugin,plugin,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-342820936,1,['plugin'],['plugin']
Modifiability,Hey @valleema. We don't think this is a bug given that the argument `--max-mnp-distance` is intended to remove Multi-Nucliotide polymorphism which generally are adjacent SNPs(i.e. sites with the pattern ref: AA alt: GT for example). Your example site here doesn't have an MNP but rather is a multi-allelic site. Consequently the flag `--max-mnp-distance` is not doing anything wrong in this case. I would direct future questions about your use case (namely how to un-collapse multi-allelic sites) to our forums: https://gatk.broadinstitute.org/hc/en-us/community/topics. Thank you;,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7782#issuecomment-1115218078:128,polymorphi,polymorphism,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7782#issuecomment-1115218078,1,['polymorphi'],['polymorphism']
Modifiability,"Hey all, I'm still interested in supporting this. We don't really have a ""plugin API"", I am in fact the API, but if you give me something usable I'll plug it in. As this is marked ""QuixoticDream"" I don't think that's likely. I'm closing the corresponding IGV issue, too many open issues, but it doesn't mean I've lost interest.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-433201230:74,plugin,plugin,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-433201230,2,['plugin'],['plugin']
Modifiability,"Hi - @kaixinxiaonvwa-hub . I have a couple of questions:. - Can you post your full stack trace with the errors?; - Did you attempt to enable `gnomAD` data sources or is it doing this without any changes to the data sources directory? Did you do any other configuration steps after downloading the datasources and before running funcotator?. If you enable `gnomAD`, the datasources are hosted on google cloud. If you don't have an internet connection or google cloud is blocked, Funcotator will not be able to connect to read the gnomAD data and will show the error in your `1` case above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1494703773:255,config,configuration,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1494703773,1,['config'],['configuration']
Modifiability,"Hi @MattMcL4475 - if you mean the images I used to test these, they are: `terrapublic.azurecr.io/gatk:4.5-squashed` and `terrapublic.azurecr.io/gatk:4.5-min-layers`. Note that these are manually built and pushed for this task and didn't go through any automated tests that are in this repo.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8808#issuecomment-2159093348:157,layers,layers,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8808#issuecomment-2159093348,1,['layers'],['layers']
Modifiability,"Hi @MattMcL4475 - so sorry I didn't see your reply until now (likely due to my email filters). Anyway, I don't think we have a squashed version of this in the official GATK image. From the conversation above, I think we decided to go with just the reduced layers version of the image which is what this PR is for. I do, however, have a sample squashed version here: `terrapublic.azurecr.io/gatk:4.5-squashed` - but then again, it's not in the official Docker hub repo.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8808#issuecomment-2231781482:256,layers,layers,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8808#issuecomment-2231781482,1,['layers'],['layers']
Modifiability,"Hi @Yyx2626, I'm Geraldine, you may remember me from the Beijing training. It was great visiting your team! I'm sorry it took me so long to follow up on this discussion, and I want to thank you again for reaching out to us about integrating the tool that you developed into GATK. We are certainly very interested in providing this enhancement to the research community, and we are now ready to talk about the next steps. . After examining your paper and the source code in Github, we think that the most efficient way to integrate the functionality you developed would be to adapt the filtering parts of your tool to run on the output of Mutect2. So this would be a standalone tool that you would run after Mutect2, much like the current FilterMutectCalls tool. . If the results are comparable to your current tool, then we would take that into the official distribution of GATK. If somehow that integration does not yield satisfactory results, then we would look at integrating the entire tool, though we're hoping it won't be necessary, so we can avoid maintaining duplicate functionality for some of the boilerplate data transformations. . David @davidbenjamin can provide some advice on how to implement this in GATK4; in brief you would need to write some code that applies the filters you developed to a variant context. Let us know if this is an option you'd like to explore; we'd be happy to help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-403101973:331,enhance,enhancement,331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-403101973,2,"['adapt', 'enhance']","['adapt', 'enhancement']"
Modifiability,"Hi @bhanugandham . I wasn't able to reproduce your problem on my laptop. Based on the error message, it looks like a network config Spark issue. What environment are you running this in? If it's MacOS, can you post the contents of `/etc/hosts`? Also the error message looks like it's truncated. You might be able to get the full stack trace by adding `--verbosity DEBUG`, which would be helpful as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380:125,config,config,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380,1,['config'],['config']
Modifiability,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:371,refactor,refactors,371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525,6,['refactor'],"['refactoring', 'refactors']"
Modifiability,"Hi @georgiiprovisor ,. Sorry this fell though the cracks. Did you find a workaround? I suspect some of our I/O refactoring caused this warning to be triggered incorrectly. Happy to take a look if that's still useful. -Laura",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8564#issuecomment-2435404906:111,refactor,refactoring,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8564#issuecomment-2435404906,1,['refactor'],['refactoring']
Modifiability,"Hi @hh1985 . Memory tuning is pretty tricky and can depend on a lot of things. How is your cluster configured? ; Are you using YARN? Are you running in client or cluster mode? . I'm assuming you're running with YARN. Mesos should also work but I don't have any experience configuring it. . BQSR should run safely with 4g of memory per core. (It should really work with much less I think, but 4 should definitely be sufficient.) There are a few different parameters that can help you adjust the memory ratios.; A good tuning might be something like; ; ```; --num-executors 5 ; --executor-cores 8 ; --executor-memory 32g ; ```. if you're not running with gatk-launch you'll need to set; ```; --conf spark.yarn.executor.memoryOverhead=600; ```; Without setting a higher than default yarn memory overhead like this we see consistent crashes, it's included in the settings gatk-launch applies already. That should run 5 separate executors with 8 cores each and give each one 32g, so 4g / core. . If you're running in cluster mode you'll have to carve out some memory and cores for the driver. You can set the driver settings with ; ```; --driver-cores 2; --driver-memory 4g; ``` ; or something along those lines. The driver doesn't need much memory or computer for BQSR. In general we've had better luck using the entire cluster for one job and running jobs in sequence rather than trying to run two jobs simultaneously using a subset of the cluster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738:99,config,configured,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738,2,['config'],"['configured', 'configuring']"
Modifiability,Hi @icemduru ; Looks like your slurm workload manager was configured to have a limit of 48GBs of maximum process memory size per execution. Your java instance is set with -Xmx45G which will cover most of this limit and leaves only a handful of memory space for the native GenomicsDB library. Native libraries work above the heapsize so it is better for you to set your -Xmx to a more sensible size of 8~12GB and leave rest of the memory space to the native library to use. . Keep in mind that this memory limit on slurm could be set per user not per task therefore you may need to run a single contig at a time or maybe 2 of them simultaneously. Otherwise slurm may interefere with all the tasks and cancel all your jobs. . One final reminder. We strongly recommend users to set the temporary directory to somewhere else other than /tmp. Slurm workload manager interferes with this preference and sometimes results in premature termination of the gatk processes due to deletion of extracted native library and accessory files. . I hope this helps.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2283694332:58,config,configured,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2283694332,1,['config'],['configured']
Modifiability,"Hi @jean-philippe-martin ,. A `Feature` in our codebase has a specific meaning that is different from ""interval"": it is a record that 1. has a location on the genome plus (typically) some metadata information about that location and 2. is in one of the formats supported by our file-parsing framework tribble and is the product of a tribble codec. A VCF record is an example of a `Feature`. . The common interface between `Feature` and `SimpleInterval` is called `Locatable`. I recommend (for now) that you simply alter your uprooted version of BQSR to take a `List<? extends Locatable>` instead of a `List<? extends Feature>` in `apply()`. This should require no code changes beyond changing method parameter types, and it will allow you to feed BQSR `SimpleIntervals` for the known sites for now, and `Features` like VCF records later on when we're ready for that. Please do return `ArtificialTestFeature` to the `FeatureDataSourceUnitTest` from which it came -- this is a very incomplete class meant only for testing purposes and not for external use.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511#issuecomment-100393247:568,extend,extends,568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511#issuecomment-100393247,2,['extend'],['extends']
Modifiability,Hi @jonn-smith I had some success getting outputs with this. However ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/ is no longer accessible. The most recent version of I accessed on 3/19/2018 still contained at least one error. I'm trying to correct them myself as I go using a more recent build of GATK but it would be helpful if the data files required by this program were available. The one I found is in `gencode_xrefseq.config` where it references a source that doesn't exist and I fixed that. After that I was able to get outputs with hg38. Thanks for your work on this!. I'd also point out there are a lot of fields in the MAF with `__UNKNOWN__` as the entry,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645:447,config,config,447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645,1,['config'],['config']
Modifiability,Hi @lvzenglei ; This is not an issue that needs any fix in fact this is the default behavior that Mutect2 and HaplotypeCaller will have. Extending MNP distance does not change any of the Smith Waterman or PairHMM parameters that will eventually decide on the model used to genotype the region. If you are interested in getting larger complex events genotyped you may need to get longer reads (preferably 2x300) and use read backed phasing before you try genotyping any such events. In that case you may need to experiment with Smith Waterman and PairHMM parameters to prefer mismatches over SNPs but this still may not result in what you are actually looking for. One better approach would be to use read backed phasing along with post processing your phased variants to convert individual phased SNPs and INDELs into COMPLEX calls by other tools. . I hope this helps. Regards.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8310#issuecomment-2421513998:137,Extend,Extending,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8310#issuecomment-2421513998,1,['Extend'],['Extending']
Modifiability,Hi @potter-s ; Our docker image is already built with root account only however PATH is set to be usable by all users so if you wish to keep user priviledges after execution you may add ` -u $UID:$GID` parameter to docker command line therefore the container will run using your user permissions. . This has a catch of course. Temporary folders must be set where your user has RWX permissions therefore we want users to pay attention to that. There is a writing that we posted a while ago which you may refer to for setting up your temporary files for GATK workflows. . [How to setup temporary folder for GATK local executtion](https://gatk.broadinstitute.org/hc/en-us/articles/18965297287067-How-to-setup-and-use-temporary-folder-for-GATK-local-execution). For some of the tools such as gCNV or CNN you may need to setup additional environment variables to locate python compilation directory to a place where you have read and write permissions. . I hope this helps.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2145780965:845,variab,variables,845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2145780965,2,['variab'],['variables']
Modifiability,"Hi @ruslan-abasov,. I believe your GermlineCNVCaller results should have inherited the correct dictionary from the count files. The issue is you created some GermlineCNVCaller shards (e.g., shard 4) with inappropriately ordered intervals (since these were instead ordered w.r.t. to the idiosyncratic dictionary you attached). However, I think if you just reshard and rerun GermlineCNVCaller for any such shards, you may be able to reuse most of your results. For example, you could take your shard 4 interval list, which contains intervals from chr18, chr19, and chr1, and reshard these intervals into two shards: 4a containing chr18-19 intervals, and 4b containing chr1 intervals. After rerunning 4a and 4b through GermlineCNVCaller, you should be able to use PostprocessGermlineCNVCalls to stitch together shards 4b, 1, 2, 3, and 4a, since these will be ordered w.r.t. the correct dictionary from the count files (i.e, they will contain intervals in the order chr1, chr10-19). Of course, you will want not want to perform this exact procedure; you'll want to generalize it to whatever will yield the correct order for all 10 of your shards across all contigs. Again, this may be error prone and I can't guarantee that it will be successful, since I haven't tried it myself. I would personally just rerun the pipeline. You might be able to cut down on runtime by using smaller shards (I believe we typically shard the entire genome into far more than 10 shards, which we usually run in parallel) and making sure you set parameters appropriately for WGS. @mwalker174 has the most experience running on WGS and should be able to provide you the latest recommendations, or you might be able to find them by searching GitHub or the GATK Forums. Your point is well taken about failing earlier, and I think I've outlined the best strategy above. It is impossible to catch all possible errors early, but for some we can certainly fail before the GermlineCNVCaller step.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-720091802:73,inherit,inherited,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-720091802,1,['inherit'],['inherited']
Modifiability,Hi @yurivict I tested this on my machine and it works for me. Do you see a message saying the version was overridden?; ```; $ ./gradlew printVersion -Drelease=true -DversionOverride=myVersion1.2. > Configure project :; Version number overridden as myVersion1.2. > Task :printVersion; myVersion1.2; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7143#issuecomment-857796023:198,Config,Configure,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7143#issuecomment-857796023,1,['Config'],['Configure']
Modifiability,"Hi DarioS. FastaAlternateReferenceMaker is a really simple tool. It actually just looks at the alternate alleles at each site and uses the first non-symbolic one to make the fasta. It doesn't even look at the genotypes. So it should work fine with a multisample vcf but it will give you a mush of samples together as a single fasta. I could be extended to be smarter but it's not a high priority for us right now. . We should improve the documentation, I had to go look in the code to see what it was doing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7557#issuecomment-969237729:344,extend,extended,344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7557#issuecomment-969237729,2,['extend'],['extended']
Modifiability,"Hi Stefan,. If there is no obvious error (e.g., is `/media/Berechnungen/GATKTest/CN_transition_matrix_autosomal.tsvx` the correct filename, rather than `/media/Berechnungen/GATKTest/CN_transition_matrix_autosomal.tsv`? Does the file exist and is it correctly formatted?), then I would guess that this is likely an error with your nd4j configuration. Just to let you know, we have significantly revamped the both somatic and germline CNV pipelines for the release in January. If you would like a preview of the germline tool, you may want to look at this branch: https://github.com/broadinstitute/gatk/tree/sl_gcnv_ploidy_cli However, be aware that it is still under development.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352760467:335,config,configuration,335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352760467,1,['config'],['configuration']
Modifiability,"Hi all. Apologies for writing in an old issue. ; has this been fixed?; With java 1.8 and GATK 4.1.3.0 I think I'm getting the same error (in this case with HaplotypeCallerSpark). Any idea on how to extend the size?. The errors are:. `org.broadinstitute.hellbender.exceptions.UserException: Max size of locatable exceeded. Max size is 5000, but locatable size is 8638. Try increasing shard size and/or padding. Locatable: Contig1:65711-74348; 	at org.broadinstitute.hellbender.engine.spark.SparkSharder$5.computeNext(SparkSharder.java:293); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder$5.computeNext(SparkSharder.java:281); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.TransformedIterator.hasNext(TransformedIterator.java:43); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994:198,extend,extend,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994,1,['extend'],['extend']
Modifiability,"Hi, ; for those looking to run containers within a multi-user HPC environment, running a container with default root privileges presents a potential data security risk. Adding something like :. RUN useradd -ms /bin/bash gatk; WORKDIR /home/gatk; USER gatk. to the Docker file would greatly reduce the risk and bring the current containers in line with general best practice, e.g https://medium.com/@mccode/processes-in-containers-should-not-run-as-root-2feae3f0df3b. There should be no downsides to running in this manner. Singularity could help but the current configuration will be picked up and prevented from running by any site using a container security scanner, e.g. Aqua.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-494457377:562,config,configuration,562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-494457377,1,['config'],['configuration']
Modifiability,"Hi, I also meet this issue. . The Specificity in `HaplotypeCallerSpark` was a bitter less than local mode in my test. Do you known which configuration can improve the Specificity in `HaplotypeCallerSpark` ? @Atahualkpa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5323#issuecomment-433815315:137,config,configuration,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5323#issuecomment-433815315,1,['config'],['configuration']
Modifiability,"Hi, I think this can be closed now. . I just found that this issue might due to the inconsistency between gCNV version and PostProcessGermlineCNVCalls version. ; I updated my python configuration from 4.1.8.0 to 4.2.2.0 and the issue is gone. . Sorry for the troubles here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-908550017:182,config,configuration,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-908550017,1,['config'],['configuration']
Modifiability,"Hi, I'm trying to generate a VCF with Mitochondrial mode of Mutect2 based on MT amplicon (PCR) sequencing. But I encountered two problems:; 1. The base site (Pos: MT:16320) has high depth and good quality, but the result of AF is low. In IGV, AF~=0.5; 2. The total depth(DP) is also quite different from the depth in bam; I tried changing various parameters but nothing seems to make a difference? and even tried turn on --disable-tool-default-read-filters. Is there a parameter I'm missing? What are the filtering criteria? How to adapt to PCR data?. version: GATK4.1.4.1; java -Xmx16g -Djava.io.tmpdir=./tmp -jar gatk-package-4.1.4.1-local.jar Mutect2 -I tmp.bam -R hs37d5.fa -L MT.bed -O raw.vcf --min-pruning 5 --mitochondria-mode --max-reads-per-alignment-start 10000. MT 16182 . A AC,ACC . . DP=262;ECNT=7;MBQ=31,26,29;MFRL=0,0,0;MMQ=60,60,60;MPOS=44,44;OCM=0;POPAF=2.40,2.40;TLOD=84.81,46.04 GT:AD:AF:DP:F1R2:F2R1:SB 0/1/2:157,72,31:0.261,0.118:260:122,48,21:0,0,0:0,157,0,103; MT 16183 . A C . . DP=262;ECNT=7;MBQ=30,34;MFRL=0,0;MMQ=60,60;MPOS=45;OCM=0;POPAF=2.40;TLOD=531.07 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:58,204:0.780:262:42,190:0,0:0,58,0,204; MT 16188 . CT C . . DP=262;ECNT=7;MBQ=34,29;MFRL=0,0;MMQ=60,60;MPOS=50;OCM=0;POPAF=2.40;TLOD=19.25 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:243,19:0.070:262:207,15:0,0:0,243,0,19; MT 16189 . T C . . DP=262;ECNT=7;MBQ=35,34;MFRL=0,0;MMQ=60,60;MPOS=51;OCM=0;POPAF=2.40;TLOD=931.43 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:2,260:0.989:262:2,237:0,0:0,2,0,260; MT 16266 . C A . . DP=1073;ECNT=4;MBQ=7,32;MFRL=0,0;MMQ=60,60;MPOS=50;OCM=0;POPAF=2.40;TLOD=3575.47 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:14,1039:0.996:1053:4,469:0,446:0,14,481,558; MT 16274 . G A . . DP=1073;ECNT=4;MBQ=33,12;MFRL=0,0;MMQ=60,60;MPOS=53;OCM=0;POPAF=2.40;TLOD=1.89 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:1057,11:5.214e-03:1068:571,1:337,4:467,590,10,1; MT 16320 . C T . . DP=643;ECNT=4;MBQ=27,36;MFRL=0,0;MMQ=60,60;MPOS=21;OCM=0;POPAF=2.40;TLOD=11.29 GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB 0|1:564,60:0.017:624:48,60:358,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-575001931:532,adapt,adapt,532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-575001931,1,['adapt'],['adapt']
Modifiability,"Hi,. Thanks for the response. Running with -u isn’t ideal as we can’t control; how the user runs this (unless they do this on their own hardware or say a; cloud instance). However, I managed to convert the docker image into a singularity one and; that runs ‘out of the box’ in user space. Simon. On 3 Jun 2024, at 18:43, Gökalp Çelik ***@***.***> wrote:. Hi @potter-s <https://github.com/potter-s>; Our docker image is already built with root account only however PATH is; set to be usable by all users so if you wish to keep user priviledges after; execution you may add -u $UID:$GID parameter to docker command line; therefore the container will run using your user permissions. This has a catch of course. Temporary folders must be set where your user; has RWX permissions therefore we want users to pay attention to that. There; is a writing that we posted a while ago which you may refer to for setting; up your temporary files for GATK workflows. How to setup temporary folder for GATK local executtion; <https://gatk.broadinstitute.org/hc/en-us/articles/18965297287067-How-to-setup-and-use-temporary-folder-for-GATK-local-execution>. For some of the tools such as gCNV or CNN you may need to setup additional; environment variables to locate python compilation directory to a place; where you have read and write permissions. I hope this helps. —; Reply to this email directly, view it on GitHub; <https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2145780965>,; or unsubscribe; <https://github.com/notifications/unsubscribe-auth/ABU3SAWISO2HSCUNHK3SGIDZFSTK5AVCNFSM6AAAAABIWRNXGKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDCNBVG44DAOJWGU>; .; You are receiving this because you were mentioned.Message ID:; ***@***.***>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2155884154:1229,variab,variables,1229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2155884154,2,['variab'],['variables']
Modifiability,"Hi,; Glad to know that you have tested GATK4 with Amazon S3 using NIO file system plugin. ; I have been stuck on this process for long...I would really appreciate if you could share the work around procedure detail for this.; Thanks in advance !; Senthil",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3708#issuecomment-354368839:82,plugin,plugin,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3708#issuecomment-354368839,1,['plugin'],['plugin']
Modifiability,"Hi,; I tried your commands (and many adaptions / changements) but I always get the same problem:; If the command line includes `--`, I get the JNI linkage error as if the spark related parameters were not parsed.; I tried many things, as:; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --javaOptions -Dmapr.library.flatclass -- --sparkRunner SPARK --sparkMaster yarn --deploy-mode cluster; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --javaOptions -Dmapr.library.flatclass --sparkRunner SPARK --sparkMaster yarn -- --master yarn --deploy-mode cluster. > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --javaOptions -Dmapr.library.flatclass --sparkRunner SPARK --sparkMaster yarn -- --master yarn --deploy-mode cluster --conf spark.driver.extraJavaOptions='-Dmapr.library.flatclass' --conf spark.executor.extraJavaOptions='-Dmapr.library.flatclass'. > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --javaOptions -Dmapr.library.flatclass --sparkRunner SPARK --sparkMaster yarn -- --master yarn --deploy-mode cluster --driver-java-options '-Dmapr.library.flatclass'. It's a non-exhaustive list, I tried a lot of configurations similar to these ones.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350227061:37,adapt,adaptions,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350227061,2,"['adapt', 'config']","['adaptions', 'configurations']"
Modifiability,"Hmm, I am also getting intermittent build errors like the following much more often:. ```; Could not determine the dependencies of task ':sparkJar'.; > Could not resolve all files for configuration ':sparkConfiguration'.; > Could not download gson.jar (com.google.code.gson:gson:2.2.2); > Could not get resource 'https://repo.maven.apache.org/maven2/com/google/code/gson/gson/2.2.2/gson-2.2.2.jar'.; > Could not GET 'https://repo.maven.apache.org/maven2/com/google/code/gson/gson/2.2.2/gson-2.2.2.jar'. Received status code 403 from server: Forbidden; > Could not download core.jar (com.github.fommil.netlib:core:1.1); > Could not get resource 'https://repo.maven.apache.org/maven2/com/github/fommil/netlib/core/1.1/core-1.1.jar'.; > Could not GET 'https://repo.maven.apache.org/maven2/com/github/fommil/netlib/core/1.1/core-1.1.jar'. Received status code 403 from server: Forbidden; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601832142:184,config,configuration,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601832142,1,['config'],['configuration']
Modifiability,"Hmm, actually, could this be a problem due to the way the native libraries are loaded in the test code? Note that we first cycle through all implementations in the DataProvider, loading the respective library for each implementation via the `synchronized boolean load` method in the `NativeLibraryLoader`. I'm not really that familiar with concurrency in Java (nor loading native libraries, for that matter), but it seems that the intermittent failure goes away when I refactor the test to remove the DataProvider (by just looping through the implementations in the test method). Perhaps related to https://github.com/broadinstitute/gatk/issues/5339?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-607596205:469,refactor,refactor,469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-607596205,1,['refactor'],['refactor']
Modifiability,How did you install the GATK Conda environment? Looks like a problem with the conda environment configuration. One possible reason could be that conda environment is not the version 4.3.0.0 is requesting.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8952#issuecomment-2287925550:96,config,configuration,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8952#issuecomment-2287925550,1,['config'],['configuration']
Modifiability,"I _believe_ your issue is that you are assigning 600GB to execution of cromwell, but the error is with the call to **VariantRecalibrator** in one of the tasks not having enough memory. A few tasks call **VariantRecalibrator**, do you know which task failed? Can you post the java call from the STDERR file? For me, it was task **SNPsVariantRecalibrator** which was assigned only 3.5GB of memory by default. In [joint-discovery-gatk4.wdl](https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4.wdl), the memory assigned for each task can be set via ""machine_mem_gb"", but it looks like the current [input.json](https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4.hg38.wgs.inputs.json) does not have that variable, but instead ""mem_size"" for each task. . A simple solution would be to replace ${java_mem} with a static value in calls to **VariantRecalibrator** (lines 564 & 684). For example, replace:. `${gatk_path} --java-options ""-Xmx${java_mem}g -Xms${java_mem}g""`. with. `${gatk_path} --java-options ""-Xmx100g -Xms100g""`. I'm not certain this will help, but I think it's a step in the right direction.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165#issuecomment-571396381:785,variab,variable,785,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165#issuecomment-571396381,2,['variab'],['variable']
Modifiability,"I addressed partially your comments (and fixed a compilation error due to the tests using the previous arguments). One of the major points of discussion are the following:. * `Collection` instead of `List`: I think that the first is more flexible, because a client maybe wants to have a `LinkedHashSet` as the argument to avoid repetition of the same filter. I agree that the abstract class should discourage not honoring the user order.; * Access to methods/fields: I think that the plugin could be used outside GATK in a different way by extending it. I explained some of my usage cases in one of the comments in the code, but just by overriding a simple method the whole plugin could be used very nicely in some of them. I would prefer to do that than copy your code and re-implement the bits that I would like to change. Back to you for your ideas on this, @cmnbroad!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275359208:238,flexible,flexible,238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275359208,8,"['extend', 'flexible', 'plugin']","['extending', 'flexible', 'plugin']"
Modifiability,"I addressed some of your comments, @droazen. If you would like to have a properties file for the configuration, I will need some help on setting it up (although I will try by my own too). Although I still set up some of the environment in `Main`, now the `CommandLineProgram` class have the same instance passed by `Main`. Looking forward for your comments on the updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2322#issuecomment-271845715:97,config,configuration,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2322#issuecomment-271845715,1,['config'],['configuration']
Modifiability,"I agree with all Chris has said, and think that it's very likely that you're running out of memory on the executors. You might try cutting back on --num-executors, and bumping up --executor-memory.; If you can figure out your adapter sequence, you can specify that as --adaptor-sequence, and sometimes that helps with this stage.; We're laying down asphalt, and you're driving on the hot pavement just behind us. Thanks for trying out this tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4635#issuecomment-380144314:226,adapt,adapter,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4635#issuecomment-380144314,2,['adapt'],"['adapter', 'adaptor-sequence']"
Modifiability,"I also just noticed that tests are failing on the branch because they still reference the old constants in a number of places:. ```; symbol: variable READ_NAME_LONG_NAME; location: class ReadNameReadFilter; /gatk/src/test/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptorTest.java:117: error: cannot find symbol; { PlatformReadFilter.class.getSimpleName(), ""--"" + PlatformReadFilter.PL_FILTER_NAME_LONG_NAME, ""fakePlatform"" }, ; ```. You'll need to update these references in order to get tests passing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542:141,variab,variable,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542,1,['variab'],['variable']
Modifiability,"I also tried the following approach which did not generate an error:. 1. imported the 10 not-reblocked gvcfs from chr16 into genomicsdb ; 2. GenotypeGVCFs with the same command line as number 3 above. . So the error appears to be related to the reblocking of the gvcfs. ```; gendb:///restricted/projectnb/kageproj/gatk/genomicsdb/genomicsDB.chr16; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx60g -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -G StandardAnnotation -G AS_StandardAnnotation -V gendb:///restricted/projectnb/kageproj/gatk/genomicsdb/genomicsDB.chr16 -L chr16:105582-211160 --use-new-qual-calculator --only-output-calls-starting-in-intervals TRUE --genomicsdb-shared-posixfs-optimizations TRUE --tmp-dir tmp -O chr16-105582-211160.vcf.gz; 07:46:18.893 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 07:46:18.944 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 25, 2021 7:46:19 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 07:46:19.128 INFO GenotypeGVCFs - ------------------------------------------------------------; 07:46:19.128 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.0.0; 07:46:19.128 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 07:46:19.129 INFO GenotypeGVCFs - Executing as farre",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-905431278:455,variab,variable,455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-905431278,1,['variab'],['variable']
Modifiability,I ask that because for htsjdk defaults they must be system properties and they're final and set statically on load so mucking about resetting system properties after the JVM started already is going to be a bit of a fiddly ordering nightmare. . [Stack overflow](http://stackoverflow.com/questions/6736235/set-java-system-properties-with-a-configuration-file) doesn't seem to think that it's possible to initialize them from a file.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2316#issuecomment-267126704:339,config,configuration-file,339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2316#issuecomment-267126704,1,['config'],['configuration-file']
Modifiability,"I attended a journal club some months ago where a paper stated most researchers use default settings of tools. The paper benchmarked tool with default settings and with tweaked parameters. I can dig up the paper if anyone is interested. So there is some expectation from the user community that the default parameters reflect some sweet spot parameterization for running the tool. . I highly support @cmnbroad's suggestion for making argument sets callable by one flag. For exomes, please do not label flag as `WES`. We want to refer instead to _targeted exomes_, so `EXOMES` or variation is preferable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-386411104:342,parameteriz,parameterization,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-386411104,1,['parameteriz'],['parameterization']
Modifiability,I believe I've had this issue before but with different tools as well.; If you are on nextflow below is a config for scope docker. ```; docker.fixOwnership; Fix ownership of files created by the docker container.; ```. There is also another scope that could be set if there is only a single user. ```; docker.runOptions; This attribute can be used to provide any extra command line options supported by the docker run command. See the [Docker documentation](https://docs.docker.com/engine/reference/run/) for details.; ```; This one enables passing -u parameter to docker directly. . If none of them are set in the nextflow config then I would first suggest these options. If not we can escalate this with the team.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-2078156593:106,config,config,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-2078156593,2,['config'],['config']
Modifiability,"I can definitely appreciate that in some cases downstream analysis might be made easier if the original representations of GGA mode alleles were preserved. . Internally, HaplotypeCaller has to convert all variants at a position to share the same reference context so that read alignments can be compared to all possible alternate alleles simultaneously, and it would be a complex and error-prone process to re-map the unified alleles back to their original representations, and would also pose problems in terms of computing the correct values for INFO field annotations such as DP if the output VCF had to be split across multiple lines according to the how things were specified in the input files. I'm going to close this for now unless you strongly object or have an additional case that shows an error in GGA mode output. It's possible that in the future we could implement an enhancement in the form of a mode that preserves the GGA input allele representations, possibly under some stricter conditions upon the input, but that would likely be a tricky implementation. Pinging @ldgauthier to make sure she agrees.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5385#issuecomment-435902950:882,enhance,enhancement,882,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5385#issuecomment-435902950,1,['enhance'],['enhancement']
Modifiability,"I can't use it because of that, and it have lots of variables that I'm not using. I'm doing my own base test class, but I'd love to have a more general base test class in GATK to extend, without that many variables specific for this repository. Thanks a lot for your interest!. Should I do something for this PR? . So should I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242839085:52,variab,variables,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242839085,3,"['extend', 'variab']","['extend', 'variables']"
Modifiability,"I concur, what it looks like we have here is code that switched (accidentally?) from the GCS adapter to GCS-NIO instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265014643:93,adapt,adapter,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265014643,1,['adapt'],['adapter']
Modifiability,"I definitely like the idea of moving in this direction, and it will become more compelling as we extend the GATKSparkTool hierarchy, which is currently pretty flat and doesn't mirror the GATKTool hierarchy. I think we should also consider using some of the concepts from the metrics refactoring, which introduces a layer that separates the implementation of the processing logic from the containing tool/driver, and allows a single implementation (i.e. metrics collector, but could be FlagStats, CountReads, SelectVariants, whatever) to be independent of the source and/or destination of the data. It adds more moving parts, but has the advantage of allowing a single implementation to be used from any of Spark tool, standalone tool, Spark pipeline, standalone pipeline, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254216118:97,extend,extend,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254216118,2,"['extend', 'refactor']","['extend', 'refactoring']"
Modifiability,I did this PR because of the GenomeLocParser; what you suggested was the first thing that I tried. I did this instead of refactoring the BaseTest because I didn't want to cause major changes in the code.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242854061:121,refactor,refactoring,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242854061,1,['refactor'],['refactoring']
Modifiability,"I discovered that one of the 345 input gvcfs failed VCF validation. When I removed that file and reran with no other changes, I did not get the ""terminate called without an active exception"" error. However, ImportGvcfs still fails; the failure seems to occur immediately after GenomicsDBImport logs success in importing all batches, in each shard. From all the Cromwell logs it looks like everything is working, but the top level workflow execution fails. I've been trying various configurations of memory, scatter count, and #nodes, so I don't have those log files around still. I can rerun with -DGATK_STACKTRACE_ON_USER_EXCEPTION=true and see if I get anything useful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1295310651:481,config,configurations,481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1295310651,1,['config'],['configurations']
Modifiability,"I do not think you should have two versions. Here is a task example from; another workflow:. ```; output {; File cnv_acs_conversion_skew = ""${output_skew_filename}""; Float cnv_acs_conversion_skew_float =; read_float(output_skew_filename); String cnv_acs_conversion_skew_string =; read_string(output_skew_filename); }; ```. While this adds some clutter, at least the task (and workflow) produces a; file, float, or string. Then you can decide which you actually want to; attach to the data model via the method configuration output. Clutter vs. fork? I say ""clutter"". Also, you may only need one alternate; type. On Tue, Jul 2, 2019 at 9:52 AM ldgauthier <notifications@github.com> wrote:. > *@ldgauthier* requested changes on this pull request.; > ------------------------------; >; > In scripts/cnv_wdl/germline/cnv_germline_case_workflow.wdl; > <https://github.com/broadinstitute/gatk/pull/6017#discussion_r299492696>:; >; > > @@ -242,6 +250,7 @@ workflow CNVGermlineCaseWorkflow {; > Array[File] gcnv_tracking_tars = GermlineCNVCallerCaseMode.gcnv_tracking_tar; > Array[File] genotyped_intervals_vcf = PostprocessGermlineCNVCalls.genotyped_intervals_vcf; > Array[File] genotyped_segments_vcf = PostprocessGermlineCNVCalls.genotyped_segments_vcf; > + Array[File] qc_status_files = CollectSampleQualityMetrics.qc_status_files; >; > Ideally I'd want to be able to flag failing samples in an obvious way in; > the workspace, like having new fields in the data model called; > ""sample_quality"" and ""model_quality"" with the QC status reported there. Are; > we violently opposed to having a Cromwell version and a Firecloud version; > of this WDL? (@LeeTL1220 <https://github.com/LeeTL1220>); > ------------------------------; >; > In scripts/cnv_wdl/cnv_common_tasks.wdl; > <https://github.com/broadinstitute/gatk/pull/6017#discussion_r299493991>:; >; > > @@ -453,3 +453,98 @@ task PostprocessGermlineCNVCalls {; > File genotyped_segments_vcf = genotyped_segments_vcf_filename; > }; > }; > +; > +task Col",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-507695717:510,config,configuration,510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-507695717,1,['config'],['configuration']
Modifiability,"I don't really like the idea of a `--fix_misencoded_quality_scores` arg at the `GATKTool` level hooked into the data source -- I'd prefer to see your read transformer PR (https://github.com/broadinstitute/gatk/pull/2085) get merged, and then make read transformers a plugin that can be turned on/off on the command line, like we can with read filters. I've asked @cmnbroad to add a comment here outlining what would have to be done to make read transformers a plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245959488:267,plugin,plugin,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245959488,2,['plugin'],['plugin']
Modifiability,"I don't think that M2 should be spewing out a concatenation of all alleles,; since that does imply ploidy via the VCF spec. Multiallelics on multiple; lines violates the spec too, right?. On Mon, Sep 18, 2017 at 9:28 PM, David Benjamin <notifications@github.com>; wrote:. > @chandrans <https://github.com/chandrans> @chapmanb; > <https://github.com/chapmanb> @ldgauthier <https://github.com/ldgauthier>; > The -ploidy argument is one of several arguments inherited from; > AssemblyRegionWalker that apply only to HaplotypeCaller and do nothing in; > Mutect2. (We should refactor this once the engine team's workload; > lightens enough to review lower-priority things like this.) The GT field; > emitted by Mutect is just the concatenation of all called alleles -- 0/1,; > 0/1/2, 0/1/2/3 etc -- and doesn't imply anything about the ploidy. Maybe we; > should get rid of it entirely since AF is so much more informative.; >; > I like the idea of splitting multiallelics into multiple lines. It would; > make filtering a lot easier. @LeeTL1220 <https://github.com/leetl1220> do; > you have an opinion?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330401348>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk2Bmhl2i8xOPd4zC_WqQ9GtNbRKNks5sjxi1gaJpZM4PTWbd>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330527699:455,inherit,inherited,455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330527699,2,"['inherit', 'refactor']","['inherited', 'refactor']"
Modifiability,"I don't think that hiding/disable arguments would work in every case: sometimes, an argument shouldn't be exposed but still available to set programmatically, or maybe just reduce visibility making it `@Hidden` and/or `@Advance`. What is the problem of making an interface for the top-level argument to the GATK? Changing the interface or the `CommadnLineProgram` has the same effect, but the API user can still behave the same as before. It is much more extensible and downstream-friendly. What's about making the `CLPConfigurationArgumentCollection` an interface always returning defaults to be able to change it in a proper way? The cycle of development of a new argument will be: 1) add a new method to the interface with a default returning what will be expected from the previous behaviour, 2) add and return by the argument in the GATK implementation, 3) use the getter in the CLP for perform the operation. This only adds the first point, and operating in 3 classes instead of 3. For API user it is really easy to maintain the previous behavior when upgrading the dependency by just using their own implementation of the class, or include the top-level new arguments by using the GATK implementation. It is much more flexible and extensible (I always think about GATK also as a library). In addition, I think that this approach is also important for evolving GATK. For example, if a new top-level argument is tagged as experimental (still not supported but requested in Barclay), removing it would allow to keep the interface (no version bump) the same and final users can still operate with the experimental argument. The same applies to the `GATKTool` base class (https://github.com/broadinstitute/gatk/issues/4341), and for downstream projects the aim should be to be able to extend safely the `CommandLineProgram` directly to implement their own toolkit using the powerful GATK framework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-366185003:1225,flexible,flexible,1225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-366185003,2,"['extend', 'flexible']","['extend', 'flexible']"
Modifiability,"I don't think the `@author` tags will show up in the doc; they generally don't show up in javadoc, and our doc system doesn't include them in the generated doc.`@author` tags are a bit sketchy to begin with, because they're block tags, so the extend all the way to the start of the next tag. But since they're stripped out, putting such a tag at the start of the javadoc can result in everything after it being silently dropped from the output. We found such a case in GATK a while back.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349354828:243,extend,extend,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349354828,1,['extend'],['extend']
Modifiability,I fixed these by update the dataproc image from 1.0 -> 1.1. . @davidbernick Is there a way to make that into a variable that's settable in one place and shared between every jenkins spark job?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2289#issuecomment-264497363:111,variab,variable,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2289#issuecomment-264497363,1,['variab'],['variable']
Modifiability,"I got it to work by using the runtime switch --disable-sequence-dictionary-validation . . If that is not used it crashes. . . Docker commandline. . /gatk Funcotator --disable-sequence-dictionary-validation \. -R mydata/refs/Homo_sapiens_assembly19.fasta \. -V mydata/P50513_mutect2_filtered.vcf \. -O mydata/P50513_mutect2_funcotator.maf \. --output-file-format MAF \. --data-sources-path mydata/dataSourcesFolder/funcotator_dataSources.v1.6.20190124s/ --ref-version hg19. . . . From: Louis Bergelson <notifications@github.com> ; Sent: Wednesday, October 30, 2019 10:26 AM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: rdbremel <rdbremel017@gmail.com>; Mention <mention@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Funcotator shuts down (#6182). . @rdbremel <https://github.com/rdbremel> This got missed in the churn of issues. Does this happen repeatedly or is it a 1 time occurrence? We've seen similar issues in the past and tried to wrap them all in layers of retries, but sometimes things slip through. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub <https://github.com/broadinstitute/gatk/issues/6182?email_source=notifications&email_token=ANCR2VB4ZCHMAJUHBKE2SP3QRGRQFA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECUTZZI#issuecomment-547962085> , or unsubscribe <https://github.com/notifications/unsubscribe-auth/ANCR2VHRV5JESZYAYX55YHTQRGRQFANCNFSM4I2MRFQA> . <https://github.com/notifications/beacon/ANCR2VAS2WE5TDCUC6G5LETQRGRQFA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECUTZZI.gif>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548102382:975,layers,layers,975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548102382,1,['layers'],['layers']
Modifiability,"I grok the refactoring changes and those are 👍, but I think I'm going to need a walkthrough for the core spanning deletion work...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7857#issuecomment-1135250576:11,refactor,refactoring,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7857#issuecomment-1135250576,1,['refactor'],['refactoring']
Modifiability,"I guess it depends on how general we want to keep this input path. I think most purely read-depth based callers won't really be able to discover events smaller than 800bp or so (maybe 500bp at the lower limit) with any accuracy. I also don't know of any tools that we're considering that will describe individual breakpoints. . What about this for a rule: create two intervals for the start and end of the CNV interval + or - 151 bases (allowing a read length of slop). If the two intervals overlap, merge them together into a single evidence interval. . We could also make the slop amount parameterizable per input file, since different tools might have different characteristics, although that would be a feature we could just make a ticket for until we need it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327499474:590,parameteriz,parameterizable,590,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327499474,1,['parameteriz'],['parameterizable']
Modifiability,"I have a PR that fixes this. It's on the branch tws_desparkify_svdiscovery, which is a big refactor on some SV code. Someone could have a look and pull out just that bit of code to make a new, smaller PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6709#issuecomment-662574860:91,refactor,refactor,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709#issuecomment-662574860,1,['refactor'],['refactor']
Modifiability,"I have pull requests in flight for both (1) and (2). They are 1469; <https://github.com/GoogleCloudPlatform/google-cloud-java/pull/1469> and; 1470 <https://github.com/GoogleCloudPlatform/google-cloud-java/pull/1470>. Cheers,; JP. On Tue, Dec 6, 2016 at 3:54 AM, Tom White <notifications@github.com> wrote:. > Yes, Hadoop-BAM uses the NIO API to do file merging, whereas in GATK we; > were using the Hadoop APIs (and therefore the GCS<->HDFS adapter) to do it.; >; > It looks like there are a couple of things needed in GCS-NIO to use the; > NIO API for this.; >; > 1. GoogleCloudPlatform/google-cloud-java#1450; > <https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1450>; > so that we don't have to special-case gs URIs to remove everything; > except the scheme and host when looking up the filesystem (see; > https://github.com/HadoopGenomics/Hadoop-BAM/; > blob/master/src/main/java/org/seqdoop/hadoop_bam/util/; > NIOFileUtil.java#L40; > <https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L40>; > ); > 2. GoogleCloudPlatform/google-cloud-java#813; > <https://github.com/GoogleCloudPlatform/google-cloud-java/issues/813>; > to support path matching (https://github.com/HadoopGenomics/Hadoop-BAM/; > blob/master/src/main/java/org/seqdoop/hadoop_bam/util/; > NIOFileUtil.java#L90; > <https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L90>; > ); >; > There may be more, as I stopped there. The best way forward is probably to; > go back to the old code in GATK while the deficiencies in GCS-NIO are fixed; > and then released.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-266151447:441,adapt,adapter,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-266151447,1,['adapt'],['adapter']
Modifiability,"I have several use cases for this:; 1. I didn't mention it in the first comment, but if a tool does not want to provide custom `ReadFilter`from the user, but allow to disable the ones applied by the tool, this will keep in sync the parameter name.; 2. I would like to have a `ReadFilter` plugin that is applied ""after analysis"", but the parameters here said that they are applied ""before analysis"". This will be misleading for my users. For this case I also opened #2353, to allow custom parameters based on the same read filter plugin descriptor implemented in GATK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2352#issuecomment-274753122:288,plugin,plugin,288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2352#issuecomment-274753122,2,['plugin'],['plugin']
Modifiability,"I havent published to github yet, pending getting these core changes in; however, the purpose is pretty simple: allow VariantEval to inherit from MultiVariantWalker, but not require it to include the required argument -V. this seemed comparable to VariantWalkerBase (no arguments), and VariantWalker (specifies -V). GATK3's VariantEval uses the --eval argument and I generally tried to keep everything in this port in sync with GATK3, within reason. If there is another way to subclasses to negate some @argument defined by a superclass this would work too. If you want to see more I'll push to github.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-379803776:133,inherit,inherit,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-379803776,2,['inherit'],['inherit']
Modifiability,I imagine that @skwalker's scripts could be adapted for the task -- I'll try to set up a meeting with her next week to discuss.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-381170947:44,adapt,adapted,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-381170947,1,['adapt'],['adapted']
Modifiability,I inherited broadinstitute/gatk-protected#795 from @davidbenjamin.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2267#issuecomment-276161535:2,inherit,inherited,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2267#issuecomment-276161535,1,['inherit'],['inherited']
Modifiability,"I like option 2. If one of the other options is specified, use the specified value. For example, the following would use 0.1 for interval-psi-scale:. --set-defaults-for-data-type WES. --interval-psi-scale 0.1. On Mon, Apr 30, 2018 at 10:27 PM, samuelklee <notifications@github.com>; wrote:. > Thanks for bringing this up! I actually think that I prefer option 1,; > although not ideal (since, as you say, it places more burden on the user).; > The whole point of having generically parameterized models is that we can; > apply them to many data types. To single out a few with hardcoded sets of; > defaults seems like a slippery slope to me. (Of course, we should; > definitely provide defaults for typical data types in *documentation*.); > And in the end, I think it is beneficial for users that wish to tweak knobs; > to do some work to understand what those knobs actually do (even if just at; > a basic level).; >; > The other downside of option 2 is that it might not be immediately obvious; > from the command line what parameters are being used. For example, if a; > user chooses a set of defaults but then overrides some of them, we should; > make it so they don't have to go digging through the logs to see what; > parameters are actually used in the end. Nor should they have to go back; > and check what the defaults were for whatever version of the jar they were; > using at the time. Option 2 might also make it easier to inadvertently; > override parameters, etc. via command-line typos or copy-and-paste; > errors---it's much more straightforward to require and check that every; > parameter is specified once and fallback to a default if not, as we do now.; > Not to say that we couldn't get around any of these issues in Barclay, but; > I think it'll require some thought and careful design. Would be interested; > to hear Engine team's opinions.; >; > Finally, one point that I think will become more relevant as our tools and; > pipeline become more flexible and parameterized: I t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385677379:482,parameteriz,parameterized,482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385677379,1,['parameteriz'],['parameterized']
Modifiability,"I looked at the first new commit and skimmed the second. I'm assuming; tests still pass. If you want another set of eyes on the test data; refactor it'll have to wait until Monday. -L. On Fri, Oct 21, 2016 at 12:19 PM, David Benjamin notifications@github.com; wrote:. > @ldgauthier https://github.com/ldgauthier I _think_ you approved; > without needing it to send back to you, but I'm paranoid and not fully; > confident with the new github review system. Also, the changes to the test; > code to get rid of the duplicated likelihood-setting were pretty big.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gatk/pull/2185#issuecomment-255445145,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/AGRhdEDyfInQUcZiSZ5qBFhrAOnJpNZiks5q2RBVgaJpZM4KFNEm; > .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-256139184:139,refactor,refactor,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-256139184,1,['refactor'],['refactor']
Modifiability,"I made the change you suggested but just realized I forgot to push before; leaving for my flight. I'll push when I get back. On Tue, Nov 20, 2018, 12:04 PM ldgauthier <notifications@github.com wrote:. > *@ldgauthier* commented on this pull request.; >; > Looks lovely, thanks for the quick fix! I have one refactoring suggestion; > -- take it or leave it.; > ------------------------------; >; > In; > src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/RMSMappingQuality.java; > <https://github.com/broadinstitute/gatk/pull/5435#discussion_r235089237>:; >; > > return Arrays.asList(squareSum,totalDP);; > } catch (final NumberFormatException e) {; > throw new UserException.BadInput(""malformed "" + GATKVCFConstants.RAW_RMS_MAPPING_QUALITY_KEY + "" annotation: "" + rawDataString);; > }; > }; >; > + /**; > + * Private getter function to replace VariantContext::getAttributeAsIntList in instances where there is a chance; > + * that ints will overlow beyond Integer.MAX_VALUE; > + * @return VariantContext attribute indexed by key, as list of long.; > + */; > + static private List<Long> getAttributeAsLongList(final VariantContext vc, final String key, final Long defaultValue) {; >; > I agree with your reticence to put this into htsjdk. The type handling; > there is super awkward, but I don't think it's worth dealing with until it; > gets improved in 3.0. However, I might suggest making this method public; > and moving it to a utility class. GATKProtectedVariantContextUtils has a; > lot of similar methods; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5435#pullrequestreview-176875488>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGKhCBnSuwz30W-52kw9uZTXywWUCua-ks5uxDYbgaJpZM4Yp2Gl>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5435#issuecomment-440649639:306,refactor,refactoring,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5435#issuecomment-440649639,1,['refactor'],['refactoring']
Modifiability,I realized that the `--disable X --disable X` cannot blow up because the argument is a `Set`. Every repeated argument is hidden from the plugin. Either the signature should change to throw the exception or ignore that issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-276979349:137,plugin,plugin,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-276979349,1,['plugin'],['plugin']
Modifiability,"I should have been more specific. `--genotype-given-alleles` is HaplotypeCaller functionality, which is very similar if not outputting GVCFs. If providing dbSNP is similar to something you might want to do, then I think this approach will work. My concern was that if you were interested in a particular locus, but had never seen a variant there in any sample (i.e. didn't have an ALT allele to compare to), that implementation could get tricky. We should be able to output 100% reference sites with what I have in mind. @davidbenjamin while you're waiting for the restoration of the TCGA data, would you be interested in extending GGA mode to GenotypeGVCFs? (Obviously without the graph part.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6239#issuecomment-549503239:622,extend,extending,622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6239#issuecomment-549503239,1,['extend'],['extending']
Modifiability,I suspect this is related to the jar configuration (3 separate uber- jars) that is unique to the docker CI tests. I'll debug and resolve this after #6351 is merged.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1251462525:37,config,configuration,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1251462525,1,['config'],['configuration']
Modifiability,"I think it's best not to co-opt existing formats for storing *variant calls* and *mutations* if we want to store generic annotations. Furthermore, many of the drawbacks of VCF (e.g, wasted space from repeated tags/unused fields) are really not worth dealing with if our data is strictly tabular and well structured. I think if we can settle on a format internally that satisfies all of our needs, then it'd probably a *very small* amount of effort on the part of external developers to write adapters to consume it. After all, we are only talking about metadata (hopefully in a standardized but suitably flexible format, e.g. SAM/VCF-style header) + tabular data. It may also be that there is a format out there that already fits the bill, in which case we just need to do some more research and discussion. I think this would be better than causing confusion and setting a bad example by co-opting unsuitable formats, even if this would require no additional effort for external developers.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386578762:492,adapt,adapters,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386578762,2,"['adapt', 'flexible']","['adapters', 'flexible']"
Modifiability,I think now that we have the NIO plugin working we can probably replace everything that used AuthHolder with NIO.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277828180:33,plugin,plugin,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277828180,1,['plugin'],['plugin']
Modifiability,"I think that it is necessary to have a way for downstream projects to override some of the top-level arguments in the base CLP class. For example, the config file is for documentation purposes, but I don't want to expose users to that argument because I will set the defaults programmatically. Another example is the GCS retries, which might not be useful for a software that is not planning to support GCS even if it is already implemented (or does not want to expose). As a downstream developer, for me it is important to being able to configure arguments and expose/hide them to my final users; with the current implementation, my main issue is to have an argument that are irrelevant for the toolkit user and that I get questions about why and how to use them (the most clear example, the config file). If the main problem is to change an interface, a default value for new methods can be added to keep the same behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361876183:151,config,config,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361876183,6,['config'],"['config', 'configure']"
Modifiability,"I think that no `VariantAnnotation` is documented yet, because there is no even a plugin. It will be nice to have them anyway...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-342818332:82,plugin,plugin,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-342818332,1,['plugin'],['plugin']
Modifiability,I think that the annotation plugin is assigned to @jamesemery here: https://github.com/broadinstitute/gatk/issues/3287. But of course it can be documented before it is a plugin. I just wanted to point out that all of them should be annotated properly...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-342823849:28,plugin,plugin,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-342823849,2,['plugin'],['plugin']
Modifiability,"I think that this is a nice feature (at least for me) and not a bug. For example, if in GATK someone runs a tool with `-RF read_filters.args`, then the pipeline cannot be reproduced in a different dataset unless the file is accessible. I can understand that it could be also nice to preserve the `-RF read_filters.args` to be able to modify the file an re-run the tool with different parameters, but for me the purpose of storing the command line in the header or other places is keep track of the exact params that I used: if a file is modified, then it is impossible to trace the params. For input files, this is expected (if the input has changed, it is expected that the result change), but for arguments it shouldn't be the case (independently of the file changing, the tool was running with exactly that parameters). I vote for solve this in Barclay in a configurable way, to allow users to decide which kind of verbosity of the command line they want (I definitely prefer to expand as currently).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3797#issuecomment-342798092:861,config,configurable,861,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3797#issuecomment-342798092,1,['config'],['configurable']
Modifiability,"I think that this is prepared for merging, @cmnbroad. As soon as it gets in, I would submit a PR fixing all the problems found in the plugin descriptor for discussion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-278391496:134,plugin,plugin,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-278391496,1,['plugin'],['plugin']
Modifiability,"I think that this is related with https://github.com/broadinstitute/gatk/issues/1880, and I've already develop a rough system in a small project to have a plugin for variant annotation. I would love to contribute to this, and I kind of started with https://github.com/broadinstitute/gatk/pull/2534",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2542#issuecomment-290173938:155,plugin,plugin,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2542#issuecomment-290173938,1,['plugin'],['plugin']
Modifiability,I think the only failure left is a Travis thing. Back to @vruano after heavy refactoring.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-519630216:77,refactor,refactoring,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-519630216,1,['refactor'],['refactoring']
Modifiability,"I think this is happening because were trying to serialize the class loader sun.misc.Launcher$AppClassLoader), which appears to be reached through the graph by way of via https://github.com/damiencarol/jsr203-hadoop/blob/master/src/main/java/hdfs/jsr203/HadoopFileSystem.java#L82. We probably need to short circuit that with a custom serializer for one of these:. Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager). See, for instance, https://github.com/dbpedia/distributed-extraction-framework/issues/9.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-668654169:466,Config,Configuration,466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-668654169,1,['Config'],['Configuration']
Modifiability,I think we can finally unblock this using PAPIv2's ability to request machine types on Google Cloud. We just have to configure our jenkins server to use PAPIv2.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4356#issuecomment-415862887:117,config,configure,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4356#issuecomment-415862887,1,['config'],['configure']
Modifiability,I think we will add a logger for GenomicsDB with configurable verbosity - but this is low priority for us.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-300298389:49,config,configurable,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-300298389,1,['config'],['configurable']
Modifiability,"I tried running gatk version 4.0.7.0 with the environment variable: 'TILEDB_DISABLE_FILE_LOCKING=YES' to see if that would fix the issue, but I still get the same error. I am not sure that the patch that enable that was actually in the 4.0.7.0 release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-409070215:58,variab,variable,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-409070215,1,['variab'],['variable']
Modifiability,"I tried setting that environment variable, but it did not resolve the issue. Please note that I have this filesystem mounted as `CIFS` not `NFS`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453657941:33,variab,variable,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453657941,1,['variab'],['variable']
Modifiability,I want to point out a bug regarding the read plugin that I reported in #357 (and fix with in #2359): disable a default filter with arguments blows up as a `CommandLineException` as if the user provided the arguments for a disabled filter. This is quite important in this regard of insane combinations.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-276625536:45,plugin,plugin,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-276625536,1,['plugin'],['plugin']
Modifiability,"I was looking into this because it is useful for me, and I have found that there is going to be redundancy between the `VariantAnnotatorEngine`code and the plugin. Here a couple of suggestions after trying to implement something in this regard time ago:. * Remove/deprecate the private class `AnnotationManager` in favor of the plugin. The current code is performing reflection operations by itself, and this can cause some problems.; * Refactor the `VariantAnnotatorEngine` constructors in favor of a constructor from the barclay plugin and a list of annotations to apply, to avoid the `AnnotationManager` implementation.; * Remove/deprecate static methods for creating an annotator engine (`ofAllMinusExcluded` and `ofSelectedMinusExcluded`) in favor of handling this in the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922:156,plugin,plugin,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922,5,"['Refactor', 'plugin']","['Refactor', 'plugin']"
Modifiability,"I was thinking more carefully on this and another option is create methods in `ReadPileup` to fix the overlaps after construction and/or getBaseCounts without overlaps. This won't break the behaviour of LIBS and it is up to the user to change overlaps. But for performance issues, I would like to have a variable in `ReadPileup` for track if the overlaps are corrected/fixed, to avoid recomputation. I can implement this in a different PR or in this one if the basic idea behind this one is not accepted.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2041#issuecomment-235993555:304,variab,variable,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2041#issuecomment-235993555,1,['variab'],['variable']
Modifiability,"I was thinking that if we relied on PyPI for distribution, it would only be for released builds, not a release for every repo merge commit. But, I'm increasingly inclined to think that in the short term we should just include the python archive/zip file right in the gatk distribution zip, and modify the env .yml to install from that. Then every configuration (docker image, git clone user, and end user) could use exactly the same method to establish the environment. That seems like the simplest solution for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-352279343:347,config,configuration,347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-352279343,2,['config'],['configuration']
Modifiability,"I will do a big PR with a commit for each of the issues that we found in the plugin, and including tests. Although the plugin interface is going to change in Barclay, I think that before that the PR should setup all the tests for the issues to ensura that the change does not broke anything. Any opinion on this, @cmnbroad, @droazen, @lbergelson?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278248587:77,plugin,plugin,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278248587,2,['plugin'],['plugin']
Modifiability,"I would like to have this feature for a new project that will rely on the built-in walkers of GATK. The main problem that I am facing is while grabbing the info from the METAINF file. For fixing this, I have a proposal:. * Create a new interface with the single method to print the startup message; * Create a base-class with the current code in GATK, which can be extended to override some parts of the startup message, but not all.; * Make a non-final static field in `CommandLineProgram` , which is settable. This could be set in the `Main` for toolkits (similarly to how the config file is set). The default will be the GATK implementation. If you agree with the proposal, let me know to implement it and submit a PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458:365,extend,extended,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458,2,"['config', 'extend']","['config', 'extended']"
Modifiability,"I would like to specify what passing a `ReadFilter` to some of my tools means, so maybe passing an `ArgumentCollection` will be simpler than this one, I agree. Although #2085 may solve the issue regarding the `ReadTransformer`/`ReadFilter` ordering, I would like to have in the plugin a way to specify different parameters (maybe some of then hidden before expose to users or advanced in the case of disabling). I will open a new PR for that change, but I will really appreciate if I can get something like that in this and other plugins (if implemented).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-275082983:278,plugin,plugin,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-275082983,4,['plugin'],"['plugin', 'plugins']"
Modifiability,"I'd be OK with adding some sort of experimental tag, but I'm not sure where to put it. Does that goes in the docs or somewhere in the code to post a warning to the log? I think the new tests should cover that it's working as intended. There is definitely room for future work (e.g. paying closer attention around the boundaries, the refactoring ideas, etc), but for now the docs should describe the expected behavior well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1847926227:333,refactor,refactoring,333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1847926227,1,['refactor'],['refactoring']
Modifiability,"I'd like to get to the point where most/all GATK tools extend `GATKTool` rather than `CommandLineProgram` directly, so I think we have to keep this one open.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358025246:55,extend,extend,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358025246,1,['extend'],['extend']
Modifiability,"I'll also mention that as part of https://github.com/broadinstitute/gatk/issues/4341 we plan to give tools more control over the arguments inherited from `GATKTool`, including selectively disabling and redefining engine arguments, so once a mechanism is in place for that `CalculateGenotypePosteriors` could make `--sequence-dictionary` required. Currently this ability only exists for a few `GATKTool` arguments, and the tool has to override methods like `requiresReads()` to make use of it. Until the ability to do this is generalized, recommend the stopgap solution with the check in `onTraversalStart()` + a note in the tool's docs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4383#issuecomment-364497042:139,inherit,inherited,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4383#issuecomment-364497042,1,['inherit'],['inherited']
Modifiability,I'll take it. The tab completion task is printing out too many warnings for all of the new instances of unresolvable backtrace variables due to Picard. I'll do....something with it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3710#issuecomment-337386911:127,variab,variables,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3710#issuecomment-337386911,1,['variab'],['variables']
Modifiability,"I'm adding some issues and PRs for make the plugin usable in other cases too, @cmnbroad. Maybe you prefer that solution instead of make it extensible. Just let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275376544:44,plugin,plugin,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275376544,2,['plugin'],['plugin']
Modifiability,"I'm always confused with static-block initializers, and I just wondered in the config PR if the static block in `Main` it is correctly setting everything in sub-classes. I understood that this won't work in Main-derived classes; if that's not the case, feel free to close this PR...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324627658:79,config,config,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324627658,1,['config'],['config']
Modifiability,"I'm assuming you will have the subset of samples before creating a GenomicsDBFeatureReader object (and before creating the corresponding Protobuf export configuration object). More precisely, you are NOT requesting a line by line filter similar to:; At pos 100, compute INFO fields etc including only the samples whose QUAL > 5; At pos 102, compute INFO fields etc including only the samples whose QUAL > 5; ....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322:153,config,configuration,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322,1,['config'],['configuration']
Modifiability,"I'm glad it's working now, but a PS since you asked about `-independent-mates`: several months ago we made Mutect2 force paired reads to share the latent random variable indicating which haplotype they are derived from in the somatic genotyping model. This is correct because paired reads come from the same molecule of DNA. `-independent-mates` disables this and tells Mutect2 to forget about pairing. We only created the option because some synthetic validation data is generated by spiking in variation without regard to pairing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-596165833:161,variab,variable,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-596165833,1,['variab'],['variable']
Modifiability,"I'm going to close this issue because it's not a bug. Several things in the code of Mutect2 and FilterMutectCalls adapt as they traverse the genome and it's possible that some learned parameter shifts minutely. For example, the assembly graph pruning algorithm uses knowledge of previously assembled regions to better distinguish between errors and somatic variation. It's also possible that somewhere we forgot to give something a fixed random seed. In full honesty, I _wish_ that I knew exactly what causes the 3142 to become 3143, and I regret that I don't have time for it. Nonetheless, in principle it is not cause for alarm.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8152#issuecomment-1983783338:114,adapt,adapt,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8152#issuecomment-1983783338,2,['adapt'],['adapt']
Modifiability,"I'm more familiar with working with interval data files so I can't speak much to variant call formats except that VCF tends to be a bit wonky with interval data (such as SV calls) because, as @samuelklee mentioned, most of the fields are likely to be irrelevant and thus waste space. I feel strongly that BED-like formats are the way to go for interval data, i.e. #contig start end x1 x2 x3 x4 ...; chr1 2938 3949 3.9 0 + cat ...; ... where x1, x2, x3, x4 ... are columns for variables of different types (which could be specified by additional header lines like in VCF).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385748457:476,variab,variables,476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385748457,1,['variab'],['variables']
Modifiability,"I'm not sure exactly what's happening but I suspect it has something to do with the way the files are mounted. My guess is that there is some sort of transient interruption happening in the connection between the EC2 instance and the file server, and it's causing an error in gatk. When reading from a local file GATK does not expect any errors since errors in local files are usually fatal problems caused by a broken disk. Its probably some sort of bug in amazon's fuse implementation which isn't properly hiding network problems from the software. . I expect that your output is truncated at the point the error occured, and you probably need to rerun those shards. Instead of mounting them with amazon's fuse, you could try to either copy the files to a local disc, or access them using an NIO filesystem plugins like this plugin https://github.com/awslabs/aws-java-nio-spi-for-s3 or as signed URLs using https://github.com/broadinstitute/http-nio/ (included in gatk 4.6).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8735#issuecomment-2214915942:809,plugin,plugins,809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8735#issuecomment-2214915942,2,['plugin'],"['plugin', 'plugins']"
Modifiability,"I'm not sure what proportion of users leverage the incremental import functionality...it wasn't available when GenomicsDBImport was first made available, but has been around for ~3 years now. As for workspaces with whole chromosomes -- there is no requirement or performance benefits to using whole chromosomes. As you say, subsetting a chromosome to smaller regions will work and make the import and query parallelizable. (if you remember where the advice about whole chromosomes came from, let us know. That might be something that needs to be updated/clarified). Many small contigs does add overhead to import though and, till recently, multiple contigs couldn't be imported together (i.e., each contig would have it's own folder under the GenomicsDB workspace - which gets inefficient with many small contigs). For WGS, probably the best way to create the GenomicsDBImport interval list is to split based on where there are consecutive N's in the reference genome (maybe using [Picard](https://broadinstitute.github.io/picard/command-line-overview.html#ScatterIntervalsByNs)) and/or regions that you are blacklisting. I think you suggested that some of the blacklisted regions were especially gnarly - maybe ploidy or high alternate allele count? - depending on the frequency of those, we may save a bit on space/memory requirements. That may address your concern about overlap between variants and import intervals. In general, any variant that starts in a specified import interval will show up in a query to that workspace. I'm not sure if the blacklist regions contain any variants that start within but extend beyond the blacklist -- those may not show up if the regions are split up in this way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1212486548:1612,extend,extend,1612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1212486548,1,['extend'],['extend']
Modifiability,"I'm not sure why the `gs` provider doesn't get installed (I think JP was seeing this before), but in any case there's a workaround in GATK for it: https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java#L380-L390. However, since the Hadoop-BAM code is doing the path lookups, it can't call that code directly (the dependency is the wrong way round). It would be best if we could fix the underlying problem of course, so that it gets picked up properly - I wonder if this can be done by fixing the service provider so it survives relocation (see http://maven.apache.org/plugins/maven-shade-plugin/examples/resource-transformers.html#ServicesResourceTransformer). BTW I'm afraid I'm travelling this week, so I won't have time to look at it until next week either :(",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-263997131:635,plugin,plugins,635,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-263997131,2,['plugin'],"['plugin', 'plugins']"
Modifiability,I'm not totally clear from your response but I think you've resolved the problem? . If you're encountering a bug merging bai files could you open an issue describing that with your stack trace and any relevant information about the configuration you're running?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547956623:232,config,configuration,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547956623,2,['config'],['configuration']
Modifiability,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:65,plugin,plugin,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675,6,"['config', 'plugin']","['configuration', 'configurations', 'plugin', 'plugins']"
Modifiability,"I'm using spark 2.1.0. I can confirm it works with the command ; ```; spark-submit \; --deploy-mode client \; --class org.broadinstitute.hellbender.Main \; --master yarn \; /home/hadoop/gatk-package-4.alpha.2-269-gdce8abc-SNAPSHOT-spark.jar BwaSpark \; --bwamemIndexImage /var/tmp/hs38DH-V.fasta.img \; -I hdfs:///unaligned.bam \; -O hdfs:///aligned.bam \; -R hdfs:///hg38/hs38DH-V.fasta \; --disableSequenceDictionaryValidation true \; --sparkMaster yarn; ```; so I guess it's really a minor issue. I can see it confusing other spark users though, who might expect spark configuration arguments to go through `spark-submit` rather than the application args, especially since the --sparkMaster app arg is optional. Just my two cents.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-301945697:572,config,configuration,572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-301945697,1,['config'],['configuration']
Modifiability,"I've added a few commits that clean up some of the code inherited from VQSR regarding the use of labeled resources when using allele-specific annotations. This should be ready for review and/or experimentation with importing into the WARP repo, @meganshand. There are a few unrelated failing tests, which I think others are seeing in their branches as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8074#issuecomment-1323953256:56,inherit,inherited,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8074#issuecomment-1323953256,1,['inherit'],['inherited']
Modifiability,"I've added a new end-to-end test for SelectVariants that writes to GCS. Sadly, the IntegrationTestSpec class uses Files throughout, so it wasn't possible to do this simply without first completely refactoring IntegrationTestSpec (which should probably be its own pull request). . Doing this refactoring would have the advantage that changing existing end-to-end tests from local to GCS would be trivial. For now instead I went with an ad-hoc approach. It works, and the test passes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455686612:197,refactor,refactoring,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455686612,4,['refactor'],['refactoring']
Modifiability,"I've pulled the problem VCF and a couple of successful ones locally and I can confirm that when running with 4 VCFs:. - VCFs that succeeded through JointGermlineCNVSegmentation in our pipeline succeeded for me locally; - The VCF that was flagged in the error message `Exception thrown at chrX:6383391 [VC SAMPLE_ID.segments.vcf.gz ...` completes just fine with other successful partners; - The VCF that was not identified in the error message, but was inferred to be a sex chromosome aneuploidy causes a failure with any combination of other VCFs; - If there are more than 2 VCFs run together, including the failing VCF/aneuploid sample, the error message indicates the problem originates in a non-aneuploid VCF, which misleading and makes this hard to treat. This behaviour was consistent in `4.5.0.0`. Command used in my toy dataset:. ```; gatk --java-options ""-Xms4000M -Xmx6000M"" JointGermlineCNVSegmentation -R /data/Homo_sapiens_assembly38_masked.fasta -O /data/out.vcf.gz -V /data/SAM1.segments.vcf.gz -V /data/SAM2.segments.vcf.gz -V /data/SAM3.segments.vcf.gz -V /data/SAM4.segments.vcf.gz --model-call-intervals /data/preprocessed.interval_list -ped /data/inferred_sex_pedigree.ped; ```. - In this configuration, `SAM4` is aneuploid, and `SAM1` is always the flagged VCF; - If I remove `SAM1` and re-run with 3 VCFs, `SAM3` is mentioned in the error message. It's not derived from alphabetical order, first argument specified with `-V`, or first in the PED file",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8834#issuecomment-2123897736:1208,config,configuration,1208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8834#issuecomment-2123897736,1,['config'],['configuration']
Modifiability,"ITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.L",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4949,variab,variable,4949,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['variab'],['variable']
Modifiability,"If I understand correctly, @bbimber, this sounds a lot like the `--genotype-given-alleles` change David B. made recently -- discover new sites in the provided samples, but _also_ output calls against the variants specified in the resource file. This is a small change from what you propose because the resource file would specify a particular ALT allele, so if you were interested in positions where you haven't seen a variant yet we'd need to extend functionality to call against <NON_REF> and output or you could put some random placeholder allele, although the identity of that allele would affect your likelihoods. On the other hand, having an ALT specified from a previous cohort would improve your likelihoods for all-reference cohorts compared to what you get now for non-variant site output.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6239#issuecomment-549456607:444,extend,extend,444,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6239#issuecomment-549456607,1,['extend'],['extend']
Modifiability,"If it helps, this is a dummy walker that illustrates the kind of parallelization I'm exploring whether I can implement. The main sticking point I think exists relates to different threads interacting with FeatureManager and the feature reading code:. I would appreciate any thoughts on how to approach this in GATK. ```. /**; * This is a contrived example. It is designed to explore multithreading; */; public class DemoMultiVariantEval extends MultiVariantWalkerGroupedOnStart {; protected List<VariantEvalEngine> engines = new ArrayList<>();. @ArgumentCollection; protected VariantEvalArgumentCollection variantEvalArgs = new VariantEvalArgumentCollection();. @Override; protected void initializeDrivingVariants() {; getDrivingVariantsFeatureInputs().addAll(VariantEvalEngine.getFeatureInputsForDrivingVariants(variantEvalArgs));. super.initializeDrivingVariants();; }. private ExecutorService pool = null;; private final int threads = 2;. @Override; public void onTraversalStart() {; //Again, contrived. The real case would set up multiple engines with different parameters:; engines.add(new VariantEvalEngine(variantEvalArgs, this, getSequenceDictionaryForDrivingVariants(), getSamplesForVariants(), logger));; engines.add(new VariantEvalEngine(variantEvalArgs, this, getSequenceDictionaryForDrivingVariants(), getSamplesForVariants(), logger));. final ThreadFactory threadFactory = new ThreadFactoryBuilder(); .setNameFormat(""dummywalker-thread-%d""); .setDaemon(true); .build();. pool = Executors.newFixedThreadPool(threads, threadFactory);; }. @Override; public void apply(final List<VariantContext> variantContexts, final ReferenceContext referenceContext, final List<ReadsContext> readsContexts) {; // Parallelization should help; however, these steps interact with FeatureManager and the FeatureInputs.; // Is there an appropriate way to approach this?; Utils.runInParallel(threads, () -> {; this.engines.parallelStream().forEach(engine -> {; engine.apply(variantContexts, referenceContext);;",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7013#issuecomment-750442132:437,extend,extends,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7013#issuecomment-750442132,1,['extend'],['extends']
Modifiability,"If the encapsulation of the datasources is causing issues for tools that extend `GATKTool` directly, we can relax it -- it was intended to prevent walker authors from directly manipulating the datasources used for the traversal, but it may be doing more harm than good at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358333054:73,extend,extend,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358333054,1,['extend'],['extend']
Modifiability,"In order to get it running though you will need to install the following things on each machine using apt-get: gawk, sysstat, and perf-tools-unstable. Additionally as root, you will have to set the /proc/sys/kernel/perf_event_paranoid variable from 1 to 0. For these tasks it might be possible to automate these steps by updating the system image that is used to setup dataproc clusters. In order to actually run and install PAT, you will need to download it from [here](https://github.com/intel-hadoop/PAT/tree/master/PAT) and add all the machines and ssh ports (including the master) in your cluster to the ""ALL_NODES"" setting in the config.template -> config file. You will also have to setup an SSH key to root on the cluster, which can be done with the command `gcloud compute ssh` and set the ""SSH_KEY"" variable in the config file to point to the google_compute_engine file in roots .ssh directory (public keys should have automatically been distributed to the other nodes). . At this point you need simply input the command line command you wish to run into the ""CMD_PATH"" variable and run ./pat run. I recommend running a spark-submit job using yarn-client as master. NOTE: the output will be a directory containing an excel spreadsheet and a bunch of data for each cluster. You will need to open the spreadsheet on a windows copy of excel and use ""control+q"" to run the macros that load the data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1986#issuecomment-234947495:235,variab,variable,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1986#issuecomment-234947495,6,"['config', 'variab']","['config', 'variable']"
Modifiability,"In terms of the two tools, I don't think it's necessary at this point to make an inheritance structure. `CallVariantsFromAlignedContigsSAMSpark` is more of a one-off for dealing with de novo assembly files and I'm not sure if it will be supported long term. However, I did extract a `callVariantsFromAlignmentRegions` method in `CallVariantsFromAlignedContigsSpark` that `CallVariantsFromAlignedContigsSAMSpark` can use, which reduces code duplication a lot. There's not much left in `CallVariantsFromAlignedContigsSAMSpark` except for the logic to convert GATKReads into AlignmentRegions, which seems appropriate.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240514475:81,inherit,inheritance,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240514475,1,['inherit'],['inheritance']
Modifiability,"Interesting! Thanks for generating these. I am already convinced by #4519 we should at least switch over to a ‘CollectReadCounts’ strategy for initial evaluations. A few comments:. -I’m guessing that the equal insert size and uniform sampling is enhancing many of these artifacts to a level that we probably don’t see in the real world. Can we take a look at some real-world examples?. -Same goes for the fact that homs will be unlikely. -Not sure about the dropouts. Might be worth running without SNPs as a confounding factor. -How flexible is SVGen? Might be worth putting together a more realistic simulated data set. Any chance @MartonKN might be able to use it to cook up some realistic tumor data?. -I don’t recall having a `CollectBaseCallCoverage` type tool in beta—which tool are you thinking of? On a related note, it seems there is some demand to port `DepthOfCoverage` from GATK3. However, I’d prefer that we roll a CNV-specific version of the tool even if it does get ported. In any case, I think along with findings from the other issue, we should issue a quick PR for `CollectReadCounts` and go ahead to change the `CollectCounts` WDL task to call it—it’s for this very reason that the task is named generically! @sooheelee note that we may have to update the tutorials, etc. at some point, but perhaps the right time will be until all evaluations are more complete. Speaking of which, this PR should not delay getting the first round of automated evaluations up and running. Again, the whole point of those is to have a reproducible baseline metric against which we can easily experiment with and adopt these sorts of changes. Although these sorts of theoretical/simulated/thought experiments are clearly useful to us, unfortunately, they may not be as compelling to some of our users as demonstrable improvement seems on real data!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976:534,flexible,flexible,534,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976,2,['flexible'],['flexible']
Modifiability,"Interesting, that's somewhat disturbing news, I wonder if we're paying for ssd's without actually being able to use them... It's also possible there's a different setting that's configuring the ssd's to be used for shuffle output. . We should investigate this further and 1) see if setting spark.local.dir makes a performance difference 2) ask the dataproc team about this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283418564:178,config,configuring,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283418564,1,['config'],['configuring']
Modifiability,"Interesting, this is the first time that I have seen a CentOS-7 install without zlib and uuid - even the minimal installations include it. Your options are:; - Install zlib and uuid (yum -y install zlib libuuid); - Ask your admins whether these packages are installed in some other location. For example, if the zlib library is at /opt/my_install/lib64/libz.so, then you can set your environment variable LD_LIBRARY_PATH; ```; export LD_LIBRARY_PATH=/opt/my_install/lib64:/opt/my_install/lib:$LD_LIBRARY_PATH; ```; - Wait for the next GenomicsDB binary jar to show up",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214:396,variab,variable,396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214,1,['variab'],['variable']
Modifiability,Is it guaranteed that one of the configurations won't include any of the MQ0 regions? Why is that?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-364663550:33,config,configurations,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-364663550,1,['config'],['configurations']
Modifiability,Is there a way to have java load a config file as system properties on startup?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2316#issuecomment-267124998:35,config,config,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2316#issuecomment-267124998,1,['config'],['config']
Modifiability,"Is this the only `CommandLineException` which should be an `UserException`? If not, how is going to work the development of new exceptions in Barclay. For instance, in https://github.com/broadinstitute/barclay/pull/11 there is a new exception that I made for values out of range, which extends `BadArgumentValue`. I agree that this errors should be decoupled from the ones that are not, but in this case I think that this is already implemented:. * `UserException` are handled in the `mainEntry()`, distinguishing errors that comes from the user's side regarding some specifications in the tools/framework.; * `CommandLineException` are handled in `parseArgs()`, distinguishing errors that comes from the command line from the user side while parsing. I expect that any command line error that is not `CommandLineParserInternalException ` or `ShouldNeverReachHereException` comes from the user's side. The contract in Barclay says that are `CommandLineException` are _""Exceptions thrown by CommandLineParser implementations.""_, and I think that if other parts of the code (outside arg parsing) is throwing this exception is a bug that does not come from the user. I guess that this is the problematic part.; * Any other `Exception` is thrown in `Main.handleNonUserException()`, which may be caused by non-user exceptions. I propose that `CommandLineException` is handled as currently to separate ""errors that are the user's fault regarding input and/or assumptions"" (`UserException`), ""errors that are the user's fault while providing parameters to the command line"" (`CommandLineException`) and ""errors that are not the user's fault"" (other `Exception`s). Actually, this is reasonable because the exit status is different for any kind of errors in the current `Main`. The only problem that I see with this approach is the silently failing of a ""bug"" in tools/engine code, which can be rethrow easily in `CommandLineProgram.instanceMain`` as following:. ```java; public Object instanceMain(final Strin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268773161:286,extend,extends,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268773161,1,['extend'],['extends']
Modifiability,"It *looks like* it doesn't. I ran a job and looked at the ""environment"" tab in the Spark page for the job and didn't see ""spark.local.dir"" mentioned in the list of properties or the command line. Based on [the documentation](http://spark.apache.org/docs/latest/configuration.html), the setting must thus still be at its default value of ""/tmp"". . /tmp is on the HDD, the SSD one would have to be on /mnt/1/.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283210934:261,config,configuration,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283210934,1,['config'],['configuration']
Modifiability,"It can easely be extended to multiple sequences... it just happened that I didn't need it personally. . I took a quick pick to your branch... do you really care about the contig descriptions?.... I would say that this ""aligner"" class should not be responsible of compose the multi sequence fasta file but rather accept one as a constructor argument and the construction of the fasta is delegated back to the invoker code; in this new more general aligner the current single contig could be implemented as a public static method call.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4780#issuecomment-389762587:17,extend,extended,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4780#issuecomment-389762587,1,['extend'],['extended']
Modifiability,"It could just be natural variability in the user's runtime environment, but it's worth doing some longer-running tests to be sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-324453449:25,variab,variability,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-324453449,1,['variab'],['variability']
Modifiability,"It depends why it fails the filter. One reason is consecutive indel elements, but consider for example:. ref: ACGTTTA; read: AC TTTTA; cigar: 2M1D1I4M. Especially in long-read technologies with a lot of indel errors it seems draconian to throw out reads where this happens once. And okay, I understand that an aligner could represent this as a G->T subsitution, but what about the same thing but with 2D followed by 2I? That strikes me as a much better cigar than calling it a DNP. In general, a bad cigar should mean either that the aligner is bad (in which case why are we filtering isolated reads and not just rejecting the entire BAM?) or the read is malformed. But consecutive indels in a technology with many indel errors is neither of these!. Anyway, I don't think there's a problem with allowing these reads in the GATK, and if there is the refactoring in this #6403 should let us fix any problem easily enough.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6433#issuecomment-583415079:849,refactor,refactoring,849,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6433#issuecomment-583415079,1,['refactor'],['refactoring']
Modifiability,"It looks like all the changes in my original commit with the raw GATK3 code (except for one file) got squashed out somehow, so I can't see just the changes from GATK3 anymore. I'll probably have to go back and re-commit those when you're ready to make this tractable to review. I'll wait to comment on #1 until that happens. As for a default plugin descriptor, I'd prefer not to take one unless its fully implemented, with tests. Plus, although we could develop it here, it should really live in the Barclay repo if its truly generic. More importantly, I'm not sure the plugins in this PR should be plugins at all. Historically, plugins have required a lot of test development and iteration because they have command line arguments (the plugin system is for extending the command line parser with discoverable, re-useable components that are shared across multiple tools, and need shared command line arguments). I haven't looked at the new ones closely, but I'm not sure they're a good fit. As for the files, it look like about 400MB (?) Thats pretty big - you should try to squeeze them down or target some existing files if you can.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431839008:342,plugin,plugin,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431839008,6,"['extend', 'plugin']","['extending', 'plugin', 'plugins']"
Modifiability,It looks like there's some minor refactoring in your new graph handler. I'm not a real stickler about sneaking that in but just want to check it was intentional.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4622#issuecomment-378055518:33,refactor,refactoring,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4622#issuecomment-378055518,1,['refactor'],['refactoring']
Modifiability,"It seems plausible to me, though, that the Google auth library may have been patched to perform checks that it wasn't performing previously. Maybe our project permissions have always been mis-configured :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762:192,config,configured,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762,1,['config'],['configured']
Modifiability,"It seems that there are a lot of soft clips that aren't bacterial reads.; What's your mean insert size? I've seen lots of aberrant soft clips when; the insert size is small and Picard doesn't catch adapter sequences with; multiple mismatches. Does the Picard percent adapter in alignment summary; metrics seem high? I've also seen lots of soft clips when the chimera rate; is high, sometimes because of bad sample extraction. What's the percent; chimeras in your alignment summary metrics? 5% is bad and I've seen up to; 15%, but that was an FFPE tumor sample. On Mon, Mar 25, 2019 at 8:48 PM jjfarrell <notifications@github.com> wrote:. > When the --dontUseSoftCliiped flag is used, the GQ=0 is much lower- N=1355; > for '0/0' calls.; >; > zcat; > A-ADC-AD004288-BL-NCR-15AD82285.hg38.realign.bqsr.dontUseSoftclipped.g.vcf.gz; > |tr '\t' '\n'|grep '0/0'|tr ':' '\t'|cut -f2,3|awk '$2 == ""0"" {print; > $0}'|cut -f1|sort -n|uniq -c; > 1355 0; > 6 0,0,0; > 7 0,0,0,0; > 602 1; > 537 2; > 520 3; > 595 4; > 441 5; > 511 6; > 583 7; > 701 8; > 403 9; > 468 10; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476431178>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdA_gZKYn3vuqNDvvDadvM9tgzQqGks5vaW5IgaJpZM4YxgEF>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476654990:198,adapt,adapter,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476654990,2,['adapt'],['adapter']
Modifiability,"It should be fairly easy to create a read transformer plugin; pretty much follow the pattern of read filter plugins: clone and modify GATKReadFilterPluginDescriptor, and add an instance of the new descriptor to the list of plugins passed in to the command line parser in (appropriate) tool base classes. And of course tests!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245968764:54,plugin,plugin,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245968764,3,['plugin'],"['plugin', 'plugins']"
Modifiability,"It turns out I was mistaken that setting the environment variables fixes the problem (stupid error on my part). It's possible the BaseTest message is unrelated. I haven't tested this branch out yet, but building from the commit immediately before the update works. I am going to try the next version to see if it helps. Edit: #3594 does not fix the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419:57,variab,variables,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419,1,['variab'],['variables']
Modifiability,It will be useful if this is added to the configuration system (#2368 and #3081).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2155#issuecomment-316078724:42,config,configuration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2155#issuecomment-316078724,1,['config'],['configuration']
Modifiability,It will be very useful to have an abstract class for the plugin arguments (as I did for the read filters plugin in #2355) to be able for downstream projects to change default values or hide arguments to the final user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3292#issuecomment-316079921:57,plugin,plugin,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3292#issuecomment-316079921,2,['plugin'],['plugin']
Modifiability,"It won't be able to run any faster than BWA mem does with a similar number of cores, since it is essentially just running bwamem. It's potentially faster as part of a spark pipeline so you can load and process data once instead of saving the data to disk and reloading it repeatedly. . The complete list of spark configuration parameters is available on the [spark docs](https://spark.apache.org/docs/3.5.0/configuration.html). Many of them are not relevant in local mode. From what I understand the local mode is going to execute as a single executor with the number of cores specified in the `local[#]` block ( or the total number of system threads if it's set to `*`) It will use the available memory that java is configured with. I'm pretty sure it's ignoring the memory and configuration parameters you've set. Those will be relevant if you configure a stand alone spark cluster (potentially one running exclusively on your local machine). . Our spark tools are not being actively developed for the most part. We've moved away from them to use single threaded tools widely sharded and managed by cromwell. The additional complexity of the spark environment made it hard to see much benefit when most of the tools are embarassingly parallel and easily shardable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8897#issuecomment-2214866066:313,config,configuration,313,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8897#issuecomment-2214866066,5,['config'],"['configuration', 'configure', 'configured']"
Modifiability,It would be good for progress meter to be more flexible.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-575773895:47,flexible,flexible,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-575773895,1,['flexible'],['flexible']
Modifiability,"It's looking like we might have to fix the issues with NIO here after all @tomwhite @jean-philippe-martin, as @lbergelson has been unable to get this working reasonably with the GCS adapter (it runs, but veeeerrryyy slowly).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271691417:182,adapt,adapter,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271691417,1,['adapt'],['adapter']
Modifiability,"It's not clear to me that we want these tools in Gatk4. We deliberately didn't port them because we felt they were unnecessary going forward. . I understand that there are some legitimate use cases that require them: ex low coverage naive variant calling from high ploidy pools which haplotype caller would do poorly on. (Also, do we know that haplotype caller doesn't do well on those sorts of things? Maybe we should consider modifications there if it doesn't?) I'm not sure that supporting that use case is worth the added complexity of maintaining and supporting these tools. Especially since we don't provide a pileup based variant caller as part of gatk4... . @vdauwera Can you comment? . @sooheelee I'm not sure I agree with you that supporting this for mutect 1 is useful. ; A) We don't want to support the use of mutect 1 anymore and would like to encourage people to switch to mutect 2 which I think we now believe is a better variant caller for both snps and indels. ; B) Mutect 1 users are already using gatk3, so they have access to these tools already. Mutect 1 also requires co-cleaning which I believe is a different but related tool to indel realignment. . For the variant review issue, we have thoughts on implementing a much better solution for variant review by creating an assembly plugin for igv.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988:1303,plugin,plugin,1303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988,2,['plugin'],['plugin']
Modifiability,"It's weird, usually java should output an error message if it runs out of memory. The exception would be when java is assigned so much memory that the SYSTEM kills it instead of java killing itself. ; You could try adding `dmesg | tail -100` to your wdl after m2 runs to see if there are any messages from the OOMkiller. . What's your total available memory on the machine and your -Xmx setting? You typically need to leave some memory room for the OS and other native sofware. (although by default our pipelines SHOULD have that configured correctly.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-939070414:530,config,configured,530,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-939070414,1,['config'],['configured']
Modifiability,Its use in `ValidateBasicSomaticShortMutations` seems limited to the integration test. Can I rewrite the test to do without `AnnotatedInterval` and call it a day?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526876913:93,rewrite,rewrite,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526876913,1,['rewrite'],['rewrite']
Modifiability,"I’ve also revisited this work for MalariaGEN, additionally including further cleanup of the canonical part of the WDLs (mostly low hanging fruit like adding structs, which help a lot for cutting down parameter cruft on Terra). For ease of iteration, this work broke things up into 3 pushes of a button: 1) data collection, 2) preclustering (done in a relatively modular way, so you can swap in whatever clustering script you like, as long as it outputs hard/soft responsibilities) +random selection of training cohorts, and 3) cohort mode + scattered case mode on all clusters. But no reason we couldn’t link some of those up. No problem running 16k samples, with 6 clusters and 300 training samples per, but also note I was only running a single genomic shard containing CNVs of interest for this use case. (I did manage to break Terra for a few days when I tried to attach collected counts to the data model in what I would’ve thought would be a relatively trivial way, but that’s another matter.). I’ve shared some version of these WDLs over Slack previously, but happy to also open up a branch here. I think some of this work may be replicated in GATK-SV and I’m also not sure what we want to make canonical. Surely most users will run only a single cluster. But from the perspective of our MalariaGEN collaborators, the more of what I put together for them being made canonical, the better, as this will ease future maintainability. But will leave it up to other current stakeholders.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5633#issuecomment-894527360:1421,maintainab,maintainability,1421,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5633#issuecomment-894527360,1,['maintainab'],['maintainability']
Modifiability,Just adding a note here that `FeatureCache` should eventually be refactored to use the simplified Interval class (when it exists) to track cache boundaries and compute overlap.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/100#issuecomment-76229630:65,refactor,refactored,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100#issuecomment-76229630,1,['refactor'],['refactored']
Modifiability,"Just an idea: it will be nice to propagate the configuration from `Main` to the tools, and obtain from it the packages/classes to include in the command line tools (this is one of the things that I implemented in #2322).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309680944:47,config,configuration,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309680944,1,['config'],['configuration']
Modifiability,"Just checked and this is not new behavior. I was afraid this would be an unintended consequence of the DRAGEN branch but that doesn't seem to be the case. Looking a little closer into the code I actually think the only difference this makes is explicitly for the contamination and nothing else. There are a few layers where we filter reads before the annotations are called (filtered by QC before active region determination, MQ/etc-filtered/un-softclipped/overlap-score-adjusted before assembly, filtered based on poor concordance with existing haplotypes, reads are realigned and re-filtered by position, and again filtered due to contamination downsampling). It seems to me that the two likelihoods arrays fed to the `prepareReadAlleleLikelihoodsForAnnotation()` have had all of the above steps applied to them EXCEPT for the contamination downsampling step applied to them looking thorough the code in the HaplotypeCaller. I guess the question is whether there is a strong reason to make the annotations with/without the contamination adjustment... I think the argument `--use-filtered-reads-for-annotations` is misleadingly labeled though the description looks correct to me since it really does only seem to make a difference for the contamination step. . There is another wrinkle to all of this. For DRAGEN-GATK we evaluated calculating the overlaps/annotations exactly how they do it in DRAGEN and decided against it. In DRAGEN they retain the original reads from the bam (i.e. no realignment/no score adjustments/etc...) and use THOSE for annotation and for genotyping. I would have to pick through their debug output to tell just which subsets get used for genotyping (for example they still use non-haplotype-matching reads for FRD and BQD but I don't remember if those are also used for calculating annotations).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7144#issuecomment-800380324:311,layers,layers,311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7144#issuecomment-800380324,1,['layers'],['layers']
Modifiability,"Just for posterity:. jhess 1:55 PM; just to clarify: what is the logic behind approximating σ_(τ/min/maj) ≈ (post90 - post10)/2? (edited) ; 1:55; what is the scale factor of 1/2 for?; 1:58; one other thing — how come σ_(min/maj) is the sum of the total CR segment’s variance (i.e. σ_τ) and the allelic segment’s variance?; 2:00; this would imply that the allelic segments are actually a sum of the random variables corresponding to the allelic and total segmentation, which I’m not sure is the case?. slee 5:32 PM; Sorry, just now seeing your questions!; 5:33; The scale factor of 1/2 is pretty arbitrary. Just trying to give an estimate of posterior width when the credible interval might be skewed. A better approach would be to refit posteriors with Gaussians/Betas as mentioned previously.; 5:35; However, I'm not actually convinced that these credible intervals are what we want to pass to the sigmas. As I also mentioned above, if sigma.tau is supposed to be a global quantity, probably the posterior median of the parameter that controls the global variance (given in the .cr.params file) might be a better thing to use. However, I never got a straight answer from anybody about whether this was a segment-level or global quantity---any idea?. slee 5:41 PM; As for using the sum of the CR variance and the MAF variance, you're right---we should be propagating error for the product of the two random variables. Not sure what I was thinking...probably just a brain fart. Not sure if it will make a difference for ABSOLUTE, but thanks for catching that!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5804#issuecomment-652411494:405,variab,variables,405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5804#issuecomment-652411494,2,['variab'],['variables']
Modifiability,Just noting for posterity that removing build strings in the conda YML seems to have improved portability to different OS environments: https://gatk.broadinstitute.org/hc/en-us/community/posts/360061666671-Broken-conda-env-create-n-gatk-f-gatkcondaenv-yml,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-628860774:94,portab,portability,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-628860774,1,['portab'],['portability']
Modifiability,"Just occured to me--Are we saying the application of a _germline workflow_ extends to the creation of a PoN consisting of germline normals for the _somatic workflow_?. If so, we should reorganize the directory structure of the CNV scripts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310873860:75,extend,extends,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310873860,1,['extend'],['extends']
Modifiability,Karthik had suggested setting the environment variable TILEDB_DISABLE_FILE_LOCKING=1 for NFS (see https://github.com/broadinstitute/gatk/issues/4753) -- maybe give that a shot?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453600476:46,variab,variable,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453600476,1,['variab'],['variable']
Modifiability,"Let us take an example. Suppose, we configure GenomicsDB with 3 column partitions - 0-10, 10-100, 100-300 and want to run GenomicsDBImport tool with an interval [0,100]. In this case, the import tool will only write contigs between 0 and 100 into first two partitions (according to the loader JSON file). Is this what you had in mind? The command line will look like:; $ gatk-launch GenomicsDBImport -L 0-100 --loaderJSONfile loader.json --streamIdJSONFile stream.json. This can definitely be done. However, the client still needs to know the column partitions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277372931:36,config,configure,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277372931,1,['config'],['configure']
Modifiability,"Let's discuss further before you get too far along. The design of the Collections code was intended to ensure that very strict file formats are adhered to within the CNV pipeline. Making it more flexible to accommodate TSVs with arbitrary column headers, relax requirements for sequence dictionaries, etc. undermines that goal. There are also two other issues to consider:. 1) It looks like @jonn-smith has also been putting considerable effort into building a TSV framework for Funcotator. Perhaps CombineSegmentBreakpoints should consider using that framework instead, if it is more appropriate. We can also discuss bringing the CNV pipeline over into that framework, but this should definitely wait until after release. The end goal is for CNV team to spend as little time as possible writing or maintaining any code related to TSV parsing. 2) @mbabadi has put together some python evaluation code for the new gCNV, which makes use of the IntervalTree python package and PyVCF to accomplish some things that are very similar to what CombineSegmentBreakpoints is doing. Perhaps we could implement a similar approach purely in Java by making use of the IntervalTree implementation in htsjdk. I think for now we should treat CombineSegmentBreakpoints as a one-off tool to be used for internal validations. After release, we should design a more generic evaluation tool. This tool could take as input multiple collections of annotated locatables, with a few rigidly defined formats allowed (e.g., VCF, CNV Collection TSVs, perhaps some TSVs from other tools, etc.), with one designated as ground truth. The regions for evaluation could also be specified via -L (since it is possible this might not completely specified by the ground-truth collection). The appropriate intersections and lookups could then be performed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352860616:195,flexible,flexible,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352860616,1,['flexible'],['flexible']
Modifiability,"Let's hear what others say, but I think I would strongly prefer to simply take over VariantEval in another repo if this was something you'd consider. I'd likely do much of what you propose anyway (certainly WRT testing); however, perhaps not the microscope we went through with the core GATK changes earlier. On plugins: I like what seems to be shaping up w/ Barclay. I carried over the Stratifier and Evaluator as plugins because it seems like it would make sense to allow tools to provide extensions (VariantEval, our tool, does). If I took this PR a step further, I would have migrated many arguments currently top-level on VariantEval into the plugins themselves (a good feature in Barclay). As an aside: I dont think VariantAnnotator is migrated yet, but we have many GATK3 plugins related to annotation, and hope that tool retains Annotator plugins when it get migrated. My impressions of barclay are probably a little out of date. I agree the main argument parsing framework is pretty robust. Specifically on plugins, it seems a little less so, or at least there are not many tools I visibly see exercising that part of the code. For example, there really should be a default implmentation or base class between Barclay's plugins and ReadFilter plugins. I'm guessing if more tools in GATK4 were using plugins this would have happened. I created something like this for VariantEval, and without a ton of work that could probably get generalized; however, doing so would throw a lot higher bar on me and as noted above I'm trying to take on less, not more at the moment. If we do take over VariantEval, I'm certainly happy to try to contribute code and experiences to improve the core, through more targeted PRs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407202501:312,plugin,plugins,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407202501,18,['plugin'],['plugins']
Modifiability,"Looking at MetricFile and with it heavy use of Reflexion looks a bit nasty, if there is a better alternative the better. I guess a refactoring of MetricFile would use annotations to allow one to customize output variable name... force one to have those not-so-good looking CAPITAL_FIELD_NAMES for the sake of it is harsh. Don't understand why One has to commit to ; particular type for all histograms either. . Anyway, only if the use of MetricFile is an overkill I would ask you to do your custom one (i.e if it can be done in a few lines of code).... probably not the case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-336521031:131,refactor,refactoring,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-336521031,2,"['refactor', 'variab']","['refactoring', 'variable']"
Modifiability,"Looking back into this PR... at some point you are using 'N' to pad what seem to be gaps on the read sequence. Although the end result would be the same perhaps is better to be more explicit and just use '-' instead. In that case my suggestion of using `Nucleotide.intersect` wouldn't cover for the '-' character so you need a explicity ""&&"" or ""II"". When you compare the cost of each different alignment the gap-open and gap-ext are ignored (you only look at base call mismatches). I wonder whether it would be more correct to actually take them in consideration... so imagine that there is no gaps in the original alignment what-soever and that adding a 1bp gap decreases the number of mis-matches by just 1 which is typically Q30 increase in the Lk but the gap itself default penalty is Q45 so can one say that that read wouldn't still support the reference over a 1-bp gap alternative? . Example with a 2-bp gap making the trick:; ```; Ref: ....GCATGTGATATATATATATATATATATATACACACAC....; Read: ....GCATGTG--ATATATATATATATATATATAC <end-of-the-read>; ```. That could happen in STRs with impurities... but if the original alignment did not added itself the gap to reduce the number of mismatches is because precisely due to the added cost of the gap-open and necessary extends that we would be ignoring here. This is all hypothetical until some one quantifies how often this might occur ... so I'm happy to keep ignoring the gaps for now until we get a report on a real-live dataset that would benefit of such a change or some enthusiastic dsde-methods member investigates this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5172#issuecomment-420743269:1270,extend,extends,1270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5172#issuecomment-420743269,1,['extend'],['extends']
Modifiability,"Looks great!. One quick note: I don't get the idea behind `Poisson` -- shouldn't we simply use negative binomials w/ modeled `mu_sj` and `alpha_sj`, evaluated at observed counts (`tt.arange(min_count, max_count + 1)`), and weighted with the number bins for each count (`_hist_sjm`)? i.e. if one observes an empirical distribution `P_obs(x)` rather than `x` draws, then the appropriate max likelihood objective function is `\sum_x P_obs(x) log P_model(x | \theta)`. Perhaps this is exactly what you've done and I don't get it. Another quick note: what I had in mind was _either_ modeling `mu_sj` at quantized ploidy states, _or_ let the ploidy state be unrestricted w/ a penalty via. a Bernoulli process (possibly w/ different per-contig penalties to account for e.g. higher rate of X/Y loss). We have enough samples in the cohort to select the quantized model (and those samples pin down the per-contig biases `b_j`). The samples that do not conform to quantized ploidy states can then choose whatever (variable) ploidy state they wish by paying a (hefty) price. We would also need to mask contigs that have variable ploidy calls from gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536:1003,variab,variable,1003,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536,4,['variab'],['variable']
Modifiability,"Lots of refactoring was done for the Segmenter classes in #6499. At least for segmentation, all use cases (CR-only, AF-only, CR+AF, single-sample, multi-sample) now go through `MultisampleMultidimensionalKernelSegmenter`. `AlleleFractionKernelSegmenter` and `CopyRatioKernelSegmenter` classes still exist, but both simply call the `MultisampleMultidimensionalKernelSegmenter` class; this was done so preexisting tests for those two classes could be reused. I'm fine with calling this done. We can always open a new issue in the unlikely event we refactor the modelling code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908:8,refactor,refactoring,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908,4,['refactor'],"['refactor', 'refactoring']"
Modifiability,"MTOOLS : true; 14:39:24.083 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:39:24.083 INFO DetermineGermlineContigPloidy - Deflater: IntelDeflater; 14:39:24.083 INFO DetermineGermlineContigPloidy - Inflater: IntelInflater; 14:39:24.083 INFO DetermineGermlineContigPloidy - GCS max retries/reopens: 20; 14:39:24.083 INFO DetermineGermlineContigPloidy - Requester pays: disabled; 14:39:24.083 INFO DetermineGermlineContigPloidy - Initializing engine; 14:39:26.111 INFO DetermineGermlineContigPloidy - Shutting down engine; [May 26, 2019 2:39:26 PM UTC] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=1511522304; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException:; python exited with 1; Command Line: python -c import gcnvkernel. Stdout:; Stderr: Traceback (most recent call last):; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configdefaults.py"", line 1738, in filter_compiledir; os.makedirs(path, 0o770) # read-write-execute for user and group; File ""/opt/miniconda/envs/gatk/lib/python3.6/os.py"", line 210, in makedirs; makedirs(head, mode, exist_ok); File ""/opt/miniconda/envs/gatk/lib/python3.6/os.py"", line 220, in makedirs; mkdir(name, mode); PermissionError: [Errno 13] Permission denied: '/root/.theano'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/pymc3/__init__.py"", line 5, in <module>; from .distributions import *; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/pymc3/distributions/__init__.py"", line 1, in <module>; from . import timeseries; File ""/opt/miniconda/envs/gatk/lib/python3.6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081:2849,config,configdefaults,2849,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081,1,['config'],['configdefaults']
Modifiability,"Mappings = new AssemblyContigWithFineTunedAlignments(contig, tigWithInsMappings.insertionMappings);; > +; > + this.basicInfo = new BasicInfo(contig);; > +; > + annotate(refSequenceDictionary);; > + }; > +; > + private static List<AlignmentInterval> deOverlapAlignments(final List<AlignmentInterval> originalAlignments,; > + final SAMSequenceDictionary refSequenceDictionary) {; > + final List<AlignmentInterval> result = new ArrayList<>(originalAlignments.size());; > + final Iterator<AlignmentInterval> iterator = originalAlignments.iterator();; > + AlignmentInterval one = iterator.next();; > + while (iterator.hasNext()) {; > + final AlignmentInterval two = iterator.next();; > + // TODO: 11/5/17 an edge case is possible where the best configuration contains two alignments,; > + // one of which contains a large gap, and since the gap split happens after the configuration scoring,; > I agree it is backwards. But...; > ; > The reason was that the (naive) alignment configuration scoring module rightnow uses MQ and AS (aligner score) for picking the ""best"" configuration (i.e. sub-list of the alignments given by aligner), which would be technically wrong if we were to split the gap and to simply grab the originating alignment's values.; > ; > This is especially true for AS, whose recomputing takes more time, and code, and forces us to know how AS are computed in the aligner so that there's no bias in computing the scores of naive alignments vs gap-split alignments (may not matter in practice, but still takes more code to compute).; > ; > Lots of the code in the discovery stage was devoted actually to alignment related acrobatics and edge cases so that the breakpoints we could resolve are as accurate as possible.; > I've kept in mind your wisdom that different aligners may be experimented with, but it seems unlikely in the near future (their own quirkiness, lack of API for JNI, etc); it seems more and more likely to me that eventually it's inevitable to have a custom alignment m",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009:1740,config,configuration,1740,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009,4,['config'],['configuration']
Modifiability,"Maybe I misunderstand the underlying model, but if some Pedigree annotations only need to know which samples are founders (ExcessHet ?) , and some need to know the full relationships (PossibleDeNovo), then I'm suggesting we change the class hierarchy to reflect that:. PedigreeAnnotation; |--TrioAnnotation; |----PossibleDeNovo; |--ExcessHet (assuming ExcessHet only needs founders...); ... Then the plugin could deterministically validate whether the user has provided sufficient args for the set of requested annotations; and if so, propagate them accordingly. A TrioAnnotation could only be populated (from the command line at least) from a file, whereas the others could be populated from either a file or just a set of IDs. I think it would simplify the annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550:400,plugin,plugin,400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550,2,['plugin'],['plugin']
Modifiability,Minor enhancements to match VariantRecalibrator tweaks,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2780#issuecomment-309635824:6,enhance,enhancements,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2780#issuecomment-309635824,1,['enhance'],['enhancements']
Modifiability,"Modifying what I wrote earlier, got confused with another issue. I am not familiar with Lustre and Lustre configuration. Did the excessive file locking from Lustre(FUTEX_WAIT_PRIVATE?) go away with `--genomicsdb-shared-posixfs-optimizations`? . Is there anyway to configure Lustre buffer sizes for writing? If not, can you try setting environment variable TILEDB_UPLOAD_BUFFER_SIZE to something like 5242880(5M) and try `GenomicsDBImport`? Does it help with performance? Is the amount of file locking lower than before?. If the performance is still not acceptable... What version of gatk are you using? Can you use the latest gatk and try using the `--bypass-feature-reader` option with `GenomicsDBImport`? Does this help with performance?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7646#issuecomment-1039746554:106,config,configuration,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7646#issuecomment-1039746554,3,"['config', 'variab']","['configuration', 'configure', 'variable']"
Modifiability,"Most spark tools use the one in GATKSparkTool, but some have some special requirements that make it not work for them. They have to specify different sequence dictionaries or something like that in a way that isn't exposed. Maybe something could be refactored there, but they needed manually adjusting to match the new behavior because of their special handling of the writing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6458#issuecomment-594167389:249,refactor,refactored,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6458#issuecomment-594167389,1,['refactor'],['refactored']
Modifiability,Most things were addressed here. A bunch of follow on tickets created to address more complicated refactorings that we don't have time to hit now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3803#issuecomment-368648535:98,refactor,refactorings,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3803#issuecomment-368648535,1,['refactor'],['refactorings']
Modifiability,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:1118,config,configuration,1118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716,1,['config'],['configuration']
Modifiability,"My $0.02:. 1. In general it's ok with me to not provide a template for WDLs in the GATK repo as long as you guys help us (ie @bshifaw) produce appropriate templates to include in the gatk-workflows repo and in FireCloud. . 2. Re: Picard tools, going forward they should be invoked from the GATK jar by default. Among other benefits, that will reduce support entropy wrt possible combination of versions of tools people might be using. 3. I like the idea of focusing on the auto-generated wrappers for improvements like the string variable for adding arbitrary extra args.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159:530,variab,variable,530,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159,1,['variab'],['variable']
Modifiability,"My 2 cents: actually the argset strategy would be nice also for plugins. For example, in ReadFilters it might allow to specify ""recommended"" filters but not necessary; and in the annotations to convert the groups to a argument set. +1 to the argset for many use-cases and not only this one!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385879758:64,plugin,plugins,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385879758,1,['plugin'],['plugins']
Modifiability,"My recollection is that this is a use case we never put any priority on so there's no test in the GATK suite for access to private files. There should be, of course. The feature is there and (at least locally) it worked when I tried it. NIO does not use the API_KEY, it uses default credentials. Those are environment variables that are set by the `gcloud` command or pre-set for you in the case of virtual machines on Google. There are two cases: local execution and Spark. . I just tested local execution and it worked fine for me:. ```; $ ./gatk-launch PrintReads -L Broad.human.exome.b37.small.interval_list -I gs://jpmartin-private/bench/WGS-G94982-NA12878.bam -O t_gcs.bam; ```. this command worked even though (unless I'm mistaken) neither the bucket nor the file are public. One challenge however is that the way to set default credentials has changed recently. Calling `gcloud auth login` used to be enough but now we have to call (IIRC) `gcloud auth application-default login`. For Spark, the default credentials are set as whoever owns the dataproc environment that's used to run the show. So it should be set so it has access to the buckets necessary. NIO has mechanisms for accessing buckets that belong to someone other than who is running the Spark job, but they are not hooked into GATK yet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277832658:318,variab,variables,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277832658,1,['variab'],['variables']
Modifiability,"My worry about camel case is that it trips up people a lot, especially those whose native language doesn't have a concept of case (like Chinese). . Maybe long arguments with lots of dashes need to be refactored to have fewer... can you give some examples?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-323747625:200,refactor,refactored,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-323747625,1,['refactor'],['refactored']
Modifiability,Namespaced arguments in barclay are something we've talked about before that could help with this. So multiple argument collections / plugins objects could declare the same argument and it would be de-ambiguated by the full name of the plugin/collection. Something like `--ReadNameFilter.invert --MappingQualityFilter.invert`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6005#issuecomment-502173995:134,plugin,plugins,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6005#issuecomment-502173995,2,['plugin'],"['plugin', 'plugins']"
Modifiability,"No problems. The walkers have no built in parallelism so there's no problem with using state. It makes it harder to adapt to spark, but that's probably not a big deal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4447#issuecomment-368091726:116,adapt,adapt,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4447#issuecomment-368091726,1,['adapt'],['adapt']
Modifiability,No validation here. I was satisfied with the validation from the Palantir report and using this as a robustness test to show that GATK4 HC isn't going to fall over. I have a matched list of GVCFs here: /humgen/gsa-hpprojects/dev/gauthier/scratch/newQualHC/check.list @skwalker could you adapt your analysis to run with this list? I'll need to give you a different jar for the GenotypeGVCFs step on my GVCFs since the annotation format is outdated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380822981:287,adapt,adapt,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380822981,1,['adapt'],['adapt']
Modifiability,"Not a bad idea, will look into that tomorrow. Note that you are using Tensorflow 1.4 or 1.5 and that from v1.6 even the; non-Intel optimized build supports only AVX capable machines. On Thu 11 Oct 2018, 21:07 droazen, <notifications@github.com> wrote:. > *@droazen* commented on this pull request.; > ------------------------------; >; > In; > src/main/java/org/broadinstitute/hellbender/tools/walkers/vqsr/CNNScoreVariants.java; > <https://github.com/broadinstitute/gatk/pull/5291#discussion_r224587026>:; >; > > @@ -198,6 +200,13 @@; > return new String[]{""No default architecture for tensor type:"" + tensorType.name()};; > }; > }; > +; > + IntelGKLUtils utils = new IntelGKLUtils();; > + if (utils.isAvxSupported() == false); > + {; > + return new String[]{CNNScoreVariants.AVXREQUIRED_ERROR};; >; > Maybe the answer is for the conda environments to set an extra environment; > variable that would allow GATK to detect which conda environment it's in.; > Then you could have a check in CNNScoreVariants that aborts the tool only; > if AVX is not present AND you're running in the Intel conda environment,; > and point the user to the non-Intel conda environment in the error message.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5291#discussion_r224587026>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG6lr8HM6ItLWqfSaTKeVY4yCp07il29ks5uj6TugaJpZM4XNHdi>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429109651:881,variab,variable,881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429109651,1,['variab'],['variable']
Modifiability,"Not sure if this is outside the scope of a simple port, but I think it would be great if the fitting of a `GaussianMixtureModel` was made a little bit more generic and extracted. Right now the method `maximizeGaussian` takes in `List<VariantDatum>`, but it should be trivial to refactor it to take in a `double[]` or `List<Double>`. Fitting a GMM could be more generally useful for other methods, after all. It might even be useful to extract the k-means clustering code used to initialize the model, if this is retained in the port. Perhaps also outside the scope, but it'd also be nice if variable names were changed to match the notation in Bishop Ch. 10 (on which the variational-Bayes algorithm is based). I think this would make the code much easier to parse from a mathematical standpoint.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236003146:278,refactor,refactor,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236003146,4,"['refactor', 'variab']","['refactor', 'variable']"
Modifiability,"Not sure if this is related, but @chandrans and I had some trouble with the dataproc launcher yesterday (didn't recognize some yarn argument). Changing the ""image"" setting in the cluster config solved it, afaiu.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2230#issuecomment-278729124:187,config,config,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2230#issuecomment-278729124,1,['config'],['config']
Modifiability,"Note separate method configuration, but uses the same WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362811803:21,config,configuration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362811803,1,['config'],['configuration']
Modifiability,"Note that before this is merged, we'll need to do a datasource release in which the following property is added to the gencode config files:. ```; # Required field for GENCODE files.; # NCBI build version:; ncbi_build_version = X; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5522#issuecomment-447141409:127,config,config,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5522#issuecomment-447141409,1,['config'],['config']
Modifiability,"Note that there is an AnnotateIntervals tool in the CNV pipeline (awaiting review in sl_denoising) that will output a TSV with column headers CONTIG, START, END, and GC_CONTENT. It takes -L, which can do the padding for you. If this doesn't exactly fit the bill for you, then it's probably best if you roll your own implementation rather than modify or refactor that code---should be easy enough.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3859#issuecomment-345807469:353,refactor,refactor,353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3859#issuecomment-345807469,1,['refactor'],['refactor']
Modifiability,"Note to self: the gcloud API changes a bit with the new release, apply the changes in [jp_gcloud_17_snapshot](https://github.com/broadinstitute/gatk/tree/jp_gcloud_17_snapshot) to adapt.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2822#issuecomment-306241927:180,adapt,adapt,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2822#issuecomment-306241927,1,['adapt'],['adapt']
Modifiability,"Now that there's been some refactoring of this code, it might be relatively straightforward to rewire the GVCFBlockCombiner to take in likelihood data from the pileup without creating a VariantContext, then pass the combined data to a VC and then to the writer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5618#issuecomment-590953474:27,refactor,refactoring,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5618#issuecomment-590953474,1,['refactor'],['refactoring']
Modifiability,"Now, it seems like calling `contaminationDownsampling` right after `retainEvidence` could cause problems if both methods remove reads. However, one might correctly point out that although the cache invalidation I mentioned is not handled systematically, the method `removeEvidenceByIndex` _does_ have some code to update the evidence by sample and the evidence index map. It's possible that this code is totally fine and that this lead is a dead end. However, the code looks like it could be simpler and it's tough to parse. For example, try to track the `to` variable, which determines the determination of the outer `for` loop:. ```; for (int etrIndex = 1, to = nextIndexToRemove, from = to + 1; to < newEvidenceCount; etrIndex++, from++) {; if (etrIndex < evidencesToRemove.length) {; nextIndexToRemove = evidencesToRemove[etrIndex];; evidenceIndex.remove(evidences.get(nextIndexToRemove));; } else {; nextIndexToRemove = oldEvidenceCount;; }; for (; from < nextIndexToRemove; from++) {; final EVIDENCE evidence = evidences.get(from);; evidences.set(to, evidence);; evidenceIndex.put(evidence, to++);; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625030697:560,variab,variable,560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625030697,2,['variab'],['variable']
Modifiability,"OK so just following along; the problem appears related to the Google Cloud Storage Connector and its configuration. When running on Cloud we need to ask for the `https://www.googleapis.com/auth/devstorage.read_write` scope, as described in [the install docs](https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/gcs/INSTALL.md). But you're right that `https://www.googleapis.com/auth/cloud-platform` should imply that so it should work... The command line argument is `--scopes` (plural) and not `--scope` but that's probably not the issue, the tool would have complained if you actually typed `scope` in there. . Perhaps the code is trying to do the non-cloud setup and that's what's making it not work on cloud?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616:102,config,configuration,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616,1,['config'],['configuration']
Modifiability,"OK, looks like you can get around the compiler lock issues by pointing each invocation of GermlineCNVCaller to a different compilation directory. For example, invoke `gatk` by. `THEANORC=PATH/TO/THEANORC_# gatk GermlineCNVCaller ...`. This uses the `THEANORC` environment variable to set the `.theanorc` configuration file to `PATH/TO/THEANORC_#` for this instance of GATK (where you should fill in `#` appropriately). Each `PATH/TO/THEANORC_#` should be a file containing the following:. ````; [global]; base_compiledir = PATH/TO/COMPILEDIR_#; ````. Where again, `#` is filled in appropriately. The goal is to point each GermlineCNVCaller instance to a different compilation directory. @xysj1989 can you let me know if this works for you?. This is a bit of a hack. We could probably avoid this by changing the GATK code to use a specified or temporary directory for the theano directory without too much effort. However, there is an upside to using a non-temporary directory to avoid recompilation of the model upon subsequent runs. In this case, we'd just want to let the user be able to specify the theano directory (rather than dump things in `~/.theano` unexpectedly). We should think about whether this should be opt-in, i.e., should we preserve the original behavior of using `~/.theano` by default?. @mwalker174 opinions? @droazen or engine team, thoughts on what the policy should be for python/R scripts doing this sort of thing? Is it generally true that the GATK leaves no trace, other than producing the expected output?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548430809:272,variab,variable,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548430809,2,"['config', 'variab']","['configuration', 'variable']"
Modifiability,"OK, thanks. I tried to keep edits here limited and protected. I'm happy to describe more about what I'm trying to do in VariantQC if that's helpful. Also - i have not forgotten about trying to refactor VariantQC to better handle arguments (i.e. dont pass the walker to the VariantEvaluator, and to separate a VariantEvalEngine class, somewhat like VariantAnnotationEngine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5998#issuecomment-502259266:193,refactor,refactor,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5998#issuecomment-502259266,1,['refactor'],['refactor']
Modifiability,"OK. Another thing: since in GATK4 it inherits from LocusWalkerByInterval, -L is now required. the usage examples still say -L is optional. . Tangentially is there a shortcut way to pass ""all intervals in the genome"" to GATK in the -L argument? Is there some trick using the DICT file or something like this? Certainly it's not that hard to convert a .dict file to an interval list, but not automatic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6617#issuecomment-634784068:37,inherit,inherits,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6617#issuecomment-634784068,1,['inherit'],['inherits']
Modifiability,"OK. As a reference, how does GATK deal with max-alternate-alleles for normal human variant calling? Presumably really high alternate alleles would primarily happen in repetitive/index prone-regions? FWIW, When we execute GenotypeGVCFs, we run as ~1000 jobs where each takes an even chunk of the genome, by base pairs. . Yes, I did see the bypass-feature-reader option, but we have jobs in-flight and I'm reluctant to change too many things as once. We will try this when possible though. As far as number of batches imported: I would need to check, but I believe it's only ~5 batches with perhaps 50-100 samples/ea. So I guess it's not that many new batches in the scheme of things, but anecdotally we have noticed that with the last couple rounds of import we needed to reduce batch size to make it work (i.e. not get hung). It is conceivable there is some other factor that is causing that variable performance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7542#issuecomment-964442581:892,variab,variable,892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7542#issuecomment-964442581,1,['variab'],['variable']
Modifiability,"OK. I found a potential solution. For this solution, we do not need to add or remove any dependencies. The only change is to the `log4j.properties` file (which configures log4j 1.x) to match the config specified in `log4j2.xml` (which configures log4j2). Now, GKL will use log4j 1.x to log, but the format will match the rest of GATK, which uses log4j2. This means that we have only one GKL for both GATK 3 and 4, at the expense of having to keep to config files, `log4j.properties` and `log4j2.xml`, in sync (which they probably should have been anyway, thought they weren't).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413:160,config,configures,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413,4,['config'],"['config', 'configures']"
Modifiability,"O_BUFFER_SIZE : 131072; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.REFERENCE_FASTA : null; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5466,Config,ConfigFactory,5466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,Obviated by ModelSegments rewrite.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3181#issuecomment-356697320:26,rewrite,rewrite,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3181#issuecomment-356697320,1,['rewrite'],['rewrite']
Modifiability,"OfBins) + "" should be >= 0."");; >; > @asmirnov <https://github.com/asmirnov> and @samuelklee; > <https://github.com/samuelklee> are both correct, but for the future in; > cases where you *would* want an IllegalArgumentException you should use; > Utils.validateArg to render this sort of thing a one-liner.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646132>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = true,; > + minValue = 0; > + ); > + private int padding = 0;; >; > . . . and if this padding is different from the inherited padding then; > this demands a comment to avoid confusion.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646146>:; >; > > +; > + // check if the bin widths are set appropriately; > + if(widthOfBins <= 0) {; > + throw new IllegalArgumentException(""Width of bins "" + Integer.toString(widthOfBins) + "" should be >= 0."");; > + }; > +; > + // get the sequence dictionary; > + final SAMSequenceDictionary sequenceDictionary = getBestAvailableSequenceDictionary();; > + final List<SimpleInterval> intervals = hasIntervals() ? intervalArgumentCollection.getIntervals(sequenceDictionary); > + : IntervalUtils.getAllIntervalsForReference(sequenceDictionary);; > +; > + // create an IntervalList by copying all elements of 'intervals' into it; > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Inte",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:4993,inherit,inherited,4993,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211,1,['inherit'],['inherited']
Modifiability,"Oh, I hadn't noticed that there was a compilation warning causing the test to fail. ```; /gatk/src/test/java/org/broadinstitute/hellbender/MainTest.java:55: warning: [serial] serializable class ExitNotAllowedExcepion has no definition of serialVersionUID; private static final class ExitNotAllowedExcepion extends SecurityException {; ^; error: warnings found and -Werror specified; ```. Please fix that also :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772:306,extend,extends,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772,1,['extend'],['extends']
Modifiability,"Oh, also note that there might be some variable-name references in the Javadocs for the VQSR-lite tools that are not rendered properly in online docs; see https://github.com/broadinstitute/gatk/issues/8146 for more context. However, if you're just looking at the Javadocs via IntelliJ, everything should look fine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8131#issuecomment-1414063049:39,variab,variable-name,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8131#issuecomment-1414063049,1,['variab'],['variable-name']
Modifiability,"Oh, interesting. That's a real problem. We inherited that code from picard and I don't think anyone ever paid attention to it. I'm assuming it's in there because someone encountered a tmp dir they couldn't read/write to but could set permissions on at some point, which seems weird. . At most we should be setting it for owner only I think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371635375:43,inherit,inherited,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371635375,1,['inherit'],['inherited']
Modifiability,Ohh. This looks like what we have really wanted when we refactor the test suite to test spark and other tools using the same methods. This should bring restful nights to us all. Unfortunately it looks like most of the docker tests have failed with errors along the lines of this: ; ```; org.gradle.api.internal.tasks.testing.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(Exec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:56,refactor,refactor,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858,1,['refactor'],['refactor']
Modifiability,"On the first question, we definitely appreciate how much work this will take. Often, porting the code is the easy part; developing new tests and test data can be a huge effort. I can try to find out if it would be possible for you to take the tool over - I know this kind of thing has come up before for other tools, but I'd have to ask around to find that out. @vdauwera do you have input on this ?. As for the plugins, currently in your branch `VariantStratification` and `VariantEvaluator` are modeled as Barclay command line plugin descriptors, and I was questioning whether thats necessary. Being a plugin is not necessarily required - `ReadFilter` and `Annotation` are both plugins, but they didn't have to be, and it takes quite a bit of work (again, mostly test development) to get a plugin right. Also, I'd consider the Barclay plugin framework to be pretty developed at this point, so I'd be curious to learn more about what issues you see. And yes, definitely don't check any of the large GATK3 test files into the repo, even temporarily. Take a look at [General guidelines for GATK4 developers](https://github.com/broadinstitute/gatk#dev_guidelines) if you haven't already. As you pointed out, new GATK4 tests that use smaller files would have to be developed. We'd want those to be included, and passing tests on the CI server, before we started reviewing the branch, so we know we're reviewing code that works and is covered by tests as much as possible. The second commit in my list above would have only your GATK3 java test files, etc (but not the big files, which you appear to have locally). The third commit would have your ported tool code, as well as the new test code, with the new tests enabled, as well as the smaller input files and expected results files. At the end we'd remove commit #2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407185633:412,plugin,plugins,412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407185633,12,['plugin'],"['plugin', 'plugins']"
Modifiability,"One concern I have is the maintainability of the test (having been burned by this in other places myself). When we add a new output field, etc we need a very easy way to update/generate these results. At the very least some instructions would be helpful (and imagine someone to follow those as part of a PR)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7192#issuecomment-821234533:26,maintainab,maintainability,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7192#issuecomment-821234533,1,['maintainab'],['maintainability']
Modifiability,"One major goal is to replace all the system properties in `gatk-launch`. Config options would be a combination of:; -Java system properties (like in gatk-launch); -Other engine-wide settings (like codec package names in `FeatureManager`, or NIO retries)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2368#issuecomment-307467920:73,Config,Config,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2368#issuecomment-307467920,1,['Config'],['Config']
Modifiability,"One more thing: I'm also wondering if it would be possible to get a quick, preliminary evaluation of such a process without actually doing the work of adding it into the training tool. It's probably possible to do a slightly more ""manual"" validation split (say, using one or a few chromosomes), run the score tool on that validation set, use some external code to calculate the desired threshold from the resulting scores, and then use that threshold going forward. Actually, now that I've written it out, that sounds a lot cleaner and more flexible! Let me try to hack together the corresponding workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065543611:541,flexible,flexible,541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065543611,1,['flexible'],['flexible']
Modifiability,"One observation that illustrates the need for care when optimizing metrics: for a few of the F1 optimizations, the haplotype-to-reference match-value parameter gets driven to its minimal value (1). Not 100% sure, but I'm guessing this might effectively boost precision by somehow cutting down on the complexity of proposed haplotypes---it depends on what the exact behavior of our SW algorithm is for negative scores. @davidbenjamin any thoughts on this behavior?. Something I don't quite understand yet is if we can impose some effective constraints on the parameters or otherwise reduce the number of independent dimensions. For example, it seems reasonable to me to fix the gap-extend penalties to -1 and let all other parameters be defined w.r.t. them. But perhaps we can also fix the match values similarly?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193:681,extend,extend,681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193,1,['extend'],['extend']
Modifiability,"One part of this ticket is done: https://github.com/broadinstitute/gatk/pull/4964 added accessors that allow direct descendants of `GATKTool` to directly access engine datasources, while still forbidding direct access for tools that extend a Walker base class (except for Walker types living in the engine package, which still have access).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878:233,extend,extend,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878,1,['extend'],['extend']
Modifiability,"One proposal for moving forward would be to have a default properties file with a known name/location that is included in the gatk jar (say, ""gatk.default.properties""), which is always loaded and populates the initial configuration, and then use the classloader getResources method to also load all resources with some other known name (say, ""gatk.properties""). That way any properties files on the classpath with the known name would be automatically discovered and loaded. The apache commons API allows looks like it has good support for handling this using a [composite](http://commons.apache.org/proper/commons-configuration/userguide/howto_compositeconfiguration.html#Composite_Configuration_Details) configuration. We would have to define some rules around override semantics, but it looks like the api provides a lot of control over that as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2322#issuecomment-274654954:218,config,configuration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2322#issuecomment-274654954,3,['config'],['configuration']
Modifiability,"One thing to try is to configure cromwell to retain the log directory via a workflow option when we run the tests. Then at the end of the build we can copy them somewhere, either always, or via the travis after_failure entry in the build matrix. Then we'd be able to see exactly what failed in the travis environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4130#issuecomment-357059677:23,config,configure,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4130#issuecomment-357059677,1,['config'],['configure']
Modifiability,"One variable that we need to control for is OpenJDK vs. Oracle JDK. Apparently these errors happened with OpenJDK, which is known to be flakier in the networking department than Oracle JDK. We should test with Oracle's JDK and see if the errors persist.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300313874:4,variab,variable,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300313874,1,['variab'],['variable']
Modifiability,"Oof, that's a nasty problem. We can definitely do something about it. It feels more like a Microsoft bug than a GATK one though. It seems crazy that each layer pull has to be a separate web request and there's no batch api for it? Multi layer docker builds are pretty standard from what I understand. . It sounds like your suggestions are talking about 2 slightly different issues to me. 1. Too many layers:. We typically have squashed the GATK docker images, but we recently switched to building our release images with google cloud build. Since squash is *STILL* an experimental feature in docker we've had trouble getting it to work there. Since the size reduction was pretty minimal from squashing we figured it would be ok to not prioritize it. It's definitely possible for us to consolidate various layers in the build. Or manually squash the images. We can take a look for our next release. Wide workflows on azure are something we need to support. 2. Docker size reduction:; I've spend a lot of time looking at this in the past. Our docker image is huge, but it's mostly due to the massive size of our python and R dependencies. I've done a bunch of work reducing temporary files in independent layers and using multiple stages to reduce the size. There's not much low hanging fruit left there. Similarly, moving to alpine is tricky an has limited benefit. GATK packages a number of C libraries which do not work out of the box on alpine due to the different C runtime. (At least that was the case the last time I investigated it a few years ago. ) I suspect there's a way to port things so they work on it, but it's not something we can do now. It also wouldn't be much of a help, the base image is completely dwarfed by piles of python and R dependencies which are very difficult to safely trim. Anyway, that's the state of things. We've considered a java only image for a while which would be much smaller than the current one. (although still fat by most docker standards...). We've never ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427:400,layers,layers,400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427,2,['layers'],['layers']
Modifiability,"Originally, we just had the normal be optional. You also had automated tests in the WDL Travis. . In FC, for tumor only, you would probably want a separate method configuration that ran on sample entity type. I'm open to other suggestions, but I can't think of another way. This could in theory be used for germline calling, too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362811723:163,config,configuration,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362811723,1,['config'],['configuration']
Modifiability,"Overall the refactoring looks good and makes sense… but I'm not seeing how this fixes the problem of eating exceptions we saw during a recent run. Can you explain what was happening before, and how the new code addresses it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7480#issuecomment-927995357:12,refactor,refactoring,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7480#issuecomment-927995357,1,['refactor'],['refactoring']
Modifiability,Override mechanisms (in order of priority). -Individual config options specified on the command line manually / Or explicit config file ; -Override config file packaged into a downstream project; -Default GATK config file,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2368#issuecomment-307467520:56,config,config,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2368#issuecomment-307467520,4,['config'],['config']
Modifiability,"PPY_COMPRESSOR : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.REFERENCE_FASTA : null; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5249,Config,ConfigFactory,5249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"Passing in the properties file did work (with the --gatk-config-file option). However, of the four tools I tested (MarkDuplicates, BaseRecalibrator, ApplyBQSR, and HaplotypeCaller) all of the tools accepted the --gatk-config-file option except for MarkDuplicates, which complains that it is not a recognized option. Perhaps this should be turned into a separate issue?. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-368036324:57,config,config-file,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-368036324,2,['config'],['config-file']
Modifiability,"Per discussion with @kgururaj, this will probably take the form of a flag that suppresses materializing the genotype data. Also see the protobuf-based enhancements described [here](https://github.com/broadinstitute/gatk/issues/3689).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-336965003:151,enhance,enhancements,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-336965003,1,['enhance'],['enhancements']
Modifiability,"Please need help : . I ran the script for VQSR . gatk-4.2.0.0/gatk VariantRecalibrator\; -V variants_sitesonly.vcf.gz\; 	-trust-all-polymorphic\; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0\; -an FS -an ReadPosRankSum -an MQRankSum -an QD -an SOR -an DP\ ; -mode INDEL\; -max-gaussians 4\; -resource:mills,known=false,training=true,truth=true,prior=12:Mills_and_1000G_gold_standard.indels.hg38.vcf.gz\; -resource:axiomPoly,known=false,training=true,truth=false,prior=Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz\; -resource:dbsnp,known=true,training=false,truth=false,prior=2:Homo_sapiens_assembly38.dbsnp138.vcf\; -O cohort_indels.recal\; --tranches-file cohort_indels.tranches. ERROR - >. A USER ERROR has occurred: Argument resource was missing: Argument 'resource' is required. Any help would be really great !. thank you; Smeeta",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2199#issuecomment-885465593:132,polymorphi,polymorphic,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2199#issuecomment-885465593,1,['polymorphi'],['polymorphic']
Modifiability,Please use the template in the WDL GATK repo doc that was shared. Or we can modify that template. I'd like the document to match what is generated automatically. The template in that document includes optimizations and is quite portable.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2480#issuecomment-358440295:228,portab,portable,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2480#issuecomment-358440295,1,['portab'],['portable']
Modifiability,Probably git. See `core.autocrlf` at https://git-scm.com/book/id/v2/Customizing-Git-Git-Configuration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431474812:88,Config,Configuration,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431474812,1,['Config'],['Configuration']
Modifiability,"RROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.mis",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5850,variab,variable,5850,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['variab'],['variable']
Modifiability,"Really we need some tests for gs:// files in ReadsSparkSinkUnitTest - e.g. a GCS version of testWritingToFileURL. This needs knowledge of how to configure the Hadoop GCS connector (outside dataproc), which I lack. Perhaps someone else knows how to do this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-270615942:145,config,configure,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-270615942,1,['config'],['configure']
Modifiability,Refactoring won't happen,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6877#issuecomment-1377803387:0,Refactor,Refactoring,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6877#issuecomment-1377803387,1,['Refactor'],['Refactoring']
Modifiability,"Results are in:. Using the branch for PR #4971 with the value `ALIGNMENT_LOW_READ_UNIQUENESS_THRESHOLD` set to 10 and 19, while keeping the gap split children together (that is, method ; `private static GoodAndBadMappings splitGaps(final GoodAndBadMappings configuration, final boolean keepSplitChildrenTogether)` is called with `false` for its second parameter). Here are the comparisons:; ```; simple variants unique TP unique FP; size-10 filter: 10756 24 101; size-19 filter: 10755 1 0; ```. So I think your suggestion is a better trade off!. What I'll do is make that parameter an (advanced) CLI argument in PR #4971 , and experiment more to settle on a good default value.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403890890:257,config,configuration,257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403890890,2,['config'],['configuration']
Modifiability,"Reviving this. This will essentially be a major refactor/rewrite of CreatePanelOfNormals to make it scalable enough to handle WGS. - [x] CombineReadCounts is too cumbersome for large matrices. Change CreatePanelOfNormals to take in multiple -I instead.; - [x] Rename NormalizeSomaticReadCounts to DenoiseReadCounts and require integer read counts as input. These will still be backed by a ReadCountCollection until @asmirnov239's changes are in.; - [x] Remove optional outputs (factor-normalized and beta-hats) from DenoiseReadCounts. For now, TN and PTN output will remain in the same format (log2) to maintain compatibility with downstream tools.; - [x] Maximum number of eigensamples K to retain in the PoN is specified; the smaller of this or the number of samples remaining after filtering is used. The number actually used to denoise can be specified in DenoiseReadCounts. If we are going to spend energy computing K eigensamples, there is no reason we shouldn't expose all of them in the PoN, even if we don't want to use all of them for denoising. (Also, the current SVD utility methods do not allow for specification of K < N when performing SVD on an MxN matrix, even though the backend implementations that are called do allow for this; this is terrible. In any case, randomized SVD should be much faster than the currently available implementations, even when K = N).; - [x] Rename CreatePanelOfNormals to CreateReadCountPanelOfNormals; - [x] Refer to ""targets"" as intervals. See #3246.; - [x] Remove QC.; - [x] Refer to proportional coverage as fractional coverage.; - [x] Perform optional GC-bias correction internally if annotated intervals are passed as input.; - [x] Make standardization process for panel and case samples identical. Currently, a sample mean is taken at one point in the PoN standardization process, while a sample median is taken in the case standardization process.; - [x] HDF5 PoN will store version number, all integer read counts, all/panel intervals, all/panel ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-313921687:48,refactor,refactor,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-313921687,2,"['refactor', 'rewrite']","['refactor', 'rewrite']"
Modifiability,"Right, the `try` block needs to catch the `java.lang.UnsatisfiedLinkError` exception. We'll fix that in the next GKL release. As a workaround, you can try defining this environment variable: `export GKL_USE_LIB_PATH=1`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2302#issuecomment-265859639:181,variab,variable,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2302#issuecomment-265859639,1,['variab'],['variable']
Modifiability,"Right. I want to subset by sample name, effectively taking a slice of the; position by sample genotype matrix and computing Info annotations based; only in the kept samples. On Mon, Mar 4, 2019, 8:52 PM Karthik Gururaj <notifications@github.com>; wrote:. > I'm assuming you will have the subset of samples before creating a; > GenomicsDBFeatureReader object (and before creating the corresponding; > Protobuf export configuration object).; >; > More precisely, you are NOT requesting a line by line filter similar to:; > At pos 100, compute INFO fields etc including only the samples whose QUAL; > > 5; > At pos 102, compute INFO fields etc including only the samples whose QUAL; > > 5; > ....; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMZjIbDJ2eDZcB69XHiUycnumzHrks5vTc3PgaJpZM4Z7pF2>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469680991:416,config,configuration,416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469680991,1,['config'],['configuration']
Modifiability,"Running a particular bam sort takes ~20minutes with hdd and 16 minutes with ssd. So it's definitely being used somehow. It looks like spark.local.dir is over ridden by the environment variable LOCAL_DIRS, and I don't see that set, but it's possible it's being set but not recorded correctly in the UI or something like that. Someone will need to poke at a bit more to be more clear about what's happening.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283481370:184,variab,variable,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283481370,2,['variab'],['variable']
Modifiability,Saw it again [here](https://travis-ci.com/broadinstitute/gatk/jobs/180435353) (now restarted). If I'm reading the serialization stack in the right order:. ```; Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager); ```. it looks like we're trying to serialize a ClassLoader. The FieldSerializer does appear to use a ClassLoader to load classes during serialization.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-467462740:262,Config,Configuration,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-467462740,1,['Config'],['Configuration']
Modifiability,"ScoreVariantAnnotations:. Scores variant calls in a VCF file based on site-level annotations using a previously trained model. TODOs:. - [x] Integration tests. Exact-match tests for (non-exhaustive) configurations given by the Cartesian product of the following options:; * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); * non-allele-specific vs. allele-specific; * SNP-only vs. SNP+INDEL (for both of these options, we use trained models that contain both SNP and INDEL scorers as input) ; - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Double check or add behavior for handling previously filtered input, clearing present filters, etc. Future work:. - [ ] The `score_samples` method of the sklearn IsolationForest is single-threaded. See (possibly stalled) PR at https://github.com/scikit-learn/scikit-learn/pull/14001 and some workarounds using e.g. `multiprocessing` ibid.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563:199,config,configurations,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563,2,['config'],['configurations']
Modifiability,"See https://github.com/broadinstitute/gatk/issues/4888, which is an older report for the same issue. As mentioned there, I think we should patch our fork of `google-cloud-java` to do a channel reopen on `UnknownHostException` for now as a quick fix. @jean-philippe-martin is eventually going to add an official configuration mechanism for clients of `google-cloud-java` to customize which errors should trigger a retry/reopen, which should provide a better way to deal with these errors as they crop up without having to modify the NIO library itself.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412134420:311,config,configuration,311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412134420,1,['config'],['configuration']
Modifiability,Seems like something like https://github.com/broadinstitute/gatk/issues/4794 could be avoided if we rewrote this. It seems like a pretty simple rewrite too...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481:144,rewrite,rewrite,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481,2,['rewrite'],['rewrite']
Modifiability,"Several backwards-incompatible changes in VCF 4.3 (eg., escape sequences) have made it difficult to update without first doing a major refactoring in HTSJDK to better version/isolate our parsers. @cmnbroad can provide further details.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-471719969:135,refactor,refactoring,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-471719969,1,['refactor'],['refactoring']
Modifiability,"Since Geraldine is away till the end of the week, and we are under the Nov 23 deadline for review, I will proceed with changes. I think it useful for me to go through the motions and see what other discussion items turn up. Notes on factors I think are of interest to users re annotators:; - cohort vs sample level annotation; - InfoFieldAnnotation; - GenotypeAnnotation; - minimum number of samples, e.g. 10 for inbreedingcoefficient; - standard annotations for each tool (HC, M2 and VariantAnnotator), standard allele-specific annotations.; - StandardMutectAnnotation; - PerAlleleAnnotation; - StandardAnnotation (extends Annotation); - StandardHCAnnotation; - VariantAnnotation; - noticing `public class` vs `public final class`. Not annotating `abstract` class nor `public interface`.; - What is a reducible annotation?; - I would really find helpful the acronym for the annotation, e.g. MBQ, be listed with the annotation summary, e.g. Median base quality of bases supporting each allele.; - Annotations that are specific to a tool. E.g. DepthPerSampleHC can only be used by HaplotypeCaller and not VariantAnnotator. Doc doesn't say anything about Mutect2. ; - Not sure what VariantOverlapAnnotator does ~~but went ahead and summarized as ""Annotate ID field and attribute overlap FLAG"".~~ `did not tag`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344427246:616,extend,extends,616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344427246,1,['extend'],['extends']
Modifiability,"Since we are going to change many of those argument names (camel-back to kebab-case) I think we should take this opportunity to use constants to specify argument names in the code and use them in our test code so further changes in argument names don't break tests. . Take as an example [CombineReadCounts](https://github.com/broadinstitute/gatk/blob/3ec7399a54ccf89d2b323b2be71b8b7e4931174c/src/main/java/org/broadinstitute/hellbender/tools/exome/CombineReadCounts.java). Extract enclosed below. It might be also beneficial to add public constant for the default values. ```java; public final class CombineReadCounts extends CommandLineProgram {. public static final String READ_COUNT_FILES_SHORT_NAME = StandardArgumentDefinitions.INPUT_SHORT_NAME;; public static final String READ_COUNT_FILES_FULL_NAME = StandardArgumentDefinitions.INPUT_LONG_NAME;; public static final String READ_COUNT_FILE_LIST_SHORT_NAME = ""inputList"";; public static final String READ_COUNT_FILE_LIST_FULL_NAME = READ_COUNT_FILE_LIST_SHORT_NAME;; public static final String MAX_GROUP_SIZE_SHORT_NAME = ""MOF"";; public static final String MAX_GROUP_SIZE_FULL_NAME = ""maxOpenFiles"";; public static final int DEFAULT_MAX_GROUP_SIZE = 100;. @Argument(; doc = ""Coverage files to combine, they must contain all the targets in the input file ("" +; TargetArgumentCollection.TARGET_FILE_LONG_NAME + "") and in the same order"",; shortName = READ_COUNT_FILE_LIST_SHORT_NAME,; fullName = READ_COUNT_FILE_LIST_FULL_NAME,; optional = true; ); protected File coverageFileList;. @Argument(; doc = READ_COUNT_FILES_DOCUMENTATION,; shortName = READ_COUNT_FILES_SHORT_NAME,; fullName = READ_COUNT_FILES_FULL_NAME,; optional = true; ); protected List<File> coverageFiles = new ArrayList<>();. @Argument(; doc = ""Maximum number of files to combine simultaneously."",; shortName = MAX_GROUP_SIZE_SHORT_NAME,; fullName = MAX_GROUP_SIZE_FULL_NAME,; optional = false; ); protected int maxMergeSize = DEFAULT_MAX_GROUP_SIZE;. @ArgumentCollection; protect",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346175904:618,extend,extends,618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346175904,1,['extend'],['extends']
Modifiability,"Size=0,spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600,spark.executor.cores=2,spark.executor.instances=2 --jar /Users/droazen/src/hellbender/build/libs/gatk-package-4.beta.6-54-g0ee99da-SNAPSHOT-spark.jar -- CountReadsSpark -I gs://hellbender/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam --sparkMaster yarn; Job [acdae2af-e0ce-4822-87f5-dcd165d85cf4] submitted.; Waiting for job output...; 20:39:42.869 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 20:39:43.053 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/acdae2af-e0ce-4822-87f5-dcd165d85cf4/gatk-package-4.beta.6-54-g0ee99da-SNAPSHOT-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [November 27, 2017 8:39:43 PM UTC] CountReadsSpark --input gs://hellbender/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam --sparkMaster yarn --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [November 27, 2017 8:39:43 PM UTC] Executing as root@droazen-test-cluster-m on Linux 3.16.0-4-amd64",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:2637,variab,variables,2637,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,2,"['config', 'variab']","['configured', 'variables']"
Modifiability,"So I just updated one of the newer tests, and now all of the tests for HaplotypeCaller seem to be passing locally. The previous commits updating the copy code were preserved when Louis reverted, so there were basically no changes I had to make to get this ""working."" That does leave us with one question now:. When looking into this a little with James and Louis earlier, we realized that the code for setting up the ActiveRegionGenotyper uses a weird partial copy of the standard CLI args method that has existed in the code for whoever knows how long. Conceptually this seems like a bad idea, but changing it now would possibly cause some older tests to fail, if they were based on this faulty method reasoning. Should we try to merge the PR as it is now, with all tests passing, and hopefully consistency with previous behavior, or try to update the logic around this genotyper as well at the same time? It's possible we can try to address the latter point as well at some point in the future when we try to get Louis's refactor code actually working. Maybe there could be some quarter goal around a HaplotypeCaller code revamp sometime inspired by some of these ideas?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1847916216:1023,refactor,refactor,1023,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1847916216,1,['refactor'],['refactor']
Modifiability,So we typically override the config files on the command line. We'll have to make sure we wire the log4j 1.x logger to respect our command line overrides if it doesn't already. You can check that by testing if you can control the log output with the --verbosity command. If not we'll have to update `LoggingUtils.setLoggingLevel()`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794:29,config,config,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794,1,['config'],['config']
Modifiability,"Some changes after the comments from @droazen (in commit #2360):; * Change the argument name from `--disableAllReadFilters` to `--disableToolDefaultReadFilters`; * Make `--disableToolDefaultReadFilters` mutex w.r.t. `--disableReadFilter`; * As pointed out in a different PR (#2355), make all the plugin arguments common.; * Make `isDisabled()` and `getAllInstances()` honor the `--disableToolDefaultReadFilters` argument (solves #2363). I think that this makes more sense than disable absolutely all the read filters, including the ones provided by the user. The cases where this is more useful are:; - Process the data without filters: provide just `--disableToolDefaultReadFilters`; - Process the data without default filters and add any other: provide `--disableToolDefaultReadFilters` and `--readFilter` with the rest of filters; - Process the data with the default filters and include more: as in the previous behaviour, provide `--readFilter` with the rest of filters; - Process the data with some default filters but change the order: provide `--disableToolDefaultReadFilters` and the list of filters in the new order. . Can you have a look to this one, @cmnbroad and/or @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2365#issuecomment-275633852:296,plugin,plugin,296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2365#issuecomment-275633852,1,['plugin'],['plugin']
Modifiability,"Some comments/questions for the review:; - I'll add a separate ticket to rewrite the integration tests, all of which pass and most of which are disabled since they require access to large files on the broad file system. In the meantime I need to add a couple of small tests to get the coverage back up, and would like to get the CR process started.; - I ported a bunch of support files but need feedback on whether they're in the right location.; - Somewhere I saw something that said GATK no longer supports .ped files ? If not, what should the replacement be in the tests require pedigree input?; - Is it a requirement to support Ploidy > 2 ? The current GATK tool, and thus the HB tool, do not; - I did not port the WalkerTestSpec.disableShadowVCF? Is that needed in Hellbender ?; - Are there other headers I should be applying to the output variant file ?. Command Line Arguments:; - I didn't port the GATK command line argument ""-no_cmd_line_in_header"". Should I ? And if not, should the command line args automatically be propagated to the output vcf file ? I didn't see GATK do this anywhere.; - There was one test that used --variant:dbsnp on the command line but I couldn't find the code that processed that in GATK, not sure what the means on the command line.; - I replaced ""-U LENIENT_VCF_PROCESSING"" with ""--lenient"" (testFileWithoutInfoLineInHeaderWithOverride needs this to pass).; - I replaced ""-L"" with --interval since HB seems to use -L for ""lane"" ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027:73,rewrite,rewrite,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027,1,['rewrite'],['rewrite']
Modifiability,Some info on Spark configurations:. https://stackoverflow.com/questions/29441316/specifying-an-external-configuration-file-for-apache-spark,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565:19,config,configurations,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565,2,['config'],"['configuration-file-for-apache-spark', 'configurations']"
Modifiability,"Some offline discussions have led us to the conclusion that this is best handled by tools upstream. Adapters should not be simply soft-clipped, so it shouldn't be the responsibility of M2 or HC to include logic to remove adapters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6346#issuecomment-575334816:100,Adapt,Adapters,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6346#issuecomment-575334816,3,"['Adapt', 'adapt']","['Adapters', 'adapters']"
Modifiability,"Sorry @droazen @LeeTL1220, can you give me a bit more context? @LeeTL1220 is no longer using any of the CNV-specific collections classes that I had hoped might be Tribble-ized in the future, so I'm OK with any decisions you guys make that are specific to his classes (does @jonn-smith have an opinion?) I think that moving towards storing the config in the header is a good thing, in general. If we need to make corresponding changes to the CNV-specific collections classes, then we should talk more. Not all of those collections describe locatables, so I'm not sure how we could fit them in the Tribble framework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369734330:343,config,config,343,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369734330,1,['config'],['config']
Modifiability,"Sorry, again confounded by static-blocks and inheritance (dup of my own issue https://github.com/broadinstitute/gatk/issues/3483)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5014#issuecomment-405100946:45,inherit,inheritance,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5014#issuecomment-405100946,1,['inherit'],['inheritance']
Modifiability,"Sorry, but this bug still isn't fixed as of v4.2.6.1. Reproduce as follows:. ```; --read-filter MateDistantReadFilter; --mate-too-distant-length 1500; ```. Instead of a run-time exception (as in v4.2.5.0), HaplotypeCaller simply produces no variant calls at all. Expected behavior would be to exclude paired-end mappings whose TLEN exceeds the parameterized value. Perhaps there is an implementation bug, unrelated to the original problem, that contains faulty logic for doing this. Thanks...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1102943692:344,parameteriz,parameterized,344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1102943692,2,['parameteriz'],['parameterized']
Modifiability,"Sorry, it's difficult for me to spot git notifications in my email. . > Maybe @bshifaw can chime in? Are the featured workspaces covered by tests elsewhere? What is the current SOP for taking workflows from this repo, turning them into featured workspaces, and populating their configurations?. Example JSONs with input test data are usually introduced in the gatk-workflows git repos and carried over to the featured workspaces. That isn't to say they are not welcomed from the gatk repo. > @bshifaw related to what Sam was saying - we also have a few standard resources needed to run the workflows that we would like to share with users. What is the standard procedure for doing so? Ideally they would be bundled with featured workspaces, but also accessible from outside of Terra. Workflow resources files that are not already in [broad-references](https://console.cloud.google.com/storage/browser/broad-references) would be saved in the [gatk-best-practices](https://console.cloud.google.com/storage/browser/gatk-best-practices) bucket. In the past i've separated the resources files per workflow directory (e.g. pathseq, cnn-hg38) but you can organize them a different way if the resources files would be shared by other workflows (e.g. somatic-hg38, somatic-b37).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-507703719:278,config,configurations,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-507703719,1,['config'],['configurations']
Modifiability,"Sorry, just saw this now. We still don't have a simple solution for training models without pysam. We can probably do something similar to what we do with inference, but I think the current priority is to improve inference throughput so it will probably be a little while before we get to re-writing the training code. If people feel we should re-prioritize please let me know.; I have installed the conda environment on the same OSX version, without seeing this issue.; Which gcc version are you using @mwalker174 ? ; My `gcc -v` output is:; ```; Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1; Apple LLVM version 8.0.0 (clang-800.0.42.1); Target: x86_64-apple-darwin15.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391014193:548,Config,Configured,548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391014193,1,['Config'],['Configured']
Modifiability,"Sounds like a good idea, thanks! I will use a copy of the current plugin in my project til all these changes of the plugin descriptor are in (both Barclay and my proposals here).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2362#issuecomment-275707975:66,plugin,plugin,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2362#issuecomment-275707975,2,['plugin'],['plugin']
Modifiability,Stack trace from failed job:. ```; Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Null value when trying to read system resource. Cannot find: org/broadinstitute/hellbender/tools/copynumber/utils/annotatedinterval/annotated_region_default.config; 	at org.broadinstitute.hellbender.utils.io.Resource.getResourceContentsAsFile(Resource.java:90); 	at org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec.<init>(AnnotatedIntervalCodec.java:55); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at java.lang.Class.newInstance(Class.java:442); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:511); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:464); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:324); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:304); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.Abstra,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5979#issuecomment-498620174:259,config,config,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5979#issuecomment-498620174,1,['config'],['config']
Modifiability,"Subsampling seems to be the way to go, see #2858. For the record, I did try to implement caching, but this results in excessive cache checking. In general, I think a better solution is to structure code so that expensive global quantities are not unnecessarily recomputed locally. At some point, this sort of undesirable recomputation snuck in during a refactoring of the allele-fraction likelihood code, probably when we tried to make the method for computing site likelihoods pull double duty based on the presence or absence of an allelic PoN. With an allelic PoN, we need to compute a log gamma at each site based on the site-specific bias hyperparameters; without a PoN, we only need to do this once for all sites, since the bias hyperparameters are now global, but the code naively recomputes it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2860#issuecomment-335621709:353,refactor,refactoring,353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2860#issuecomment-335621709,1,['refactor'],['refactoring']
Modifiability,"Substituting `STANDARD_CONFIDENCE_FOR_CALLING/3` for `STANDARD_CONFIDENCE_FOR_EMITTING` seems wrong, given that `STANDARD_CONFIDENCE_FOR_CALLING` is a user-configurable value. We talked to @vdauwera just now and she agrees -- we're going to close this PR here and open a ticket against GATK3 to fix this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2194#issuecomment-259794842:156,config,configurable,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2194#issuecomment-259794842,1,['config'],['configurable']
Modifiability,"Sure thing. I can find out which changes I needed to make in gatk to get certain tools to work, like `PrintReads` and `MarkDuplicates`, though they were certainly not exhaustive. We will also see about open sourcing our s3 nio library which is basically a rewrite of https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 with changes for handling s3 endpoints.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319206378:256,rewrite,rewrite,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319206378,1,['rewrite'],['rewrite']
Modifiability,TODO: refactor duplicated VC generation code from PosteriorProbabilitiesUtilsUnitTest in ReblockGVCFUnitTest by extracting to VariantContextTestUtils,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-403224932:6,refactor,refactor,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-403224932,1,['refactor'],['refactor']
Modifiability,"Testing the tool behavior when given an incomplete PED file. PED; <img width=""847"" alt=""screenshot 2019-01-22 16 42 07"" src=""https://user-images.githubusercontent.com/11543866/51567234-b42e3200-1e64-11e9-942c-2934980dc04a.png"">. Command; ```; gatk CalculateGenotypePosteriors \; -V precomputed/trioGGVCF.vcf.gz \; -ped duo.ped \; --skip-population-priors \; -O sandbox/duoCGP.vcf.gz; ```. Results; <img width=""842"" alt=""screenshot 2019-01-22 16 44 01"" src=""https://user-images.githubusercontent.com/11543866/51567337-ef306580-1e64-11e9-8ca6-051ccb3fa18d.png"">. The line of interest reads:; ```; 16:27:00.401 INFO CalculateGenotypePosteriors - No PED file passed or no *non-skipped* trios found in PED file. Skipping family priors.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-456575220:361,sandbox,sandbox,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-456575220,1,['sandbox'],['sandbox']
Modifiability,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:1105,config,configuration,1105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504,2,['config'],['configuration']
Modifiability,"Thank you @mwalker174 for the suggestions. I ended up writing for loops to test which configurations work. Driver memory: 2-50g; executor memory: 2-50g; executor cores: 1-20; bamPartitionSize: 1-64m. Some combinations failed in minutes, some failed in hours, and some finished without errors. Bellow are three of which work for a ~33X WGS data:; ```; ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 20 ; --executor-memory 10g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 5 ; --executor-memory 50g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 64000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.core",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314:86,config,configurations,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314,1,['config'],['configurations']
Modifiability,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:1292,variab,variables,1292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160,2,['variab'],['variables']
Modifiability,"Thanks @davidbenjamin for essentially refactoring this code three times now!. Looking forward to reviewing your latest changes, but it may have to wait until early next week. Apologies for the delay. In the meantime, I see that there is a minor rebase conflict—up to you if you want to address it now, no biggie if you want to wait until after review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1070960072:38,refactor,refactoring,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1070960072,1,['refactor'],['refactoring']
Modifiability,"Thanks @droazen. Because you assigned it to me, I would like to know a couple of details on how this should be implemented in GATK4:. * GATK3 use to have a the `MisencodedBaseQualityReadTransformer` always on, with a switch for checking/fixing the qualities. If we follow this approach in GATK, the only change for this is to include the checking step every n reads and then #2160 will do the rest. Nevertheles, I think that it's quite dangerous to allow an user to disable it with the plugin (because the name suggest that it is only fixing the qualities), so I suggest to integrate in the read data source an iterator for checking every x reads if the qualities are misencoded, independently on the transformer.; * GATK3 throws an UserException for ""putatively misencoded"" qualities, using 60 as maximum base quality for throwing. I think that in the case of GATK4 could be more useful to use a warning if it is over 60 (I do not know what is the reasoning behind this value), and use `SAMUtils.MAX_PHRED_SCORE` for throwing. I'd be happy to implement this if there is a consensus about what to do here, so I'll wait for your ideas...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2082#issuecomment-288760814:486,plugin,plugin,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2082#issuecomment-288760814,1,['plugin'],['plugin']
Modifiability,"Thanks @lbergelson for looking into this. Users can definitely squash the image after pulling, and then push it to their private registries - that's the best workaround here, so this is likely a low-priority issue. Docker images can only be pulled by layers currently; there's no way to pull an image that has multiple layers with one HTTP request. In the [TES runner](https://github.com/microsoft/ga4gh-tes), we are also increasing the docker pull retry count to help. I'll try to update the `dockerfile` and send a PR, thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1935007776:251,layers,layers,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1935007776,2,['layers'],['layers']
Modifiability,"Thanks @lbergelson! I agree that it might be good to break into more layers—could be worth talking to SV team and seeing what lessons they learned in putting together their hierarchy of images. Also, note that I pushed the install of miniconda into the base, but I did not push down the setup of the GATK conda environment itself (which takes the bulk of the time during the main-image build, as it requires lots of downloading). I think I commented elsewhere that a good strategy might be to set up the conda environment with the non-GATK python dependencies in the base, and then update the environment via a pip install of the GATK python packages in the main image. This would let us make python code changes without having to rebuild the base, but might require a bit of scripting to create a final yml for non-Docker users. I also agree that it would be nice to cut down the Travis time, might be worth taking a look at other strategies to do that—could save everyone a lot of time!. Will try to add the test you suggested sometime tomorrow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662:69,layers,layers,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662,2,['layers'],['layers']
Modifiability,"Thanks @mwalker174! I think I responded to or addressed everything. The code paths for reading TSVs all go through the abstract CNV collection classes. Those require a bit of boilerplate, but were IMO a huge improvement over the horrowshow of utility methods from the old code... Happy to discuss possible further refactoring and improvement (and there are already catch-all issues open), if needed. If we decide to stream other locatable collections, we can start to extract more of these streaming/subsetting methods to `AbstractLocatableCollection`, which would give us something like the `LocatableTableReader` you're envisioning in your edit. We've discussed using @jonn-smith's `XSVLocatableTable` machinery as well. I think the only downsides are the conventional reliance on extensions/config files for decoding, as well as the need to accommodate CNV headers. Encoding is also not handled. We also still need to represent non-Locatable TSVs, ideally with a minimal number of code paths, although that probably won't present any major refactoring issues. Also recall that we discussed moving from Files -> Paths in previous PRs, so we should instead go from Files -> FeatureDataSources where it makes sense.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6266#issuecomment-558720770:314,refactor,refactoring,314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6266#issuecomment-558720770,3,"['config', 'refactor']","['config', 'refactoring']"
Modifiability,"Thanks @ruqianl, you may want to read through the comments at https://github.com/broadinstitute/gatk/issues/6235 and the corresponding PR https://github.com/broadinstitute/gatk/pull/6244, which both address this issue. See also the following bit of documentation added in that PR:. > Advanced users may wish to set the THEANO_FLAGS environment variable to override the GATK theano configuration. For example, by running THEANO_FLAGS=""base_compiledir=PATH/TO/BASE_COMPILEDIR"" gatk GermlineCNVCaller ..., users can specify the theano compilation directory (which is set to $HOME/.theano by default). See theano documentation at https://theano-pymc.readthedocs.io/en/latest/library/config.html. So you can specify a unique compilation directory for each of your jobs to avoid the compilelock, e.g., `THEANO_FLAGS=""base_compiledir=PATH/TO/BASE_COMPILEDIR/FOR/JOB/0"" gatk GermlineCNVCaller ...`, `THEANO_FLAGS=""base_compiledir=PATH/TO/BASE_COMPILEDIR/FOR/JOB/1"" gatk GermlineCNVCaller ...`, etc. Alternatively, you can increase `config.compile.timeout` as discussed in those comments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905070899:344,variab,variable,344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7411#issuecomment-905070899,4,"['config', 'variab']","['config', 'configuration', 'variable']"
Modifiability,"Thanks for bringing this to our attention, @Tintest. I think that we may be able to address this by setting `base_compiledir` via `os.environ[""THEANO_FLAGS""]` appropriately (see http://deeplearning.net/software/theano/library/config.html). @mbabadi @cmnbroad any thoughts? . In any case, thanks for trying out the GermlineCNVCaller pipeline. You may have to tune some parameters, depending on your data type. You may find the following discussions helpful:. https://gatkforums.broadinstitute.org/gatk/discussion/11711/germlinecnvcaller-interval-merging-rule-error. https://github.com/broadinstitute/gatk/issues/4719. Note that we're still in beta, but our preliminary evaluations have demonstrated improved performance over other callers in both WES and WGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-390303432:226,config,config,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-390303432,1,['config'],['config']
Modifiability,"Thanks for bringing this up! I actually think that I prefer option 1, although not ideal (since, as you say, it places more burden on the user). The whole point of having generically parameterized models is that we can apply them to many data types. To single out a few with hardcoded sets of defaults seems like a slippery slope to me. (Of course, we should definitely provide defaults for typical data types in *documentation*.) And in the end, I think it is beneficial for users that wish to tweak knobs to do some work to understand what those knobs actually do (even if just at a basic level). The other downside of option 2 is that it might not be immediately obvious from the command line what parameters are being used. For example, if a user chooses a set of defaults but then overrides some of them, we should make it so they don't have to go digging through the logs to see what parameters are actually used in the end. Nor should they have to go back and check what the defaults were for whatever version of the jar they were using at the time. Option 2 might also make it easier to inadvertently override parameters, etc. via command-line typos or copy-and-paste errors---it's much more straightforward to require and check that every parameter is specified once and fallback to a default if not, as we do now. Not to say that we couldn't get around any of these issues in Barclay, but I think it'll require some thought and careful design. Would be interested to hear Engine team's opinions. Finally, one point that I think will become more relevant as our tools and pipelines become more flexible and parameterized: I think we should start thinking of ""Best Practices Recommendations"" less as ""here is the best set of parameters to use with your data"" and more as ""here is *how to find* the best set of parameters to use with your data (for a given truth set, sensitivity requirement, etc.)"". After all, if we are putting together pipelines to do hyperparameter optimization, there is n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385584289:183,parameteriz,parameterized,183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385584289,1,['parameteriz'],['parameterized']
Modifiability,"Thanks for indulging me on this. To me it seems like `UnfilledReadsLikelihoods` diverges too much from `ReadsLikelihoods` to extend it. In effect it's letting `ReadsLikelihoods` sometimes be a wrapper for something that is not a `ReadsLikelihoods`. I haven't worked this out but I would hope that it's possible to construct a `ReadsLikelihoods` from a pileup. I mean, the idea of pileup calling is that you use just a single base for the likelihoods and not the whole read (via Pair-HMM), so we should be able to fill the likelihoods from the base qualities.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4865#issuecomment-396369856:125,extend,extend,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4865#issuecomment-396369856,1,['extend'],['extend']
Modifiability,"Thanks for looking into this @davidbenjamin. I followed the best practices using bwa mem, mark duplicates etc., to create these input bams for HaplotypeCaller. This is Novaseq 2 x 150 data, I ran Fastqc on the reads and everything looks really good, the only thing I can find that might explain the soft-clipping is that there's some Nextera adapter read through on a small percentage of the reads. I haven't been using -Y with bwa (I see it's used in GATK 4 wdls), so it seems like there should be less soft-clipping than normal. I'll admit these are definitely messy regions we're dealing with, but we really need to make the F5 calls for our clinical pipeline. I just tried --dont-use-soft-clipped-bases and I wasn't able to pick the SNP up in the 55-55003_F5_region.bam, but using forceActive/dontTrimActiveRegions does work on this call.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402690747:342,adapt,adapter,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402690747,1,['adapt'],['adapter']
Modifiability,"Thanks for reporting this, @Stikus! That change you highlighted indeed fixes the issue. There was an oblique mention of issues with the previously specified version of pip in the comments of that PR. Note that we now use conda 23.10.0 with the libmamba solver in the GATK Docker image. Please feel free to reopen if you have issues with that specific configuration!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8618#issuecomment-1851818671:351,config,configuration,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8618#issuecomment-1851818671,1,['config'],['configuration']
Modifiability,"Thanks for that info and for sharing the files, @asmirnov239. I suspect that there are essentially two types of bins: ""nice"" and ""not so nice"". The sampling noise in the former is determined by Poisson observation noise, whereas that in the latter is determined by uncertainty in the bias posteriors. This is a bit hard to see in the plots above, and even in this version where I tried to adjust the point size and alpha:. ![image](https://user-images.githubusercontent.com/11076296/137733810-16a79ea9-ea7b-47cc-a42f-40130a949015.png). However, plotting a measure of the difference in the dCRs (from 20 and 200 posterior samples) vs. the dCR is more suggestive:. ![image](https://user-images.githubusercontent.com/11076296/137734587-1b9f6551-74b2-4097-a02c-f51d7341251c.png). As are the dCR histograms:. ![image](https://user-images.githubusercontent.com/11076296/137733867-ce0f5573-a5cc-412c-9060-56fbb09d1ef0.png). I would guess that the nice spike around CR ~ 2 and the fatter base extending up to dCR ~ 100 are distinct populations of bins. So the punchline would be that differences at high dCR are probably just noise within the noise. For ""nice"" bins at dCR ~ few, the sampling noise looks to be <1%. Not really sure what's going on at very high dCR, but I think it's safe to say that these are ""not so nice"" bins!. I've seen this pattern in other WES cohorts when plotting the posterior means vs. std devs for the biases; tried to dig up the plots on Slack, but I can't find them at the moment. Perhaps something along those lines might be worth visualizing in your model-criticism notebooks, if you don't already?. Again, hard to say this is indeed the case from the dCRs alone, but if so, it might be worth baking this sort of mixture into future versions of the model or coming up with other strategies to deal with such bins.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-945731946:985,extend,extending,985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-945731946,1,['extend'],['extending']
Modifiability,"Thanks for the feedback, @cmnbroad.  @droazen, should I open a ticket for implement the plugin and close this issue? What's about the checking of the quals?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245969652:88,plugin,plugin,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245969652,2,['plugin'],['plugin']
Modifiability,"Thanks for the suggestion, @droazen! I did this PR before the read filter plugin was included, and actually I was thinking about remove this PR because it is very clunky. Should I close this and open a discussion about the plugin?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245960477:74,plugin,plugin,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245960477,2,['plugin'],['plugin']
Modifiability,"Thanks guys!. On Sat, Sep 23, 2017 at 11:38 PM, David Benjamin <notifications@github.com>; wrote:. > *@davidbenjamin* requested changes on this pull request.; >; > Done with my review. Mainly the usual stuff about writing more idiomatic; > Java that all C++ coders go through!; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646010>:; >; > > +import org.broadinstitute.hellbender.utils.IntervalUtils;; > +import org.broadinstitute.hellbender.utils.SimpleInterval;; > +; > +import java.io.File;; > +import java.util.List;; > +; > +; > +; > +@CommandLineProgramProperties(; > + summary = ""Split intervals into sub-interval files."",; > + oneLineSummary = ""Split intervals into sub-interval files."",; > + programGroup = VariantProgramGroup.class; > +); > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; >; > @samuelklee <https://github.com/samuelklee> is the boss of the copy; > number code, but personally I don't see the need to be extremely concise; > with short names and would prefer width.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646054>:; >; > > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; > + public static final String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + pri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:967,extend,extends,967,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211,1,['extend'],['extends']
Modifiability,That code checks whether DP is 0 or the maximum PL value is 0. If any of the conditions is satisfied then plugin will assign nocall ./. to that site.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-2117184307:106,plugin,plugin,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-2117184307,1,['plugin'],['plugin']
Modifiability,"That should work for both my cases. It could be nice for SelectVariants to; be able to specify whether genotypes should be called or not too. Other; tools might want the sites-only option. On Mon, Mar 4, 2019 at 12:40 PM droazen <notifications@github.com> wrote:. > *@droazen* commented on this pull request.; > ------------------------------; >; > In; > src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBUtils.java; > <https://github.com/broadinstitute/gatk/pull/4947#discussion_r262167602>:; >; > > @@ -40,7 +40,7 @@; > */; > public static GenomicsDBExportConfiguration.ExportConfiguration createExportConfiguration(final File reference, final String workspace,; > final String callsetJson, final String vidmapJson,; > - final String vcfHeader) {; > + final String vcfHeader, final boolean doGnarlyGenotyping) {; >; > @lbergelson <https://github.com/lbergelson> @ldgauthier; > <https://github.com/ldgauthier> If tools had a way to inject custom GDB; > config (eg., via an overridable method in GATKTool), and the engine used; > this config when creating the Feature Manager on startup, would that solve; > the problem here?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4947#discussion_r262167602>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdOOjGpZBu39mqk7jekA7iOzWDTFrks5vTVqFgaJpZM4U4KK0>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-469412816:975,config,config,975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-469412816,2,['config'],['config']
Modifiability,"That sounds like a good thing to look at. If someone has already written it, it would be great to not have to rewrite it..",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4086#issuecomment-356366388:110,rewrite,rewrite,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4086#issuecomment-356366388,1,['rewrite'],['rewrite']
Modifiability,"That's a good sign. However the code above only checks the providers at the client. It'd be interesting to also check what happens at the workers. I wrote ExampleNioCheckFS for this purpose earlier, you can use it. It's only in a test branch of mine (since it's just test code) but it's pretty short. Looks like this:. ````java; /**; * Example of how to use Spark on Google Cloud Storage directly, without using the GCS Hadoop Connector.; */; @CommandLineProgramProperties(; summary = ""Example of how to use Spark on Google Cloud Storage directly, without using the GCS Hadoop Connector"",; oneLineSummary = ""Example of how to use Spark on Google Cloud Storage directly, without using the GCS Hadoop Connector"",; programGroup = ReadProgramGroup.class; ); public class ExampleNioCheckFS extends SparkCommandLineProgram {; private static final long serialVersionUID = 1L;. @Argument(fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME, shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME, doc = ""Output file (if not provided, defaults to STDOUT)"", common = false, optional = true); private File OUTPUT_FILE = null;. @Argument(fullName = ""inputPath"", shortName = ""P"", doc = ""Input path (eg. gs://foo/bar.bam)"", optional = false); private String path = null;. // Typically set to number of executors times number of cores per executor.; @Argument(fullName = ""parts"", doc = ""number of partitions"", optional = false); private int parts = 3;. private void countReads(JavaSparkContext ctx) {; PrintStream outputStream;. try {; outputStream = OUTPUT_FILE != null ? new PrintStream(OUTPUT_FILE) : System.out;; }; catch ( FileNotFoundException e ) {; throw new UserException.CouldNotReadInputFile(OUTPUT_FILE, e);; }. NioBam input = new NioBam(path, path + "".bai"");; List<String> ret = input.getReads(ctx, parts).mapPartitions(ExampleNioCheckFS::getFS).collect();; outputStream.println(""**** Results **** : "" + String.join("", "", ret));; }. private static Iterator<String> getFS(Iterator<SAMRecord> rs) {",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312#issuecomment-267424466:785,extend,extends,785,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312#issuecomment-267424466,1,['extend'],['extends']
Modifiability,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:221,config,configurable,221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090,4,"['config', 'extend']","['configurable', 'extending']"
Modifiability,The Engine Team discussed this internally and we're going to pull out a subset of all the configuration options into the config file. These options should be those that will change only infrequently (like the data sources directory).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4960#issuecomment-461937685:90,config,configuration,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4960#issuecomment-461937685,2,['config'],"['config', 'configuration']"
Modifiability,The actual code for the funcotation factories is all set up for this. The required update is that `GencodeFuncotationFactory` needs to be refactored to take in the name of the data source. Right now it's assumed that it can only be `Gencode`.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3956#issuecomment-378314286:138,refactor,refactored,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3956#issuecomment-378314286,1,['refactor'],['refactored']
Modifiability,"The behavior of the GATK3 CombineVariants was very inconsistent and the arguments weren't entirely clear. I also suspect that some operations weren't possible with the arguments given. Rather than port that old broken version, I would advocate for an overhaul or rewrite. @bhanugandham it's going to be a big project to collect requirements and expected behavior for this tool. For example, what should the MQ be for the combined VCF for two different input VCFs with different MQ values? Much of the confusion stemmed from the old ability to merge VCFs containing the same sample. In the case where we take one genotype for each sample name (e.g. the old ` -genotypeMergeOptions PRIORITIZE`) then I believe the old behavior was wrong in some cases, taking the filter status from an input VCF at random. We also need to clarify `FilteredRecordMergeType` options, e.g. https://github.com/broadinstitute/gsa-unstable/issues/935",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/17#issuecomment-430229167:263,rewrite,rewrite,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/17#issuecomment-430229167,1,['rewrite'],['rewrite']
Modifiability,The concise message is:. ```; cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle; > Configure project :; Executing: git lfs pull --include src/main/resources/large. > Task :condaStandardEnvironmentDefinition; Created standard Conda environment yml file: gatkcondaenv.yml. > Task :pythonPackageArchive; Created GATK Python package archive in /home/cb2/gatk/build/gatkPythonPackageArchive.zip. > Task :gatkDoc FAILED; Unable to find the 'javadoc' executable. Tried the java home: /usr/lib/jvm/java-11-openjdk-amd64 and the PATH. We will assume the executable can be ran in the current working folder. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org; ```. And stacktrace flag output looks like:. ```; `cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(Execu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:77,Config,Configure,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716,1,['Config'],['Configure']
Modifiability,"The fact that it's circular means that there are reads and bases right up against the edge of the contig and often have soft clips that extend beyond the contig. So it looks a bit like this:. <img width=""945"" alt=""screen shot 2018-07-19 at 11 37 45 am"" src=""https://user-images.githubusercontent.com/13020550/42953344-3ba4f544-8b48-11e8-9250-db75e56c2069.png"">. So yes, circular means it's probably throwing in a weird edge case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5036#issuecomment-406322137:136,extend,extend,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5036#issuecomment-406322137,1,['extend'],['extend']
Modifiability,"The file size only went from 1.9MB to 3MB -- there's no perceptible; difference in test runtime that I can see. On Wed, Apr 5, 2017 at 2:04 PM, droazen <notifications@github.com> wrote:. > *@droazen* commented on this pull request.; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/spark/; > ParallelCopyGCSDirectoryIntoHDFSSparkIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/2540#discussion_r109987028>:; >; > > +; > +; > +public class ParallelCopyGCSDirectoryIntoHDFSSparkIntegrationTest extends CommandLineProgramTest {; > +; > + @Override; > + public String getTestedToolName() {; > + return ParallelCopyGCSDirectoryIntoHDFSSpark.class.getSimpleName();; > + }; > +; > + @Test(groups = {""spark"", ""bucket""}); > + public void testCopyFile() throws Exception {; > + MiniDFSCluster cluster = null;; > + try {; > + final Configuration conf = new Configuration();; > + // set the minicluster to have a very low block size so that we can test transfering a file in chunks without actually needing to move a big file; > + conf.set(""dfs.blocksize"", ""1048576"");; >; > Instead of switching to a larger file, is it possible to just decrease the; > block size further? (thinking about test runtimes here); >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/2540#discussion_r109987028>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZYV_vD1XwS5IPvZiNZKOe6QzDJDVks5rs9e2gaJpZM4MtGXX>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-291948506:555,extend,extends,555,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-291948506,3,"['Config', 'extend']","['Configuration', 'extends']"
Modifiability,The idea behind this branch: make the output to readsSparkSort consistent and configurable. So that if a tool alters reads without changing their sort order then no sort will be performed by default. It also means that if you request sharded output there is the ability to ask reasSparkSource to sort the file for you.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4874#issuecomment-416339183:78,config,configurable,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4874#issuecomment-416339183,1,['config'],['configurable']
Modifiability,The main issue with this task was that the query results were being limited to 100 by default. So we use the -n param now in the query. Another issue was that we were running bq show on a table variable $TABLE which is never defined.; I also changed this because the approach (returning all the samples names of the samples that have been loaded) didn't seem scalable. I wanted to only return at most the number of samples we are trying to ingest.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7470#issuecomment-921024230:194,variab,variable,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7470#issuecomment-921024230,1,['variab'],['variable']
Modifiability,"The master branch failed on BaseRealibratorSpark when running WGS. Try to test this branch, but got hit by a strange error message. The jar file looks right to me. @tomwhite did you have some environment variables? . ````Using GATK jar /home/genomics/Projects/TomWhitePatches/gatk/build/libs/gatk-package-4.alpha.2-230-g19db939-SNAPSHOT-spark.jar; Running:; /home/genomics/Projects/spark/bin/spark-submit --master spark://n001:7077 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --executor-memory 25G --driver-memory 5G /home/genomics/Projects/TomWhitePatches/gatk/build/libs/gatk-package-4.alpha.2-230-g19db939-SNAPSHOT-spark.jar BaseRecalibratorSpark -I hdfs://n001:54310/GATK4TEST/LargeBroadData/WGS-G94982-NA12878.bam -knownSites hdfs://n001:54310/GATK4TEST/DBSNP/dbsnp_138.hg19.vcf.gz -R hdfs://n001:54310/GATK4TEST/OldData/human_g1k_v37.2bit -O hdfs://n001:54310/GATK4TEST/LargeOutput/WGS_BQSR --sparkMaster spark://n001:7077; Picked up JAVA_TOOL_OPTIONS: -XX:+UseG1GC -XX:ParallelGCThreads=4; Picked up JAVA_TOOL_OPTIONS: -XX:+UseG1GC -XX:ParallelGCThreads=4; java.lang.ClassNotFoundException: org.broadinstitute.hellbender.Main; at java.lang.ClassLoader.findClass(ClassLoader.java:530); at org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26); at java.lang.ClassLoader.loadClass(ClassLoader.ja",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299259877:204,variab,variables,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299259877,1,['variab'],['variables']
Modifiability,"The naming of the different classes (`AlignmentRegion`, `AssembledBreakpoint`, `BreakpointAllele`) was very confusing especially with the id variable `breakpointId` in several classes. I've renamed `AssembledBreakpoint` to `BreakpointAlignment`, since I think that the main thing it's trying to capture is a split alignment that's indicating there might be a breakpoint at a given location. Then, the actual breakpoint is represented by `BreakpointAllele` which the information about the breakpoint junction, but not the alignment-related fields. Does that make more sense?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240475247:141,variab,variable,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240475247,1,['variab'],['variable']
Modifiability,"The problem is that htsjdk supports reading multiple versions of vcf, but only knows how to write the current version. Traditionally this has worked because older vcf versions could be trivially written out as a newer version. But v4.3 restricts some values to a narrower range than previous versions, so its not always possible to write out a pre-v4.3 version as a v4.3 compliant file in a non-destructive way. Hence the need to refactor to better support full versioning.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-472037659:430,refactor,refactor,430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-472037659,1,['refactor'],['refactor']
Modifiability,The problem looks like it's due to the Hadoop version. Hadoop 2.7.0 or later is required for https://issues.apache.org/jira/browse/HDFS-3689. We rely on this change to concatenate the VCF parts together (which are variable lengths).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6218#issuecomment-546884621:214,variab,variable,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6218#issuecomment-546884621,1,['variab'],['variable']
Modifiability,The problem seems to be fixed in picard with @cmnbroad's change to the cloud configuration. Thew pom for 2.18.1+ looks like it won't include nio.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4556#issuecomment-375432298:77,config,configuration,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4556#issuecomment-375432298,1,['config'],['configuration']
Modifiability,"The problem seems to be that some of the ""deep"" filters inherited from ReadWalker require to look into the read-base/qualities (just to compare their lenghts) which seems to be quite costly to decode and some of the read-attributes when this particular tool does not need to look into those fields. . It seems to me that we could override these check with a more lightweight alternative. . <img width=""1009"" alt=""screen shot 2018-09-27 at 3 03 36 pm"" src=""https://user-images.githubusercontent.com/791104/46168553-d32a0800-c266-11e8-96fd-d60d7c0380d5.png"">",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5233#issuecomment-425207954:56,inherit,inherited,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5233#issuecomment-425207954,1,['inherit'],['inherited']
Modifiability,"The properties needed are listed here (for testing in this case): https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/engine/spark/SparkContextFactory.java#L83-L86. They are; * `fs.gs.impl`; * `fs.AbstractFileSystem.gs.impl`; * `fs.gs.project.id`; * `google.cloud.auth.service.account.json.keyfile`. Note that to set them as Spark configuration values, they need to be prefixed with `spark.hadoop`. So from the `spark-submit` command line you would write. ```; --conf spark.hadoop.fs.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500745498:374,config,configuration,374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500745498,1,['config'],['configuration']
Modifiability,"The regression tests added as part of #4344 fulfill this requirement. However, they need to be refactored to take advantage of the newly-included full `hg19` and `hg38` reference sequences.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5295#issuecomment-430312265:95,refactor,refactored,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5295#issuecomment-430312265,1,['refactor'],['refactored']
Modifiability,"The snapshot builds get published to an artifact repository, but I don't think those are accessible from outside of Broad. The build from this morning with your branch is [here](https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot-local/org/broadinstitute/gatk/4.0.11.0-30-g9c4a27b-SNAPSHOT/) if you can access it. Otherwise, for local development, you can do the following:. - pull gatk master from today so it includes your commit; - run `git fetch --tags` (this is optional but it will give your local build a more reasonable version tag); - run `./gradlew install printVersion` to install the locally built gatk into your local machine's maven repository; - change your VariantQC gradle project to include the `maven` gradle plugin if its not already there; - add `mavenLocal()` to your projects' `repositories `closure; - change your gatk dependency to the version number printed out by 'printVersion'; - rebuild VariantQC. Having said all that, what code are you dependent on ? I expect the command line interface to VariantEval, and the VariantUtils and StratificationManager and friends classes all to undergo some refactoring and evolve a bit before the tool has the beta tag removed and the interfaces are stabilized. See https://github.com/broadinstitute/gatk/issues/5439 and https://github.com/broadinstitute/gatk/issues/5440.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440782148:737,plugin,plugin,737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440782148,3,"['evolve', 'plugin', 'refactor']","['evolve', 'plugin', 'refactoring']"
Modifiability,"The task here is to simply move the code while changing as little as possible, and then validate that. Once that's done, we can do whatever refactoring/changes we want to VQSR, or replace it completely.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236014525:140,refactor,refactoring,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236014525,2,['refactor'],['refactoring']
Modifiability,"The underlying issue here is is that the GATK conda env environment isn't established since bioconda doesn't appear to configure it. The NPE needs is fixed by #7816. In this particular case it appears that some of the requirements are satisfied, since the code gets past the initial check to see if the GATK python code is available. But then the actual CNN code can't be loaded.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1110010269:119,config,configure,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1110010269,1,['config'],['configure']
Modifiability,"Theory from @cmnbroad is below:. ```; I think this is happening because were trying to serialize the class loader sun.misc.Launcher$AppClassLoader), which appears to be reached through the graph by way of via https://github.com/damiencarol/jsr203-hadoop/blob/master/src/main/java/hdfs/jsr203/HadoopFileSystem.java#L82. We probably need to short circuit that with a custom serializer for one of these:. Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager). See, for instance, dbpedia/distributed-extraction-framework#9.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730#issuecomment-671508579:504,Config,Configuration,504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730#issuecomment-671508579,1,['Config'],['Configuration']
Modifiability,"There are still too many variables here. Do you know that the input bams are the same? Are you using BWA-MEM? My theory is that it's choosing different secondary alignments in MQ0 cases, preferring bases that are capital. If you can show that the same reads going in produce different variants with your two different references then this will be a lot easier to debug.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6825#issuecomment-707755358:25,variab,variables,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6825#issuecomment-707755358,1,['variab'],['variables']
Modifiability,"There has been no activity on this for two years, and the two classes already inherit from different superclasses, and the current ""has a"" implementation avoids code duplication nicely.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4580#issuecomment-592146189:78,inherit,inherit,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4580#issuecomment-592146189,1,['inherit'],['inherit']
Modifiability,"There is a first attempt to have some configurable settings in #2322. If in that PR this could be included, feel free to let me know how do you want to do this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272485359:38,config,configurable,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272485359,1,['config'],['configurable']
Modifiability,"There is no conceivable worst case for this PR -- the only reason for having a `CountSet` was to be be able to have quick `min` and `max` operations (in log(n) time), *but*. * these operations are not used anywhere outside of unit tests, so to make an illuminating worst case you would have to rewrite the assembly engine.; * Even if we did use these operations they would be done once per assembly region, and therefore we could make this class 1000x slower and we would add about a second to the run time of a WGS bam.; * a plain old `TreeSet`, which is what this PR replaces the `CountSet` with, also has these operations in log time.; * the number of kmer sizes used is usually 2, and will be up to 6 in very rare cases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5467#issuecomment-443463884:294,rewrite,rewrite,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5467#issuecomment-443463884,1,['rewrite'],['rewrite']
Modifiability,"There were a few issues with this case. First, the data source was not constructed 100% correctly. The config file is correct. . The index file is for the tar.gz version of the source data and not for the uncompressed version that they're using. The index should correspond to the source data in the file referenced by the config file itself (not a zipped or otherwise transformed version). Secondly, the source `tsv` data file has the header line for the table commented out. The Xsv codec is aware of leading hash marks as comments and will ignore any such lines. Because of this, the leading hash in the table header is ignored and the file cannot be properly parsed. The fix is simple - just remove the leading hash from the table header (the preceding line with the two hash marks is correctly interpreted as a file header because of the leading hashes acting as comments). Lastly, even if the user fixed the file they would still need to index it with`IndexFeatureFile`. At some point the code underlying this in `HTSJDK` was broken such that no Xsv files can currently be indexed. I have submitted a pull request in `HTSJDK` (https://github.com/samtools/htsjdk/pull/1429) for this and have another ready to go in GATK (#6224) that includes a test for this case so this reversion cannot happen again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223#issuecomment-545186183:103,config,config,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223#issuecomment-545186183,4,['config'],['config']
Modifiability,"These kind of errors are typically seen when the field description in the VCF header is incorrect. For example, describing the field length to be a fixed integer when the field is really variable length. I would recommend closely scanning the VCF header for inconsistencies first.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407450035:187,variab,variable,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407450035,1,['variab'],['variable']
Modifiability,"Things left for later:; * `GenotypeIndexCalculator` sometimes interacts with primitive arrays, sometimes with `GenotypeAlleleCounts`; * `GenotypeLikelihoodCalculator` has extraneous responsibilities and doesn't interact with `GenotypeAlleleCounts` as well as it should.; * `alleleCountsToIndex(final GenotypeAlleleCounts newGAC, final int[] newToOldAlleleMap)` in `GenotypeIndexCalculator` needs refactoring.; * `GenotypeLikelihoodCalculators` is really just a cache of `GenotypeAlleleCounts`.; * `GenotypeAlleleCounts` has some unused and barely-used methods, and it precomputes a lot of quantities that are not often needed and could be computed on-the-fly without difficulty or expense.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1066400217:396,refactor,refactoring,396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1066400217,1,['refactor'],['refactoring']
Modifiability,This also means the `GeneListOutputRenderer` will need to accept a config file as a parameter. `SimpleTsvOutputRenderer` already does this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5962#issuecomment-494907060:67,config,config,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5962#issuecomment-494907060,1,['config'],['config']
Modifiability,"This bug has become part of a bigger effort to address how configure the gatk. We're working on a general solution to avoid this sort of issue in the future. We haven't addressed this specific subcase yet though. For now the workaround I described above should work for you. If it doesn't, let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-274899565:59,config,configure,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-274899565,1,['config'],['configure']
Modifiability,"This error message is related to GATK's ability to load files on Google buckets (""gcs://bucket/file.bam""). This ability is enabled even when running locally (this aspect is intentional, because it's useful to be able to run a local GATK instance to process remote data without having to fire up a VM). As the bucket-reading code (""NIO"") initializes, it looks for credentials to use. Those can be set via an environment variable or via `gcloud auth`, as described in GATK's README. If neither of these are set, it checks whether it's currently running in a Google virtual machine (so it can figure out who owns the virtual machine that it's running on, and use those credentials). Apparently this code throws an exception if it runs out of ways to find credentials, and our code prints it out and moves on. The message is useful, for if we *were* running in a google VM and the credential-finding failed, we'd certainly like to know. Whether we need the full stack trace, now, that's a choice we have to make.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095:419,variab,variable,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095,1,['variab'],['variable']
Modifiability,This is fixed for now with a travis environment variable. I'm testing lb_add_region_to_dataproc to make sure that the fix works before removing that variable and merging a change to the dataproc code.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6129#issuecomment-525941840:48,variab,variable,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6129#issuecomment-525941840,2,['variab'],['variable']
Modifiability,"This is not ready for merge -- I just want to see if tests pass with this configuration. There are still some unresolved vulnerabilities:. ```; [1/7] - pkg:maven/com.google.protobuf/protobuf-java@4.0.0-rc-2 - 3 vulnerabilities found!; [2/7] - pkg:maven/log4j/log4j@1.2.17 - 6 vulnerabilities found!; [3/7] - pkg:maven/org.codehaus.janino/janino@3.1.9 - 1 vulnerability found!; [4/7] - pkg:maven/net.minidev/json-smart@2.4.7 - 1 vulnerability found!; [5/7] - pkg:maven/org.codehaus.jettison/jettison@1.1 - 3 vulnerabilities found!; [6/7] - pkg:maven/org.eclipse.jetty/jetty-util@9.4.48.v20220622 - 1 vulnerability found!; [7/7] - pkg:maven/org.eclipse.jetty/jetty-http@9.4.48.v20220622 - 1 vulnerability found!; ```. Some of these we may be unable to resolve. Eg., the `protobuf-java` version in this branch appears to be the most recent one, but still has open vulnerabilities filed against it. The ancient log4j 1.x version is used by two of our dependencies (`hdf5-java-bindings` and `spark-mllib_2.12`), and is the most recent version. Note that this is completely unrelated to the infamous log4j 2.x vulnerability, which was patched in GATK a long time ago.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8352#issuecomment-1581408853:74,config,configuration,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8352#issuecomment-1581408853,1,['config'],['configuration']
Modifiability,This is now configurable via Owner -- closing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-358072659:12,config,configurable,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-358072659,1,['config'],['configurable']
Modifiability,"This is only changing codepaths related with the help. So this change will change the usage to say that all filters are valid for disabeFilter to say that only the available ones are valid. The only problem could be in the docgen code, but not in the behavior of the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2360#issuecomment-275496845:267,plugin,plugin,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2360#issuecomment-275496845,1,['plugin'],['plugin']
Modifiability,"This is the set of fixes for the filter plugin, @cmnbroad. The first commit is the change introduced in #2385 for less verbose test output, so it should be drop once it is accepted.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-278899912:40,plugin,plugin,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-278899912,1,['plugin'],['plugin']
Modifiability,"This likely has to do with your spark configuration. Check on the Spark job's progress through the web interface, which should be something like http://<driver_address>:4040 (see https://spark.apache.org/docs/latest/monitoring.html). . If your BAM is very small, you can also try increasing the number of partitions by reducing --bamPartitionSize.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932:38,config,configuration,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932,1,['config'],['configuration']
Modifiability,This list was generated using a not-yet merged version of my CRAM metadata tool that uses my not-yet-merged refactored CRAM code.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6018#issuecomment-505925995:108,refactor,refactored,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6018#issuecomment-505925995,1,['refactor'],['refactored']
Modifiability,"This looks promising, at a minimum we should try setting up the docker with hadoop native libraries so the performance gains can be extended to most use cases. This might also include adding some magic to the gatk launch script inside the docker to detect and run with the correct version of the hadoop libraries.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746#issuecomment-387519906:132,extend,extended,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746#issuecomment-387519906,1,['extend'],['extended']
Modifiability,This must be the most discussed tool in the GATK. I am relieved to close the book on this PR. Very nice work @mwalker174 -- thanks for all the refactoring!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7243#issuecomment-936636793:143,refactor,refactoring,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7243#issuecomment-936636793,1,['refactor'],['refactoring']
Modifiability,This needs to happen for MAF too. . We should add a method `OutputRenderer::sanitizeField` that we can plug into the annotation process that will automatically sanitize each field for illegal characters as they are added to the output. This will require refactoring the `OutputRenderer::write` method to be concrete with a call to another write method and this sanitizeField method to get the benefits automatically for all OutputRenderers.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4693#issuecomment-383709501:254,refactor,refactoring,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4693#issuecomment-383709501,1,['refactor'],['refactoring']
Modifiability,"This requires also a finer control for the codecs, once the configuration-code is implemented, to ignore default packages, and include/exclude single classes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-324272895:60,config,configuration-code,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-324272895,1,['config'],['configuration-code']
Modifiability,"This seems like a consequence of the fact that we use `java.nio.file.Path`for a lot of things in gatk. This requires a custom `java.nio.file.spi.FileSystemProvider` to be available for each type of path you want to be able to resolve. Spark native uses `org.apache.hadoop.fs.Path` for a lot of things. It's seems likely that that maprfs provides a hadoop file system plugin, which many spark applications can consume, but it's unlikely that it also provides a java.nio.file.Path implementation. ; ; I don't think we'd be able to implement a provider for maprfs ourselves. We don't have any systems with maprfs and don't have the bandwidth to take it on right now. Implementing a file system provider isn't a terribly complicated project, but it's not a trivial one either. However, there's an implementation for hadoop here https://github.com/damiencarol/jsr203-hadoop which is sufficient for what gatk does. If maprfs provides a hadoop file system, it would probably not be too difficult to take that project as a template and modify it to use the maprfs implementation. . I think the only things you'd have to implement for the spark tools to work are the basic Path operations that support the simple operations like `Paths.get()`,`Files.exists()`, and `Path.resolve()`. (although that's not a complete list. . If you are interested in writing a plugin like that, you can add it to the gatk class path at runtime. We might also be open to packaging such a plugin with the gatk if there was wide demand for it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-350070555:367,plugin,plugin,367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-350070555,6,['plugin'],['plugin']
Modifiability,"This seems like a lot of machinery (introducing two new types and a new method) just to hide the config file argument. What if we just mark it `@Hidden` (I know thats prohibited, but this is kind of a special case). The only reason it even exists is because we wanted it to appear in the command lines we display on output and embed in output files. If its `@Hidden` it will still be reflected there when it's used, but it wouldn't be displayed in tool help/usage. Its already always displayed in help as an arg for the gatk wrapper.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371570897:97,config,config,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371570897,1,['config'],['config']
Modifiability,"This seems to be a regression with GATK 4.1.0.0. The code does check for compatible versions before beginning traversal. However, the following log was reported using the M2 WDL:; ```; Runtime.totalMemory()=58851328; ***********************************************************************. A USER ERROR has occurred: Bad input: Config file for datasource (file:///cromwell_root/funcotator_dataSources.v1.4.20180615/gencode/hg19/gencode.config) does not contain required key: ""ncbi_build_version"". ***********************************************************************; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5660#issuecomment-463020005:328,Config,Config,328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5660#issuecomment-463020005,2,"['Config', 'config']","['Config', 'config']"
Modifiability,"This seems to happen in the cloud auth layers, which I don't control. . One potential workaround would be to add a command-line option to disable GCS support. This would only help the original reporter if they don't use GCS paths, of course. Is this something we think may be worth doing at all?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427413074:39,layers,layers,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427413074,1,['layers'],['layers']
Modifiability,This seems to have already been refactored at some point.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2102#issuecomment-590488457:32,refactor,refactored,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2102#issuecomment-590488457,1,['refactor'],['refactored']
Modifiability,"This ticket is just to make the codec packages configurable, which would be resolved by https://github.com/broadinstitute/gatk/pull/3447. If you need more fine-grained control than this, we could discuss as part of a separate ticket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-337651849:47,config,configurable,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-337651849,1,['config'],['configurable']
Modifiability,This ties into the URI class design meeting we're having next week -- I'd say wait until then before starting any refactor of this part of the code.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4480#issuecomment-369943177:114,refactor,refactor,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4480#issuecomment-369943177,1,['refactor'],['refactor']
Modifiability,"Those sound like issues with the IndelRealigner tool from GATK3, which is; not part of our pipeline anymore. Is this still a problem with 4.1.4.1?. On Wed, Feb 19, 2020, 1:00 AM Dario Strbenac <notifications@github.com>; wrote:. > In the news file of a structural variant software I use, I read; >; > Added FIX_SA and FIX_MISSING_HARD_CLIP; > FIX_SA: rewrites split read SA tags; > corrects GATK indel realignment SA tag data inconsistency; > FIX_MISSING_HARD_CLIP: infers missing hard clipping if split read records; > have different lengths; > corrects for GATK indel realignment stripping hard clipping when realigning; >; > Could such issues perhaps be resolved in an update to GATK?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6459?email_source=notifications&email_token=ABSGC5E7CIUF53HYCPS76FDRDTDHBA5CNFSM4KXSMK22YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IOQ3U6A>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABSGC5DYKL5KH6EZS5ZU66DRDTDHBANCNFSM4KXSMK2Q>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6459#issuecomment-588488049:351,rewrite,rewrites,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6459#issuecomment-588488049,1,['rewrite'],['rewrites']
Modifiability,To add to this ticket. In #7876 we have had to expand the JumboAnnotations to work in the HaplotypeCaller as well. Unfortunately this has created problems since there aren't evidences objects in the HC so we have had to change the erasure of the annotate() methods somewhat and some hacky code is now part of the `VariantAnnotatorEngine` which currently has some code in the `addInfoAnnotations()` method that has to resolve the complicated spiderwebs of which likelihoods objects do or don't exist at any given time and then cast them to what they likely are. This really needs to be revisited and refactored to handle the extra annotation inputs more gracefully.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7543#issuecomment-1191802150:599,refactor,refactored,599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7543#issuecomment-1191802150,1,['refactor'],['refactored']
Modifiability,"To clarify what needs to be done here:. -Add a new `--javaOptions` argument to `gatk-launch`. -When running with a packaged local jar, the value of `--javaOptions` should be injected into the command line built by `formatLocalJarCommand()`. -When running with the ""wrapper script"" (as a result of building with `./gradlew installDist` instead of `./gradlew localJar`), propagate the value of `--javaOptions` to the `JAVA_OPTS` environment variable the wrapper script expects. You can inspect the wrapper script itself by running `./gradlew installDist` and then examining `build/install/gatk/bin/gatk`. -When running on Spark, you'll need to add the `--javaOptions` to `spark.driver.extraJavaOptions` and `spark.executor.extraJavaOptions`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2694#issuecomment-305007868:439,variab,variable,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2694#issuecomment-305007868,1,['variab'],['variable']
Modifiability,"To clarify, the tests are being run. It appears to be a bug in how we have configured the jacocoTestReport job that gets executed inside the docker image which seems to result some missing xml files that codeCoverage uses to build its reports. Since we have our integration and cloud tests outside of the docker image the coverage didn't drop to zero. I am looking into reconfiguring the jacocoTestReport task to behave correctly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5001#issuecomment-404629551:75,config,configured,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5001#issuecomment-404629551,1,['config'],['configured']
Modifiability,"To provide some more background, the idea is to generate output as generated by [CollectAllelicCounts](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_tools_copynumber_CollectAllelicCounts.php) for a pool of normals so that we can correct allelic biases in tumor-only. Would it be possible that CreateSomaticPanelofNormals is extended to cover the CollectAllelicCounts ""special case""? . @samuelklee @davidbenjamin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5649#issuecomment-462058940:380,extend,extended,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5649#issuecomment-462058940,1,['extend'],['extended']
Modifiability,"TrainVariantAnnotationsModel:. Trains a model for scoring variant calls based on site-level annotations. TODOs:. - [x] Integration tests. Exact-match tests for (non-exhaustive) configurations given by the Cartesian product of the following options:; * non-allele-specific vs. allele-specific; * SNP-only vs. SNP+INDEL (for both of these options, we use extracted annotations that contain both SNP and INDEL variants as input); * positive (training with *.annot.hdf5) vs. positive-unlabeled (training with *.annot.hdf5 and *.unlabeled.annot.hdf5); * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Refactor main code block for model training; it's a bit monolithic and procedural now.; - [x] Decide on behavior for ill-behaved annotations. E.g., all missing, zero variance. Future work:. - [ ] We could allow subsetting of annotations here, which might allow for easier treatment of ill-behaved annotations. However, I'd say enabling workflows where the set of annotations is fixed is the priority.; - [ ] We could do positive-unlabeled training more rigorously or iteratively. Right now, we essentially do a single iteration to determine negative data. This could perhaps be preceded by a round of refactoring to clean up model training and make it less procedural.; - [ ] Automatic threshold tuning could be built into the tool, see #7711. We'd probably have to introduce a ""validation"" label. Perhaps it makes sense to keep this sort of thing at the workflow level?; - [ ] In the positive-negative framework enforced by the Java code in this tool, a ""model"" is anything that assigns a score, we fit two models to different subsets of the data, and then take the difference of the two scores. While the python backend does give some freedom to specify a model, future developers may want",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369:177,config,configurations,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369,2,"['Refactor', 'config']","['Refactor', 'configurations']"
Modifiability,"Turns out a typo prevents running the ""manage_sv_pipeline"" script, saying GATK_DIR is an unbound variable. Please fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318746083:97,variab,variable,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318746083,1,['variab'],['variable']
Modifiability,Unbound variable bug fixed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318751586:8,variab,variable,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318751586,1,['variab'],['variable']
Modifiability,"Use SampleLocatableMetadata if you want CombineSegmentBreakpoints to only operate on segment files from a single sample. It's conceivable that you want it to be more flexible, in which case I would use LocatableMetadata. Also, go ahead and move the collection class into the collection package, rather than expose the abstract classes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352762883:166,flexible,flexible,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352762883,1,['flexible'],['flexible']
Modifiability,"VariantQC is a tool we made that is somewhat analogous to FastQC. Given an input VCF, it runs VariantEval to generate various summary tables of data, and then makes an HTML report (borrowing a lot from the tool MultiQC) summarizing that VCF. . I wrote this originally by forking GATK3 and wrote a new walker that internally called and run VariantEval. That was never the final plan. I dont know what this will need to look like in GATK4 yet. I'm fine with the expectation that GATK4 VariantEval will evolve and we'd need to update our code wrapping it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440806347:500,evolve,evolve,500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440806347,1,['evolve'],['evolve']
Modifiability,"VariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 19/02/18 16:58:25 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 19/02/18 16:58",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4890,config,configuration,4890,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['config'],['configuration']
Modifiability,"WIth the 4.2.2.0 ReblockGVCF it is running fine. This was without rerunning the HaplotypeCaller to create the gvcf just the reblock. . ```; Using GATK jar /share/pkg.7/gatk/4.2.2.0/install/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.2.2.0/install/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar ReblockGVCF -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -V gvcf.gather/GARDWGSN00001.autosome.g.vcf.gz -drop-low-quals -rgq-threshold 20 -do-qual-approx -O g1.test.reblock.g.vcf.gz; 00:54:40.318 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.2.0/install/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 25, 2021 12:54:40 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 00:54:40.501 INFO ReblockGVCF - ------------------------------------------------------------; 00:54:40.501 INFO ReblockGVCF - The Genome Analysis Toolkit (GATK) v4.2.2.0; 00:54:40.501 INFO ReblockGVCF - For support and documentation go to https://software.broadinstitute.org/gatk/; 00:54:40.501 INFO ReblockGVCF - Executing as farrell@scc-hadoop.bu.edu on Linux v3.10.0-1160.36.2.el7.x86_64 amd64; 00:54:40.502 INFO ReblockGVCF - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 00:54:40.502 INFO ReblockGVCF - Start Date/Time: August 25, 2021 12:54:40 AM EDT; 00:54:40.502 INFO ReblockGVCF - ------------------------------------------------------------; 00:54:40.502 INFO ReblockGVCF - ------------------------------------------------------------; 00:54:40.503 INFO ReblockGVCF - HTSJDK Version: 2.24.1; 00:54:40.503 INFO ReblockGVCF - Picard",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7334#issuecomment-905183643:256,variab,variable,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7334#issuecomment-905183643,1,['variab'],['variable']
Modifiability,"We build GATK-SV docker images on GitHub runners. We use the following to set up the environment to use `--squash` flag. https://github.com/broadinstitute/gatk-sv/blob/52813222b64bf2d15fb9a1aae068590bee184511/.github/workflows/sv_pipeline_docker.yml#L199-L204. I am unsure if you can configure the runtime env on Google Cloud build, but if you can, hopefully, the above can hint some directions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1979099671:284,config,configure,284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1979099671,1,['config'],['configure']
Modifiability,We can either add `to*LegacySegmentCollection` methods to ModeledSegmentCollection or add static utility methods to ModelSegments. No real preference here as the coupling is minimal.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5037#issuecomment-407170543:162,coupling,coupling,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5037#issuecomment-407170543,1,['coupling'],['coupling']
Modifiability,We could combine the filters and transformers into 1 plugin that can intersperse them. It would be more complicated but be maximally expressive.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-246002976:53,plugin,plugin,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-246002976,1,['plugin'],['plugin']
Modifiability,"We generate indices on output files, but we decided not to auto-generate indices on input files in GATK4. We included tools `IndexFeatureFile` and `BuildBamIndex` that can generate these indices on-demand. Indexing inputs automatically is inherently racy/dangerous in the face of multiple processes sharing inputs unless you do things like file locking, which comes with all sorts of portability issues.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2647#issuecomment-298768350:384,portab,portability,384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2647#issuecomment-298768350,1,['portab'],['portability']
Modifiability,"We recommend backing up data just because it is the ""cleanest"" way to roll back. If backing up data is really such a pain point, you could skip doing that. Just back up the callset.json file, and don't turn on `--consolidate` when you're doing incremental import. If a failure happens, just roll back the callset.json and re-do the import. The downside is that the failed import will hang around and take up disk space, but hopefully it is a rare enough occurrence that it doesn't matter - and you will have saved yourself backing up the data. In response to 2) - I guess you're implying that the overhead of cluster/job scheduling won't amortize any benefits from parallelism there? I suppose that could be true, but doesn't seem to be worth optimizing towards that. What I'm asking is whether split and merge are purely an instrument to allow you to choose the granularity of parallelism you want to use? Or is there something else? As I said before, we are considering enabling other ways to do distributed import which would work for the former. It might go something like:; - Create a workspace/initialize configuration+intervals to be imported; - Actually do the import by kicking off (multiple) import(s). User can pick the number of intervals each import is responsible for. User must ensure that no interval gets specified in multiple import processes. P.S: regarding 1000s of small contigs - the current GenomicsDBImport doesn't so so well with large number of contigs (unless you do concatenate the contigs into fewer groups). We hope to have some changes coming soon that will help with that by adding an option for the tool to merge multiple contigs into a single folder in the workspace.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641037548:1111,config,configuration,1111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641037548,1,['config'],['configuration']
Modifiability,We should definitely try to centralize setting of the system properties if possible (perhaps using a master config file) -- though I vote that we put in a quick fix for this first.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2316#issuecomment-267123755:108,config,config,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2316#issuecomment-267123755,1,['config'],['config']
Modifiability,"We've filed a ticket with github support -- however, the branch has been cleared to merge in its current state, as it's had more than enough reviews. We can file tickets to improve/refactor once it's in master.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3945#issuecomment-351092625:181,refactor,refactor,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3945#issuecomment-351092625,2,['refactor'],['refactor']
Modifiability,"Weird, I would have that that forcing the htsjdk version like we already do would have done it... I don't see anything wrong with adding that exclusion, but I'm confused why we need it. ` force 'com.github.samtools:htsjdk:' + htsjdkVersion`. It sounds like a gradle bug in building the final pom file. I wonder if switching to the javaLibrary plugin would fix it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292579154:343,plugin,plugin,343,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292579154,1,['plugin'],['plugin']
Modifiability,"Well, I guess that part of the contract for GATKTool is that GATK tools should report progress as they go. I agree that the ProgressMeter should be made more flexible and allow reporting of progress in terms of things other than genomic location.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577262636:158,flexible,flexible,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577262636,1,['flexible'],['flexible']
Modifiability,"Well, that explains that, sort of. The code snippet you're providing looks like it ought to do what you say it does (i.e., the mates have to be paired, not unmapped, mapped to the same contig, and have a difference in their start positions that is at least `mateTooDistantLength`). . But there are two problems with this:. 1) This filter's behavior is unexpected wrt HaplotypeCaller. It seems to me that an inclusive filter (i.e., process only paired-end mappings whose TLEN falls within a specified range) would be more usable. That would imply a filter implementation that accepts a pair of integers, but the expected behavior would be more obvious and in line with GATK's other range-limited parameterizations (e.g., `MappingQualityReadFilter` comes immediately to mind). 2) I can't tell from where I sit, but the code snippet looks correct only if `getStart()` and `getMateStart()` return a zero-based start position of each mate relative to the start of the strand to which the mate is mapped. If the code is just computing the difference between POS for the mates, the computation is incorrect for forward + reverse-complement (Illumina-style) pairs. In addition, computing TLEN requires not only that you consider the orientation of the individual mate mappings, but also that you make an arbitrary decision about how to handle soft-clipped reads. I hate to say this, but I think this parameter needs some attention. Its potential utility with HaplotypeCaller seems evident to me (i.e., it would be good to be able to exclude outliers with unreasonable TLENs) but its implementation and frugal documentation make it unusable in practice.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103199220:695,parameteriz,parameterizations,695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103199220,2,['parameteriz'],['parameterizations']
Modifiability,What is the progress on this @cmnbroad? Is this waiting for the new Barclay plugin interface?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-282995363:76,plugin,plugin,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-282995363,1,['plugin'],['plugin']
Modifiability,"What is the timeline for portable WDL-NIO?. This would make things like performing preliminary analyses on subsets of contigs, etc. go a bit faster. I agree that this is not a common use case, but since it's such a small amount of work, I don't see the harm. Would be nice to be consistent with other Featured WDLs, if they're all using NIO as well (is this true?)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-391724363:25,portab,portable,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-391724363,1,['portab'],['portable']
Modifiability,"What is your cluster configuration? . That's a lot of memory for one executor, it may be having trouble allocating workers with that much memory, or using all the memory on 1 very large executor.; Have you tried setting executor cores as well? I would usually set it to something like `--executor-cores 4 --executor-memory 16G` . You want to design your executors so they fit evenly into the worker nodes on your cluster but don't have too many cores per executor. . An aside, you *should* be able to create a bam index as part of SortSamSpark now, we have support for generating it in parallel and merging the indexes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547077382:21,config,configuration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547077382,1,['config'],['configuration']
Modifiability,"What the rules for when a tool is allowed to be a `CommandLineProgram`? Most of the CNV tools extend `CommandLineProgram` rather than `GATKTool` for various reasons, including: 1) they use sequence-dictionary input in a way that requires custom argument documentation, 2) they use `-I` to specify non-BAM/SAM/CRAM input, and 3) they don't really make use of the argument collections available in `GATKTool` or otherwise fall under the walker paradigm. These reasons are admittedly minor, but they do make the tools a bit nicer to use in the end. Otherwise, whenever it makes sense for a tool to extend `GATKTool`, it does (4 out of 12 of the CNV tools). (A bit of a tangent: in all the cases where we do extend `GATKTool` to e.g. make use of the `-L` functionality, we still have to jump through some extra hoops to make sure we don't get tripped up. For example, the default `--interval-merging-rule` behavior is incorrect for most CNV analyses, so the user has to set this to `OVERLAPPING_ONLY` manually, otherwise we throw an exception---which is quite awkward. Ideally, we'd have some option to not modify the incoming intervals at all, as well.). So I'm comfortable with closing this issue, but we can discuss the pros and cons of moving more of the tools over if necessary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358038497:94,extend,extend,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358038497,3,['extend'],['extend']
Modifiability,"While we normally don't recommend ignoring that wrapper, this seems like a good reason to do so. . The wrapper is pretty simple, most of what it's doing is some munging of the input to allow it to be more standardized in several different gatk use cases. The only thing I can think of that you would want to be sure to copy is that it sets a number of properties. . We set these spark `--conf` properties with the wrapper. I don't actually know how important some of them are anymore. If it works without them then you're probably good.; ```; ""spark.kryoserializer.buffer.max"" : ""512m"",; ""spark.driver.maxResultSize"" : ""0"",; ""spark.driver.userClassPathFirst"" : ""false"",; ""spark.io.compression.codec"" : ""lzf"",; ""spark.executor.memoryOverhead"" : ""600"",; ""spark.driver.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK,; ""spark.executor.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK; ```. These are htsjdk properties we want to set for spark. ; ```; EXTRA_JAVA_OPTIONS_SPARK= ""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true "" \; ""-Dsamjdk.use_async_io_read_samtools=false "" \; ""-Dsamjdk.use_async_io_write_samtools=false "" \; ""-Dsamjdk.use_async_io_write_tribble=false "" \; ""-Dsamjdk.compression_level=2 ""; ```. If you can get this value into your spark environment variables it prevents and anying warning output. `SUPPRESS_GCLOUD_CREDS_WARNING=true`. Let us know how it works for you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6198#issuecomment-539073054:1251,variab,variables,1251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6198#issuecomment-539073054,2,['variab'],['variables']
Modifiability,Will add a variable to our Protobuf configuration object - the JSON already an option to set this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2687#issuecomment-300298863:11,variab,variable,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2687#issuecomment-300298863,2,"['config', 'variab']","['configuration', 'variable']"
Modifiability,Will refactor and re-open as a different PR,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8642#issuecomment-1937109021:5,refactor,refactor,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8642#issuecomment-1937109021,1,['refactor'],['refactor']
Modifiability,"With a service account key set, it worked like a charm:. ```; $ ./gatk-launch PrintReadsSpark -I gs://jpmartin-testing-project/hellbender-test-inputs/CEUTrio.HiSeq.WGS.b37.ch20.1m-2m.NA12878.bam -O gs://jpmartin-testing-project/test-output/readcount --shardedOutput true -- --sparkRunner GCS --cluster jps-test-cluster; (...); [November 20, 2017 6:17:08 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.72 minutes.; Runtime.totalMemory()=670040064; Job [13c93a62-96d0-456e-91d1-ef7b20f1236b] finished successfully.; ```. Though I understand that [this is expected](https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894). So next I tried it without any `HELLBEND*` environment variable and it worked as well!. ```; Job [6e2f2c6b-921a-4fdf-a42e-0706216b2098] finished successfully.; (...); $ gsutil ls -lh gs://jpmartin-testing-project/test-output/readcount/; 0 B 2017-11-20T18:28:27Z gs://jpmartin-testing-project/test-output/readcount/; 0 B 2017-11-20T18:28:52Z gs://jpmartin-testing-project/test-output/readcount/_SUCCESS; 120.25 MiB 2017-11-20T18:28:51Z gs://jpmartin-testing-project/test-output/readcount/part-r-00000.bam; ```. This is with `GOOGLE_APPLICATION_CREDENTIALS` set, as I believe is part of the GATK README instructions. Next I went to my repro code and tried it again with v30. It failed (`StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account.`) I'm not sure why but the new version is certainly an improvement over the previous one since it fixes `PrintReadsSpark`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-345788205:745,variab,variable,745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-345788205,1,['variab'],['variable']
Modifiability,"With the exception of the HMM package, all of our R dependencies are available through the conda R or bioconda channels; the HMM package is available only through a user's custom channel. However, the HMM package is only used to generate truth for testing the Java HMM code by @vruano (which is currently unused, but we thought was worth keeping around). I'm sure we could easily rewrite the tests to load the truth from a file. I think we should get rid of the install_R_packages.R script altogether and just roll all of these dependencies into the conda environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920:380,rewrite,rewrite,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920,1,['rewrite'],['rewrite']
Modifiability,"Wow, thanks for the detailed comments so far, @davidbenjamin! But perhaps let's quickly chat before you go any further?. There are a lot of things you commented on---temporary integration tests using local files, lots of code/arguments/etc. intentionally copied verbatim over from VQSR/tranches, and entire tools (the ""monolithic"" GMMVariantTrain and ScikitLearnVariantTrain)---that are rather in flux or will be scrapped/cleaned up shortly. That said, the comments on the code inherited from VQSR will certainly be useful in this process!. But it might save you some time if we could chat so I can give you a rough orientation and perhaps point out where the vestigial VQSR code remains. I think focusing discussion on the high level design of the tools that are likely to stay would also be most useful at this stage. Feel free to throw something on my calendar!. In the end, I think we will probably just retain the BGMM backend + the versions of the tools in the ""scalable"" package. I left the ""monolithic"" GMMVariantTrain and ScikitLearnVariantTrain tools in this branch so I could do one round of tieout. That tieout came out OK, so I think we'll abandon the monolithic tools, along with all the associated code outside of the scalable package. If it helps, I can go ahead and remove that stuff from this draft PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1029393942:478,inherit,inherited,478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1029393942,1,['inherit'],['inherited']
Modifiability,YXZh) | `0% <0%> (-100%)` | `0% <0%> (-8%)` | |; | [...ct/CreateSomaticPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.448% <0%> (-94.253%)` | `2% <0%> (-8%)` | |; | [...ls/walkers/mutect/CreateSomaticPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHMuamF2YQ==) | `0% <0%> (-91.429%)` | `0% <0%> (-23%)` | |; | [.../org/broadinstitute/hellbender/utils/IGVUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JR1ZVdGlscy5qYXZh) | `0% <0%> (-88.889%)` | `0% <0%> (-3%)` | |; | [...alkers/mutect/filtering/PolymorphicNuMTFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvUG9seW1vcnBoaWNOdU1URmlsdGVyLmphdmE=) | `0% <0%> (-88.235%)` | `0% <0%> (-9%)` | |; | [...aplotypecaller/HaplotypeCallerIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `0.431% <0%> (-87.5%)` | `2% <0%> (-85%)` | |; | [...alkers/mutect/SomaticReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljUmVmZXJlbmNlQ29uZmlkZW5jZU1vZGVsLmphdmE=) | `12.5% <0%> (-84.375%)` | `1% <0%> (-7%)` | |; | [...tils/variant/writers/SomaticGVCFBlockCombiner.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5803#issuecomment-473417970:2816,Polymorphi,PolymorphicNuMTFilter,2816,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5803#issuecomment-473417970,1,['Polymorphi'],['PolymorphicNuMTFilter']
Modifiability,"Yeah, I don't like these new interface methods -- they make `GATKRead` significantly worse. We should cache `isUnmapped`, etc. in the adapter to accomplish the same thing, as @lbergelson suggests. Not that hard, and we can just unconditionally invalidate the cached values (using `Boolean` fields set to null) whenever the read is mutated in any way in order to simplify the logic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282:134,adapt,adapter,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282,1,['adapt'],['adapter']
Modifiability,"Yeah, it would be useful (see https://github.com/broadinstitute/gatk/issues/2582). Not sure if/when we'll ever get around to the Barclay changes though. Another simple option that wouldn't require Barclay changes would be to implement it as just another (plugin descriptor) command line argument that could be sued alongside `--read-filter`'. So if you wanted a `ReadNameFilter` and an inverted `ReadLengthFilter`, the syntax would be:. `--read-filter ReadNameFilter --invert-read-filter ReadLengthReadFilter`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6005#issuecomment-502231306:255,plugin,plugin,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6005#issuecomment-502231306,2,['plugin'],['plugin']
Modifiability,"Yeah, the workaround was simply to add the library jar to the classpath and not try to compile them together. I created the issue to soon, Sorry. . As for the NIO library, it is for AWS S3. We are adapting this one https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 to meet our needs. We didn't like the way it handles s3 endpoints because AWS EMR Spark clusters don't support s3 uri's with that particular syntax. Our version modifies it to support normal s3 uri's without endpoints, instead setting the endpoint with a configuration parameter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431:197,adapt,adapting,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431,4,"['adapt', 'config']","['adapting', 'configuration']"
Modifiability,"Yep, that will definitely cause a crash - variable length fields need a length value stored while fixed length fields don't. I can add checks for this scenario in GenomicsDB. Please let me know if the following make sense:; Header says that the field F is a fixed length field with length = N. In the data section, if; * length(F) < N - pad with missing values, no error message, continue; * length(F) > N - error, throw exception and print descriptive error message",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407501684:42,variab,variable,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407501684,1,['variab'],['variable']
Modifiability,"Yes it is. Honestly not sure on the u/g config, as an end user I'd really rather not have to care about that 😅 ; This is the only tool causing this kind of issue so it's got to be the tool itself, no?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-2078145966:40,config,config,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-2078145966,1,['config'],['config']
Modifiability,"Yes, Hadoop-BAM uses the NIO API to do file merging, whereas in GATK we were using the Hadoop APIs (and therefore the GCS<->HDFS adapter) to do it. It looks like there are a couple of things needed in GCS-NIO to use the NIO API for this.; 1. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1450 so that we don't have to special-case `gs` URIs to remove everything except the scheme and host when looking up the filesystem (see https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L40); 2. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/813 to support path matching (https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L90). There may be more, as I stopped there. The best way forward is probably to go back to the old code in GATK while the deficiencies in GCS-NIO are fixed and then released. The stacktrace I got for 1 was:. ```; java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://gatk-demo-tom/TEST/markdups.parts/_SUCCESS; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:54); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); ```. And for 2:. ```; java.lang.UnsupportedOperationException; 	at com.google.cloud.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050:129,adapt,adapter,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050,1,['adapt'],['adapter']
Modifiability,"Yes, thank you for jogging my memory @bbimber. @davidbenjamin adding something to that extend in the BadArgumentException message would be helpful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-558740872:87,extend,extend,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-558740872,1,['extend'],['extend']
Modifiability,YnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9jbHVzdGVyL1NWQ2x1c3RlckVuZ2luZS5qYXZh) | `93.269% <0.000%> (-1.002%)` | :arrow_down: |; | [...stitute/hellbender/tools/walkers/sv/SVCluster.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L1NWQ2x1c3Rlci5qYXZh) | `89.773% <0.000%> (-0.881%)` | :arrow_down: |; | [...tools/walkers/sv/JointGermlineCNVSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L0pvaW50R2VybWxpbmVDTlZTZWdtZW50YXRpb24uamF2YQ==) | `86.047% <0.000%> (-0.752%)` | :arrow_down: |; | [...der/tools/walkers/sv/SVClusterIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L1NWQ2x1c3RlckludGVncmF0aW9uVGVzdC5qYXZh) | `99.496% <0.000%> (-0.004%)` | :arrow_down: |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `97.368% <0.000%> (+0.035%)` | :arrow_up: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7858#issuecomment-1130438520:4985,Adapt,AdaptiveChainPruner,4985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7858#issuecomment-1130438520,1,['Adapt'],['AdaptiveChainPruner']
Modifiability,"You can currently specify additional spark configuration with the --conf argument, so you could override the registrator that way. I think you'd have to update gatk-launch as well as build.gradle to get it to work, and currently gatk-launch is shared with gatk-protected. Probably the best solution is going to be to extract all the hardcoded configurations into a configuration file that can be changed on a per project basis. There's some movement to this in gatk public at the moment, but we haven't settled on a solution yet I think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272484533:43,config,configuration,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272484533,3,['config'],"['configuration', 'configurations']"
Modifiability,"You can detect whether a tool has failed in bash by checking whether the exit status code is non-zero. In bash, the exit status code of the last command run is stored in the variable `$?`; ; In general, you should ask questions like these on the GATK forum (https://gatkforums.broadinstitute.org/gatk) instead of here, however -- this is for bug reports rather than support requests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4242#issuecomment-359955349:174,variab,variable,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4242#issuecomment-359955349,1,['variab'],['variable']
Modifiability,You would not have access to docker container options when using the Google backend because the running of your image is all controlled by Pipelines API. You would be able to set that value when running on a local backend but thats probably not portable enough for your workflow.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468:245,portab,portable,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468,1,['portab'],['portable']
Modifiability,"You'd better verify the consistency of the results step by step, then you can find which step's result become diffierent, finally fix it.; For example, you want to see if the `JavaRDD<Shard<GATKRead>> readShards`results are always same. You can add debug info in `callVariantsWithHaplotypeCaller` just like this:. ```; ...... final JavaRDD<Shard<GATKRead>> readShards = SparkSharder.shard ....; //Debug; String path = ""./dubug/readShardsTest1"";; java.io.File debug = new File(path);; if (!debug.getParentFile().exists()); debug.getParentFile().mkdir();; try (PrintStream printStream = new PrintStream(debug)) {; printStream.println(""List<ShardBoundary> shardBoundaries size : "" + shardBoundaries.size());; printStream.printf(""NumPartitions : %d\n"", readShards.getNumPartitions());. List<ShardDebug> shardDebugs = readShards.mapToPair(shard -> new Tuple2<>(new ShardDebug(shard), null)); .sortByKey((Comparator<ShardDebug> & Serializable) (o1, o2) ->; IntervalUtils.compareLocatables(o1, o2, header.getSequenceDictionary()); ).keys().collect();; printStream.printf(""NumShard : %d\n"", shardDebugs.size());; for (ShardDebug shardDebug : shardDebugs) {; printStream.println(shardDebug.toString());; }; }catch (Exception e){; e.printStackTrace();; }; ```. ```; static class ShardDebug extends ShardBoundary{; int size;. public ShardDebug(Shard<GATKRead> shard) {; super(shard.getInterval(),shard.getPaddedInterval());; size = Iterators.size(shard.iterator());; }. @Override; public String toString() {; return this.getInterval().toString() + ""\t"" + size;; }; }; ```; ; Run twice and compare the differences, do this step by step, you will find the bug. Gook Luck!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4231#issuecomment-371415511:1280,extend,extends,1280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4231#issuecomment-371415511,1,['extend'],['extends']
Modifiability,"Your solution doesn't address your third listed drawback to the current; approach, though I'm not sure there's any way to do that that wouldn't; require a pretty dramatic change. It's not obvious to me why we wanted the given alleles in the graph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:862,Adapt,AdaptiveChainPruner,862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767,1,['Adapt'],['AdaptiveChainPruner']
Modifiability,"_FIELD_FORMAT : DECIMAL; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_CRAM_REF_DOWNLOAD : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Deflater IntelDeflater; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Inflater IntelInflater; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Initializing engine; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4769b07b] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@5ef60048].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4769b07b] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@5ef60048].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296871363:2279,variab,variable,2279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296871363,1,['variab'],['variable']
Modifiability,"_epochs=10 --max_training_epochs=50 --initial_temperature=1.500000e+00 --num_thermal_advi_iters=2500 --convergence_snr_averaging_window=500 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=10 --caller_update_convergence_threshold=1.000000e-03 --caller_internal_admixing_rate=7.500000e-01 --caller_external_admixing_rate=1.000000e+00 --disable_caller=false --disable_sampler=false --disable_annealing=false; Stdout: 14:13:50.032 INFO cohort_denoising_calling - Loading 24 read counts file(s)...; 14:13:53.719 INFO gcnvkernel.io.io_metadata - Loading germline contig ploidy and global read depth metadata...; 14:13:58.626 INFO gcnvkernel.tasks.task_cohort_denoising_calling - Instantiating the denoising model (warm-up)...; 14:14:04.543 INFO gcnvkernel.models.fancy_model - Global model variables: {'W_tu', 'psi_t_log__', 'ard_u_log__', 'log_mean_bias_t'}; 14:14:04.544 INFO gcnvkernel.models.fancy_model - Sample-specific model variables: {'z_su', 'psi_s_log__', 'read_depth_s_log__'}; 14:14:04.544 WARNING gcnvkernel.tasks.inference_task_base - No log emission sampler given; skipping the sampling step; 14:14:04.544 WARNING gcnvkernel.tasks.inference_task_base - No caller given; skipping the calling step; 14:14:04.544 INFO gcnvkernel.tasks.inference_task_base - Instantiating the convergence tracker...; 14:14:04.544 INFO gcnvkernel.tasks.inference_task_base - Setting up DA-ADVI...; 14:14:10.902 INFO gcnvkernel.tasks.inference_task_base - (denoising (warm-up)) starting...: 0%| | 0/5000 [00:00<?, ?it/s]; 14:14:12.877 INFO gcnvkernel.tasks.inference_task_base - (denoising (warm-up) epoch 1) ELBO: N/A, SNR: N/A, T: 1.50: 0%| | 1/5000 [00:01<2:44:32, 1.97s/it]; 14:14:14.753 INFO gcnvkernel.tasks.inference_task_base - (denoising (warm-up) epoch 1) ELBO: -145.294 +/- 0.000, SNR: 35869952999211676.0, T: 1.50: 0%| | 2/5000 [00:03<2:40:21, 1.93s/it]; 14:14:16.609 INFO gcnvkernel.tasks.inference_task_base - (denoising (warm-up) epoch 1) E",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-467406398:3698,variab,variables,3698,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-467406398,1,['variab'],['variables']
Modifiability,"`FilterMutectCalls` has always and continues to filter multiallelics by default, except in mitochondria mode. You may adjust this with the `max-alt-allele-count` argument. `-max-alternate-alleles` is a `HaplotypeCaller` argument that appeared in `Mutect2` due to excess inheritance in the class hierarchy. I don't believe it ever had any effect in `Mutect2`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6603#issuecomment-629897864:270,inherit,inheritance,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6603#issuecomment-629897864,1,['inherit'],['inheritance']
Modifiability,"```; $ git remote show origin; fatal: 'origin' does not appear to be a git repository; fatal: Could not read from remote repository. Please make sure you have the correct access rights; and the repository exists.; $ cat .git/config ; [core]; 	repositoryformatversion = 0; 	filemode = true; 	bare = false; 	logallrefupdates = true; $; ```. Hmm, here is the full log, actually I see some shared library errors at the top. Grr, I have `ncurses-6` library only. Why doesn't the build system die immediately upon an error? Anyway, this is exactly why Gentoo does not like executing zillions of evil jar files and other executables. As I said in the past, your step away from Apache ant build system was a very bad decision. You can see in the log the git tag too. I am not sure if the build system used `master` instead of `gatk` branch. Is that a problem?. [build.log.txt](https://github.com/broadinstitute/gatk/files/1933626/build.log.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687#issuecomment-383221183:225,config,config,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687#issuecomment-383221183,1,['config'],['config']
Modifiability,"aJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/staging/gatk-package-4.1.0.0-24-g18a95c7-SNAPSHOT-spark_3e9078b7e67707952fa12a0c5c4d2b71.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/staging/12dc38b0-0b40-49d5-a98e-fe83ca658003.vcf --spark-master yarn; Job [654b5b8e01de4c60bd87d941d4ec8831] submitted.; Waiting for job output...; 19/02/18 16:58:03 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 16:58:09.526 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 16:58:09.705 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/654b5b8e01de4c60bd87d941d4ec8831/gatk-package-4.1.0.0-24-g18a95c7-SNAPSHOT-spark_3e9078b7e67707952fa12a0c5c4d2b71.jar!/com/intel/gkl/native/libgkl_compression.so; 16:58:10.112 INFO PrintVariantsSpark - ------------------------------------------------------------; 16:58:10.113 INFO PrintVariantsSpark - The Genome Analysis Toolkit (GATK) v4.1.0.0-24-g18a95c7-SNAPSHOT; 16:58:10.113 INFO PrintVariantsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:58:10.113 INFO PrintVariantsSpark - E",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:1272,config,configuration,1272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['config'],['configuration']
Modifiability,"al String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; >; > binWidth would be a more readable variable name. There's nothing wrong; > with the command line argument and the variable being identical.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646097>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = true,; > + minValue = 0; > + ); > + private int padding = 0;; >; > This tool extends GATKTool, which means that it inherits an; > IntervalArgumentCollection that already includes a padding argument. A; > new one is not needed. BTW @samuelklee <https://github.com/samuelklee>; > does this come up elsewhere in the CNV code? It could be a holdover from; > the days of porting ReCapSeg when I feel we used to write more; > CommandLinePrograms.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646119>:; >; > > + createBins();; > + }; > +; > + /**; > + * Generates binning coverage in the intervals given by the user.; > + * The width of bins, the intervals and the output file's path are given by the user.; > + */; > + public void createBin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:2816,extend,extends,2816,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211,2,"['extend', 'inherit']","['extends', 'inherits']"
Modifiability,"am/md5/%s; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.REFERENCE_FASTA : null; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipeline",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5391,Config,ConfigFactory,5391,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"ark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --num-executors 20 --executor-cores 6 --executor-memory 6g /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 23:10:10.737 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 23:10:10.965 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 23:10:12.679 INFO CountReadsSpark - ------------------------------------------------------------; 23:10:12.680 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.1.0.0; 23:10:12.680 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 23:10:12.680 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 23:10:12.681 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 23:10:12.681 INFO CountReadsSpark - Start Date/Time: February 5, 2019 11:10:10 PM EST; 23:10:12.681 INFO CountReadsSpark - -------------------------------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:3169,variab,variables,3169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912,2,"['config', 'variab']","['configured', 'variables']"
Modifiability,"athSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from htt",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5680,Config,ConfigFactory,5680,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"aults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.REFERENCE_FASTA : null; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.us",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5324,Config,ConfigFactory,5324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,ava:648); 	at org.gradle.api.internal.file.copy.DefaultCopySpec$DefaultCopySpecResolver.walk(DefaultCopySpec.java:650); 	at org.gradle.api.internal.file.copy.DefaultCopySpec.walk(DefaultCopySpec.java:458); 	at org.gradle.api.internal.file.copy.CopySpecBackedCopyActionProcessingStream.process(CopySpecBackedCopyActionProcessingStream.java:38); 	at org.gradle.api.internal.file.copy.DuplicateHandlingCopyActionDecorator$1.process(DuplicateHandlingCopyActionDecorator.java:44); 	at org.gradle.api.internal.file.copy.NormalizingCopyActionDecorator$1.process(NormalizingCopyActionDecorator.java:57); 	at org.gradle.api.internal.file.copy.CopyActionProcessingStream$process.call(Unknown Source); 	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction$1.execute(ShadowCopyAction.groovy:78); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction$1$execute.call(Unknown Source); 	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction.withResource(ShadowCopyAction.groovy:109); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93); 	at org.codehaus.groovy.runtime.callsite.StaticMetaMethodSite$Static,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445:4713,plugin,plugins,4713,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445,1,['plugin'],['plugins']
Modifiability,b3e464b642?src=pr&el=desc) will **increase** coverage by `0.036%`.; > The diff coverage is `84.211%`. ```diff; @@ Coverage Diff @@; ## master #4960 +/- ##; ==============================================; + Coverage 80.784% 80.82% +0.036% ; - Complexity 17957 17967 +10 ; ==============================================; Files 1095 1095 ; Lines 64587 64600 +13 ; Branches 10392 10394 +2 ; ==============================================; + Hits 52176 52210 +34 ; + Misses 8388 8372 -16 ; + Partials 4023 4018 -5; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4960?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ools/funcotator/FuncotatorArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/4960/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JBcmd1bWVudERlZmluaXRpb25zLmphdmE=) | `86.364% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/utils/config/ConfigFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4960/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb25maWcvQ29uZmlnRmFjdG9yeS5qYXZh) | `77.64% <100%> (+1.242%)` | `45 <0> (ø)` | :arrow_down: |; | [...titute/hellbender/tools/funcotator/Funcotator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4960/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3IuamF2YQ==) | `90.556% <81.25%> (+4.927%)` | `53 <7> (+6)` | :arrow_up: |; | [...e/hellbender/tools/funcotator/FuncotatorUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4960/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JVdGlscy5qYXZh) | `80.491% <0%> (+0.546%)` | `170% <0%> (+2%)` | :arrow_up: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/4960/diff?src=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4960#issuecomment-400812242:1267,config,config,1267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4960#issuecomment-400812242,2,"['Config', 'config']","['ConfigFactory', 'config']"
Modifiability,broadinstitute) (9aa31e4) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/72684d0fae3326398c80e2f47d78eeff1fcc14fe?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) (72684d0) will **decrease** coverage by `0.001%`.; > The diff coverage is `100.000%`. ```diff; @@ Coverage Diff @@; ## master #7851 +/- ##; ===============================================; - Coverage 86.948% 86.947% -0.001% ; Complexity 36927 36927 ; ===============================================; Files 2219 2219 ; Lines 173673 173674 +1 ; Branches 18755 18755 ; ===============================================; - Hits 151006 151005 -1 ; + Misses 16055 16054 -1 ; - Partials 6612 6615 +3 ; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/7851?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | Coverage Δ | |; |---|---|---|; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/7851/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `97.368% <100.000%> (+0.035%)` | :arrow_up: |; | [.../hellbender/utils/python/PythonUnitTestRunner.java](https://codecov.io/gh/broadinstitute/gatk/pull/7851/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uVW5pdFRlc3RSdW5uZXIuamF2YQ==) | `75.410% <0.000%> (-3.279%)` | :arrow_down: |; | [...itute/hellbender/tools/LocalAssemblerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7851/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7851#issuecomment-1126424538:1373,Adapt,AdaptiveChainPruner,1373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7851#issuecomment-1126424538,1,['Adapt'],['AdaptiveChainPruner']
Modifiability,builds are now failing due to the changes in the artifical reads generator...I'll make them more flexible so that I can still get more random reads without breaking the other tests....,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6280#issuecomment-559244663:97,flexible,flexible,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6280#issuecomment-559244663,1,['flexible'],['flexible']
Modifiability,"c 5 12:51:17 2017 -0500. Updates to handle SAM header changes from sl_wgs_acnv_headers and updates to mb_gcnv_python_kernel. commit d02d04df684a2820308a1d1c2bfda4b7d1c5f05e; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Nov 13 12:52:33 2017 -0500. Added CLIs and WDL for python gCNV pipeline. commit 66ed74b68375d43514ef84658e7a6c771ed9053c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Nov 15 01:50:03 2017 -0500. Polished code, ready for review; ; gCNV computational kernel (initial release); ; renaming gammas_s to psi_s to uniformity (sample-specific unexplained variance); ; renamed determine_ploidy_and_depth.py to cohort_determine_ploidy_and_depth.py; finite-temperature forward-backward algorithm; in the ploidy model, replaced alpha_j (NB over-dispersion) with psi_j (unexplained variance) for uniformity. Also, added the possibility of sample-specific unexplained variance in the germline contig ploidy model; ; updated I/O routines and CLIs according to team discussion; ; updated I/O routines and CLIs according to team discussion; ; changed the output layout of the ploidy determination tool; refactored parts of io.py; upped the version to 0.3 as it is not backwards compatible anymore; ; case ploidy determination tool from a given ploidy model; major code cleanup and refactoring of I/O module; refactoring of common CLI script snippets; ; removed all ""targets""; some code cleanup; ; pad flat class bitmask w/ a given padding value in the hybrid q_c_expectation_mode; option to disable annealing and keep the temperature fixed; ; bugfix in finite-temperature forward-backward; further refactoring of model I/O; ; the option to take a previously trained model as starting point in cohort CLI; the option to take previous calls as a starting point in cohort CLI; ; option to save and load adamax moments; ; import/export adamax bias correction tensor; ; refactoring related to fancy opt I/O; added average ploidy column to read depth; updated docs of hybrid ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:11083,refactor,refactored,11083,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['refactor'],['refactored']
Modifiability,c=pr&el=desc) will **increase** coverage by `0.012%`.; > The diff coverage is `86.42%`. ```diff; @@ Coverage Diff @@; ## master #5462 +/- ##; ===============================================; + Coverage 87.075% 87.087% +0.012% ; + Complexity 31334 31225 -109 ; ===============================================; Files 1921 1915 -6 ; Lines 144602 144079 -523 ; Branches 15951 15891 -60 ; ===============================================; - Hits 125912 125474 -438 ; + Misses 12896 12834 -62 ; + Partials 5794 5771 -23; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5462?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/walkers/haplotypecaller/graphs/PathUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvUGF0aFVuaXRUZXN0LmphdmE=) | `93.258% <ø> (-0.22%)` | `7 <0> (ø)` | |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `95.349% <100%> (ø)` | `16 <0> (ø)` | :arrow_down: |; | [...ller/readthreading/ReadThreadingGraphUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaFVuaXRUZXN0LmphdmE=) | `95.238% <100%> (+0.018%)` | `55 <0> (ø)` | :arrow_down: |; | [...rs/haplotypecaller/graphs/ChainPrunerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQ2hhaW5QcnVuZXJVbml0VGVzdC5qYXZh) | `99.194% <100%> (-0.006%)` | `40 <0> (ø)` | |; | [...der/t,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5462#issuecomment-450062027:1281,Adapt,AdaptiveChainPruner,1281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5462#issuecomment-450062027,1,['Adapt'],['AdaptiveChainPruner']
Modifiability,ch 52/65; 19:36:40.808 INFO  GenomicsDBImport - Done importing batch 53/65; 20:18:42.274 INFO  GenomicsDBImport - Done importing batch 54/65; 21:01:51.304 INFO  GenomicsDBImport - Done importing batch 55/65; 21:36:00.458 INFO  GenomicsDBImport - Done importing batch 56/65; 22:08:38.587 INFO  GenomicsDBImport - Done importing batch 57/65; 22:40:44.082 INFO  GenomicsDBImport - Done importing batch 58/65; 23:14:11.202 INFO  GenomicsDBImport - Done importing batch 59/65; 23:48:23.805 INFO  GenomicsDBImport - Done importing batch 60/65; 00:20:35.869 INFO  GenomicsDBImport - Done importing batch 61/65; 00:51:47.408 INFO  GenomicsDBImport - Done importing batch 62/65; 01:25:23.587 INFO  GenomicsDBImport - Done importing batch 63/65; 01:59:03.103 INFO  GenomicsDBImport - Done importing batch 64/65; Using GATK jar /share/pkg.7/gatk/[4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar](http://4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar) defined in environment variable GATK_LOCAL_JAR; Running:;     java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx150g -Xms16g -jar /share/pkg.7/gatk/[4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar](http://4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar) GenomicsDBImport --sample-name-map sample_map.chr3 --genomicsdb-workspace-path genomicsDB.rb.chr3 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --L chr3 --batch-size 50 --bypass-feature-reader --reader-threads 5 --merge-input-intervals --overwrite-existing-genomicsdb-workspace --consolidate; [farrell@scc-hadoop genomicsdb]$ ls genomicsDB.rb.chr3; __tiledb_workspace.tdb  chr3$1$198295559  vcfheader.vcf  vidmap.json. ```; It never indicates that it imported batch 65/65. No error and the  callset.json is missing which we found in chr4 to chr22. ;   ; ls genomicsDB.rb.chr4. __tiledb_workspace.tdb  callset.json  chr4$1$1902145,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1246785232:3638,variab,variable,3638,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1246785232,1,['variab'],['variable']
Modifiability,closing - refactoring to one WDL,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7112#issuecomment-786760463:10,refactor,refactoring,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7112#issuecomment-786760463,1,['refactor'],['refactoring']
Modifiability,"cotationFactory.createDefaultFuncotationsOnVariant(GencodeFuncotationFactory.java:499); 22 Jun 2023 14:54:27,163 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:217); 22 Jun 2023 14:54:27,164 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 22 Jun 2023 14:54:27,166 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); 22 Jun 2023 14:54:27,167 DEBUG: 		at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197); 22 Jun 2023 14:54:27,168 DEBUG: 		at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179); 22 Jun 2023 14:54:27,170 DEBUG: 		at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625); 22 Jun 2023 14:54:27,171 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509); 22 Jun 2023 14:54:27,172 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499); 22 Jun 2023 14:54:27,174 DEBUG: 		at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:921); 22 Jun 2023 14:54:27,175 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 22 Jun 2023 14:54:27,177 DEBUG: 		at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682); 22 Jun 2023 14:54:27,178 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); 22 Jun 2023 14:54:27,180 DEBUG: 		at com.github.discvrseq.walkers.ExtendedFuncotator.enqueueAndHandleVariant(ExtendedFuncotator.java:209); 22 Jun 2023 14:54:27,181 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226:3423,Extend,ExtendedFuncotator,3423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226,2,['Extend'],['ExtendedFuncotator']
Modifiability,"ctory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the -- will be passed to dataproc; --cluster <your-cluster> must be specified after the --; spark properties and some common spark-submit parameters will be translated; to dataproc equivalents. --dry-run may be specified to output the generated command line without running it; --java-options 'OPTION1[ OPTION2=Y ... ]' optional - pass the given string of options to the; java JVM at runtime.; Java options MUST be passed inside a single string with space-separated values.; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:1429,Config,Configuration,1429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030,2,"['Config', 'config']","['Configuration', 'config-file']"
Modifiability,"cuting as myname@ln14 on Linux 3.10.0-514.16.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b15; Version: 4.alpha.2-1125-g27b5190-SNAPSHOT; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4504,variab,variable,4504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['variab'],['variable']
Modifiability,cy93YWxrZXJzL3Zxc3Ivc2NhbGFibGUvVHJhaW5WYXJpYW50QW5ub3RhdGlvbnNNb2RlbC5qYXZh) | `77.778% <0.000%> (-2.991%)` | :arrow_down: |; | [...bender/utils/runtime/AsynchronousStreamWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/8092?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL0FzeW5jaHJvbm91c1N0cmVhbVdyaXRlci5qYXZh) | `81.633% <0.000%> (-2.041%)` | :arrow_down: |; | [...ct/CreateSomaticPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/8092?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `96.396% <0.000%> (-1.305%)` | :arrow_down: |; | [...stitute/hellbender/utils/config/ConfigFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/8092?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb25maWcvQ29uZmlnRmFjdG9yeS5qYXZh) | `73.750% <0.000%> (-1.250%)` | :arrow_down: |; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/8092?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `86.260% <0.000%> (-0.999%)` | :arrow_down: |; | [...org/broadinstitute/hellbender/utils/MathUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/8092?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8092#issuecomment-1374581874:4557,config,config,4557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8092#issuecomment-1374581874,2,"['Config', 'config']","['ConfigFactory', 'config']"
Modifiability,"d I think things look good from this perspective, at least. This tieout uses a subset of the Pf7 samples containing 300 cohort and 1683 case samples (which were indeed treated as a cohort-case cluster in the original Pf7 CNV genotyping analysis). ~4k genomic bins are covered. We compare this branch against 4.5.0.0, as well as this branch against itself (checking for reproducibility). Costs for this branch ($10.92) and 4.5.0.0 ($10.96) were quite comparable. Note that a small portion of these costs derives from Pf7-specific genotyping steps, which I did not bother to remove from the workflow. Runtime for the ploidy modeling and postprocessing steps were comparable. Interestingly, **runtime for the gCNV was ~20-25% longer with this branch than with 4.5.0.0, but memory usage fell by a factor of ~3 (~6GB to ~2GB)!** I am not sure if we could recoup the runtime with some more tweaking of the environment (perhaps double checking that optimized BLAS/MKL/etc. packages are properly used, changing environment variables/flags, etc.), but I think the decrease in memory usage is quite nice. Concordance was checked for the following quantities (4.5.0.0 is on the x-axis and this branch is on the y-axis in all plots below):. 1) Variational posterior means (`mu_*`) and standard deviations (`std_*`) for all analogous variables in the ploidy and gCNV models. There were some slight changes to the gCNV model in this branch (e.g., the functional form of the ARD prior was changed), which means some variables are no longer directly comparable. Furthermore, some variables (such as the bias factors W) are degenerate and cannot be immediately compared. Otherwise, there is good concordance between the remaining variables, e.g.:. ![image](https://github.com/broadinstitute/gatk/assets/11076296/614cf501-ca31-4199-badb-3194b7f78154); ![image](https://github.com/broadinstitute/gatk/assets/11076296/f615084d-d0bf-44e9-bcf5-98abd26ceb06); ![image](https://github.com/broadinstitute/gatk/assets/11076296/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2079695268:1085,variab,variables,1085,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2079695268,1,['variab'],['variables']
Modifiability,"d be in a separate commit that we can just delete at the end, but that can get unwieldy if the files in the commit need to change as we go along. Alternatively you could isolate them into a separate directory. They should either be disabled or made dependent on a test method (see the `@Test` annotation properties `enabled` and `dependsOn`) that is easily toggled so they can be run locally, but don't run on the CI server. Otherwise the CI server build will always fail. In general, its really helpful to have the first commit in the PR contain the completely unmodified GATK3 source files. It makes it much easier for the reviewer to see what changed for the port. I noticed that you have 2 new plugins included in this. I'm not sure if that was suggested by someone on the GATK team (I'm wondering if we want to go down that path...) but I can tell you that the existing plugins required an enormous amount of test development and review iteration. If we do decide to make them plugins, I think it would be a good idea to do so in a separate PR. Also, if we choose to make an AbstractPlugin base class, we may want that to live in the Barclay repo. As @magicdgs points out, master already has your previous commits, so you should start by rebasing on that. Ideally, the branch would have the following commits before we start the first review cycle:. 1. A single commit containing the unmodified GATK3 source (unmodified with the exception that if a file is renamed for GATK4, its helpful to rename the GATK3 version in this commit so it's easy to compare in the next commit). This commit doesn't have to compile or run - its just to make the review process easier for us, and will be deleted at some point. I can help with how to get this into your branch if you like.; 2. Your modified GATK3 tests in a single commit. This will also be removed before merge.; 3. A single commit with all of your ""minimal"" changes for the port, including the real, new tests. This should compile, and tests should",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352:1888,plugin,plugins,1888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352,2,['plugin'],['plugins']
Modifiability,"dGraph only allows a single annotation/track. I'm not sure if the track definition line is intended to hold any metadata other than display parameters, either? https://genome.ucsc.edu/goldenPath/help/bedgraph.html. As for the unmarked column header line, the reason I decided this would be useful in the CNV TSV formats is that it's very easy to throw the table into a pandas or R dataframe for quick analysis, where you can then use the column names to manipulate the table. Typically, pandas/R TSV loading methods let you specify the `@` comment character to strip the SAM header (although we recently ran into some trouble with this in https://github.com/broadinstitute/gatk/pull/581). Note that we *require* a single unmarked column header, which is easy enough to skip (in the case you don't want to use it) if you know it's there. On the other hand, one could argue that if we store the type of each column in the metadata, then any analysis code should technically use that to parse the table (rather than letting pandas/R automatically infer the type of each column). So a marked column header line would make quick analyses a bit more difficult (as users would need to write parsing code), but could encourage more careful downstream code practices. @SHuang-Broad Just to be clear, the way I originally used ""annotation"" refers to any quantity that could be represented by a single type in a column (not in the sense of variant annotation). If string types are allowed, this is indeed pretty flexible! All I care about extracting is the common functionality related to the fact that we have locatable columns. I think the concerns you raise about e.g. SV representation in VCF are a separate matter, but happy to discuss further. I think once we decide what the header needs to be able to represent and what it should look like, this problem is mostly solved. There may be some things to decide about e.g. representation of doubles, NaNs, etc. but I don't think we need to be too rigid here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480917329:1644,flexible,flexible,1644,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480917329,2,['flexible'],['flexible']
Modifiability,"e GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use directly something like the Spring framework, but I think that it is quite complicated for API users without knowledge of Spring (like me).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:2071,config,configuration,2071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['config'],['configuration']
Modifiability,"eCaller.java b/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; index cf34b1fb4e..2ee5752f04 100644; --- a/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; +++ b/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; @@ -497,10 +497,11 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; protected boolean mergeVariantsViaLD = false;; ; @Advanced; - @Argument(fullName=""tryPhysicalPhasing"", shortName=""tryPhysicalPhasing"", doc=""If specified, we will add physical (read-based) phasing information"", required = false); - protected boolean tryPhysicalPhasing = false;; + @Argument(fullName=""doNotRunPhysicalPhasing"", shortName=""doNotRunPhysicalPhasing"", doc=""If specified, we will not try to add physical (read-based) phasing information"", required = false); + protected boolean doNotRunPhysicalPhasing = false;; ; - public static final String HAPLOTYPE_CALLER_PHASING_KEY = ""HCP"";; + public static final String HAPLOTYPE_CALLER_PHASING_ID_KEY = ""PID"";; + public static final String HAPLOTYPE_CALLER_PHASING_GT_KEY = ""PGT"";; ; // -----------------------------------------------------------------------------------------------; // arguments for debugging / developing the haplotype caller; @@ -634,12 +635,11 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if ( emitReferenceConfidence() ) {; ; if (SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES); - throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and Genotyping Giving Alleles at the same time"");; + throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and GENOTYPE_GIVEN_ALLELES at the same time"");; ; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:1232,extend,extends,1232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237,2,['extend'],['extends']
Modifiability,"e_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600 --jar gs://hellbender-test-logs/staging/gatk-package-4.1.0.0-24-g18a95c7-SNAPSHOT-spark_3e9078b7e67707952fa12a0c5c4d2b71.jar -- PrintVariantsSpark --V gs://hellbender/test/resources/large/gvcfs/gatk3.7_30_ga4f720357.24_sample.21.expected.vcf --output gs://hellbender-test-logs/staging/12dc38b0-0b40-49d5-a98e-fe83ca658003.vcf --spark-master yarn; Job [654b5b8e01de4c60bd87d941d4ec8831] submitted.; Waiting for job output...; 19/02/18 16:58:03 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 16:58:09.526 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 16:58:09.705 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/tmp/654b5b8e01de4c60bd87d941d4ec8831/gatk-package-4.1.0.0-24-g18a95c7-SNAPSHOT-spark_3e9078b7e67707952fa12a0c5c4d2b71.jar!/com/intel/gkl/native/libgkl_compression.so; 16:58:10.112 INFO PrintVariantsSpark - ------------------------------------------------------------; 16:58:10.113 INFO PrintVariantsSpark - The Genome Analysis Toolkit (GATK) v4.1.0.0-24-g18a95c7-SNAPSHOT; 16:58:10.113 INFO PrintVariantsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:58:10.113 INFO PrintVariantsSpark - Executing as root@gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m on Linux v4.9.0-8-amd64 amd64; 16:58:10.114 INFO PrintVariantsSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_181-8u181-b13-2~deb9u1-b13; 16:58:10.114 INFO PrintVariantsSpark - Start Date/Time: February 18, 2019 4:58:09 PM",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:1514,variab,variables,1514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,2,"['config', 'variab']","['configured', 'variables']"
Modifiability,"eano/compile/__init__.py"", line 10, in <module>; from theano.compile.function_module import *; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 21, in <module>; import theano.compile.mode; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/mode.py"", line 10, in <module>; import theano.gof.vm; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/vm.py"", line 662, in <module>; from . import lazylinker_c; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 42, in <module>; location = os.path.join(config.compiledir, 'lazylinker_ext'); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configparser.py"", line 333, in __get__; self.__set__(cls, val_str); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configparser.py"", line 344, in __set__; self.val = self.filter(val); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configdefaults.py"", line 1745, in filter_compiledir; "" '%s'. Check the permissions."" % path); ValueError: Unable to create the compiledir directory '/root/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64'. Check the permissions. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeCommand(PythonScriptExecutor.java:79); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:192); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.onStartup(DetermineGermlineContigPloidy.java:269); at org.broadinstitute.hell",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081:5142,config,configdefaults,5142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081,1,['config'],['configdefaults']
Modifiability,ed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist[0K; 2022-08-16T00:09:07.4435974Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T00:09:07.4436105Z @VisibleForTesting; 2022-08-16T00:09:07.4436380Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4436641Z location: class CommandLineProgram; 2022-08-16T00:09:07.4436930Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:120: error: cannot find symbol; 2022-08-16T00:09:07.4437094Z @VisibleForTesting; 2022-08-16T00:09:07.4437369Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4437519Z location: class FeatureInput<T>; 2022-08-16T00:09:07.4437725Z where T is a type-variable:; 2022-08-16T00:09:07.4437925Z T extends Feature declared in class FeatureInput; 2022-08-16T00:09:07.4438276Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:251: error: cannot find symbol; 2022-08-16T00:09:07.4438417Z @VisibleForTesting; 2022-08-16T00:09:07.4438677Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4438873Z location: class PosteriorProbabilitiesUtils; 2022-08-16T00:09:07.4439223Z src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/PosteriorProbabilitiesUtils.java:271: error: cannot find symbol; 2022-08-16T00:09:07.4439362Z @VisibleForTesting; 2022-08-16T00:09:07.4439618Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4439806Z location: class PosteriorProbabilitiesUtils; 2022-08-16T00:09:07.4465668Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/DefaultGATKVariantAnnotationArgumentCollection.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4466113Z [done in 2417 ms]; 2022-08-16T00:09:07.4466222Z ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:20885,extend,extends,20885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['extend'],['extends']
Modifiability,ed-websocket\9.0.35\tomcat-embed-websocket-9.0.35.jar;E:\repository\org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\firebase\firebase-admin\6.8.1\firebase-admin-6.8.1.jar;E:\repository\com\google\api-client\google-api-client\1.25.0\google-api-client-1.25.0.jar;E:\repository\com\google\oauth-client\google-oauth-client\1.25.0\google-oauth-client-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-jackson2\1.25.0\google-http-client-jackson2-1.25.0.jar;E:\repository\com\google\api-client\google-api-client-gson\1.25.0\google-api-client-gson-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-gson\1.25.0\google-http-client-gson-1.25.0.jar;E:\repository\com\google\code\gson\gson\2.8.6\gson-2.8.6.jar;E:\repository\com\google\http-client\google-http-client\1.25.0\google-http-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:5458,config,configuration-processor,5458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['config'],['configuration-processor']
Modifiability,"er and -consolidate; 2. With --bypass-feature-reader; 3. With --consolidate without --bypass-feature-reader (This ended up on a node with 384gb.) The other ran on 256GB nodes. . Test 2 ran the fastest with the lowest memory requirements (Wall clock 76 hours); Test 1 ran slower and required more memory 40-50% of 256GB (Wall Clock 94 hours); Test 3 ran initially faster with less memory than test 1 but by batch 65 it was using 75% of 384 GB. This job has not finished and appears stuck on importing batch 65. So the consolidate option appears to have a memory leak or using just requiring too much memory. The -consolidate option was the culprit. So rerunning chr1-3 with just the --bypass-feature-reader option (test2) ran fine without lots of memory being used. Below is the time output from chr1. The output shows the Maximum resident set size (kbytes): **2630440**. Using GATK jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar defined in environment variable GATK_LOCAL_JAR; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx200g -Xms16g -jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reader-threads 4 --overwrite-existing-genomicsdb-workspace; Command being timed: ""gatk --java-options -Xmx200g -Xms16g GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reader-threads 4 --overwrite-existing-genomicsdb-workspace""; User time (seconds): 270716.45; System time (seconds): 1723.34; Percent of CPU this job go",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687:1474,variab,variable,1474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687,2,['variab'],['variable']
Modifiability,erArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWFkVGhyZWFkaW5nQXNzZW1ibGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `94.118% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `76.923% <ø> (-0.946%)` | `34 <0> (-1)` | |; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `78.425% <100%> (ø)` | `76 <0> (ø)` | :arrow_down: |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `95.349% <100%> (+0.111%)` | `16 <0> (ø)` | :arrow_down: |; | [...hellbender/tools/walkers/mutect/Mutect2Engine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `90.173% <100%> (ø)` | `65 <0> (ø)` | :arrow_down: |; | [...otypecaller/HaplotypeCallerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (ø)` | `3 <1> (+1)` | :arrow_up: |; | [...r/tools/walkers/mutect/Mutect2Integrati,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5544#issuecomment-449424951:2272,Adapt,AdaptiveChainPruner,2272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5544#issuecomment-449424951,1,['Adapt'],['AdaptiveChainPruner']
Modifiability,erce.invoke(StaticMetaMethodSite.java:151); 	at org.codehaus.groovy.runtime.callsite.StaticMetaMethodSite.callStatic(StaticMetaMethodSite.java:102); 	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:214); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction.execute(ShadowCopyAction.groovy:75); 	at org.gradle.api.internal.file.copy.NormalizingCopyActionDecorator.execute(NormalizingCopyActionDecorator.java:53); 	at org.gradle.api.internal.file.copy.DuplicateHandlingCopyActionDecorator.execute(DuplicateHandlingCopyActionDecorator.java:42); 	at org.gradle.api.internal.file.copy.CopyActionExecuter.execute(CopyActionExecuter.java:40); 	at org.gradle.api.tasks.AbstractCopyTask.copy(AbstractCopyTask.java:174); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar.copy(ShadowJar.java:70); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:73); 	at org.gradle.api.internal.project.taskfactory.StandardTaskAction.doExecute(StandardTaskAction.java:46); 	at org.gradle.api.internal.project.taskfactory.StandardTaskAction.execute(StandardTaskAction.java:39); 	at org.gradle.api.internal.project.taskfactory.StandardTaskAction.execute(StandardTaskAction.java:26); 	at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:788); 	at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:755); 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$1.run(ExecuteActi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445:6739,plugin,plugins,6739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445,1,['plugin'],['plugins']
Modifiability,ering/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvTXV0ZWN0MkZpbHRlcmluZ0VuZ2luZS5qYXZh) | `97.115% <100%> (+0.057%)` | `43 <0> (ø)` | :arrow_down: |; | [.../mutect/filtering/M2FiltersArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvTTJGaWx0ZXJzQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `93.75% <100%> (+0.417%)` | `6 <0> (ø)` | :arrow_down: |; | [...kers/mutect/filtering/MinAlleleFractionFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvTWluQWxsZWxlRnJhY3Rpb25GaWx0ZXIuamF2YQ==) | `100% <100%> (ø)` | `7 <7> (?)` | |; | [...e/hellbender/utils/variant/GATKVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `94.886% <100%> (+0.029%)` | `11 <0> (ø)` | :arrow_down: |; | [...alkers/mutect/filtering/PolymorphicNuMTFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvUG9seW1vcnBoaWNOdU1URmlsdGVyLmphdmE=) | `88.235% <88.235%> (ø)` | `9 <9> (?)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `87.309% <0%> (-0.306%)` | `244% <0%> (-2%)` | |; | ... and [10 more](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477635851:3450,Polymorphi,PolymorphicNuMTFilter,3450,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477635851,1,['Polymorphi'],['PolymorphicNuMTFilter']
Modifiability,"erval_list=/tmp/intervals9016836733228000464.tsv --contig_ploidy_prior_table=/home/n.liorni/snakemake_cnv_gatk/resources/contig_ploidy_priors.tsv --output_model_path=/home/n.liorni/snakemake_cnv_gatk/results/cnv/ploidy/ploidy-model; Stdout: 15:09:46.970 INFO cohort_determine_ploidy_and_depth - THEANO_FLAGS environment variable has been set to: device=cpu,floatX=float64,optimizer=fast_run,compute_test_value=ignore,openmp=true,blas.ldflags=-lmkl_rt,openmp_elemwise_minsize=10; 15:09:47.017 INFO gcnvkernel.structs.metadata - Generating intervals metadata...; 15:09:47.024 INFO gcnvkernel.tasks.task_cohort_ploidy_determination - Instantiating the germline contig ploidy determination model...; 15:09:50.320 INFO gcnvkernel.tasks.task_cohort_ploidy_determination - Instantiating the ploidy emission sampler...; 15:09:50.321 INFO gcnvkernel.tasks.task_cohort_ploidy_determination - Instantiating the ploidy caller...; 15:09:50.957 INFO gcnvkernel.models.fancy_model - Global model variables: {'psi_j_log__', 'mean_bias_j_lowerbound__'}; 15:09:50.957 INFO gcnvkernel.models.fancy_model - Sample-specific model variables: {'psi_s_log__'}; 15:09:50.957 INFO gcnvkernel.tasks.inference_task_base - Instantiating the convergence tracker...; 15:09:50.958 INFO gcnvkernel.tasks.inference_task_base - Setting up DA-ADVI...; 15:10:03.310 INFO gcnvkernel.tasks.inference_task_base - (denoising) starting...: 0%| | 0/1000 [00:00<?, ?it/s]; 15:10:03.410 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -1038.498 +/- 431.707, SNR: 71.3, T: 1.98: 8%|8 | 83/1000 [00:00<00:01, 826.53it/s]; 15:10:03.522 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -821.262 +/- 327.042, SNR: 38.9, T: 1.97: 17%|#6 | 166/1000 [00:00<00:01, 776.56it/s]; 15:10:03.636 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -727.432 +/- 277.971, SNR: 29.4, T: 1.95: 24%|##4 | 244/1000 [00:00<00:01, 732.12it/s]; 15:10:03.754 INFO gcnvkernel.tasks.inference_task_base - (deno",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:7364,variab,variables,7364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['variab'],['variables']
Modifiability,"es can be specified as:; ./. .. completely missing (""."" or ""./."", depending on ploidy); ./x .. partially missing (e.g., ""./0"" or "".|1"" but not ""./.""); . .. partially or completely missing; a .. all genotypes; b .. heterozygous genotypes failing two-tailed binomial test (example below); q .. select genotypes using -i/-e options; and the new genotype can be one of:; . .. missing (""."" or ""./."", keeps ploidy); 0 .. reference allele (e.g. 0/0 or 0, keeps ploidy); c:GT .. custom genotype (e.g. 0/0, 0, 0/1, m/M, overrides ploidy); m .. minor (the second most common) allele (e.g. 1/1 or 1, keeps ploidy); M .. major allele (e.g. 1/1 or 1, keeps ploidy); p .. phase genotype (0/1 becomes 0|1); u .. unphase genotype and sort by allele (1|0 becomes 0/1); Usage: bcftools +setGT [General Options] -- [Plugin Options]; Options:; run ""bcftools plugin"" for a list of common options. Plugin options:; -e, --exclude <expr> Exclude a genotype if true (requires -t q); -i, --include <expr> include a genotype if true (requires -t q); -n, --new-gt <type> Genotypes to set, see above; -t, --target-gt <type> Genotypes to change, see above. Example:; # set missing genotypes (""./."") to phased ref genotypes (""0|0""); bcftools +setGT in.vcf -- -t . -n 0p. # set missing genotypes with DP>0 and GQ>20 to ref genotypes (""0/0""); bcftools +setGT in.vcf -- -t q -n 0 -i 'GT=""."" && FMT/DP>0 && GQ>20'. # set partially missing genotypes to completely missing; bcftools +setGT in.vcf -- -t ./x -n . # set heterozygous genotypes to 0/0 if binom.test(nAlt,nRef+nAlt,0.5)<1e-3; bcftools +setGT in.vcf -- -t ""b:AD<1e-3"" -n 0. # force unphased heterozygous genotype if binom.test(nAlt,nRef+nAlt,0.5)>0.1; bcftools +setGT in.vcf -- -t ./x -n c:'m/M'; ```; I was always wondering if GATK will have a plugin interface where people can code their own using groovy, kotlin, javascript or python plugins to extend some of the functionality where developers may not reach immediately. Personally I use htsjdk extensively (and sometimes p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501:1030,Plugin,Plugin,1030,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501,1,['Plugin'],['Plugin']
Modifiability,eshold 0.5 --pileup-detection-absolute-alt-depth 0.0 --pileup-detection-snp-adjacent-to-assembled-indel-range 5 --pileup-detection-bad-read-tolerance 0.0 --pileup-detection-pro; per-pair-read-badness true --pileup-detection-edit-distance-read-badness-threshold 0.08 --pileup-detection-chimeric-read-badness true --pileup-detection-template-mean-badness-threshold 0.0; --pileup-detection-template-std-badness-threshold 0.0 --bam-writer-type CALLED_HAPLOTYPES --dont-use-soft-clipped-bases false --override-fragment-softclip-check false --min-base-quality-s; core 10 --smith-waterman JAVA --max-mnp-distance 0 --force-call-filtered-alleles false --reference-model-deletion-quality 30 --soft-clip-low-quality-ends false --allele-informative-reads-o; verlap-margin 2 --smith-waterman-dangling-end-match-value 25 --smith-waterman-dangling-end-mismatch-penalty -50 --smith-waterman-dangling-end-gap-open-penalty -110 --smith-waterman-danglin; g-end-gap-extend-penalty -6 --smith-waterman-haplotype-to-reference-match-value 200 --smith-waterman-haplotype-to-reference-mismatch-penalty -150 --smith-waterman-haplotype-to-reference-ga; p-open-penalty -260 --smith-waterman-haplotype-to-reference-gap-extend-penalty -11 --smith-waterman-read-to-haplotype-match-value 10 --smith-waterman-read-to-haplotype-mismatch-penalty -15; --smith-waterman-read-to-haplotype-gap-open-penalty -30 --smith-waterman-read-to-haplotype-gap-extend-penalty -5 --flow-assembly-collapse-hmer-size 0 --flow-assembly-collapse-partial-mode; false --flow-filter-alleles false --flow-filter-alleles-qual-threshold 30.0 --flow-filter-alleles-sor-threshold 3.0 --flow-filter-lone-alleles false --flow-filter-alleles-debug-graphs fal; se --min-assembly-region-size 50 --max-assembly-region-size 300 --active-probability-threshold 0.002 --max-prob-propagation-distance 50 --force-active false --assembly-region-padding 100 -; -padding-around-indels 75 --padding-around-snps 20 --padding-around-strs 75 --max-extension-into-assembly-region-pa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789:7749,extend,extend-penalty,7749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789,3,['extend'],['extend-penalty']
Modifiability,feCycle.doStart(ContainerLifeCycle.java:105); at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61); at org.eclipse.jetty.server.Server.doStart(Server.java:394); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1155); at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:181); at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:885); at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:707); at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:953); at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:926); at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1692); at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1314); at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1083); at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:958); at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:890); at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:518); at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:477); at org.broadinstitute.hellbender.testutils.MiniClusterUtils.getMiniCluster(MiniClusterUtils.java:30); at org.broadinstitute.hellbender.testutils.MiniClusterUtils.getMiniCluster(MiniClusterUtils.java:38); at org.broadinstitute.hellbender.metrics.MetricsUtilsTest.setupMiniCluster(MetricsUtilsTest.java:24). Caused by:; java.lang.IllegalArgumentException: Invalid Java version 11.0.16.1; at org.eclipse.jetty.util.JavaVersion.parseJDK9(JavaVersion.java:71); at org.eclipse.jetty.util.JavaVersion.parse(JavaVersion.java:49); at org.eclipse.jetty.util.JavaVersion.<clinit>(JavaVersion.java:[43](https://github.com/broadinstitute/gatk/action,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8098#issuecomment-1320505279:2385,config,configureNameService,2385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8098#issuecomment-1320505279,1,['config'],['configureNameService']
Modifiability,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6298,variab,variable,6298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,2,['variab'],['variable']
Modifiability,ge Δ | Complexity Δ | |; |---|---|---|---|; | [...r/tools/walkers/mutect/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRmlsdGVyaW5nRW5naW5lLmphdmE=) | `80.743% <0%> (-4.581%)` | `89% <0%> (ø)` | |; | [...ute/hellbender/utils/test/FuncotatorTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Z1bmNvdGF0b3JUZXN0VXRpbHMuamF2YQ==) | `95.161% <0%> (-3.084%)` | `7% <0%> (+1%)` | |; | [...GATKPlugin/GATKReadFilterPluginDescriptorTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yVGVzdC5qYXZh) | `88.62% <0%> (-1.76%)` | `48% <0%> (+1%)` | |; | [...Plugin/GATKAnnotationPluginDescriptorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yVW5pdFRlc3QuamF2YQ==) | `88.235% <0%> (-1.43%)` | `58% <0%> (+1%)` | |; | [.../tools/walkers/haplotypecaller/RefVsAnyResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZWc0FueVJlc3VsdC5qYXZh) | `100% <0%> (ø)` | `3% <0%> (+1%)` | :arrow_up: |; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `91.304% <0%> (ø)` | `70% <0%> (ø)` | :arrow_down: |; | [...line/GATKPlugin/testpluggables/TestAnnotation.java](https:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310:1862,Plugin,Plugin,1862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310,1,['Plugin'],['Plugin']
Modifiability,gradle.api.internal.file.copy.NormalizingCopyActionDecorator$1.process(NormalizingCopyActionDecorator.java:57); 	at org.gradle.api.internal.file.copy.CopyActionProcessingStream$process.call(Unknown Source); 	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction$1.execute(ShadowCopyAction.groovy:78); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction$1$execute.call(Unknown Source); 	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction.withResource(ShadowCopyAction.groovy:109); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93); 	at org.codehaus.groovy.runtime.callsite.StaticMetaMethodSite$StaticMetaMethodSiteNoUnwrapNoCoerce.invoke(StaticMetaMethodSite.java:151); 	at org.codehaus.groovy.runtime.callsite.StaticMetaMethodSite.callStatic(StaticMetaMethodSite.java:102); 	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:214); 	at com.github.jen,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445:5197,plugin,plugins,5197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445,1,['plugin'],['plugins']
Modifiability,hadowCopyAction.withResource(ShadowCopyAction.groovy:109); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93); 	at org.codehaus.groovy.runtime.callsite.StaticMetaMethodSite$StaticMetaMethodSiteNoUnwrapNoCoerce.invoke(StaticMetaMethodSite.java:151); 	at org.codehaus.groovy.runtime.callsite.StaticMetaMethodSite.callStatic(StaticMetaMethodSite.java:102); 	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallStatic(CallSiteArray.java:56); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:194); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callStatic(AbstractCallSite.java:214); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction.execute(ShadowCopyAction.groovy:75); 	at org.gradle.api.internal.file.copy.NormalizingCopyActionDecorator.execute(NormalizingCopyActionDecorator.java:53); 	at org.gradle.api.internal.file.copy.DuplicateHandlingCopyActionDecorator.execute(DuplicateHandlingCopyActionDecorator.java:42); 	at org.gradle.api.internal.file.copy.CopyActionExecuter.execute(CopyActionExecuter.java:40); 	at org.gradle.api.tasks.AbstractCopyTask.copy(AbstractCopyTask.java:174); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar.copy(ShadowJar.java:70); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:73); 	at org.gradle.api.internal.project.taskfactory.StandardTask,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445:6215,plugin,plugins,6215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445,1,['plugin'],['plugins']
Modifiability,hc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `80.172% <ø> (ø)` | `19 <0> (ø)` | :arrow_down: |; | [...tute/hellbender/tools/AnnotatePairOrientation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Bbm5vdGF0ZVBhaXJPcmllbnRhdGlvbi5qYXZh) | `96.429% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...nder/tools/copynumber/utils/TagGermlineEvents.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL1RhZ0dlcm1saW5lRXZlbnRzLmphdmE=) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...t/java/org/broadinstitute/hellbender/MainTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluVGVzdC5qYXZh) | `85.714% <90.909%> (+2.787%)` | `15 <9> (+9)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ender/tools/walkers/annotator/PolymorphicNuMT.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9Qb2x5bW9ycGhpY051TVQuamF2YQ==) | `92.593% <0%> (-3.704%)` | `8% <0%> (-1%)` | |; | [...r/tools/walkers/mutect/Mutect2IntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QySW50ZWdyYXRpb25UZXN0LmphdmE=) | `87.586% <0%> (-0.517%)` | `89% <0%> (-2%)` | |; | ... and [13 more](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-450184780:3447,Polymorphi,PolymorphicNuMT,3447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-450184780,1,['Polymorphi'],['PolymorphicNuMT']
Modifiability,"ies = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:39:19 INFO SparkContext: Running Spark version 2.2.0; 18/04/24 17:39:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes whe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:6149,Config,ConfigFactory,6149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"ility). Costs for this branch ($10.92) and 4.5.0.0 ($10.96) were quite comparable. Note that a small portion of these costs derives from Pf7-specific genotyping steps, which I did not bother to remove from the workflow. Runtime for the ploidy modeling and postprocessing steps were comparable. Interestingly, **runtime for the gCNV was ~20-25% longer with this branch than with 4.5.0.0, but memory usage fell by a factor of ~3 (~6GB to ~2GB)!** I am not sure if we could recoup the runtime with some more tweaking of the environment (perhaps double checking that optimized BLAS/MKL/etc. packages are properly used, changing environment variables/flags, etc.), but I think the decrease in memory usage is quite nice. Concordance was checked for the following quantities (4.5.0.0 is on the x-axis and this branch is on the y-axis in all plots below):. 1) Variational posterior means (`mu_*`) and standard deviations (`std_*`) for all analogous variables in the ploidy and gCNV models. There were some slight changes to the gCNV model in this branch (e.g., the functional form of the ARD prior was changed), which means some variables are no longer directly comparable. Furthermore, some variables (such as the bias factors W) are degenerate and cannot be immediately compared. Otherwise, there is good concordance between the remaining variables, e.g.:. ![image](https://github.com/broadinstitute/gatk/assets/11076296/614cf501-ca31-4199-badb-3194b7f78154); ![image](https://github.com/broadinstitute/gatk/assets/11076296/f615084d-d0bf-44e9-bcf5-98abd26ceb06); ![image](https://github.com/broadinstitute/gatk/assets/11076296/48570e53-024c-44b5-8835-3fd40b4c5866); ![image](https://github.com/broadinstitute/gatk/assets/11076296/99100e5d-05e2-4a5c-9d68-57db1b734029); ![image](https://github.com/broadinstitute/gatk/assets/11076296/abae09e1-70a5-4213-95a2-0cb10f9db192); ![image](https://github.com/broadinstitute/gatk/assets/11076296/ef68d0da-90df-4c4b-9802-97988a498280). 2) ... Will update more later!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2079695268:1571,variab,variables,1571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2079695268,3,['variab'],['variables']
Modifiability,"ingframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550); 	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:143); 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758); 	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750); 	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397); 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315); 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1237); 	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226); 	at com.luz.push.PushApplication.main(PushApplication.java:10). java.io.IOException: The Application Default Credentials are not available. They are available if running in Google Compute Engine. Otherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.; 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:131); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); 	at com.luz.push.utils.GcmUtils.init(GcmUtils.java:31); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389); 	at org.springf",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:28788,variab,variable,28788,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['variab'],['variable']
Modifiability,"ission_sampling_median_rel_error=5.000000e-03 --max_advi_iter_first_epoch=5000 --max_advi_iter_subsequent_epochs=200 --min_training_epochs=10 --max_training_epochs=50 --initial_temperature=1.500000e+00 --num_thermal_advi_iters=2500 --convergence_snr_averaging_window=500 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=10 --caller_update_convergence_threshold=1.000000e-03 --caller_internal_admixing_rate=7.500000e-01 --caller_external_admixing_rate=1.000000e+00 --disable_caller=false --disable_sampler=false --disable_annealing=false; Stdout: 14:13:50.032 INFO cohort_denoising_calling - Loading 24 read counts file(s)...; 14:13:53.719 INFO gcnvkernel.io.io_metadata - Loading germline contig ploidy and global read depth metadata...; 14:13:58.626 INFO gcnvkernel.tasks.task_cohort_denoising_calling - Instantiating the denoising model (warm-up)...; 14:14:04.543 INFO gcnvkernel.models.fancy_model - Global model variables: {'W_tu', 'psi_t_log__', 'ard_u_log__', 'log_mean_bias_t'}; 14:14:04.544 INFO gcnvkernel.models.fancy_model - Sample-specific model variables: {'z_su', 'psi_s_log__', 'read_depth_s_log__'}; 14:14:04.544 WARNING gcnvkernel.tasks.inference_task_base - No log emission sampler given; skipping the sampling step; 14:14:04.544 WARNING gcnvkernel.tasks.inference_task_base - No caller given; skipping the calling step; 14:14:04.544 INFO gcnvkernel.tasks.inference_task_base - Instantiating the convergence tracker...; 14:14:04.544 INFO gcnvkernel.tasks.inference_task_base - Setting up DA-ADVI...; 14:14:10.902 INFO gcnvkernel.tasks.inference_task_base - (denoising (warm-up)) starting...: 0%| | 0/5000 [00:00<?, ?it/s]; 14:14:12.877 INFO gcnvkernel.tasks.inference_task_base - (denoising (warm-up) epoch 1) ELBO: N/A, SNR: N/A, T: 1.50: 0%| | 1/5000 [00:01<2:44:32, 1.97s/it]; 14:14:14.753 INFO gcnvkernel.tasks.inference_task_base - (denoising (warm-up) epoch 1) ELBO: -145.294 +/- 0.000, SNR: 35869952999211676.0, T: 1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-467406398:3556,variab,variables,3556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-467406398,1,['variab'],['variables']
Modifiability,java:650); 	at org.gradle.api.internal.file.copy.DefaultCopySpec.walk(DefaultCopySpec.java:458); 	at org.gradle.api.internal.file.copy.CopySpecBackedCopyActionProcessingStream.process(CopySpecBackedCopyActionProcessingStream.java:38); 	at org.gradle.api.internal.file.copy.DuplicateHandlingCopyActionDecorator$1.process(DuplicateHandlingCopyActionDecorator.java:44); 	at org.gradle.api.internal.file.copy.NormalizingCopyActionDecorator$1.process(NormalizingCopyActionDecorator.java:57); 	at org.gradle.api.internal.file.copy.CopyActionProcessingStream$process.call(Unknown Source); 	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction$1.execute(ShadowCopyAction.groovy:78); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction$1$execute.call(Unknown Source); 	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:48); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:113); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction.withResource(ShadowCopyAction.groovy:109); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:93); 	at org.codehaus.groovy.runtime.callsite.StaticMetaMethodSite$StaticMetaMethodSiteNoUnwrapNoCoerce.invoke(StaticMetaMethodSite.java:151); 	at org.codehaus.groovy.runtime.callsit,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445:4822,plugin,plugins,4822,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445,1,['plugin'],['plugins']
Modifiability,jdk1.8.0_121\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3.0.RELEASE\spring-boot-starter-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot\2.3.0.RELEASE\spring-boot-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-autoconfigure\2.3.0.RELEASE\spring-boot-autoconfigure-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter-logging\2.3.0.RELEASE\spring-boot-starter-logging-2.3.0.RELEASE.jar;E:\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;E:\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;E:\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.2\log4j-to-slf4j-2.13.2.jar;E:\repository\org\apache\logging\log,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:1669,plugin,plugin,1669,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['plugin'],['plugin']
Modifiability,"k/resources/contig_ploidy_priors.tsv --output_model_path=/home/n.liorni/snakemake_cnv_gatk/results/cnv/ploidy/ploidy-model; Stdout: 15:09:46.970 INFO cohort_determine_ploidy_and_depth - THEANO_FLAGS environment variable has been set to: device=cpu,floatX=float64,optimizer=fast_run,compute_test_value=ignore,openmp=true,blas.ldflags=-lmkl_rt,openmp_elemwise_minsize=10; 15:09:47.017 INFO gcnvkernel.structs.metadata - Generating intervals metadata...; 15:09:47.024 INFO gcnvkernel.tasks.task_cohort_ploidy_determination - Instantiating the germline contig ploidy determination model...; 15:09:50.320 INFO gcnvkernel.tasks.task_cohort_ploidy_determination - Instantiating the ploidy emission sampler...; 15:09:50.321 INFO gcnvkernel.tasks.task_cohort_ploidy_determination - Instantiating the ploidy caller...; 15:09:50.957 INFO gcnvkernel.models.fancy_model - Global model variables: {'psi_j_log__', 'mean_bias_j_lowerbound__'}; 15:09:50.957 INFO gcnvkernel.models.fancy_model - Sample-specific model variables: {'psi_s_log__'}; 15:09:50.957 INFO gcnvkernel.tasks.inference_task_base - Instantiating the convergence tracker...; 15:09:50.958 INFO gcnvkernel.tasks.inference_task_base - Setting up DA-ADVI...; 15:10:03.310 INFO gcnvkernel.tasks.inference_task_base - (denoising) starting...: 0%| | 0/1000 [00:00<?, ?it/s]; 15:10:03.410 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -1038.498 +/- 431.707, SNR: 71.3, T: 1.98: 8%|8 | 83/1000 [00:00<00:01, 826.53it/s]; 15:10:03.522 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -821.262 +/- 327.042, SNR: 38.9, T: 1.97: 17%|#6 | 166/1000 [00:00<00:01, 776.56it/s]; 15:10:03.636 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -727.432 +/- 277.971, SNR: 29.4, T: 1.95: 24%|##4 | 244/1000 [00:00<00:01, 732.12it/s]; 15:10:03.754 INFO gcnvkernel.tasks.inference_task_base - (denoising epoch 1) ELBO: -662.875 +/- 251.403, SNR: 23.4, T: 1.94: 32%|###1 | 318/1000 [00:00<00:00, 689.38it/s]; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:7492,variab,variables,7492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['variab'],['variables']
Modifiability,"le>; from . import timeseries; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/pymc3/distributions/timeseries.py"", line 1, in <module>; import theano.tensor as tt; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/__init__.py"", line 66, in <module>; from theano.compile import (; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/__init__.py"", line 10, in <module>; from theano.compile.function_module import *; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 21, in <module>; import theano.compile.mode; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/mode.py"", line 10, in <module>; import theano.gof.vm; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/vm.py"", line 662, in <module>; from . import lazylinker_c; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 42, in <module>; location = os.path.join(config.compiledir, 'lazylinker_ext'); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configparser.py"", line 333, in __get__; self.__set__(cls, val_str); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configparser.py"", line 344, in __set__; self.val = self.filter(val); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configdefaults.py"", line 1745, in filter_compiledir; "" '%s'. Check the permissions."" % path); ValueError: Unable to create the compiledir directory '/root/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64'. Check the permissions. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081:4769,config,config,4769,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081,1,['config'],['config']
Modifiability,lizer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:35:11.508 INFO CountReadsSpark - For support and documentat,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:1703,config,configuration,1703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['config'],['configuration']
Modifiability,"ly braces can wait for a separate pass (we will want to do those in this PR though). If you're not sure what to include or not just ask. I like the idea of keeping the GATK3 tests working as we go along. We should make a clear distinction between the old and new tests though. Ideally the GATK3 tests would be in a separate commit that we can just delete at the end, but that can get unwieldy if the files in the commit need to change as we go along. Alternatively you could isolate them into a separate directory. They should either be disabled or made dependent on a test method (see the `@Test` annotation properties `enabled` and `dependsOn`) that is easily toggled so they can be run locally, but don't run on the CI server. Otherwise the CI server build will always fail. In general, its really helpful to have the first commit in the PR contain the completely unmodified GATK3 source files. It makes it much easier for the reviewer to see what changed for the port. I noticed that you have 2 new plugins included in this. I'm not sure if that was suggested by someone on the GATK team (I'm wondering if we want to go down that path...) but I can tell you that the existing plugins required an enormous amount of test development and review iteration. If we do decide to make them plugins, I think it would be a good idea to do so in a separate PR. Also, if we choose to make an AbstractPlugin base class, we may want that to live in the Barclay repo. As @magicdgs points out, master already has your previous commits, so you should start by rebasing on that. Ideally, the branch would have the following commits before we start the first review cycle:. 1. A single commit containing the unmodified GATK3 source (unmodified with the exception that if a file is renamed for GATK4, its helpful to rename the GATK3 version in this commit so it's easy to compare in the next commit). This commit doesn't have to compile or run - its just to make the review process easier for us, and will be delete",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352:1604,plugin,plugins,1604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352,2,['plugin'],['plugins']
Modifiability,"ly. I am busy with graduation in recent days, and will work on visa application for the further postdoc position at Harvard Medical School. Thank you for the interests in our tool, MosaicHunter. The option you suggest looks great. Do you mean that I should establish the GATK 4 developing environment and develop the MosaicHunterFilter tool? I may do that when I have some time. I found the document of GATK 4 at https://github.com/broadinstitute/gatk. Do you have any further advices?. Best regards,; Adam Yongxin Ye; Center for Bioinformatics; Peking University. At 2018-07-07 01:43:05, ""Geraldine Van der Auwera"" <notifications@github.com> wrote:. Hi @Yyx2626, I'm Geraldine, you may remember me from the Beijing training. It was great visiting your team! I'm sorry it took me so long to follow up on this discussion, and I want to thank you again for reaching out to us about integrating the tool that you developed into GATK. We are certainly very interested in providing this enhancement to the research community, and we are now ready to talk about the next steps. After examining your paper and the source code in Github, we think that the most efficient way to integrate the functionality you developed would be to adapt the filtering parts of your tool to run on the output of Mutect2. So this would be a standalone tool that you would run after Mutect2, much like the current FilterMutectCalls tool. If the results are comparable to your current tool, then we would take that into the official distribution of GATK. If somehow that integration does not yield satisfactory results, then we would look at integrating the entire tool, though we're hoping it won't be necessary, so we can avoid maintaining duplicate functionality for some of the boilerplate data transformations. David @davidbenjamin can provide some advice on how to implement this in GATK4; in brief you would need to write some code that applies the filters you developed to a variant context. Let us know if this is an opt",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349:1033,enhance,enhancement,1033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349,1,['enhance'],['enhancement']
Modifiability,"makeBefore/makeAfter seems more flexible in that it makes before/after a property of the way the transformer is applied, rather than of the transformer itself. When we write the plugin descriptor, it can maintain two separate argument lists (for ""--preFilterTransformer ..."" and ""--postFilterTransformer ...""), and then merge them accordingly. It does complicate the tool structure, but its the price for flexibility, and the pattern is not that complex. I think we should be explicit about what ""pre"" and ""post"" are relative to in the method and argument names, i.e., makePreReadFilterTransformer and makePostReadFilterTransformer, or maybe even one makeReadFilterTransformer method that takes a pre/post argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-246000255:32,flexible,flexible,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-246000255,2,"['flexible', 'plugin']","['flexible', 'plugin']"
Modifiability,"mbler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.3891049Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3891593Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3892257Z symbol: class RangeMap; 2022-08-16T00:09:07.3892601Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3893126Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3893670Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3894352Z symbol: class Range; 2022-08-16T00:09:07.3894678Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3897711Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3902203Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3902980Z symbol: class RangeMap; 2022-08-16T00:09:07.3903340Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3903864Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3904505Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3905250Z symbol: class Range; 2022-08-16T00:09:07.3905751Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3906273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T00:09:07.3906908Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T00:09:07.3907793Z symbol: class Range; 2022-08-16T00:09:07.3908125Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3910592Z src/main/java/org/broadinstitute/hellbender/to",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:6286,extend,extends,6286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['extend'],['extends']
Modifiability,"mbler.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.7690890Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7738985Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7739852Z symbol: class RangeMap; 2022-08-16T22:45:53.7740332Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7740892Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7741707Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7743523Z symbol: class Range; 2022-08-16T22:45:53.7743866Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7747579Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7748444Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7776218Z symbol: class RangeMap; 2022-08-16T22:45:53.7776715Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7777389Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7778220Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7779110Z symbol: class Range; 2022-08-16T22:45:53.7779574Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7780209Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T22:45:53.7780965Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T22:45:53.7781896Z symbol: class Range; 2022-08-16T22:45:53.7782232Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7785096Z src/main/java/org/broadinstitute/hellbender/to",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:8324,extend,extends,8324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['extend'],['extends']
Modifiability,"ms that we will want to run the filter with more stringent parameters, as higher base error rates are causing homs to leak past the filter, which in turn affects the fit of the allele-fraction model (which only attempts to model hets) by biasing normal segments towards unbalanced, and 2) we now want to run ModelSegments separately on the normal to allow for the filtering of germline events. So we want to be more stringent with low-coverage normals without affecting our high-coverage tumors. For example, here's some hg38 NovaSeq FFPE WGS data from a ~40x normal:. ![download](https://user-images.githubusercontent.com/11076296/43977946-9bd0a1bc-9cb3-11e8-9d7f-016a99c1c173.png). Compare to an hg19 TCGA WGS ~40x normal:. ![download 1](https://user-images.githubusercontent.com/11076296/43978051-f8820770-9cb3-11e8-8e16-13b51792614f.png). The hom-ref tail in the first plot is much fatter and clearly leaks into the het cloud. Also curious is that the het cloud is far less binomial (or even beta-binomial---note also the absence of the tail extending to the origin). I am still not sure why the incoming data looks different. There are several confounding factors: NovaSeq vs. HiSeq, hg38 vs. hg19, AF > 2% gnomAD sites vs. AF > 10% 1000G sites, FFPE vs. frozen, etc. I have not seen enough examples/combinations to be able to say which are the most important factors. Changing the genotyping/filtering strategy can get around this change in the data without a corresponding change in the allele-fraction model for now, but getting the data to look as good as possible upstream would be even better. Another thought: would be nice if the strategy was easily compatible with an eventual implementation of multi-sample segmentation, which would require that the same sites are used in both the tumor and the normal. We would want to strike a balance between maximizing the number of sites and including questionable sites from the normal. Will add more details later. @davidbenjamin @LeeTL1220 @eit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3915#issuecomment-412189218:1597,extend,extending,1597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3915#issuecomment-412189218,2,['extend'],['extending']
Modifiability,"n Tools; #; # Only update this environment if there is a *VERY* good reason to do so!; # If the build is broken but could be fixed by doing something else, then do that thing instead.; # Ensuring the correct environment for canonical (or otherwise reasonable) usage of our standard Docker takes precedence over edge cases.; # If you break the environment, you are responsible for fixing it and also owe the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely nec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:1270,flexible,flexible,1270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['flexible'],['flexible']
Modifiability,ncotator/funcotator_dataSources.v1.6.20190124s/gencode_xrefseq/hg38/gencode_xrefseq_v90_38.tsv; > 12:28:17.939 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/hgnc_download_Nov302017.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/hgnc/hg38/hgnc_download_Nov302017.tsv; > 12:28:17.939 INFO Funcotator - Finalizing data sources (this step can be long if data sources are cloud-based)...; > 12:28:17.940 INFO DataSourceUtils - Setting lookahead cache for data source: chr1_b_bed : 100000; > 12:28:17.951 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/chr1_b_bed.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_b_bed/hg38/chr1_b_bed.tsv; > 12:28:17.967 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_b_bed/hg38/chr1_b_bed.config; > 12:28:17.995 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/chr1_b_bed.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_b_bed/hg38/chr1_b_bed.tsv; > 12:28:17.997 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/chr1_b_bed.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_b_bed/hg38/chr1_b_bed.tsv; > WARNING 2020-07-21 12:28:17 AsciiLineReader Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; > 12:28:18.002 INFO DataSourceUtils - Setting lookahead cache for data source: Oreganno : 100000; > 12:28:18.009 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/oreganno.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/oreganno/hg38/oreganno.tsv; > 12:28:18.020 INFO Fe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975:8858,config,config,8858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975,1,['config'],['config']
Modifiability,"nd other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4. # other python dependencies; these should be removed after functionality is moved into Java code; - biopython=1.76; - pyvcf=0.6.8; - bioconda::pysam=0.15.3 # using older conda-installed versions may result in libcrypto / openssl bugs. # pip installs should be avoided, as pip may not respect the dependencies found by the conda solver; - pip:; - gatkPythonPackageArchive.zip; ```. It seems to successfully create the environment. I'd still recommend updating the information on your README.md and the file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:3013,variab,variable,3013,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['variab'],['variable']
Modifiability,"nd the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:2181,config,config,2181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['config'],['config']
Modifiability,"nd, so it cannot localize gs; paths. In other words, the WDL tests in travis need a local instance of; the file and to use that path in the json. On Wed, Apr 10, 2019 at 3:49 PM Jonn Smith <notifications@github.com> wrote:. > @LeeTL1220 <https://github.com/LeeTL1220>; >; > This seems to be running into a cromwell / WDL error:; >; > java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); > LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; > 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); >; > Isn't cromwell supposed to handle gs:// URLs for localizing files? Do you; > have any thoughts?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk7Wd-RgMx2g-UPLNrvjettNMf9ixks5vfkA3gaJpZM4clLLK>; > .; >. -- ; Lee Lichtenstein; Br",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426:1069,config,configure,1069,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426,1,['config'],['configure']
Modifiability,nds 11 --gvcf-gq-bands 12 --gvcf-gq-bands 13 --gvcf-gq-bands 14 --gvcf-gq-bands 15 --gvcf-gq-bands 16 --gvcf-gq-bands 17 --gvc; f-gq-bands 18 --gvcf-gq-bands 19 --gvcf-gq-bands 20 --gvcf-gq-bands 21 --gvcf-gq-bands 22 --gvcf-gq-bands 23 --gvcf-gq-bands 24 --gvcf-gq-bands 25 --gvcf-gq-bands 26 --gvcf-gq-bands 27 --g; vcf-gq-bands 28 --gvcf-gq-bands 29 --gvcf-gq-bands 30 --gvcf-gq-bands 31 --gvcf-gq-bands 32 --gvcf-gq-bands 33 --gvcf-gq-bands 34 --gvcf-gq-bands 35 --gvcf-gq-bands 36 --gvcf-gq-bands 37 -; -gvcf-gq-bands 38 --gvcf-gq-bands 39 --gvcf-gq-bands 40 --gvcf-gq-bands 41 --gvcf-gq-bands 42 --gvcf-gq-bands 43 --gvcf-gq-bands 44 --gvcf-gq-bands 45 --gvcf-gq-bands 46 --gvcf-gq-bands 47; --gvcf-gq-bands 48 --gvcf-gq-bands 49 --gvcf-gq-bands 50 --gvcf-gq-bands 51 --gvcf-gq-bands 52 --gvcf-gq-bands 53 --gvcf-gq-bands 54 --gvcf-gq-bands 55 --gvcf-gq-bands 56 --gvcf-gq-bands ; 57 --gvcf-gq-bands 58 --gvcf-gq-bands 59 --gvcf-gq-bands 60 --gvcf-gq-bands 70 --gvcf-gq-bands 80 --gvcf-gq-bands 90 --gvcf-gq-bands 99 --floor-blocks false --indel-size-to-eliminate-in-re; f-model 10 --disable-optimizations false --dragen-mode false --flow-mode NONE --apply-bqd false --apply-frd false --disable-spanning-event-genotyping false --transform-dragen-mapping-quali; ty false --mapping-quality-threshold-for-genotyping 20 --max-effective-depth-adjustment-for-frd 0 --just-determine-active-regions false --dont-genotype false --do-not-run-physical-phasing ; false --do-not-correct-overlapping-quality false --use-filtered-reads-for-annotations false --use-flow-aligner-for-stepwise-hc-filtering false --adaptive-pruning false --do-not-recover-dan; gling-branches false --recover-dangling-heads false --kmer-size 10 --kmer-size 25 --dont-increase-kmer-sizes-for-cycles false --allow-non-unique-kmers-in-ref false --num-pruning-samples 1 ; --min-dangling-branch-length 4 --recover-all-dangling-branches false --max-num-haplotypes-in-population 128 --min-pruning 2 --adaptive-pruning-initial-error-rate 0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789:4845,adapt,adaptive-pruning,4845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789,2,['adapt'],"['adaptive-pruning', 'adaptive-pruning-initial-error-rate']"
Modifiability,"ntervals of two jobs, and whether separating the jobs would impact calls. In this example, GenotypeGVCFs would run over 1:1050-1150. For example, if we had a multi-NT variant that spanned 1148-1052, we'd want that called correctly no matter what intervals were used for the jobs. I tried using running GenomicsDBImport with -L over a small region, or I ran SelectVariants on the gVCF first (which behaves a little differently), and then used that subset gVCF as input to GenomicsDBImport, where GenomicsDBImport is given the entire contig as the interval. The resulting workspaces will be slightly different, with the latter containing information over a wider region (GenomicsDBIport truncates start/end of the input records to just the target interval). . So if either of these workspaces is passed to GenotypeGVCFs, using --only-output-calls-starting-in-intervals and -L 1:1050-1150:. I think any upstream padding doesnt matter. If you have a multi-nucleotide polymorphism that starts upstream of 1050 but spans 1050, this job wouldnt be responsible for calling that. The prior job, which has an interval set upstream of this one should call it. I think GenomicsDbImport's behavior is fine here. If you have a multi-NT variant that starts within 1050-1150, but extends outside (i.e. deletion or insertion starting at 1148), this could be a problem. The GenomicsDB workspace created with the interval 1:1050-1150 lacks the information to score that, right? The workspace created using the more permissive SelectVariants->GenomicsDBImport contains that downstream information and presumably would make the same call as if GenotypeGVCFs was given the intact chromosome as input, right?. However, it seems that if I simply create the workspace with a reasonably padded interval (adding 1kb should be more than enough for Illumina, right?), and then run GenotypeGVCFs with the original, unpassed interval, then the resulting workspace should contain all available information and GenotypeGVCFs should be",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221558244:1317,polymorphi,polymorphism,1317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221558244,2,['polymorphi'],['polymorphism']
Modifiability,"o go ahead and add this option, I would probably keep the directory structure of the GermlineCNVCaller output the same (i.e., with folders named ""SAMPLE_#""), and just check the sample_name.txt files at the PostprocessGermlineCNVCalls step. I don't think this should require GermlineCNVCaller code changes, right?. 4) We may require additional code at the WDL level if we want to both switch over to primarily using sample names but also get rid of bundling (i.e., by passing only the calls for each sample when needed). Locally, you can always just search all output for directories containing the appropriate sample_name.txt. But on the cloud, you'd want to make sure that the postprocessing step for a particular sample gets only its corresponding directories, which would have to happen at the WDL level; the check against sample_name.txt at the tool level would just be a formality. I can foresee headaches with globbing and funky sample names. I'm not sure I understand your point about extending PostprocessGermlineCNVCalls to run on all samples. The point of that tool is to take results from all genomic shards for a single sample and stitch them together, right? Even if we extend this to run on a batch of multiple samples (which would just be moving the loop over samples at the WDL level to some lower level, i.e., Java or python), we still need to see all shards for those samples. Perhaps I'm misunderstanding---can you clarify?. @mwalker174 can we once and for all clearly document the issue with the transpose? Perhaps by pointing to specific WGS runs that have issues with call caching? I think being able to pinpoint the exact issue will help us identify the right solution---whether that be choosing an appropriate bundling scheme, taking advantage of #5781 to reduce the number of shards, batching during the postprocessing step, removing unnecessary outputs, etc. Recall that we'd like to be able to use the same WDL locally (when you have easy access to all GermlineCNVCaller re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765:2180,extend,extending,2180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765,2,['extend'],['extending']
Modifiability,"o the right processing methods in a single pass over the RDD. Reply by @SHuang-Broad. > I tried to fix it in this PR, but that seems to be a big task,; and probably is impossible to achieve in a single pass,; because currently each class of contig ends up producing a different type of object; (3 general classes: simple -> SimpleNovelAdjacency, complex -> ComplexVariantCanonicalRepresentation, and unknown -> SAM records of the contigs); and a groupBy() operation is necessary in the middle using these objects as keys; due to the fact that different contigs may produce the same variant; So what I'm thinking about, is two pass:; one pass for splitting them up into the 3 classes,; then another pass on each of those 3 RDD's to turn them into VariantContext's.; Any better idea?. Reply by @cwhelan ; > That would be better, and yeah you don't have to do it in this PR.; In theory you could make the keys for the groupByKey() (ie NovelAdjacencyAndAltHaplotype, CpxVariantCanonicalRepresentation, right?) all inherit from the same superclass and do a single group by, couldn't you? Then you could do everything in a single pass. Reply by @SHuang-Broad; > Yes, that is what I'm planning but I'm not sure yet about how to approach that (I actually tried it, before putting in the above comment, and quickly ran into the problem of mixing Java serialization and Kryo serialization, so a larger re-structuring might be needed, and not just a inheritance structure). ------------; ### On the problem of having a confusing TODO for ; `boolean SimpleChimera.isCandidateInvertedDuplication()`. The todo message. > TODO: 5/5/18 Note that the use of the following predicate is currently obsoleted by; {@link AssemblyContigWithFineTunedAlignments#hasIncompletePictureFromTwoAlignments()}; because the contigs with this alignment signature is classified as ""incomplete"",; hence will NOT sent here for constructing SimpleChimera's.; But we may want to keep the code (and related code in BreakpointComplications) ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:1548,inherit,inherit,1548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,2,['inherit'],['inherit']
Modifiability,"ode:. -`BaseRecalibratorSpark` is the standalone BQSR tool, and calls into the `BaseRecalibratorSparkFn` (which is also called from `ReadsPipelineSpark`). -`ApplyBQSRSpark` is the standalone ApplyBQSR tool, and calls into the `ApplyBQSRSparkFn` (also called from `ReadsPipelineSpark`). -Integration tests for the above are in `BaseRecalibratorSparkIntegrationTest` and `ApplyBQSRSparkIntegrationTest`. -Almost all other changes in the branch are related to the BQSR engine refactoring, which I summarize below:; - We pulled out the guts of the walker `BaseRecalibrator` tool, combined it with all of the code from the former `RecalibrationEngine` class (now deleted) to make a new `BaseRecalibrationEngine` class under `utils/recalibration`.; - We stripped out all copies of the code in `BaseRecalibrationEngine` from the walker, dataflow, and spark versions of BQSR, and modified them to call into `BaseRecalibrationEngine`.; - We moved all auxiliary classes needed by the `BaseRecalibrationEngine` (eg., the covariates, etc.) into `utils/recalibration`.; - We refactored the argument collections. Now there is a single shared `RecalibrationArgumentCollection` that contains **only** the parameters for the `BaseRecalibrationEngine` itself, and this argument collection is exposed by all 3 versions of the tool. Input/output arguments have been removed from this argument collection and put into the individual implementations of BQSR, since they vary between the walker, dataflow, and spark versions of the tool. This eliminates awkward problems such as having both a `knownSites` argument AND a `BQSRKnownVariants` exposed at the same time, with only 1 of them usable for a given version of a tool. The dataflow-only `BaseRecalibrationArgumentCollection` has been deleted completely as no longer needed.; - We tweaked the names of some tool arguments to enforce consistency between the 3 versions of the tool as well as the rest of hellbender (eg., output arg for BQSR is now a more standard `-O`)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073:1113,refactor,refactored,1113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073,1,['refactor'],['refactored']
Modifiability,odecov.io/gh/broadinstitute/gatk/pull/3447?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../broadinstitute/hellbender/utils/LoggingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9Mb2dnaW5nVXRpbHMuamF2YQ==) | `82.222% <ø> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `65.926% <ø> (ø)` | `35 <0> (ø)` | :arrow_down: |; | [...ellbender/utils/config/CustomBooleanConverter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb25maWcvQ3VzdG9tQm9vbGVhbkNvbnZlcnRlci5qYXZh) | `100% <100%> (ø)` | `2 <2> (?)` | |; | [...rg/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzLmphdmE=) | `60.104% <100%> (+0.418%)` | `50 <2> (+1)` | :arrow_up: |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `86.408% <100%> (+0.408%)` | `29 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/engine/FeatureManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3447#issuecomment-323474032:1818,config,config,1818,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447#issuecomment-323474032,1,['config'],['config']
Modifiability,odehaus.groovy.runtime.callsite.CallSiteArray.defaultCallConstructor(CallSiteArray.java:60); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callConstructor(AbstractCallSite.java:235); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callConstructor(AbstractCallSite.java:255); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction$StreamAction.visitFile(ShadowCopyAction.groovy:185); 	at sun.reflect.GeneratedMethodAccessor34.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite$PogoCachedMethodSiteNoUnwrapNoCoerce.invoke(PogoMetaMethodSite.java:210); 	at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite.callCurrent(PogoMetaMethodSite.java:59); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:166); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction$StreamAction.processFile(ShadowCopyAction.groovy:151); 	at org.gradle.api.internal.file.copy.NormalizingCopyActionDecorator$1$1.processFile(NormalizingCopyActionDecorator.java:66); 	at org.gradle.api.internal.file.copy.DuplicateHandlingCopyActionDecorator$1$1.processFile(DuplicateHandlingCopyActionDecorator.java:60); 	at org.gradle.api.internal.file.copy.CopyFileVisitorImpl.processFile(CopyFileVisitorImpl.java:62); 	at org.gradle.api.internal.file.copy.CopyFileVisitorImpl.visitFile(CopyFileVisitorImpl.java:46); 	at org.gradle.api.internal.file.collections.jdk7.Jdk7DirectoryWalker$1.visitFile(Jdk7DirectoryWalker.java:86); 	at org.gradle.api.internal.file.collections.jdk7.Jdk7DirectoryWalker$1.visitFile(Jdk7DirectoryWalker.java:59); 	at java.nio.file.Files.walkFileTree(Files.java:2670); 	at org.gradle.api.internal.file.collections.jdk7.Jdk7DirectoryWalker.walkDir(Jdk7DirectoryWalker.java:59); 	at org.gradle.api.internal.file.collections.DirectoryFileTree,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445:2008,plugin,plugins,2008,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445,1,['plugin'],['plugins']
Modifiability,"ok, got it. sorry, i missed 'install' in that command. my initial impression is that VariantQC will be able to adapt fine to VariantEvalEngine. I wrote VariantEvalEngine with this is mind, but it's good to formally test it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759645374:111,adapt,adapt,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759645374,1,['adapt'],['adapt']
Modifiability,"olders named ""SAMPLE_#""), and just check the sample_name.txt files at the PostprocessGermlineCNVCalls step. I don't think this should require GermlineCNVCaller code changes, right?. 4) We may require additional code at the WDL level if we want to both switch over to primarily using sample names but also get rid of bundling (i.e., by passing only the calls for each sample when needed). Locally, you can always just search all output for directories containing the appropriate sample_name.txt. But on the cloud, you'd want to make sure that the postprocessing step for a particular sample gets only its corresponding directories, which would have to happen at the WDL level; the check against sample_name.txt at the tool level would just be a formality. I can foresee headaches with globbing and funky sample names. I'm not sure I understand your point about extending PostprocessGermlineCNVCalls to run on all samples. The point of that tool is to take results from all genomic shards for a single sample and stitch them together, right? Even if we extend this to run on a batch of multiple samples (which would just be moving the loop over samples at the WDL level to some lower level, i.e., Java or python), we still need to see all shards for those samples. Perhaps I'm misunderstanding---can you clarify?. @mwalker174 can we once and for all clearly document the issue with the transpose? Perhaps by pointing to specific WGS runs that have issues with call caching? I think being able to pinpoint the exact issue will help us identify the right solution---whether that be choosing an appropriate bundling scheme, taking advantage of #5781 to reduce the number of shards, batching during the postprocessing step, removing unnecessary outputs, etc. Recall that we'd like to be able to use the same WDL locally (when you have easy access to all GermlineCNVCaller results from all genomic shards) and in the cloud, with minimal duplication of output from bundling when running locally, if possible.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765:2371,extend,extend,2371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765,2,['extend'],['extend']
Modifiability,"on: class GVCFBlockCombiner; 2022-08-16T00:09:07.3893126Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T00:09:07.3893670Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T00:09:07.3894352Z symbol: class Range; 2022-08-16T00:09:07.3894678Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3897711Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3902203Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3902980Z symbol: class RangeMap; 2022-08-16T00:09:07.3903340Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3903864Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T00:09:07.3904505Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T00:09:07.3905250Z symbol: class Range; 2022-08-16T00:09:07.3905751Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3906273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T00:09:07.3906908Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T00:09:07.3907793Z symbol: class Range; 2022-08-16T00:09:07.3908125Z location: class GVCFBlockCombiner; 2022-08-16T00:09:07.3910592Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3914013Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.3921838Z src/main/java/org/broadinstitute/hellbender/tools/walkers",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:6678,extend,extends,6678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['extend'],['extends']
Modifiability,"on: class GVCFBlockCombiner; 2022-08-16T22:45:53.7740892Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:32: error: cannot find symbol; 2022-08-16T22:45:53.7741707Z final RangeMap<Integer, Range<Integer>> gqPartitions;; 2022-08-16T22:45:53.7743523Z symbol: class Range; 2022-08-16T22:45:53.7743866Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7747579Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7748444Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7776218Z symbol: class RangeMap; 2022-08-16T22:45:53.7776715Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7777389Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:62: error: cannot find symbol; 2022-08-16T22:45:53.7778220Z RangeMap<Integer,Range<Integer>> parsePartitions(final List<? extends Number> gqPartitions) ***; 2022-08-16T22:45:53.7779110Z symbol: class Range; 2022-08-16T22:45:53.7779574Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7780209Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java:101: error: cannot find symbol; 2022-08-16T22:45:53.7780965Z static VCFHeaderLine rangeToVCFHeaderLine(Range<Integer> genotypeQualityBand) ***; 2022-08-16T22:45:53.7781896Z symbol: class Range; 2022-08-16T22:45:53.7782232Z location: class GVCFBlockCombiner; 2022-08-16T22:45:53.7785096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/ChainPruner.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7789228Z src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/BaseVertex.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.7798240Z src/main/java/org/broadinstitute/hellbender/tools/walkers",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:8716,extend,extends,8716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['extend'],['extends']
Modifiability,"ong. We should make a clear distinction between the old and new tests though. Ideally the GATK3 tests would be in a separate commit that we can just delete at the end, but that can get unwieldy if the files in the commit need to change as we go along. Alternatively you could isolate them into a separate directory. They should either be disabled or made dependent on a test method (see the `@Test` annotation properties `enabled` and `dependsOn`) that is easily toggled so they can be run locally, but don't run on the CI server. Otherwise the CI server build will always fail. In general, its really helpful to have the first commit in the PR contain the completely unmodified GATK3 source files. It makes it much easier for the reviewer to see what changed for the port. I noticed that you have 2 new plugins included in this. I'm not sure if that was suggested by someone on the GATK team (I'm wondering if we want to go down that path...) but I can tell you that the existing plugins required an enormous amount of test development and review iteration. If we do decide to make them plugins, I think it would be a good idea to do so in a separate PR. Also, if we choose to make an AbstractPlugin base class, we may want that to live in the Barclay repo. As @magicdgs points out, master already has your previous commits, so you should start by rebasing on that. Ideally, the branch would have the following commits before we start the first review cycle:. 1. A single commit containing the unmodified GATK3 source (unmodified with the exception that if a file is renamed for GATK4, its helpful to rename the GATK3 version in this commit so it's easy to compare in the next commit). This commit doesn't have to compile or run - its just to make the review process easier for us, and will be deleted at some point. I can help with how to get this into your branch if you like.; 2. Your modified GATK3 tests in a single commit. This will also be removed before merge.; 3. A single commit with all o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352:1781,plugin,plugins,1781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352,2,['plugin'],['plugins']
Modifiability,onnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:113); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:86); 	at com.google.cloud.ServiceOptions.defaultCredentials(ServiceOptions.java:277); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:252); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:361); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```; I was able to fix the issue by setting the environment variable `NO_GCE_CHECK=true` in my shell though,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:6606,variab,variable,6606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,1,['variab'],['variable']
Modifiability,org\springframework\spring-web\5.2.6.RELEASE\spring-web-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-webmvc\5.2.6.RELEASE\spring-webmvc-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-aop\5.2.6.RELEASE\spring-aop-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-context\5.2.6.RELEASE\spring-context-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-expression\5.2.6.RELEASE\spring-expression-5.2.6.RELEASE.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.2\mybatis-spring-boot-starter-2.1.2.jar;E:\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.2\mybatis-spring-boot-autoconfigure-2.1.2.jar;E:\repository\org\mybatis\mybatis\3.5.4\mybatis-3.5.4.jar;E:\repository\org\mybatis\mybatis-spring\2.0.4\mybatis-spring-2.0.4.jar;E:\repository\mysql\mysql-connector-java\8.0.20\mysql-connector-java-8.0.20.jar;E:\repository\org\springframework\boot\spring-boot-configuration-processor\2.3.0.RELEASE\spring-boot-configuration-processor-2.3.0.RELEASE.jar;E:\repository\org\springframework\spring-core\5.2.6.RELEASE\spring-core-5.2.6.RELEASE.jar;E:\repository\org\springframework\spring-jcl\5.2.6.RELEASE\spring-jcl-5.2.6.RELEASE.jar;E:\repository\com\google\firebase\firebase-admin\6.8.1\firebase-admin-6.8.1.jar;E:\repository\com\google\api-client\google-api-client\1.25.0\google-api-client-1.25.0.jar;E:\repository\com\google\oauth-client\google-oauth-client\1.25.0\google-oauth-client-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-jackson2\1.25.0\google-http-client-jackson2-1.25.0.jar;E:\repository\com\google\api-client\google-api-client-gson\1.25.0\google-api-client-gson-1.25.0.jar;E:\repository\com\google\http-client\google-http-client-gson\1.25.0\google-http-client-gson-1.25.0.jar;E:\repository\com\google\code\gson\gson\2.8.6\gson-2.8.6.jar;E:\repository\com\google\http-client\google-http-client\1.25.0\google-http-client-1.25.0.jar;E:\repository\com\google\code\findbugs\jsr305\3.0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:5508,config,configuration-processor-,5508,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['config'],['configuration-processor-']
Modifiability,"ould like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I added something else in https://github.com/samtools/htsjdk/issues/520",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:1281,config,configure,1281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940,2,['config'],['configure']
Modifiability,"ouldn't update the docs for `ReadWindowWalker` to clear up the confusion without mentioning `AssemblyRegion`-specific concepts.; - The `ReadShard` / `ReadWindow` was/is **only** there to prove that we can shard the data without introducing calling artifacts, and to provide a unit of parallelism for the upcoming Spark implementation. It's not something we really want to expose to users as a prominent knob, and we may hide it completely in the future once the shard size is tuned for performance.; - Inheriting from a more abstract walker type caused a number of other problems as well: methods that should have been final in the supertype could no longer be made final, with the result that tool implementations could inappropriately override engine initialization/shutdown routines. Also, there were issues with the progress meter, since both the supertype traversal and subtype traversal needed their own progress meter for their different units of processing. Ultimately it was just too awkward and forced, and the read shard is something that we eventually want to make an internal/encapsulated implementation detail anyway. GATK3 made the mistake, I think, of using long, confusing inheritance chains for its walker types, with the result that you got awkward and forced relationships like `RodWalker` inheriting from `LocusWalker`. It's better, I think, to make each traversal as standalone as possible, especially given the simplicity of writing a new walker type in GATK4. For all of these reasons we don't want `AssemblyRegionWalker` to inherit from a more abstract traversal type -- it's just going to be its own standalone thing, so that it can evolve freely without affecting anyone else. For `SlidingWindowWalker`, which we still want to merge, I recommend making the traversal do **exactly** what you want for your use case, as clearly and simply as possible, without worrying about serving as a base class for other traversals. Ping me once you're happy with it, and I'll re-review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513:2073,inherit,inheritance,2073,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513,4,"['evolve', 'inherit']","['evolve', 'inherit', 'inheritance', 'inheriting']"
Modifiability,"ozygous genotypes failing two-tailed binomial test (example below); q .. select genotypes using -i/-e options; and the new genotype can be one of:; . .. missing (""."" or ""./."", keeps ploidy); 0 .. reference allele (e.g. 0/0 or 0, keeps ploidy); c:GT .. custom genotype (e.g. 0/0, 0, 0/1, m/M, overrides ploidy); m .. minor (the second most common) allele (e.g. 1/1 or 1, keeps ploidy); M .. major allele (e.g. 1/1 or 1, keeps ploidy); p .. phase genotype (0/1 becomes 0|1); u .. unphase genotype and sort by allele (1|0 becomes 0/1); Usage: bcftools +setGT [General Options] -- [Plugin Options]; Options:; run ""bcftools plugin"" for a list of common options. Plugin options:; -e, --exclude <expr> Exclude a genotype if true (requires -t q); -i, --include <expr> include a genotype if true (requires -t q); -n, --new-gt <type> Genotypes to set, see above; -t, --target-gt <type> Genotypes to change, see above. Example:; # set missing genotypes (""./."") to phased ref genotypes (""0|0""); bcftools +setGT in.vcf -- -t . -n 0p. # set missing genotypes with DP>0 and GQ>20 to ref genotypes (""0/0""); bcftools +setGT in.vcf -- -t q -n 0 -i 'GT=""."" && FMT/DP>0 && GQ>20'. # set partially missing genotypes to completely missing; bcftools +setGT in.vcf -- -t ./x -n . # set heterozygous genotypes to 0/0 if binom.test(nAlt,nRef+nAlt,0.5)<1e-3; bcftools +setGT in.vcf -- -t ""b:AD<1e-3"" -n 0. # force unphased heterozygous genotype if binom.test(nAlt,nRef+nAlt,0.5)>0.1; bcftools +setGT in.vcf -- -t ./x -n c:'m/M'; ```; I was always wondering if GATK will have a plugin interface where people can code their own using groovy, kotlin, javascript or python plugins to extend some of the functionality where developers may not reach immediately. Personally I use htsjdk extensively (and sometimes pysam) to code a new personal tool each time I need something that I cannot find exactly what I look for. But a generic gatk plugin interface would be really useful and may provide means to extend the community support.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501:1923,plugin,plugin,1923,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501,5,"['extend', 'plugin']","['extend', 'plugin', 'plugins']"
Modifiability,"provements that were discovered while reviewing the variants ; (https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest/tree/master/Evaluation/Analysis/masterVSfeature/notes.xlsx); The implemented fixes are:; * for removing the hard-coded/explicit mentioning of ""chr"" in non-canonical versions, it is now fixed in 5eff782e4d582d516004fba2cee7535d984b1540; * for contigs whose alignments paint ambiguous picture, i.e. multiple alignment configurations offer equally good explanation:; 	1. if only one configuration has all alignment with MQ above a specified threshold, it is favored; this is implemented in ecc31f5fbec4e524b401fc9474a3a1b7ab08c561; 	2. if one configuration has alignment to non-canonical chromosome that explains the contig better than would-be-event-inducing mappings to canonical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face by group represented by asm002398:tig00001); asm014580:tig00018	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:863,config,configuration,863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522,2,['config'],['configuration']
Modifiability,"put); * positive (training with *.annot.hdf5) vs. positive-unlabeled (training with *.annot.hdf5 and *.unlabeled.annot.hdf5); * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Refactor main code block for model training; it's a bit monolithic and procedural now.; - [x] Decide on behavior for ill-behaved annotations. E.g., all missing, zero variance. Future work:. - [ ] We could allow subsetting of annotations here, which might allow for easier treatment of ill-behaved annotations. However, I'd say enabling workflows where the set of annotations is fixed is the priority.; - [ ] We could do positive-unlabeled training more rigorously or iteratively. Right now, we essentially do a single iteration to determine negative data. This could perhaps be preceded by a round of refactoring to clean up model training and make it less procedural.; - [ ] Automatic threshold tuning could be built into the tool, see #7711. We'd probably have to introduce a ""validation"" label. Perhaps it makes sense to keep this sort of thing at the workflow level?; - [ ] In the positive-negative framework enforced by the Java code in this tool, a ""model"" is anything that assigns a score, we fit two models to different subsets of the data, and then take the difference of the two scores. While the python backend does give some freedom to specify a model, future developers may want to go beyond the framework itself. For example, more traditional classification frameworks, etc. could be explored. As an intermediate step, one could perhaps use the positive/negative scores from the current framework in a more sophisticated way (e.g., using them as features), rather than just taking their difference. This sort of future work could be developed completely independently of the codebase associated wit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369:1411,refactor,refactoring,1411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369,1,['refactor'],['refactoring']
Modifiability,r/ports/biology/gatk/work/gatk-4.0.11.0/build/libs/gatk-package-1.0-SNAPSHOT-local.jar'.; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at org.codehaus.groovy.reflection.CachedConstructor.invoke(CachedConstructor.java:83); 	at org.codehaus.groovy.runtime.callsite.ConstructorSite$ConstructorSiteNoUnwrapNoCoerce.callConstructor(ConstructorSite.java:105); 	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallConstructor(CallSiteArray.java:60); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callConstructor(AbstractCallSite.java:235); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callConstructor(AbstractCallSite.java:255); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction$StreamAction.visitFile(ShadowCopyAction.groovy:185); 	at sun.reflect.GeneratedMethodAccessor34.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite$PogoCachedMethodSiteNoUnwrapNoCoerce.invoke(PogoMetaMethodSite.java:210); 	at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite.callCurrent(PogoMetaMethodSite.java:59); 	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:166); 	at com.github.jengelman.gradle.plugins.shadow.tasks.ShadowCopyAction$StreamAction.processFile(ShadowCopyAction.groovy:151); 	at org.gradle.api.internal.file.copy.NormalizingCopyActionDecorator$1$1.processFile(NormalizingCopyActionDecorator.java:66); 	at org.gradle.api.internal.file.copy.DuplicateHandlingCopyActionDecorator$1$1.processFile(DuplicateHandlingCopyAction,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445:1341,plugin,plugins,1341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445,1,['plugin'],['plugins']
Modifiability,"r_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_advi_iters=5000 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_internal_admixing_rate=7.500000e-01 --caller_external_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/intervals9016836733228000464.tsv --contig_ploidy_prior_table=/home/n.liorni/snakemake_cnv_gatk/resources/contig_ploidy_priors.tsv --output_model_path=/home/n.liorni/snakemake_cnv_gatk/results/cnv/ploidy/ploidy-model; Stdout: 15:09:46.970 INFO cohort_determine_ploidy_and_depth - THEANO_FLAGS environment variable has been set to: device=cpu,floatX=float64,optimizer=fast_run,compute_test_value=ignore,openmp=true,blas.ldflags=-lmkl_rt,openmp_elemwise_minsize=10; 15:09:47.017 INFO gcnvkernel.structs.metadata - Generating intervals metadata...; 15:09:47.024 INFO gcnvkernel.tasks.task_cohort_ploidy_determination - Instantiating the germline contig ploidy determination model...; 15:09:50.320 INFO gcnvkernel.tasks.task_cohort_ploidy_determination - Instantiating the ploidy emission sampler...; 15:09:50.321 INFO gcnvkernel.tasks.task_cohort_ploidy_determination - Instantiating the ploidy caller...; 15:09:50.957 INFO gcnvkernel.models.fancy_model - Global model variables: {'psi_j_log__', 'mean_bias_j_lowerbound__'}; 15:09:50.957 INFO gcnvkernel.models.fancy_model - Sample-specific model variables: {'psi_s_log__'}; 15:09:50.957 INFO gcnvkernel.tasks.inference_task_base - Instantiating the convergence tracker...; 15:09:50.958 INFO gcnvkernel.tasks.inference_task_base - Setting up DA-ADVI...; 15:10:03.310 INFO gcnvkern",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:6703,variab,variable,6703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['variab'],['variable']
Modifiability,"ranch against 4.5.0.0, as well as this branch against itself (checking for reproducibility). Costs for this branch ($10.92) and 4.5.0.0 ($10.96) were quite comparable. Note that a small portion of these costs derives from Pf7-specific genotyping steps, which I did not bother to remove from the workflow. Runtime for the ploidy modeling and postprocessing steps were comparable. Interestingly, **runtime for the gCNV was ~20-25% longer with this branch than with 4.5.0.0, but memory usage fell by a factor of ~3 (~6GB to ~2GB)!** I am not sure if we could recoup the runtime with some more tweaking of the environment (perhaps double checking that optimized BLAS/MKL/etc. packages are properly used, changing environment variables/flags, etc.), but I think the decrease in memory usage is quite nice. Concordance was checked for the following quantities (4.5.0.0 is on the x-axis and this branch is on the y-axis in all plots below):. 1) Variational posterior means (`mu_*`) and standard deviations (`std_*`) for all analogous variables in the ploidy and gCNV models. There were some slight changes to the gCNV model in this branch (e.g., the functional form of the ARD prior was changed), which means some variables are no longer directly comparable. Furthermore, some variables (such as the bias factors W) are degenerate and cannot be immediately compared. Otherwise, there is good concordance between the remaining variables, e.g.:. ![image](https://github.com/broadinstitute/gatk/assets/11076296/614cf501-ca31-4199-badb-3194b7f78154); ![image](https://github.com/broadinstitute/gatk/assets/11076296/f615084d-d0bf-44e9-bcf5-98abd26ceb06); ![image](https://github.com/broadinstitute/gatk/assets/11076296/48570e53-024c-44b5-8835-3fd40b4c5866); ![image](https://github.com/broadinstitute/gatk/assets/11076296/99100e5d-05e2-4a5c-9d68-57db1b734029); ![image](https://github.com/broadinstitute/gatk/assets/11076296/abae09e1-70a5-4213-95a2-0cb10f9db192); ![image](https://github.com/broadinstitute/gatk/a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2079695268:1391,variab,variables,1391,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2079695268,1,['variab'],['variables']
Modifiability,ree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...bender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `70.968% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `92.617% <100%> (+0.531%)` | `33 <1> (+1)` | :arrow_up: |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <100%> (+1.429%)` | `2 <0> (ø)` | :arrow_down: |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <92.857%> (ø)` | `12 <12> (?)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <94.286%> (ø)` | `11 <11> (?)` | |; | [...nstitute/hellbender/utils/clipping/ClippingOp.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9DbGlwcGluZ09wLmphdmE=) | `84.365% <0%> (+1.629%)` | `91% <0%> (+2%)` | :arrow_up: |; | [...stitute/hellbender/utils/clipping/ReadClipper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310:1867,Adapt,AdapterTrimTransformer,1867,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310,1,['Adapt'],['AdapterTrimTransformer']
Modifiability,"rg\apache\commons\commons-pool2\2.8.0\commons-pool2-2.8.0.jar;C:\Program Files\JetBrains\IntelliJ IDEA 2020.1\lib\idea_rt.jar"" com.luz.push.PushApplication; Connected to the target VM, address: '127.0.0.1:62530', transport: 'socket'. . ____ _ __ _ _; /\\ / ___'_ __ _ _(_)_ __ __ _ \ \ \ \; ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \; \\/ ___)| |_)| | | | | || (_| | ) ) ) ); ' |____| .__|_| |_|_| |_\__, | / / / /; =========|_|==============|___/=/_/_/_/; :: Spring Boot :: (v2.3.0.RELEASE). 2020-05-29 15:14:30.695 INFO 12904 --- [ main] com.luz.push.PushApplication : Starting PushApplication on DESKTOP-05L3FQL with PID 12904 (C:\project\push\target\classes started by Sweet in C:\project\push); 2020-05-29 15:14:30.712 INFO 12904 --- [ main] com.luz.push.PushApplication : No active profile set, falling back to default profiles: default; 2020-05-29 15:14:32.088 WARN 12904 --- [ main] o.m.s.mapper.ClassPathMapperScanner : No MyBatis mapper was found in '[com.luz.push]' package. Please check your configuration.; 2020-05-29 15:14:32.662 INFO 12904 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8282 (http); 2020-05-29 15:14:32.675 INFO 12904 --- [ main] o.a.coyote.http11.Http11NioProtocol : Initializing ProtocolHandler [""http-nio-8282""]; 2020-05-29 15:14:32.676 INFO 12904 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]; 2020-05-29 15:14:32.677 INFO 12904 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]; 2020-05-29 15:14:32.802 INFO 12904 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext; 2020-05-29 15:14:32.802 INFO 12904 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1944 ms; 2020-05-29 15:14:32.899 INFO 12904 --- [ main] com.luz.push.utils.GcmUtils : start init gcm server; 2020-05-29 15:14:33.029 WARN 12904 --- [ main] c.g.a.oauth2.ComputeEngineCredenti",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:11692,config,configuration,11692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['config'],['configuration']
Modifiability,"roadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T00:09:07.4040311Z @VisibleForTesting; 2022-08-16T00:09:07.4040921Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4041294Z location: class CountingVariantFilter; 2022-08-16T00:09:07.4054361Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4060164Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T00:09:07.4060614Z @VisibleForTesting; 2022-08-16T00:09:07.4061233Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4061591Z location: class ReadFilter; 2022-08-16T00:09:07.4083439Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4092135Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4107682Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4116317Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4117746Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4124264Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T00:09:07.4124816Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-08-16T00:09:07.4125855Z symbol: class BiMap; 2022-08-16T00:09:07.4126189Z location: class LoggingUtils; 2022-08-16T00:09:07.4126674Z src/main/java/org/broadinstitute/he",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:12376,config,config,12376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['config'],['config']
Modifiability,"roadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T22:45:53.8024772Z @VisibleForTesting; 2022-08-16T22:45:53.8025036Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8025212Z location: class CountingVariantFilter; 2022-08-16T22:45:53.8032154Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8035089Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T22:45:53.8035234Z @VisibleForTesting; 2022-08-16T22:45:53.8035505Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8035658Z location: class ReadFilter; 2022-08-16T22:45:53.8087327Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8103864Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8113680Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8117654Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8118430Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8124030Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T22:45:53.8124383Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-08-16T22:45:53.8124657Z symbol: class BiMap; 2022-08-16T22:45:53.8124810Z location: class LoggingUtils; 2022-08-16T22:45:53.8125227Z src/main/java/org/broadinstitute/he",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:14414,config,config,14414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['config'],['config']
Modifiability,"roblem with the following location: '/home/jeremie/GATK/build/classes/java/main'. Reason: Task ':gatkDoc' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/home/jeremie/GATK/build/resources/main'. Reason: Task ':gatkDoc' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/jeremie/GATK/build/tmp/gatkDoc/javadoc.options'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.gradle.org/7.3.2/userguide/command_line_interface.html#sec:command_line_warnings. Execution optimizations have been disabled for 1 invalid unit(s) of work during this build to ensure correctness.; Please consult deprecation warnings for more details. BUILD FAILED in 33s; 5 actionable tasks: 5 executed; ```; which does not seem related to any changes I made.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1202544500:1832,plugin,plugins,1832,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1202544500,1,['plugin'],['plugins']
Modifiability,"s where results changed:. - For the snpeff test, since the behavior on this branch seems more correct to me than master, I tried running the GATK4 test case inputs with GATK3, and it produces exactly the same results as this branch does. So I think that issue was introduced by the original GATK4 port, and is fixed in this branch.; - The rest of the tests with changed results don't seem to hit your breakpoint, though. So I think we need to figure out why they changed, and maybe also compare them with GATK3 (which can be a pain because the output format is slightly different).; - As you mentioned, you changed the reference for testEvalTrackWithoutGenotypesWithSampleFields, which seems to have only affected the number of loci processed. So I'm unclear why that change was necessary. If the test truly should have been failing without this change, will it still fail if the change is reverted ? If not, can we fix it, and either way there should be a negative test for that case. A few other general comments:. - I changed this PR to `draft` mode for now, which just better categorizes it for our internal workflow purposes. When its ready for a detailed code review we can remove the `draft` status.; - The `HashMap<FeatureInput<VariantContext>, HashMap<String, Collection<VariantContext>>>` can be wrapped in a class with just a couple of methods, so we don't have to manifest that long type all over the place.; - I know this PR still in an interim state, but passing the VariantWalker in as an argument to the comp methods doesn't seem like a step forward to me. If we can't solve that problem completely in this PR (which is fine, I'm all for trying to contain this), are those changes necessary ? Perhaps that part should just wait for the next round.; - Any new classes/methods should use `final` for variables and parameters wherever applicable, and public classes and methods should have javadoc.; - Finally, I'm curious if you've tried any perf testing on this branch ? Is it better ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744689987:1888,variab,variables,1888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744689987,1,['variab'],['variables']
Modifiability,"s(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); at com.google.cloud.ServiceOptions.defaultCredentials(ServiceOptions.java:304); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:278); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:83); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Produced by pulling the docker image, **shutting off the internet connection**, mounting [helloHaplotypeCaller](https://drive.google.com/file/d/0B7akc6CTmxIHdy11R1M3ZjJJdUU/view), and running:. ```shell; docker run \; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```. Adding in a `GOOGLE_APPLICATION_CREDENTIALS` environment variable short circuits the above stack trace. ```shell; docker run \; -e GOOGLE_APPLICATION_CREDENTIALS=whatever; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:4199,variab,variable,4199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843,1,['variab'],['variable']
Modifiability,"s/theano/__init__.py"", line 66, in <module>; from theano.compile import (; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/__init__.py"", line 10, in <module>; from theano.compile.function_module import *; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 21, in <module>; import theano.compile.mode; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/mode.py"", line 10, in <module>; import theano.gof.vm; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/vm.py"", line 662, in <module>; from . import lazylinker_c; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 42, in <module>; location = os.path.join(config.compiledir, 'lazylinker_ext'); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configparser.py"", line 333, in __get__; self.__set__(cls, val_str); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configparser.py"", line 344, in __set__; self.val = self.filter(val); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configdefaults.py"", line 1745, in filter_compiledir; "" '%s'. Check the permissions."" % path); ValueError: Unable to create the compiledir directory '/root/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64'. Check the permissions. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeCommand(PythonScriptExecutor.java:79); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:192); at org.broadinstitute",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081:5007,config,configparser,5007,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081,1,['config'],['configparser']
Modifiability,seems like a good candidate to be moved into the config files...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3552#issuecomment-327585040:49,config,config,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3552#issuecomment-327585040,1,['config'],['config']
Modifiability,"serException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and GENOTYPE_GIVEN_ALLELES at the same time"");; ; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_EMITTING = -0.0;; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_CALLING = -0.0;; ; -; // also, we don't need to output several of the annotations; annotationsToExclude.add(""ChromosomeCounts"");; annotationsToExclude.add(""FisherStrand"");; @@ -651,6 +651,9 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if (!SCAC.annotateAllSitesWithPLs); logger.info(""All sites annotated with PLs forced to true for reference-model confidence output"");; SCAC.annotateAllSitesWithPLs = true;; + } else if ( ! doNotRunPhysicalPhasing ) {; + doNotRunPhysicalPhasing = true;; + logger.info(""Disabling physical phasing, which is supported only for reference-model confidence output"");; }; ; if ( SCAC.AFmodel == AFCalcFactory.Calculation.EXACT_GENERAL_PLOIDY ); @@ -678,7 +681,7 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if( SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES && consensusMode ); throw new UserException(""HaplotypeCaller cannot be run in both GENOTYPE_GIVEN_ALLELES mode and in consensus mode. Please choose one or the other."");; ; - genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, tryPhysicalPhasing);; + genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, !doNotRunPhysicalPhasing);; // initialize the output VCF header; final VariantAnnotatorEngine annotationEngine = new VariantAnnotatorEngine(Arrays.asList(annotationClassesToUse), annotationsToUse, annotationsToExclude, this, getToolkit());; ; @@ -699,8 +702,10 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; VCFConstants.DEPTH_KEY,; VCFConstants.GENOTYPE_PL_KEY);; ; - if ( tryPhysicalPhasing ); - headerInfo.add(new VCFFormatHeaderLine(HAPLOTYPE_CALLER_PHASING_KEY, VCFHeaderL",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:3579,extend,extends,3579,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237,1,['extend'],['extends']
Modifiability,"sh Babadi <mehrtash@broadinstitute.org>; Date: Wed Nov 15 01:50:03 2017 -0500. Polished code, ready for review; ; gCNV computational kernel (initial release); ; renaming gammas_s to psi_s to uniformity (sample-specific unexplained variance); ; renamed determine_ploidy_and_depth.py to cohort_determine_ploidy_and_depth.py; finite-temperature forward-backward algorithm; in the ploidy model, replaced alpha_j (NB over-dispersion) with psi_j (unexplained variance) for uniformity. Also, added the possibility of sample-specific unexplained variance in the germline contig ploidy model; ; updated I/O routines and CLIs according to team discussion; ; updated I/O routines and CLIs according to team discussion; ; changed the output layout of the ploidy determination tool; refactored parts of io.py; upped the version to 0.3 as it is not backwards compatible anymore; ; case ploidy determination tool from a given ploidy model; major code cleanup and refactoring of I/O module; refactoring of common CLI script snippets; ; removed all ""targets""; some code cleanup; ; pad flat class bitmask w/ a given padding value in the hybrid q_c_expectation_mode; option to disable annealing and keep the temperature fixed; ; bugfix in finite-temperature forward-backward; further refactoring of model I/O; ; the option to take a previously trained model as starting point in cohort CLI; the option to take previous calls as a starting point in cohort CLI; ; option to save and load adamax moments; ; import/export adamax bias correction tensor; ; refactoring related to fancy opt I/O; added average ploidy column to read depth; updated docs of hybrid inference; ; modeling intervals can span multiple contigs now; ploidy can change; across contigs with no issue; ; save/load adamax state to .npy instead of .tsv for speed; ; part 1 of doc updates; ; part 2 of doc updates; ; part 3 of doc updates; ; part 4 of doc updates; ; bumped version to 0.5; readme; ; update readme; ; last minute stylistic doc updates.; ````",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:11261,refactor,refactoring,11261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,8,['refactor'],['refactoring']
Modifiability,"sing ) {; + doNotRunPhysicalPhasing = true;; + logger.info(""Disabling physical phasing, which is supported only for reference-model confidence output"");; }; ; if ( SCAC.AFmodel == AFCalcFactory.Calculation.EXACT_GENERAL_PLOIDY ); @@ -678,7 +681,7 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if( SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES && consensusMode ); throw new UserException(""HaplotypeCaller cannot be run in both GENOTYPE_GIVEN_ALLELES mode and in consensus mode. Please choose one or the other."");; ; - genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, tryPhysicalPhasing);; + genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, !doNotRunPhysicalPhasing);; // initialize the output VCF header; final VariantAnnotatorEngine annotationEngine = new VariantAnnotatorEngine(Arrays.asList(annotationClassesToUse), annotationsToUse, annotationsToExclude, this, getToolkit());; ; @@ -699,8 +702,10 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; VCFConstants.DEPTH_KEY,; VCFConstants.GENOTYPE_PL_KEY);; ; - if ( tryPhysicalPhasing ); - headerInfo.add(new VCFFormatHeaderLine(HAPLOTYPE_CALLER_PHASING_KEY, VCFHeaderLineCount.UNBOUNDED, VCFHeaderLineType.String, ""Physical phasing information, each unique ID within a given sample (but not across samples) connects alternate alleles as occurring on the same haplotype""));; + if ( ! doNotRunPhysicalPhasing ) {; + headerInfo.add(new VCFFormatHeaderLine(HAPLOTYPE_CALLER_PHASING_ID_KEY, 1, VCFHeaderLineType.String, ""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group""));; + headerInfo.add(new VCFFormatHeaderLine(HAPLOTYPE_CALLER_PHASING_GT_KEY, 1, VCFHeaderLineType.String, ""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another""));; + }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:4352,extend,extends,4352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237,1,['extend'],['extends']
Modifiability,"st and there's no batch api for it? Multi layer docker builds are pretty standard from what I understand. . It sounds like your suggestions are talking about 2 slightly different issues to me. 1. Too many layers:. We typically have squashed the GATK docker images, but we recently switched to building our release images with google cloud build. Since squash is *STILL* an experimental feature in docker we've had trouble getting it to work there. Since the size reduction was pretty minimal from squashing we figured it would be ok to not prioritize it. It's definitely possible for us to consolidate various layers in the build. Or manually squash the images. We can take a look for our next release. Wide workflows on azure are something we need to support. 2. Docker size reduction:; I've spend a lot of time looking at this in the past. Our docker image is huge, but it's mostly due to the massive size of our python and R dependencies. I've done a bunch of work reducing temporary files in independent layers and using multiple stages to reduce the size. There's not much low hanging fruit left there. Similarly, moving to alpine is tricky an has limited benefit. GATK packages a number of C libraries which do not work out of the box on alpine due to the different C runtime. (At least that was the case the last time I investigated it a few years ago. ) I suspect there's a way to port things so they work on it, but it's not something we can do now. It also wouldn't be much of a help, the base image is completely dwarfed by piles of python and R dependencies which are very difficult to safely trim. Anyway, that's the state of things. We've considered a java only image for a while which would be much smaller than the current one. (although still fat by most docker standards...). We've never released one publicly because it seemed like it might cause confusion, but it's a reasonable possibility. . If you have any secret methods to reduce the size of python or R installations we're ha",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427:1203,layers,layers,1203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427,1,['layers'],['layers']
Modifiability,"stributions/timeseries.py"", line 1, in <module>; import theano.tensor as tt; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/__init__.py"", line 66, in <module>; from theano.compile import (; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/__init__.py"", line 10, in <module>; from theano.compile.function_module import *; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 21, in <module>; import theano.compile.mode; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/mode.py"", line 10, in <module>; import theano.gof.vm; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/vm.py"", line 662, in <module>; from . import lazylinker_c; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 42, in <module>; location = os.path.join(config.compiledir, 'lazylinker_ext'); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configparser.py"", line 333, in __get__; self.__set__(cls, val_str); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configparser.py"", line 344, in __set__; self.val = self.filter(val); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configdefaults.py"", line 1745, in filter_compiledir; "" '%s'. Check the permissions."" % path); ValueError: Unable to create the compiledir directory '/root/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64'. Check the permissions. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeCommand(PythonScriptExecutor.java:79); at org.broadinstitu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081:4873,config,configparser,4873,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-496007081,1,['config'],['configparser']
Modifiability,"t$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:530); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getGermlineAltAlleleFrequencies(SomaticGenotypingEngine.java:354); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getNegativeLogPopulationAFAnnotation(SomaticGenotypingEngine.java:337); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:155); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:259); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:306); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; ```. one happened while working on chr21, the other on chr9",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-936771625:2971,variab,variable,2971,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-936771625,1,['variab'],['variable']
Modifiability,t&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9kcmFnc3RyL0NhbGlicmF0ZURyYWdzdHJNb2RlbC5qYXZh) | `70.345% <ø> (ø)` | |; | [...r/utils/fasta/CachingIndexedFastaSequenceFile.java](https://codecov.io/gh/broadinstitute/gatk/pull/7920/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9mYXN0YS9DYWNoaW5nSW5kZXhlZEZhc3RhU2VxdWVuY2VGaWxlLmphdmE=) | `70.330% <ø> (-1.099%)` | :arrow_down: |; | [...t/java/org/broadinstitute/hellbender/MainTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7920/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluVGVzdC5qYXZh) | `2.564% <ø> (-82.182%)` | :arrow_down: |; | [...Plugin/GATKAnnotationPluginDescriptorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7920/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yVW5pdFRlc3QuamF2YQ==) | `7.219% <ø> (-81.016%)` | :arrow_down: |; | [...GATKPlugin/GATKReadFilterPluginDescriptorTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7920/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yVGVzdC5qYXZh) | `0.484% <ø> (-88.136%)` | :arrow_down: |; | [...lbender/engine/AssemblyRegionIteratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7920/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1239413884:2777,Plugin,Plugin,2777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1239413884,1,['Plugin'],['Plugin']
Modifiability,"te). Strands of the intervals indicate whether the distal target intervals are; * upstream or downstream of their proposed breakpoints: true indicates that the breakpoint is upstream of the interval; * start position; false indicates that the breakpoint is downstream of the interval end position; */; ```. What else would you like to see documented there? . - The use of the word strand in this case is largely driven by a mapping of these data structures to the BEDPE format, which is the older format for representing breakpoints implied by paired-end mapping data without assembly. If you only consider read pair mappings, strand has the natural interpretation of being the strand to which reads aligned. For example, a deletion's two intervals have strands `+` and `-` because the `+` reads align at left breakpoint and `-` reads align near the right breakpoint. Extending the concept to supplementary mappings of split reads muddies the concept a bit, which made me change the definition of strand to the existing one: whether the evidence suggests a breakpoint upstream of the interval start or downstream of the interval end. . - I created `StrandedInterval` mostly just as a data container since I was often passing around an interval and an associated strand, and using them in conjunction with the `PairedStrandedIntervalTree` data structure. My goal with those was to have them be utility classes that could be used by anyone without regards to the particular mechanics of imprecise evidence clustering I've implemented here. I'd prefer to put the definition of how we're interpreting the interval and strand in our logic classes (`BreakpointEvidence`, `EvidenceTargetLink`, and EvidenceTargetLinkClusterer`). Does that make sense?. - A ""distal target region"" can be represented by a `StrandedInterval`. So can the original, proximal (non-distal) location of the breakpoint evidence. An `EvidenceTargetLink` has the two `StrandedInterval` objects representing the proximal and distal loca",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471:1758,Extend,Extending,1758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471,1,['Extend'],['Extending']
Modifiability,ter yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 11:33:26.271 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.272 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:33:26.272 INFO CountReadsSpark - For support and documentat,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:1963,config,configuration,1963,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['config'],['configuration']
Modifiability,thanks for the review @kcibul. I made some changes accordingly. re: PrepareCallset file of sample names. That would be nice! It would make this workflow simpler and it also simplifies the access requirements for PrepareCallset. re: Dockstore. We actually ruled this out because Terra says that the definition of a method configuration can change automatically if its updated in dockstore. Which can be useful but it adds a security risk since a compromised Dockstore can change the definition of the production AoU extraction WDL which runs with highly elevated permissions. We already have a script that creates method configurations from github so I can probably add something a little hacky to resolve relative imports to the raw github file that it refers to.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-846494686:321,config,configuration,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-846494686,4,['config'],"['configuration', 'configurations']"
Modifiability,"the implementation of posterior sampling, 3) some shape/dimshuffle operations, and other things along these lines. Using a single test shard of 20 1kGP WES samples x 1000 intervals, I have verified determinism/reproducibility for DetermineGermlineContigPloidy COHORT/CASE modes, GermlineCNVCaller COHORT/CASE modes, and PostprocessGermlineCNVCalls. Numerical results are also relatively close to those from 4.4.0.0 for all identifiable call and model quantities (albeit far outside any reasonable exact-match thresholds, most likely due to differences in RNG, sampling, and the aforementioned priors). Some remaining TODOs:. - [x] Rebuild and push the base Docker. EDIT: Mostly covered by #8610, but this also includes an addition of `libblas-dev`.; - [x] Update expected results for integration tests, perhaps add any that might be missing. EDIT: These were generated on WSL Ubuntu 20.04.2, we'll see if things pass on 22.04. Note that changing the ARD priors does change the *names* of the expected files, since the transform is appended to the corresponding variable name. DetermineGermlineContigPloidy and PostprocessGermlineCNVCalls are missing exact-match tests and should probably have some, but I'll leave that to someone else.; - [x] Update other python integration tests.; - [x] Clean up some of the changes to the priors.; - [x] Clean up some TODO comments that I left to track code changes that might result in changed numerics. I'll try to go through and convert these to PR comments in an initial review pass.; - [x] Test over multiple shards on WGS and WES. Probably some scientific tests on ~100 samples in both cohort and case mode would do the trick. We should also double check runtime/memory performance (I noted ~1.5x speedups, but didn't measure carefully; I also want to make sure the changes to posterior sampling didn't introduce any memory issues). @mwalker174 will ping you when a Docker is ready! Might be good to loop in Isaac and/or Jack as well.; - [x] Perhaps add back ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:2232,variab,variable,2232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,1,['variab'],['variable']
Modifiability,"toHDFSSpark - Defaults.REFERENCE_FASTA : null; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Defaults.USE_CRAM_REF_DOWNLOAD : false; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Deflater IntelDeflater; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Inflater IntelInflater; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Initializing engine; 02:03:27.963 INFO ParallelCopyGCSDirectoryIntoHDFSSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4769b07b] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@5ef60048].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4769b07b] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@5ef60048].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase).; log4j:WARN Please initia",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296871363:1834,variab,variable,1834,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296871363,1,['variab'],['variable']
Modifiability,tools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /scratch/home/int/eva/username/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-spark.jar PathSeqPipelineSpark --spark-master spark://xx.xx.xx.xx:7077 --input test_sample.bam --filter-bwa-image hg19mini.fasta.img --kmer-file hg19mini.hss --min-clipped-read-length 70 --microbe-fasta e_coli_k12.fasta --microbe-bwa-image e_coli_k12.fasta.img --taxonomy-file e_coli_k12.db --output output.pathseq.bam --verbosity DEBUG --scores-output output.pathseq.txt; 17:39:18.382 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 17:39:18.825 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/scratch/home/int/eva/username/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 17:39:18.857 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/username/libgkl_compression3681606702485397808.so; 17:39:19.218 INFO PathSeqPipelineSpark - ------------------------------------------------------------; 17:39:19.218 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 17:39:19.218 INFO PathSeqPipelineSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:39:19.219 INFO PathSeqPipelineSpark - Executing as username@node016 on Linux v2.6.32-220.4.1.el6.x86_64 amd64; 17:39:19.220 INFO PathSeqPipelineSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_131-b11; 17:39:19.220 INFO PathSeqPipelineSpark - ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:2348,variab,variables,2348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,4,"['config', 'variab']","['configured', 'variables']"
Modifiability,"tor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 11:33:26.271 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.272 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:33:26.272 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:33:26.272 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 11:33:26.273 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 11:33:26.273 INFO CountReadsSpark - Start Date/Time: January 7, 2019 11:33:24 AM EST; 11:33:26.273 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.273 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:2355,variab,variables,2355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,"['config', 'variab']","['configured', 'variables']"
Modifiability,tractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx3500m -jar /root/gatk.jar Funcotator --data-sources-path /cromwell_root/datasources_dir --ref-version hg38 --output-file-format VCF -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta -V gs://fc-secure-d2a2d895-a7af-4117-bdc7-652d7d268324/94e769a1-28e1-4bd7-b09f-9e47fb7d8352/omics_mutect2/14fe5685-740c-4e09-9d1a-8c8d14c0ae5b/call-mutect2/Mutect2/2de52f4f-eea0-4ec7-acc1-f47b1a2d1e6c/call-Filter/attempt-2/CDS-2jucw0.hg38-filtered.vcf.gz -O CDS-2jucw0.hg38-filtered.vcf.gz.annotated.vcf.gz -L /cromwell_root/ccleparams/region_file_wgs.list --annotation-default normal_barcode: --annotation-default tumor_barcode:NP5 --annotation-default Center:DEPMAP --annotation-default source:Unknown; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:7041,variab,variable,7041,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,1,['variab'],['variable']
Modifiability,"ts header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and complexity of the header tag might also depend on the ; execution environment. If the execution environment only supports a ; small finite number of headers, the header tag could be a small integer, ; or in a different execution environment it could be; a unique hash of the header or something like that. Memory footprint in ; the receiver is minimized because many SAMRecords can all share the same ; header object.; This requires more work to support in each execution environment, but it ; seems like it could be efficient and allows application code written to ; operate on SAMRecords to be portable; across different execution environments without having to contend with ; the possible presence of headerless SAMRecords. -Bob. On 9/17/15 4:28 PM, droazen wrote:. > @davidadamsphd https://github.com/davidadamsphd, @lbergelson ; > https://github.com/lbergelson, and myself met for an hour or two ; > just now to discuss this issue, and after reviewing all the options I ; > think we were convinced by the following argument:; > ; > The |SAMRecord| class currently allows its header to be set to null, ; > so if there are cases where the class won't function properly or can ; > enter into an inconsistent state when a header is not present these ; > should be treated as bugs and patched, and we should add unit tests to ; > htsjdk to prove that headerless |SAMRecords| function properly. Then ; > in hellbender we can freely use headerless |SAMRecords| everywhere, ; > only restoring the header to the record when writing out the final bam ; > (since our bam writers",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:2594,portab,portable,2594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,1,['portab'],['portable']
Modifiability,tureManager - Using codec VCFCodec to read file gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf; 01:39:08.399 INFO FilterAlignmentArtifacts - Done initializing engine; 01:39:09.523 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 01:39:09.565 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 01:39:09.566 INFO IntelPairHmm - Available threads: 4; 01:39:09.566 INFO IntelPairHmm - Requested threads: 4; 01:39:09.566 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 01:39:09.567 INFO ProgressMeter - Starting traversal; 01:39:09.567 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; munmap_chunk(): invalid pointer; Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx11500m -jar /root/gatk.jar FilterAlignmentArtifacts -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -V gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf -I gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/209d1183-ed9a-4755-a4b3-d595797640ea/PreProcessingForVariantDiscovery_GATK4/9f7c0ab6-b61b-4797-92f1-7929bbf677d8/call-GatherBamFiles/22.hg38.bam --bwa-mem-index-image /cromwell_root/gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle -O 22.hg38-filtered.vcf; 2020/07/25 01:46:01 Starting delocalization.; 2020/07/25 01:46:02 Delocalization script execution started...; 2020/07/25 01:46:02 Delocalizing output /cromwell_root/memory_retry_rc -> gs://fc-ac4624cb-a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:5507,variab,variable,5507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860,1,['variab'],['variable']
Modifiability,typingEngineUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5365/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyR2Vub3R5cGluZ0VuZ2luZVVuaXRUZXN0LmphdmE=) | `100% <100%> (ø)` | `31 <0> (ø)` | :arrow_down: |; | [...ypecaller/AssemblyBasedCallerGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5365/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `89.45% <100%> (+0.049%)` | `89 <0> (+1)` | :arrow_up: |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/5365/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `83.117% <0%> (+1.948%)` | `43% <0%> (+1%)` | :arrow_up: |; | [...stitute/hellbender/utils/config/ConfigFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5365/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb25maWcvQ29uZmlnRmFjdG9yeS5qYXZh) | `76.398% <0%> (+3.727%)` | `45% <0%> (+2%)` | :arrow_up: |; | [...r/arguments/CopyNumberArgumentValidationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5365/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FyZ3VtZW50cy9Db3B5TnVtYmVyQXJndW1lbnRWYWxpZGF0aW9uVXRpbHMuamF2YQ==) | `77.778% <0%> (+6.173%)` | `20% <0%> (+1%)` | :arrow_up: |; | [...tute/hellbender/utils/runtime/ProcessSettings.java](https://codecov.io/gh/broadinstitute/gatk/pull/5365/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1Byb2Nlc3NTZXR0aW5ncy5qYXZh) | `93.75% <0%> (+6.25%)` | `18% <0%> (+2%)` | :arrow_up: |; | [...te/hellbender/utils/python/PythonExecutorBase.java](https://codecov.io/gh/br,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5365#issuecomment-433471265:1961,config,config,1961,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5365#issuecomment-433471265,2,"['Config', 'config']","['ConfigFactory', 'config']"
Modifiability,"ub.com> wrote:; > ; > @SHuang-Broad commented on this pull request.; > ; > In src/main/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/prototype/CpxVariantDetector.java:; > ; > > + this.tigWithInsMappings = new AssemblyContigWithFineTunedAlignments(contig, tigWithInsMappings.insertionMappings);; > +; > + this.basicInfo = new BasicInfo(contig);; > +; > + annotate(refSequenceDictionary);; > + }; > +; > + private static List<AlignmentInterval> deOverlapAlignments(final List<AlignmentInterval> originalAlignments,; > + final SAMSequenceDictionary refSequenceDictionary) {; > + final List<AlignmentInterval> result = new ArrayList<>(originalAlignments.size());; > + final Iterator<AlignmentInterval> iterator = originalAlignments.iterator();; > + AlignmentInterval one = iterator.next();; > + while (iterator.hasNext()) {; > + final AlignmentInterval two = iterator.next();; > + // TODO: 11/5/17 an edge case is possible where the best configuration contains two alignments,; > + // one of which contains a large gap, and since the gap split happens after the configuration scoring,; > I agree it is backwards. But...; > ; > The reason was that the (naive) alignment configuration scoring module rightnow uses MQ and AS (aligner score) for picking the ""best"" configuration (i.e. sub-list of the alignments given by aligner), which would be technically wrong if we were to split the gap and to simply grab the originating alignment's values.; > ; > This is especially true for AS, whose recomputing takes more time, and code, and forces us to know how AS are computed in the aligner so that there's no bias in computing the scores of naive alignments vs gap-split alignments (may not matter in practice, but still takes more code to compute).; > ; > Lots of the code in the discovery stage was devoted actually to alignment related acrobatics and edge cases so that the breakpoints we could resolve are as accurate as possible.; > I've kept in mind your wisdom that different aligners may ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009:1509,config,configuration,1509,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009,4,['config'],['configuration']
Modifiability,urces.v1.6.20190124s/chr1_b_bed/hg38/chr1_b_bed.tsv; > 12:28:17.997 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/chr1_b_bed.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_b_bed/hg38/chr1_b_bed.tsv; > WARNING 2020-07-21 12:28:17 AsciiLineReader Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; > 12:28:18.002 INFO DataSourceUtils - Setting lookahead cache for data source: Oreganno : 100000; > 12:28:18.009 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/oreganno.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/oreganno/hg38/oreganno.tsv; > 12:28:18.020 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/oreganno/hg38/oreganno.config; > 12:28:18.120 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/oreganno.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/oreganno/hg38/oreganno.tsv; > 12:28:18.121 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/oreganno.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/oreganno/hg38/oreganno.tsv; > WARNING 2020-07-21 12:28:18 AsciiLineReader Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; > 12:28:18.125 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/simple_uniprot_Dec012014.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/simple_uniprot/hg38/simple_uniprot_Dec012014.tsv; > 12:28:18.424 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975:10036,config,config,10036,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975,1,['config'],['config']
Modifiability,"ureInput;. public CodecWrapper(FeatureCodec<FEATURE_TYPE, SOURCE> childCodec, FeatureInput<FEATURE_TYPE> featureInput); {; this.childCodec = childCodec;; this.featureInput = featureInput;; }. @Override; public Feature decodeLoc(SOURCE source) throws IOException {; return childCodec.decodeLoc(source);; }. @Override; public FEATURE_TYPE decode(SOURCE source) throws IOException {; FEATURE_TYPE feature = childCodec.decode(source);. //Either look for marker class or otherwise poke in FeatureInput here:; if (feature instanceof VariantContext); {; feature = new FeatureInputAwareVariantContext(feature, featureInput);; }. return feature;; }. @Override; public FeatureCodecHeader readHeader(SOURCE source) throws IOException {; return childCodec.readHeader(source);; }. @Override; public Class<FEATURE_TYPE> getFeatureType() {; return childCodec.getFeatureType();; }. @Override; public SOURCE makeSourceFromStream(InputStream bufferedInputStream) {; return childCodec.makeSourceFromStream(bufferedInputStream);; }. @Override; public LocationAware makeIndexableSourceFromStream(InputStream inputStream) {; return childCodec.makeIndexableSourceFromStream(inputStream);; }. @Override; public boolean isDone(SOURCE source) {; return childCodec.isDone(source);; }. @Override; public void close(SOURCE source) {; childCodec.close(source);; }. @Override; public boolean canDecode(String path) {; return childCodec.canDecode(path);; }; }. public static interface FeatureInputAware<FEATURE_TYPE extends Feature>; {; public FeatureInput<FEATURE_TYPE> getFeatureInput();; }. public static class FeatureInputAwareVariantContext extends VariantContext implements FeatureInputAware<VariantContext>; {; private FeatureInput<VariantContext> featureInput;. public FeatureInputAwareVariantContext(VariantContext parent, FeatureInput<VariantContext> featureInput); {; super(parent);; this.featureInput = featureInput;; }. @Override; public FeatureInput<VariantContext> getFeatureInput() {; return featureInput;; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823546766:2219,extend,extends,2219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823546766,2,['extend'],['extends']
Modifiability,va:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.collectCaseStatsSequencial(CalibrateDragstrModel.java:459); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.traverse(CalibrateDragstrModel.java:159); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar CalibrateDragstrModel --tmp-dir tmp -R /restricte; d/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --str-table-path gvcf.STR/HGDP00001.alt_bwamem_GRCh38DH.20181023.Brahui/HGDP00001.alt_bwamem_GRCh38DH.20181023.Brahui.STR.table -O gvcf.STR/HGDP00001.alt_bwamem_GRCh38DH.20181023.Brahui/HGDP00001.alt_bwamem_GRCh38DH.20181023.Brahui; .Dragstr.model -I ../pop/Brahui/HGDP00001/alignment/HGDP00001.alt_bwamem_GRCh38DH.20181023.Brahui.cram; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182#issuecomment-821876394:6783,variab,variable,6783,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182#issuecomment-821876394,1,['variab'],['variable']
Modifiability,"willing to give it a try but I need minimal info to do so. * can I add `library(""ggplot2"")` to the code or will this new library not be supported by the package?. * what value (are these defaults?) do. ```; targetTITV = as.numeric(args[2]); targetSensitivity = as.numeric(args[3]) ; ```. take for a command like this. > cmd=""java ${javaopts} -jar $GATK/gatk.jar \; > 	VariantRecalibrator \; > 	-R ${reference_fa} \; > 	-V ${outfolder}/gatk_variants_excesshet_sitesonly.vcf.gz \; > 	-O ${outfolder}/gatk_variants_recalibrate_SNP.recal.vcf.gz \; > 	${intervals} \; > 	--resource:1001Gsnp,known=true,training=true,truth=true,prior=12.0 ${knownsnps} \; > 	--trust-all-polymorphic \; > 	--use-annotation DP \; > 	--use-annotation QD \; > 	--use-annotation FS \; > 	--use-annotation SOR \; > 	--use-annotation MQ \; > 	--use-annotation MQRankSum \; > 	--use-annotation ReadPosRankSum \; > 	--mode SNP \; > 	--max-gaussians ${maxSNPgaussians} \; > 	--tranches-file ${outfolder}/gatk_variants_recalibrate_snp.tranches \; > 	--tranche 100.0 \; > 	--tranche 99.95 \; > 	--tranche 99.9 \; > 	--tranche 99.8 \; > 	--tranche 99.6 \; > 	--tranche 99.5 \; > 	--tranche 99.4 \; > 	--tranche 99.3 \; > 	--tranche 99.0 \; > 	--tranche 98.0 \; > 	--tranche 97.0 \; > 	--tranche 90.0 \; > 	--rscript-file ${outfolder}/gatk_variantsgatk_variants_recalibrate_snp_plots.R \; > 	--tmp-dir ${basedir}/tmpfiles/"". Sorry but I do not know where to look in the java code for this. Thanks in advance",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6585#issuecomment-624680466:664,polymorphi,polymorphic,664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6585#issuecomment-624680466,1,['polymorphi'],['polymorphic']
Modifiability,"windows in my implementation is different from the one in `ReadWindowWalker`: first, the overlap between windows is only in one direction; second, `SlidingWindowWalker` is more like a reference/interval walker, from the beginning of the reference (or interval) till the end, it walks in overlapping windows. One example is the following (window-size 10, window-step 5, the - represent the window):. ```; Reference: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; Windows1: _ _ _ _ _ _ _ _ _ _; Windows2: _ _ _ _ _ _ _ _ _ _; Windows3: _ _ _ _ _ _ _ _ _ _; Windows4: _ _ _ _ _ _ _ _ _ _; Windows5: _ _ _ _ _ _ _ _ _ _; ```. Of course, after having a look to `ReadWindowWalker` I think that several things could be improved in my implementation for a general `SlidingWindowWalker`:; - Apply function similar to the `ReadWindowWalker`, with `ReadWindow` being empty if reads are not provided.; - Three window options: `windowSize` (the actual size of the window), `windowStep` (how much advance for the following window) and `windowPadding` (how much extend the window in both directions). Using this abstraction, `ReadWindowWalker` could be implemented setting `windowSize=windowStep`, and the problem that I need to solve could be implemented setting `windowPadding=0`. The simplest way to acomplish this is to use the current implementation of `ReadWindowWalker` to develop a `SlidingWindowWalker` adding three abstract methods for the three parameters (`getWindowSize()`, `getWindowStep()` and `getWindowPadding()`, and implement `ReadWindowWalker` as a extension of this interface setting `getWindowStep()` to return `getWindowSize()` and `requiresReads()` to true. I can do this once the PR #1567 is accepted and generate the two interfaces (to be sure that the integration with the HC engine is working as expected with the changes), or just implement the `SlidingWindowWalker` and you can include it in the HC PR, or update afterwards to avoid redundancy in the code. What do you thi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775:1629,extend,extend,1629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775,1,['extend'],['extend']
Modifiability,"yf_documentation_update we; can use that for initial testing. On Tue, Dec 5, 2017 at 1:56 PM, sooheelee <notifications@github.com> wrote:. > @samuelklee <https://github.com/samuelklee>, thanks for the update and; > suggestion. I moved CollectAllelicCounts to the Coverage Analysis; > category. CollectFragmentCounts isn't on the list currently so I added it; > to the same. I hope I'm not missing a bunch of other new tools given I; > missed this one.; >; > @yfarjoun <https://github.com/yfarjoun>; >; > - You are now in charge of deciding whether we should include; > authorship in code. What the Comms team wants is for authorship to NOT show; > up in the gatkDoc/javaDoc. If you want to keep them, author lines should be; > at the bottom and formatted so they do not show up in the documentation.; > Geraldine is fine with completely removing them if you prefer that. There; > is a format trick that has javaDoc skip the author line and I can get that; > to you if you decide to keep some of these and @vdauwera; > <https://github.com/vdauwera> would know this or I can get you what I; > see in other docs. Let either of us know.; > - I can help you test your changes. I think the categories are good to; > go now so I will need to put these into both Picard and GATK; > HelpConstants.java, with the latter being a placeholder until the new; > Picard release is incorporated into the next GATK release, with variables; > that then must be included in each tool doc. I will find an example in a; > bit. Which tool do you want to test? @cmnbroad; > <https://github.com/cmnbroad> can explain the engineering details in; > engineering lingo if you need more information.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349404645>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0jIdprE580XBgq1jL-EIV1hFOcDyks5s9ZHAgaJpZM4QitCF>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349407253:1482,variab,variables,1482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349407253,1,['variab'],['variables']
Performance, 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:362); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:353); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:46); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:134); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:40); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 18 more; 19/02/18 16:58:29 INFO org.spark_pro,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:7675,concurren,concurrent,7675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['concurren'],['concurrent']
Performance, 	at com.github.discvrseq.walkers.BackportLiftedVcf.apply(BackportLiftedVcf.java:156); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at com.github.discvrseq.Main.main(Main.java:51); Caused by: java.lang.ClassNotFoundException: org.xerial.snappy.LoadSnappy; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	... 26 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333579182:2635,Load,LoadSnappy,2635,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333579182,4,"['Load', 'load']","['LoadSnappy', 'loadClass']"
Performance," ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-NISTSampleHeadToHead/BenchmarkComparison/a39481f5-0969-4891-a843-f3c3fd7437d1/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-NISTSampleHeadToHead/BenchmarkComparison/a39481f5-0969-4891-a843-f3c3fd7437d1/call-BenchmarkVCFControlSample/Benchmark/0c99102a-bca1-4426-97c6-5a311ace93c1/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""95.62183055555556"",; ""NIST evalHCsystemhours"": ""0.18361111111111117"",; ""NIST evalHCwallclockhours"": ""64.22846111111112"",; ""NIST evalHCwallclockmax"": ""3.3683277777777776"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-NISTSampleHeadToHead/BenchmarkComparison/a39481f5-0969-4891-a843-f3c3fd7437d1/call-EVALRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-NISTSampleHeadToHead/BenchmarkComparison/a39481f5-0969-4891-a843-f3c3fd7437d1/call-BenchmarkVCFTestSample/Benchmark/a3925c8a-7e0a-4fec-8507-f885061b69c3/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-CreateHTMLReport/cacheCopy/report.html""; }; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069766207:14465,cache,cacheCopy,14465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069766207,2,['cache'],['cacheCopy']
Performance," - 1:210675831 4.2 5438000 1282169.2; 15:39:25.463 INFO ProgressMeter - 10:119579965 4.4 5479000 1242549.2; 15:39:35.700 INFO ProgressMeter - 11:118752077 4.6 5530000 1207397.2; 15:39:46.028 INFO ProgressMeter - 12:58875536 4.8 5592000 1176709.9; 15:39:56.079 INFO ProgressMeter - 13:37022394 4.9 5628000 1143956.7; 15:40:06.117 INFO ProgressMeter - 16:14727212 5.1 5728000 1125992.7; 15:40:16.383 INFO SplitNCigarReads - Shutting down engine; [March 2, 2023 3:40:16 PM EST] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 5.27 minutes.; Runtime.totalMemory()=3432513536; java.lang.ClassCastException: htsjdk.samtools.BAMRecord cannot be cast to java.lang.Comparable; 	at java.util.Arrays$NaturalOrder.compare(Arrays.java:102); 	at java.util.TimSort.countRunAndMakeAscending(TimSort.java:355); 	at java.util.TimSort.sort(TimSort.java:234); 	at java.util.ArraysParallelSortHelpers$FJObject$Sorter.compute(ArraysParallelSortHelpers.java:145); 	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401); 	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734); 	at java.util.Arrays.parallelSort(Arrays.java:1180); 	at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:247); 	at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:182); 	at htsjdk.samtools.SAMFileWriterImpl.addAlignment(SAMFileWriterImpl.java:202); 	at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:36); 	at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); 	at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:123); 	at java.lang.Thread.run(Thread.java:750); 	Suppressed: htsjdk.samtools.util.RuntimeIOException: Attempt to add record to closed writer.; 		at htsjdk.samtools.util.AbstractAs",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452525485:6103,concurren,concurrent,6103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452525485,1,['concurren'],['concurrent']
Performance," --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:48:31.693 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.693 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 13:48:31.693 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:48:31.694 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:48:31.694 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:48:31.694 INFO CountReadsSpark - Start Date/Time: December 21, 2018 1:48:31 PM EST; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.695 INFO CountReadsSpark - HTSJDK Vers",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:1878,Load,Loading,1878,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,1,['Load'],['Loading']
Performance," 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 18/04/24 14:34:27 INFO DAGScheduler: Job 0 failed: first at ReadsSparkSource.java:221, took 4.816635 s; ```; Our system is an HPC, where all the nodes share the same file system. I run my SPARK on only one node to test the software. I red elesewhere that this might be aproblem of missing jars, so I tried to inlcude these libraries in the SPARK jar folder and added the option:; `; --conf [--jars=""~/bin/spark-2.2.0-bin-hadoop2.7/jars/hbase-client-1.4.3.jar, ~/bin/spark-2.2.0-bin-hadoop2.7/jars/hbase-common-1.4.3.jar, ~/bin/spark-2.2.0-bin-hadoop2.7/jars/hbase-hadoop2-compat-1.4.3.jar, ~/bin/spark-2.2.0-bin-hadoop2.7/jars/hive-hbase-handler-1.2.1.spark2.jar"" ]`. But I still get the error. Is GATK using hbase? If yes shall some jars be included to a local SPARK system to enable it to run GATK tools? Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383916494:1991,concurren,concurrent,1991,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383916494,1,['concurren'],['concurrent']
Performance," 11 hours to get to the point where the error occurs it has been difficult to trouble shoot, I am hoping that I can fix this without rebuilding everything which is why I decided to write. Thanks for any information or suggestions you may have. . Dan; ; Using GATK jar /home/dan_vanderpool/src/gatk-4.2.5.0/gatk-package-4.2.5.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx1600g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /home/dan_vanderpool/src/gatk-4.2.5.0/gatk-package-4.2.5.0-local.jar GenotypeGVCFs -R /home/dan_vanderpool/Wolf_raw_reads/Wolf_genome/GCA_905319855.2_mCanLor1.2_genomic.fa -V gendb://Wolf_Genome_Variantsdb -O All_Wolf_Samples_Joint_Genotypes_Raw.vcf.gz -L /scratch/dan/Wolf_reads_raw/Wolf_GenCov300_Q20_Merged.interval_list -imr ALL --genomicsdb-max-alternate-alleles 10 --max-alternate-alleles 6; 17:49:29.781 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/dan_vanderpool/src/gatk-4.2.5.0/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 23, 2022 5:49:30 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:49:30.164 INFO GenotypeGVCFs - ------------------------------------------------------------; 17:49:30.165 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.2.5.0; 17:49:30.165 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:49:30.165 INFO GenotypeGVCFs - Executing as dan_vanderpool@0e07622619ad on Linux v4.4.0-210-generic amd64; 17:49:30.165 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v10.0.2+13; 17:49:30.166 INFO GenotypeGVCFs - Start Date/Time: February 23, 2022 at 5:49:29 PM UTC; 17:49:30.166 INFO GenotypeGVCFs - -------------------------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1049112454:4188,Load,Loading,4188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1049112454,1,['Load'],['Loading']
